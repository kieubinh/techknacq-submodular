{
  "info": {
    "authors": [
      "Emmanuel Giguet",
      "Pierre-Sylvain Luquet"
    ],
    "book": "International Conference on Computational Linguistics and Annual Meeting of the Association for Computational Linguistics – Poster Sessions",
    "id": "acl-P06-2035",
    "title": "Multilingual Lexical Database Generation from Parallel Texts in 20 European Languages With Endogenous Resources",
    "url": "https://aclweb.org/anthology/P06-2035",
    "year": 2006
  },
  "references": [
    "acl-E03-1026",
    "acl-H91-1026",
    "acl-J93-1006",
    "acl-J96-1001",
    "acl-P91-1022",
    "acl-P91-1023",
    "acl-P93-1003",
    "acl-P94-1051",
    "acl-W96-0107",
    "acl-W98-1239"
  ],
  "sections": [
    {
      "heading": "Abstract",
      "text": [
        "This paper deals with multilingual database generation from parallel corpora.",
        "The idea is to contribute to the enrichment of lexical databases for languages with few linguistic resources.",
        "Our approach is endogenous: it relies on the raw texts only, it does not require external linguistic resources such as stemmers or taggers.",
        "The system produces alignments for the 20 European languages of the ‘Acquis Communautaire’ Corpus."
      ]
    },
    {
      "heading": "1 Introduction",
      "text": []
    },
    {
      "heading": "1.1 Automatic processing of bilingual and multilingual corpora",
      "text": [
        "Processing bilingual and multilingual corpora constitutes a major area of investigation in natural language processing.",
        "The linguistic and translational information that is available make them a valuable resource for translators, lexicographers as well as terminologists.",
        "They constitute the nucleus of example-based machine translation and translation memory systems.",
        "Another field of interest is the constitution of multilingual lexical databases such as the project planned by the European Commission's Joint Research Centre (JRC) or the more established Papillon project.",
        "Multilingual lexical databases are databases for structured lexical data which can be used either by humans (e.g. to define their own dictionaries) or by natural language processing (NLP) applications.",
        "Parallel corpora are freely available for research purposes and their increasing size demands the exploration of automatic methods.",
        "The ‘Acquis Communautaire’ (AC) Corpus is such a corpus.",
        "Many research teams are involved in the JRC project for the enrichment of a multilingual lexical database.",
        "The aim of the project is to reach an automatic extraction of lexical tuples from the AC Corpus.",
        "The AC document collection was constituted when ten new countries joined the European Union in 2004.",
        "They had to translate an existing collection of about ten thousand legal documents covering a large variety of subject areas.",
        "The ‘Acquis Communautaire’ Corpus exists as a parallel text in 20 languages.",
        "The JRC has collected large parts of this document collection, has converted it to XML, and provide sentence alignments for most language pairs (Steinberger et al., 2006)."
      ]
    },
    {
      "heading": "1.2 Alignment approaches",
      "text": [
        "Alignment becomes an important issue for research on bilingual and multilingual corpora.",
        "Existing alignment methods define a continuum going from purely statistical methods to linguistic ones.",
        "A major point of divergence is the granularity of the proposed alignments (entire texts, paragraphs, sentences, clauses, words) which often depends on the application.",
        "In a coarse-grained alignment task, punctuation or formatting can be sufficient.",
        "At finer-grained levels, methods are more sophisticated and combine linguistic clues with statistical ones.",
        "Statistical alignment methods at sentence level have been thoroughly investigated (Gale & Church, 1991a/ 1991b ; Brown et al., 1991 ; Kay & Röscheisen, 1993).",
        "Others use various linguistic information (Simard et al., 1992 ; Papageorgiou et al., 1994).",
        "Purely statistical alignment methods are proposed at word level (Gale & Church, 1991a ; Kitamura & Matsumoto, 1995).",
        "(Tiedemann, 1993 ; Boutsis & Piperidis, 1996 ; Piperidis et al., 1997) combine statistical and linguistic information for the same task.",
        "Some methods make alignment suggestions at an intermediate level between sentence and word",
        "A common problem is the delimitation and spotting of the units to be matched.",
        "This is not a real problem for methods aiming at alignments at a high level of granularity (paragraphs, sentences) where unit delimiters are clear.",
        "It becomes more difficult for lower levels of granularity (Simard, 2003), where correspondences between graphically delimited words are not always satisfactory."
      ]
    },
    {
      "heading": "2 The multi-grained endogenous alignment approach",
      "text": [
        "The approach proposed here deals with the spotting of multi-grained translation equivalents.",
        "We do not adopt very rigid constraints concerning the size of linguistic units involved, in order to account for the flexibility of language and translation divergences.",
        "Alignment links can then be established at various levels, from sentences to words and obeying no other constraints than the maximum size of candidate alignment sequences and their minimum frequency of occurrence.",
        "The approach is endogenous since the input is used as the only used linguistic resource.",
        "It is the multilingual parallel AC corpus itself.",
        "It does not contain any syntactical annotation, and the texts have not been lemmatised.",
        "In this approach, no classical linguistic resources are required.",
        "The input texts have been segmented and aligned at sentence level by the JRC.",
        "Inflectional divergen-cies of isolated words are taken into account without external linguistic information (lexicon) and without linguistic parsers (stemmer or tag-ger).",
        "The morphology is learnt automatically using an endogenous parsing module integrated in the alignment tool based on (Déjean, 1998).",
        "We adopt a minimalist approach, in the line of GREYC.",
        "In the JRC project, many languages do not have available linguistic resources for automatic processing, neither inflectional or syntactical annotation, nor surface syntactic analysis or lexical resources (machine-readable dictionaries etc.).",
        "Therefore we can not use a large amount of a priori knowledge on these languages."
      ]
    },
    {
      "heading": "3 Considerations on the Corpus",
      "text": []
    },
    {
      "heading": "3.1 Corpus definition",
      "text": [
        "Concretely, the texts constituting the AC corpus (Steinberger et al., 2006) are legal documents translated in several languages and aligned at sentence level.",
        "Here is a description of the parallel corpus, in the 20 languages available:",
        "- Czech: 7106 documents - Danish: 8223 documents - German: 8249 documents - Greek: 8003 documents - English: 8240 documents - Spanish: 8207 documents - Estonian: 7844 documents - Finnish: 8189 documents - French: 8254 documents - Hungarian: 7535 documents - Italian: 8249 documents, - Lithuanian: 7520 documents - Latvian: 7867 documents - Maltese: 6136 documents - Dutch: 8247 documents - Polish: 7768 documents - Portuguese: 8210 documents - Slovakian: 6963 documents - Slovene:7821 documents - Swedish: 8233 documents",
        "The documents contained in the archives are XML files, UTF-8 encoding, containing information on “sentence” segmentation.",
        "Each file is stamped with a unique identifier (the celex identifier).",
        "It refers to a unique document.",
        "Here is an excerpt of the document 31967R0741, in Czech.",
        "Sentence alignments files are also provided with the corpus for 111 language pairs.",
        "The XML files encoded in UTF-8 are about 2M packed and 10M unpacked.",
        "Here is an excerpt of the alignment file of the document 31967R0741, for the language pair Czech-Danish.",
        "<link type=\"1-1\" xtargets=\"49;53\" /> <link type=\"2-1\" xtargets=\"50 51;54\" /> <link type=\"1-1\" xtargets=\"52;55\" /> </document> In this file, the xtargets “ids” refer to the <P sid=“...”> of the Czech and Danish translations of the document 31967R0741.",
        "The current version of our alignment system deals with one language pair at a time, whatever the languages are.",
        "The algorithm takes as input a corpus of bitexts aligned at sentence level.",
        "Usually, the alignment at this level outputs aligned windows containing from 0 to 2 segments.",
        "One-to-one mapping corresponds to a standard output (see link types “1-1” above).",
        "An empty window corresponds to a case of addition in the source language or to a case of omission in the target language.",
        "One-to-two mapping corresponds to split sentences (see link types “1-2” and “2-1” above).",
        "Formally, each bitext is a quadruple < T1, T2, Fs, C> where T1 and T2 are the two texts, Fs is the function that reduces T1 to an element set Fs(T1) and also reduces T2 to an element set Fs(T2), and C is a subset of the Cartesian product of Fs(T1) x Fs(T2) (Harris, 1988).",
        "Different standards define the encoding of parallel text alignments.",
        "Our system natively handles TMX and XCES format, with UTF-8 or UTF-16 encoding."
      ]
    },
    {
      "heading": "4 The Resolution Method",
      "text": [
        "The resolution method is composed of two stages, based on two underlying hypotheses.",
        "The first stage handles the document grain.",
        "The second stage handles the corpus grain."
      ]
    },
    {
      "heading": "4.1 Hypotheses",
      "text": [
        "hypothesis 1 : let’s consider a bitext composed of the texts T1 and T2.",
        "If a sequence S1 is repeated several times in T1 and in well-defined sentences1, there are many chances that a repeated sequence S2 corresponding to the translation of S1 occurs in the corresponding aligned sentences in T2.",
        "hypothesis 2 : let’s consider a corpus of bitexts, composed of two languages L1 and L2.",
        "There is no guarantee for a sequence S1 which is repeated in many texts of language L1 to have a unique translation in the corresponding texts of language L2."
      ]
    },
    {
      "heading": "4.2 Stage 1 : Bitext analysis",
      "text": [
        "The first stage handles the document scale.",
        "Thus it is applied on each document, individually.",
        "There is no interaction at the corpus level.",
        "Determining the multi-grained sequences to be aligned First, we consider the two languages of the document independently, the source language L1 and the target language L2.",
        "For each language, we compute the repeated sequences as well as their frequency.",
        "The algorithm based on suffix arrays does not retain the sub-sequences of a repeated sequence if they are as frequent as the sequence itself.",
        "For instance, if “subjects” appears with the same frequency than “healthy subjects” we retain only the second sequence.",
        "On the contrary, if “disease” occurs more frequently than “thyroid disease” we retain both.",
        "When computing the frequency of a repeated sequence, the offset of each occurrence is memorized.",
        "So the output of this processing stage is a list of sequences with their frequency and the offset list in the document."
      ]
    },
    {
      "heading": "Handling inflections",
      "text": [
        "Inflectional divergencies of isolated words are taken into account without external linguistic information (lexicon) and without linguistic parsers (stemmer or tagger).",
        "The morphology is learnt automatically using an endogenous approach derived from (Déjean, 1998).",
        "The algorithm is reversible: it allows to compute prefixes the same way, with reversed word list as input.",
        "The basic idea is to approximate the border between the nucleus and the suffixes.",
        "The border matches the position where the number of distinct letters preceding a suffix of length n is greater than the number of distinct letters preceding a suffix of length n-1.",
        "For instance, in the first English document of our corpus, “g” is preceded by 4 distinct letters, “ng” by 2 and “ing” by 10: “ing” is probably a suffix.",
        "In the first Greek document, “ά” is preceded by 5 letters, “κά” by 1 and “ ικά” by 10.",
        "“ικά” is probably a suffix.",
        "The algorithm can generate some wrong morphemes, from a strictly linguistic point of view.",
        "But at this stage, no filtering is done in order to check their validity.",
        "We let the alignment algorithm do the job with the help of contextual information."
      ]
    },
    {
      "heading": "Vectorial representation of the sequences",
      "text": [
        "An orthonormal space is then considered in order to explore the existence of possible translation relations between the sequences, and in order to define translation couples.",
        "The existence of translation relations between sequences is approximated by the cosine of vectors associated to them, in this space.",
        "The links in the alignment file allow the construction of this orthonormal space.",
        "This space has no dimensions, where no is the number of non-empty links.",
        "Alignment links with empty sets (type=\"0-?\"",
        "or type=\"?-0\") corresponds to cases of omission or addition in one language.",
        "Every repeated sequence is seen as a vector in this space.",
        "For the construction of this vector, we first pick up the segment offset in the document for each repeated sequence.",
        "Then we convert this list in a nL-dimension vector vL, where nL is the number of textual segments of the document of language L. Each dimension contains the number of occurrences present in the segment.",
        "With the help of the alignment file, we can now make the projection of the vector vL in the no-dimension vector vo.",
        "For instance, if the link <link type=\"2-1\" xtargets=\"45 46;45\" /> is located at rank r=40 in the alignment file and if English is the first language (L=en), then vo[40] = ven[45] + ven[46]."
      ]
    },
    {
      "heading": "Sequence alignment",
      "text": [
        "For each sequence of L1 to be aligned, we look for the existence of a translation relation between it and every L2 sequence to be aligned.",
        "The existence of a translation relation between two sequences is approximated by the cosine of the vectors associated to them.",
        "The cosine is a mathematical tool used in in Natural Language Processing for various purposes, e.g. (Roy & Beust, 2004) uses the cosine for thematic categorisation of texts.",
        "The cosine is obtained by dividing the scalar product of two vectors with the product of their norms.",
        "We note that the cosine is never negative as vectors coordinates are always positive.",
        "The sequences proposed for the alignment are those that obtain the largest cosine.",
        "We do not propose an alignment if the best cosine is inferior to a certain threshold."
      ]
    },
    {
      "heading": "4.3 Stage 2 : Corpus management",
      "text": [
        "The second stage handles the corpus grain and merges the information found at document grain, in the first stage."
      ]
    },
    {
      "heading": "Handling the Corpus Dimension",
      "text": [
        "The bitext corpus is not a bag of aligned sentences and is not considered as if it were.",
        "It is a bag of bitexts, each bitext containing a bag of aligned sentences.",
        "Considering the bitext level (or document grain) is useful for several reasons.",
        "First, for operational sake.",
        "The greedy algorithm for repeated sequence extraction has a cubic complexity.",
        "It is better to apply it on the document unit rather than on the corpus unit.",
        "But this is not the main reason.",
        "Second, the alignment algorithm between sequences relies on the principle of translation coherence: a repeated sequence in L1 has many chances to be translated by the same sequence in L2 in the same text.",
        "This hypothesis holds inside the document but not in the corpus: a polysemic term can be translated in different ways according to the document genre or domain.",
        "Third, the confidence in the generated alignments is improved if the results obtained by the execution of the process on several documents share compatible alignments."
      ]
    },
    {
      "heading": "Alignment Filtering and Ranking",
      "text": [
        "The filtering process accepts terms which have been produced (1) by the execution on at least two documents, (2) by the execution on solely one document if the aligned terms correspond to the same character string or if the frequency of the terms is greater than an empirical threshold function.",
        "This threshold is proportional to the inverse term length since there are fewer complex repeated terms than simple terms.",
        "The ranking process sorts candidates using the product of the term frequency by the number of output agreements."
      ]
    },
    {
      "heading": "5 Results",
      "text": [
        "The results concern an alignment task between English and the 19 other languages of the AC-Corpus.",
        "For each language pair, we considered 500 bitexts of the AC Corpus.",
        "We join in annexes A, B, and C some sample of this results.",
        "Annex A deals with English-French parallel texts, Annex B deals with English-Spanish parallel texts and finally Annex C deals with English-German ones.",
        "We discuss in the following lines of the English-French alignment.",
        "Among the correct alignments, we find domain dependant lexical terms: - legal terms of the EEC (EEC initial verifi",
        "- specialty terms (rear-view mirrors / rétroviseurs, poultry/volaille).",
        "We also find invariant terms (km/h/km/h, kg/kg, mortem/mortem).",
        "We encounter alignments at different grain: territory/territoire Member States/États membres, Whereas/Considérant que, fresh poultrymeat/viandes fraîches de volaille, Having regard to the Opinion of the/vu l’avis.",
        "The wrong alignments mainly come from candidates that have not been confirmed by running on several documents (column ndoc=1): on/la commercialisation des.",
        "A permanent dedicated web site will be open in March 2006 to detail all the results for each language pair.",
        "The URL is http://users.info.unicaen.fr/~giguet/alignment."
      ]
    },
    {
      "heading": "5.1 Discussion",
      "text": [
        "First, the results are similar to those obtained on the Greek/English scientific corpus.",
        "Second, it is sometimes difficult to choose between distinct proposals for a same term when the grain vary: Member/membre – Member State~/membre – Member States/États membres State/membre State – /membre – .",
        "There is a problem both in the definition of terms and in the ability of an automatic process to choose between the components of the terms.",
        "Third, thematic terms of the corpus are not always aligned, since they are not repeated.",
        "Core-fence is used instead, thanks to nominal anaphora, acronyms, and also lexical reductions.",
        "Accuracy depends on the document domain.",
        "In the medical domain, acronyms are aligned but not their expansion.",
        "However, we consider that this problem has to be solved by an anaphora resolution system, not by this alignment algorithm."
      ]
    },
    {
      "heading": "6 Conclusion",
      "text": [
        "We showed that it is possible to contribute to the processing of languages for which few linguistic resources are available.",
        "We propose a solution to the spotting of multi-grained translation from parallel corpora.",
        "The results are surprisingly good and encourage us to improve the method, in order to reach a semi-automatic construction of a multilingual lexical database.",
        "The endogenous approach allows to handle inflectional variations.",
        "We also show the importance of using the proper knowledge at the proper level (sentence grain, document grain and corpus grain).",
        "An improvement would be to calculate inflectional variations at corpus grain rather than at document grain.",
        "Therefore, it is possible to plug any external and exogenous component in our architecture to improve the overall quality.",
        "The size of this “massive compilation” (we work with a 20 languages corpora) implies the design of specific strategies in order to handle it properly and quite efficiently.",
        "Special efforts have been done in order to manage the AC Corpus from our document management platform, WIMS.",
        "The next improvement is to precisely evaluate the system.",
        "Another perspective is to integrate an endogenous coreference solver (Giguet & Lucas, 2004)."
      ]
    }
  ]
}
