{
  "info": {
    "authors": [
      "Jesús Giménez",
      "Lluís Màrquez"
    ],
    "book": "Workshop on Building and Using Parallel Texts",
    "id": "acl-W05-0826",
    "title": "Combining Linguistic Data Views for Phrase-Based SMT",
    "url": "https://aclweb.org/anthology/W05-0826",
    "year": 2005
  },
  "references": [
    "acl-J93-2003",
    "acl-N03-1017",
    "acl-P00-1056",
    "acl-P01-1067",
    "acl-P03-1011",
    "acl-W03-1002"
  ],
  "sections": [
    {
      "heading": "Abstract",
      "text": [
        "We describe the Spanish-to-English LDV-COMBO system for the Shared Task 2: “Exploiting Parallel Texts for Statistical Machine Translation” of the ACL-2005 Workshop on “Building and Using Parallel Texts: Data-Driven Machine Translation and Beyond”.",
        "Our approach explores the possibility of working with alignments at different levels of abstraction, using different degrees of linguistic annotation.",
        "Several phrase-based translation models are built out from these alignments.",
        "Their combination significa-tively outperforms any of them in isolation.",
        "Moreover, we have built a word-based translation model based on Word-Net which is used for unknown words."
      ]
    },
    {
      "heading": "1 Introduction",
      "text": [
        "The main motivation behind our work is to introduce linguistic information, other than lexical units, to the process of building word and phrase alignments.",
        "Many other authors have tried to do so.",
        "See (Och and Ney, 2000), (Yamada and Knight, 2001), (Koehn and Knight, 2002), (Koehn et al., 2003), (Schafer and Yarowsky, 2003) and (Gildea, 2003).",
        "Far from full syntactic complexity, we suggest to go back to the simpler alignment methods first described by (Brown et al., 1993).",
        "Our approach exploits the possibility of working with alignments at two different levels of granularity, lexical (words) and shallow parsing (chunks).",
        "In order to avoid confusion so forth we will talk about tokens instead of words as the minimal alignment unit.",
        "Apart from redefining the scope of the alignment unit, we may use different degrees of linguistic annotation.",
        "We introduce the general concept of data view, which is defined as any possible representation of the information contained in a bitext.",
        "We enrich data view tokens with features further than lexical such as PoS, lemma, and chunk label.",
        "As an example of the applicability of data views, suppose the case of the word ‘plays’ being seen in the training data acting as a verb.",
        "Representing this information as ‘playsVBZ’would allow us to distinguish it from its homograph ‘playsNN� ’ for ‘plays’ as a noun.",
        "Ideally, one would wish to have still deeper information, moving through syntax onto semantics, such as word senses.",
        "Therefore, it would be possible to distinguish for instance between two realizations of ‘plays’ with different meanings: ‘hePRP playsVBG guitarNN’ and ‘hePRP playsVBG basketballNN’.",
        "Of course, there is a natural trade-off between the use of data views and data sparsity.",
        "Fortunately, we hava data enough so that statistical parameter estimation remains reliable."
      ]
    },
    {
      "heading": "2 System Description",
      "text": [
        "The LDV-COMBO system follows the SMT architecture suggested by the workshop organizers.",
        "First, training data are linguistically annotated for the two languages involved (See subsection 2.1).",
        "10 different data views have been built.",
        "Notice that it is not necessary that the two parallel counterparts of a bitext share the same data view, as",
        "long as they share the same granularity.",
        "However, in all our experiments we have annotated both sides with the same linguistic information.",
        "See token descriptions: (W) word, (WL) word and lemma, (WP) word and PoS, (WC) word and chunk label, (WPC) word, PoS and chunk label, (Cw) chunk of words (Cwl), chunk of words and lemmas, (Cwp) chunk of words and PoS (Cwc) chunk of words and chunk labels (Cwpc) chunk of words, PoS and chunk labels.",
        "By chunk label we refer to the IOB label associated to every word inside a chunk, e.g. ‘IB_NP declareB_VP resumed,_VP theB_NP session,_NP ofB_PP theB_NP European,_NP Parliament,_NP .�’).",
        "We build chunk tokens by explicitly connecting words in the same chunk, e.g. ‘(I)NP (declare resumed)VP (the session)NP (of)PP (the European Parliament)NP’.",
        "See examples of some of these data views in Table 1.",
        "Then, running GIZA++, we obtain token alignments for each of the data views.",
        "Combined phrase-based translation models are built on top of the Viterbi alignments output by GIZA++.",
        "See details in subsection 2.2.",
        "Combo-models must be then post-processed in order to remove the additional linguistic annotation and split chunks back into words, so they fit the format required by Pharaoh.",
        "Moreover, we have used the Multilingual Central Repository (MCR), a multilingual lexical-semantic database (Atserias et al., 2004), to build a word-based translation model.",
        "We back-off to this model in the case of unknown words, with the goal of improving system recall.",
        "See subsection 2.3."
      ]
    },
    {
      "heading": "2.1 Data Representation",
      "text": [
        "In order to achieve robustness the same tools have been used to linguistically annotate both languages.",
        "The SVMTool1 has been used for PoS-tagging (Gim´enez and M`arquez, 2004).",
        "The Freeling2 package (Carreras et al., 2004) has been used for lemma-tizing.",
        "Finally, the Phreco software by (Carreras et al., 2005) has been used for shallow parsing.",
        "No additional tokenization or preprocessing steps other than case lowering have been performed.",
        "Special treatment of named entities, dates, numbers,",
        "currency, etc., should be considered so as to further enhance the system."
      ]
    },
    {
      "heading": "2.2 Building Combined Translation Models",
      "text": [
        "Because data views capture different, possibly complementary, aspects of the translation process it seems reasonable to combine them.",
        "We consider two different ways of building such combo-models: LPHEX Local phrase extraction.",
        "To build a separate phrase-based translation model for each data view alignment, and then combine them.",
        "There are two ways of combining translation models: MRG Merging translation models.",
        "We work on a weighted linear interpolation of models.",
        "These weights may be tuned, although a uniform weight selection yields good results.",
        "Additionally, phrase-pairs may be filtered out by setting a score threshold.",
        "noMRG Passing translation models directly to the Pharaoh decoder.",
        "However, we encountered many problems with phrase-pairs that were not seen in all single models.",
        "This obliged us to apply arbitrary smoothing values to score these pairs.",
        "GPHEX Global phrase extraction.",
        "To build a single phrased-based translation model from the union of alignments from several data views.",
        "In its turn, any MRG operation performed on a combo-model results again in a valid combo-model.",
        "In any case, phrase extraction3 is performed as depicted by (Och, 2002)."
      ]
    },
    {
      "heading": "2.3 Using the MCR",
      "text": [
        "Outer knowledge may be supplied to the Pharaoh decoder by annotating the input with alternative translation options via XML-markup.",
        "We enrich every unknown word by looking up every possible translation for all of its senses in the MCR.",
        "These are scored by relative frequency according to the number of senses that lexicalized in the same manner.",
        "Let w f, p f be the source word and PoS, and we be the target word, we define a function",
        "Better results would be expected working with word sense disambiguated text.",
        "We are not at this point yet.",
        "A first approach could be to work with the most frequent sense heuristic."
      ]
    },
    {
      "heading": "3 Experimental Results",
      "text": []
    },
    {
      "heading": "3.1 Data and Evaluation Metrics",
      "text": [
        "We have used the data sets and language model provided by the organization.",
        "No extra training or development data were used in our experiments.",
        "We evaluate results with 3 different metrics: GTM F1-measure (e = 1, 2), BLEU score (n = 4) as provided by organizers, and NIST score (n = 5)."
      ]
    },
    {
      "heading": "3.2 Experimenting with Data Views",
      "text": [
        "Table 2 presents MT results for the 10 elementary data views devised in Section 2.",
        "Default parameters are used for At,,,, Al,,,, and A,,,.",
        "No tuning has been performed.",
        "As expected, word-based views obtain significatively higher results than chunk-based.",
        "All data views at the same level of granularity obtain comparable results.",
        "In Table 3 MT results for different data view combinations are showed.",
        "Merged model weights are set equiprobable, and no phrase-pair score filtering",
        "is performed.",
        "We refer to the W model as our baseline.",
        "In this view, only words are used.",
        "The 5W-MRG and 5W-GPHEX models use a combination of the 5 word-based data views, as in MRG and GPHEX, respectively.",
        "The 5C-MRG and 5C-GPHEX system use a combination of the 5 chunk based data views, as in MRG and GPHEX, respectively.",
        "The 10-MRG system uses all 10 data views combined as in MRG.",
        "The 10-GPHEX/MRG system uses the 5 word based views combined as in GPHEX, the 5 chunk based views combined as in GPHEX, and then a combination of these two combo-models as in MRG.",
        "It can be seen that results improve by combining several data views.",
        "Furthermore, global phrase extraction (GPHEX) seems to work much finer than local phrase extraction (LPHEX).",
        "Table 4 shows MT results after optimizing At,,,, Al,,,, Aw, and the weights for the MRG operation, by means of the Downhill Simplex Method in Multi-dimensions (William H. Press and Flannery, 2002).",
        "Observe that tuning the system improves the performance considerably.",
        "The A,,, parameter is particularly sensitive to tuning.",
        "Even though the performance of chunk-based models is poor, the best results are obtained by com-binining the two levels of abstraction, thus proving that syntactically motivated phrases may help.",
        "10- MRG and 10-GPHEX models achieve a similar performance.",
        "The 10-MRG-bestWN system corresponds to the 10-MRG model using WordNet.",
        "The 1 0-MRGsubWN system is this same system at the time of submission.",
        "Results using WordNet, taking into account that the number of unknown4 words in the development set was very small, are very promising."
      ]
    },
    {
      "heading": "4 Conclusions",
      "text": [
        "We have showed that it is possible to obtain better phrase-based translation models by utilizing alignments built on top of different linguistic data views.",
        "These models can be robustly combined, significantly outperforming all of their components in isolation.",
        "We leave for further work the experimentation of new data views such as word senses and semantic roles, as well as their natural porting and evolution from the alignment step to phrase extraction and decoding."
      ]
    },
    {
      "heading": "Acknowledgements",
      "text": [
        "This research has been funded by the Spanish Ministry of Science and Technology (ALIADO TIC2002-04447-C02).",
        "Authors are thankful to Pa-trik Lambert for providing us with the implementation of the Simplex Method used for tuning."
      ]
    }
  ]
}
