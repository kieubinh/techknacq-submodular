{
  "info": {
    "authors": [
      "Zhengyu Niu",
      "Ji Donghong",
      "Chew Lim Tan"
    ],
    "book": "Conference on Empirical Methods in Natural Language Processing",
    "id": "acl-W06-1649",
    "title": "Partially Supervised Sense Disambiguation by Learning Sense Number from Tagged and Untagged Corpora",
    "url": "https://aclweb.org/anthology/W06-1649",
    "year": 2006
  },
  "references": [
    "acl-J94-4003",
    "acl-J98-1004",
    "acl-J98-1006",
    "acl-P05-1049",
    "acl-P91-1034",
    "acl-P95-1026",
    "acl-W02-1006",
    "acl-W04-0807"
  ],
  "sections": [
    {
      "heading": "Abstract",
      "text": [
        "Supervised and semi-supervised sense disambiguation methods will mis-tag the instances of a target word if the senses of these instances are not defined in sense inventories or there are no tagged instances for these senses in training data.",
        "Here we used a model order identification method to avoid the misclassification of the instances with undefined senses by discovering new senses from mixed data (tagged and untagged corpora).",
        "This algorithm tries to obtain a natural partition of the mixed data by maximizing a stability criterion defined on the classification result from an extended label propagation algorithm over all the possible values of the number of senses (or sense number, model order).",
        "Experimental results on SENSEVAL-3 data indicate that it outperforms SVM, a one-class partially supervised classification algorithm, and a clustering based model order identification algorithm when the tagged data is incomplete."
      ]
    },
    {
      "heading": "1 Introduction",
      "text": [
        "In this paper, we address the problem of partially supervised word sense disambiguation, which is to disambiguate the senses of occurrences of a target word in untagged texts when given incomplete tagged corpus 1.",
        "Word sense disambiguation can be defined as associating a target word in a text or discourse",
        "with a definition or meaning.",
        "Many corpus based methods have been proposed to deal with the sense disambiguation problem when given definition for each possible sense of a target word or a tagged corpus with the instances of each possible sense, e.g., supervised sense disambiguation (Leacock et al., 1998), and semi-supervised sense disambiguation (Yarowsky, 1995).",
        "Supervised methods usually rely on the information from previously sense tagged corpora to determine the senses of words in unseen texts.",
        "Semi-supervised methods for WSD are characterized in terms of exploiting unlabeled data in the learning procedure with the need of predefined sense inventories for target words.",
        "The information for semi-supervised sense disambiguation is usually obtained from bilingual corpora (e.g. parallel corpora or untagged monolingual corpora in two languages) (Brown et al., 1991; Da-gan and Itai, 1994), or sense-tagged seed examples (Yarowsky, 1995).",
        "Some observations can be made on the previous supervised and semi-supervised methods.",
        "They always rely on hand-crafted lexicons (e.g., Word-Net) as sense inventories.",
        "But these resources may miss domain-specific senses, which leads to incomplete sense tagged corpus.",
        "Therefore, sense taggers trained on the incomplete tagged corpus will misclassify some instances if the senses of these instances are not defined in sense inventories.",
        "For example, one performs WSD in information technology related texts using WordNet 2 as sense inventory.",
        "When disambiguating the word “boot” in the phrase “boot sector”, the sense tagger will assign this instance with one of the senses of “boot” listed in WordNet.",
        "But the correct sense",
        "“loading operating system into memory” is not included in WordNet.",
        "Therefore, this instance will be associated with an incorrect sense.",
        "So, in this work, we would like to study the problem of partially supervised sense disambiguation with an incomplete sense tagged corpus.",
        "Specifically, given an incomplete sense-tagged corpus and a large amount of untagged examples for a target word 3, we are interested in (1) labeling the instances in the untagged corpus with sense tags occurring in the tagged corpus; (2) trying to find undefined senses (or new senses) of the target word 4 from the untagged corpus, which will be represented by instances from the untagged corpus.",
        "We propose an automatic method to estimate the number of senses (or sense number, model order) of a target word in mixed data (tagged cor-pus+untagged corpus) by maximizing a stability criterion defined on classification result over all the possible values of sense number.",
        "At the same time, we can obtain a classification of the mixed data with the optimal number of groups.",
        "If the estimated sense number in the mixed data is equal to the sense number of the target word in tagged corpus, then there is no new sense in untagged corpus.",
        "Otherwise new senses will be represented by groups in which there is no instance from the tagged corpus.",
        "This partially supervised sense disambiguation algorithm may help enriching manually compiled lexicons by inducing new senses from untagged corpora.",
        "This paper is organized as follows.",
        "First, a model order identification algorithm will be presented for partially supervised sense disambiguation in section 2.",
        "Section 3 will provide experimental results of this algorithm for sense disambiguation on SENSEVAL-3 data.",
        "Then related work on partially supervised classification will be summarized in section 4.",
        "Finally we will conclude our work and suggest possible improvements in section 5."
      ]
    },
    {
      "heading": "2 Partially Supervised Word Sense Disambiguation",
      "text": [
        "The partially supervised sense disambiguation problem can be generalized as a model order iden",
        "tification problem.",
        "We try to estimate the sense number of a target word in mixed data (tagged cor-pus+untagged corpus) by maximizing a stability criterion defined on classification results over all the possible values of sense number.",
        "If the estimated sense number in the mixed data is equal to the sense number in the tagged corpus, then there is no new sense in the untagged corpus.",
        "Otherwise new senses will be represented by clusters in which there is no instance from the tagged corpus.",
        "The stability criterion assesses the agreement between classification results on full mixed data and sampled mixed data.",
        "A partially supervised classification algorithm is used to classify the full or sampled mixed data into a given number of classes before the stability assessment, which will be presented in section 2.1.",
        "Then we will provide the details of the model order identification procedure in section 2.2."
      ]
    },
    {
      "heading": "2.1 An Extended Label Propagation Algorithm",
      "text": [
        "Table 1: Extended label propagation algorithm.",
        "Function: ELP(DL, DU, k, Y0DL+DU ) Input: labeled examples DL, unlabeled examples DU, model order k, initial labeling matrix Y0DL+DU ; Output: the labeling matrix YDU on DU;",
        "Run plain label propagation algorithm on DU with YDU as output;"
      ]
    },
    {
      "heading": "3 Else then",
      "text": []
    },
    {
      "heading": "3.1 Estimate the size of tagged data set",
      "text": [
        "of new classes;"
      ]
    },
    {
      "heading": "3.2 Generate tagged examples from DU",
      "text": [
        "for (kXL + 1)-th to k-th new classes; 3.3 Run plain label propagation algorithm on DU with augmented tagged dataset as labeled data;"
      ]
    },
    {
      "heading": "4 Return YDU;",
      "text": [
        "Let XL+U = {xi }�i� 1 be a set of contexts of occurrences of an ambiguous word w, where xi represents the context of the i-th occurrence, and n is the total number of this word’s occurrences.",
        "Let",
        "5L = {sp }cp�1 denote the sense tag set of w in XL, where XL denotes the first l examples xg(1 < g < l) that are labeled as yg (yg E 5L).",
        "Let XU denote other u (l + u = n) examples xh(l + 1 < h < n) that are unlabeled.",
        "Let Y0XL+U E NI XL+U I x I SL I represent initial soft labels attached to tagged instances, where Y0XL+U,ip = 1 if yi is sp and 0 otherwise.",
        "LetY0XL be the top l rows of Y0XL+U and Y0XU be the remaining u rows.Y0XL is consistent with the labeling in labeled data, and the initialization of Y0XU can be arbitrary.",
        "Let k denote the possible value of the number of senses in mixed data XL+U, and kXL be the number of senses in initial tagged data XL.",
        "Note that kXL = I5L I, and k > kXL.",
        "The classification algorithm in the order identification process should be able to accept labeled data DL 5, unlabeled data DU 6 and model order k as input, and assign a class label or a cluster index to each instance in DU as output.",
        "Previous supervised or semi-supervised algorithms (e.g. SVM, label propagation algorithm (Zhu and Ghahra-mani, 2002)) cannot classify the examples in DU into k groups if k > kXL.",
        "The semi-supervised k-means clustering algorithm (Wagstaff et al., 2001) may be used to perform clustering analysis on mixed data, but its efficiency is a problem for clustering analysis on a very large dataset since multiple restarts are usually required to avoid local optima and multiple iterations will be run in each clustering process for optimizing a clustering solution.",
        "In this work, we propose an alternative method, an extended label propagation algorithm (ELP), which can classify the examples in DU into k groups.",
        "If the value of k is equal to kXL, then ELP is identical with the plain label propagation algorithm (LP) (Zhu and Ghahramani, 2002).",
        "Otherwise, if the value of k is greater than kXL, we perform classification by the following steps: (1) estimate the dataset size of each new class as sizenew class by identifying the examples of new classes using the “Spy” technique 7 and assuming",
        "classifier on this labeled dataset without the m-th class;",
        "(4) the classifier is then used to classify the examples in D�U; (5) the least confidently unlabeled point",
        "(6) steps (3) to (5) are repeated for each new class till the augmented tagged data set is large enough (here we try to select sizenew class/4 examples with their sense tags as tagged data for each new class); (7) use plain LP algorithm to classify remaining unlabeled data D�U with D�L as labeled data.",
        "Table 1 shows this extended label propagation algorithm.",
        "Next we will provide the details of the plain label propagation algorithm.",
        "2 Define Wip = exp( – a2) if i 7� j and Wii = 0 (1 < i, j < IDL + DU I), where dip is the distance (e.g., Euclidean distance) between the example xi and xp, and Q is used to control the weight Wip.",
        "where Tip is the probability to jump from example xp to example xi.",
        "Compute the row-normalized matrix T by Tip = Tip/ �nk�1 Tik.",
        "The classification solution is obtained by YDU = (I – Tuu)-1TulY0DL.",
        "I is IDUI x IDUI identity matrix.",
        "Tuu and Tul are acquired by splitting matrix T after the I DL I -th row and the I DL I -th column into 4 sub-matrices."
      ]
    },
    {
      "heading": "2.2 Model Order Identification Procedure",
      "text": [
        "For achieving the model order identification (or sense number estimation) ability, we use a cluster validation based criterion (Levine and Domany, 2001) to infer the optimal number of senses of w in XL+U.",
        "tion confidence less than the average of that in DsL.",
        "Classification confidence of the example xi is defined as the absolute value of the difference between two maximum values from the i-throw in labeling matrix.",
        "8Initially there are no tagged examples for the m-th class in D�L.",
        "Therefore we do not need to remove tagged examples for this new class, and then directly train a classifier with D",
        "Function: CV(XL+U, k, q, Y0XL+U) Input: data set XL+U, model order k, and sampling frequency q; Output: the score of the merit of k;",
        "1 Run the extended label propagation algorithm with XL, XU, k and Y0XL+U ; 2 Construct connectivity matrix Ck based on above classification solution on XU; 3 Use a random predictor Pk to assign uniformly drawn labels to each vector in XU;",
        "where M(Cµ, C) is given by equation (2); 7 Return Mk; Then this model order identification procedure can be formulated as:",
        "�kXL+U is the estimated sense number in XL+U, Kmin (or Kmax) is the minimum (or maximum) value of sense number, and k is the possible value of sense number in XL+U.",
        "Note that k > kXL.",
        "Then we set Kmi,,, = kXL.",
        "Kmax may be set as a value greater than the possible ground-truth value.",
        "CV is a cluster validation based evaluation function.",
        "Table 2 shows the details of this function.",
        "We set q, the resampling frequency for estimation of stability score, as 20. a is set as 0.90.",
        "The random predictor assigns uniformly distributed class labels to each instance in a given dataset.",
        "We run this CV procedure for each value of k. The value of k that maximizes this function will be selected as the estimation of sense number.",
        "At the same time, we can obtain a partition of XL+U with �kXL+U groups.",
        "The function M(Cµ, C) in Table 2 is given by (Levine and Domany, 2001):",
        "where XµU is the untagged data in XµL+U, XµL+U is a subset with the size aIXL+UI (0 < a < 1) sampled from XL+U, C or Cµ is IXUI x IXUI or I XµU I x I XµU I connectivity matrix based on classification solutions computed on XU or XµU respectively.",
        "The connectivity matrix C is defined as: Ci,j = 1 if xi and xj belong to the same cluster, otherwise Ci,j = 0.",
        "Cµ is calculated in the same way.",
        "M(Cµ, C) measures the proportion of example pairs in each group computed on XU that are also assigned into the same group by the classification solution on XµU.",
        "Clearly, 0 < M < 1.",
        "Intuitively, if the value of k is identical with the true value of sense number, then classification results on the different subsets generated by sampling should be similar with that on the full dataset.",
        "In the other words, the classification solution with the true model order as parameter is robust against resampling, which gives rise to a local optimum of M(Cµ, C).",
        "In this algorithm, we normalize M(Cµk, Ck) by the equation in step 6 of Table 2, which makes our objective function different from the figure of merit (equation ( 2)) proposed in (Levine and Domany, 2001).",
        "The reason to normalize M(Cµk, Ck) is that M(Cµk, Ck) tends to decrease when increasing the value of k (Lange et al., 2002).",
        "Therefore for avoiding the bias that the smaller value of k is to be selected as the model order, we use the cluster validity of a random predictor to normalize M(Cµk, Ck).",
        "If �kXL+U is equal to kXL, then there is no new sense in XU.",
        "Otherwise (�kXL+U > kXL) new senses of w may be represented by the groups in which there is no instance from XL."
      ]
    },
    {
      "heading": "3 Experiments and Results",
      "text": []
    },
    {
      "heading": "3.1 Experiment Design",
      "text": [
        "We evaluated the ELP based model order identification algorithm on the data in English lexical sample task of SENSEVAL-3 (including all",
        "the 57 English words ) 9, and further empirically compared it with other state of the art classification methods, including SVM 10 (the state of the art method for supervised word sense disambiguation (Mihalcea et al., 2004)), a one-class partially supervised classification algorithm (Liu et al., 2003) 11, and a semi-supervised k-means clustering based model order identification algorithm.",
        "The data for English lexical samples task in SENSEVAL-3 consists of 7860 examples as official training data, and 3944 examples as official test data for 57 English words.",
        "The number of senses of each English word varies from 3 to 11.",
        "We evaluated these four algorithms with different sizes of incomplete tagged data.",
        "Given official training data of the word w, we constructed incomplete tagged data XL by removing the all the tagged instances from official training data that have sense tags from Ss„bset, where Ss„bset is a subset of the ground-truth sense set S for w, and S consists of the sense tags in official training set for w. The removed training data and official test data of w were used as XU.",
        "Note that SL = S−Ss„bset.",
        "Then we ran these four algorithm for each target word w with XL as tagged data and XU as untagged data, and evaluated their performance using the accuracy on official test data of all the 57 words.",
        "We conducted six experiments for each target word w by setting Ss„bset as {s1}, {s2}, {s3}, {s1, s2}, {s1, s3}, or {s2, s3}, where si is the i-th most frequent sense of w. Ss„bset cannot be set as {s4} since some words have only three senses.",
        "Table 3 lists the percentage of official training data used as tagged data (the number of examples in in",
        "complete tagged data divided by the number of examples in official training data) when we removed the instances with sense tags from Ss„bset for all the 57 words.",
        "If Ss„bset = {s3}, then most of sense tagged examples are still included in tagged data.",
        "If Ss„bset = {s 1, s2}, then there are very few tagged examples in tagged data.",
        "If no instances are removed from official training data, then the value of percentage is 100%.",
        "Given an incomplete tagged corpus for a target word, SVM does not have the ability to find the new senses from untagged corpus.",
        "Therefore it labels all the instances in the untagged corpus with sense tags from SL.",
        "Given a set of positive examples for a class and a set of unlabeled examples, the one-class partially supervised classification algorithm, LPU (Learning from Positive and Unlabeled examples) (Liu et al., 2003), learns a classifier in four steps: Step 1: Identify a small set of reliable negative examples from unlabeled examples by the use of a classifier.",
        "Step 2: Build a classifier using positive examples and automatically selected negative examples.",
        "Step 3: Iteratively run previous two steps until no unlabeled examples are classified as negative ones or the unlabeled set is null.",
        "Step 4: Select a good classifier from the set of classifiers constructed above.",
        "For comparison, LPU 12 was run to perform classification on XU for each class in XL.",
        "The label of each instance in XU was determined by maximizing the classification score from LPU output for each class.",
        "If the maximum score of an instance is negative, then this instance will be labeled as a new class.",
        "Note that LPU classifies XL+U into kx, + 1 groups in most of cases.",
        "The clustering based partially supervised sense disambiguation algorithm was implemented by replacing ELP with a semi-supervised k-means clustering algorithm (Wagstaff et al., 2001) in the model order identification procedure.",
        "The label information in labeled data was used to guide the semi-supervised clustering on XL+U.",
        "Firstly, the labeled data may be used to determine initial cluster centroids.",
        "If the cluster number is greater 12 The three parameters in LPU were set as follows: “-s 1 spy -s2 svm c 1”.",
        "It means that we used the spy technique for step 1 in LPU, the SVM algorithm for step 2, and selected the first or the last classifier as the final classifier.",
        "It is identical with the algorithm “Spy+SVM IS” in Liu et al.",
        "(2003).",
        "than kXL, the initial centroids of clusters for new classes will be assigned as randomly selected instances.",
        "Secondly, in the clustering process, the instances with the same class label will stay in the same cluster, while the instances with different class labels will belong to different clusters.",
        "For better clustering solution, this clustering process will be restarted three times.",
        "Clustering process will be terminated when clustering solution converges or the number of iteration steps is more than 30.",
        "Kmin = kXL = I SL I, Kmax = Kmin + m. m is set as 4.",
        "We used Jensen-Shannon (JS) divergence (Lin, 1991) as distance measure for semi-supervised clustering and ELP, since plain LP with JS divergence achieves better performance than that with cosine similarity on SENSEVAL-3 data (Niu et al., 2005).",
        "For the LP process in ELP algorithm, we constructed connected graphs as follows: two instances u, v will be connected by an edge if u is among v’s 10 nearest neighbors, or if v is among u’s 10 nearest neighbors as measured by cosine or JS distance measure (following (Zhu and Ghahramani, 2002)).",
        "We used three types of features to capture the information in all the contextual sentences of target words in SENSEVAL-3 data for all the four algorithms: part-of-speech of neighboring words with position information, words in topical context without position information (after removing stop words), and local collocations (as same as the feature set used in (Lee and Ng, 2002) except that we did not use syntactic relations).",
        "We removed the features with occurrence frequency (counted in both training set and test set) less than 3 times.",
        "If the estimated sense number is more than the sense number in the initial tagged corpus XL, then the results from order identification based methods will consist of the instances from clusters of unknown classes.",
        "When assessing the agreement between these classification results and the known results on official test set, we will encounter the problem that there is no sense tag for each instance in unknown classes.",
        "Slonim and Tishby (2000) proposed to assign documents in each cluster with the most dominant class label in that cluster, and then conducted evaluation on these labeled documents.",
        "Here we will follow their method for assigning sense tags to unknown classes from LPU, clustering based order identification process, and ELP based order identification process.",
        "We assigned the instances from unknown classes with the dominant sense tag in that cluster.",
        "The result from LPU always includes only one cluster of the unknown class.",
        "We also assigned the instances from the unknown class with the dominant sense tag in that cluster.",
        "When all instances have their sense tags, we evaluated the their results using the accuracy on official test set."
      ]
    },
    {
      "heading": "3.2 Results on Sense Disambiguation",
      "text": [
        "Table 4 summarizes the accuracy of SVM, LPU, the semi-supervised k-means clustering algorithm with correct sense number ISI or estimated sense number �kXL+U as input, and the ELP algorithm with correct sense number ISI or estimated sense number �kXL+U as input using various incomplete tagged data.",
        "The last row in Table 4 lists the average accuracy of each algorithm over the six experimental settings.",
        "Using IS I as input means that we do not perform order identification procedure, while using �kXL+U as input is to perform order identification and obtain the classification results on XU at the same time.",
        "We can see that ELP based method outperforms clustering based method in terms of average accuracy under the same experiment setting, and these two methods outperforms SVM and LPU.",
        "Moreover, using the correct sense number as input helps to improve the overall performance of both clustering based method and ELP based method.",
        "Comparing the performance of the same system with different sizes of tagged data (from the first experiment to the third experiment, and from the fourth experiment to the sixth experiment), we can see that the performance was improved when given more labeled data.",
        "Furthermore, ELP based method outperforms other methods in terms of accuracy when rare senses (e.g. s3) are missing in the tagged data.",
        "It seems that ELP based method has the ability to find rare senses with the use of tagged and untagged corpora.",
        "LPU algorithm can deal with only one-class classification problem.",
        "Therefore the labeled data of other classes cannot be used when determining the positive labeled data for current class.",
        "ELP can use the labeled data of all the known classes to determine the seeds of unknown classes.",
        "It may explain why LPU’s performance is worse than ELP based sense disambiguation although LPU can correctly estimate the sense number in XL+U",
        "standard deviation of absolute values of the difference between ground-truth results ISI and sense numbers estimated by clustering or ELP based order identification procedure respectively.",
        "when only one sense is missing in XL.",
        "When very few labeled examples are available, the noise in labeled data makes it difficult to learn the classification score (each entry in YDU ).",
        "Therefore using the classification confidence criterion may lead to poor performance of seed selection for unknown classes if the classification score is not accurate.",
        "It may explain why ELP based method does not outperform clustering based method with small labeled data (e.g., Ssubset = {s11)."
      ]
    },
    {
      "heading": "3.3 Results on Sense Number Estimation",
      "text": [
        "Table 5 provides the mean and standard deviation of absolute difference values between ground-truth results ISI and sense numbers estimated by clustering or ELP based order identification procedures respectively.",
        "For example, if the ground truth sense number of the word w is kw, and the estimated value is �kw, then the absolute value of the difference between these two values is I kw − �kwI.",
        "Therefore we can have this value for each word.",
        "Then we calculated the mean and deviation on this array of absolute values.",
        "LPU does not have the order identification capability since it always assumes that there is at least one new class in unlabeled data, and does not further differentiate the instances from these new classes.",
        "Therefore we do not provide the order identification results of LPU.",
        "From the results in Table 5, we can see that estimated sense numbers are closer to ground truth results when given less labeled data for clustering or ELP based methods.",
        "Moreover, clustering based method performs better than ELP based method in terms of order identification when given less labeled data (e.g., Ssubset = {s11).",
        "It seems that ELP is not robust to the noise in small labeled data, compared with the semi-supervised k-means clustering algorithm."
      ]
    },
    {
      "heading": "4 Related Work",
      "text": [
        "The work closest to ours is partially supervised classification or building classifiers using positive examples and unlabeled examples, which has been studied in machine learning community (Denis et al., 2002; Liu et al., 2003; Manevitz and Yousef, 2001; Yu et al., 2002).",
        "However, they cannot",
        "group negative examples into meaningful clusters.",
        "In contrast, our algorithm can find the occurrence of negative examples and further group these negative examples into a “natural” number of clusters.",
        "Semi-supervised clustering (Wagstaff et al., 2001) may be used to perform classification by the use of labeled and unlabeled examples, but it encounters the same problem of partially supervised classification that model order cannot be automatically estimated.",
        "Levine and Domany (2001) and Lange et al.",
        "(2002) proposed cluster validation based criteria for cluster number estimation.",
        "However, they showed the application of the cluster validation method only for unsupervised learning.",
        "Our work can be considered as an extension of their methods in the setting of partially supervised learning.",
        "In natural language processing community, the work that is closely related to ours is word sense discrimination which can induce senses by grouping occurrences of a word into clusters (Schfitze, 1998).",
        "If it is considered as unsupervised methods to solve sense disambiguation problem, then our method employs partially supervised learning technique to deal with sense disambiguation problem by use of tagged and untagged texts."
      ]
    },
    {
      "heading": "5 Conclusions",
      "text": [
        "In this paper, we present an order identification based partially supervised classification algorithm and investigate its application to partially supervised word sense disambiguation problem.",
        "Experimental results on SENSEVAL-3 data indicate that our ELP based model order identification algorithm achieves better performance than other state of the art classification algorithms, e.g., SVM, a one-class partially supervised algorithm (LPU), and a semi-supervised k-means clustering based model order identification algorithm."
      ]
    }
  ]
}
