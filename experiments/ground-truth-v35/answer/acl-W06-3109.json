{
  "info": {
    "authors": [
      "Daniel Ortiz-Martínez",
      "Ismael García-Varea",
      "Francisco Casacuberta"
    ],
    "book": "Workshop on Statistical Machine Translation",
    "id": "acl-W06-3109",
    "title": "Generalized Stack Decoding Algorithms for Statistical Machine Translation",
    "url": "https://aclweb.org/anthology/W06-3109",
    "year": 2006
  },
  "references": [
    "acl-J93-2003",
    "acl-N03-1017",
    "acl-P01-1030",
    "acl-P01-1067",
    "acl-W01-1408",
    "acl-W02-1018"
  ],
  "sections": [
    {
      "heading": "Abstract",
      "text": [
        "In this paper we propose a generalization of the Stack-based decoding paradigm for Statistical Machine Translation.",
        "The well known single and multi-stack decoding algorithms defined in the literature have been integrated within a new formalism which also defines a new family of stack-based decoders.",
        "These decoders allows a tradeoff to be made between the advantages of using only one or multiple stacks.",
        "The key point of the new formalism consists in parameterizeing the number of stacks to be used during the decoding process, and providing an efficient method to decide in which stack each partial hypothesis generated is to be inserted-during the search process.",
        "Experimental results are also reported for a search algorithm for phrase-based statistical translation models."
      ]
    },
    {
      "heading": "1 Introduction",
      "text": [
        "The translation process can be formulated from a statistical point of view as follows: A source language string f J1 = f1 ... fJ is to be translated into a target language string eI1 = e1 ... eI.",
        "Every target string is regarded as a possible translation for the source language string with maximum a-posteriori probability Pr(eI1|fJ1 ).",
        "According to Bayes’ theorem, the target string �eI1 that maximizes1 the product",
        "of both the target language model Pr (eI1) and the string translation model Pr (f J1 |eI1) must be chosen.",
        "The equation that models this process is:",
        "The search/decoding problem in SMT consists in solving the maximization problem stated in Eq.",
        "(1).",
        "In the literature, we can find different techniques to deal with this problem, ranging from heuristic and fast (as greedy decoders) to optimal and very slow decoding algorithms (Germann et al., 2001).",
        "Also, under certain circumstances, stack-based decoders can obtain optimal solutions.",
        "Many works (Berger et al., 1996; Wang and Waibel, 1998; Germann et al., 2001; Och et al., 2001; Ortiz et al., 2003) have adopted different types of stack-based algorithms to solve the global search optimization problem for statistical machine translation.",
        "All these works follow two main different approaches according to the number of stacks used in the design and implementation of the search algorithm (the stacks are used to store partial hypotheses, sorted according to their partial score/probability, during the search process) :",
        "• On the one hand, in (Wang and Waibel, 1998; Och et al., 2001) a single stack is used.",
        "In that case, in order to make the search feasible, the pruning of the number of partial hypotheses stored in the stack is needed.",
        "This causes many search errors due to the fact that hypotheses covering a different number of source (translated) words compete in the same conditions.",
        "Therefore, the greater number of covered words the higher possibility to be pruned.",
        "• On the other hand (Berger et al., 1996; Germann et al., 2001) make use of multiple stacks"
      ]
    },
    {
      "heading": "Proceedings of the Workshop on Statistical Machine Translation, pages 64–71, New York City, June 2006. c�2006 Association for Computational Linguistics",
      "text": [
        "(one for each set of source covered/translated words in the partial hypothesis) in order to solve the disadvantages of the single-stack approach.",
        "By contrast, the problem of finding the best hypothesis to be expanded introduces an exponential term in the computational complexity of the algorithm.",
        "In (Ortiz et al., 2003) the authors present an empirical comparison (about efficiency and translation quality) of the two approaches paying special attention to the advantages and disadvantages of the two approaches.",
        "In this paper we present a new formalism consisting of a generalization of the classical stack-based decoding paradigm for SMT.",
        "This new formalism defines a new family of stack-based decoders, which also integrates the well known stack-based decoding algorithms proposed so far within the framework of SMT, that is single and multi-stack decoders.",
        "The rest of the paper is organized as follows: in section 2 the phrase-based approach to SMT is depicted; in section 3 the main features of classical stack-based decoders are presented; in section 4 the new formalism is presented and in section 5 experimental results are shown; finally some conclusions are drawn in section 6."
      ]
    },
    {
      "heading": "2 Phrase Based Statistical Machine Translation",
      "text": [
        "Different translation models (TMs) have been proposed depending on how the relation between the source and the target languages is structured; that is, the way a target sentence is generated from a source sentence.",
        "This relation is summarized using the concept of alignment; that is, how the constituents (typically words or group-of-words) of a pair of sentences are aligned to each other.",
        "The most widely used single-word-based statistical alignment models (SAMs) have been proposed in (Brown et al., 1993; Ney et al., 2000).",
        "On the other hand, models that deal with structures or phrases instead of single words have also been proposed: the syntax translation models are described in (Yamada and Knight, 2001) , alignment templates are used in (Och, 2002), and the alignment template approach is re-framed into the so-called phrase based translation (PBT) in (Marcu and Wong, 2002; Zens et al., 2002; Koehn et al., 2003; Tom´as and Casacuberta, 2003).",
        "For the translation model (Pr(fJ1 IeI1)) in Eq.",
        "(1), PBT can be explained from a generative point of view as follows (Zens et al., 2002):",
        "1.",
        "The target sentence eI1 is segmented into K phrases (�eK1 ).",
        "2.",
        "Each target phrase �ek is translated into a source phrase �f.",
        "3.",
        "Finally, the source phrases are reordered in order to compose the source sentence �fK1=fJ1 .",
        "In PBT, it is assumed that the relations between the words of the source and target sentences can be explained by means of the hidden variable �aK1 , which contains all the decisions made during the generative story.",
        "Different assumptions can be made from the previous equation.",
        "For example, in (Zens et al., 2002) the following model is proposed:",
        "where �ak notes the index of the source phrase e� which is aligned with the k-th target phrase �fk and that all possible segmentations have the same probability.",
        "In (Tom´as and Casacuberta, 2001; Zens et al., 2002), it also is assumed that the alignments must be monotonic.",
        "This led us to the following equation:",
        "In both cases the model parameters that have to be estimated are the translation probabilities between phrase pairs (0 = {p(�f I�e)�), which typically are estimated as follows:",
        "where N(�f |e) is the number of times that f� have been seen as a translation of a within the training corpus."
      ]
    },
    {
      "heading": "3 Stack-Decoding Algorithms",
      "text": [
        "The stack decoding algorithm, also called A* algorithm, was first introduced by F. Jelinek in (Jelinek, 1969).",
        "The stack decoding algorithm attempts to generate partial solutions, called hypotheses, until a complete translation is found2; these hypotheses are stored in a stack and ordered by their score.",
        "Typically, this measure or score is the probability of the product of the translation and the language models introduced above.",
        "The A* decoder follows a sequence of steps for achieving a complete (and possibly optimal) hypothesis:",
        "1.",
        "Initialize the stack with an empty hypothesis.",
        "2.",
        "Iterate (a) Pop h (the best hypothesis) off the stack.",
        "(b) If h is a complete sentence, output h and terminate.",
        "(c) Expand h. (d) Go to step 2a.",
        "The search is started from a null string and obtains new hypotheses after an expansion process (step 2c) which is executed at each iteration.",
        "The expansion process consists of the application of a set of operators over the best hypothesis in the stack, as it is depicted in Figure 1.",
        "Thus, the design of stack decoding algorithms involves defining a set of operators to be applied over every hypothesis as well as the way in which they are combined in the expansion process.",
        "Both the operators and the expansion algorithm depend on the translation model that we use.",
        "For the case of the phrase-based translation models described in the previous section, the operator add is defined, which adds a sequence of words to the target sentence, and aligns it with a sequence of words of the source sentence.",
        "The number of hypotheses to be stored during the search can be huge.",
        "In order then to avoid mem",
        "ory overflow problems, the maximum number of hypotheses that a stack may store has to be limited.",
        "It is important to note that for a hypothesis, the higher the aligned source words, the worse the score.",
        "These hypotheses will be discarded sooner when an A* search algorithm is used due to the stack length limitation.",
        "Because of this, the multi-stack algorithms were introduced.",
        "Multi-stack algorithms store those hypotheses with different subsets of source aligned words in different stacks.",
        "That is to say, given an input sentence f J1 composed of J words, multi-stack algorithms employes 2j stacks to translate it.",
        "Such an organization improves the pruning of the hypotheses when the stack length limitation is exceeded, since only hypotheses with the same number of covered positions can compete with each other.",
        "All the search steps given for A* algorithm can also be applied here, except step 2a.",
        "This is due to the fact that multiple stacks are used instead of only one.",
        "Figure 2 depicts the expansion process that the multi-stack algorithms execute, which is slightly different than the one presented in Figure 1.",
        "Multi-stack algorithms have the negative property of spending significant amounts of time in selecting the hypotheses to be expanded, since at each iteration, the best hypothesis in a set of 2j stacks must be searched for (Ortiz et al., 2003).",
        "By contrast, for the A* algorithm, it is not possible to reduce the length of the stack in the same way as in the multi-stack case without loss of translation quality.",
        "Additionally, certain translation systems, e.g. the Pharaoh decoder (Koehn, 2003) use an alternative",
        "approach which consists in assigning to the same stack, those hypotheses with the same number of source words covered."
      ]
    },
    {
      "heading": "4 Generalized Stack-Decoding Algorithms",
      "text": [
        "As was mentioned in the previous section, given a sentence f J1 to be translated, a single stack decoding algorithm employs only one stack to perform the translation process, while a multi-stack algorithm employs 2J stacks.",
        "We propose a possible way to make a tradeoff between the advantages of both algorithms that introduces a new parameter which will be referred to as the granularity of the algorithm.",
        "The granularity parameter determines the number of stacks used during the decoding process."
      ]
    },
    {
      "heading": "4.1 Selecting the granularity of the algorithm",
      "text": [
        "The granularity (G) of a generalized stack algorithm is an integer which takes values between 1 and J, where J is the number of words which compose the sentence to translate.",
        "Given a sentence f J1 to be translated, a generalized stack algorithm with a granularity parameter equal to g, will have the following features:",
        "• The algorithm will use at most 2g stacks to perform the translation • Each stack will contain hypotheses which have 2J-g different coverages of fJ1 • If the algorithm can store at most S = s hypotheses, then, the maximum size of each stack will be equal to s"
      ]
    },
    {
      "heading": "4.2 Mapping hypotheses to stacks",
      "text": [
        "Generalized stack-decoding algorithms require a mechanism to decide in which stack each hypothesis is to be inserted.",
        "As stated in section 4.1, given an input sentence f J1 and a generalized stack-decoding algorithm with G = g, the decoder will work with 2g stacks, and each one will contain 2J-g different coverages.",
        "Therefore, the above mentioned mechanism can be expressed as a function which will be referred to as the p function.",
        "Given a hypothesis coverage composed of J bits, the p function return a stack identifier composed of only g bits:",
        "Generalized stack algorithms are strongly inspired by multi-stack algorithms; however, both types of algorithms differ in the way the hypothesis expansion is performed.",
        "Figure 3 shows the expansion algorithm of a generalized stack decoder with a granularity parameter equal to g and a function p which maps hypotheses coverages to stacks.",
        "Figure 3: Flow chart associated to the expansion of a hypothesis when using a generalized-stack algorithm.",
        "The function p can be defined in many ways, but there are two essential principles which must be taken into account:",
        "• The p function must be efficiently calculated • Hypotheses whose coverage have a similar number of bits set to one must be assigned to the same stack.",
        "This requirement allows the pruning of the stacks to be improved, since the",
        "hypotheses with a similar number of covered words can compete fairly A possible way to implement the µ function, namely µ1, consists in simply shifting the coverage vector J − g positions to the right, and then keeping only the first g bits.",
        "Such a proposal is very easy to calculate, however, it has a poor performance according to the second principle explained above.",
        "A better alternative to implement the µ function, namely µ2, can be formulated as a composition of two functions.",
        "A constructive definition of such a implementation is detailed next:",
        "1.",
        "Let us suppose that the source sentence is composed by J words, we order the set of J bit numbers as follows: first the numbers which do not have any bit equal to one, next, the numbers which have only one bit equal to one, and so on 2.",
        "Given the list of numbers described above, we define a function which associates to each number of the list, the order of the number within this list 3.",
        "Given the coverage of a partial hypothesis, x,",
        "the stack on which this partial hypothesis is to be inserted is obtained by a two step process: First, we obtain the image of x returned by the function described above.",
        "Next, the result is shifted J − g positions to the right, keeping the first g bits Let Q be the function that shifts a bit vector J − g positions to the right, keeping the first g bits; and let a be the function that for each coverage returns its order:",
        "Table 1 shows an example of the values which returns the µ1 and the µ2 functions when the input sentence has 4 words and the granularity of the decoder is equal to 2.",
        "As it can be observed, µ2 function performs better than µ1 function according to the second principle described at the beginning of this section."
      ]
    },
    {
      "heading": "4.3 Single and Multi Stack Algorithms",
      "text": [
        "The classical single and multi-stack decoding algorithms can be expressed/instantiated as particular cases of the general formalism that have been proposed.",
        "Given the input sentence f J1 , a generalized stack decoding algorithm with G = 0 will have the following features:",
        "• The algorithm works with 20 = 1 stacks.",
        "• Such a stack may store hypotheses with 2J different coverages.",
        "That is to say, all possible coverages.",
        "• The mapping function returns the same stack identifier for each coverage",
        "The previously defined algorithm has the same features as a single stack algorithm.",
        "Let us now consider the features of a generalized stack algorithm with a granularity value of J:",
        "• The algorithm works with 2J stacks • Each stack may store hypotheses with only 20 = 1 coverage.",
        "• The mapping function returns a different stack identifier for each coverage",
        "The above mentioned features characterizes the multi-stack algorithms described in the literature."
      ]
    },
    {
      "heading": "5 Experiments and Results",
      "text": [
        "In this section, experimental results are presented for two well-known tasks: the EUTRANS-I (Amengual et al., 1996), a small size and easy translation task, and the XEROX (Cubel et al., 2004), a medium size and difficult translation task.",
        "The main statistics of these corpora are shown in Table 2.",
        "The translation results were obtained using a non-monotone generalized stack algorithm.",
        "For both tasks, the training of the different phrase models was carried out using the publicly available Thot toolkit (Ortiz et al., 2005).",
        "Different translation experiments have been carried out, varying the value of G (ranging from 0 to 8) and the maximum number of hypothesis that the algorithm is allow to store for all used stacks (5) (ranging from 28 to 212).",
        "In these experiments the following statistics are computed: the average score (or logProb) that the phrase-based translation model assigns to each hypothesis, the translation quality (by means of WER and Bleu measures), and the average time (in secs.)",
        "per sentence3.",
        "In Figures 4 and 5 two plots are shown: the average time per sentence (left) and the average score (right), for EUTRANS and XEROX corpora respectively.",
        "As can be seen in both figures, the bigger the value of G the lower the average time per sentence.",
        "This is true up to the value of G = 6.",
        "For higher values of G (keeping fixed the value of 5) the average time per sentence increase slightly.",
        "This is due to the fact that at this point the algorithm start to spend more time to decide which hypothesis is to be expanded.",
        "With respect to the average score similar values are obtained up to the value of G = 4.",
        "Higher",
        "values of G slightly decreases the average score.",
        "In this case, as G increases, the number of hypotheses per stack decreases, taking into account that the value of 5 is fixed, then the “optimal” hypothesis can easily be pruned.",
        "In tables 3 and 4 detailed experiments are shown for a value of 5 = 212 and different values of G, for EUTRANS and XEROX corpora respectively.",
        "According to the experiments presented here we can conclude that:",
        "• The results correlates for the two considered tasks: one small and easy, and other larger and difficult.",
        "• The proposed generalized stack decoding paradigm can be used to make a tradeoff be",
        "tween the advantages of classical single and multi-stack decoding algorithms.",
        "• As we expected, better results (regarding efficiency and accuracy) are obtained when using a value of G between 0 and J."
      ]
    },
    {
      "heading": "6 Concluding Remarks",
      "text": [
        "In this paper, a generalization of the stack-decoding paradigm has been proposed.",
        "This new formalism includes the well known single and multi-stack decoding algorithms and a new family of stack-based algorithms which have not been described yet in the literature.",
        "Essentially, generalized stack algorithms use a parameterized number of stacks during the decoding process, and try to assign hypotheses to stacks such that there is ”fair competition” within each stack, i.e., brother hypotheses should cover roughly the same number of input words (and the same words) if possible.",
        "The new family of stack-based algorithms allows a tradeoff to be made between the classical single and multi-stack decoding algorithms.",
        "For this purpose, they employ a certain number of stacks between 1(the number of stacks used by a single stack algorithm) and 2j (the number of stacks used by a multiple stack algorithm to translate a sentence with J words.)",
        "According to the experimental results, it has been proved that an appropriate value of G yields in a stack decoding algorithm that outperforms (in effi",
        "ciency and acuraccy) the single and multi-stack algorithms proposed so far.",
        "As future work, we plan to extend the experimentation framework presented here to larger and more complex tasks as HANSARDS and EUROPARL corpora."
      ]
    }
  ]
}
