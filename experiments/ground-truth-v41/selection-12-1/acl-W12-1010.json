{
  "info": {
    "authors": [
      "Eva Pettersson",
      "Be√°ta Megyesi",
      "Joakim Nivre"
    ],
    "book": "Proceedings of the 6th Workshop on Language Technology for Cultural Heritage, Social Sciences, and Humanities",
    "id": "acl-W12-1010",
    "title": "Parsing the Past - Identification of Verb Constructions in Historical Text",
    "url": "https://aclweb.org/anthology/W12-1010",
    "year": 2012
  },
  "references": [
    "acl-A00-1031",
    "acl-W11-1501",
    "acl-W11-1512"
  ],
  "sections": [
    {
      "heading": "Abstract",
      "text": [
        "Even though NLP tools are widely used for contemporary text today, there is a lack of tools that can handle historical documents.",
        "Such tools could greatly facilitate the work of researchers dealing with large volumes of historical texts.",
        "In this paper we propose a method for extracting verbs and their complements from historical Swedish text, using NLP tools and dictionaries developed for contemporary Swedish and a set of normalisation rules that are applied before tagging and parsing the text.",
        "When evaluated on a sample of texts from the period 1550?",
        "1880, this method identifies verbs with an F-score of 77.2% and finds a partially or completely correct set of complements for 55.6% of the verbs.",
        "Although these results are in general lower than for contemporary Swedish, they are strong enough to make the approach useful for information extraction in historical research.",
        "Moreover, the exact match rate for complete verb constructions is in fact higher for historical texts than for contemporary texts (38.7% vs. 30.8%)."
      ]
    },
    {
      "heading": "1 Introduction",
      "text": [
        "Today there is an abundance of NLP tools that can analyse contemporary language and extract information relevant to a particular user need, but there is a real lack of tools that can handle historical documents.",
        "Historians and other researchers working with older texts are still mostly forced to manually search large amounts of text in order to find the passages of interest to their research.",
        "Developing tools to facilitate this process is a great challenge, however, as historical texts vary greatly in both spelling and grammar between different authors, genres and time periods, and even within the same text, due to the lack of spelling conventions.",
        "In addition to this, there is a shortage of annotated resources that can be used for the development and evaluation of new tools.",
        "The work presented in this paper has been carried out in cooperation with historians, who are studying what men and women did for a living in the Early Modern Swedish society.",
        "Currently, the historians are manually extracting segments describing work activities from a number of historical texts, and entering them into a database, the Gender and Work Database.",
        "Their work so far has shown that the typical segment describing an activity of work is a verb construction, that is, a verb together with its complements (A?gren et al., 2011).",
        "(Examples of such segments can be found below in Table 1.)",
        "It is very likely that the manual effort and the time needed by the historians to find these segments and enter them into the database could be substantially reduced if verbs and their complements were automatically extracted and presented to the historian.",
        "This would give a general overview of the content of a text, and the task of the historian would be to select those segments that are actually describing work activities.",
        "By linking extracted segments back to larger passages of text, historians would also be able to find additional segments that were missed by the first automatic extraction.",
        "The core of such a system would be a component for identifying verb constructions in running text.",
        "We propose a method for automatically identifying verbs and their complements in various types of historical documents, produced in the Early Modern Swedish period (1550?1800).",
        "The method is based on using existing NLP tools for",
        "contemporary Swedish, in particular a part-of-speech tagger and a syntactic parser, and automatically normalising the input text into a more modern orthography before running it through the tagger and parser.",
        "In order to increase the precision of complement extraction, we use valency dictionaries to filter out unlikely complements in the output of the syntactic parser.",
        "Using this method, we are able to identify verbs with an F-score of 77.2% and find a partially or completely correct set of complements for 55.6% of the verbs.",
        "To our knowledge, extracting verb constructions from historical texts is a task that has not been directly addressed in previous research, which means that these results are also important in setting benchmarks for future research.",
        "The paper is structured as follows.",
        "Section 2 reviews related work.",
        "Section 3 describes the method for identification of verbs and complements in more detail.",
        "Section 4 presents the data and evaluation metrics used in our experiments, and Section 5 discusses the results of the evaluation.",
        "Finally, Section 6 concludes the paper."
      ]
    },
    {
      "heading": "2 Related Work",
      "text": [
        "Using NLP tools for analysing historical texts is still to a large extent unexplored.",
        "There is however a growing interest in this area, and there have been attempts to analyse historical texts (1) by using contemporary NLP tools as they are, (2) by using such tools in combination with normalisation rules and/or dictionaries covering historical language variation, and (3) by training new tools on annotated historical corpora.",
        "Pennacchiotti and Zanzotto (2008) concluded that contemporary NLP tools are not suitable as they are for analysing historical text.",
        "They tried to use a contemporary dictionary, morphological analyser and part-of-speech tagger to analyse Italian texts from the period 1200?1881.",
        "In their experiments, the dictionary only covered approximately 27% of the words in the oldest text, as compared to 62.5% of the words in a contemporary Italian newspaper text.",
        "Consequently, the morphological analyser based on the dictionary reached an accuracy of only 48%, as compared to 91% for contemporary text.",
        "Similarly, the part-of-speech tagger used reached an accuracy of only 54%, as compared to 97% for contemporary text.",
        "Oravecz et al. (2010) included a standardisation/normalisation step in their work on semi-automatically annotating a corpus of Old Hungarian.",
        "Normalisation was performed using a noisy channel model combined with morphological analysis filtering and decision tree reranking.",
        "Combining these methods, they reached a normalisation precision of 73.3%.",
        "Rocio et al. (1999) used a grammar of contemporary Portuguese to syntactically annotate medieval Portuguese texts.",
        "A dictionary and inflectional rules for medieval Portuguese were added to the parser, to make it suitable for handling these texts.",
        "This approach proved to be successful for partial parsing of medieval Portuguese texts, even though there were some problems remaining concerning grammar limitations, dictionary incompleteness and insufficient part-of-speech tagging.",
        "Sa?nchez-Marco et al. (2011) adapted an existing NLP tool to deal with Old Spanish.",
        "The adapted tool had an accuracy of 94.5% in finding the right part of speech, and 89.9% accuracy in finding the complete morphological tag.",
        "The adaptation was performed on the basis of a 20 million token corpus of texts from the 12th to the 16th century, and included expansion of the dictionary, modification of tokenisation and affixation rules, and retraining of the tagger.",
        "The retraining was based on a gold standard of 30,000 tokens, where the tokens were first pre-annotated with the contemporary tagger, and then manually corrected.",
        "Adding new words to the dictionary had the highest impact on the results.",
        "This was done by automatically generating word forms through mapping old spelling variants to their contemporary counterparts.",
        "Pettersson and Nivre (2011) presented a study on automatically extracting verbs from Swedish 17th century texts, using contemporary language technology tools combined with normalisation of the input text.",
        "The verb extraction process included an iterative process of normalisation and morphological analysis, followed by part-of-speech tagging for disambiguation of competing interpretations and for analysing words still unknown to the morphological analyser after all normalisation rules had been applied.",
        "Using this method, verbs were extracted with 82% precision and 88% recall.",
        "The study also included the results of using only the part-of-speech tagger for verb recognition, i.e., dropping the morphological analyser.",
        "This resulted in a small decrease in precision to 81% and in recall to 86%."
      ]
    },
    {
      "heading": "3 Extraction of Verb Constructions",
      "text": [
        "In this paper, we will focus on adapting existing NLP tools by adding normalisation rules prior to processing.",
        "We will mainly follow the methodology for verb extraction described in Pettersson and Nivre (2011), but adding the extraction of not only the verbs themselves, but also their adherent complements.",
        "It would perhaps have been desirable to use tools specifically trained for analysing historical texts.",
        "This would however be a resource-demanding task, considering the lack of annotated data and the language variation, and is currently not a realistic scenario.",
        "The goal is to automatically extract verbs and relevant complements from historical texts, in order to give an overview of the contents and present segments that are possibly describing work activities.",
        "In this context, we use the term complement in a broad sense and do not impose a sharp distinction between complements and adjuncts, especially not for prepositional phrases.",
        "This is motivated by the fact that in the Gender and Work Database, both segments that would traditionally be seen as complements and phrases that would rather be categorised as adjuncts have been considered relevant.",
        "A closer look at the database shows that 67% of the entered segments consist of a verb with a direct object.",
        "Other common constructions are verbs with a prepositional complement (11%), verbs with both a direct object and a prepositional complement (10%), and (intransitive) verbs without complements (7%).",
        "Table 1 illustrates the most common construction types found in the database, which have been used to define the rules for extracting complements from parsed sentences.",
        "There were also a small number of segments (8 in total), that we were not able to categorise."
      ]
    },
    {
      "heading": "3.1 System Overview",
      "text": [
        "The extraction of verbs and their complements is basically performed in five steps:",
        "1.",
        "Tokenisation 2.",
        "Normalisation 3.",
        "Part-of-speech tagging 4.",
        "Parsing 5.",
        "Extraction of verb constructions Freq Comp Source Text Example 273 dobj dhe ba?rgadhe [Ho?o?]",
        "they harvested [Hay] 47 pcomp [med een ha?st] kio?rtt",
        "plements in brackets.",
        "Grammatical functions: dobj = direct object, pcomp = prepositional complement, intrans = intransitive, indobj = indirect object, infc = infinitive clause, subc = subordinate clause.",
        "Tokenisation is performed with a simple tokeniser for Swedish that has not been adapted for historical texts."
      ]
    },
    {
      "heading": "3.2 Normalisation",
      "text": [
        "After tokenisation, each word is normalised to a more modern spelling using a set of 29 hand-crafted rules.",
        "The rules were developed using a text sample from Per Larssons dombok, a selection of court records from 1638 (Edling, 1937), a sample that has not been used in subsequent evaluation.",
        "An example of a normalisation rule is the transformation of the letter combination sch into sk, as in the old spelling schall that is normalised to the contemporary spelling skall (?shall/should?).",
        "Some additional rules were also formulated based on the reformed Swedish spelling introduced in 1906 (Bergman, 1995).",
        "This set of rules includes the transformation of double vowels into a single vowel, as in so?o?ka, which is normalised into so?ka (?search?",
        ")."
      ]
    },
    {
      "heading": "3.3 Part-of-speech Tagging",
      "text": [
        "The purpose of part-of-speech tagging in our experiments is both to find the verbs in the text and to prepare for the parsing step, in which the complements are identified.",
        "Part-of-speech tagging is performed using HunPOS (Hala?csy et al., 2007), a free and open source reimplementation of the HMM-based TnT-tagger by Brants (2000).",
        "The tagger is used with a pre-trained language model based on the Stockholm-Umea?",
        "Corpus (SUC), a balanced, manually annotated corpus of different text types representative of the Swedish language in the 1990s, comprising approximately one million tokens (Gustafson-Capkova?",
        "and Hartmann, 2006).",
        "Megyesi (2009) showed that the HunPOS tagger trained on SUC, is one of the best performing taggers for (contemporary) Swedish texts."
      ]
    },
    {
      "heading": "3.4 Parsing",
      "text": [
        "The normalised and tagged input text is parsed using MaltParser version 1.6, a data-driven dependency parser developed by Nivre et al. (2006a).",
        "In our experiments, the parser is run with a pre-trained model1 for parsing contemporary Swedish text, based on the Talbanken section of the Swedish Treebank (Nivre et al., 2006b).",
        "The parser produces dependency trees labeled with grammatical functions, which can be used to identify different types of complements."
      ]
    },
    {
      "heading": "3.5 Extraction of Verb Constructions",
      "text": [
        "The extraction of verb constructions from the tagged and parsed text is performed in two steps:",
        "1.",
        "Every word form analysed as a verb by the tagger is treated as the head of a verb construction.",
        "2.",
        "Every phrase analysed as a dependent of the",
        "verb by the parser is treated as a complement provided that it has a relevant grammatical function.",
        "The following grammatical functions are defined to be relevant:",
        "1.",
        "Subject (SS) 2.",
        "Direct object (OO) 3.",
        "Indirect object (IO) 1http://maltparser.org/mco/swedish parser/swemalt.html 4.",
        "Predicative complement (SP) 5.",
        "Prepositional complement (OA) 6.",
        "Infinitive complement of object (VO) 7.",
        "Verb particle (PL)",
        "Subjects are included only if the verb has been analysed as a passive verb by the tagger, in which case the subject is likely to correspond to the direct object in the active voice.",
        "In an attempt to improve precision in the complement extraction phase, we also use valency dictionaries for filtering the suggested complements.",
        "The valency frame of a verb tells us what complements the verb is likely to occur with.",
        "The assumption is that this information could be useful for removing unlikely complements, i.e., complements that are not part of the valency frame for the verb in question.",
        "The following example illustrates the potential usefulness of this method: J midler tijd kom greffuinnans gotze fougte thijtt However, the Countess?",
        "estate bailiff came there In this case, the parser analysed the partial noun phrase greffuinnans gotze (?the Countess?",
        "estate?)",
        "as a direct object connected to kom (?came?).",
        "However, since the word kom is present in the valency dictionaries, we know that it is an intransitive verb that does not take a direct object.",
        "Hence, this complement can be removed.",
        "The valency"
      ]
    },
    {
      "heading": "4 Experimental Setup",
      "text": []
    },
    {
      "heading": "4.1 Data",
      "text": [
        "In order to evaluate the accuracy of our method, we have used ten texts from the period 1527?",
        "and documents related to the Church.",
        "In total, there are 444,075 tokens in the corpus, distributed as follows (number of tokens in parentheses):",
        "Court records: 1.",
        "Per Larssons dombok (subset),1638(11,439) 2.",
        "Hammerdals tingslag, 1649?1686 (66,928) 3.",
        "Revsunds tingslag, 1649?1689 (101,020) 4.",
        "Vendels socken, 1615?45 (59,948) 5.",
        "Vendels socken, 1736?37 (55,780) 6.",
        "O?stra ha?rads i Njudung,1602?1605(34,956) Documents related to the Church: 1.",
        "Va?stera's recess, 1527 (12,193) 2.",
        "1571 a?rs kyrkoordning (49,043) 3.",
        "Uppsala mo?tes beslut, 1593 (26,969) 4.",
        "1686 a?rs kyrkolag (25,799)",
        "A gold standard of 40 randomly selected sentences from each text was compiled, i.e., in total 400 sentences.",
        "The gold standard was produced by manually annotating the sentences regarding verbs and complements.",
        "Because sentences are much longer in these texts than in contemporary texts, the 400 sentences together contain a total of 3,105 verbs.",
        "Each word form that was interpreted as a verb was annotated with the tag VB, and complements were enclosed in brackets labeled with their grammatical function.",
        "This is illustrated in Figure 1, which shows an annotated segment from the test corpus.",
        "For comparison with contemporary text, we make use of a subset of the Stockholm-Umea?",
        "Corpus of contemporary Swedish text, SUC (Ejerhed and Ka?llgren, 1997).",
        "This subset contains those segments in SUC that have been syntactically annotated and manually revised in the Swedish Treebank.",
        "In total, the subset includes approximately 20,000 tokens.",
        "Since the tagger used in the experiments on historical texts is trained on the whole of SUC, we had to slightly modify the extraction algorithm in order not to evaluate on the same data as the tagger has been trained.",
        "When testing the algorithm on contemporary text, we therefore trained a new model for the tagger, including all tokens in SUC except for the tokens reserved for evaluation."
      ]
    },
    {
      "heading": "4.2 Evaluation Metrics",
      "text": [
        "In order to get a more fine-grained picture of the system's performance, we want to evaluate three",
        "different aspects: 1.",
        "Identification of verbs 2.",
        "Identification of complements 3.",
        "Identification of holistic verb constructions",
        "The identification of verbs depends only on the part-of-speech tagger and can be evaluated using traditional precision and recall measures, comparing the tokens analysed as verbs by the tagger to the tokens analysed as verbs in the gold standard.",
        "The identification of complements depends on both the tagger and the parser and can also be",
        "evaluated using precision and recall measures.",
        "In this case, every complement identified by the parser is compared to the complements annotated in the gold standard.",
        "Precision is the number of correct complements found by the parser divided by the total number of complements output by the parser, while recall is the number of correct complements found by the parser divided by the number of complements in the gold standard.",
        "We do not take the labels into account when assessing complements as correct or incorrect.",
        "The motivation for this is that the overall aim of the complement extraction is to present verb expressions to historians, for them to consider whether they are describing work activities or not.",
        "In this context, only textual strings will be of interest, and grammatical function labels are ignored.",
        "For example, assume that the gold standard is: lefverere [IO honom] [OO Sa?dh] deliver [IO him] [OO grain] and that the system produces: lefverere [OO honom] deliver [OO him] In this context, the complement honom (?him?)",
        "will be regarded as correct, even though it has been analysed as a direct object instead of an indirect object.",
        "On the other hand, the evaluation of complement identification is strict in that it requires the complement found to coincide exactly with the complement in the gold standard.",
        "For example, assume the gold standard is: effterfra?gat [OA om sinss manss do?dh] asked [OA about her husband's death] and that the system produces: effterfra?gat [OA om sinss manss] asked [OA about her husband?s] In this case, the complement will not be regarded as correct because it does not cover exactly the same textual string as the gold standard annotation.",
        "The identification of holistic verb constructions, that is, a verb and all its complements, depends on the identification of verbs and complements, as well as the optional filtering of complements using valency dictionaries.",
        "Here we want to evaluate the entire text segment extracted in a way that is relevant for the intended application of the system.",
        "First of all, this means that partially correct constructions should be taken into account.",
        "Consider again the earlier example: effterfra?gat [OA om sinss manss do?dh] asked [OA about her husband's death] and assume that the system produces: effterfra?gat [OA om sinss manss] asked [OA about her husband?s] As noted above, this complement would be considered incorrect in the precision/recall evaluation of complement extraction, even though only one word is missing as compared to the gold standard, and the output would probably still be valuable to the end-user.",
        "Secondly, we should consider the total segment extracted for a verb including all complements, rather than inspecting each complement separately.",
        "In order to reflect partially correct complements and take the total segment extracted for each verb into account, we use a string-based evaluation method for the identification of holistic verb constructions.",
        "In this evaluation, all labels and brackets are removed before comparing the segments extracted to the segments in the text corpus and each extracted instance is classified as falling into one of the four following categories:",
        "?",
        "Fully correct complement set (F) ?",
        "Partially correct complement set (P) ?",
        "Incorrect complement set (I) ?",
        "Missing complement set (M)",
        "A complement set is regarded as fully correct if the output string generated by the system is identical to the corresponding gold standard string.",
        "Since labels and brackets have been removed, these analyses will be regarded as identical: lemnat [IO swaranden] [OO tid] given [IO the defendant] [OO time]",
        "lemnat [OO swaranden tid] given [OO the defendant time] A complement set is regarded as partially correct if the output string generated by the system has a non-empty overlap with the corresponding gold standard string.",
        "For example, the following three sets of analyses will be considered as partially correct (gold standard top, system output bottom): lefverere [IO honom] [OO Sa?dh] deliver [IO him] [OO Grain] lefverere [OO honom] deliver [OO him] effterfra?gat [OA om sinss manss do?dh] asked [OA about her husband's death] effterfra?gat [OA om sinss manss] asked [OA about her husband?s] betale [PL a?ter] [IO ha?r Mattz] [OO Ra?gen] pay [PL back] [IO mister Mattz] [OO the Rye] betale [OO a?ter ha?r Mattz] pay [OO back mister Mattz] A (non-empty) complement set is regarded as incorrect if the output string has no overlap with the gold standard string.",
        "Finally, a complement set is regarded as missing if the output string is empty but the gold standard string is not.",
        "It is worth noting that the four categories are mutually exclusive."
      ]
    },
    {
      "heading": "5 Results and Discussion",
      "text": [
        "In this section, we evaluate the identification of verbs, complements and holistic verb constructions using the data and metrics described in the previous section."
      ]
    },
    {
      "heading": "5.1 Verbs",
      "text": [
        "Results on the identification of verbs using part-of-speech tagging, with and without normalisation, are reported in Table 2.",
        "As can be seen, recall drastically increases when normalisation rules are applied prior to tagging, even though the normalisation rules used in this experiment are formulated based on a subset of one single 17th century text, and the test corpus contains samples of various text types ranging from 1527?1737.",
        "Normalisation also has a small positive effect on precision, and the best result for historical texts is 78.4% precision and 76.0% recall.",
        "This is slightly",
        "normalised input text.",
        "Norm = Normalisation of input prior to tagging.",
        "SUC = Subset of Stockholm-Umea?",
        "corpus of contemporary Swedish texts, as described in section 4.1. lower than the results presented by Pettersson and Nivre (2011) where only 17th century text was used for evaluation, indicating that the normalisation rules are somewhat biased towards 17th century text, and that the results could be improved if normalisation were adapted to specific time periods.",
        "It is also worth noting that the results are substantially lower for historical text than the results for contemporary text, with precision and recall at 99.1%, but still high enough to be useful in the intended context of application.",
        "Tokens that are still erroneously analysed by the tagger include the following cases: ?",
        "tokens where the old spelling is identical to an existing, but different, word form in contemporary language; for example, the spelling skal would in contemporary language be considered a noun (?shell?)",
        "but in the old texts this spelling is used for a word that is nowadays spelled skall (?shall/should?)",
        "and should be regarded as a verb; ?",
        "ambiguous words; for example, past participles are often spelled the same way as the corresponding past tense verb, but participles are not regarded as verb forms in our experiments;4 ?",
        "tokens that have not been normalised enough and thus do not correspond to a word form recognised by the tagger, e.g., the word form lemnas which in contemporary language should be spelled as la?mnas (?be left?",
        ").",
        "Raw = Unnormalised input text.",
        "Norm = Normalisation of input prior to tagging and parsing.",
        "+Valency = Adding valency filtering to the setting in the preceding row.",
        "SUC = Subset of Stockholm-Umea?",
        "corpus of contemporary Swedish texts, as described in section 4.1."
      ]
    },
    {
      "heading": "5.2 Complements",
      "text": [
        "Recall and precision for the identification of complements using parsing are presented in Table 3.",
        "In this case, normalisation has a smaller effect than in the case of tagging and affects precision more than recall.",
        "Adding a filter that eliminates unlikely complements based on the valency frame of the verb in existing dictionaries predictably improves precision at the expense of recall and results in a small F-score improvement.",
        "Again, the best scores on the historical texts are much lower than the corresponding results for contemporary text, with an F-score of 28.8% in the former case and 69.5% in the latter, but it is worth remembering that precision and recall on exactly matching complements is a harsh metric that is not directly relevant for the intended application.",
        "Finally, it is worth noting that the valency filter has a large negative impact on recall for the modern texts, resulting in a decrease in the F-score, which indicates that the parser in this case is quite successful at identifying complements (in the wide sense) that are not covered by the valency dictionaries."
      ]
    },
    {
      "heading": "5.3 Verb Constructions",
      "text": [
        "As argued in section 4.2, precision and recall measures are not sufficient for evaluating the extraction of holistic verb constructions.",
        "A more relevant assessment is made by counting the number of fully correct, partially correct, incorrect and missing complement sets for the verbs identified.",
        "Table 4 summarises the results in accordance with this metric.",
        "First of all, we see that normalisation again has a rather small effect on overall results, increas",
        "= Normalisation of input prior to tagging and parsing.",
        "+Valency = Adding valency filtering to the setting in the preceding row.",
        "SUC = Subset of Stockholm-Umea?",
        "corpus of contemporary Swedish texts, as described in section 4.1. ing the number of fully correct constructions and decreasing the number of incorrect constructions, but also leading to an increase in the number of missing complements.",
        "Adding the valency filter to remove unlikely complements has a similar effect and increases the percentage of correctly extracted verb constructions to 38.7% while decreasing the share of incorrect constructions to 18.9%.",
        "However, it also increases the percentage of verbs with missing complement sets from 20.8% to 25.5%.",
        "This is partly due to the fact that some of the verbs are used in a slightly different way in historical text as compared to contemporary text, meaning that the valency frames are not as reliable.",
        "For example, the verb avsta?",
        "(?refrain?)",
        "in the historical corpus is used with a direct object, as in Anders Andersson afsta?dt sitt skatte hemman (?Anders Andersson refrained his homestead?",
        "), whereas in a contemporary context this verb would more likely be used with a prepositional complement, avsta?",
        "fra?n na?gonting (?refrain from something?).",
        "In total, 55.6% of the verbs are assigned a fully or partially correct set of complements.",
        "This is again lower than the result for contemporary texts (78.7%), but the difference is smaller than for the previous metrics, which is encouraging given that the evaluation in this section is most relevant for the intended application.",
        "Moreover, it is worth noting that the difference is mostly to be found in the category of partially correct constructions, where the best result for modern texts is 54.2%, to be compared to 16.9% for the historical texts.",
        "With respect to fully correct constructions, however, the results are actually better for the histor",
        "ical texts than for the modern texts, 38.7% vs. 30.8%, a rather surprising positive result."
      ]
    },
    {
      "heading": "6 Conclusion",
      "text": [
        "We have presented a method for automatically extracting verbs and their complements from historical Swedish texts, more precisely texts from the Early Modern era (1550?1800), with the aim of providing language technology support for historical research.",
        "We have shown that it is possible to use existing contemporary NLP tools and dictionaries for this purpose, provided that the input text is first (automatically) normalised to a more modern spelling.",
        "With the best configuration of our tools, we can identify verbs with an F-score of 77.2% and find a partially or completely correct set of complements for 55.6% of the verbs.",
        "To the best of our knowledge, these are the first results of their kind.",
        "In addition to presenting a method for the identification of verb constructions, we have also proposed a new evaluation framework for such methods in the context of information extraction for historical research.",
        "As a complement to standard precision and recall metrics for verbs and their complements, we have evaluated the text segments extracted using the categories fully correct, partially correct, incorrect, and missing.",
        "One important topic for future research is to validate this evaluation framework by correlating it to the perceived usefulness of the system when used by historians working on the Gender and Work Database.",
        "Preliminary experiments using a prototype system indicate that this kind of support can in fact reduce the time-consuming, manual work that is currently carried out by historians and other researchers working with older texts.",
        "Another topic for future research concerns the variation in performance across time periods and text types.",
        "In the current evaluation, court records and papers related to the Church ranging from 1527 to 1737 have been sampled in the gold standard.",
        "It would be interesting to explore in more detail how the program performs on the oldest texts as compared to the youngest texts, and on court records as compared to the other genres."
      ]
    }
  ]
}
