{
  "info": {
    "authors": [
      "Ruifeng Xu",
      "Jun Xu",
      "Jie Liu",
      "Chengxiang Liu",
      "Chengtian Zou",
      "Lin Gui",
      "Yanzhen Zheng",
      "Peng Qu"
    ],
    "book": "Joint Conference on EMNLP and CoNLL â€“ Shared Task",
    "id": "acl-W12-4512",
    "title": "Incorporating Rule-based and Statistic-based Techniques for Coreference Resolution",
    "url": "https://aclweb.org/anthology/W12-4512",
    "year": 2012
  },
  "references": [
    "acl-C10-1068",
    "acl-D07-1052",
    "acl-D08-1031",
    "acl-J01-4004",
    "acl-M95-1002",
    "acl-M98-1001",
    "acl-P02-1014",
    "acl-W11-1902",
    "acl-W11-1919",
    "acl-W12-4501",
    "acl-W97-1306"
  ],
  "sections": [
    {
      "heading": "Abstract",
      "text": [
        "This paper describes a coreference resolution system for CONLL 2012 shared task developed by HLT_HITSZ group, which incorporates rule-based and statistic-based techniques.",
        "The system performs coreference resolution through the mention pair classification and linking.",
        "For each detected mention pairs in the text, a Decision Tree (DT) based binary classifier is applied to determine whether they form a coreference.",
        "This classifier incorporates 51 and 61 selected features for English and Chinese, respectively.",
        "Meanwhile, a rule-based classifier is applied to recognize some specific types of coreference, especially the ones with long distances.",
        "The outputs of these two classifiers are merged.",
        "Next, the recognized coreferences are linked to generate the final coreference chain.",
        "This system is evaluated on English and Chinese sides (Closed Track), respectively.",
        "It achieves 0.5861 and 0.6003 F1 score on the development data of English and Chinese, respectively.",
        "As for the test dataset, the achieved F1 scores are 0.5749 and 0.6508, respectively.",
        "This encouraging performance shows the effectiveness of our proposed coreference resolution system."
      ]
    },
    {
      "heading": "1 Introduction",
      "text": [
        "Coreference resolution aims to find out the different mentions in a document which refer to the same entity in reality (Sundheim and Beth, 1995; Lang et al. 1997; Chinchor and Nancy, 1998;).",
        "It is a core component in natural language processing and information extraction.",
        "Both rule-based approach (Lee et al. 2011) and statistic-based approach (Soon et al., 2001; Ng and Cardie, 2002; Bengtson and Roth, 2008; Stoyanov et al., 2009; Chen et al. 2011) are proposed in coreference resolution study.",
        "Besides the frequently used syntactic and semantic features, the more linguistic features are exploited in recent works (Versley, 2007; Kong et al. 2010).",
        "CoNLL-2012 proposes a shared task, ?Modeling multilingual unrestricted coreference in the OntoNotes?",
        "(Pradhan et al. 2012).",
        "This is an extension of the CoNLL-2011 shared task.",
        "The task involves automatic anaphoric mention detection and coreference resolution across three languages including English, Chinese and Arabic.",
        "HLT_HITSZ group participated in the Closed Track evaluation on English and Chinese side.",
        "This paper presents the framework and techniques of HLT_HITSZ system which incorporates both rule-based and statistic-based techniques.",
        "In this system, the mentions are firstly identified based on the provided syntactic information.",
        "The mention pairs in the document are fed to a Decision Tree based classifier to determine whether they form a coreference or not.",
        "The rule-based classifiers are then applied to recognize some specific types of coreference, in particular, the long distance ones.",
        "Finally, the recognized coreference are linked to obtain the final coreference resolution results.",
        "This system incorporates lexical, syntactical and semantic features.",
        "Especially for English, WordNet is used to provide semantic information of the mentions, such as semantic distance and the",
        "category of the mentions and so on.",
        "Other than the officially provided number and gender data, we generated some lexicons from the training dataset to obtain the values of some features.",
        "This system achieves 0.5861 and 0.6003 F1 scores on English and Chinese development data, respectively, and 0.5749 and 0.6508 F1 scores on English and Chinese testing data, respectively.",
        "The achieved encouraging performances show that the proposed incorporation of rule-based and statistic-based techniques is effective.",
        "The rest of this report is organized as below.",
        "Section 2 presents the mention detection.",
        "Section 3 presents the coreference determination and Section 4 presents the coreference linking.",
        "The experimental results are given in Section 5 in detail.",
        "Finally, Section 6 concludes this report."
      ]
    },
    {
      "heading": "2 Mention Detection",
      "text": [
        "In this stage, the system detects the mentions from the text.",
        "The pairs of these mentions in one document are regarded as the coreference candidates.",
        "Thus, the high recall is a more important target than higher precision for this stage.",
        "Corresponding to English and Chinese, we adopted different detection methods, respectively."
      ]
    },
    {
      "heading": "2.1 Mention Detection - English",
      "text": [
        "HLT_HITSZ system chooses the marked noun phrase (NP), pronouns (PRP) and PRP$ in English data as the mentions.",
        "The system selects most named entities (NE) as the mentions but filter out some specific types.",
        "Firstly, the NEs which cannot be labeled either as NP or NML are filter out because there are too cases that the pairs of these NEs does not corefer even they are in the same form as shown in the training dataset.",
        "Second, the NEs of ORDINAL, PERCENT and MONEY types are filtered because they have very low coreference ratio (less than 2%).",
        "Furthermore, for the cases that NPs overlapping a shorter NP, normally, only the longer one are choose.",
        "An exception is that if the shorter NPs are in parallel structures with the same level to construct a longer NP.",
        "For example, for a NP ?A and B?, ?A?, ?B?",
        "and ?A and B?",
        "as regarded ed as three different mentions."
      ]
    },
    {
      "heading": "2.2 Mention Detection ? Chinese",
      "text": [
        "HLT_HITSZ system extracts all NPs and PNs as the mention candidates.",
        "For the NPs have the overlaps, we handle them in three ways: 1.",
        "For the cases that two NPs share the same tail, the longer NP is kept and the rest discarded; 2.",
        "For cases that the longer NP has a NR as its tail, the NPs which share the same tail are discarded; 3.",
        "In MZ and NW folders, they are many mentions nested marked as the nested co-referent mentions.",
        "The system selects the longest NP as mention in this stage while the other mention candidates in the longest NP will be recalled in the post processing stage."
      ]
    },
    {
      "heading": "3 Coreference Determination",
      "text": [
        "Any pair of two detected mentions in one document becomes one coreference candidate.",
        "In this stage, the classifiers are developed to determine whether this pair be a coreference or not.",
        "During the generation of mention pairs, it is observed that linking any two mentions in one document as candidates leads to much noises.",
        "The statistical observation on the Chinese training dataset show that 90% corefered mention pairs are in the distance of 10 sentences.",
        "Similar results are found in the English training dataset while the context window is set to 5 sentences.",
        "Therefore, in this stage, the context windows for generating mention pairs as coreference candidates for English and Chinese are limited to 5 and 10 sentences, respectively."
      ]
    },
    {
      "heading": "3.1 The Statistic-based Coreference Determination",
      "text": [
        "The same framework is adopted in the statistical-based coreference determination for English and Chinese, respectively, which is based on a machine learning-based statistical classifier and selected language-dependent features.",
        "Through transfer the examples in the training test into feature-valued space, the classifier is trained.",
        "This binary classifier will be applied to determine whether the input mention pair be a coreference or not.",
        "Here, we evaluated three machine learning based classifiers including Decision Tree, Support Vector Machines and Maximum Entropy on the training data while Decision Tree perform the best.",
        "Thus, DT classifier is selected.",
        "Since the annotations on the training data from different directory show some inconsistence, multiple classifiers corresponding to each directory are trained individually.",
        "51 features are selected for English coreference determination.",
        "The features are camped to six categories.",
        "Some typical features are listed below:",
        "1.",
        "Basic features: (1) Syntactic type of the two mentions, includes NP, NE, PRP, PRP$.",
        "Here, only the NPs which do not contain any named entities or its head word isn't a named entity are considered as an NP while the others are discarded.",
        "(2) If one mention is a PRP or PRP$, use an ID to specify which one it is.",
        "(3) The sentence distance between two mentions.",
        "(4) Whether one mention is contained by another one.",
        "2.",
        "Parsing features: (1) Whether two mentions belong to one NP.",
        "(2) The phrase distance between the two mentions.",
        "(3) The predicted arguments which the two mentions belong to.",
        "3.",
        "Named entity related features: (1) If both of the two mentions may be considered as named entities, whether they have the same type.",
        "(2) If one mention is a common NP or PRP and another one can be considered as named entity, whether the words of the common NP or PRP can be used to refer this type of named entity.",
        "This knowledge is extracted from the training dataset.",
        "(3) Whether the core words of the two named entity type NP match each other.",
        "4.",
        "Features for PRP: (1) If both mentions are PRP or PRP$, use an",
        "ID to show what they are.",
        "The PRP$ with the same type will be assigned the same ID, for example, he, him and his.",
        "(2) Whether the two mentions has the same PRP ID.",
        "5.",
        "Semantic Features: (1) Whether the two mentions have the same headword.",
        "(2) Whether the two mentions belong to the same type.",
        "Here, we use WordNet to get three most common sense of each NP and compare the type they belong to.",
        "(3) The semantic distance between two mentions.",
        "WordNet is used here.",
        "(4) The natures of the two mentions, including number, gender, is human or not, and match each other or not.",
        "We use WordNet and a lexicon extracted from the gender and number file here.",
        "6.",
        "Document features: (1) How many speakers in this document.",
        "(2) Whether the mention is the first or the last sentence of the document.",
        "(3) Whether the two mentions are from the same speaker.",
        "There are 61 features adopted in Chinese side.",
        "Because of the restriction of closed crack, most of features use the position and POS information.",
        "It is mentionable that the ways for calculating the features values.",
        "For instance, the sentence distance is not the real sentence distance in the document.",
        "For instead, the value is the number of sentences in which there are at least one mention between the mention pair.",
        "This ignores the sentences of only modal particles.",
        "The 61 features are camped into five groups.",
        "Some example features are listed below.",
        "1.",
        "Basic information: (1) The matching degree of two mentions (2) The word distance of two mentions (3) The sentence distance of two mentions 2.",
        "Parsing information: (1) Predicted arguments which the two mentions belong to and corresponding layers.",
        "3.",
        "POS features (1) Whether the mention is NR (2) Whether the two mentions are both NR and are matched 4.",
        "Semantic features: (1) Whether the two mention is related (2) Whether the two mentions corefer in the",
        "history.",
        "Since the restriction of closed track, we did not use any additional semantic resources.",
        "Here, we extract the co-reference history from the training set to obtain some semantic information, such as ?NN ???",
        "and ?NN ???",
        "corefered in the training data, and they are regarded as coreference in the testing data."
      ]
    },
    {
      "heading": "5. Document Features:",
      "text": [
        "(1) Whether the two mentions have the same speaker.",
        "(2) Whether the mention is a human.",
        "(3) Whether the mention is the first mention in the sentence.",
        "(4) Whether the sentence to which the mention belongs to is the first sentence.",
        "(5) Whether the sentence to which the mention belongs to is the second sentence (6) Whether the sentence to which the mention belongs to is the last sentence (7) The number of the speakers in the document."
      ]
    },
    {
      "heading": "3.2 The Rule-based Coreference Determination",
      "text": [
        "The rule-based classifier is developed to recognize some specific types of coreference and especially, the long distance ones.",
        "To achieve a high precision, only the mention pairs of NE-NE (include NPs those can be considered as NE) or NP-NP types with the same string are classified here.",
        "For the NE-NE pair, the classifier identifies their NE part from the whole NP, if their strings are the same, they are considered as coreference.",
        "For the NP-NP pair, the pairs satisfy the following rules are regarded as coreference.",
        "(1) The POS of the first word isn't ?JJR?",
        "or ?JJ?.",
        "(2) If NP has only one word, its POS isn't ?NNS?",
        "or ?NNPS?.",
        "(3) The NP have no word like ?every?, ?every-?, ?none?, ?no?, ?any?, ?some?, ?each?.",
        "(4) If the two NP has article, they can't be both",
        "?a?",
        "or ?an?.",
        "Additionally, for the PRP mention pairs, only ?I?, ?me?, ?my?",
        "with the same speaker can be regarded as coreference.",
        "A rule-based classifier is developed to determine whether the mention pairs between PNs and mentions not PN corefer or not.",
        "For instance, the mention pairs between the PN ???",
        "which is after a comma and the mention which is marked as ARG0 in the same sentence.",
        "In the sentence ??????",
        "??",
        "?",
        "?",
        "??",
        "??",
        "??",
        "??",
        "?",
        "??",
        "?, because the mention pair between ???????",
        "and the first ???",
        "match the mentioned above rule, it is classified as a positive one.",
        "The result on the development set shows that the rule-based classifier brings good improvement."
      ]
    },
    {
      "heading": "4 Coreference Chain Construction",
      "text": []
    },
    {
      "heading": "4.1 Coreference Chain Construction-English",
      "text": [
        "The evaluation on development data shows that the achieved precision of our system is better than recall.",
        "Thus, in this stage, we simply link every pair of mentions together if there is any links can link them together to generate the initial coreference chain.",
        "After that, the mentions have the distance longer than 5 sentences are observed.",
        "The NE-NE or NP-NP mention pairs between one known coreference and an observing mention with long distance are classified to determine they are corefered or not by using a set of rules.",
        "The new detected conference will be linked to the initial coreference chain."
      ]
    },
    {
      "heading": "4.2 Coreference Chain Construction-Chinese",
      "text": [
        "The coreference chain construction for Chinese is similar to English.",
        "Furthermore, as mentioned above, in MZ and NW folders, there are many mentions nested marked as the nested co-referenced mentions.",
        "In this stage, HLT_HITSZ system generates the nested co-reference mentions for improving the analysis for these two folders.",
        "Additionally, the system uses some rules to improve the coreference chain construction.",
        "We find that the trained classifier performs poor in coreference resolution related to Pronoun.",
        "So, most rules adopted here are related to these Pronouns: ???",
        "?, ??",
        "?, ??",
        "?, ??",
        "?, ??",
        "?, ???",
        "?, ???",
        "?, ???.",
        "We use these rules to bridge the chain of pronouns and the chain of other type.",
        "Although high precision for NT co-reference cases are achieved through string matching, the recall is not satisfactory.",
        "It partially attributes to the fact that the flexible use of Chinese.",
        "For example, to express the year of 1980, we found ??????",
        "?, ?????",
        "?, ?",
        "????",
        "?, ???",
        "?",
        "?, ?1980 ?",
        "?.",
        "Similar situation happens for month (?, ??)",
        "and day (?,?",
        "), we conclude most situations to several templates to improve the rule-based conference resolution."
      ]
    },
    {
      "heading": "5 Evaluation Results",
      "text": []
    },
    {
      "heading": "5.1 Dataset",
      "text": [
        "The status of training dataset, development dataset and testing dataset in CoNLL 2012 for English and Chinese are given in Table 1 and Table 2, respectively."
      ]
    },
    {
      "heading": "5.2 Evaluation on Mention Detection",
      "text": [
        "Firstly, the mention detection performance is evaluated.",
        "The performance achieved on the development dataset (Gold/Auto) and test data on English and Chinese are given in Table 3 and Table 4, respectively.",
        "In which, Gold means the development dataset with gold manually annotation and Auto means the automatically generated annotations.",
        "Generally speaking, our system achieves acceptable mention detection performance, but further improvements are desired."
      ]
    },
    {
      "heading": "5.3 Evaluation on Coreference Resolution",
      "text": [
        "The performance on coreference resolution is next evaluated.",
        "The achieved performances on the development data (Gold/Auto) and test dataset on English and Chinese are given in Table 5 and Table 6, respectively.",
        "It is shown that the OF performance drops 0.0309(Gold) and 0.0112(Auto) from development dataset to test dataset on English, respectively.",
        "On the contrary, the OF performance increases 0.0096(Gold) and 0.0505(Auto) from development dataset to test dataset on Chinese, respectively.",
        "Compared with the performance reported in CoNLL2012 shared task, our system achieves a good result, ranked 3rd, on Chinese.",
        "The results show the effectiveness of our proposed system."
      ]
    },
    {
      "heading": "6 Conclusions",
      "text": [
        "This paper presents the HLT_HITSZ system for CoNLL2012 shared task.",
        "Generally speaking, this system uses a statistic-based classifier to handle short distance coreference resolution and uses a rule-based classifier to handle long distance cases.",
        "The incorporation of rule-based and statistic-based techniques is shown effective to improve the performance of coreference resolution.",
        "In our future work, more semantic and knowledge bases will be incorporated to improve coreference resolution in open track."
      ]
    },
    {
      "heading": "Acknowledgement",
      "text": []
    }
  ]
}
