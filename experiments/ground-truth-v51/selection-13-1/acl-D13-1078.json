{
  "info": {
    "authors": [
      "Steven Bethard"
    ],
    "book": "EMNLP",
    "id": "acl-D13-1078",
    "title": "A Synchronous Context Free Grammar for Time Normalization",
    "url": "https://aclweb.org/anthology/D13-1078",
    "year": 2013
  },
  "references": [
    "acl-N12-1049",
    "acl-S10-1010",
    "acl-S13-2001"
  ],
  "sections": [
    {
      "text": [
        "Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing, pages 821?826, Seattle, Washington, USA, 18-21 October 2013. c?2013 Association for Computational Linguistics A synchronous context free grammar for time normalization"
      ]
    },
    {
      "heading": "Abstract",
      "text": [
        "We present an approach to time normalization (e.g. the day before yesterday?2013-04-12) based on a synchronous context free grammar.",
        "Synchronous rules map the source language to formally defined operators for manipulating times (FINDENCLOSED, STARTATENDOF, etc.).",
        "Time expressions are then parsed using an extended CYK+ algorithm, and converted to a normalized form by applying the operators recursively.",
        "For evaluation, a small set of synchronous rules for English time expressions were developed.",
        "Our model outperforms HeidelTime, the best time normalization system in TempEval 2013, on four different time normalization corpora."
      ]
    },
    {
      "heading": "1 Introduction",
      "text": [
        "Time normalization is the task of converting a natural language expression of time into a formal representation of a time on a timeline.",
        "For example, the expression the day before yesterday would be normalized to the formal representation 2013-04-12 (assuming that today is 2013-04-14) in the ISO-TimeML representation language (Pustejovsky et al., 2010).",
        "Time normalization is a crucial part of almost any information extraction task that needs to place entities or events along a timeline.",
        "And research into methods for time normalization has been growing since the ACE1 and TempEval (Verhagen et al., 2010; UzZa-man et al., 2013) challenges began to include time normalization as a shared task.",
        "Most prior work on time normalization has taken a rule-based, string-to-string translation approach.",
        "That is, each word in a time expression is looked up in a normalization lexicon, and then rules map this sequence of lexical entries directly to the normalized form.",
        "HeidelTime (Stro?tgen and Gertz, 2012), which had the highest performance in TempEval 2010 and 2013, and TIMEN (Llorens et al., 2012), which reported slightly higher performance in its own experiments, both follow this approach.",
        "A drawback of this approach though is that there is no nesting of rules: for example, in HeidelTime the rules for yesterday and the day before yesterday are completely separate, despite the compositional nature of the latter.",
        "A notable exception to the string-to-string approach is the work of (Angeli et al., 2012).",
        "They define a target grammar of typed pre-terminals, such as YESTERDAY (a SEQUENCE) or DAY (a DURATION), and compositional operations, such as SHIFTLEFT (a (RANGE, DURATION) ?",
        "RANGE).",
        "They apply an expectation-maximization approach to learn how words align to elements of the target grammar, and achieve performance close to that of the rule-based systems.",
        "However, their grammar does not allow for non-binary or partially lexicalized rules (e.g. SEQUENCE ?",
        "DURATION before SEQUENCE would be impossible), and some of their primitive elements could naturally be expressed using other primitives (e.g.",
        "YESTERDAY as SHIFTLEFT(TODAY, 1 DAY)).",
        "We present a synchronous grammar for time normalization that addresses these shortcomings.",
        "We first define a grammar of formal operations over temporal elements.",
        "We then develop synchronous rules that map time expression words to temporal opera",
        "non-terminals indicate the alignment between the source and target parses.",
        "tors, and perform normalization by parsing with an extended CYK+ parsing algorithm.",
        "We evaluate this approach to time normalization on the TimeBank, AQUAINT, Timen and TempEval 2013 corpora."
      ]
    },
    {
      "heading": "2 Synchronous grammars",
      "text": [
        "Our time grammar is based on the synchronous context free grammar formalism.",
        "Synchronous grammars allow two trees, one in the source language and one in the target language, to be constructed simultaneously.",
        "A synchronous context free grammar has rules of the form X ?",
        "(S,T, A), where X is a non-terminal, S is the sequence of terminals and non-terminals that X expands to in the source language, T is the sequence of terminals and non-terminals that X expands to in the target language, and A is the alignment between the non-terminals of S and T (which must be the same).",
        "For time normalization, the source side is the natural language text, and the target side is a formal grammar of temporal operators.",
        "Figure 1 shows a synchronous parse of the week of March 6 2.",
        "The left side is the source side (an English expression), the right side is the target side (a temporal operator expression), and the alignment is shown via subscripts.",
        "2Figure 1 corresponds to an interpretation along the lines of the week of the last March 6.",
        "The full grammar developed in this article would also produce an interpretation corresponding to the week of the next March 6, since the phrase is ambiguous."
      ]
    },
    {
      "heading": "3 Target time grammar",
      "text": [
        "The right side of Figure 1 shows an example of our target formal representation: FINDENCLOSING( FINDEARLIER(PRESENT, MONTHOFYEAR?3, DAYOFMONTH?6), WEEKS).",
        "Each terminal in the parse is either a numeric value or an operator like FINDENCLOSING, WEEKS or MONTHOFYEAR.",
        "Each non-terminal combines terminals or non-terminals to create a [TIMESPAN], [PERIOD], [FIELD], [UNIT] or [INT].",
        "The list of rules allowed by our target grammar (the right-hand side of our synchronous grammar) is given in Table 1.",
        "Each of the target operators defines a procedure for creating a temporal object from others.",
        "For example, FINDENCLOSING takes a [TIMESPAN] and a [UNIT] and expands the start and end of the time span to fill a period of one unit.",
        "This could be used, for example, to define today as FINDENCLOSING(PRESENT, DAYS), where the PRESENT, which is instantaneous, is expanded out to the enclosing day.",
        "Note that we define things like today and yesterday in terms of primitive operations, rather than making them primitives themselves as in (Angeli et al., 2012).",
        "The left side of Figure 1 shows the synchronous parse of the source language.",
        "Note that each of the non-terminals is aligned (shown as a subscript) with a non-terminal in the target parse3, while terminals are not aligned and may freely appear or disappear 3We actually allow a slightly asynchronous grammar, where a non-terminal may be used 0 or more times on the target side.",
        "is any of the TIMEX3 ?mod?",
        "values defined in TimeML.",
        "from the source to the target.",
        "Each non-terminal thus corresponds to a synchronous grammar rule that describes how a source expression should be translated into the target time grammar.",
        "For example the root nodes correspond to an application of the following full synchronous rule: [TIMESPAN]?",
        "source: [UNIT] of [TIMESPAN] target: FINDENCLOSING [TIMESPAN] [UNIT]"
      ]
    },
    {
      "heading": "4 Parsing algorithm",
      "text": [
        "Parsing with a synchronous context free grammar is much the same as parsing with just the source side of the grammar.",
        "Only a small amount of bookkeeping is necessary to allow the generation of the target parse once the source parse is complete.",
        "We can therefore apply standard parsing algorithms to this task.",
        "However, we have some additional grammar requirements.",
        "As shown in Figure 1, we allow rules that expand into more than two terminals or non-terminals, the mixing of terminals and non-terminals in a production, a special [NIL] non-terminal for the ignoring of words, and a special [INT] non-terminal that can match ranges of integers and does not require all possible integers to be manually listed in the grammar.",
        "This means that we can't directly use CYK parsing or even CYK+ parsing (Chappelier and Rajman, 1998), which allows rules that expand into more than two terminals or non-terminals, but does not meet our other requirements.",
        "Algorithm 1 shows our extended version of CYK+ parsing.",
        "As with standard CYK+ parsing, two charts are filled, one for rules that have been completed (C) and one for rules that have been only partially advanced (P ).",
        "All parses covering 1 terminal are completed first, then these are used to complete parses covering 2 terminals, etc.",
        "until all parses covering all terminals are complete.",
        "Our extensions to the standard CYK+ parsing are as follows.",
        "To handle integers, we modify the initialization to generate new rules on the fly for any numeric terminals that fit the range of an [INT:X-Y] non-terminal in the grammar (starts at line 5).",
        "To allow mixing of terminals and non-terminals, we extend the initialization step to also produce partial parses (line 17), and extend the parse advancement step to allow advancing rules with terminals (starting at line 23).",
        "Finally, to handle [NIL] rules, which consume tokens but are not included in the final parse, we add a step where rules are allowed to advance, unchanged, past a [NIL] rule (starting at line 35)."
      ]
    },
    {
      "heading": "5 Parsing example",
      "text": [
        "As an example, consider parsing the week of March",
        "Next, the algorithm starts working on parses that span 1 token.",
        "It can start two partial parses, using the [UNIT] at C(1,1), and using the [MONTH] at C(1,3):",
        "Algorithm 1 CYK+ parsing, extended for partially lexicalized rules, [Nil] rules and numbers Require: G a set of rules, w a sequence of tokens",
        "1: function PARSE(G,w) 2: C ?",
        "a new |w|+ 1 by |w |matrix 3: P ?",
        "a new |w|+ 1 by |w |matrix 4: // Generate rules on the fly for numeric tokens 5: for i?",
        "0 .",
        ".",
        ".",
        "(|w |?",
        "1) do 6: if ISNUMBER(wi) then 7: for all [INT:x-y] ?",
        "non-terminals of G do 8: if x ?",
        "TONUMBER(wi) ?",
        "y then 9: C(1,i) ?= [INT:x-y]?",
        "wi 10: // Start any rules that begin with terminals 11: for i?",
        "0 .",
        ".",
        ".",
        "(|w |?",
        "1) do 12: for all X?",
        "??",
        "?",
        "G do 13: if ?j |?",
        "= wi:j ?",
        "?ISTERMINAL(?0) then 14: if ?",
        "= then 15: C(|wi:j |,i) ?= X?",
        "wi:j?",
        "16: else 17: P(|wi:j |,i) ?= (|wi:j |,X?",
        "wi:j?)",
        "18: for n?",
        "1 .",
        ".",
        ".",
        "|w|; i?",
        "0 .",
        ".",
        ".",
        "(|w |?",
        "n) do 19: // Find all parses of size n starting at i 20: form?",
        "1 .",
        ".",
        ".",
        "n do 21: for all (p,X?",
        "?)",
        "?",
        "P(m,i) do 22: // Advance partial parses using terminals 23: if wi+m:i+n = ?p:p+n?m then 24: if ?p+n?m:|?",
        "|= then 25: C(n,i) ?= X?",
        "?",
        "26: else 27: P(n,i) ?= (p+ n?m,X?",
        "?)",
        "28: // Advance partial parses using completes 29: for all ?p ?",
        "?",
        "?",
        "C(n?m,i+m) do 30: if |?",
        "|= p+ 1 then 31: C(n,i) ?= X?",
        "?",
        "32: else 33: P(n,i) ?= (p+ 1,X?",
        "?)",
        "34: // Advance complete parses past [Nil] parses 35: for all X?",
        "?",
        "?",
        "C(m,i) do 36: for all Y?",
        "?",
        "?",
        "C(n?m,i+m) do 37: if X 6= Nil ?",
        "Y = Nil then 38: C(n,i) ?= X?",
        "?",
        "39: else if X = Nil ?",
        "Y 6= Nil then 40: C(n,i) ?= Y?",
        "?",
        "41: // Start any rules that begin with a complete parse 42: for all X?",
        "?",
        "?",
        "C(n,i) do 43: for all Y?",
        "X?",
        "?",
        "C(n,i) do 44: if ?",
        "= then 45: C(n,i) ?= Y?",
        "X?",
        "46: else 47: P(n,i) ?= (1,Y?",
        "X?)",
        "48: return C(|w|,0)",
        "(The ?",
        "is the visual equivalent of the first element in the partial parse tuples of Algorithm 1, which marks parsing progress.)",
        "And given the [INT:1-31] atC(1,4) the algorithm can make a complete size 1 parse:",
        "The algorithm then moves on to create parses that span 2 tokens.",
        "The special handling of [NIL] allows the [UNIT] at C(1,1) to absorb the [NIL] at C(1,0): C(2,0) ?= [UNIT] ?",
        "week This [UNIT] then allows the start of a partial parse:",
        "The partial parse at P(1,1) can be advanced using of at position 2, creating another 2 token partial parse:",
        "The partial parse at P(1,3) can be advanced using the [DAY] at C(1,4), completing the 2 token parse: C(2,3) ?= [FIELD] ?",
        "[MONTH][DAY] This [FIELD] allows completion of a 2 token parse: C(2,3) ?= [TIMESPAN] ?",
        "[FIELD] The algorithm then moves on to 3 token parses.",
        "Only one is possible: the partial parse at P(2,0) can be advanced using the of at position 2, yielding:",
        "The algorithm moves on to 4 token parses, finding that the partial parse at P(2,1) can be advanced using the [TIMESPAN] at C(2,3), completing the parse: C(4,1) ?= [TIMESPAN] ?",
        "[UNIT] of [TIMESPAN] Finally, the algorithm moves on to 5 token parses, where (1) the special handling of [NIL] allows the partial parse at C(4,1) to consume the [NIL] at C(1,0) and (2) the partial parse at P(3,0) can be advanced using the [TIMESPAN] at C(2,3).",
        "Both of these yield: C(5,0) ?= [TIMESPAN] ?",
        "[UNIT] of [TIMESPAN] The complete parses in C(5,0) are then deterministically translated into target side parses using the alignments in the rules of the synchronous grammar."
      ]
    },
    {
      "heading": "6 Evaluation",
      "text": [
        "Using our synchronous grammar formalism for time normalization, we manually developed a grammar for English time expressions.",
        "Following the lead of TIMEN and HeidelTime, we developed our grammar by inspecting examples from the AQUAINT4 and",
        "synchronous context free grammar (SCFG) on each evaluation corpus.",
        "(N is the number of time expressions.)",
        "TimeBank (Pustejovsky et al., 2003) corpora.",
        "The resulting grammar has 354 rules, 192 of which are only lexical, e.g., [UNIT]?",
        "(seconds, SECONDS).",
        "Our grammar produces multiple parses when the input is ambiguous.",
        "For example, the expression Monday could mean either the previous Monday or the following Monday, and the expression the day could refer either to a period of one day, or to a specific day in time, e.g. 2013-04-14.",
        "For such expressions, our grammar produces both parses.",
        "To choose between the two, we employ a very simple set of heuristics: (1) prefer [TIMESPAN] to [PERIOD], (2) prefer an earlier [TIMESPAN] to a later one and (3) prefer a [TIMESPAN] with QUARTERS granularity if the anchor time is also in QUARTERS (this is a common rule in TimeBank annotations).",
        "We evaluate on the AQUAINT corpus, the TimeBank corpus, the Timen corpus (Llorens et al., 2012) and the TempEval 2013 test set (UzZaman et al., 2013)5.",
        "We compare to two6 state-of-the-art systems: TIMEN and HeidelTime.",
        "Table 2 shows the results.",
        "Our synchronous grammar approach outperformed HeidelTime on all corpora, both on the training corpora (AQUAINT and TimeBank) and on the test corpora (Timen and TempEval 2013).",
        "Both our model and HeidelTime outperformed TIMEN on all corpora except for the Timen corpus.",
        "To better understand the issues in the Timen corpus, we manually inspected the 33 time expressions that TIMEN normalized correctly and our approach 5We evaluate normalization accuracy over all time expressions, not the F1 of both finding and normalizing expressions, so the numbers here are not directly comparable to those reported by the TempEval 2013 evaluation.",
        "6Though its performance was slightly lower than HeidelTime, we also intended to compare to the (Angeli et al., 2012) system.",
        "Its authors graciously helped us get the code running, but to date all models we were able to train performed substantially worse than their reported results, so we do not compare to them here.",
        "normalized incorrectly.",
        "4 errors were places where our heuristic was wrong (e.g. we chose the earlier, not the later Sept. 22).",
        "6 errors were coverage problems of our grammar, e.g. not handling season, every time or long ago.",
        "2 errors were actually human annotation errors (several years ago was annotated as PASTREF and daily was annotated as XXXX-XXXX, while the guidelines say these should be PXY and P1D respectively).",
        "The remaining 21 errors were from two new normalization forms not present at all in the training data: 19 instances of THH:MM:SS (times were always YYYY-MM-DDTHH:MM:SS in the training data) and 2 instances of BCYYYY (years were always YYYY in the training data)."
      ]
    },
    {
      "heading": "7 Discussion",
      "text": [
        "Our synchronous grammar approach to time normalization, which handles recursive structures better than existing string-to-string approaches and handles a wider variety of grammars than existing parsing approaches, outperforms the HeidelTime system on four evaluation corpora and outperforms the TIMEN system on three of the four corpora.",
        "Our time normalization code and models are freely available.",
        "The source code and English grammar are hosted at https://github.com/ bethard/timenorm, and official releases are published to Maven Central (group=info.bethard, artifact=timenorm).",
        "In future work, we plan to replace the heuristic for selecting between ambiguous parses with a more principled approach.",
        "It would be a simple extension to support a probabilistic grammar, as in (Angeli et al., 2012).",
        "But given an expression like Monday, it would still be impossible to decide whether it refers to the future or the past, since the surrounding context, e.g. tense of the governing verb, is needed for such a judgment.",
        "A more promising approach would be to train a classifier that selects between the ambiguous parses based on features of the surrounding context."
      ]
    },
    {
      "heading": "Acknowledgements",
      "text": [
        "The project described was supported in part by Grant Number R01LM010090 from the National Library Of Medicine.",
        "The content is solely the responsibility of the authors and does not necessarily represent the official views of the National Library of Medicine or the National Institutes of Health."
      ]
    }
  ]
}
