{
  "info": {
    "authors": [
      "David Chiang",
      "Jacob Andreas",
      "Daniel Bauer",
      "Karl Moritz Hermann",
      "Bevan Jones",
      "Kevin Knight"
    ],
    "book": "ACL",
    "id": "acl-P13-1091",
    "title": "Parsing Graphs with Hyperedge Replacement Grammars",
    "url": "https://aclweb.org/anthology/P13-1091",
    "year": 2013
  },
  "references": [
    "acl-J11-1008"
  ],
  "sections": [
    {
      "heading": "Abstract",
      "text": [
        "Hyperedge replacement grammar (HRG) is a formalism for generating and transforming graphs that has potential applications in natural language understanding and generation.",
        "A recognition algorithm due to Lautemann is known to be polynomial-time for graphs that are connected and of bounded degree.",
        "We present a more precise characterization of the algorithm's complexity, an optimization analogous to binarization of context-free grammars, and some important implementation details, resulting in an algorithm that is practical for natural-language applications.",
        "The algorithm is part of Boli-nas, a new software toolkit for HRG processing."
      ]
    },
    {
      "heading": "1 Introduction",
      "text": [
        "Hyperedge replacement grammar (HRG) is a context-free rewriting formalism for generating graphs (Drewes et al., 1997), and its synchronous counterpart can be used for transforming graphs to/from other graphs or trees.",
        "As such, it has great potential for applications in natural language understanding and generation, and semantics-based machine translation (Jones et al., 2012).",
        "Figure 1 shows some examples of graphs for natural-language semantics.",
        "A polynomial-time recognition algorithm for HRGs was described by Lautemann (1990), building on the work of Rozenberg and Welzl (1986) on boundary node label controlled grammars, and others have presented polynomial-time algorithms as well (Mazanek and Minas, 2008; Moot, 2008).",
        "Although Lautemann's algorithm is correct and tractable, its presentation is prefaced with the remark: ?As we are only interested in distinguishing polynomial time from non-polynomial time, the analysis will be rather crude, and implementation details will be explicated as little as possible.?",
        "Indeed, the key step of the algorithm, which matches a rule against the input graph, is described at a very high level, so that it is not obvious (for a non-expert in graph algorithms) how to implement it.",
        "More importantly, this step as described leads to a time complexity that is polynomial, but potentially of very high degree.",
        "In this paper, we describe in detail a more efficient version of this algorithm and its implementation.",
        "We give a more precise complexity analysis in terms of the grammar and the size and maximum degree of the input graph, and we show how to optimize it by a process analogous to binarization of CFGs, following Gildea (2011).",
        "The resulting algorithm is practical and is implemented as part of the open-source Bolinas toolkit for hy-peredge replacement grammars."
      ]
    },
    {
      "heading": "2 Hyperedge replacement grammars",
      "text": [
        "We give a short example of how HRG works, followed by formal definitions."
      ]
    },
    {
      "heading": "2.1 Example",
      "text": [
        "Consider a weighted graph language involving just two types of semantic frames (want and believe), two types of entities (boy and girl), and two roles (arg0 and arg1).",
        "Figure 1 shows a few graphs from this language.",
        "Figure 2 shows how to derive one of these graphs using an HRG.",
        "The derivation starts with a single edge labeled with the nonterminal symbol S .",
        "The first rewriting step replaces this edge with a subgraph, which we might read as ?The",
        "representing the meanings of (clockwise from upper left): ?The girl wants the boy,?",
        "?The boy is believed,?",
        "and ?The boy wants the girl to believe that he wants her.?",
        "boy wants something (X) involving himself.?",
        "The second rewriting step replaces the X edge with another subgraph, which we might read as ?The boy wants the girl to believe something (Y) involving both of them.?",
        "The derivation continues with a third rewriting step, after which there are no more nonterminal-labeled edges."
      ]
    },
    {
      "heading": "2.2 Definitions",
      "text": [
        "The graphs we use in this paper have edge labels, but no node labels; while node labels are intuitive for many graphs in NLP, using both node and edge labels complicates the definition of hyper-edge grammar and algorithms.",
        "All of our graphs are directed (ordered), as the purpose of most graph structures in NLP is to model dependencies between entities.",
        "Definition 1.",
        "An edge-labeled, ordered hyper-graph is a tuple H = ?V, E, ?",
        "?, where ?",
        "V is a finite set of nodes ?",
        "E ?",
        "V+ is a finite set of hyperedges, each of which connects one or more distinct nodes ?",
        "?",
        ": E ?",
        "C assigns a label (drawn from the finite set C) to each edge.",
        "For brevity we use the terms graph and hyper-graph interchangeably, and similarly for edge and hyperedge.",
        "In the definition of HRGs, we will use the notion of hypergraph fragments, which are the elementary structures that the grammar assembles into hypergraphs.",
        "ternal nodes.",
        "The function of graph fragments in HRG is analogous to the right-hand sides of CFG rules and to elementary trees in tree adjoining grammars (Joshi and Schabes, 1997).",
        "The external nodes indicate how to integrate a graph into another graph during a derivation, and are analogous to foot nodes.",
        "In diagrams, we draw them with a",
        "We now describe the HRG rewriting mechanism.",
        "Definition 4.",
        "Given a HRG G, we define the relation H ?G H?",
        "(or, H?",
        "is derived from H in one step) as follows.",
        "Let e = (v1 ?",
        "?",
        "?",
        "vk) be an edge in H with label A.",
        "Let (A?",
        "R) be a production ofG, where R has external nodes XR = (u1 ?",
        "?",
        "?",
        "uk).",
        "Then we write H ?G H?",
        "if H?",
        "is the graph formed by removing e from H, making an isomorphic copy of R, and identifying vi with (the copy of) ui for",
        "Let H ?",
        "?G H?",
        "(or, H?",
        "is derived from H) be thereflexive, transitive closure of?G.",
        "The graph language of a grammar G is the (possibly infinite) set of graphs H that have no edges with nonterminal labels such that S ?",
        "?G H. When a HRG rule (A ?",
        "R) is applied to an edge e, the mapping of external nodes in R to the",
        "boy wants the girl to believe that he wants her.?",
        "nodes of e is implied by the ordering of nodes in e and XR.",
        "When writing grammar rules, we make this ordering explicit by writing the left hand side of a rule as an edge and indexing the external nodes of R on both sides, as shown in Figure 2.",
        "HRG derivations are context-free in the sense that the applicability of each production depends on the nonterminal label of the replaced edge only.",
        "This allows us to represent a derivation as a derivation tree, and sets of derivations of a graph as a derivation forest (which can in turn represented as hypergraphs).",
        "Thus we can apply many of the methods developed for other context free grammars.",
        "For example, it is easy to define weighted and synchronous versions of HRGs.",
        "Definition 5.",
        "If K is a semiring, a K-weighted HRG is a tuple G = ?N,T, P, S , ?",
        "?, where ?N, T, P, S ?",
        "is a HRG and ?",
        ": P ?",
        "K assigns a weight in K to each production.",
        "The weight of a derivation ofG is the product of the weights of the productions used in the derivation.",
        "We defer a definition of synchronous HRGs until Section 4, where they are discussed in detail."
      ]
    },
    {
      "heading": "3 Parsing",
      "text": [
        "Lautemann's recognition algorithm for HRGs is a generalization of the CKY algorithm for CFGs.",
        "Its key step is the matching of a rule against the input graph, analogous to the concatenation of two spans in CKY.",
        "The original description leaves open how this matching is done, and because it tries to match the whole rule at once, it has asymptotic complexity exponential in the number of nonterminal edges.",
        "In this section, we present a refinement that makes the rule-matching procedure explicit, and because it matches rules little by little, similarly to binarization of CFG rules, it does so more efficiently than the original.",
        "Let H be the input graph.",
        "Let n be the number of nodes in H, and d be the maximum degree of any node.",
        "Let G be a HRG.",
        "For simplicity, we assume that the right-hand sides of rules are connected.",
        "This restriction entails that each graph generated by G is connected; therefore, we assume that H is connected as well.",
        "Finally, let m be an arbitrary node of H called the marker node, whose usage will become clear below.1"
      ]
    },
    {
      "heading": "3.1 Representing subgraphs",
      "text": [
        "Just as CKY deals with substrings (i, j] of the input, the HRG parsing algorithm deals with edge-induced subgraphs I of the input.",
        "An edge-induced subgraph of H = ?V, E, ??",
        "is, for some",
        "subset E?",
        "?",
        "E, the smallest subgraph containing all edges in E?.",
        "From now on, we will assume that all subgraphs are edge-induced subgraphs.",
        "In CKY, the two endpoints i and j completely specify the recognized part of the input, wi+1 ?",
        "?",
        "?w j.",
        "Likewise, we do not need to store all of I explicitly.",
        "Definition 6.",
        "Let I be a subgraph of H. A boundary node of I is a node in I which is either a node with an edge in H\\I or an external node.",
        "A boundary edge of I is an edge in I which has a boundary node as an endpoint.",
        "The boundary representation of I is the tuple ?bn(I), be(I, v),m ?",
        "I?, where ?",
        "bn(I) is the set of boundary nodes of I ?",
        "be(I, v) be the set of boundary edges of v in I ?",
        "(m ?",
        "I) is a flag indicating whether the marker node is in I.",
        "The boundary representation of I suffices to specify I compactly.",
        "Proposition 1.",
        "If I and I?",
        "are two subgraphs of H with the same boundary representation, then I = I?.",
        "Proof.",
        "Case 1: bn(I) is empty.",
        "If m ?",
        "I and m ?",
        "I?, then all edges of H must belong to both I and I?, that is, I = I?",
        "= H. Otherwise, if m < I and m < I?, then no edges can belong to either I or I?, that is,",
        "without loss of generality, suppose that there is an edge e that is in I \\ I?.",
        "Let ?",
        "be the shortest path (ignoring edge direction) that begins with e and ends with a boundary node.",
        "All the edges along ?",
        "must be in I \\ I?, or else there would be a boundary node in the middle of ?, and ?",
        "would not be the shortest path from e to a boundary node.",
        "Then, in particular, the last edge of ?must be in I \\ I?.",
        "Since it has a boundary node as an endpoint, it must be a boundary edge of I, but cannot be a boundary edge of I?, which is a contradiction.",
        "If two subgraphs are disjoint, we can use their boundary representations to compute the boundary representation of their union.",
        "Proposition 2.",
        "Let I and J be two subgraphs whose edges are disjoint.",
        "A node v is a boundary",
        "node of I ?",
        "J iff one of the following holds: (i) v is a boundary node of one subgraph but not the other (ii) v is a boundary node of both subgraphs, and has an edge which is not a boundary edge of either.",
        "An edge is a boundary edge of I ?",
        "J iff it has a boundary node of I ?",
        "J as an endpoint and is a boundary edge of I or J.",
        "Proof.",
        "(?)",
        "v has an edge in either I or J and an edge e outside both I and J.",
        "Therefore it must be a boundary node of either I or J.",
        "Moreover, e is not a boundary edge of either, satisfying condition (ii).",
        "(?)",
        "Case (i): without loss of generality, assume",
        "v is a boundary node of I.",
        "It has an edge e in I, and therefore in I ?",
        "J, and an edge e?",
        "outside I, which must also be outside J.",
        "For e < J (because I and J are disjoint), and if e?",
        "?",
        "J, then v would be a boundary node of J.",
        "Therefore, e?",
        "< I ?",
        "J, so v is a boundary node of I ?",
        "J.",
        "Case (ii): v has an edge in I and therefore I ?",
        "J, and an edge not in either I or J.",
        "This result leads to Algorithm 1, which runs in time linear in the number of boundary nodes.",
        "In practice, for small subgraphs, it may be more efficient simply to use an explicit set of edges instead of the boundary representation.",
        "For the GeoQuery corpus (Tang and Mooney, 2001), whose graphs are only 7.4 nodes on average, we generally find this to be the case."
      ]
    },
    {
      "heading": "3.2 Treewidth",
      "text": [
        "Lautemann's algorithm tries to match a rule against the input graph all at once.",
        "But we can optimize the algorithm by matching a rule incrementally.",
        "This is analogous to the rank-minimization problem for linear context-free rewriting systems.",
        "Gildea has shown that this problem is related to",
        "the notion of treewidth (Gildea, 2011), which we review briefly here.",
        "Definition 7.",
        "A tree decomposition of a graph H = ?V, E?",
        "is a tree T , each of whose nodes ?",
        "is associated with sets V?",
        "?",
        "V and E?",
        "?",
        "E, with the following properties:",
        "1.",
        "Vertex cover: For each v ?",
        "V , there is a node ?",
        "?",
        "T such that v ?",
        "V?.",
        "2.",
        "Edge cover: For each e = (v1 ?",
        "?",
        "?",
        "vk) ?",
        "E, there is exactly one node ?",
        "?",
        "T such that e ?",
        "E?.",
        "We say that ?",
        "introduces e. Moreover, v1, .",
        ".",
        ".",
        ", vk ?",
        "V?.",
        "3.",
        "Running intersection: For each v ?",
        "V , the set {?",
        "?",
        "T |v ?",
        "V?}",
        "is connected.",
        "The width of T is max |V?",
        "|?",
        "1.",
        "The treewidth of H is the minimal width of any tree decomposition of H. A tree decomposition of a graph fragment ?V, E, X?",
        "is a tree decomposition of ?V, E?",
        "that has the additional property that all the external nodes belong to V?",
        "for some ?.",
        "(Without loss of generality, we assume that ?",
        "is the root.)",
        "For example, Figure 3b shows a graph, and Figure 3c shows a tree decomposition.",
        "This decomposition has width three, because its largest node has 4 elements.",
        "In general, a tree has width one, and it can be shown that a graph has treewidth at most two iff it does not have the following graph as a minor (Bodlaender, 1997):",
        "Finding a tree decomposition with minimal width is in general NP-hard (Arnborg et al., 1987).",
        "However, we find that for the graphs we are interested in in NLP applications, even a na?",
        "?ve algorithm gives tree decompositions of low width in practice: simply perform a depth-first traversal of the edges of the graph, forming a tree T .",
        "Then, augment the V?",
        "as necessary to satisfy the running intersection property.",
        "As a test, we extracted rules from the Geo-Query corpus (Tang and Mooney, 2001) using the SynSem algorithm (Jones et al., 2012), and computed tree decompositions exactly using a branch-and-bound method (Gogate and Dechter, 2004) and this approximate method.",
        "Table 1 shows that, in practice, treewidths are not very high even when computed only approximately.",
        "method mean max",
        "Any tree decomposition can be converted into one which is nice in the following sense (simplified from Cygan et al. (2011)).",
        "Each tree node ?",
        "must be one of:",
        "?",
        "A leaf node, such that V?",
        "= ?.",
        "?",
        "A unary node, which introduces exactly one edge e. ?",
        "A binary node, which introduces no edges.",
        "The example decomposition in Figure 3c is nice.",
        "This canonical form simplifies the operation of the parser described in the following section.",
        "Let G be a HRG.",
        "For each production (A ?",
        "R) ?",
        "G, find a nice tree decomposition of R and call it TR.",
        "The treewidth of G is the maximum",
        "treewidth of any right-hand side in G. The basic idea of the recognition algorithm is to recognize the right-hand side of each rule incrementally by working bottom-up on its tree decomposition.",
        "The properties of tree decomposition allow us to limit the number of boundary nodes of the partially-recognized rule.",
        "More formally, let RD?",
        "be the subgraph of R induced by the union of E??",
        "for all ??",
        "equal to or dominated by ?.",
        "Then we can show the following.",
        "Proposition 3.",
        "Let R be a graph fragment, and assume a tree decomposition of R. All the boundary nodes of RD?",
        "belong to V?",
        "?",
        "Vparent(?).",
        "Proof.",
        "Let v be a boundary node of RD?.",
        "Node v must have an edge in RD?",
        "and therefore in R??",
        "for some ??",
        "dominated by or equal to ?.",
        "Case 1: v is an external node.",
        "Since the root node contains all the external nodes, by the running intersection property, both V?",
        "and Vparent(?)",
        "must contain v as well.",
        "Case 2: v has an edge not in RD?.",
        "Therefore there must be a tree node not dominated by or equal to ?",
        "that contains this edge, and therefore v. So by the running intersection property, ?",
        "and its parent must contain v as well.",
        "This result, in turn, will allow us to bound the complexity of the parsing algorithm in terms of the treewidth of G."
      ]
    },
    {
      "heading": "3.3 Inference rules",
      "text": [
        "We present the parsing algorithm as a deductive system (Shieber et al., 1995).",
        "The items have one of two forms.",
        "A passive item has the form [A, I, X], where X ?",
        "V+ is an explicit ordering of the boundary nodes of I.",
        "This means that we have recognized that A ?",
        "?G I.",
        "Thus, the goalitem is [S ,H, ?].",
        "An active item has the form [A?",
        "R, ?, I, ?",
        "], where ?",
        "(A?",
        "R) is a production of G ?",
        "?",
        "is a node of TR ?",
        "I is a subgraph of H ?",
        "?",
        "is a bijection between the boundary nodes of RD?",
        "and those of I.",
        "The parser must ensure that ?",
        "is a bijection when it creates a new item.",
        "Below, we use the notation {e 7?",
        "e?}",
        "or {e 7?",
        "X} for the mapping that sends each node of e to the corresponding node of e?",
        "or X.",
        "Passive items are generated by the following rule: ?",
        "Root [B?",
        "Q, ?, J, ?]",
        "[B, J, X] where ?",
        "is the root of TQ, and X j = ?",
        "(XQ, j).",
        "If we assume that the TR are nice, then the inference rules that generate active items follow the different types of nodes in a nice tree decomposition: ?",
        "Leaf [A?",
        "R, ?, ?, ?]",
        "where ?",
        "is a leaf node of TR.",
        "?",
        "(Unary) Nonterminal [A?",
        "R, ?1, I, ?]",
        "[B, J, X] [A?",
        "R, ?, I ?",
        "J, ?",
        "?",
        "{e 7?",
        "X}] where ?1 is the only child of ?, and e is introduced by ?",
        "and is labeled with nonterminal B. ?",
        "(Unary) Terminal [A?",
        "R, ?1, I, ?]",
        "[A?",
        "R, ?, I ?",
        "{e?",
        "}, ?",
        "?",
        "{e 7?",
        "e?}]",
        "where ?1 is the only child of ?, e is introduced by ?, and e and e?",
        "are both labeled with terminal a. ?",
        "Binary [A?",
        "R, ?1, I, ?1] [A?",
        "R, ?2, J, ?2] [A?",
        "R, ?, I ?",
        "J, ?1 ?",
        "?2] where ?1 and ?2 are the two children of ?.",
        "In the Nonterminal, Terminal, and Binary rules, we form unions of subgraphs and unions of mappings.",
        "When forming the union of two subgraphs, we require that the subgraphs be disjoint (however, see Section 3.4 below for a relaxation of this condition).",
        "When forming the union of two mappings, we require that the result be a bijection.",
        "If either of these conditions is not met, the inference rule cannot apply.",
        "For efficiency, it is important to index the items for fast access.",
        "For the Nonterminal inference rule, passive items [B, J, X] should be indexed by key ?B, |bn(J)|?, so that when the next item on the agenda is an active item [A ?",
        "R, ?1, I, ?",
        "], we know that all possible matching passive items are",
        "nition algorithm without the disjointness check.",
        "Using grammar (a), the recognition algorithm would incorrectly accept the graph (b) by assembling together the three overlapping fragments (c).",
        "under key ??",
        "(e), |e|?.",
        "Similarly, active items should be indexed by key ??",
        "(e), |e|?",
        "so that they can be found when the next item on the agenda is a passive item.",
        "For the Binary inference rule, active items should be indexed by their tree node (?1 or ?2).",
        "This procedure can easily be extended to produce a packed forest of all possible derivations of the input graph, representable as a hypergraph just as for other context-free rewriting formalisms.",
        "The Viterbi algorithm can then be applied to this representation to find the highest-probability derivation, or the Inside/Outside algorithm to set weights by Expectation-Maximization."
      ]
    },
    {
      "heading": "3.4 The disjointness check",
      "text": [
        "A successful proof using the inference rules above builds an HRG derivation (comprising all the rewrites used by the Nonterminal rule) which derives a graph H?, as well as a graph isomorphism ?",
        ": H?",
        "?",
        "H (the union of the mappings from all the items).",
        "During inference, whenever we form the union of two subgraphs, we require that the subgraphs be disjoint.",
        "This is a rather expensive operation: it can be done using only their boundary representations, but the best algorithm we are aware of is still quadratic in the number of boundary nodes.",
        "Is it possible to drop the disjointness check?",
        "If we did so, it would become possible for the algorithm to recognize the same part of H twice.",
        "For example, Figure 4 shows an example of a grammar and an input that would be incorrectly recognized.",
        "However, we can replace the disjointness check with a weaker and faster check such that any derivation that merges two non-disjoint subgraphs will ultimately fail, and therefore the derived graph H?",
        "is isomorphic to the input graph H?",
        "as desired.",
        "This weaker check is to require, when merging two subgraphs I and J, that:",
        "1.",
        "I and J have no boundary edges in common, and 2.",
        "If m belongs to both I and J, it must be a",
        "boundary node of both.",
        "Condition (1) is enough to guarantee that ?",
        "is locally one-to-one in the sense that for all v ?",
        "H?, ?",
        "restricted to v and its neighbors is one-to-one.",
        "This is easy to show by induction: if ?I : I?",
        "?",
        "H and ?J : J?",
        "?",
        "H are locally one-to-one, then ?I ?",
        "?J must also be, provided condition (1) is met.",
        "Intuitively, the consequence of this is that we can detect any place where ?",
        "changes (say) from being one-to-one to two-to-one.",
        "So if ?",
        "is two-to-one, then it must be two-to-one everywhere (as in the example of Figure 4).",
        "But condition (2) guarantees that ?",
        "maps only one node to the marker m. We can show this again by induction: if ?I and ?J each map only one node to m, then ?I?",
        "?J must map only one node to m, by a combination of condition (2) and the fact that the inference rules guarantee that ?I , ?J , and ?I ?",
        "?J are one-to-one on boundary nodes.",
        "Then we can show that, since m is recognized exactly once, the whole graph is also recognized exactly once.",
        "Proposition 4.",
        "If H and H?",
        "are connected graphs, ?",
        ": H?",
        "?",
        "H is locally one-to-one, and ?",
        "?1 is defined for some node of H, then ?",
        "is a bijection.",
        "Proof.",
        "Suppose that ?",
        "is not a bijection.",
        "Then there must be two nodes v?1, v?2 ?",
        "H?",
        "such that",
        "fined.2 Choose a path ?",
        "(ignoring edge direction) from v to m. Because ?",
        "is a local isomorphism, we can construct a path from v?1 to m?",
        "that mapsto ?.",
        "Similarly, we can construct a path from v?2to m?",
        "that maps to ?.",
        "Let u?",
        "be the first node that these two paths have in common.",
        "But u?",
        "must have two edges that map to the same edge, which is a contradiction.",
        "2If H were not connected, we would choose the marker in the same connected component as v."
      ]
    },
    {
      "heading": "3.5 Complexity",
      "text": [
        "The key to the efficiency of the algorithm is that the treewidth of G leads to a bound on the number of boundary nodes we must keep track of at any time.",
        "Let k be the treewidth of G. The time complexity of the algorithm is the number of ways of instantiating the inference rules.",
        "Each inference rule mentions only boundary nodes of RD?",
        "or RD?i , all of which belong to V?",
        "(by Proposition 3), so there are at most |V?",
        "|?",
        "k + 1 of them.",
        "In the Nonterminal and Binary inference rules, each boundary edge could belong to I or J or neither.",
        "Therefore, the number of possible instantiations of any inference rule is in O((3dn)k+1).",
        "The space complexity of the algorithm is the number of possible items.",
        "For each active item [A?",
        "R, ?, I, ?",
        "], every boundary node of RD?",
        "must belong to V??Vparent(?)",
        "(by Proposition 3).",
        "Therefore the number of boundary nodes is at most k+1 (but typically less), and the number of possible items is in O((2dn)k+1)."
      ]
    },
    {
      "heading": "4 Synchronous Parsing",
      "text": [
        "As mentioned in Section 2.2, because HRGs have context-free derivation trees, it is easy to define synchronous HRGs, which define mappings between languages of graphs.",
        "Definition 8.",
        "A synchronous hyperedge replacement grammar (SHRG) is a tuple G = ?N, T, T ?, P, S ?, where ?",
        "N is a finite set of nonterminal symbols ?",
        "T and T ?",
        "are finite sets of terminal symbols ?",
        "S ?",
        "N is the start symbol ?",
        "P is a finite set of productions of the form (A?",
        "?R,R?,??",
        "), where R is a graph fragment over N ?",
        "T and R?",
        "is a graph fragment over N ?",
        "T ?.",
        "The relation ?",
        "is a bijection linking nonterminal mentions in R and R?, such that if e ?",
        "e?, then they have the same label.",
        "We call R the source side and R?",
        "the target side.",
        "Some NLP applications (for example, word alignment) require synchronous parsing: given a pair of graphs, finding the derivation or forest of derivations that simultaneously generate both the source and target.",
        "The algorithm to do this is a straightforward generalization of the HRG parsing algorithm.",
        "For each rule (A?",
        "?R,R?,??",
        "), we construct a nice tree decomposition of R?R?",
        "such that: ?",
        "All the external nodes of both R and R?",
        "belong to V?",
        "for some ?.",
        "(Without loss of generality, assume that ?",
        "is the root.)",
        "?",
        "If e ?",
        "e?, then e and e?",
        "are introduced by the same tree node.",
        "In the synchronous parsing algorithm, passive items have the form [A, I, X, I?, X?]",
        "and active items have the form [A?",
        "R : R?, ?, I, ?, I?, ??].",
        "For brevity we omit a representation of all the inference rules, as they are very similar to their non-synchronous counterparts.",
        "The main difference is that in the Nonterminal rule, two linked edges are rewritten simultaneously: [A?",
        "R : R?, ?1, I, ?, I?, ??]",
        "[B, J, X, J?, X?]",
        "[A?",
        "R : R?, ?, I ?",
        "J, ?",
        "?",
        "{e j 7?",
        "X j}, I?",
        "?",
        "J?, ??",
        "?",
        "{e?j 7?",
        "X?j}] where ?1 is the only child of ?, e and e?",
        "are both introduced by ?",
        "and e ?",
        "e?, and both are labeled with nonterminal B.",
        "The complexity of the parsing algorithm is again in O((3dn)k+1), where k is now the maximum treewidth of the dependency graph as defined in this section.",
        "In general, this treewidth will be greater than the treewidth of either the source or target side on its own, so that synchronous parsing is generally slower than standard parsing."
      ]
    },
    {
      "heading": "5 Conclusion",
      "text": [
        "Although Lautemann's polynomial-time extension of CKY to HRGs has been known for some time, the desire to use graph grammars for large-scale NLP applications introduces some practical considerations not accounted for in Lautemann's original presentation.",
        "We have provided a detailed description of our refinement of his algorithm and its implementation.",
        "It runs in O((3dn)k+1) time and requires O((2dn)k+1) space, where n is the number of nodes in the input graph, d is its maximum degree, and k is the maximum treewidth of the rule right-hand sides in the grammar.",
        "We have also described how to extend this algorithm to synchronous parsing.",
        "The parsing algorithms described in this paper are implemented in the Bolinas toolkit.3"
      ]
    },
    {
      "heading": "Acknowledgements",
      "text": [
        "We would like to thank the anonymous reviewers for their helpful comments.",
        "This research was supported in part by ARO grant W911NF-10-1-0533."
      ]
    }
  ]
}
