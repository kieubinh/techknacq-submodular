{
  "info": {
    "authors": [
      "Goran Glavaš",
      "Jan Šnajder"
    ],
    "book": "ACL",
    "id": "acl-P13-2139",
    "title": "Recognizing Identical Events with Graph Kernels",
    "url": "https://aclweb.org/anthology/P13-2139",
    "year": 2013
  },
  "references": [
    "acl-C00-2137",
    "acl-D12-1045",
    "acl-H05-1016",
    "acl-L08-1554",
    "acl-P10-1143",
    "acl-S10-1010",
    "acl-W07-2014"
  ],
  "sections": [
    {
      "heading": "Abstract",
      "text": [
        "Identifying news stories that discuss the same real-world events is important for news tracking and retrieval.",
        "Most existing approaches rely on the traditional vector space model.",
        "We propose an approach for recognizing identical real-world events based on a structured, event-oriented document representation.",
        "We structure documents as graphs of event mentions and use graph kernels to measure the similarity between document pairs.",
        "Our experiments indicate that the proposed graph-based approach can outperform the traditional vector space model, and is especially suitable for distinguishing between topically similar, yet non-identical events."
      ]
    },
    {
      "heading": "1 Introduction",
      "text": [
        "News stories typically describe real-world events.",
        "Topic detection and tracking (TDT) aims to detect stories that discuss identical or directly related events, and track these stories as they evolve over time (Allan, 2002).",
        "Being able to identify the stories that describe the same real-world event is essential for TDT, and event-based information retrieval in general.",
        "In TDT, an event is defined as something happening in a certain place at a certain time (Yang et al., 1999), while a topic is defined as a set of news stories related by some seminal real-world event (Allan, 2002).",
        "To identify news stories on the same topic, most TDT approaches rely on traditional vector space models (Salton et al., 1975), as more sophisticated natural language processing techniques have not yet proven to be useful for this task.",
        "On the other hand, significant advances in sentence-level event extraction have been made over the last decade, in particular as the result of standardization efforts such as TimeML (Puste-jovsky et al., 2003a) and TimeBank (Pustejovsky et al., 2003b), as well as dedicated evaluation tasks (ACE, 2005; Verhagen et al., 2007; Verhagen et al., 2010).",
        "However, these two lines of research have largely remained isolated from one another.",
        "In this paper we bridge this gap and address the task of recognizing stories discussing identical events by considering structured representations from sentence-level events.",
        "More concretely, we structure news stories into event graphs built from individual event mentions extracted from text.",
        "To measure event-based similarity of news stories, we compare their event graphs using graph kernels (Borgwardt, 2007).",
        "We conduct preliminary experiments on two event-oriented tasks and show that the proposed approach can outperform traditional vector space model in recognizing identical real-world events.",
        "Moreover, we demonstrate that our approach is especially suitable for distinguishing between topically similar, yet non-identical real-world events."
      ]
    },
    {
      "heading": "2 Related Work",
      "text": [
        "The traditional vector space model (VSM) (Salton et al., 1975) computes the cosine between bag-of-words representations of documents.",
        "The VSM is at the core of most approaches that identify same-topic news stories (Hatzivassiloglou et al., 2000; Brants et al., 2003; Kumaran and Allan, 2005; Atkinson and Van der Goot, 2009).",
        "However, it has been observed that some word classes (e.g., named entities, noun phrases, collocations) have more significance than the others.",
        "Among them, named entities have been considered as particularly important, as they often identify the participants of an event.",
        "In view of this, Hatzivassiloglou et al. (2000) restrict the set of words to be used for document representation to words constituting noun phrases and named entities.",
        "Makkonen et",
        "al.",
        "(2004) divide document terms into four semantic categories (locations, temporal expressions, proper names, and general terms) and construct separate vector for each of them.",
        "Kumaran and Allan (2004) represent news stories with three different vectors, modeling all words, named-entity words, and all non-named-entity words occurring in documents.",
        "When available, recognition of identical events can rely on meta-information associated with news stories, such as document creation time (DCT).",
        "Atkinson and Van der Goot (2009) combine DCT with VSM, assuming that temporally distant news stories are unlikely to describe the same event.",
        "In research on event extraction, the task of recognizing identical events is known as event coreference resolution (Bejan and Harabagiu, 2010; Lee et al., 2012).",
        "There, however, the aim is to identify sentence-level event mentions referring to the same real-world events, and not stories that discuss identical events."
      ]
    },
    {
      "heading": "3 Kernels on Event Graphs",
      "text": [
        "To identify the news describing the same real-world event, we (1) structure event-oriented information from text into event graphs and (2) use graph kernels to measure the similarity between a pair of event graphs."
      ]
    },
    {
      "heading": "3.1 Event graphs",
      "text": [
        "An event graph is a vertex-and edge-labeled mixed graph in which vertices represent individual event mentions and edges represent temporal relations between event mentions.",
        "We adopt a generic representation of event mentions, as proposed by Glavas?",
        "and S?najder (2013): each mention consists of an anchor (a word that conveys the core meaning) and four types of arguments (agent, target, time, location).",
        "Furthermore, we consider four types of temporal relations between event mentions: before, after, overlap, and equal (Allen, 1983).",
        "As relations overlap and equal are symmetric, whereas before and after are not, an event graph may contain both directed and undirected edges.",
        "Formally, an event graph G is represented as a tuple G = (V,E,A,m, r), where V is the set of vertices, E is the set of undirected edges, A is the set of directed edges (arcs), m : V ?",
        "M is a bijection mapping the vertices to event mentions, and r : E ?",
        "R is the edge-labeling function, assigning temporal relations to edges (cf.",
        "Fig.",
        "1).",
        "The construction of an event graph from a news story involves the extraction of event mentions (anchors and arguments) and the extraction of temporal relations between mentions.",
        "We use a supervised model (with 80% F1 extraction performance) based on a rich set of features similar to those proposed by Bethard (2008) to extract event anchors.",
        "We then employ a robust, rule-based approach proposed by Glavas?",
        "and S?najder (2013) to extract generic event arguments.",
        "Finally, we employ a supervised model (60% micro-averaged F1 classification performance) with a rich set of features, similar to those proposed by Bethard (2008), to extract temporal relations between event mentions.",
        "A detailed description of the graph construction steps is outside the scope of this paper.",
        "To compute event graph kernels (cf.",
        "Section 3.2), we need to determine whether two event mentions co-refer.",
        "To resolve cross-document event coreference, we use the model proposed by Glavas?",
        "and S?najder (2013).",
        "The model determines coreference by comparing factual event anchors and arguments of four coarse-grained semantic types (agent, target, location, and time), and achieves an F-score of 67% (79% precision and 57% recall) on the cross-document mention pairs from the EventCorefBank dataset (Bejan and Harabagiu, 2008).",
        "In what follows, cf (m1,m2) denotes whether event mentions m1 and m2 co-refer (equals 1 if mentions co-refer, 0 otherwise)."
      ]
    },
    {
      "heading": "3.2 Graph kernels",
      "text": [
        "Graph kernels are fast polynomial alternatives to traditional graph comparison techniques (e.g., subgraph isomorphism), which provide an expressive measure of similarity between graphs (Borgwardt, 2007).",
        "We employ two different graph kernels: product graph kernel and weighted decomposition kernel.",
        "We chose these kernels because their general forms have intuitive interpretations for event matching.",
        "These particular kernels have shown to perform well on a number of tasks from chemoinformatics (Mahe?",
        "et al, 2005; Menchetti et al., 2005).",
        "Product graph kernel.",
        "A product graph kernel (PGK) counts the common walks between two input graphs (Ga?rtner et al., 2003).",
        "The graph product of two labeled graphs, G and G?",
        ", denoted",
        "where ?",
        "(v, v?)",
        "is a predicate that holds when vertices v and v?",
        "are identically labeled (Ham-mack et al., 2011).",
        "Given event graphs G = (V,E,A,m, r) and G?",
        "= (V ?, E?, A?,m?, r?",
        "), we consider the vertices to be identically labeled if the corresponding event mentions co-refer, i.e., ?",
        "(v, v?)",
        ".= cf (m(v),m?(v?)).",
        "The edge set of the graph product depends on the type of the product.",
        "We experiment with two different products: tensor product and conormal product.",
        "In the tensor product, an edge is introduced iff the corresponding edges exist in both input graphs and the labels of those edges match (i.e., both edges represent the same temporal relation).",
        "In the conormal product, an edge is introduced iff the corresponding edge exists in at least one input graph.",
        "Thus, a conormal product may compensate for omitted temporal relations in the input graphs.",
        "Let AP be the adjacency matrix of the graph productGP built from input graphsG andG?.",
        "The product graph kernel that counts common walks in G and G?",
        "can be computed efficiently as:",
        "when ?",
        "< 1/t , where t is the maximum degree of a vertex in the graph product GP .",
        "In our experiments, we set ?",
        "to 1/(t+ 1) .",
        "Weighted decomposition kernel.",
        "A weighted decomposition kernel (WDK) compares small graph parts, called selectors, being matched according to an equality predicate.",
        "The importance of the match is weighted by the similarity of the contexts in which the matched selectors occur.",
        "For a description of a general form of WDK, see Menchetti et al. (2005).",
        "Let S(G) be the set of all pairs (s, z), where s is the selector (subgraph of interest) and z is the context of s. We decompose event graphs into individual vertices, i.e., we define selectors to be the individual vertices.",
        "In this case, similarly as above, the equality predicate ?",
        "(v, v?)",
        "for two vertices v ?",
        "G and v?",
        "?",
        "G?",
        "holds if and only if the corresponding event mentions m(v) and m?(v?)",
        "co-refer.",
        "Using selectors that consist of more than one vertex would require a more complex and perhaps a less intuitive definition of the equality predicate ?.",
        "The selector context Zv of vertex v is a subgraph of G that contains v and all its immediate neighbors.",
        "In other words, we consider as context all event mentions that are in a direct temporal relation with the selected mention.",
        "WDK between event graphs G and G?",
        "is computed as:",
        "(2) where ?",
        "(Zv, Z ?v?)",
        "is the context kernel measuring the similarity between the context Zv of selector v ?",
        "G and the context Z ?v?",
        "of selector v?",
        "?",
        "G?.",
        "We compute the context kernel ?",
        "as the number of coreferent mention pairs found between the contexts, normalized by the context size:",
        "The intuition behind this is that a pair of coreferent mentions m(v) and m?(v?)",
        "should contribute to the overall event similarity according to the number of pairs of coreferent mentions,m(w) and m?(w?",
        "), that are in temporal relation with v and v?, respectively.",
        "Graph kernels example.",
        "As an example, consider the following two story snippets describing the same sets of real-world events: Story 1: A Cezanne masterpiece worth at least $131 million that was the yanked from the wall of a Zurich art gallery in 2008 has been recovered, Serbian police said today.",
        "Four arrests were made overnight in connection with the theft, which was one of the biggest art heists in recent history.",
        "Story 2: Serbian police have recovered a painting by French impressionist Paul Cezanne worth an estimated 100 million euros (131.7 million U.S. dollars), media reported on Thursday.",
        "The painting ?A boy in a red vest?",
        "was stolen in 2008 from a Zurich museum by masked perpetrators.",
        "Four members of an international crime ring were arrested Wednesday.",
        "The corresponding event graphs G and G?",
        "are shown in Fig. 1a and 1b, respectively, while their product is shown in Fig. 1c.",
        "There are three pairs of coreferent event mentions between G and G?",
        ": (yanked, stolen), (recovered, recovered), and (arrests, arrested).",
        "Accordingly, the product graph P has three nodes.",
        "The dashed edge between vertices (yanked, stolen) and (arrests, arrested) exists only in the conormal product graph.",
        "By substituting into (1) the adjacency matrix and maximum vertex degree of tensor product graph P , we obtain",
        "Similarly, for the conormal product graph P we obtain the conormal PGK score of KPG = 9.",
        "By substitutingG andG?",
        "into (2), we obtain the WDK score as:",
        "where VP contains pairs of coreferent event mentions: (yanked, stolen), (recovered, recovered), and (arrests, arrested)."
      ]
    },
    {
      "heading": "4 Experiments",
      "text": [
        "We conducted two preliminary experiments to investigate whether kernels on event graphs can be used to recognize identical events."
      ]
    },
    {
      "heading": "4.1 Task 1: Recognizing identical events",
      "text": [
        "Dataset.",
        "In the first experiment, we classify pairs of news stories as either describing identical real-world events or not.",
        "For this we need a collection of stories in which pairs of stories on identical events have been annotated as such.",
        "TDT corpora (Wayne, 2000) is not directly usable because it has no such annotations.",
        "We therefore decided to build a small annotated dataset.1 To this end, we use the news clusters of the EMM NewsBrief service (Steinberger et al., 2009).",
        "EMM clusters news stories from different sources using a document similarity score.",
        "We acquired 10 randomly chosen news clusters, manually inspected each of them, and retained in each cluster only the documents that describe the same real-world events.",
        "Additionally, we ensured that no documents from",
        "different clusters discuss the same event.",
        "To obtain the gold standard dataset, we build all pairs of documents.",
        "The final dataset consists of 64 documents in 10 clusters, with 195 news pairs from the same clusters (positive pairs) and 1821 news pairs from different clusters (negative pairs).",
        "We divide the dataset into a train and a test set (7:3 split ratio).",
        "Note that, although our dataset has ground-truth annotations, it is incomplete in the sense that some pairs of documents describing the same events, which were not recognized as such by the EMM, are not included.",
        "Furthermore, because EMM similarity score uses VSM cosine similarity as one of the features, VSM cosine similarity constitutes a competitive baseline on this dataset.",
        "Results.",
        "For each graph kernel and the VSM baseline, we determine the optimal threshold on the train set and evaluate the classification performance on the test set.",
        "The results are given in Table 1.",
        "The precision is consistently higher than recall for all kernels and the baseline.",
        "High precision is expected, as clusters represent topically dissimilar events.",
        "PGK models (both tensor and conormal) outperform the WDK model, indicating that common walks correlate better to event-based document similarity than common subgraphs.",
        "Individually, none of the graph kernels outperforms the baseline.",
        "To investigate whether the two kernels complement each other, we fed the",
        "individual kernel scores to an SVM model (with RBF kernel), along with additional graph-based features such as the number of nodes and the number of edges (SVM graph model).",
        "Finally, we combined the graph-based features with the VSM cosine similarity (SVM graph + VSM model).",
        "SVM graph model significantly (at p < 0.05, student's 2-tailed t-test) outperforms the individual kernel models and the baseline.",
        "The combined model",
        "outperforms the baseline and all kernel models."
      ]
    },
    {
      "heading": "4.2 Task 2: Event-based similarity ranking",
      "text": [
        "Dataset.",
        "In the second experiment we focus on the task of distinguishing between news stories that describe topically very similar, yet distinct events.",
        "For this purpose, we use a small set of event paraphrases, constructed as follows.",
        "We manually selected 10 news stories from EMM NewsBrief and altered each of them to obtain two meaning-preserving (event-preserving) and two meaning-changing (event-shifting) paraphrases.",
        "To obtain the meaning-preserving paraphrases, we use Google translate and round-trip translation via two pairs of arbitrarily chosen languages (Danish/Finnish and Croatian/Hungarian).",
        "Annotators manually corrected lexical and syntactic errors introduced by the round-trip translation.",
        "To obtain meaning-changing paraphrases, we asked human annotators to alter each story so that it topically resembles the original, but describes a different real-world event.",
        "The extent of the alteration was left to the annotators, i.e., no specific transformations were proposed.",
        "Paraphrase examples are given in Table 2.",
        "The final dataset consists of 60 news pairs: 30 positive and 30 negative.",
        "Results.",
        "For each method we ranked the pairs based on the assigned similarity scores.",
        "An ideal method would rank all positive pairs above all negative pairs.",
        "We evaluated the performance using Model R-prec.",
        "Avg.",
        "prec.",
        "two different rank evaluation metrics: R-precision (precision at rank 30, as there are 30 positive pairs) and average precision.",
        "The performance of graph kernel models and the VSM baseline is given in Table 3.",
        "We tested the significance of differences using stratified shuffling (Yeh, 2000).",
        "When considering average precision, all kernel models significantly (at p < 0.01) outperform the baseline.",
        "However, when considering R-precision, only the conormal PGK model significantly (at p < 0.05) outperforms the baseline.",
        "There is no statistical significance in performance differences between the considered kernel methods.",
        "Inspection of the rankings reveals that graph kernels assign very low scores to negative pairs, i.e., they distinguish well between textual representations of topically similar, but different real-world events."
      ]
    },
    {
      "heading": "5 Conclusion",
      "text": [
        "We proposed a novel approach for recognizing identical events that relies on structured, graph-based representations of events described in a document.",
        "We use graph kernels as an expressive framework for modeling the similarity between structured events.",
        "Preliminary results on two event-similarity tasks are encouraging, indicating that our approach can outperform traditional vector-space model, and is suitable for distinguishing between topically very similar events.",
        "Further improvements could be obtained by increasing the accuracy of event coreference resolution, which has a direct influence on graph kernels.",
        "The research opens up many interesting directions for further research.",
        "Besides a systematic evaluation on larger datasets, we intend to investigate the applications in event tracking and event-oriented information retrieval."
      ]
    },
    {
      "heading": "Acknowledgments",
      "text": [
        "This work has been supported by the Ministry of Science, Education and Sports, Republic of Croatia under the Grant 036-1300646-1986.",
        "We thank the reviewers for their constructive comments."
      ]
    }
  ]
}
