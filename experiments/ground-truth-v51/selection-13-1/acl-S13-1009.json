{
  "info": {
    "authors": [
      "Sai Wang",
      "Ru Li",
      "Ruibo Wang",
      "Zhiqiang Wang",
      "Xia Zhang"
    ],
    "book": "*SEM",
    "id": "acl-S13-1009",
    "title": "SXUCFN-Core: STS Models Integrating FrameNet Parsing Information",
    "url": "https://aclweb.org/anthology/S13-1009",
    "year": 2013
  },
  "references": [
    "acl-N12-1086",
    "acl-P11-1144",
    "acl-S12-1051",
    "acl-S12-1059",
    "acl-S12-1060",
    "acl-W99-0625"
  ],
  "sections": [
    {
      "text": [
        "Second Joint Conference on Lexical and Computational Semantics (*SEM), Volume 1: Proceedings of the Main Conference and the Shared Task, pages 74?79, Atlanta, Georgia, June 13-14, 2013. c?2013 Association for Computational Linguistics SXUCFN-Core: STS Models Integrating FrameNet Parsing Information"
      ]
    },
    {
      "heading": "Abstract",
      "text": [
        "This paper describes our system submitted to *SEM 2013 Semantic Textual Similarity (STS) core task which aims to measure semantic similarity of two given text snippets.",
        "In this shared task, we propose an interpolation STS model named Model_LIM integrating FrameNet parsing information, which has a good performance with low time complexity compared with former submissions."
      ]
    },
    {
      "heading": "1 Introduction",
      "text": [
        "The goal of Semantic Textual Similarity (STS) is to measure semantic similarity of two given text snippets.",
        "STS has been recently proposed by Agirre et al. (2012) as a pilot task, which has close relationship with both tasks of Textual Entailment and Paraphrase, but not equivalent with them and it is more directly applicable to a number of NLP tasks such as Question Answering (Lin and Pantel, 2001), Text Summarization (Hatzivassiloglou et al., 1999), etc.",
        "And yet, the acquiring of sentence similarity has been the most important and basic task in STS.",
        "Therefore, the STS core task of *SEM 2013 conference, is formally defined as the degree of semantic equivalence between two sentences as follows: ?",
        "5: completely equivalent, as they mean the same thing.",
        "?",
        "4: mostly equivalent, but some unimportant details differ.",
        "?",
        "3: roughly equivalent, but some important information differs/missing.",
        "?",
        "2: not equivalent, but share some details.",
        "?",
        "1: not equivalent, but are on the same topic.",
        "?",
        "0: on different topics.",
        "In this paper, we attempt to integrate semantic information into STS task besides the lower-level word and syntactic information.",
        "Evaluation results show that our STS model could benefit from semantic parsing information of two text snippets.",
        "The rest of the paper is organized as follows: Section 2 reviews prior researches on STS.",
        "Section 3 illustrates three models measuring text similarity.",
        "Section 4 describes the linear interpolation model in detail.",
        "Section 5 provides the experimental results on the development set as well as the official results on all published datasets.",
        "Finally, Section 6 summarizes our paper with direction for future works."
      ]
    },
    {
      "heading": "2 Related Work",
      "text": [
        "Several techniques have been developed for STS.",
        "The typical approach to finding the similarity between two text segments is to use simple word matching method.",
        "In order to improve this simple method, Mihalcea et al. (2006) combine two corpus-based and six knowledge-based measures of word similarity, but the cost of their algorithm is expensive.",
        "In contrast, our method treats words and texts in essentially the same way.",
        "In 2012 STS task, 35 teams participate and submit 88 runs.",
        "The two top scoring systems are UKP",
        "and Takelab.",
        "The former system (B?r et al., 2012) uses a simple log-linear regression model to combine multiple text similarity measures (related to content, structure and style) of varying complexity.",
        "While the latter system Takelab (?ari?",
        "et al, 2012) uses a support vector regression model with multiple features measuring word-overlap similarity and syntax similarity.",
        "The results of them score over 80%, far exceeding that of a simple lexical baseline.",
        "But both share one characteristic: they integrate lexical and syntax information without semantic information, especially FrameNet parsing information.",
        "In addition, the complexity of these algorithms is very high.",
        "Therefore, we propose a different and simple model integrating FrameNet parsing information in this paper."
      ]
    },
    {
      "heading": "3 Linear Interpolation Model",
      "text": [
        "In this paper, we propose a combination interpolation model which is constructed by the results of three similarity models based on words, WordNet, FrameNet , which are called simWD(?",
        "), simWN(?)",
        "and simFN(?)",
        "respectively.",
        "The overall similarity simLIM(S1, S2) between a pair of texts S1, S2 is computed in the following equation:",
        "In which, ?1, ?2 and ?3 are respectively the weights of the similarity models, i.e., ?1 +?2 +?3 = 1; and they are all positive hyperparameters.",
        "Now, we describe the three models used in this equation."
      ]
    },
    {
      "heading": "3.1 Similarity Based on Words",
      "text": [
        "This model is motivated by Vector Space Model (Salton et al., 1975).",
        "We present each sentence as a vector in the multidimensional token space.",
        "Let Sc denote the set of all words in the c-th text snippets (c = 1, 2); the words of bag is W = S1 ?",
        "S2.",
        "Hence, the similarity of a pair of sentences, formally expressed as:",
        "(2) In which, we can find ??,?",
        "?",
        "??",
        "?",
        "?",
        "1,2, ?",
        ", |?|; ?",
        "?",
        "1,2?",
        "by solving:",
        "From these two equations above, we can see the more identical words in a text pair, the more similar the two snippets are.",
        "Whereas, by intuition, many high-frequency functional words would not be helpful to the estimation of the similarity given in Eq.(2).",
        "Therefore, in the preprocessing stage, we compute the word frequencies per dataset, and then remove the high frequency words (top 1% in frequency list) in each segment."
      ]
    },
    {
      "heading": "3.2 Similarity Based on WordNet",
      "text": [
        "This model measures semantic similarity with the help of such resources that specifically encode relations between words or concepts like WordNet (Fellbaum, 1998).",
        "We use the algorithms by Lin (1998) on WordNet to compute the similarity between two words a and b, which we call simLin(a, b).",
        "Let S1, S2 be the two word sets of two given text snippets, we use the method below:",
        "In which, ??,?",
        "?",
        "????",
        "?",
        "1,2?.",
        "In the numerator of Eq.",
        "(4),we try to max(?",
        "), avg(?)",
        "and mid(?)",
        "respectively, then we find the max(?)",
        "is the best."
      ]
    },
    {
      "heading": "3.3 Similarity Based on FrameNet",
      "text": [
        "FrameNet lexicon (Fillmore et al., 2003) is a rich linguistic resource containing expert knowledge about lexical and predicate-argument semantics in English.",
        "In a sentence, word or phrase tokens that evoke a frame are known as targets.",
        "Each frame definition also includes a set of frame elements, or roles, corresponding to different aspects of the concept represented by the frame, such as participants, props, and attributes.",
        "We use the term argument to refer to a sequence of word tokens annotated as filling a frame role.",
        "All the data are automatically parsed by",
        "2011).",
        "Figure 1 shows the parser output of a sentence pair given in Microsoft Research Video Description Corpus with annotated targets, frames and role argument pairs.",
        "It can be noticed that FrameNet parsing information could give some clues of the similarity of two given snippets and we think that integrating this information could improve the accuracy of STS task.",
        "For example, the sentences in the Figure 1 both illustrate ?somebody is moving?.",
        "However, our model depends on the precision of that parser.",
        "If it would be improved, the results in STS task would be better.",
        "ing data: (a) Girls are walking on the stage; (b) Women models are walking down a catwalk.",
        "The words in bold correspond to targets, which evoke semantic frames that are denoted in capital letters.",
        "Every frame is shown in a distinct color; the arguments of each frame are annotated with the same color, and marked below the sentence, at different levels; the spans marked in the block of dotted liens fulfill a specific role.",
        "For a given sentence Sc (c = 1,2) with a set of evoked frame Fc = < f1,f2, ?, fn > (n is the number of evoked frames), a set of target word with each frame Tc = < t1, t2, ?, tn > and the set of roles (namely, frame elements) ?c = {Rc,1, Rc,2, ?,Rc,n}, each frame contains one or more arguments Rc,i = {rj} (i = 1, 2, ?, n; j is an integer that is greater or equal to zero).",
        "Take Figure 1 as an example,",
        "In order to compute simFr(?)",
        "simply, we also use a interpolation model to combine the similarities based on target words simTg(?",
        "), frames simFr(?)",
        "and frame relations simRe(?).",
        "They are estimated as the following: When computing the similarity on target word level simTg(S1, S2), we also consider each sentence as a vector of target words as is seen in Eq.",
        "(5).",
        "In which, we can find t?,?",
        "?",
        "??",
        "?",
        "?",
        "1,2,?",
        ", |?|; ?",
        "?",
        "1,2?",
        "by solving:",
        "Let simFr(S1, S2) be the similarity on frame level as shown in Eq.",
        "(7), with each sentence as a vector of frames.",
        "We define f1,i, f2,i like ??,?",
        "in Eq.",
        "(3).",
        "Before computing the role relationship between the pair of sentences, we should find the containment relationship of each pair of frames in one sentence.",
        "We use a rule to define the containment relationship: Given two frames fc,i, fc,j in a sentence Sc, if ??,?",
        "?",
        "??,?",
        "??",
        "?",
        "?",
        "?, then fc,j contains fc,i - and that is fc,i is a child of fc,j.",
        "After that we add them into the set of frame relationship ????",
        "?",
        "??",
        "??,??",
        ", ??,??",
        "?",
        "?????",
        "?",
        "?????,??????",
        ", ??",
        "?",
        "0?.",
        "We consider the relationship between two frames in a sentence as a 2-tuple, and again use",
        "Besides, we do exactly the same with both frames, namely ????,?",
        "?",
        "????",
        "?c ?",
        "1,2?",
        "the value of ????,?",
        "is 1.",
        "The similarity on frame relationship level simRe(S1, S2) presents each sentence as a vector of roles as shown in Eq.",
        "(8).",
        "Lastly, the shallow semantic similarity between two given sentences is computed as:",
        "In which, ?",
        "+ ?",
        "+ ?",
        "=1, and they are all positive hyperparameters.",
        "As shown in Figure 2, we plot the Pearson correlation (vertical axis) against the combination of parameters (horizontal axis) in all 2013 STS train data (2012 STS data).",
        "We notice that generally the Pearson correlation is fluctuates, and the correlation peak is found at 32, which in Table 1 is ?=0.6, ?=0.3, ?=0.1.",
        "?",
        "=1) with ID that is horizontal axis in Figure 2.",
        "This table also apples to different combinations of ?1, ?2, ?3 (?1 +?2 +?3 =1) with ID that is horizontal axis in Figure 3.",
        "(2012 STS data), with numbers (horizontal axis) indicating different combinations ?, ?, ?",
        "in Table 1 and when the value of result confidence is 100.",
        "The effect values are represented by a vertical line (i.e. ID = 32)."
      ]
    },
    {
      "heading": "4 Tuning Hyperparameters",
      "text": [
        "Eq.",
        "(1) is a very simple linear interpolation model, and we tune the hyperparameters on the whole 2012 STS data.",
        "As shown in Figure 3,we plot the Pearson correlation (vertical axis) for the different combination of parameters ?1, ?2 and ?3 (horizontal axis).",
        "We notice that generally the Pearson correlation fluctuates with a dropping tendency in most cases, and the correlation peak presents at 13, which in Table",
        "(2012 STS data), with numbers (horizontal axis) indicating different combinations ?1, ?2, ?3 in Table 1 and when the value of result confidence is 100.",
        "The effect values are represented by a vertical line (i.e. ID = 13)."
      ]
    },
    {
      "heading": "5 Results",
      "text": [
        "We submit four runs: the first one (Model_WD) is based on word similarity; the second one (Mod-el_WN) which is only using the similarity based on WordNet, is submitted with the team name of SXULLL; the third one (Model_FN) which uses FrameNet similarity defined in Section 3.3; and the last one in which we combine the three similarities described in Section 4 together with an interpolation model.",
        "In addition, we map our outputs multiply by five to the [0-5] range.",
        "It is worth notice that in the first model, we lo-wercase all words and remove all numbers and punctuations.",
        "And in the third model, we extract all frame-semantic roles with SEMFOR.",
        "In the experiment, we use eight datasets totally - namely MSRpar, MSRvid, SMTeuroparl, OnWN, SMTnews, headlines, FNWN and SMT - with their gold standard file to evaluate the performance of the submitted systems.",
        "Evaluation is carried out using the official scorer which computes Pearson correlation between the human rated similarity scores and the system's output.",
        "The final measure is the score that is weighted by the number of text pairs in each dataset (?Mean?).",
        "See Agirre et al. (2012) for a full description of the metrics."
      ]
    },
    {
      "heading": "5.1 Experiments on STS 2012 Data",
      "text": [
        "There is no new train data in 2013, so we use 2012 data as train data.",
        "From Table 2, 3 we can see that the Model_LIM has better performance than the other three models.",
        "data.",
        "The highest correlation in each column is given in bold.",
        "From Table 2, we notice that all the models except Model_FN, are apt to handle the SMTeuroparl that involves long sentences.",
        "For Model_FN, it performs well in computing on short and similarly structured texts such as MSRvid (This will be confirmed in test data later).",
        "Although WordNet and FrameNet model has a mere weight of 20% in Model_LIM (i.e. ?1 +?2 = 0.2), the run which integrate more semantic information displays a consistent performance across the three train sets (especially in SMTeuroparl, the Pearson correlation rises from 0.5178 to 0.66808), when compared to the other three.",
        "the baseline and UKP_run2 (that is ranked 1 in last STS task) results on 2012 test data.",
        "The highest correlation in each column is given in bold.",
        "The 2012 STS test results obtained by first ranking UKP_run2 and baseline system are shown in Table 3, it is interesting to notice that performance of Model_WD is similar with Model_LIM except on MSRvid, the text segments in which there are fewer identical words because of the semantic equivalence.",
        "For Model_FN, we can see it performs well on short and similarly structured texts (MSRvid and OnWN) as mentioned before.",
        "This is because the precision of FrameNet parser took effect on the FrameNet-based models performance.",
        "Compared to UKP_run2, the performance of Mod-el_LIM is obviously better on OnWN set, while on SMTeuroparl and SMTnews this model scores slightly lower than UKP_run2.",
        "Finally, Mod-el_LIM did not perform best on MSRpar and MSRvid compared with UKP_run2, but it has low time complexity and integrates semantic information."
      ]
    },
    {
      "heading": "5.2 Official Results on STS 2013 Test Data",
      "text": [
        "Table 4 provides the official results of our submitted systems, along with the rank on each dataset.",
        "Generally, all results outperform the baseline, based on simple word overlap.",
        "However, the performance of Model_LIM is not always the best in the three runs for each dataset.",
        "From the table we can note that a particular model always performs well on the dataset including the lexicon on which the model is based on e.g. Model_WN in OnWN, Model_FN in FNWN.",
        "Besides, Model_WD and Model_LIM almost have same scores except in OnWN set, because in Model_LIM is included with WordNet resource.",
        "their rank (out of 90) shown in brackets.",
        "Scores in bold denote significant improvements over the baseline.",
        "As seen from the system rank in table, the optimal runs in the three submitted system remain with Model_LIM.",
        "Not only Model_LIM performs best on two occasions, but also Model_FN ranks top ten twice, in FNWN and SMT respectively, we owe this result to the contribution of FrameNet parsing information."
      ]
    },
    {
      "heading": "6 Conclusion",
      "text": [
        "We have tested all the models on published STS datasets.",
        "Compared with the official results, Mod-el_LIM system is apt to handle the SMT that involves long sentences.",
        "Moreover, this system just integrates words, WordNet and FrameNet semantic information, thus it has low time complexity.",
        "There is still much room for improvement in our work.",
        "For example, we will attempt to use multivariate regression software to tuning the hyperparameters."
      ]
    },
    {
      "heading": "Acknowledgments",
      "text": [
        "This work is supported by the National Nature Science Foundation of China (No.60970053), by the National High-tech Research and Development Projects (863) grant No.2006AA01Z142, by the State Language Commission of China No.YB12519 as well as by the International Cooperation of Shanxi Province, Contracts 2010081044.",
        "And we would like to thank the organizer for the tremendous effort they put into formulating this challenging work."
      ]
    }
  ]
}
