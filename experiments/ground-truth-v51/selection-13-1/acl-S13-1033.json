{
  "info": {
    "authors": [
      "Fernando Sánchez-Vega",
      "Manuel Montes-y-Gómez",
      "Paolo Rosso",
      "Luis Villaseñor-Pineda"
    ],
    "book": "*SEM",
    "id": "acl-S13-1033",
    "title": "INAOE_UPV-CORE: Extracting Word Associations from Document Corpora to estimate Semantic Textual Similarity",
    "url": "https://aclweb.org/anthology/S13-1033",
    "year": 2013
  },
  "references": [
    "acl-J06-3003",
    "acl-S12-1051",
    "acl-S12-1094"
  ],
  "sections": [
    {
      "heading": "Abstract",
      "text": [
        "This paper presents three methods to evaluate the Semantic Textual Similarity (STS).",
        "The first two methods do not require labeled training data; instead, they automatically extract semantic knowledge in the form of word associations from a given reference corpus.",
        "Two kinds of word associations are considered: co-occurrence statistics and the similarity of word contexts.",
        "The third method was done in collaboration with groups from the Universities of Paris 13, Matanzas and Alicante.",
        "It uses several word similarity measures as features in order to construct an accurate prediction model for the STS."
      ]
    },
    {
      "heading": "1 Introduction",
      "text": [
        "Even with the current progress of the natural language processing, evaluating the semantic text similarity is an extremely challenging task.",
        "Due to the existence of multiple semantic relations among words, the measuring of text similarity is a multi-factorial and highly complex task (Turney, 2006).",
        "Despite the difficulty of this task, it remains as one of the most attractive research topics for the NLP community.",
        "This is because the evaluation of text similarity is commonly used as an internal module in many different tasks, such as, information retrieval, question answering, document sum-marization, etc.",
        "(Resnik, 1999).",
        "Moreover, most of these tasks require determining the ?semantic?",
        "similarity of texts showing stylistic differences or using polysemicwords (Hliaoutakis et al., 2006).",
        "The most popular approach to evaluate the semantic similarity of words and texts consists in using the semantic knowledge expressed in ontologies (Resnik, 1999); commonly, WorldNet is used for this purpose (Fellbaum, 2005).",
        "Unfortunately, despite the great effort that has been the creation of WordNet, it is still far to cover all existing words and senses (Curran, 2003).Therefore, the semantic similarity methods that use this resource tend to reduce their applicability to a restricted domain and to a specific language.",
        "We recognize the necessity of having and using manually-constructed semantic-knowledge sources in order to get precise assessments of the semantic similarity of texts, but, in turn, we also consider that it is possible to obtain good estimations of these similarities using less-expensive, and perhaps broader, information sources.",
        "In particular our proposal is to automatically extract the semantic knowledge from large amounts of raw data samples i.e. document corpora without labels.",
        "In this paper we describe two different strategies to compute the semantic similarity of words from a reference corpus.",
        "The first strategy uses word co-occurrence statistics.",
        "It determines that two words are associated (in meaning) if they tend to be used together, in the same documents or contexts.",
        "The second strategy measures the similarity of words by taking into consideration second order word co-occurrences.",
        "It defines two words as associated if they are used in similar contexts (i.e., if they co-occur with similar words).",
        "The following section describes the implementation of these two strategies for our participation at the STS-SEM 2013 task, as well as their combination with the measures designed by the groups from the Universities of Matanzas, Alicante and Paris 13.",
        "sists of estimated the value of semantic similarity between two texts,?1 and ?2 for now on.",
        "As we mentioned previously, our participation in the STS task of SEM 2013 considered two different approaches that aimed to take advantage of the language knowledge latent in a given reference corpus.",
        "By applying simple statistics we obtained a semantic similarity measure between words, and then we used this semantic word similarity (SWS) to get a sentence level similarity estimation.",
        "We explored two alternatives for measuring the semantic similarity of words, the first one, called ????????",
        ", uses the co-occurrence of words in a limited context1,and the second, ??????????",
        ", compares the contexts of the words using the vector model and cosine similarity to achieve this comparison.",
        "It is important to point out that using the vector space model directly, without any spatial transformation as those used by other approaches2, we could get greater control in the selection of the features used for the extraction of knowledge from the corpus.",
        "It is also worth mentioning that we applied a stemming procedure to the sentences to be compared as well as to all documents from the reference corpus.",
        "We represented the texts ?1 and ?2 by bags of tokens, which means that our approaches did not take into account the word order.",
        "Following we present our baseline method, then, we introduce the two proposed methods as well as a method done in collaboration with other groups.",
        "The idea of this shared-method is to enhance the estimation of the semantic textual similarity by combining different and diverse strategies for computing word similarities."
      ]
    },
    {
      "heading": "2.1 STS-baseline method",
      "text": [
        "Given texts?1 and ?2, their textual similarity is given by: ???",
        "?",
        "????????",
        "= ???(???",
        "?1 ,?2 , ???",
        "(?2 ,?1)) where",
        "This measure is based on a direct matching of tokens.",
        "It simply counts the number of tokens from one text ??",
        "that also exist in the other text ??",
        ".",
        "Because STS is a symmetrical attribute, unlike Textual Entailment (Agirre et al., 2012), we designed it as a symmetric measure.",
        "We assumed that the relationship between both texts is at least equal to their smaller asymmetric similarity."
      ]
    },
    {
      "heading": "2.2 The proposed STS methods",
      "text": [
        "These methods incorporate semantic knowledge extracted from a reference corpus.",
        "They aim to take advantage of the latent semantic knowledge from a large document collection.",
        "Because the extracted knowledge from the reference corpus is at word level, these methods for STS use the same basic ?word matching?",
        "strategy for comparing the sentences like the baseline method.",
        "Nevertheless, they allow a soft matching between words by incorporating information about their semantic similarity.",
        "The following formula shows the proposed modification to the SIM function in order to incorporate information of the semantic word similarity (SWS).",
        "This modification allowed us not only to match words with exactly the same stem but also to link different but semantically related words.",
        "???",
        "??",
        ",??",
        "= ???",
        "???(??",
        ", ??)",
        "?????",
        "?????",
        "We propose two different strategies to compute the semantic word similarity (SWS), ????????",
        "and ?????????",
        ".",
        "The following subsections describe in detail these two strategies.",
        "????????",
        "uses a reference corpus to get a numerical approximation of the semantic similarity between two terms ?",
        "?and ??",
        "(when these terms have not the same stem).",
        "As shown in the following formula, ????????",
        "takes values between 0 and 1; 0 indicates that it does not exist any text sample in the corpus that contains both terms, whereas, 1 indicates that they always occur together.",
        "??",
        "co-occur and # ??",
        "and # ??",
        "are the number of times that terms ??",
        "and ??",
        "occur in the reference corpus respectively.",
        "??????????",
        "is based on the idea that two terms are semantically closer if they tend to be used in similar contexts.",
        "This measure uses the well-known vector space model and cosine similarity to compare the terms?",
        "contexts.",
        "In a first step, we created a context vector for each term, which captures all the terms that appear around it in the whole reference corpus.",
        "Then, we computed the semantic similarity of two terms by the following formula.",
        "where the cosine similarity, SIMCOS, is calculated on the vectors ?",
        "?and ?",
        "?",
        "corresponding to the vector space model representation of terms ??",
        "and ??",
        ", as indicated in the following equation:",
        "It is important to point out that SIMCOS is calculated on a ?predefined?",
        "vocabulary of interest; the appropriate selection of this vocabulary helps to get a better representation of terms, and, consequently, a more accurate estimation of their semantic similarities."
      ]
    },
    {
      "heading": "2.3 STS based on a combination of measures",
      "text": [
        "In addition to our main methods we also developed a method that combines our SWS measures with measures proposed by other two research groups, namely: ?",
        "LIPN (Laboratoire d'Informatique de Paris-Nord, Universit?",
        "Paris 13, France).",
        "?",
        "UMCC_DLSI (Universidad de Matanzas Cami-lo Cienfuegos, Cuba, in conjuction with the Departamento de Lenguajes y Sistemas In-form?ticos, Universidad de Alicante, Spain).",
        "The main motivation for this collaboration was to investigate the relevance of using diverse strategies for computing word similarities and the effectiveness of their combination for estimating the semantic similarity of texts.",
        "The proposed method used a set of measures provided by each one of the groups.",
        "These measures were employed as features to obtained a prediction model for the STS.",
        "Table 1 summarizes the used measures.",
        "For the generation and fitting of the model we used three approaches: linear regression, a Gaussian process and a multilayer neural network.",
        "thod.",
        "The second column indicates the source team for each group of features; the third column indicates the number of used features from each group; the last two columns show the information gain rank of each group of features over the training set."
      ]
    },
    {
      "heading": "3 Implementation considerations",
      "text": [
        "The extraction of knowledge for the computation of the SWS was performed over the Reuters-21578 collection.",
        "This collection was selected because it is a well-known corpus and also because it includes documents covering a wide range of topics.",
        "Due to time and space restrictions we could not consider all the vocabulary from the reference corpus; the vocabulary selection was conducted by taking the best 20,000 words according to the tran",
        "sition point method (Pinto et al., 2006).",
        "This method selects the terms associated to the main topics of the corpus, which presumably contain more information for estimating the semantic similarity of words.",
        "We also preserved the vocabulary from the evaluation samples, provided they also occur in the reference corpus.",
        "The size of the vocabulary used in the experiments and the size of the corpus and test set vocabularies are shown in Table 2."
      ]
    },
    {
      "heading": "4 Evaluation and Results",
      "text": [
        "The methods proposed by our group do not require to be trained, i.e., they do not require tagged data, only a reference corpus, therefore, it was possible to evaluate them on the whole training set available this year.",
        "Table 3 shows their results on this set."
      ]
    },
    {
      "heading": "Method Correlation",
      "text": [
        "our baseline method with human judgments.",
        "Results in Table 3 show that the use of the co-occurrence information improves the correlation with human judgments.",
        "It also shows that the use of context information further improves the results.",
        "One surprising finding was the competitive performance of our baseline method; it is considerably better than the previous year's baseline result (0.31).",
        "In order to evaluate the method done in collaboration with LIPN and UMCC_DLSI, we carried out several experiments using the features provided by each group independently and in conjunction with the others.",
        "The experiments were performed over the whole training set by means of twofold cross-validation.",
        "The individual and global results are shown in Table 4.",
        "As shown in Table 4, the result corresponding to the combination of all features clearly outperformed the results obtained by using each team's features independently.",
        "Moreover, the best combination of features, containing selected features from the three teams, obtained a correlation value very close to last year's winner result."
      ]
    },
    {
      "heading": "4.1 Officials Runs",
      "text": [
        "For the official runs (refer to Table 5) we submitted the results corresponding to the ????????",
        "and ??????????",
        "methods.",
        "We also submitted a result from the method done in collaboration with LIPN and UMCC_DLSI.",
        "Due to time restrictions we were not able to submit the results from our best configuration; we submitted the results for the linear regression model using all the features (second best result from Table 4).Table 5 shows the results in the four evaluation sub-collections; Headlines comes from news headlines, OnWN and FNWN contain pair senses definitions from WordNet and other resources, finally, SMT are translations from automatic machine translations and from the reference human translations.",
        "As shown in Table 5, the performances of the two proposed methods by our group were very close.",
        "We hypothesize that this result could be caused by the use of a larger vocabulary for the computation of co-occurrence statistics than for the calculation of the context similarities.",
        "We had to use a smaller vocabulary for the later because its higher computational cost.",
        "Finally, Table 5 also shows that the method done in collaboration with the other groups ob",
        "tained our best results, confirming that using more information about the semantic similarity of words allows improving the estimation of the semantic similarity of texts.",
        "The advantage of this approach over the two proposed methods was especially clear on the OnWN and FNWN datasets, which were created upon WordNet information.",
        "Somehow this result was predictable since several measures from this ?share-method?",
        "use WordNet information to compute the semantic similarity of words.",
        "However, this pattern was not the same for the other two (WordNet unrelated) datasets.",
        "In these other two collections, the average performance of our two proposed methods, without using any expensive and manually constructed resource, improved by 4% the results from the share-method."
      ]
    },
    {
      "heading": "5 Conclusions",
      "text": [
        "The main conclusion of this experiment is that it is possible to extract useful knowledge from raw corpora for evaluating the semantic similarity of texts.",
        "Other important conclusion is that the combination of methods (or word semantic similarity measures) helps improving the accuracy of STS.",
        "As future work we plan to carry out a detailed analysis of the used measures, with the aim of determining their complementariness and a better way for combining them.",
        "We also plan to evaluate the impact of the size and vocabulary richness of the reference corpus on the accuracy of the proposed STS methods."
      ]
    },
    {
      "heading": "Acknowledgments",
      "text": [
        "This work was done under partial support of CONACyT project Grants: 134186, and Scholarship 224483.",
        "This work is the result of the collaboration in the framework of the WIQEI IRSES project (Grant No.",
        "269180) within the FP 7 Marie Curie.",
        "The work of the last author was in the framework the DIANA-APPLICATIONS-Finding Hidden Knowledge in Texts: Applications (TIN2012-38603-C02-01) project, and the"
      ]
    },
    {
      "heading": "VLC/CAMPUS Microcluster on Multimodal Inte",
      "text": [
        "raction in Intelligent Systems.",
        "We also thank the teams from the Universities of Paris 13, Matanzas and Alicante for their willingness to collaborate with us in this evalaution exercise."
      ]
    }
  ]
}
