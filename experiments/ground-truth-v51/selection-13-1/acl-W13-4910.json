{
  "info": {
    "authors": [
      "Yuval Marton",
      "Nizar Habash",
      "Owen Rambow",
      "Sarah Alkhulani"
    ],
    "book": "Workshop on Statistical Parsing of Morphologically-Rich Languages",
    "id": "acl-W13-4910",
    "title": "SPMRL'13 Shared Task System: The CADIM Arabic Dependency Parser",
    "url": "https://aclweb.org/anthology/W13-4910",
    "year": 2013
  },
  "references": [
    "acl-C08-1081",
    "acl-E12-1069",
    "acl-J08-3003",
    "acl-J08-4003",
    "acl-J13-1008",
    "acl-N10-1115",
    "acl-P05-1071",
    "acl-P11-2062",
    "acl-P99-1065",
    "acl-W13-4917"
  ],
  "sections": [
    {
      "heading": "Abstract",
      "text": [
        "We describe the submission from the"
      ]
    },
    {
      "heading": "Columbia Arabic & Dialect Modeling",
      "text": [
        "group (CADIM) for the Shared Task at the Fourth Workshop on Statistical Parsing of Morphologically Rich Languages (SPMRL?2013).",
        "We participate in the Arabic Dependency parsing task for predicted POS tags and features.",
        "Our system is based on Marton et al. (2013)."
      ]
    },
    {
      "heading": "1 Introduction",
      "text": [
        "In this paper, we discuss the system that the Columbia Arabic & Dialect Modeling group (CADIM) submitted to the 2013 Shared Task on Parsing Morphologically Rich Languages (Seddah et al., 2013).",
        "We used a system for Arabic dependency parsing which we had previously developed, but retrained it on the training data splits used in this task.",
        "We only participated in the Arabic dependency parsing track, and in it, only optimized for predicted (non-gold) POS tags and features.",
        "We first summarize our previous work (Section 2).",
        "We then discuss our submission and the results (Section 3)."
      ]
    },
    {
      "heading": "2 Approach",
      "text": [
        "In this section, we summarize Marton et al. (2013).",
        "We first present some background information on Arabic morphology and then discuss our methodology and main results.",
        "We present our best performing set of features, which we also use in our SPMRL?2013 submission."
      ]
    },
    {
      "heading": "2.1 Background",
      "text": [
        "Morphology interacts with syntax in two ways: agreement and assignment.",
        "In agreement, there is coordination between the morphological features of two words in a sentence based on their syntactic configuration (e.g., subject-verb or noun-adjective agreement in GENDER and/or NUMBER).",
        "In assignment, specific morphological feature values are assigned in certain syntactic configurations (e.g., CASE assignment for the subject or direct object of a verb).",
        "The choice of optimal linguistic features for a parser depends on three factors: relevance, redundancy and accuracy.",
        "A feature has relevance if it is useful in making an attachment (or labeling) decision.",
        "A particular feature may or may not be relevant to parsing.",
        "For example, the GENDER feature may help parse the Arabic phrase",
        "if the-new is masculine (Aljdyd YK Ym.?",
        "'@), it should attach to the masculine door (bAb H.",
        "AK.",
        "), resulting in the meaning ?the car's new door?",
        "; if the-new is fem",
        "??",
        "@), resulting in ?the door of the new car?.",
        "In contrast, the ASPECT feature does 1Arabic orthographic transliteration is presented in the HSB scheme (Habash et al., 2007): (in alphabetical order) @ H.",
        "A b t ?",
        "j H x d ?",
        "r z s ?",
        "S D T D?",
        "?",
        "?",
        "f q k l m n h w y and the additional letters: ?",
        "Z, ?",
        "not constrain any syntactic decision.2 Even if relevant, a feature may not necessarily contribute to optimal performance since it may be redundant with other features that surpass it in relevance.",
        "For example, the DET and STATE features alone both help parsing because they help identify the idafa construction (the modificiation of a nominal by a genitive noun phrase), but they are redundant with each other and the DET feature is more helpful since it also helps with adjectival modification of nouns.",
        "Finally, the accuracy of automatically predicting the feature values (ratio of correct predictions out of all predictions) of course affects the value of a feature on unseen text.",
        "Even if relevant and non-redundant, a feature may be hard to predict with sufficient accuracy by current technology, in which case it will be of little or no help for parsing, even if helpful when its gold values are provided.",
        "The CASE feature is very relevant and not redundant, but it cannot be predicted with high accuracy and overall it is not useful.",
        "Different languages vary with respect to which features may be most helpful given various tradeoffs among these three factors.",
        "It has been shown previously that if the relevant morphological features in assignment configurations can be recognized well enough, then they contribute to parsing accuracy.",
        "For example, modeling CASE in Czech improves Czech parsing (Collins et al., 1999): CASE is relevant, not redundant, and can be predicted with sufficient accuracy.",
        "However, it had been more difficult showing that agreement morphology helps parsing, with negative results for dependency parsing in several languages (Nivre et al., 2008; Eryigit et al., 2008; Nivre, 2009).",
        "In contrast to these negative results, Marton et al. (2013) showed positive results for using agreement morphology for Arabic."
      ]
    },
    {
      "heading": "2.2 Methodology",
      "text": [
        "In Marton et al. (2013), we investigated morphological features for dependency parsing of Modern Standard Arabic (MSA).",
        "The goal was to find a set of relevant, accurate and non-redundant features.",
        "We used both the MaltParser (Nivre, 2008) and the Easy-First 2For more information on Arabic morphology in the context of natural language processing see Habash (2010).",
        "For a detailed analysis of morpho-syntactic agreement, see Alkuhlani and Habash (2011).",
        "Parser (Goldberg and Elhadad, 2010).",
        "Since the Easy-First Parser performed better, we use it in all experiments reported in this paper.",
        "For MSA, the space of possible morphological features is quite large.",
        "We determined which morphological features help by performing a search through the feature space.",
        "In order to do this, we separated part-of-speech (POS) from the morphological features.",
        "We defined a core set of 12 POS features, and then explored combinations of morphological features in addition to this POS tagset.",
        "This core set of POS tags is similar to those proposed in cross-lingual work (Rambow et al., 2006; Petrov et al., 2012).",
        "We performed this search independently for Gold input features and predicted input features.",
        "We used our MADA+TOKAN system (Habash and Rambow, 2005; Habash et al., 2009; Habash et al., 2012) for the prediction.",
        "As the Easy-First Parser predicts links separately before labels, we first optimized for unlabeled attachment score, and then optimized the Easy-First Parser labeler for label score.",
        "As had been found in previous results, assignment features, specifically CASE and STATE, are very helpful in MSA.",
        "However, in MSA this is true only under gold conditions: since CASE is rarely explicit in the typically undiacritized written MSA, it has a dismal accuracy rate, which makes it useless when used in machine-predicted (real, non-gold) condition.",
        "In contrast with previous results, we showed that agreement features are quite helpful in both gold and predicted conditions.",
        "This is likely a result of MSA having a rich agreement system, covering both verb-subject and noun-adjective relations.",
        "Additionally, almost all work to date in MSA morphological analysis and part-of-speech (POS) tagging has concentrated on the morphemic form of the words.",
        "However, often the functional morphology (which is relevant to agreement, and relates to the meaning of the word) is at odds with the ?surface?",
        "(form-based) morphology; a well-known example of this are the ?broken?",
        "(irregular) plurals of nominals, which often have singular-form morphemes but are in fact plurals and show plural agreement if the referent is rational.",
        "In Marton et al. (2013), we showed that by modeling the functional morphology rather than the form-based morphology, we obtain a further increase in parsing performance",
        "??",
        "70?",
        "refers to the test sentences with 70 or fewer words (again, both when using gold and when using predicted POS and morphological features).",
        "We also showed that for parsing with predicted POS and morphological features, training on a combination of gold and predicted POS and morphological feature values outperforms the alternative training scenarios."
      ]
    },
    {
      "heading": "2.3 Best Performing Feature Set",
      "text": [
        "The best performing set of features on non-gold input, obtained in Marton et al. (2013), are shown in Table 1.",
        "The features are clustered into three types.",
        "?",
        "First is part-of-speech, represented using a ?core?",
        "12-tag set.",
        "?",
        "Second are the inflectional morphological features: determiner clitic, person and functional gender and number.",
        "?",
        "Third are the rationality (humanness) feature, which participates in morphosyntactic agreement in Arabic (Alkuhlani and Habash, 2011), and a form of the lemma, which abstract over all inflectional morphology.",
        "For the training corpus, we use a combination of the gold and predicted features."
      ]
    },
    {
      "heading": "3 Our Submission",
      "text": []
    },
    {
      "heading": "3.1 Data Preparation",
      "text": [
        "The data split used in the shared task is different from the data split we used in (Marton et al., 2013), so we retrained our models on the new splits (Diab et al., 2013).",
        "The data released for the Shared Task showed inconsistent availability of lemmas across gold and predicted input, so we used the ALMOR analyzer (Habash, 2007) with the SAMA databases (Graff et al., 2009) to determine a lemma given the word form and the provided (gold or predicted) POS tags.",
        "In addition to the lemmas, the ALMOR analyzer also provides morphological features in the feature-value representation our approach requires.",
        "Finally, we ran our existing converter (Alkuhlani and Habash, 2012) over this representation to obtain functional number and gender, as well as the rationality feature.3 For simplicity reasons, we used the MLE:W2+CATiB model (Alkuhlani and Habash, 2012), which was the best performing model on seen words, as opposed to the combination system that used a syntactic component with better results on unseen words.",
        "We did not perform Alif or Ya normalization on the data.",
        "We trained two models: one on 5,000 sentences of training data and one on the entire training data."
      ]
    },
    {
      "heading": "3.2 Results",
      "text": [
        "Our performance in the Shared Task for Arabic Dependency, Gold Tokenization, Predicted Tags, is shown in Table 2.",
        "Our performance in the Shared Task for Arabic Dependency, Predicted Tokenization, Predicted Tags, is shown in Table 3.",
        "For predicted tokenization, only the IMS/Szeged system which uses system combination (Run 2) outperformed our parser on all measures; our parser performed better than all other single-parser systems.",
        "For gold tokenization, our system is the second best single-parser system after the IMS/Szeged single system (Run 1).",
        "For gold tokenization and predicted morphology (Table 2), we also give the performance reported in our previous work (Marton et al., 2013).",
        "The increase over the previously 3The functional feature generator of (Alkuhlani and Habash, 2012) was trained on a different training set from the parser, but the functional feature generator was not trained on any of the test corpus for the Shared Task.",
        "reported work may simply be due to the different split for training and test, but it may also be due to improvements to the functional feature prediction (Alkuhlani and Habash, 2012), and the predicted features provided by the Shared Task organizers."
      ]
    }
  ]
}
