{
  "info": {
    "authors": [
      "Victoria Li Fossum",
      "Kevin Knight",
      "Steven Abney"
    ],
    "book": "Proceedings of the Third Workshop on Statistical Machine Translation",
    "id": "acl-W08-0306",
    "title": "Using Syntax to Improve Word Alignment Precision for Syntax-Based Machine Translation",
    "url": "https://aclweb.org/anthology/W08-0306",
    "year": 2008
  },
  "references": [
    "acl-C96-2141",
    "acl-D07-1006",
    "acl-D07-1038",
    "acl-D07-1104",
    "acl-H05-1010",
    "acl-H05-1011",
    "acl-H05-1012",
    "acl-H05-1022",
    "acl-J03-1002",
    "acl-J04-4002",
    "acl-J93-2003",
    "acl-N03-1017",
    "acl-P02-1040",
    "acl-P03-1021",
    "acl-P05-1022",
    "acl-P05-1033",
    "acl-P05-1034",
    "acl-P05-1057",
    "acl-P06-1065",
    "acl-P06-1077",
    "acl-P06-1096",
    "acl-P06-1121",
    "acl-P06-2014",
    "acl-P07-1003",
    "acl-P07-2045",
    "acl-W02-1001",
    "acl-W05-0812",
    "acl-W06-3601"
  ],
  "sections": [
    {
      "text": [
        "Using Syntax to Improve Word Alignment Precision for Syntax-Based",
        "Machine Translation",
        "Victoria Fossum",
        "Word alignments that violate syntactic correspondences interfere with the extraction of string-to-tree transducer rules for syntax-based machine translation.",
        "We present an algorithm for identifying and deleting incorrect word alignment links, using features of the extracted rules.",
        "We obtain gains in both alignment quality and translation quality in Chinese-English and Arabic-English translation experiments relative to a GIZA++ union baseline."
      ]
    },
    {
      "heading": "1. Introduction 1.1 Motivation",
      "text": [
        "Word alignment typically constitutes the first stage of the statistical machine translation pipeline.",
        "GIZA++ (Och and Ney, 2003), an implementation of the IBM (Brown et al., 1993) and HMM (?)",
        "alignment models, is the most widely-used alignment system.",
        "GIZA++ union alignments have been used in the state-of-the-art syntax-based statistical MT system described in (Galley et al., 2006) and in the hierarchical phrase-based system Hiero (Chiang, 2007).",
        "GIZA++ refined alignments have been used in state-of-the-art phrase-based statistical MT systems such as (Och, 2004); variations on the refined heuristic have been used by (Koehn et al., 2003) (diag and diag-and) and by the phrase-based system Moses (grow-diag-final) (Koehn et al., 2007).",
        "GIZA++ union alignments have high recall but low precision, while intersection or refined alignments have high precision but low recall.",
        "There are two natural approaches to improving upon GIZA++ alignments, then: deleting links from union alignments, or adding links to intersection or refined alignments.",
        "In this work, we delete links from GIZA++ union alignments to improve precision.",
        "The low precision of GIZA++ union alignments poses a particular problem for syntax-based rule extraction algorithms such as (Quirk et al., 2005; Galley et al., 2006; Huang et al., 2006; Liu et al., 2006): if the incorrect links violate syntactic correspondences, they force the rule extraction algorithm to extract rules that are large in size, few in number, and poor in generalization ability.",
        "Figure 1 illustrates this problem: the dotted line represents an incorrect link in the GIZA++ union alignment.",
        "Using the rule extraction algorithm described in (Galley et al., 2004), we extract the rules shown in the leftmost column (R1-R4).",
        "Rule R1 is large and unlikely to generalize well.",
        "If we delete the incorrect link in Figure 1, we can extract the rules shown in the rightmost column (R2-R9): Rule R1, the largest rule from the initial set, disappears, and several smaller, more modular rules (R5-R9) replace it.",
        "In this work, we present a supervised algorithm that uses these two features of the extracted rules (size of largest rule and total number of rules), as well as a handful of structural and lexical features, to automatically identify and delete incorrect links from GIZA++ union alignments.",
        "We show that link",
        "its own country",
        "FROM OWN-COUNTRY NEEDS STARTS-OUT",
        "Rules Extracted Using GIZA++ Union Alignments",
        "Rules Extracted After Deleting Dotted Link",
        "DT NNS I I the needs",
        "VBZ PRT x0:PP I i starts RP",
        "Figure 1: The impact of incorrect alignment links upon rule extraction.",
        "Using the original alignment (including all links shown) leads to the extraction of the tree-to-string transducer rules whose left hand sides are rooted at the solid boxed nodes in the parse tree (R1, R2, R3, and R4).",
        "Deleting the dotted alignment link leads to the omission of rule R1, the extraction of R9 in its place, the extraction of R2, R3, and R4 as before, and the extraction of additional rules whose left hand sides are rooted at the dotted boxed nodes in the parse tree (R5, R6, R7, R8).",
        "deletion improves alignment quality and translation quality in Chinese-English and Arabic-English MT, relative to a strong baseline.",
        "Our link deletion algorithm is easy to implement, runs quickly, and has been used by a top-scoring MT system in the Chinese newswire track of the 2008 NIST evaluation.",
        "Recently, discriminative methods for alignment have rivaled the quality of IBM Model 4 alignments (Liu et al., 2005; Ittycheriah and Roukos, 2005; Taskar et al., 2005; Moore et al., 2006; Fraser and Marcu, 2007b).",
        "However, except for (Fraser and Marcu, 2007b), none of these advances in alignment quality has improved translation quality of a state-of-the-art system.",
        "We use a discriminatively trained model to identify and delete incorrect links, and demonstrate that these gains in alignment quality lead to gains in translation quality in a state-of-the-art syntax-based MT system.",
        "In contrast to the semi-supervised LEAF alignment algorithm of (Fraser and Marcu, 2007b), which requires 1,5002,000 CPU days per iteration to align 8.4M Chinese-English sentences (anonymous, p.c.",
        "), link deletion requires only 450 CPU hours to realign such a corpus (after initial alignment by GIZA++, which requires 20-24 CPU days).",
        "Several recent works incorporate syntactic features into alignment.",
        "(May and Knight, 2007) use syntactic constraints to realign a parallel corpus that has been aligned by GIZA++ as follows: they extract string-to-tree transducer rules from the corpus, the target parse trees, and the alignment; discard the initial alignment; use the extracted rules to construct a forest of possible string-to-tree derivations for each string/tree pair in the corpus; use EM to select the Viterbi derivation tree for each pair; and finally, induce a new alignment from the Viterbi derivations, using the realigned corpus to train a syntax-based MT system.",
        "(May and Knight, 2007) differs from our approach in two ways: first, the set of possible realignments they consider for each sentence pair is limited by the initial GIZA++ alignments seen over the training corpus, while we consider all alignments that can be reached by deleting links from the initial GIZA++ alignment for that sentence pair.",
        "Second, (May and Knight, 2007) use a time-intensive training algorithm to select the best realignment for each sentence pair, while we use a fast greedy search to determine which links to delete; in contrast to (May and Knight, 2007), who require 400 CPU hours to realign 330k Chinese-English sentence pairs (anonymous, p.c), link deletion requires only 18 CPU hours to realign such a corpus.",
        "(Lopez and Resnik, 2005) and (Denero and Klein, 2007) modify the distortion model of the HMM alignment model (Vogel et al., 1996) to reflect tree distance rather than string distance; (Cherry and Lin, 2006) modify an ITG aligner by introducing a penalty for induced parses that violate syntactic bracketing constraints.",
        "Similarly to these approaches, we use syntactic bracketing to constrain alignment, but our work extends beyond improving alignment quality to improve translation quality as well."
      ]
    },
    {
      "heading": "2. Link Deletion",
      "text": [
        "We propose an algorithm to realign a parallel bitext that has been aligned by GIZA++ (IBM Model 4), then symmetrized using the union heuristic.",
        "We then train a syntax-based translation system on the realigned bitext, and evaluate whether the realigned bitext yields a better translation model than a baseline system trained on the GIZA++ union aligned bitext.",
        "Our algorithm for realignment proceeds as follows.",
        "We make a single pass over the corpus.",
        "For each sentence pair, we initialize the alignment A = Akamai (the GIZA++ union alignment for that sentence pair).",
        "We represent the score of A as a weighted linear combination of features hi of the alignment A, the target parse tree parse(e) (a phrase-structure syntactic representation of e), and the source string",
        "We define a branch of links to be a contiguous 1-to-many alignment.",
        "We define two alignments, A and A', to be neighbors if they differ only by the deletion of a link or branch of links.",
        "We consider all alignments A' in the neighborhood of A, greedily deleting the link I or branch of links b maximizing the score of the resulting alignment A' = A \\ I or A' = A \\ b.",
        "We delete links until no further increase in the score of A is possible.",
        "In section 2.2 we describe the features hi, and in section 2.4 we describe how to set the weights Ai.",
        "We use two features of the string-to-tree transducer rules extracted from A, parse(e), and f according to the rule extraction algorithm described in (Galley et al., 2004):",
        "ruleCount: Total number of rules extracted from A, parse(e), and f. As Figure 1 illustrates, incorrect links violating syntactic brackets tend to decrease ruleCount; ruleCount increases from 4 to 8 after deleting the incorrect link.",
        "sizeOfLargestRule: The size, measured in terms of internal nodes in the target parse tree, of the single largest rule extracted from A, parse(e), and f. In Figure 1, the largest rules in the leftmost and rightmost columns are R1 (with 9 internal nodes) and R9 (with 4 internal nodes), respectively.",
        "wordsUnaligned: Total number of unaligned words.",
        "1-to-many Links: Total number of links for which one word is aligned to multiple words, in either direction.",
        "In Figure 1, the links {£fj ^-starts, £b %L-out,£rj/§>needs} represent a 1-to-many alignment.",
        "1-to-many links appear more frequently in GIZA++ union alignments than in gold alignments, and are therefore good candidates for deletion.",
        "The category of 1-to-many links is further subdivided, depending on the degree of contiguity that the link exhibits with its neighbors.",
        "Each link in a 1-to-many alignment can have 0, 1, or 2 neighbors, according to how many links are adjacent to it in the 1-to-many alignment:",
        "zeroNeighbors: In Figure 1, the link needs has 0 neighbors.",
        "oneNeighbor: In Figure 1, the links starts and £b /§>out each have 1 neighbor-namely, each other.",
        "twoNeighbors: In Figure 1, in the 1-to-many alignment formed by { -its, -own, -country} , the link own has 2 neighbors, namely it and -country.",
        "highestLexProbRank: A link ei-fj is \"maxprobable from ei to fj\" if p(fj|ei) > p(fj'|ei) for all alternative words fj' with which ei is aligned in Ainitiai.",
        "In Figure 1, p(ff J?| needs) > p(£fj ^needs), so Ws Jc-needs is max-probable for \"needs\".",
        "The definition of \"max-probable from fj to ei\" is analogous, and a link is max-probable (nondi-rectionally) if it is max-probable in either direction.",
        "The value of highestLexProbRank is the total number of max-probable links.",
        "The conditional lexical probabilities p(ei\\fj) and p(fj are estimated using frequencies of aligned word pairs in the high-precision GIZA++ intersection alignments for the training corpus.",
        "In addition to the above syntactic, structural, and lexical features of A, we also incorporate two features of the link deletion history itself into linksDeleted: Total number of links deleted Ainitiai thus far.",
        "At each iteration, either a link or a branch of links is deleted.",
        "aligned to multiple English words are aligned to a contiguous block of English words; similarly, 88% of the English words that are aligned to multiple Chinese words are aligned to a contiguous block ofChinese words.",
        "Thus, ifa Chinese word is correctly aligned to multiple English words, those English words are likely to be \"neighbors\" of each other, and if an English word is correctly aligned to multiple Chinese words, those Chinese words are likely to be \"neighbors\" of each other.",
        "stepsTaken: Total number of iterations thus far in the search; at each iteration, either a link or a branch is deleted.",
        "This feature serves as a constant cost function per step taken during link deletion.",
        "Protecting Refined Links from Deletion: Since GIZA++ refined links have higher precision than union links, we do not consider any GIZA++ refined links for deletion.",
        "Stoplist: In our Chinese-English corpora, the 10 most common English words (excluding punctuation marks) include {a,in,to,of,and,the}, while the 10 most common Chinese words include {7,&,&Mtfi}.",
        "Of these, {a,the} and {7M} have no explicit translational equivalent in the other language.",
        "These words are aligned with each other frequently (and erroneously) by GIZA++ union, but rarely in the gold standard.",
        "We delete all links in the set {a, an, the} x {(ft,7} from Ainitial as a preprocessing step.",
        "We set the feature weights A using a modified version of averaged perceptron learning with structured outputs (Collins, 2002).",
        "Following (Moore, 2005), we initialize the value of our expected most informative feature (ruleCount) to 1.0, and initialize all other feature weights to 0.",
        "During each pass over the discriminative training set, we \"decode\" each sentence pair by greedily deleting links from Ainitial in order to maximize the score of the resulting alignment using the current settings of A (for details, refer to section 2.1).",
        "We construct a set of candidate alignments Acandidates for use in reranking as follows.",
        "Starting with A = Ainitial, we iteratively explore all alignments A' in the neighborhood of A, adding each neighbor to Acandidates, then selecting the neighbor that maximizes Score(A').",
        "When it is no longer possible to increase Score(A) by deleting any links, link deletion concludes and returns the highest-scoring alignment, Ai-best.",
        "In general, Agdid <£ Acandidates; following (Collins, 2000) and (Charniak and Johnson, 2005) for parse reranking and (Liang et al., 2006) for translation reranking, we define Aoracle as alignment in Acandidates that is most similar to AgoW.",
        "We update each feature weight Ai as follows: Ai = Ai +",
        "Following (Moore, 2005), after each training pass, we average all the feature weight vectors seen during the pass, and decode the discriminative training set using the vector of averaged feature weights When alignment quality stops increasing on the discriminative training set, perceptron training ends The weight vector returned by perceptron training is the average over the training set of all weight vectors seen during all iterations; averaging reduces overfit-ting on the training set (Collins, 2002)"
      ]
    },
    {
      "heading": "3. Experimental Setup 3.1 Data Sets",
      "text": [
        "We evaluate the effect of link deletion upon alignment quality and translation quality for two Chinese-English data sets, and one Arabic-English data set Each data set consists of newswire, and contains a small subset of manually aligned sentence pairs.",
        "We divide the manually aligned subset into a training set (used to discriminatively set the feature weights for link deletion) and a test set (used to evaluate the impact of link deletion upon alignment quality).",
        "Table 1 lists the source and the size of the manually aligned training and test sets used for each alignment task.",
        "3.2.",
        "Using the feature weights learned on the manually aligned training set, we then apply link deletion to the remainder (non-manually aligned) of each bilingual data set, and train a full syntax-based statistical MT system on these sentence pairs.",
        "After maximum BLEU tuning (Och, 2003 a) on a held-out tuning set, we evaluate translation quality on a held-out test set.",
        "Table 2 lists the source and the size of the training, tuning, and test sets used for each translation task.",
        "AER (Alignment Error Rate) (Och and Ney, 2003) is the most widely used metric of alignment quality, but requires gold-standard alignments labelled with \"sure/possible\" annotations to compute; lacking such annotations, we can compute alignment f-measure instead.",
        "However, (Fraser and Marcu, 2007a) show that, in phrase-based translation, improvements in AER or f-measure do not necessarily correlate with improvements in BLEU score.",
        "They propose two modifications to f-measure: varying the precision/recall tradeoff, and fully-connecting the alignment links before computing f-measure.",
        "Weighted Fully-Connected F-Measure Given a hypothesized set of alignment links H and a gold-standard set of alignment links G, we define H + = fullyConnect(H) and G+ = fullyConnect(G), and then compute:",
        "For phrase-based Chinese-English and Arabic-English translation tasks, (Fraser and Marcu, 2007a) obtain the closest correlation between weighted fully-connected alignment f-measure and BLEU score using a=0.5 and a=0.1, respectively.",
        "We use weighted fully-connected alignment f-measure as the training criterion for link deletion, and to evaluate alignment quality on training and test sets.",
        "Rule F-Measure To evaluate the impact of link deletion upon rule quality, we compare the rule precision, recall, and f-measure ofthe rule set extracted",
        "Language Train Test from our hypothesized alignments and a Collins-style parser against the rule set extracted from gold alignments and gold parses.",
        "BLEU For all translation tasks, we report case-insensitive NIST BLEU scores (Papineni et al., 2002) using 4 references per sentence.",
        "Starting with GIZA++ union (IBM Model 4) alignments, we use perceptron training to set the weights of each feature used in link deletion in order to optimize weighted fully-connected alignment f-measure (a=0.5 for Chinese-English and a=0.1 for Arabic-English) on a manually aligned discriminative training set.",
        "We report the (fully-connected) precision, recall, and weighted alignment f-measure on a held-out test set after running perceptron training, relative to the baseline GIZA++ union alignments.",
        "Using the learned feature weights, we then perform link deletion over the GIZA++ union alignments for the entire training corpus for each translation task.",
        "Using these alignments, which we refer to as \"GIZA++ union + link deletion\", we train a syntax-based translation system similar to that described in (Galley et al., 2006).",
        "After extracting string-to-tree translation rules from the aligned, parsed training corpus, the system assigns weights to each rule via frequency estimation with smoothing.",
        "The rule probabilities, as well as trigram language model probabilities and a handful of additional features of each rule, are used as features during decoding.",
        "The feature weights are tuned using minimum error rate training (Och and Ney, 2003) to optimize BLEU score on a held-out development set.",
        "We then compare the BLEU score of this system against a baseline system trained using GIZA++ union alignments.",
        "To determine which value of a is most effective as a training criterion for link deletion, we set a=0.4 (favoring recall), 0.5, and 0.6 (favoring precision), and compare the effect on translation quality for Chinese-English data set A."
      ]
    },
    {
      "heading": "4. Results",
      "text": [
        "For each translation task, link deletion improves translation quality relative to a GIZA++ union baseline.",
        "For each alignment task, link deletion tends to improve fully-connected alignment precision more than it decreases fully-connected alignment recall, increasing weighted fully-connected alignment f-measure overall.",
        "On Chinese-English translation task A, link deletion increases BLEU score by 1.26 points on tuning and 0.76 points on test (Table 3); on Chinese-English translation task B, link deletion increases BLEU score by 1.38 points on tuning and 0.49 points on test (Table 3).",
        "On the Arabic-English translation task, link deletion improves BLEU score by 0.84 points on tuning, 0.18 points on test1, and 0.56 points on test2 (Table 3).",
        "Note that the training criterion for Arabic-English link deletion uses a=0.1; because this penalizes a loss in recall more heavily than it rewards an increase in precision, it is more difficult to increase weighted fully-connected alignment f-measure using link deletion for Arabic-English than for Chinese-English.",
        "This difference is reflected in the average number of links deleted per sentence: 4.19 for Chinese-English B (Table 3), but only 1.35 for Arabic-English (Table 3).",
        "Despite this difference, link deletion improves translation results for Arabic-English as well.",
        "On Chinese-English data set A, we explore the effect of varying a in the weighted fully-connected",
        "Figure 2: Effect of discriminative training set size on link deletion accuracy for Chinese-English B, a=0.5 alignment f-measure used as the training criterion for link deletion.",
        "Using a=0.5 leads to a higher gain in BLEU score on the test set relative to the baseline (+0.76 points) than either a=0.4 (+0.70 points) or a=0.6 (+0.67 points).",
        "To examine how many manually aligned sentence pairs are required to set the feature weights reliably, we vary the size of the discriminative training set from 2-1500 sentence pairs while holding test set size constant at 1500 sentence pairs; run per-ceptron training; and record the resulting weighted fully-connected alignment f-measure on the test set.",
        "Figure 2 illustrates that using 100-200 manually aligned sentence pairs of training data is sufficient for Chinese-English; a similarly-sized training set is also sufficient for Arabic-English.",
        "Link deletion increases the size of the extracted grammar.",
        "To determine how the quality of the extracted grammar changes, we compute the rule pre-",
        "Language",
        "Train",
        "Tune",
        "Testl",
        "Test2",
        "Chinese-English A",
        "9.8M/newswire",
        "25.9k/NIST02",
        "29.0k/NIST03",
        "-",
        "Chinese-English B",
        "12.3M/newswire",
        "42.9k/newswire",
        "42.1k/newswire",
        "-",
        "Arabic-English",
        "174.8M/newswire",
        "35.8k/NIST04-05",
        "40.3k/NIST04-05",
        "53.0k/newswire",
        "Table 3: Results of link deletion.",
        "Weighted fully-connected alignment f-measure is computed on alignment test sets (Table 1); BLEU score is computed on translation test sets (Table 2).",
        "Table 4: Rule precision, recall, and f-measure of rules extracted from 400 sentence pairs of Chinese-English data cision, recall, and f-measure of the GIZA++ union alignments and various link deletion alignments on a held-out Chinese-English test set of 400 sentence pairs.",
        "Table 4 indicates the total (non-unique) number of rules extracted for each alignment/parse pairing, as well as the rule precision, recall, and f-measure of each pair.",
        "As more links are deleted, more rules are extracted-but of those, some are of good quality and others are of bad quality.",
        "Link-deleted alignments produce rule sets with higher rule f-measure than either GIZA++ union or GIZA++ refined."
      ]
    },
    {
      "heading": "5. Conclusion",
      "text": [
        "We have presented a link deletion algorithm that improves the precision of GIZA++ union alignments without notably decreasing recall.",
        "In addition to lexical and structural features, we use features ofthe extracted syntax-based translation rules.",
        "Our method improves alignment quality and translation quality on Chinese-English and Arabic-English translation tasks, relative to a GIZA++ union baseline.",
        "The algorithm runs quickly, and is easily applicable to other language pairs with limited amounts (100-200 sentence pairs) of manually aligned data available."
      ]
    },
    {
      "heading": "Acknowledgments",
      "text": [
        "We thank Steven DeNeefe and Wei Wang for assistance with experiments, and Alexander Fraser and Liang Huang for helpful discussions.",
        "This research 0022) and by a fellowship from AT&T Labs.",
        "Language",
        "Alignment",
        "Prec",
        "Rec",
        "a",
        "F-measure",
        "Links Del/ Sent",
        "Grammar Size",
        "Tune",
        "BLEU Test1",
        "Test2",
        "Chi-Eng A",
        "GIZA++ union",
        "54.76",
        "75.38",
        "0.5",
        "63.44",
        "-",
        "23.4M",
        "41.80",
        "41.17",
        "-",
        "Chi-Eng A",
        "GIZA++ union + link deletion",
        "79.59",
        "71.16",
        "0.5",
        "75.14",
        "4.77",
        "59.7M",
        "43.06",
        "41.93",
        "-",
        "Chi-Eng B",
        "GIZA++ union",
        "36.61",
        "66.28",
        "0.5",
        "47.16",
        "-",
        "28.9M",
        "39.59",
        "41.39",
        "-",
        "Chi-Eng B",
        "GIZA++ union + link deletion",
        "65.52",
        "59.28",
        "0.5",
        "62.24",
        "4.19",
        "73.0M",
        "40.97",
        "41.88",
        "-",
        "Ara-Eng",
        "GIZA++ union",
        "35.34",
        "84.05",
        "0.1",
        "73.87",
        "-",
        "52.4M",
        "54.73",
        "50.9",
        "38.16",
        "Ara-Eng",
        "GIZA++ union + link deletion",
        "52.68",
        "79.75",
        "0.1",
        "75.85",
        "1.35",
        "64.9M",
        "55.57",
        "51.08",
        "38.72",
        "Alignment",
        "Parse",
        "Precision",
        "Recall",
        "Rule",
        "F-measure",
        "Total Non-Unique",
        "gold",
        "gold",
        "100.00",
        "100.00",
        "100.00",
        "12,809",
        "giza++ union",
        "collins",
        "50.49",
        "44.23",
        "47.15",
        "11,021",
        "giza++ union+link deletion, a=0.5",
        "collins",
        "47.51",
        "53.20",
        "50.20",
        "13,987",
        "giza++ refined",
        "collins",
        "44.20",
        "54.06",
        "48.64",
        "15,182"
      ]
    }
  ]
}
