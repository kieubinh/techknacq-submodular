{
  "info": {
    "authors": [
      "Spence Green",
      "Nicholas Andrews",
      "Matthew R. Gormley",
      "Mark Dredze",
      "Christopher D. Manning"
    ],
    "book": "NAACL",
    "id": "acl-N12-1007",
    "title": "Entity Clustering Across Languages",
    "url": "https://aclweb.org/anthology/N12-1007",
    "year": 2012
  },
  "references": [
    "acl-A00-1020",
    "acl-C10-2121",
    "acl-C98-1012",
    "acl-D07-1020",
    "acl-D08-1029",
    "acl-D08-1089",
    "acl-D09-1092",
    "acl-H05-1004",
    "acl-H05-1083",
    "acl-J98-4003",
    "acl-L08-1254",
    "acl-L08-1390",
    "acl-N01-1007",
    "acl-N04-1001",
    "acl-N04-1002",
    "acl-N06-1060",
    "acl-N09-1019",
    "acl-N10-1073",
    "acl-N10-2003",
    "acl-P03-1054",
    "acl-P05-1071",
    "acl-P09-2090",
    "acl-P10-1087",
    "acl-P11-1080",
    "acl-W03-0405",
    "acl-W04-0701",
    "acl-W07-0804",
    "acl-W09-0210",
    "acl-W09-1121",
    "acl-W10-4305",
    "acl-W99-0613"
  ],
  "sections": [
    {
      "heading": "Abstract",
      "text": [
        "Standard entity clustering systems commonly rely on mention (string) matching, syntactic features, and linguistic resources like English WordNet.",
        "When co-referent text mentions appear in different languages, these techniques cannot be easily applied.",
        "Consequently, we develop new methods for clustering text mentions across documents and languages simultaneously, producing cross-lingual entity clusters.",
        "Our approach extends standard clustering algorithms with cross-lingual mention and context similarity measures.",
        "Crucially, we do not assume a pre-existing entity list (knowledge base), so entity characteristics are unknown.",
        "On an Arabic-English corpus that contains seven different text genres, our best model yields a 24.3% F1 gain over the baseline."
      ]
    },
    {
      "heading": "1 Introduction",
      "text": [
        "This paper introduces techniques for clustering co-referent text mentions across documents and languages.",
        "On the web today, a breaking news item may instantly result in mentions to a real-world entity in multiple text formats: news articles, blog posts, tweets, etc.",
        "Much NLP work has focused on model adaptation to these diverse text genres.",
        "However, the diversity of languages in which the mentions appear is a more significant challenge.",
        "This was particularly evident during the 2011 popular uprisings in the Arab world, in which electronic media played a prominent role.",
        "A key issue for the outside world was the aggregation of information that appeared simultaneously in English, French, and various Arabic dialects.",
        "To our knowledge, we are the first to consider clustering entity mentions across languages without a priori knowledge of the quantity or types of real-world entities (a knowledge base).",
        "The cross-lingual setting introduces several challenges.",
        "First, we cannot assume a prototypical name format.",
        "For example, the Anglo-centric first/middle/last prototype used in previous name modeling work (cf. (Charniak, 2001)) does not apply to Arabic names like Abdullah ibn Abd Al-Aziz Al-Saud or Chinese names like Hu Jin-tao (referred to as Mr. Hu, not Mr. Jintao).",
        "Second, organization names often require both transliteration and translation.",
        "For example, the Arabic",
        "??Q??",
        "?Corporation?.",
        "Our models are organized as a pipeline.",
        "First, for each document, we perform standard mention detection and coreference resolution.",
        "Then, we use pairwise cross-lingual similarity models to measure both mention and context similarity.",
        "Finally, we cluster the mentions based on similarity.",
        "Our work makes the following contributions: (1) introduction of the task, (2) novel models for cross-lingual entity clustering of person and organization entities, (3) cross-lingual annotation of the NIST Automatic Content Extraction (ACE) 2008 Arabic-English evaluation set, and (4) experimental results using both gold and automatic within-document processing.",
        "We will release our software and annotations to support future research."
      ]
    },
    {
      "heading": "1.1 Task Description via a Simple Example",
      "text": [
        "Consider the toy corpus in Fig. 1.",
        "The English documents contain mentions of two people: Steven Paul Jobs and Mark Elliot Zuckerberg.",
        "Of course, the surface realization of Mr. Jobs?",
        "last name in English is also an ordinary nominal, hence the ambiguous mention string (absent context) in the second document.",
        "The Arabic document introduces an organization entity (Apple Inc.) along with proper and pronominal references to Mr. Jobs.",
        "Finally, the French document refers to Mr. Jobs by the honorific ?Monsieur,?",
        "and to",
        "Jobs program details delayed Steve Jobs admired Mark Zuckerberg M. Jobs, le fondateur d'Apple, est mort",
        "identification of which is the primary objective of this work.",
        "We use a separately-trained system for within-document mention detection and coreference (indicated by the text boxes and intra-document links, respectively).",
        "Our experimental results are for Arabic-English only.",
        "Apple without its corporate designation.",
        "Our goal is to automatically produce the cross-lingual entity clusters E1 (Mark Elliot Zuckerberg), E2 (Apple Inc.), and E3 (Steven Paul Jobs).",
        "Both the true number and characteristics of these entities are unobserved.",
        "Our models require two preprocessing steps: mention detection and within-document coreference/anaphora resolution, shown in Fig. 1 by the text boxes and intra-document links, respectively.",
        "For example, in doc3, a within-document coreference system would pre-link QK.",
        "?k.",
        "joobz ?Jobs?",
        "with the masculine pronoun ?",
        "h ?his?.",
        "In addition, the mention detector determines that the surface form ?Jobs?",
        "in doc2 is not an entity reference.",
        "For this within-document preprocessing we use Serif (Ramshaw et al., 2011).1 Our models measure cross-lingual similarity of the coreference chains to make clustering decisions (?",
        "in Fig. 1).",
        "The similarity models (indicated by the = and 6= operators in Fig. 1) consider both mention string and context similarity (?2).",
        "We use the mention similarities as hard constraints, and the context similarities as soft constraints.",
        "In this work, we investigate two standard constrained clustering algorithms (?3).",
        "Our methods can be used to extend existing systems for monolingual entity clustering (also known as ?cross-document coreference resolution?)",
        "to the cross-lingual setting.",
        "contains only one language.",
        "Currently, there are no publicly available within-document coreference systems for Arabic and many other languages.",
        "To remedy this problem, the CoNNL-2012 shared task aims to develop multilingual coreference systems."
      ]
    },
    {
      "heading": "2 Mention and Context Similarity",
      "text": [
        "Our goal is to create cross-lingual sets of co-referent mentions to real-world entities (people, places, organizations, etc.).",
        "In this paper, we adopt the following notation.",
        "LetM be a set of distinct text mentions in a collection of documents;C is a partitioning ofM into document-level sets of co-referent mentions (called coreference chains); E is a partitioning of C into sets of co-referent chains (called entities).",
        "Let i, j be non-negative integers less than or equal to |M |and a, b be non-negative integers less than or equal to |C|.",
        "Our experiments use a separate within-document coreference system to createC, which is fixed.",
        "We will learn E, which has size no greater than |C |since the set of monolingual chains is the largest valid partitioning.",
        "We define accessor functions to access properties of mentions and chains.",
        "For any mentionmi, define the following functions: lang(mi) is the language; doc(mi) is the document containingmi; type(mi) is the semantic type, which is assigned by the within-document coreference system.",
        "We also extract a set of mention contexts S, which are the sentences containing each mention (i.e., |S |= |M |).",
        "We learn the partition E by considering mention and context similarity, which are measured with separate component models."
      ]
    },
    {
      "heading": "2.1 Mention Similarity",
      "text": [
        "We use separate methods for within-and cross-language mention similarity.",
        "The pairwise similarity",
        "thographic representation.",
        "???",
        "indicates a null mapping.",
        "For English, we also lowercase and remove determiners and punctuation.",
        "For Arabic, we remove the determiner ?",
        "@ Al ?the?",
        "and the elongation character tatwil ??.",
        "of any two mentionsmi andmj is:",
        "distance (Porter and Winkler, 1997).",
        "Jaro-Winkler rewards matching prefixes, the empirical justification being that less variation typically occurs at the beginning of names.",
        "The metric produces a score in the range [0,1], where 0 indicates equality.",
        "Maxent model (cross-language) When lang(mi) 6= lang(mj), then the two mentions might be in different writing systems.",
        "Edit distance calculations no longer apply directly.",
        "One solution would be full-blown transliteration (Knight and Graehl, 1998), followed by application of Jaro-Winkler.",
        "However, transliteration systems are complex and require significant training resources.",
        "We find that a simpler, low-resource approach works well in practice.",
        "First, we deterministically map both languages to a common phonetic representation (Tbl.",
        "1).3 Next, we align the mention pairs with the Hungarian algorithm,",
        "whitespace-tokenized mention pair ?mi,mj?",
        "with alignment Ami,mj .",
        "Let (u, v) ?",
        "Ami,mj indicate aligned token indices.",
        "Define the following functions for strings: cbigrams(?)",
        "returns the set of character bigrams; len(?)",
        "is",
        "the token length; Lev(?, ?)",
        "is the Levenshtein edit distance between two strings.",
        "Prior to feature extraction, we add unique start and end symbols to the mention strings.",
        "which produces a word-to-word alignment Ami,mj .",
        "Finally, we build a simple binary Maxent classifier p(y|mi,mj ;?)",
        "that extracts features from the aligned mentions (Tbl.",
        "2).",
        "We learn the parameters ?",
        "using a quasi-Newton procedure with L1 (lasso) regularization (Andrew and Gao, 2007)."
      ]
    },
    {
      "heading": "2.2 Context Mapping and Similarity",
      "text": [
        "Mention strings alone are not always sufficient for disambiguation.",
        "Consider again the simple example in Fig. 1.",
        "Both doc3 and doc4 reference ?Steve Jobs?",
        "and ?Apple?",
        "in the same contexts.",
        "Context co-occurence and/or similarity can thus disambiguate these two entities from other entities with similar references (e.g., ?Steve Jones?",
        "or ?Apple Corps?).",
        "As with the mention strings, the contexts may originate in different writing systems.",
        "We consider both high-and low-resource approaches for mapping contexts to a common representation.",
        "Machine Translation (MT) For the high-resource setting, if lang(mi) 6=English, then we translate both mi and its context si to English with an MT system.",
        "We use Phrasal (Cer et al., 2010), a phrase-based system which, like most public MT systems, lacks a transliteration module.",
        "We believe that this approach yields the most accurate context mapping for high-resource language pairs (like English-Arabic).",
        "Polylingual Topic Model (PLTM) The polylin-gual topic model (PLTM) (Mimno et al., 2009) is a generative process in which document tuples?",
        "groups of topically-similar documents?share a topic distribution.",
        "The tuples need not be sentence-aligned, so training data is easier to obtain.",
        "For example, one document tuple might be the set of Wikipedia articles (in all languages) for Steve Jobs.",
        "Let D be a set of document tuples, where there is one document in each tuple for each of L languages.",
        "Each language has vocabulary Vl and each document dlt has N l t tokens.",
        "We specify a fixed-size set of topics K. The PLTM generates the document tuples as follows:",
        "For cross-lingual context mapping, we infer the 1 best topic assignments for each token in all S mention contexts.",
        "This technique reduces Vl = k for all l. Moreover, all languages have a common vocabulary: the set of K topic indices.",
        "Since the PLTM is not a contribution of this paper, we refer the interested reader to (Mimno et al., 2009) for more details.",
        "After mapping each mention context to a common representation, we measure context similarity based on the choice of clustering algorithm."
      ]
    },
    {
      "heading": "3 Clustering Algorithms",
      "text": [
        "We incorporate the mention and context similarity measures into a clustering framework.",
        "We consider two algorithms.",
        "The first is hierarchical agglomerative clustering (HAC), with which we assume basic familiarity (Manning et al., 2008).",
        "A shortcoming of HAC is that a stop threshold must be tuned.",
        "To avoid this requirement, we also consider non-parametric probabilistic clustering in the form of a Dirichlet process mixture model (DPMM) (Antoniak, 1974) .",
        "Both clustering algorithms can be modified to accommodate pairwise constraints.",
        "We have observed better results by encoding mention similarity as a hard constraint.",
        "Context similarity is thus the cluster distance measure.5 To turn the Jaro-Winkler distance into a hard boolean constraint, we tuned a threshold ?",
        "on held-out data, i.e., jaro-winkler(mi,mj) ?",
        "?",
        "?",
        "mi = mj .",
        "Likewise, the Maxent model is a binary classifier, so",
        "In both clustering algorithms, any two chains Ca",
        "and Cb cannot share the same cluster assignment if: 1.",
        "Document origin: doc(Ca) = doc(Cb) 2.",
        "Semantic type: type(Ca) 6= type(Cb) 3.",
        "Mention Match: sim(mi,mj) = false,",
        "The deterministic accessor function repr(Ca) returns the representative mention of a chain.",
        "The heuristic we used was ?first mention?",
        ": the function returns the earliest mention that appears in the associated document.",
        "In many languages, the first mention is typically more complete than later mentions.",
        "This heuristic also makes our system less sensitive to within-document coreference errors.",
        "The representative mention only has special status for mention similarity: context similarity considers all mention contexts."
      ]
    },
    {
      "heading": "3.1 Constrained Hierarchical Clustering",
      "text": [
        "HAC iteratively merges the ?nearest?",
        "clusters according to context similarity.",
        "In our system, each cluster context is a bag of wordsW formed from the contexts of all coreference chains in that cluster.",
        "For each word inW we estimate a unigram Entity Language Model",
        "the corpus7 and ?",
        "is a smoothing parameter.",
        "For any",
        "two entity clusters Ea and Eb, the distance between PEa and PEb is given by a metric based on the Jensen-Shannon Divergence (JSD) (Endres and Schindelin, 2003):",
        "where KL(PEa ||M) is the Kullback-Leibler divergence andM = 12(PEa + PEb).",
        "We initialize HAC to E = C, i.e., the initial clustering solution is just the set of all coreference chains.",
        "Thenwe remove all links in the HAC proximitymatrix that violate pairwise cannot-link constraints.",
        "During clustering, we do not merge Ea and Eb if any pair of chains violates a cannot-link constraint.",
        "This procedure propagates the cannot-link constraints (Klein et al., 2002).",
        "To output E, we stop clustering when the minimum JSD exceeds a stop threshold ?, which is tuned on a development set."
      ]
    },
    {
      "heading": "3.2 Constrained Dirichlet Process Mixture Model (DPMM)",
      "text": [
        "Instead of tuning a parameter like ?, it would be preferable to let the data dictate the number of entity clusters.",
        "We thus consider a non-parametric Bayesian mixture model where the mixtures are multinomial distributions over the entity contexts S. Specifically, we consider a DPMM, which automatically infers the number of mixtures.",
        "Each Ca has an associated mixture ?a:",
        "where ?",
        "is the concentration parameter of the DP prior and G0 is the base distribution with support V .",
        "For our experiments, we set G0 = Dir(pi1, .",
        ".",
        ".",
        ", piV ), where pii = PV (wi).",
        "For inference, we use the Gibbs sampler of Vla-chos et al. (2009), which can incorporate pairwise constraints.",
        "The sampler is identical to a standard collapsed, token-based sampler, except the conditional probability p(Ea = E|E?a, Ca) = 0 if Ca cannot be merged with the chains in clusterE.",
        "This property makes the model non-exchangeable, but in practice non-exchangeable models are sometimes useful (Blei and Frazier, 2010).",
        "During sampling, we also learn ?",
        "using the auxiliary variable procedure of West (1995), so the only fixed parameters are those of the vague Gamma prior.",
        "However, we found that these hyper-parameters were not sensitive."
      ]
    },
    {
      "heading": "4 Training Data and Procedures",
      "text": [
        "We trained our system for Arabic-English cross-lingual entity clustering.8 Maxent Mention Similarity The Maxent mention similarity model requires a parallel name list for training.",
        "Name pair lists can be obtained from the LDC (e.g., LDC2005T34 contains nearly 450,000 parallel Chinese-English names) or Wikipedia (Irvine et al., 2010).",
        "We extracted 12,860 name pairs from the parallel Arabic-English translation treebanks,9 although our experiments show that the model achieves high accuracy with significantly fewer training examples.",
        "We generated a uniform distribution of training examples by running a Bernoulli trial for each aligned name pair in the corpus.",
        "If the coin was heads, we replaced the English name with another English name chosen randomly from the corpus.",
        "MT Context Mapping For the MT context mapping method, we trained Phrasal with all data permitted under the NIST OpenMT Ar-En 2009 constrained track evaluation.",
        "We built a 5-gram language model from the Xinhua and AFP sections of the Gigaword corpus (LDC2007T07), in addition to all of the target side training data.",
        "In addition to the baseline Phrasal feature set, we used the lexicalized reordering model of Galley and Manning (2008).",
        "PLTM Context Mapping For PLTM training, we formed a corpus of 19,139 English-Arabic topically-aligned Wikipedia articles.",
        "Cross-lingual links in Wikipedia are abundant: as of February 2010, there were 77.07M cross-lingual links among Wikipedia's 272 language editions (de Melo and Weikum, 2010).",
        "To increase vocabulary coverage for our ACE2008 evaluation corpus, we added 20,000 document singletons from the ACE2008 training corpus.",
        "The",
        "topically-aligned tuples served as ?glue?",
        "to share topics between languages, while the ACE documents distribute those topics over in-domain vocabulary.10 We used the PLTM implementation in Mallet (Mc-Callum, 2002).",
        "We ran the sampler for 10,000 iterations and set the number of topicsK = 512."
      ]
    },
    {
      "heading": "5 Task Evaluation Framework",
      "text": [
        "Our experimental design is a cross-lingual extension of the standard cross-document coreference resolution task, which appeared in ACE2008 (Strassel et al., 2008; NIST, 2008).",
        "We evaluate name (NAM) mentions for cross-lingual person (PER) and organization (ORG) entities.",
        "Neither the number nor the attributes of the entities are known (i.e., the task does not include a knowledge base).",
        "We report results for both gold and automatic within-document mention detection and coreference resolution.",
        "Evaluation Metrics We use entity-level evaluation metrics, i.e., we evaluate the E entity clusters rather than the mentions.",
        "For the gold setting, we report: ?",
        "B3 (Bagga and Baldwin, 1998a): Precision and recall are computed from the intersection of the hypothesis and reference clusters.",
        "?",
        "CEAF (Luo, 2005): Precision and recall are computed from a maximum bipartite matching between hypothesis and reference clusters.",
        "?",
        "NVI (Reichart and Rappoport, 2009): Information-theoretic measure that utilizes the entropy of the clusters and their mutual information.",
        "Unlike the commonly-used Variation of Information (VI) metric, normalized VI (NVI) is not sensitive to the size of the data set.",
        "For the automatic setting, we must apply a different metric since the number of system chains may differ from the reference.",
        "We use B3sys (Cai and Strube, 2010), a variant of B3 that was shown to penalize both twinless reference chains and spurious system chains more fairly.",
        "Evaluation Corpus The automatic evaluation of cross-lingual coreference systems requires annotated 10Mimno et al. (2009) showed that so long as the proportion of topically-aligned to non-aligned documents exceeded 0.25, the topic distributions (as measured by mean Jensen-Shannon",
        "statistics.",
        "Singleton chains account for 51.4% of the Arabic data and 46.2% of the English data.",
        "Just 216 entities appear in both languages.",
        "multilingual corpora.",
        "Cross-document annotation is expensive (Strassel et al., 2008), so we chose the ACE2008 Arabic-English evaluation corpus as a starting point for cross-lingual annotation.",
        "The corpus consists of seven genres sampled from independent sources over the course of a decade (Tbl.",
        "3).",
        "The corpus provides gold monolingual cross-document coreference annotations for both PER and ORG entities.",
        "Using these annotations as a starting point, we found and annotated 216 cross-lingual entities.11 Because a similar corpus did not exist for development, we split the evaluation corpus into development and test sections.",
        "However, the usual method of splitting by document would not confine all mentions of each entity to one side of the split.",
        "We thus split the corpus by global entity id.",
        "We assigned one-third of the entities to development, and the remaining two-thirds to test."
      ]
    },
    {
      "heading": "6 Comparison to Related Tasks and Work",
      "text": [
        "Our modeling techniques and task formulation can be viewed as cross-lingual extensions to cross-document coreference resolution.",
        "The classic work on this task was by Bagga and Baldwin (1998b), who adapted the Vector Space Model (VSM) (Salton et al., 1975).",
        "Gooi and Allan (2004) found effective algorithmic extensions like agglomerative clustering.",
        "Successful feature extensions to the VSM for cross-document coreference have included biographical information (Mann and Yarowsky, 2003) and syntactic context (Chen and Martin, 2007).",
        "However, neither of these feature sets generalize easily to the cross-lingual setting with multiple entity types.",
        "Fleischman and Hovy (2004) added a discriminative pairwise mention classifier to a VSM-like model, much as we do.",
        "More 11The annotators were the first author and another fluent speaker of Arabic.",
        "The annotations, corrections, and corpus split are available at http://www.spencegreen.com/research/.",
        "recent work has considered new models for web-scale corpora (Rao et al., 2010; Singh et al., 2011).",
        "Cross-document work on languages other than English is scarce.",
        "Wang (2005) used a combination of the VSM and heuristic feature selection strategies to cluster transliterated Chinese personal names.",
        "For Arabic, Magdy et al. (2007) started with the output of the mention detection and within-document coreference system of Florian et al. (2004).",
        "They clustered the entities incrementally using a binary classifier.",
        "Baron and Freedman (2008) used complete-link agglomerative clustering, wheremerging decisions were based on a variety of features such as document topic and name uniqueness.",
        "Finally, Sayeed et al. (2009) translated Arabic name mentions to English and then formed clusters greedily using pairwise matching.",
        "To our knowledge, the cross-lingual entity clustering task is novel.",
        "However, there is significant prior work on similar tasks: ?",
        "Multilingual coreference resolution: Adapt English within-document coreference models to other languages (Harabagiu andMaiorano, 2000; Florian et al., 2004; Luo and Zitouni, 2005).",
        "?",
        "Named entity translation: For a non-English document, produce an inventory of entities in English.",
        "An ACE2007 pilot task (Song and Strassel, 2008).",
        "?",
        "Named entity clustering: Assign semantic types to text mentions (Collins and Singer, 1999; Elsner et al., 2009).",
        "?",
        "Cross-language name search / entity linking: Match a single query name against a list of known multilingual names (knowledge base).",
        "A track in the 2011NIST Text Analysis Conference (TAC-KBP) evaluation (Aktolga et al., 2008; McCarley, 2009; Udupa and Khapra, 2010; Mc-Namee et al., 2011).",
        "Our work incorporates elements of the first three tasks.",
        "Most importantly, we avoid the key element of entity linking: a knowledge base."
      ]
    },
    {
      "heading": "7 Experiments",
      "text": [
        "We performed intrinsic evaluations for both mention and context similarity.",
        "For context similarity, we analyzed monolingual entity clustering, which also facilitated comparison to prior work on the ACE2008",
        "The training data contains names from three genres: broadcast news (bn), newswire (nw), and weblog (wb).",
        "We used the full training corpus (all) for the cross-lingual clustering experiments, but the model achieved high accuracy with significantly fewer training examples (e.g., bn).",
        "set, gold within-document processing).",
        "Higher scores (?)",
        "are better for CEAF and B3, whereas lower (?)",
        "is better for NVI.",
        "#gold indicates the number of reference entities, whereas #hyp is the size of E. evaluation set.",
        "Our main results are for the new task: cross-lingual entity clustering."
      ]
    },
    {
      "heading": "7.1 Intrinsic Evaluations Cross-lingual Mention Matching We created a",
      "text": [
        "random 80/10/10 (train, development, test) split of the Maxent training corpus and evaluated binary classification accuracy (Tbl.",
        "4).",
        "Of the misclassified examples, we observed three major error types.",
        "First, the model learns that high edit distance is predictive of a mismatch.",
        "However, singleton strings that do not match often have a lower edit distance than longer strings that do match.",
        "As a result, singletons often cause false positives.",
        "Second, names that originate in a third language tend to violate the phonemic correspondences.",
        "For example, the model gives a false negative for a German football team: ?QK??",
        "?P Q ?",
        "?",
        "??",
        "?",
        "@ (phonetic mapping: af s kazrslawtrn) versus ?FC Kaiserslautern.?",
        "Finally, names that require translation are problematic.",
        "For example, the classifier produces a false negative for ?God, gd?"
      ]
    },
    {
      "heading": "3 metric",
      "text": [
        "applied to the subset of target cross-lingual entities in the test set.",
        "For CEAF and B3, Singleton is the stronger baseline due to the high proportion of singleton entities in the corpus.",
        "Of course, cross-lingual entities have at least two chains, so No-context is a better baseline for cross-lingual clustering."
      ]
    },
    {
      "heading": "Mono-lingual Entity Clustering For comparison,",
      "text": [
        "we also evaluated our system on a standard monolingual cross-document coreference task (Arabic and English) (Tbl.",
        "5).",
        "We configured the system with HAC clustering and Jaro-Winkler (within-language) mention similarity.",
        "We built monolingual ELMs for context similarity.",
        "We used two baselines: ?",
        "Singleton: E = C, i.e., the cross-lingual clustering solution is just the set of monolingual coreference chains.",
        "This is a common baseline for monolingual entity clustering (Baron and Freedman, 2008).",
        "?",
        "No-context: We run HAC with ?",
        "=?.",
        "Therefore, E is the set of fully-connected components in C subject to the pairwise constraints.",
        "For HAC, we manually tuned the stop threshold ?, the Jaro-Winkler threshold ?, and the ELM smoothing parameter ?",
        "on the development set.",
        "For the DPMM, no development tuning was necessary, and we evaluated a single sample of E taken after 3,000 iterations.",
        "To our knowledge, Baron and Freedman (2008) reported the only previous results on the ACE2008 data set.",
        "However, they only gave gold results for English, and clustered the entire evaluation corpus (test+development).",
        "To control for the effect of within-document errors, we considered their gold input (mention detection and within-document coreference resolution) results.",
        "They reported B3 for the two entity types separately: ORG (91.5% F1) and PER (94.3% F1).",
        "The different experimental designs preclude a precise comparison, but the accuracy of",
        "(Serif) within-document processing).",
        "For HAC, we used the same parameters as the gold setting.",
        "the two systems are at least in the same range."
      ]
    },
    {
      "heading": "7.2 Cross-lingual Entity Clustering",
      "text": [
        "We evaluated four system configurations on the new task: HAC+MT, HAC+PLTM, DPMM+MT, and DPMM+PLTM.",
        "First, we established an upper bound by assuming gold within-document mention detection and coreference resolution (Tbl.",
        "6).",
        "This setting isolated the new cross-lingual clustering methods from within-document processing errors.",
        "Then we evaluated with Serif (automatic) within-document processing (Tbl.",
        "7).",
        "This second experiment replicated an application setting.",
        "We used the same baselines and tuning procedures as in the monolingual clustering experiment.",
        "Results In the gold setting, HAC+MTproduces the best results, as expected.",
        "The dimensionality reduction of the vocabulary imposed by PLTM significantly reduces accuracy, but HAC+PLTM still exceeds the",
        "baseline.",
        "We tried increasing the number of PLTM topics k, but did not observe an improvement in task accuracy.",
        "For both context-mapping methods, the DPMM suffers from low-recall.",
        "Upon inspection, the clustering solution of DPMM+MT contains a high proportion of singleton hypotheses, suggesting that the model finds lower similarity in the presence of a larger vocabulary.",
        "When the context vocabulary consists of PLTM topics, larger clusters are discovered (DPMM+PLTM).",
        "The effect of dimensionality reduction is also apparent in the clustering solutions of the PLTM models.",
        "For example, for the Serif output, DPMM+PLTM produces a cluster consisting of ?White House?, ?Senate?, ?House of Representatives?, and ?Parliament?.",
        "Arabic mentions of the latter three entities pass the pairwise mention similarity constraints due to the word ??m.?",
        "?council?, which appears in text mentions for all three legislative bodies.",
        "A cross-language matching error resulted in the linking of ?White House?, and the reduced granularity of the contexts precluded further disambiguation.",
        "Of course, these entities probably appear in similar contexts.",
        "The caveat with the Serif results in Tbl.",
        "7 is that 3,251 of the 7,655 automatic coreference chains are not in the reference.",
        "Consequently, the evaluation is dominated by the penalty for spurious system coreference chains.",
        "Nonetheless, all models except for DPMM+PLTM exceed the baselines, and the relationships between models depicted in the gold experiments hold for the this setting."
      ]
    },
    {
      "heading": "8 Conclusion",
      "text": [
        "Cross-lingual entity clustering is a natural step toward more robust natural language understanding.",
        "We proposed pipeline models that make clustering decisions based on cross-lingual similarity.",
        "We investigated two methods for mapping documents in different languages to a common representation: MT and the PLTM.",
        "Although MT may achieve more accurate results for some language pairs, the PLTM training resources (e.g., Wikipedia) are readily available for many languages.",
        "As for the clustering algorithms, HAC appears to perform better than the DPMM on our dataset, but this may be due to the small corpus size.",
        "The instance-level constraints represent tendencies that could be learned from larger amounts of data.",
        "With more data, we might be able to relax the constraints and use an exchangeable DPMM,whichmight be more effective.",
        "Finally, we have shown that significant quantities of within-document errors cascade into the cross-lingual clustering phase.",
        "As a result, we plan a model that clusters the mentions directly, thus removing the dependence on within-document coreference resolution.",
        "In this paper, we have set baselines and proposed models that significantly exceeded those baselines.",
        "The best model improved upon the cross-lingual entity baseline by 24.3% F1.",
        "This result was achieved without a knowledge base, which is required by previous approaches to cross-lingual entity linking.",
        "More importantly, our techniques can be used to extend existing cross-document entity clustering systems for the increasingly multilingual web.",
        "AcknowledgmentsWe thank Jason Eisner, David Mimno, Scott Miller, Jim Mayfield, and Paul McNamee for helpful discussions.",
        "This work was started during the SCALE 2010 summer workshop at Johns Hopkins.",
        "The first author is supported by a National Science Foundation Graduate Fellowship."
      ]
    }
  ]
}
