{
  "info": {
    "authors": [
      "Xiaoqiang Luo"
    ],
    "book": "Human Language Technology Conference and Empirical Methods in Natural Language Processing",
    "id": "acl-H05-1004",
    "title": "On Coreference Resolution Performance Metrics",
    "url": "https://aclweb.org/anthology/H05-1004",
    "year": 2005
  },
  "references": [
    "acl-M95-1005",
    "acl-P04-1018"
  ],
  "sections": [
    {
      "heading": "Abstract",
      "text": [
        "The paper proposes a Constrained Entity-Alignment F-Measure (CEAF) for evaluating coreference resolution.",
        "The metric is computed by aligning reference and system entities (or coreference chains) with the constraint that a system (reference) entity is aligned with at most one reference (system) entity.",
        "We show that the best alignment is a maximum bipartite matching problem which can be solved by the Kuhn-Munkres algorithm.",
        "Comparative experiments are conducted to show that the widely-known MUC F-measure has serious flaws in evaluating a coreference system.",
        "The proposed metric is also compared with the ACE-Value, the official evaluation metric in the Automatic Content Extraction (ACE) task, and we conclude that the proposed metric possesses some properties such as symmetry and better inter-pretability missing in the ACE-Value."
      ]
    },
    {
      "heading": "1 Introduction",
      "text": [
        "A working definition of coreference resolution is partitioning the noun phrases we are interested in into equivalence classes, each of which refers to a physical entity.",
        "We adopt the terminologies used in the Automatic Content Extraction (ACE) task (NIST, 2003a) and call each individual phrase a mention and equivalence class an entity.",
        "For example, in the following text segment, (1): “The American Medical Association voted yesterday to install the heir apparent as its president-elect, rejecting a strong, upstart challenge by a district doctor who argued that the nation’s largest physicians’ group needs stronger ethics and new leadership.” mentions are underlined, “American Medical Association”, “its” and “group” refer to the same organization (object) and they form an entity.",
        "Similarly, “the heir apparent” and “president-elect” refer to the same person and they form another entity.",
        "It is worth pointing out that the entity definition here is different from what used in the Message Understanding Conference (MUC) task (MUC, 1995; MUC, 1998) – ACE entity is called coreference chain or equivalence class in MUC, and ACE mention is called entity in MUC.",
        "An important problem in coreference resolution is how to evaluate a system’s performance.",
        "A good performance metric should have the following two properties:",
        "• Discriminativity: This refers to the ability to differentiate a good system from a bad one.",
        "While this criterion sounds trivial, not all performance metrics used in the past possess this property.",
        "• Interpretability: A good metric should be easy to interpret.",
        "That is, there should be an intuitive sense of how good a system is when a metric suggests that a certain percentage of coreference results are correct.",
        "For example, when a metric reports ✁✂☎ or above correct for a system, we would expect that the vast majority of mentions are in right entities or coreference chains.",
        "A widely-used metric is the link-based F-measure (Vi-lain et al., 1995) adopted in the MUC task.",
        "It is computed by first counting the number of common links between the reference (or “truth”) and the system output (or “response”); the link precision is the number of common links divided by the number of links in the system output, and the link recall is the number of common links divided by the number of links in the reference.",
        "There are known problems associated with the link-based F-measure.",
        "First, it ignores single-mention entities since no link can be found in these entities; Second, and more importantly, it fails to distinguish system outputs with different qualities: the link-based F-measure intrinsically favors systems producing fewer entities, and may result in higher F-measures for worse systems.",
        "We will revisit these issues in Section 3.",
        "To counter these shortcomings, Bagga and Baldwin (1998) proposed a B-cubed metric, which first computes a precision and recall for each individual mention, and then takes the weighted sum of these individual precisions and recalls as the final metric.",
        "While the B-cubed metric fixes some of the shortcomings of the MUC F-measure, it has its own problems: for example, the mention precision/recall is computed by comparing entities containing the mention and therefore an entity can be used more than once.",
        "The implication of this drawback will be revisited in Section 3.",
        "In the ACE task, a value-based metric called ACE-value (NIST, 2003b) is used.",
        "The ACE-value is computed by counting the number of false-alarm, the number of miss, and the number of mistaken entities.",
        "Each error is associated with a cost factor that depends on things such as entity type (e.g., “LOCATION”, “PERSON”), and mention level (e.g., “NAME,” “NOMINAL,” and “PRONOUN”).",
        "The total cost is the sum of the three costs, which is then normalized against the cost of a nominal system that does not output any entity.",
        "The ACE-value is finally computed by subtracting the normalized cost from 1.",
        "A perfect coreference system will get a 100% ACE-value while a system outputs no entities will get a 0 ACE-value.",
        "A system outputting many erroneous entities could even get negative ACE-value.",
        "The ACE-value is computed by aligning entities and thus avoids the problems of the MUC F-measure.",
        "The ACE-value is, however, hard to interpret: a system with 90% ACE-value does not mean that 90% of system entities or mentions are correct, but that the cost of the system, relative to the one outputting no entity, is 10%.",
        "In this paper, we aim to develop an evaluation metric that is able to measure the quality of a coreference system – that is, an intuitively better system would get a higher score than a worse system, and is easy to interpret.",
        "To this end, we observe that coreference systems are to recognize entities and propose a metric called Constrained Entity-Aligned F-Measure (CEAF).",
        "At the core of the metric is the optimal one-to-one map between subsets of reference and system entities: system entities and reference entities are aligned by maximizing the total entity similarity under the constraint that a reference entity is aligned with at most one system entity, and vice versa.",
        "Once the total similarity is defined, it is straightforward to compute recall, precision and F-measure.",
        "The constraint imposed in the entity alignment makes it impossible to “cheat” the metric: a system outputting too many entities will be penalized in precision while a system outputting two few entities will be penalized in recall.",
        "It also has the property that a perfect system gets an F-measure 1 while a system outputting no entity or no common mentions gets an F-measure 0.",
        "The proposed CEAF has a clear meaning: for mention-based CEAF, it reflects the percentage of mentions that are in the correct entities; For entity-based CEAF, it reflects the percentage of correctly recognized entities.",
        "The rest of the paper is organized as follows.",
        "In Section 2, the Constrained Entity-Alignment F-Measure is presented in detail: the constraint entity alignment can be represented by a bipartite graph and the optimal alignment can be found by the Kuhn-Munkres algorithm (Kuhn, 1955; Munkres, 1957).",
        "We also present two entity-pair similarity measures that can be used in CEAF: one is the absolute number of common mentions between two entities, and the other is a “local” mention F-measure between two entities.",
        "The two measures lead to the mention-based and entity-based CEAF, respectively.",
        "In Section 3, we compare the proposed metric with the MUC link-based metric and ACE-value on both artificial and real data, and point out the problems of the MUC F-measure."
      ]
    },
    {
      "heading": "2 Constrained Entity-Alignment F-Measure",
      "text": [
        "Some notations are needed before we present the proposed metric and the algorithm to compute the metric.",
        "Let reference entities in a document d be",
        "and system entities be",
        "To simplify typesetting, we will omit the dependency on d, when it is clear from context, and write R(d,) as R and S(d) as S. Let",
        "and let R7Z c R and Sn,, c S be any subsets with m entities.",
        "That is, R,,,, I = m and IS, I = m. Let G(R,,,,, Ste,) be the set of one-to-one entity maps from 7Z,,, to S,,,, and G, be the set of all possible one-to-one maps between the size-m subsets of R and S. Or",
        "The requirement of one-to-one map means that for any 9 E G(R,,,,, 5,,,,), and any R E R,,,, and R' E R,,,,, we have that R A R' implies that g (R) A g (R'), and g (R) A g (R') implies that R A R. Clearly, there are m!",
        "one-to-one maps from R,n, to <S7Z (or IG(7Z ,,Sm,)I = m!",
        "), and IG,,,,I = (\",')m!.",
        "Let 6 (R, S) be a “similarity” measure between two entities R and S. 6(R, S) takes non-negative value: zero",
        "value means that R and S have nothing in common.",
        "For example, 6(R, S) could be the number of common mentions shared by R and S, and 6 (R, R) the number of mentions in entity R. For any g E G,,,, the total similarity (D(g) for a map ,g is the sum of similarities between the aligned entity pairs:",
        "its reference entities R and system entities S, we can find the best alignment maximizing the total similarity:",
        "Let R* and S* = ,g* (7Z* ) denote the reference and system entity subsets where ,g* is attained, respectively.",
        "Then the maximum total similarity is",
        "If we insist that 6(R, S) = 0 whenever R or S is empty, then the non-negativity requirement of O(R, S) makes it unnecessary to consider the possibility of mapping one entity to an empty entity since the one-to-one map maximizing (D (g) must be in G,,,,.",
        "Since we can compute the entity self-similarity 6(R, R) and 6(S, S) for any R E R and S E S (i.e., using the identity map), we are now ready to define the precision, recall and F-measure as follows: The optimal alignment g* involves only m = min{IR1, IS I reference and system entities, and entities not aligned do not get credit.",
        "Thus the F-measure (5) penalizes a coreference system that proposes too many (i.e., lower precision) or too few entities (i.e., lower recall), which is a desired property.",
        "In the above discussion, it is assumed that the similarity measure 6(R, S) is computed for all entity pair (R, S).",
        "In practice, computation of 6(R, S) can be avoided if it is clear that R and S have nothing in common (e.g., if no mention in R and S overlaps, then 6, (R, S) _ 0).",
        "These entity pairs are not linked and they will not be considered when searching for the optimal alignment.",
        "Consequently the optimal alignment could involve less than m reference and system entities.",
        "This can speed up considerably the F-measure computation when the majority of entity pairs have zero similarity.",
        "Nevertheless, summing over m entity pairs in the general formulae (2) does not change the optimal total similarity between R and S and hence the F-measure.",
        "In formulae (3)-(5), there is only one document in the test corpus.",
        "Extension to corpus with multiple test documents is trivial: just accumulate statistics on the per-document basis for both denominators and numerators in (3) and (4), and find the ratio of the two.",
        "So far, we have tacitly kept abstract the similarity measure 6(R, S) for entity pair R and S. We will defer the discussion of this metric to Section 2.2.",
        "Instead, we first present the algorithm computing the F-measure (3)-(5)."
      ]
    },
    {
      "heading": "2.1 Computing Optimal Alignment and F-measure",
      "text": [
        "A naive implementation of (1) would enumerate all the possible one-to-one maps (or alignments) between size-m (recall that m = min {IR1, 1511) subsets of R and size-m subsets of S, and find the best alignment maximizing the similarity.",
        "Since this requires computing the similarities between mM entity pairs and there are G, I _ (m7) m!",
        "possible one-to-one maps, the complexity of this implementation is O(Mm + (m) m!).",
        "This is not satisfactory even for a document with a moderate number of entities: it will have about 3.6 million operations for M = m = 10, a document with only 10 reference and 10 system entities.",
        "Fortunately, the entity alignment problem under the constraint that an entity can be aligned at most once is the classical maximum bipartite matching problem and there exists an algorithm (Kuhn, 1955; Munkres, 1957) (henceforth Kuhn-Munkres Algorithm) that can find the optimal solution in polynomial time.",
        "Casting the entity alignment problem as the maximum bipartite matching is trivial: each entity in R and S is a vertex and the node pair (R, S), where R E R, S E S, is connected by an edge with the weight 6(R, S).",
        "Thus the problem (1) is exactly the maximum bipartite matching.",
        "With the Kuhn-Munkres algorithm, the procedure to compute the F-measure (5) can be described as Algorithm 1.",
        "Algorithm 1 Computing the F-measure (5).",
        "Input: reference entities:R; system entities: S Output: optimal alignment ,g*; F-measure (5).",
        "8:return g* and F. The input to the algorithm are reference entities R and system entities S. The algorithm returns the best one-to",
        "one map g* and F-measure in equation (5).",
        "Loop from line 2 to 4 computes the similarity between all the possible reference and system entity pairs.",
        "The complexity of this loop is O(Mm).",
        "Line 5 calls the Kuhn-Munkres algorithm, which takes as input the entity-pair scores {6(R, S)} and outputs the best map ,g* and the corresponding total similarity (D(g*).",
        "The worst case (i.e., when all entries in {6(R, S)} are non-zeros) complexity of the Kuhn-Algorithm is O(Mm2 log m).",
        "Line 6 computes “self-similarity” (D (R) and (D (S) needed in the F-measure computation at Line 7.",
        "The core of the F-measure computation is the Kuhn-Munkres algorithm at line 5.",
        "The algorithm is initially discovered by Kuhn (1955) and Munkres (1957) to solve the matching (a.k.a assignment) problem for square matrices.",
        "Since then, it has been extended to rectangular matrices (Bourgeois and Lassalle, 1971) and parallelized (Balas et al., 1991).",
        "A recent review can be found in (Gupta and Ying, 1999), which also details the techniques of fast implementation.",
        "A short description of the algorithm is included in Appendix for the sake of completeness."
      ]
    },
    {
      "heading": "2.2 Entity Similarity Metric",
      "text": [
        "In this section we consider the entity similarity metric 6(R, S) defined on an entity pair (R, S).",
        "It is desirable that 6(R, S) is large when R and S are “close” and small when R and S are very different.",
        "Some straightforward choices could be",
        "(6) insists that two entity are the same if all the mentions are the same, while (7) goes to the other extreme: two entities are the same if they share at least one common mention.",
        "(6) does not offer a good granularity of similarity: For",
        "lacks of the desired discriminativity as well.",
        "From the above argument, it is clear that we want to have a metric that can measure the degree to which two entities are similar, not a binary decision.",
        "One natural choice is measuring how many common mentions two entities share, and this can be measured by the absolute number or relative number:",
        "Metric (8) simply counts the number of common mentions shared by R and S, while (9) is the mention F-measure between R and S, a relative number measuring how similar R and S are.",
        "For the abovementioned example,",
        "ber of total common mentions corresponding to the best one-to-one map ,g* while the denominators of (3) and (4) are the number of proposed mentions and the number of system mentions, respectively.",
        "The F-measure in (5) can be interpreted as the ratio of mentions that are in the “right” entities.",
        "Similarly, if c64(-, -) is adopted in Algorithm 1, the denominators of (3) and (4) are the number of proposed entities and the number of system entities, respectively, and the F-measure in (5) can be understood as the ratio of correct entities.",
        "Therefore, (5) is called mention-based CEAF and entity-based CEAF when (8) and (9) are used, respectively.",
        "63 (-, -) and 64 (-, -) are two reasonable entity similarity measures, but by no means the only choices.",
        "At mention level, partial credit could be assigned to two mentions with different but overlapping spans; or when mention type is available, weights defined on the type confusion matrix can be incorporated.",
        "At entity level, entity attributes, if avaiable, can be weighted in the similarity measure as well.",
        "For example, ACE data defines three entity classes: NAME, NOMINAL and PRONOUN.",
        "Different weights can be assigned to the three classes.",
        "No matter what entity similarity measure is used, it is crucial to have the constraint that the document-level similarity between reference entities and system entities is calculated over the best one-to-one map.",
        "We will see examples in Section 3 that misleading results could be produced without the alignment constraint.",
        "Another observation is that the same evaluation paradigm can be used in any scenario that needs to measure the “closeness” between a set of system and reference objects, provided that a similarity between two objects is defined.",
        "For example, the 2004 ACE tasks include detecting and recognizing relations in text documents.",
        "A relation instance can be treated as an object and the same evaluation paradigm can be applied."
      ]
    },
    {
      "heading": "3 Comparison with Other Metrics",
      "text": [
        "In this section, we compare the proposed F-measure with the MUC link-based F-measure (and its variation B-cube F-measure) and the more recent ACE-value.",
        "The",
        "proposed metric has fixed problems associated with the MUC and B-cube F-measure, and has better interpretabil-ity than the ACE-value."
      ]
    },
    {
      "heading": "3.1 Comparison with the MUC F-measure and B-cube Metric on Artificial Data",
      "text": [
        "We use the example in Figure 1 to compare the MUC link-based F-measure, B-cube, and the proposed mention and entity-based CEAF.",
        "In Figure 1, mentions are represented in circles and mentions in an entity are connected by arrows.",
        "Intuitively, if each mention is treated equally, the system response (a) is better than the system response (b) since the latter mixes two big entities, {1, 2, 3, 4, 51 and {8, 9, A, B, C }, while the former mixes a small entity {6, 71 with one big entity {8, 9, A, B, C }.",
        "System response (b) is clearly better than system response (c) since the latter puts all the mentions into a single entity while (b) has correctly separated the entity {6, 71 from the rest.",
        "The system response (d) is the worst: the system does not link any mentions and outputs 12 single-mention entities.",
        "Table 1 summarizes various F-measures for system response (a) to (d): the first column contains the indices of the system responses found in Figure 1; the second and third columns are the MUC F-measure and B-cubic F-measure respectively; the last two columns are the proposed CEAF F-measures, using the entity similarity metric 2 (-, -) and 64 (-, -), respectively.",
        "As shown in Table 1, the MUC link-based F-measure fails to distinguish the system response (a) and the system response (b) as the two are assigned the same F-measure.",
        "The system response (c) represents a trivial output: all mentions are put in the same entity.",
        "Yet the MUC metric will lead to a 100% recall (9 out of 9 reference links are",
        "are correct), which gives rise to a 90% F-measure.",
        "It is striking that a “bad” system response gets such a high F-measure.",
        "Another problem with the MUC link-based metric is that it is not able to handle single-mention entities, as there is no link for a single mention entity.",
        "That is why the entry for system response (d) in Table 1 is empty.",
        "B-cube F-measure ranks the four system responses in Table 1 as desired.",
        "This is because B-cube metric (Bagga and Baldwin, 1998) is computed based on mentions (as opposed to links in the MUC F-measure).",
        "But B-cube uses the same entity “intersecting” procedure found in computing the MUC F-measure (Vi-lain et al., 1995), and it sometimes can give counterintuitive results.",
        "To see this, let us take a look at recall and precision for system response (c) and (d) for B-cube metric.",
        "Notice that all the reference entities are found after intersecting with the system responsce",
        "intuitive because the set of reference entities is not a subset of the proposed entities, thus the system response should not have gotten a 100% recall.",
        "The same problem exists for the system response (d): it gets a 100% B-cube precision (the corresponding B-cube recall is 12 (5 * 5 + 2 * 2 + 5 * 5) = 0.25), but clearly not all the entities in the system response (d) are correct!",
        "These numebrs are summarized in Table 2, where columns with R and P represent recall and precision, respectively.",
        "precision: system repsonse (c) gets 100% recall (column R) while system repsonse (d) gets 100% precision (column P).",
        "The problem is fixed in both CEAF metrics.",
        "The counter-intuitive results associated with the MUC and B-cube F-measures are rooted in the procedure of “intersecting” the reference and system entities, which allows an entity to be used more than once!",
        "We will come back to this after discussing the CEAF numbers.",
        "From Table 1, we see that both mention-based ( col",
        "umn under 63(-, -)) CEAF and entity-based 04(•, •)) CEAF are able to rank the four systems properly: system (a) to (d) are increasingly worse.",
        "To see how the CEAF numbers are computed, let us take the system response (a) as an example: first, the best one-one entity map is determined.",
        "In this case, the best map is: the reference entity {1, 2, 3, 4, 51 is aligned to the system entity {1, 2, 3, 4, 5}, the reference entity {8, 9, A, B, C } is aligned to the system {6, 7, 8, 9, A, B, C } and the reference entity {6, 71 is unaligned.",
        "The number of common mentions is therefore 10 which results in a mention-based 03(-,-)) recall 5 and precision",
        "CEAF recall and precision breakdown for system (c) and (d) are listed in column 4 through 7 of Table 1.",
        "As can be seen, neither mention-based nor entity-based CEAF has the abovementioned problem associated with the B-cube metric, and the recall and precision numbers are more or less compatible with our intuition: for instance, for system (c), based on 03-CEAF number, we can say that about 41.7°x, mentions are in the right entity, and based on the 64-CEAF recall and precision, we can state that about 19.6% of “true” entities are recovered (recall) and about 58.8% of the proposed entities are correct.",
        "A comparison of the procedures of computing the MUC F-measure/B-cube and CEAF reveals that the crucial difference is that the MUC and B-cube F-measure allow an entity to be used multiple times while CEAF insists that entity map be one-to-one.",
        "So an entity will never get double credit.",
        "Take the system repsonse (c) as an example, intersecting three reference entity in turn with the reference entities produces the same set of reference entities, which leads to 100% recall.",
        "In the intersection step, the system entity is effectively used three times.",
        "In contrast, the system entity is aligned to only one reference entity when computing CEAF."
      ]
    },
    {
      "heading": "3.2 Comparisons On Real Data 3.2.1 MUC F-measure and CEAF",
      "text": [
        "We have seen the different behaviors of the MUC F-measure, B-cube F-measure and CEAF on the artificial data.",
        "We now compare the MUC F-measure, CEAF, and ACE-value metrics on real data (compasion between the MUC and B-cube F-measure can be found in (Bagga and Baldwin, 1998)).",
        "Comparsion between the MUC F-measure and CEAF is done on the MUC6 coreference test set, while comparison between the CEAF and ACE-value is done on the 2004 ACE data.",
        "The setup reflects the fact that the official MUC scorer and ACE scorer run on their own data format and are not easily portable to the other data set.",
        "All the experiments in this section are done on true mentions.",
        "the official MUC6 test set.",
        "The first column contains the penalty value in decreasing order.",
        "The second column contains the number of system-proposed entities.",
        "The column under MUC-F is the MUC F-measure while 03- CEAF is the mention-based CEAF.",
        "The coreference system is similar to the one used in (Luo et al., 2004).",
        "Results in Table 3 are produced by a system trained on the MUC6 training data and tested on the 30 official MUC6 test documents.",
        "The test set contains 460 reference entities.",
        "The coreference system uses a penalty parameter to balance miss and false alarm errors: the smaller the parameter, the fewer entities will be generated.",
        "We vary the parameter from 0.6 to 10, listed in the first column of Table 3, and compare the system performance measured by the MUC F-measure and the proposed mention-based CEAF.",
        "As can be seen, the mention-based CEAF has a clear maximum when the number of proposed entities is close to the truth: at the penlaty value 1.2, the system produces 483 entities, very close to 460, and the 653-CEAF achieves the maximum 0.768.",
        "In contrast, the MUC F-measure increases almost monotonically as the system proposes fewer and fewer entities.",
        "In fact, the best system according to the MUC F-measure is the one proposing only 113 entities.",
        "This demonstrates a fundamental flaw of the MUC F-measure: the metric intrinsically favors a system producing fewer entities and therefore lacks of discriminativity.",
        "CEAF.",
        "The first column contains the penalty value in decreasing order.",
        "The second column contains the number of system-proposed entities.",
        "ACE-values are in percentage.",
        "The number of reference entities is 853. when the penalty value is 0.2 and CEAF is maximum when the penalty value is 0.8.",
        "However, the optimal CEAF system produces 930 entities while the optimal ACE-value system produces 1050 entities.",
        "Judging from the number of entities, the optimal CEAF system is closer to the “truth” than the counterpart of ACE-value.",
        "This is not very surprising since ACE-value is a weighted metric while CEAF treats each mention and entity equally.",
        "As such, the two metrics have very weak correlation.",
        "While we can make a statement such as “the system with penalty 0.8 puts about 79.4% mentions in right entities”, it is hard to interpret the ACE-value numbers.",
        "Another difference is that CEAF is symmetric1, but ACE-Value is not.",
        "Symmetry is a desirable property.",
        "For example, when comparing inter-annotator agreement, a symmetric metric is independent of the order of two sets of input documents, while an asymmetric metric such as ACE-Value needs to state the input order along with the metric value."
      ]
    },
    {
      "heading": "4 Conclusions",
      "text": [
        "A coreference performance metric – CEAF – is proposed in this paper.",
        "The CEAF metric is computed based on the best one-to-one map between reference entities and system entities.",
        "Finding the best one-to-one map is a maximum bipartite matching problem and can be solved by the Kuhn-Munkres algorithm.",
        "Two example entity-pair similarity measures (i.e., 03(-, -) and 64(-, -)) are proposed, resulting one mention-based CEAF and one entity-based CEAF, respectively.",
        "It has been shown that the proposed CEAF metric has fixed problems associated with the MUC link-based F-measure and B-cube F-measure.",
        "1 This was pointed out by Nanda Kambhatla.",
        "The proposed metric also has better interpretability than ACE-value."
      ]
    },
    {
      "heading": "Acknowledgments",
      "text": [
        "This work was partially supported by the Defense Advanced Research Projects Agency and monitored by SPAWAR under contract No. N66001-99-2-8916.",
        "The views and findings contained in this material are those of the authors and do not necessarily reflect the position of policy of the Government and no official endorsement should be inferred.",
        "The author would like to thank three reviewers and my colleagues, Hongyan Jing and Salim Roukos, for suggestions of improving the paper."
      ]
    },
    {
      "heading": "Appendix: Kuhn-Munkres Algorithm",
      "text": [
        "Let i index the reference entities R and ,j index the system entities S, and 6(i, j) be the similarity between the ith reference entity and the jth system entity.",
        "Algebraically, the maximum bipartite matching can be stated as an integer programming problem: max 6(i, g )xzj",
        "If xzj = 1, the ith reference entity and the /h system entity are aligned.",
        "Constraint (11) (or (12)) implies that a reference (or system) entity cannot be aligned more than once with a system (or reference) entity.",
        "Observe that the coefficients of (11) and (12) are uni-modular.",
        "Thus, Constraint (13) can be replaced by .xzj > 0,Vi, j.",
        "(14) The dual (cf. pp.",
        "219 of (Fletcher, 1987)) to the optimization problem (10) with constraints (11),(12) and (14) is:",
        "The dual has the same optimal objective value as the primal.",
        "It can be shown that the optimal conditions for the dual problem (and hence the maximum similarity match) are: vj = 0, if j is free.",
        "(21) The Kuhn-Munkres algorithm starts with an empty match and an initial feasible set of {uz} and {vj}, and iteratively increases the cardinality of the match while satisfying the optimal conditions (19)-(21).",
        "Notice that conceptually, a matching problem with a rectangular matrix [6(i, j)] can always reduce to a square one by padding zeros (this is not necessary in practice, see, for instance (Bourgeois and Lassalle, 1971)).",
        "For this reason, we state the Kuhn-Munkres algorithm for the case where 17Z I = IS I (or M = m) in Algorithm 2.",
        "The proof of correctness is omitted due to space limit.",
        "Note that Pa,,,,9 (i, j) on line 9 stands for the augmenting (i.e., a free node followed by an aligned node, followed by a free node, ...) path from i to j in the corresponding bipartite graph.",
        "A+ P,,,,,,g (i, j) is understood as"
      ]
    }
  ]
}
