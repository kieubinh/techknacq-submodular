{
  "info": {
    "authors": [
      "Jinxiu Chen",
      "Ji Donghong",
      "Chew Lim Tan",
      "Zhengyu Niu"
    ],
    "book": "Second International Joint Conference on Natural Language Processing: Companion Volume including Posters/Demos and tutorial abstracts",
    "id": "acl-I05-2045",
    "title": "Unsupervised Feature Selection for Relation Extraction",
    "url": "https://aclweb.org/anthology/I05-2045",
    "year": 2005
  },
  "references": [
    "acl-P03-1029",
    "acl-P04-1053",
    "acl-P97-1009",
    "acl-W02-1010"
  ],
  "sections": [
    {
      "heading": "Abstract",
      "text": [
        "This paper presents an unsupervised relation extraction algorithm, which induces relations between entity pairs by grouping them into a “natural” number of clusters based on the similarity of their contexts.",
        "Stability-based criterion is used to automatically estimate the number of clusters.",
        "For removing noisy feature words in clustering procedure, feature selection is conducted by optimizing a trace based criterion subject to some constraint in an unsupervised manner.",
        "After relation clustering procedure, we employ a discriminative category matching (DCM) to find typical and discriminative words to represent different relations.",
        "Experimental results show the effectiveness of our algorithm."
      ]
    },
    {
      "heading": "1 Introduction",
      "text": [
        "Relation extraction is the task of finding relationships between two entities from text contents.",
        "There has been considerable work on supervised learning of relation patterns, using corpora which have been annotated to indicate the information to be extracted (e.g. (Califf and Mooney, 1999; Ze-lenko et al., 2002)).",
        "A range of extraction models have been used, including both symbolic rules and statistical rules such as HMMs or Kernels.",
        "These methods have been particularly successful in some specific domains.",
        "However, manually tagging of large amounts of training data is very time-consuming; furthermore, it is difficult for one extraction system to be ported across different domains.",
        "Due to the limitation of supervised methods, some weakly supervised (or semi-supervised) approaches have been suggested (Brin, 1998; Eugene and Luis, 2000; Sudo et al., 2003).",
        "One common characteristic of these algorithms is that they need to predefine some initial seeds for any particular relation, then bootstrap from the seeds to acquire the relation.",
        "However, it is not easy to select representative seeds for obtaining good results.",
        "Hasegawa, et al.",
        "put forward an unsupervised approach for relation extraction from large text corpora (Hasegawa et al., 2004).",
        "First, they adopted a hierarchical clustering method to cluster the contexts of entity pairs.",
        "Second, after context clustering, they selected the most frequent words in the contexts to represent the relation that holds between the entities.",
        "However, the approach exists its limitation.",
        "Firstly, the similarity threshold for the clusters, like the appropriate number of clusters, is somewhat difficult to predefined.",
        "Secondly, the representative words selected by frequency tends to obscure the clusters.",
        "For solving the above problems, we present a novel unsupervised method based on model order selection and discriminative label identification.",
        "For achieving model order identification, stability-based criterion is used to automatically estimate the number of clusters.",
        "For removing noisy feature words in clustering procedure, feature selection is conducted by optimizing a trace based criterion subject to some constraint in an",
        "unsupervised manner.",
        "Furthermore, after relation clustering, we employ a discriminative category matching (DCM) to find typical and discriminative words to represent different relations types."
      ]
    },
    {
      "heading": "2 Proposed Method",
      "text": [
        "Feature selection for relation extraction is the task of finding important contextual words which will help to discriminate relation types.",
        "Unlike supervised learning, where class labels can guide feature search, in unsupervised learning, it is expected to define a criterion to assess the importance of the feature subsets.",
        "Due to the interplay between feature selection and clustering solution, we should define an objective function to evaluate both feature subset and model order.",
        "In this paper, the model selection capability is achieved by resampling based stability analysis, which has been successfully applied to several unsupervised learning problems (e.g. (Levine and Domany, 2001), (Lange et al., 2002), (Roth and Lange et al., 2003), (Niu et al., 2004)).",
        "We extend the cluster validation strategy further to address both feature selection and model order identification.",
        "Table 1 presents our model selection algorithm.",
        "The objective function MFk k is relevant with both feature subset and model order.",
        "Clustering solution that is stable against resampling will give rise to a local optimum of MFk k, which indicates both important feature subset and the true cluster number."
      ]
    },
    {
      "heading": "2.1 Entropy-based Feature Ranking",
      "text": [
        "Let P = {p1, p2, ...pNl be a set of local context vectors of co-occurrences of entity pair E1 and E2.",
        "Here, the context includes the words occurring between, before and after the entity pair.",
        "Let W = {w1, w2, ..., wml represent all the words occurred in P. To select a subset of important features from W, words are first ranked according to their importance on clustering.",
        "The importance can be assessed by the entropy criterion.",
        "Entropy-based feature ranking is based on the assumption that a feature is irrelevant if the presence of it obscures the separability of data set(Dash et al., 2000).",
        "We assume pn, 1 < n < N, lies in feature space W, and the dimension of feature space is",
        "1.",
        "Collect the contexts of all entity pairs in the document corpus D, namely P; 2.",
        "Rank features using entropy-based method described in section 2.1; 3.",
        "Set the range (Kl, Kh) for the possible number of relation clusters; 4.",
        "Set estimated model order k = Kl; 5.",
        "Conduct feature selection using the algorithm presented in section 2.2; 6.",
        "Record ˆFk,k and the score of the merit of both of them, namely MF,k; 7.",
        "If k < Kh, k = k + 1, go to step 5; otherwise, go to Step 7; 8.",
        "Select k and feature subset ˆFk which maximizes the score of the merit MF,k;",
        "M. Then the similarity between i-th data point pi and j-th data point pj is given by the equation: Si j = exp( – α ∗ Di j), where Dij is the Euclidean distance between pi and pj, and α is a positive constant, its value is – l D 5 , where D is the average distance among the data points.",
        "Then the entropy of data set P with N data points is defined as:",
        "For ranking of features, the importance of each word I(wk) is defined as entropy of the data after discarding feature wk.",
        "It is calculated in this way: remove each word in turn from the feature space and calculate E of the data in the new feature space using the Equation 1.",
        "Based on the observation that a feature is the least important if the removal of it results in minimum E, we can obtain the rankings of the features."
      ]
    },
    {
      "heading": "2.2 Feature Subset Selection and Model Order Identification",
      "text": [
        "In this paper, for each specified cluster number, firstly we perform K-means clustering analysis on each feature subset and adopts a scattering criterion ”Invariant Criterion” to select an optimal feature subset F from the feature subset space.",
        "Here, trace(PW1 PB) is used to compare the cluster quality for different feature subsets 1, which 1trace(P�,1PB) is trace of a matrix which is the sum of its diagonal elements.",
        "PW is the within-cluster scatter",
        "Input: feature subset F, cluster number k, entity pairs set P, and sampling frequency q; Output: the score of the merit of F and k;",
        "1.",
        "With the cluster number k as input, perform k-means clustering analysis on pairs set PF; 2.",
        "Construct connectivity matrix CF,k based on above clustering solution on full pairs set PF; 3.",
        "Use a random predictor ρk to assign uniformly drawn labels to each entity pair in PF; 4.",
        "Construct connectivity matrix CF,pk based on above clustering solution on full pairs set PF; 5.",
        "Construct q sub sets of the full pairs set, by randomly selecting αN of the N original pairs, 0 < α < 1; 6.",
        "For each sub set, perform the clustering analysis in Step 2, 3, 4, and result CµF,k, CµF,pk; 7.",
        "Compute MF, k to evaluate the merit of k using Equation 3; 8.",
        "Return MF,k;",
        "measures the ratio of between-cluster to within-cluster scatter.",
        "The higher the trace (P – 1 WPB), the higher the cluster quality.",
        "To improve searching efficiency, features are first ranked according to their importance.",
        "Assume Wr = { f1, ..., fM} is the sorted feature list.",
        "The task of searching can be seen in the feature subset space: {(f1, ..., fk),1 < k < M}.",
        "Then the selected feature subset F is evaluated with the cluster number using the objective function, which can be formulated as: ˆFk = arg maXF⊆Wr {criterion(F, k)}, subject to coverage(P, F) ≥ T 2.",
        "Here, ˆFk is the optimal feature subset, F and k are the feature subset and the value of cluster number under evaluation, and the criterion is set up based on resampling-based stability, as Table 2 shows.",
        "Let Pµ be a subset sampled from full entity pairs set P with size α|P |(α set as 0.9 in this paper.",
        "), C(Cµ) be |P |x |P|(|Pµ |x |Pµ|) connectivity matrix based on the clustering results on P(Pµ).",
        "Each entry cij(cµ ij) of C(Cµ) is calculated in the following: if the entity pair pi E P(Pµ), pj E P(Pµ) belong to the same cluster, then cij(cµij) equals 1, else 0.",
        "Then the stability is de",
        "tor and m j is the mean vector for j th cluster and (Xj – m j) t is the matrix transpose of the column vector (Xj – mj).",
        "Intuitively, M(Cµ, C) denotes the consistency between the clustering results on Cµ and C. The assumption is that if the cluster number k is actually the “natural” number of relation types, then clustering results on subsets Pµ generated by sampling should be similar to the clustering result on full entity pair set P. Obviously, the above function satisfies 0 < M < 1.",
        "It is noticed that M(Cµ, C) tends to decrease when increasing the value of k. Therefore for avoiding the bias that small value of k is to be selected as cluster number, we use the cluster validity of a random predictor ρk to normalize M(Cµ, C).",
        "The random predictor ρk achieved the stability value by assigning uniformly drawn labels to objects, that is, splitting the data into k clusters randomly.",
        "Furthermore, for each k, we tried q times.",
        "So, in the step 7 of the algorithm of Table 2, the objective function M(Cµ F,k, CF,k) can be normalized as equations 3:",
        "Normalizing M(Cµ, C) by the stability of the random predictor can yield values independent of k. After the number of optimal clusters and the feature subset has been chosen, we adopted the K-means algorithm for the clustering phase.",
        "The output of context clustering is a set of context clusters, each of them is supposed to denote one relation type."
      ]
    },
    {
      "heading": "2.3 Discriminative Feature identification",
      "text": [
        "For labelling each relation type, we use DCM (discriminative category matching) scheme to identify discriminative label, which is also used in document classification (Gabriel et al., 2002) and weights the importance of a feature based on their distribution.",
        "In this scheme, a feature is not important if the feature appears in many clusters and is evenly distributed in these clusters, otherwise it will be assigned higher importance.",
        "To weight a feature fi within a category, we take into account the following information:",
        "• The relative importance of fi within a cluster is defined as: WCi,k = lo2(pf:,k+1), where pfi,k is the",
        "number of those entity pairs which contain feature fi in cluster k. Nk is the total number of term pairs in cluster k.",
        "Here, WCZ,k and CCZ are designed to capture both local information within a cluster and global information about the feature distribution across clusters respectively.",
        "Combining both WCZ,k and CCZ we define the weight WZ,k of fZ in cluster k"
      ]
    },
    {
      "heading": "3 Experiments and Results",
      "text": []
    },
    {
      "heading": "3.1 Data",
      "text": [
        "We constructed three subsets for domains PER-ORG, ORG-GPE and ORG-ORG respectively from ACE corpus3 The details of these subsets are given in Table 3, which are broken down by different relation types.",
        "To verify our proposed method, we only extracted those pairs of entity mentions which have been tagged relation types.",
        "And the relation type tags were used as ground truth classes to evaluate."
      ]
    },
    {
      "heading": "3.2 Evaluation method for clustering result",
      "text": [
        "Since there was no relation type tags for each cluster in our clustering results, we adopted a permutation procedure to assign different relation type tags to only min(jECj,jTCj) clusters, where jECj is the estimated number of clusters, and jTCj is the number of ground truth classes",
        "(relation types).",
        "This procedure aims to find an one-to-one mapping function Q from the TC to EC.",
        "To perform the mapping, we construct a contingency table T, where each entry tZj gives the number of the instances that belong to both the i-th cluster and j-th ground truth class.",
        "Then the mapping procedure can be formulated as:ˆQ =",
        "of the estimated cluster associated with the j-th class.",
        "Given the result of one-to-one mapping, we can define the evaluation measure as follows: Accuracy(P) = EjtΩ(j),j.",
        "Intuitively, it reflects"
      ]
    },
    {
      "heading": "Ei j ti,j",
      "text": [
        "the accuracy of the clustering result."
      ]
    },
    {
      "heading": "3.3 Evaluation method for relation labelling",
      "text": [
        "For evaluation of the relation labeling, we need to explore the relatedness between the identified labels and the predefined relation names.",
        "To do this, we use one information-content based measure (Lin, 1997), which is provided in WordnetSimilarity package (Pedersen et al., 2004) to evaluate the similarity between two concepts in Word-net.",
        "Intuitively, the relatedness between two concepts in Wordnet is captured by the information content of their lowest common subsumer (lcs) and the information content of the two concepts themselves, which can be formalized as follows:",
        "measure depends upon the corpus to estimate information content.",
        "We carried out the experiments using the British National Corpus (BNC) as the source of information content."
      ]
    },
    {
      "heading": "3.4 Experiments and Results",
      "text": [
        "For comparison of the effect of the outer and within contexts of entity pairs, we used five dif",
        "ferent settings of context window size (WINpre-WINmid-WINpost) for each domain.",
        "Table 4 shows the results of model order identification without feature selection (Baseline) and with feature selection based on different feature ranking criterion( x2 , Frequency and Entropy).",
        "The results show that the model order identification algorithm with feature selection based on entropy achieve best results: estimate cluster numbers which are very close to the true values.",
        "In addition, we can find that with the context setting, 0 10-0, the estimated number of the clusters is equal or close to the ground truth value.",
        "It demonstrates that the intervening words less than 10 are appropriate features to reflect the structure behind the contexts, while the intervening words less than 5 are not enough to infer the structure.",
        "For the contextual words beyond (before or after) the entities, they tend to be noisy features for the relation estimation, as can be seen that the performance deteriorates when taking them into consideration, especially for the case without feature selection.",
        "Table 5 gives a comparison of the average accuracy over five different context window size settings for different clustering settings.",
        "For each domain, we conducted five clustering procedures: Hasegawa’s method, RLBaseline, RLFSx2, RLFSFreq and RLFSEntropy.",
        "For Hasegawa’s method (Hasegawa et al., 2004), we set the cluster number to be identical with the number of ground truth classes.",
        "For RLBaseline, we use the estimated cluster number to cluster contexts without feature selection.",
        "For RLFSx2,RLFSFreq and RLFSEntropy, we use the selected feature subset and the estimated cluster number to cluster the contexts, where the feature subset comes from x2, frequency and entropy criterion respectively.",
        "Comparing the average accuracy of these clustering methods, we can find that the performance of feature selection methods is better than or comparable with the baseline system without feature selection.",
        "Furthermore, it is noted that RLFSEntropy achieves the highest average accuracy in three domains, which indicates that entropy based feature pre-ranking provides useful heuristic information for the selection of important feature subset.",
        "Table 6 gives the automatically estimated labels for relation types for the domain PER-ORG.",
        "We select two features as labels of each relation type according to their DCM scores and calculate the average (and maximum) relatedness between our selected labels (E) and the predefined labels (H).",
        "Following the same strategy, we also extracted relation labels (T) from the ground truth classes and provided the relatedness between T and H. From the column of relatedness (E-H), we can see that it is not easy to find the hand-tagged relation labels exactly, furthermore, the identified labels from the ground-truth classes are either not always comparable to the predefined labels in most cases (TH).",
        "The reason may be that the predefined relation names tend to be some abstract labels over the features, e.g., ‘management’ vs. ‘president’,",
        "‘head’ or ‘control’; ‘member’ vs. ‘join’, ‘become’, etc., while the abstract words and the features are located far away in Wordnet.",
        "Table 6 also lists the relatedness between (E) and (T).",
        "We can see that the labels are comparable by their maximum relatedness(E-T)."
      ]
    },
    {
      "heading": "4 Conclusion and Future work",
      "text": [
        "In this paper, we presented an unsupervised approach for relation extraction from corpus.",
        "The advantages of the proposed approach includes that it doesn’t need any manual labelling of the relation instances, it can identify an important feature subset and the number of the context clusters automatically, and it can avoid extracting those common words as characterization of relations."
      ]
    }
  ]
}
