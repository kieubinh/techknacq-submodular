{
  "info": {
    "authors": [
      "ShuangLong Li"
    ],
    "book": "Proceedings of the Fourth SIGHAN Workshop on Chinese Language Processing",
    "id": "acl-I05-3032",
    "title": "Chinese Word Segmentation in ICT-NLP",
    "url": "https://aclweb.org/anthology/I05-3032",
    "year": 2005
  },
  "references": [],
  "sections": [
    {
      "text": [
        "C, T* arg max P (T |C) T is determined using the Viterbi algorithm, An N-best list of tagging sequences is obtained using modified Viterbi algorithm.",
        "Six tags according to the different positions of one character in a word are used in this model, such as #START(beginning of one sentence), B(beginning of one word), M(middle of one word), E(end of one word), and #END(end of one sentence).",
        "The feature templates used in this model are listed in Table 1."
      ]
    },
    {
      "heading": "Abstract",
      "text": [
        "Chinese word segmentation is always much accounted of in ICT-NLP.",
        "In this bakeoff, two different systems in ICT-NLP participated.",
        "The one is SYSTEM_#1 evaluated in three tracks -- PK-close, MSR-close and MSR-open, and SYSTEM _#2 PK-open.",
        "Through this bakeoff , the development of Chinese segmentation is learned and the problems are found in our systems."
      ]
    },
    {
      "heading": "1 System Description",
      "text": [
        "Two different systems in ICT-NLP participated the second bakeoff."
      ]
    },
    {
      "heading": "1.1 SYSTEM #1",
      "text": [
        "The SYSTEM_#1 is implemented mainly based on the log-linear model CRFs (Conditional Random Fields).",
        "CRFs are arbitrary undirected graphical models trained to maximize the conditional probability of the desired outputs given the corresponding inputs.",
        "We cast the segmentation as one of sequence tagging.",
        "The conditional probability for the tag sequence T = t1t2...tn given a input Chinese sentence C = c1c2...cn is defined by a linear-chain CRF with parameters Where Zc is the per-input normalization that makes the probability of all state sequences sum to one.",
        "fm (ti 1, ti, C, i) is a feature function which is can be any real number.",
        "The most probable tag sequence for an input",
        "Any Chinese letter like a, ,b, ... is replaced by mark #L; All the characters are classified to be 7 types, such as : number, letter, time-suffix, etc.",
        "In this model, the parameters are estimated by one Perceptron Algorithm.",
        "The parameters can also be trained through the maximum entropy learning algorithms like GIS or IIS, but performed poorly in our tests."
      ]
    },
    {
      "heading": "1.2 SYSTEM #2",
      "text": [
        "The SYSTEM_#2 is mainly a HHMM-based Chinese segmentation system which has participated the 1st bakeoff in 2003.",
        "And the improvement has been made by some post processes.",
        "The system structure is shown in Figure 1",
        "Details of the post-processing are listed below.",
        "TBL(Transformation Based Learning) is applied for adaptation to different segmentation standards.",
        "The repeating strings extracted in the test data using Accessor Variety correct the inconsistent segmentation.",
        "A filtering approach to find the unknown words in the single character strings is used."
      ]
    },
    {
      "heading": "2 Track",
      "text": [
        "Here ,we introduce the operation of the different tracks.",
        "Table 2 gives the results of the tracks."
      ]
    },
    {
      "heading": "2.1 Closed Tracks",
      "text": [
        "Only the SYSTEM_#1 participated the closed tracks(PK and MSR) because SYSTEM_#2 must utilize the POS information in the entity recognition process.",
        "All the features information used in the SYSTEM_#1 were trained automatic for one time.",
        "We split the training randomly to two parts 80% used for training and 20% used for estimating the parameters."
      ]
    },
    {
      "heading": "2.2 Open Tracks",
      "text": [
        "We participated two open tracks-SYSTEM _#1 MSR and SYSTEM_#2 PK.",
        "For SYSTEM_#1, an external dictionary which contains 140,332 entries with POS is used.",
        "However, because of the standard conflict, the open result is weaker than the closed result.",
        "For SYSTEM_#2, the system is trained on six-months tagged news corpus of People Daily 1998 and an external dictionary which contains 22,858 entries with POS."
      ]
    },
    {
      "heading": "3 Conclusion",
      "text": [
        "The result in this bakeoff is not so satisfied as there are also many problems in our systems.",
        "Through this bakeoff, we learn more about the the development of Chinese segmentation.",
        "So the future research is needed to improve our work."
      ]
    }
  ]
}
