{
  "info": {
    "authors": [
      "Lishuang Li",
      "Tingting Mao",
      "Degen Huang",
      "Yuansheng Yang"
    ],
    "book": "SIGHAN Workshop on Chinese Language Processing",
    "id": "acl-W06-0110",
    "title": "Hybrid Models for Chinese Named Entity Recognition",
    "url": "https://aclweb.org/anthology/W06-0110",
    "year": 2006
  },
  "references": [
    "acl-N01-1025",
    "acl-P02-1060",
    "acl-P02-1062",
    "acl-P03-2039",
    "acl-P97-1041",
    "acl-W02-2002",
    "acl-W02-2004",
    "acl-W02-2025",
    "acl-W02-2029"
  ],
  "sections": [
    {
      "heading": "Abstract",
      "text": [
        "This paper describes a hybrid model and the corresponding algorithm combining support vector machines (SVMs) with statistical methods to improve the performance of SVMs for the task of Chinese Named Entity Recognition (NER).",
        "In this algorithm, a threshold of the distance from the test sample to the hyperplane of SVMs in feature space is used to separate SVMs region and statistical method region.",
        "If the distance is greater than the given threshold, the test sample is classified using SVMs; otherwise, the statistical model is used.",
        "By integrating the advantages of two methods, the hybrid model achieves 93.18% F-measure for Chinese person names and 91.49% F-measure for Chinese location names."
      ]
    },
    {
      "heading": "1 Introduction",
      "text": [
        "Named entity (NE) recognition is a fundamental step to many language processing tasks such as information extraction (IE), question answering (QA) and machine translation (MT).",
        "On its own, NE recognition can also provide users who are looking for person or location names with quick information.",
        "Palma and Day (1997) reported that person (PER), location (LOC) and organization (ORG) names are the most difficult subtasks as compared to other entities as defined in Message Understanding Conference (MUC).",
        "So we focus on the recognition of PER, LOC and ORG entities.",
        "Recently, machine learning approaches are widely used in NER, including the hidden Markov model (Zhou and Su, 2000; Miller and Crystal, 1998), maximum entropy model (Borthwick, 1999), decision tree (Qin and Yuan, 2004), transformation-based learning (Black and Vasilakopoulos, 2002), boosting (Collins, 2002; Carreras et al., 2002), support vector machine (Takeuchi and Collier, 2002; Yu et al., 2004; Goh et al., 2003), memory-based learning (Sang, 2002).",
        "SVM has given high performance in various classification tasks (Joachims, 1998; Kudo and Matsumoto, 2001).",
        "Goh et al.",
        "(2003) presented a SVM-based chunker to extract Chinese unknown words.",
        "It obtained higher F-measure for person names and organization names.",
        "Like other classifiers, the misclassified testing samples by SVM are mostly near the decision plane (i.e., the hyperplane of SVM in feature space).",
        "In order to increase the accuracy of SVM, we propose a hybrid model combining SVM with a statistical approach for Chinese NER, that is, in the region near the decision plane, statistical method is used to classify the samples instead of SVM, and in the region far away from the decision plane, SVM is used.",
        "In this way, the misclassification by SVM near the decision plane can be decreased significantly.",
        "A higher F-measure for Chinese NE recognition can be achieved.",
        "In the following sections, we shall describe our approach in details."
      ]
    },
    {
      "heading": "2 Recognition of Chinese Named Entity Using SVM",
      "text": [
        "Firstly, we segment and assign part-of-speech (POS) tags to words in the texts using a Chinese lexical analyzer.",
        "Secondly, we break segmented words into characters and assign each character its features.",
        "Lastly, a model based on SVM to identify Chinese named entities is set up by choosing a proper kernel function.",
        "In the following, we will exemplify the person names and location names to illustrate the identification process."
      ]
    },
    {
      "heading": "2.1 Support Vector Machines",
      "text": [
        "Support Vector Machines first introduced by Vapnik (1996) are learning systems that use a hypothesis space of linear functions in a high dimensional feature space, trained with a learning algorithm from optimization theory that implements a learning bias derived from statistical theory.",
        "SVMs are based on the principle of structural risk minimization.",
        "Viewing the data as points in a high-dimensional feature space, the goal is to fit a hyperplane between the positive and negative examples so as to maximize the distance between the data points and the hyperplane.",
        "Given training examples:",
        "xi is a feature vector (n dimension) of the i-th sample.",
        "yi is the class (positive(+1) or negative(-1) class) label of the i-th sample.",
        "l is the number of the given training samples.",
        "SVMs find an “optimal” hyperplane: (wx + b) = 0 to separate the training data into two classes.",
        "The optimal hyperplane can be found by solving the following quadratic programming problem (we leave the details to Vapnik (1998)): The function K(xi, xj) = ϕ(xi) ⋅ ϕ(xj) is called kernel function, cp(x) is the mapping from primary input space to feature space.",
        "Given a test example, its label y is decided by the following function:",
        "Basically, SVMs are binary classifiers, and can be extended to multi-class classifiers in order to solve multi-class discrimination problems.",
        "There are two popular methods to extend a binary classification task to that of K classes: one class vs. all others and pairwise.",
        "Here, we employ the simple pairwise method.",
        "This idea is to build K x (K – 1) / 2 classifiers considering all pairs of classes, and final decision is given by their voting."
      ]
    },
    {
      "heading": "2.2 Recognition of Chinese Person Names Based on SVM",
      "text": [
        "We use a SVM-based chunker, YamCha (Kudo and Masumoto, 2001), to extract Chinese person names from the Chinese lexical analyzer.",
        "1) Chinese Person Names Chunk Tags",
        "We use the Inside/Outside representation for proper chunks: I Current token is inside of a chunk.",
        "O Current token is outside of any chunk.",
        "B Current token is the beginning of a chunk.",
        "A chunk is considered as a Chinese person name in this case.",
        "Every character in the training set is given a tag classification of B, I or O, that is, yi ∈ {B, I, O} .",
        "Here, the multi-class decision",
        "method pairwise is selected.",
        "2) Features Extraction for Chinese Person Names",
        "Since Chinese person names are identified from the segmented texts, the mistakes of word segmentation can result in error identification of person names.",
        "So we must break words into characters and extract features for every character.",
        "Table 1 summarizes types of features and their values.",
        "The POS tag from the output of lexical analysis is subcategorized to include the position of the character in the word.",
        "The list of POS tags is shown in Table 2.",
        "If the character is a surname, the value is assigned to Y, otherwise assigned to N. The “character” is surface form of the character in the word.",
        "We extract all person names in January 1998 of the People’s Daily to set up person names table and calculate the frequency of every charac",
        "ter (F) of person names table in the training corpus.",
        "The frequency of F is defined as P(F) = the number of F as a character of person names, (4) the total number of F if P(F) is greater than the given threshold, the value is assigned to Y, otherwise assigned to N. We also use previous BIO-tags as features.",
        "Whether a character is inside a person name or not, it depends on the context of the character.",
        "Therefore, we use contextual information of two previous and two successive characters of the current character as features.",
        "Figure 1 shows an example of features extraction for the i-th character.",
        "When training, the features of the character “Min” contains all the features surrounded in the frames.",
        "If the same sentence is used as testing, the same features are used.",
        "Position Character POS tags Whether the character is a surname The frequency of a character in the person names table Previous BIO tags",
        "3) Choosing Kernel Functions Here, we choose polynomial kernel functions:",
        "separating hyperplane."
      ]
    },
    {
      "heading": "2.3 Recognition of Chinese Location Names Based on SVM",
      "text": [
        "The identification process of location names is the same as that of person names except for the features extraction.",
        "Table 3 summarizes types of features and their values of location names extraction.",
        "The location names characteristic table is set up in advance, and it includes the characters or words expressing the characteristics of location names such as “sheng (province)”, “shi (city)”, “xian (county)”etc.",
        "If the character is in the location names characteristic table, the value is assigned to Y, otherwise assigned to N."
      ]
    },
    {
      "heading": "3 Statistical Models",
      "text": [
        "Many statistical models for NER have been presented (Zhang et al., 1992; Huang et al., 2003 etc).",
        "In this section, we proposed our statistical models for Chinese person names recognition and Chinese location names recognition."
      ]
    },
    {
      "heading": "3.1 Chinese Person Names",
      "text": [
        "We define a function to evaluate the person name candidate PN.",
        "The evaluated function Total-Probability(PN) is composed of two parts: the lexical probability LP(PN) and contextual probability CP(PN) based on POS tags.",
        "where PN is the evaluated person name and α is the balance cofficient.",
        "1) lexical probability LP(PN) We establish the surname table (SurName) and the first name table (FirstName) from the students of year 1999 in a university (containing 9986 person names).",
        "Suppose PN=LF1F2, where L is the surname of the evaluated person name PN, Fi (i=1,2) is the i-th first name of the evaluated person name PN.",
        "The probability of the surname Pl(L) is defined as",
        "where Pl0 (L) = log2 (N(L) + 2) , N(L) is the number of L as the single or multiple surname of person names in the SurName.",
        "The probability of the first name Pf(F) is defined as",
        "where P f0 (F) =log2 (N(F) + 2) ,N(F) is the number of F in the FirstName.",
        "The lexical probability of the person name PN is defined as",
        "where Cb is the balance cofficient between the single name and the double name.",
        "Here, Cb=°.844 (Huang et al., 2001).",
        "2) contextual probability based on POS tags CP(PN) Chinese person names have characteristic contexual POS tags in real Chinese texts, for example, in the phrase “dui Zhangshuai shuo (say to Zhangshuai)”, the POS tag before the person name “Zhangshuai” is prepnoun and verb occurs after the person name.",
        "We define the bigram contextual probability CP(PN) of the person name PN as the following equation: TotalPOS is the total number of the contexual"
      ]
    },
    {
      "heading": "3.2 Chinese Location Names",
      "text": [
        "as the firstcharacteroflocation names in the Chinese Location Names Record.",
        "Ph′°(F°)=log2(C′(F°)+2), C′(F°)isthetotal numberof F0 in the Chinese Location Names Record.",
        "The probability of the middle character of the evaluated location name Pf(F+) is defined as",
        "as the i-th middle characterofloca-tionnames inthe Chinese LocationNames Record.",
        "d verb occurs after the location name.",
        "We define the bigram contextual probability CP(LN) of the location name LN similar to that of the person name PN in equation (9), where PN is replaced with LN.",
        "4 Recognition ofChinese Named Entity UsingHybrid Model Analyzingthe classificationresults (obtained by sole SVMs describedinsection2) between B andI, B and O, Iand O respectively, we findthat the erroris mainlycausedby the second classification.",
        "The samples whichattribute to B class are misclassifiedto O class, whichleads to B class vote’s diminishingandthe corresponding named entities are lost.",
        "Therefore the Recall is lower.",
        "Inthe meantime, the numberofthe mis-classifiedsamples whose function distances to the hyperplane ofSVM infeature space are less than1 can reach over 83% of the number of total misclassified samples.",
        "That means the misclassi",
        "where lpos is the POS tag of the character before PN (called POS forward), rpos is the POS tag of the character after PN (called POS backward), and PersonPOS(< lpos, PN, rpos >) is the number of PN as a pereson name whose POS forward is lpos and POS backward is rpos in training corpus.",
        "fication of a classifier is occurred in the region of two overlapping classes.",
        "Considering this fact, we can expect to improve SVM using the following hybrid model.",
        "The hybrid model includes the following procedure: 1) compute the distance from the test sample to the hyperplane of SVM in feature space.",
        "2) compare the distance with given threshold.",
        "The algorithm of hybrid model can be described as follows:"
      ]
    },
    {
      "heading": "5 Experiments",
      "text": [
        "Our experimental results are all based on the corpus of Peking University."
      ]
    },
    {
      "heading": "5.1 Extracting Chinese Person Names",
      "text": [
        "We use 180 thousand characters corpus of year 1998 from the People’s Daily as the training corpus and extract other sentences (containing 1526 Chinese person names) as testing corpus to conduct an open test experiment.",
        "The results are obtained as follows based on different models.",
        "1) Based on Sole SVM An experiment is carried out to recognize Chinese person names based on sole SVM by the method as described in Section 2.",
        "The Recall, Precision and F-measure using different number of degree of polynomial kernel function are given in Table 4.",
        "The best result is obtained when d=2."
      ]
    },
    {
      "heading": "2) Using Hybrid Model",
      "text": [
        "As mentioned in section 4, the test samples which attribute to B class are misclassified to O class and therefore the Recall for person names extraction from sole SVM is lower.",
        "So we only deal with the test samples (B class and O class) whose function distances to the hyperplane of SVM in feature space (i.e. g(x)) is between 0 and E .",
        "We move class-boundary learned by SVM towards the O class, that is, the O class samples are considered as B class in that area.",
        "93.64% of the Chinese person names in testing corpus are recalled when E =0.9 (Here, E also represents how much the boundary is moved).",
        "However, a number of non-person names are also identified as person names wrongly and the Precision is decreased correspondingly.",
        "Table 5 shows the Recall and Precision of person names extraction with different E .",
        "with Different E We use the evaluated function TotalProbabil-ity(PN) as described in section 3 to filter the wrongly recalled person names using SVM.",
        "We tune a in equation (5) to obtain the best results.",
        "The results based on the hybrid model with different a are listed in Table 6 (when d=2).",
        "We can observe that the result is best when a=0.4.",
        "Table 7 shows the results based on the hybrid model with different E when a =0.4.",
        "We can observe that the Recall rises and the Precision drops on the whole when E increases.",
        "The synthetic index F-measures are improved when E is between 0.1 and 0.8 compared with sole SVM.",
        "The best result is obtained when E =0.3.",
        "The Re call and the F-measure increases 3.27% and 1.77% respectively."
      ]
    },
    {
      "heading": "5.2 Extracting Chinese Location Names",
      "text": [
        "We use 1.5M characters corpus of year 1998 from the People’s Daily as the training corpus and extract sentences of year 2000 from the People’s Daily (containing 2919 Chinese location names) as testing corpus to conduct an open test experiment.",
        "The results are obtained as follows based on different models.",
        "1) Based on Sole SVM The Recall, Precision and F-measure using different number of degree of polynomial kernel function are given in Table 8.",
        "The best result is obtained when d=2."
      ]
    },
    {
      "heading": "2) Using Hybrid Model",
      "text": [
        "The results for Chinese location names extraction based on the hybrid model are listed in Table 9 (when d=2; a =0.2 in equation (10)).",
        "We can observe that the Recall rises and the Precision drops on the whole when E increases.",
        "The synthetic index F-measures are improved when E is between 0.1 and 0.7 compared with sole SVM.",
        "The best result is obtained when E =0.3.",
        "The Recall increases 3.55%, the Precision decreases 1.05% and the F-measure increases 1.37%."
      ]
    },
    {
      "heading": "6 Comparison with other work",
      "text": [
        "The same corpus was also tested using statistics-based approach to identify Chinese person names (Huang et al., 2001) and location names (Huang and Yue, 2003).",
        "In their systems, lexical reliability and contextual reliability were used to identify person names and location names calculated from statistical information drawn from a training corpus.",
        "The results of our models and the statistics-based methods (Huang 2001; Huang 2003) are shown in Table 10 for comparison.",
        "We can see that the Recall and F-measure in our method all increase a lot."
      ]
    },
    {
      "heading": "7 Conclusions and Future work",
      "text": [
        "We recognize Chinese named entities using a hybrid model combining support vector machines with statistical methods.",
        "The model integrates the advantages of two methods and the experimental results show that it can achieve higher F-measure than the sole SVM and individual statistical approach.",
        "Future work includes optimizing statistical models, for example, we can add the probability information of Chinese named entities in real texts to compute lexical probability, and we can",
        "also use trigram models to compute contextual probability.",
        "The hybrid model is expected to extend to foreign names in transliteration to obtain improved results by sole SVMs.",
        "The identification of transliterated names by SVMs has been completed (Li et al., 2004).",
        "The future work includes: set up statistical models for transliterated names and combine statistical models with SVMs to identify transliterated names."
      ]
    }
  ]
}
