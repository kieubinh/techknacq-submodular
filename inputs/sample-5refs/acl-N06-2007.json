{
  "info": {
    "authors": [
      "Jinxiu Chen",
      "Ji Donghong",
      "Chew Lim Tan",
      "Zhengyu Niu"
    ],
    "book": "Human Language Technology Conference and Meeting of the North American Association for Computational Linguistics – Short Papers",
    "id": "acl-N06-2007",
    "title": "Semi-Supervised Relation Extraction With Label Propagation",
    "url": "https://aclweb.org/anthology/N06-2007",
    "year": 2006
  },
  "references": [
    "acl-A00-2030",
    "acl-P04-1053",
    "acl-P04-1054",
    "acl-P04-3022",
    "acl-P95-1026",
    "acl-W02-1010"
  ],
  "sections": [
    {
      "heading": "Abstract",
      "text": [
        "To overcome the problem of not having enough manually labeled relation instances for supervised relation extraction methods, in this paper we propose a label propagation (LP) based semi-supervised learning algorithm for relation extraction task to learn from both labeled and unlabeled data.",
        "Evaluation on the ACE corpus showed when only a few labeled examples are available, our LP based relation extraction can achieve better performance than SVM and another bootstrapping method."
      ]
    },
    {
      "heading": "1 Introduction",
      "text": [
        "Relation extraction is the task of finding relationships between two entities from text.",
        "For the task, many machine learning methods have been proposed, including supervised methods (Miller et al., 2000; Zelenko et al., 2002; Culotta and Soresen, 2004; Kambhatla, 2004; Zhou et al., 2005), semi-supervised methods (Brin, 1998; Agichtein and Gravano, 2000; Zhang, 2004), and unsupervised method (Hasegawa et al., 2004).",
        "Supervised relation extraction achieves good performance, but it requires a large amount of manually labeled relation instances.",
        "Unsupervised methods do not need the definition of relation types and manually labeled data, but it is difficult to evaluate the clustering result since there is no relation type label for each instance in clusters.",
        "Therefore, semi-supervised learning has received attention, which can minimize corpus annotation requirement.",
        "Current works on semi-supervised resolution for relation extraction task mostly use the bootstrapping algorithm, which is based on a local consistency assumption: examples close to labeled examples within the same class will have the same labels.",
        "Such methods ignore considering the similarity between unlabeled examples and do not perform classification from a global consistency viewpoint, which may fail to exploit appropriate manifold structure in data when training data is limited.",
        "The objective of this paper is to present a label propagation based semi-supervised learning algorithm (LP algorithm) (Zhu and Ghahramani, 2002) for Relation Extraction task.",
        "This algorithm works by representing labeled and unlabeled examples as vertices in a connected graph, then propagating the label information from any vertex to nearby vertices through weighted edges iteratively, finally inferring the labels of unlabeled examples after the propagation process converges.",
        "Through the label propagation process, our method can make the best of the information of labeled and unlabeled examples to realize a global consistency assumption: similar examples should have similar labels.",
        "In other words, the labels of unlabeled examples are determined by considering not only the similarity between labeled and unlabeled examples, but also the similarity between unlabeled examples."
      ]
    },
    {
      "heading": "2 The Proposed Method",
      "text": []
    },
    {
      "heading": "2.1 Problem Definition",
      "text": [
        "Let X = {xi}�i� ' be a set of contexts of occurrences of all entity pairs, where xi represents the contexts of the i-th occurrence, and n is the total number of occurrences of all entity pairs.",
        "The first l examples are labeled as yg ( yg E {rj }�j� ', rj denotes relation type and R is the total number of relation types).",
        "And the remaining u(u = n �l) examples are unlabeled.",
        "Intuitively, if two occurrences of entity pairs have",
        "the similar contexts, they tend to hold the same relation type.",
        "Based on this assumption, we create a graph where the vertices are all the occurrences of entity pairs, both labeled and unlabeled.",
        "The edge between vertices represents their similarity.",
        "Then the task of relation extraction can be formulated as a form of propagation on a graph, where a vertex’s label propagates to neighboring vertices according to their proximity.",
        "Here, the graph is connected with the weights: Wij = exp(� �� �� ), where sij is the sim�� ilarity between xi and xj calculated by some similarity measures.",
        "In this paper,two similarity measures are investigated, i.e. Cosine similarity measure and Jensen-Shannon (JS) divergence (Lin, 1991).",
        "And we set a as the average similarity between labeled examples from different classes."
      ]
    },
    {
      "heading": "2.2 Label Propagation Algorithm",
      "text": [
        "Given such a graph with labeled and unlabeled vertices, we investigate the label propagation algorithm (Zhu and Ghahramani, 2002) to help us propagate the label information of any vertex in the graph to nearby vertices through weighted edges until a global stable stage is achieved.",
        "ability to jump from vertex xj to vertex xi.",
        "Also define a n x R label matrix Y, where Yij representing the probabilities of vertex yi to have the label rj.",
        "Then the label propagation algorithm consists the following main steps: Step1: Initialization Firstly, set the iteration index t = 0.",
        "Then let Y0 be the initial soft labels attached to each vertex and YL0 be the top l rows of Y0, which is consistent with the labeling in labeled data (Y0 ij = 1 if yi is label rj and 0 otherwise ).",
        "Let YU0 be the remaining u rows corresponding to unlabeled data points and its initialization can be arbitrary.",
        "Step 2: Propagate the label by where T is the row-normalized matrix of T, i.e. Tij = Tij Ek Tik, which can maintain the class probability interpretation.",
        "Step 3: Clamp the labeled data, i.e., replace the top l row of Yt+1 with Y0� .",
        "In this step, the labeled data is clamped to replenish the label sources from these labeled data.",
        "Thus the labeled data act like sources to push out labels through unlabeled data."
      ]
    },
    {
      "heading": "3 Experiments and Results",
      "text": []
    },
    {
      "heading": "3.1 Data",
      "text": [
        "Our proposed graph-based method is evaluated on the ACE corpus 1, which contains 519 files from sources including broadcast, newswire, and newspaper.",
        "A breakdown of the tagged data by different relation subtypes is given in Table 1."
      ]
    },
    {
      "heading": "3.2 Features",
      "text": [
        "We extract the following lexical and syntactic features from two entity mentions, and the contexts before, between and after the entity pairs.",
        "Especially, we set the mid-context window as everything between the two entities and the pre and post context as up to two words before and after the corresponding entity.",
        "Most of these features are computed from the parse trees derived from Charniak Parser (Charniak, 1999) and the Chunklink script 2 written by Sabine Buchholz from Tilburg University.",
        "Entity Type: the entity type of both entity mentions, which can be PERSON, ORGANIZATION, FACILITY, LOCATION and GPE.",
        "POS: Part-Of-Speech tags corresponding to all tokens in the two entities and three context windows.",
        "Chunking features: Chunk tag information and Grammatical function of the two entities and three context windows.",
        "IOB-chains of the heads of the two entities are also considered.",
        "IOB-chain notes the syntactic categories of all the constituents on the path from the root node to this leaf node of tree.",
        "We combine the above features with their position information in the context to form the context vector.",
        "Before that, we filter out low frequency features which appeared only once in the entire set."
      ]
    },
    {
      "heading": "3.3 Experimental Evaluation 3.3.1 Relation Detection",
      "text": [
        "We collect all entity mention pairs which co-occur in the same sentence from the training and devtest corpus into two set C1 and C2 respectively.",
        "The set C1 includes annotated training data AC1 and unrelated data UC1.",
        "We randomly sample l examples from AC1 as labeled data and add a “NONE” class into labeled data for the case where the two entity mentions are not related.",
        "The data of the “NONE”",
        "class is resulted by sampling l examples from UC1.",
        "Moreover, we combine the rest examples of C1 and the whole set C2 as unlabeled data.",
        "Given labeled and unlabeled data,we can perform LP algorithm to detect possible relations, which are those entity pairs that are not classified to the “NONE” class but to the other 24 subtype classes.",
        "In addition,we conduct experiments with different sampling set size l, including 1% x Ntrain,10% x",
        "100% x Ntrain (Ntrain = AC1 ).",
        "If any major subtype was absent from the sampled labeled set,we redo the sampling.",
        "For each size,we perform 20 trials and calculate an average of 20 random trials.",
        "labled data.",
        "For SVM, we use LIBSVM tool with linear kernel function 3.",
        "And the same sampled labeled data used in LP is used to train SVM models.",
        "From Table 2, we see that both LPCosine and LP JS achieve higher Recall than SVM.",
        "Especially, with small labeled dataset (percentage of labeled data < 25%), this merit is more distinct.",
        "When the percentage of labeled data increases from 50% to 100%, LPCosine is still comparable to SVM in F-measure while LP JS achieves better F-measure than SVM.",
        "On the other hand, LP JS consistently outperforms LPCosine.",
        "Table 3 reports the performance of relation classification, where the performance describes the average values over major relation subtypes.",
        "From Table 3, we see that LPCosine and LP JS outperform SVM by F-measure in almost all settings of labeled data, which is due to the increase of Recall.",
        "With smaller labeled dataset, the gap between LP and SVM is larger.",
        "On the other hand, LP JS divergence consistently outperforms LPCosine."
      ]
    },
    {
      "heading": "3.3.3 LP vs. Bootstrapping",
      "text": [
        "In (Zhang, 2004), they perform relation classification on ACE corpus with bootstrapping on top of SVM.",
        "To compare with their proposed Bootstrapped SVM algorithm, we use the same feature stream setting and randomly selected 100 instances from the training data as the size of initial labeled data.",
        "Table 4 lists the performance on individual relation type.",
        "We can find that LP algorithm achieves 6.8% performance improvement compared with the (Zhang, 2004)’s bootstrapped SVM algorithm average on all five relation types.",
        "Notice that performance reported on relation type “NEAR” is low, because it occurs rarely in both training and test data."
      ]
    },
    {
      "heading": "4 Conclusion and Future work",
      "text": [
        "This paper approaches the task of semi-supervised relation extraction on Label Propagation algorithm.",
        "Our results demonstrate that, when only very few labeled examples are available, this manifold learning based algorithm can achieve better performance than supervised learning method (SVM) and bootstrapping based method, which can contribute to 3LIBSVM: a library for support vector machines.",
        "Software available at http://www.csie.ntu.edu.tw/ – cjlin/libsvm.",
        "minimize corpus annotation requirement.",
        "In the future we would like to investigate how to select more useful feature stream and whether feature selection method can improve the performance of our graph-based semi-supervised relation extraction."
      ]
    }
  ]
}
