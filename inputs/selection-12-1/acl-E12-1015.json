{
  "info": {
    "authors": [
      "JÃ¶rg Tiedemann"
    ],
    "book": "EACL",
    "id": "acl-E12-1015",
    "title": "Character-Based Pivot Translation for Under-Resourced Languages and Domains",
    "url": "https://aclweb.org/anthology/E12-1015",
    "year": 2012
  },
  "references": [
    "acl-C10-1027",
    "acl-D09-1141",
    "acl-D10-1015",
    "acl-J03-1002",
    "acl-N07-1047",
    "acl-N07-1061",
    "acl-P03-1021",
    "acl-P05-1074",
    "acl-P07-1092",
    "acl-P07-1108",
    "acl-P07-2045",
    "acl-P09-1018",
    "acl-W07-0705"
  ],
  "sections": [
    {
      "text": [
        ": It's just a question of yourself.",
        "Leaving unseen words untranslated is not only annoying (especially if the input language uses a different writing system) but often makes translations completely incomprehensible.",
        "Pivot translations will still not be perfect (see example two above), but can at least be more intelligible.",
        "Character-based models can even take care of tokenization errors as the one shown above (?Tincque?",
        "should be two words ?Tinc que?).",
        "Fortunately, the generation of non-word sequences (observed as unknown words) does not seem to be a big problem and no special treatment is required to avoid such output.",
        "We would still like to address this issue in future work by adding a word level LM in character-based SMT.",
        "However, (Vilar et al. 2007) already showed that this did not have any positive effect in their character-based system.",
        "In a second study, we also showed that pivot models can be useful for adapting to a new domain.",
        "The use of in-domain pivot data leads to systems that outperform out-of-domain translation models by a large margin.",
        "Our findings point to many prospects for future work.",
        "For example, we would like to investigate combinations of character-based and word-based models.",
        "Character-based models may also be used for treating unknown words only.",
        "Multiple source approaches via several pivots is another possibility to be explored.",
        "Finally, we also need to further investigate the robustness of the approach with respect to other language pairs, data sets and learning parameters."
      ]
    }
  ]
}
