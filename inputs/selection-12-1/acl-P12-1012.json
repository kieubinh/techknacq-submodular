{
  "info": {
    "authors": [
      "Guillermo Garrido",
      "Anselmo Peñas",
      "Bernardo Cabaleiro",
      "Àlvaro Rodrigo"
    ],
    "book": "ACL",
    "id": "acl-P12-1012",
    "title": "Temporally Anchored Relation Extraction",
    "url": "https://aclweb.org/anthology/P12-1012",
    "year": 2012
  },
  "references": [
    "acl-C08-1108",
    "acl-I08-1054",
    "acl-N03-2019",
    "acl-N04-1020",
    "acl-P03-1054",
    "acl-P05-3021",
    "acl-P07-2044",
    "acl-P09-1046",
    "acl-P09-1113",
    "acl-P09-2093",
    "acl-W07-2014",
    "acl-W07-2025",
    "acl-W07-2052",
    "acl-W07-2108",
    "acl-W09-2418"
  ],
  "sections": [
    {
      "heading": "Abstract",
      "text": [
        "Although much work on relation extraction has aimed at obtaining static facts, many of the target relations are actually fluents, as their validity is naturally anchored to a certain time period.",
        "This paper proposes a methodological approach to temporally anchored relation extraction.",
        "Our proposal performs distant supervised learning to extract a set of relations from a natural language corpus, and anchors each of them to an interval of temporal validity, aggregating evidence from documents supporting the relation.",
        "We use a rich graph-based document-level representation to generate novel features for this task.",
        "Results show that our implementation for temporal anchoring is able to achieve a 69% of the upper bound performance imposed by the relation extraction step.",
        "Compared to the state of the art, the overall system achieves the highest precision reported."
      ]
    },
    {
      "heading": "1 Introduction",
      "text": [
        "A question that arises when extracting a relation is how to capture its temporal validity: Can we assign a period of time when the obtained relation held?",
        "As pointed out in (Ling and Weld, 2010), while much research in automatic relation extraction has focused on distilling static facts from text, many of the target relations are in fact fluents, dynamic relations whose truth value is dependent on time (Russell and Norvig, 2010).",
        "The Temporally anchored relation extraction problem consists in, given a natural language text document corpus, C, a target entity, e, and a target relation, r, extracting from the corpus the value of that relation for the entity, and a temporal interval for which the relation was valid.",
        "In this paper, we introduce a methodological approach to temporal anchoring of relations automatically extracted from unrestricted text.",
        "Our system (see Figure 1) extracts relational facts from text using distant supervision (Mintz et al., 2009) and then anchors the relation to an interval of temporal validity.",
        "The intuition is that a distant supervised system can effectively extract relations from the source text collection, and a straightforward date aggregation can then be applied to anchor them.",
        "We propose a four step process for temporal anchoring:",
        "(1) represent temporal evidence; (2) select temporal information relevant to the relation; (3) decide how a relational fact and its relevant temporal in",
        "formation are themselves related; and (4) aggregate imprecise temporal intervals across multiple documents.",
        "In contrast with previous approaches that aim at intra-document temporal information extraction (Ling and Weld, 2010), we focus on mining a corpus aggregating temporal evidences across the supporting documents.",
        "We address the following research questions:",
        "(1) Validate whether distant supervised learning is suitable for the task, and evaluate its shortcomings.",
        "(2) Explore whether the use of features extracted",
        "from a document-level rich representation could improve distant supervised learning.",
        "(3) Compare the use of document metadata against temporal expressions within the document for relation temporal anchoring.",
        "(4) Analyze how, in a pipeline architecture, the propagation of errors limits the overall system?s",
        "performance.",
        "The representation we use for temporal information is detailed in section 2; the rich document-level representation we exploit is described in section 3.",
        "For a query entity and target relation, the system first performs relation extraction (section 4); then, we find and aggregate time constraint evidence for the same relation across different documents, to establish a temporal validity anchor interval (section 5).",
        "Empirical comparative evaluation of our approach is introduced in section 6; while some related work is shown in section 7 and conclusions in section 8."
      ]
    },
    {
      "heading": "2 Temporal Anchors",
      "text": [
        "We will denominate relation instance a triple ?entity, relation name, value?.",
        "We aim at anchoring relation instances to their temporal validity.",
        "We need a representation flexible enough to capture the imprecise temporal information available in text, but expressed in a structured style.",
        "Allen's (1983) interval-based algebra for temporal representation and reasoning, underlies much research, such as the Tempeval challenges (Verhagen et al., 2007; Puste-jovsky and Verhagen, 2009).",
        "Our task is different, as we focus on obtaining the temporal interval associated to a fact, rather than reasoning about the temporal relations among the events appearing in a single text.",
        "Let us assume that each relation instance is valid during a certain temporal interval, I = [t0, tf ].",
        "This sharp temporal interval fails to capture the imprecision of temporal boundaries conveyed in natural language text.",
        "The Temporal Slot Filling task at TAC-KBP 2011 (Ji et al., 2011) proposed a 4-tuple representation that we will refer to as imprecise anchor intervals.",
        "An imprecise temporal interval is defined as an ordered 4-tuple of time points: (t1, t2, t3, t4), with the following semantics: the relation is true for a period which starts at some point between t1 and t2 and ends between t3 and t4.",
        "It should hold that: t1 ?",
        "t2, t3 ?",
        "t4, and t1 ?",
        "t4.",
        "Any of the four endpoints can be left unconstrained (t1 or t3 would be ?",
        "?, and t2 or t4 would be +?).",
        "This representation is flexible and expressive, although it cannot capture certain types of information (Ji et al., 2011)."
      ]
    },
    {
      "heading": "3 Document Representation",
      "text": [
        "We use a rich document representation that employs a graph structure obtained by augmenting the syntactic dependency analysis of the document with semantic information.",
        "A document D is represented as a document graph GD; with node set VD and edge set, ED.",
        "Each node v ?",
        "VD represents a chunk of text, which is a sequence of words1.",
        "Each node is labeled with a dictionary of attributes, some of which are common for every node: the words it contains, their part-of-speech annotations (POS) and lemmas.",
        "Also, a representative descriptor, which is a normalized string value, is generated from the chunks in the node.",
        "Certain nodes are also annotated with one or more types.",
        "There are three families of types: Events (verbs that describe an action, annotated with tense, polarity and aspect); standardized Time Expressions; and Named Entities, with additional annotations such as gender or age.",
        "Edges in the document graph, e ?",
        "ED, represent four kinds of relations between the nodes:",
        "?",
        "Syntactic: a dependency relation.",
        "?",
        "Coreference: indicates that two chunks refer to",
        "for the sample text document ?David's wife, Julia, is celebrating her birthday.",
        "She was born in September 1979?.",
        "the same discourse referent.",
        "?",
        "Semantic relations between two nodes, such as hasClass, hasProperty and hasAge.",
        "?",
        "Temporal relations between events and time expressions.",
        "The processing includes dependency parsing, named entity recognition and coreference resolution, done with the Stanford CoreNLP software (Klein and Manning, 2003); and events and temporal information extraction, via the TARSQI Toolkit (Verhagen et al., 2005).",
        "The document graph GD is then further transformed into a collapsed document graph, GC .",
        "Each node of GC clusters together coreferent nodes, representing a discourse referent.",
        "Thus, a node u in GC is a cluster of nodes u1, .",
        ".",
        ".",
        ", uk of GD.",
        "There is an edge (u, v) in GC if there was an edge between any of the nodes clustered into u and any of the nodes v1, .",
        ".",
        ".",
        ", vk?",
        ".",
        "The coreference edges do not appear in this representation.",
        "Additional semantic information is also blended into this representation: normalization of genitives, semantic class indicators inferred from appositions and genitives, and gender annotation inferred from pronouns.",
        "A final graph example can be seen in Figure 2."
      ]
    },
    {
      "heading": "4 Distant Supervised Relation Extraction",
      "text": [
        "To perform relation extraction, our proposal follows a distant supervision approach (Mintz et al., 2009), which has also inspired other slot filling systems (Agirre et al., 2009; Surdeanu et al., 2010).",
        "We capture long distance relations by introducing a document-level representation and deriving novel features from deep syntactic and semantic analysis.",
        "Seed harvesting.",
        "From a reference Knowledge Base (KB), we extract a set of relation triples or seeds: ?entity, relation, value?, where the relation is one of the target relations.",
        "Our document-level distant supervision assumption is that if entity and value are found in a document graph (see section 3), and there is a path connecting them, then the document expresses the relation.",
        "Relation candidates gathering.",
        "From a seed triple, we retrieve candidate documents that contain both the entity and value, within a span of 20 tokens, using a standard IR approach.",
        "Then, entity and value are matched to the document graph representation.",
        "We first use approximate string comparison to find nodes matching the seed entity.",
        "After an entity node has been found we use local breadth-first-search (BFS) to find a matching value and the shortest connecting path between them.",
        "We enforce the Named Entity type of entity and value to match a expected type, predefined for the relation.",
        "Our procedure traverses the document graph looking for entity and value nodes meeting those conditions; when found, we generate features for a positive example for the relation2.",
        "If we encounter a node that matches the expected NE type of the relation, but does not match the seed value, we generate a negative example for that relation.",
        "Training.",
        "From positive and negative examples, we generate binary features; some of them are inspired by previous work (Surdeanu and Ciaramita, 2007; Mintz et al., 2009; Riedel et al., 2010; Surdeanu et al., 2010), and others are novel, taking advantage of our graph representation.",
        "Table 1 summarizes our choice of features.",
        "Features appearing in less than 5 training examples were discarded.",
        "Relation instance extraction.",
        "Given an input entity and a target relation, we aim at finding a filler value for a relation instance.",
        "This task is known as Slot Filling.",
        "From the set of retrieved documents relevant to the query entity, represented as document graphs, 2From the collapsed document graph representation we obtained an average of 9213 positive training examples per slot; from the uncollapsed document graph, a slightly lower average of 8178.5 positive examples per slot.",
        "Feature name Description path dependency path between ENTITY and",
        "ENTITY and VALUE.",
        "Verb features are generated from the verbs, V , identified in the path between ENTITY and VALUE.",
        "we locate matching entities and start a local BFS of candidate values, generating for them an unlabelled example.",
        "For each of the relations to extract, a binary classifier (extractor) decides whether the example is a valid relation instance.",
        "For each particular relation classifier, only candidates with the expected entity and value types for the relation were used in the application phase.",
        "Each extractor was a SVM classifier with linear kernel (Joachims, 2002).",
        "All learning parameters were set to their default values.",
        "The classification process yields a predicted class label, plus a real number indicating the margin.",
        "We performed an aggregation phase to sum the margins over distinct occurrences of the same extracted value.",
        "The rationale is that when the same value is extracted from more than one document, we should accumulate that evidence.",
        "The output of this phase is the set of extracted relations (positive for each of the classifiers), plus the documents where the same fact was detected (supporting documents)."
      ]
    },
    {
      "heading": "5 Temporal Anchoring of Relations",
      "text": [
        "In this section, we propose and discuss a unified methodological approach for temporal anchoring of relations.",
        "We assume the input is a relation instance and a set of supporting documents.",
        "The task is establishing a imprecise temporal anchor interval for the relation.",
        "We present a four-step methodological approach: (1) representation of intra-document temporal information; (2) selection of relevant temporal information for the relation; (3) mapping of the link between relational fact and temporal information into an interval; and (4) aggregation of imprecise intervals.",
        "Temporal representation.",
        "The first methodological step is to obtain and represent the available intra-document temporal information; the input is a document, and the task is to identify temporal signals and possible links among them.",
        "We use the term link for a relation between a temporal expression (a date) and an event; we want to avoid confusion with the term relation (a relational fact extracted from text).",
        "In our particular implementation: ?",
        "We use TARSQI to extract temporal expressions and link them to events.",
        "In particular, TARSQI uses the following temporal links: included, simultaneous, after, before, begun by or ended.",
        "?",
        "We focus also on the syntactic pattern [Event-preposition-Time] within the lexical context of the candidate entity and value.",
        "?",
        "Both are normalized into one from a set of predefined temporal links: within, throughout, beginning, ending, after and before.",
        "Selection of temporal evidence.",
        "For each document and relational instance, we have to select those temporal expressions that are relevant.",
        "a. Document-level metadata.",
        "The default value we use is the document creation time (DCT), if available.",
        "The underlying assumption is that there is a within link from each fact expressed in the text and the document creation time.",
        "b. Temporal expressions.",
        "Temporal evidence comes also from the temporal expressions present in the context of a relation.",
        "In our particular implementation, we followed a straightforward approach, looking for the time expression closest in the document graph to the shortest path between the entity and value nodes.",
        "This search is performed via a limited depth BFS, starting from the nodes in the path, in order from value to entity.",
        "Mapping of temporal links into intervals.",
        "The third step is deciding how a relational fact and its relevant temporal information are themselves related.",
        "We have to map this information, expressed in text,",
        "lation to temporal constraints.",
        "to a temporal representation.",
        "We will use the imprecise anchor intervals described is section 2.",
        "Let T be a temporal expression identified in the document or its metadata.",
        "Now, the mapping of temporal constraints depends on the temporal link to the time expression identified; also, the semantics of the event have to be considered in order to decide the time period associated to a relation instance.",
        "This step is important because the event could refer just to the beginning of the relation, its ending, or both.",
        "For instance, it is obvious that having the event marry is different to having the event divorce, when deciding the temporal constraints associated to the spouse relation.",
        "Table 2 shows our particular mapping between temporal links and constraints.",
        "In particular, for the default document creation time, we suppose that a relation which appears in a document with creation time d held true at least in that date; that is, we are assuming a within link, and we map t2 = d, t3 = d. Inter-document temporal evidence aggregation.",
        "The last step is aggregating all the time constraints found for the same relation and value across different documents.",
        "If we found that a relation started after two dates d and d?, where d?",
        "> d, the closest constraint to the real start of the relation is d?.",
        "Mapped to temporal constraints, it means that we would choose the biggest t1 possible.",
        "Following the same reasoning, we would want to maximize t3.",
        "On the other side, when a relation started before two dates d2 and d?2, where d ?",
        "2 > d2, the closest constraint is d2 and we would choose the smallest t2.",
        "In summary, we will maximize t1 and t3 and minimize t2 and t4, so we will narrow the margins."
      ]
    },
    {
      "heading": "6 Evaluation",
      "text": [
        "We have used for our evaluation the dataset compiled within the TAC-KBP 2011 Temporal Slot Filling Task (Ji et al., 2011).",
        "We employed as initial KB the one distributed to participants in the task, which has been compiled from Wikipedia infoboxes.",
        "It contains 898 triples ?entity, slot type, value?",
        "for 100 different entities and up to 8 different slots (relations) per entity3.",
        "This gold standard contains the correct responses pooled from the participant systems plus a set of responses manually found by annotators.",
        "Each triple has associated a temporal anchor.",
        "The relations had to be extracted from a domain-general collection of 1.7 million documents.",
        "Our system was one of the five that took part in the task.We have evaluated the overall system and the two main components of the architecture: Relation Extraction, and Temporal Anchoring of the relations.",
        "Due to space limitations, the description of our implementation is very concise; refer to (Garrido et al., 2011) for further details."
      ]
    },
    {
      "heading": "6.1 Evaluation of Relation Extraction",
      "text": [
        "System response in the relation extraction step consists in a set of triples ?entity, slot type, value?.",
        "Performance is measured using precision, recall and F-measure (harmonic mean) with respect to the 898 triples in the key.",
        "Target relations (slots) are potentially list-valued, that is, more than one value can be valid for a relation (possibly at different points in time).",
        "Only correct values yield any score, and redundant triples are ignored.",
        "Experiments.",
        "We run two different system settings for the relation extraction step.",
        "They differ in the document representation used (detailed in section3), in order to empirically assess whether clustering of discourse referents into single nodes benefits the extraction.",
        "In SETTING 1, each document is represented as a document graph, GD, while in SETTING 2 collapsed document graph representation, GC , is employed.",
        "Results.",
        "Results are shown in Table 3 in the column Relation Extraction.",
        "Both settings have a similar performance with a slight increase in the case of graphs with clustered referents.",
        "Although precision is close to 0.5, recall is lower than 0.1.",
        "We have studied the limits of the assumptions our approach",
        "is based on.",
        "First, our standard retrieval component performance limits the overall system?s.",
        "As a matter of example, if we retrieve the first 100 documents per entity, we find relevant documents only for 62% of the triples in the key.",
        "This number means that no matter how good relation extraction method is, 38% of relations will not be found.",
        "Second, the distant supervision assumption underlying our approach is that for a seed relation instance ?entity, relation, value?, any textual mention of entity and value expresses the relation.",
        "It has been shown that this assumption is more often violated when training knowledge base and document collection are of different type, e.g. Wikipedia and news-wire (Riedel et al., 2010).",
        "We have realized that a more determinant factor is the relation itself and the type of arguments it takes.",
        "We randomly sampled 100 training examples per relation, and manually inspected them to assess if they were indeed mentions of the relation.",
        "While for the relation cities of residence only 30% of the training examples are expressing the relation, for spouse the number goes up to 59%.",
        "For title, up to 90% of the examples are correct.",
        "This fact explains, at least partially, the zeros we obtain for some relations."
      ]
    },
    {
      "heading": "6.2 Evaluation of Temporal Anchoring",
      "text": [
        "Under the evaluation metrics proposed by TAC-KBP 2011, if the value of the relation instance is judged as correct, the score for temporal anchoring depends on how well the returned interval matches the one provided in the key.",
        "More precisely, let the correct imprecise anchor interval in the gold standard key",
        "a constraint in t2 or t4 is treated as a value of +?.",
        "Then, let di = |ki ?",
        "ri|, for i ?",
        "1, .",
        ".",
        ".",
        ", 4, be the difference, a real number measured in years.",
        "The score for the system response is:",
        "The score for a target relation Q(r) is computed by summing Q(S) over all unique instances of the relation whose value is correct.",
        "If the gold standard contains N responses, and the system output M responses, then precision is: P = Q(r)/M , and recall:",
        "Experiments.",
        "We evaluated two different settings for the temporal anchoring step; both use the collapsed document graph representation, GC (SETTING 2).",
        "The goal of the experiment is twofold.",
        "First, test the strength of the document creation time as evidence for temporal anchoring.",
        "Second, test how hard this metadata-level baseline is to beat using contextual temporal expressions.",
        "The SETTING 2-I assumes a within temporal link between the document creation time and any relation expressed inside the document, and aggregates this information across the documents that we have identified as supporting the relation.",
        "The SETTING 2-II considers documents content in order to extract temporal links from the context of the text that expresses the relation.",
        "If no temporal expression is found, the date of the document is used as default.",
        "Temporal links from all supporting documents are mapped into intervals and aggregated as detailed in section 5.",
        "The performance on relation extraction is an upper bound for temporal anchoring, attainable if temporal anchoring is perfect.",
        "Thus, we also evaluate the temporal anchoring performance as the percentage the final system achieves with respect to the relation extraction upper bound.",
        "Results.",
        "Results are shown in Table 3 under column Temporal Anchoring.",
        "They are low, due to the upper bound that error propagation in candidate retrieval and relation extraction imposes upon this step: temporally anchoring alone achives 69% of its upper bound.",
        "This value corresponds to the baseline SETTING 2-I, showing its strength.",
        "The difference with SETTING 2-II shows that this baseline is difficult to beat by considering temporal evidence inside the document content.",
        "There is a reason for this.",
        "The temporal link mapping into time intervals does not depend only on the type of link, but also on the semantics of the text that expresses the relation as we pointed out above.",
        "We have to decide how to transform the link between relation and temporal expression into a temporal interval.",
        "Learning a model for this is a hard open research problem that has a strong adversary in the baseline proposed."
      ]
    },
    {
      "heading": "6.3 Comparative Evaluation",
      "text": [
        "Our approach was compared with the other four participants at the KBP Temporal Slot Filling Task 2011.",
        "Table 4 shows results sorted by F-measure in comparison to our two settings (described above).",
        "These official results correspond to a previous dataset containing 712 triples4.",
        "As shown in column Filled our approach returns less triples than other systems, explaining low recall.",
        "However, our system achieves the highest precision for the complete task of temporally anchored relation extraction.",
        "Despite low recall, our system obtains the third best F1 value.",
        "This is a very promising result, since several directions can be explored to consider more candidates and increase recall."
      ]
    },
    {
      "heading": "7 Related Work",
      "text": [
        "Compiling a Knowledge Base of temporally anchored facts is an open research challenge (Weikum et al., 2011).",
        "Despite the vast amount of research focusing on understanding temporal expressions and 4Slot-fillers from human assessors were not considered their relation to events in natural language, the complete problem of temporally anchored relation extraction remains relatively unexplored.",
        "Also, while much research has focused on single-document extraction, it seems clear that extracting temporally anchored relations needs the aggregation of evidences across multiple documents.",
        "There have been attempts to extend an existing knowledge base.",
        "Wang et al. (2010) use regular expressions to mine Wikipedia infoboxes and categories and it is not suited for unrestricted text.",
        "An earlier attempt (Zhang et al., 2008), is specific for business and difficult to generalize to other relations.",
        "Two recent promising works are more related to our research.",
        "Wang et al. (2011) uses manually defined patterns to collect candidate facts and explicit dates, and re-rank them using a graph label propagation algorithm; their approach is complementary to ours, as our aim is not to harvest temporal facts but to extract the relations in which a query entity takes part; unlike us, they require entity, value, and a explicit date to appear in the same sentence.",
        "Talukdar et al. (2012) focus on the partial task of temporally anchoring already known facts, showing the usefulness of the document creation time as temporal signal, aggregated across documents.",
        "Earlier work has dealt mainly with partial aspects of the problem.",
        "The TempEval community focused on the classification of the temporal links between pairs of events, or an event and a temporal expression; using shallow features (Mani et al., 2003; La-pata and Lascarides, 2004; Chambers et al., 2007), or syntactic-based structured features (Bethard and Martin, 2007; Pus?cas?u, 2007; Cheng et al., 2007).",
        "Aggregating evidence across different documents",
        "to temporally anchor facts has been explored in settings different to Information Extraction, such as answering of definition questions (Pas?ca, 2008) or extracting possible dates of well-known historical events (Schockaert et al., 2010).",
        "Temporal inference or reasoning to solve conflicting temporal expressions and induce temporal order of events has been used in TempEval (Tatu and Srikanth, 2008; Yoshikawa et al., 2009) and ACE (Gupta and Ji, 2009) tasks, but focused on single-document extraction.",
        "Ling et al. (2010), use cross-event joint inference to extract temporal facts, but only inside a single document.",
        "Evaluation campaigns, such as ACE and TAC-KBP 2011 have had an important role in promoting this research.",
        "While ACE required only to identify time expressions and classify their relation to events, KBP requires to infer explicitly the start/end time of relations, which is a realistic approach in the context of building time-aware knowledge bases.",
        "KBP represents an important step for the evaluation of temporal information extraction systems.",
        "In general, the participant systems adapted existing slot filling systems, adding a temporal classification component: distant supervised (Chen et al., 2010; Surdeanu et al., 2010) on manually-defined patterns (Byrne and Dunnion, 2010)."
      ]
    },
    {
      "heading": "8 Conclusions",
      "text": [
        "This paper introduces the problem of extracting, from unrestricted natural language text, relational knowledge anchored to a temporal span, aggregating temporal evidence from a collection of documents.",
        "Although compiling time-aware knowledge bases is an important open challenge (Weikum et al., 2011), it has remained unexplored until very recently (Wang et al., 2011; Talukdar et al., 2012).",
        "We have elucidated the two challenges of the task, namely relation extraction and temporal anchoring of the extracted relations.",
        "We have studied how, in a pipeline architecture, the propagation of errors limits the overall system's performance.",
        "The performance attainable in the full task is limited by the quality of the output of the three main phases: retrieval of candidate passages/ documents, extraction of relations and temporal anchoring of those.",
        "We have also studied the limits of the distant supervision approach to relation extraction, showing empirically that its performance depends not only on the nature of reference knowledge base and document corpus (Riedel et al., 2010), but also on the relation to be extracted.",
        "Given a relation between two arguments, if it is not dominant among textual expressions of those arguments, the distant supervision assumption will be more often violated.",
        "We have introduced a novel graph-based document level representation, that has allowed us to generate new features for the task of relation extraction, capturing long distance structured contexts.",
        "Our results show how, in a document level syntactic representation, it yields better results to collapse coreferent nodes.",
        "We have presented a methodological approach to temporal anchoring composed of: (1) intra-document temporal information representation; (2) selection of relation-dependent relevant temporal information; (3) mapping of temporal links to an interval representation; and (4) aggregation of imprecise intervals.",
        "Our proposal has been evaluated within a framework that allows for comparability.",
        "It has been able to extract temporally anchored relational information with the highest precision among the participant systems taking part in the competitive evaluation TAC-KBP 2011.",
        "For the temporal anchoring sub-problem, we have demonstrated the strength of the document creation time as a temporal signal.",
        "It is possible to achieve a performance of 69% of the upper-bound imposed by relation extraction by assuming that any relation mentioned in a document held at the document creation time (there is a within link between the relational fact and the document creation time).",
        "This baseline has proved stronger than extracting and an-alyzing the temporal expressions present in the document content."
      ]
    },
    {
      "heading": "Acknowledgments",
      "text": [
        "This work has been partially supported by the Spanish Ministry of Science and Innovation, through the project Holopedia (TIN2010-21128-C02), and the Regional Government of Madrid, through the project MA2VICMR (S2009/TIC1542)."
      ]
    }
  ]
}
