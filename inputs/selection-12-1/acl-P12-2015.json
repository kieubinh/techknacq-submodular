{
  "info": {
    "authors": [
      "Tony Veale"
    ],
    "book": "ACL",
    "id": "acl-P12-2015",
    "title": "A Context-sensitive, Multifaceted Model of Lexico-Conceptual Affect",
    "url": "https://aclweb.org/anthology/P12-2015",
    "year": 2012
  },
  "references": [
    "acl-P02-1053",
    "acl-P05-1017",
    "acl-P07-1008",
    "acl-P07-1054",
    "acl-P11-1029",
    "acl-W04-3252",
    "acl-W10-0204",
    "acl-W11-1709"
  ],
  "sections": [
    {
      "text": [
        "Liu et al. (2003) also present a multidimensional affective model that uses the six basic emotion categories of Ekman (1993) as its dimensions: happy, sad, angry, fearful, disgusted and surprised.",
        "These authors base estimates of affect on the contents of Open Mind, a common-sense knowledge-base (Singh, 2002) harvested from contributions of web volunteers.",
        "These contents are treated as sentential objects, and a range of NLP models is used to derive affective labels for the subset of contents (~10%) that appear to convey an emotional stance.",
        "These labels are then propagated to related concepts (e.g., excitement is propagated from roller-coasters to amusement parks) so that the implicit affect of many other concepts can be determined.",
        "Strapparava and Valitutti (2004) provide a set of affective annotations for a subset of WordNet's synsets in a resource called Wordnet-affect.",
        "The annotation labels, called a-labels, focus on the cognitive dynamics of emotion, allowing one to distinguish e.g. between words that denote an emo-tion-eliciting situation and those than denote an emotional response.",
        "Esuli and Sebastiani (2006) also build directly on WordNet as their lexical plat-form, using a semi-supervised learning algorithm to assign a trio of numbers ?",
        "positivity, negativity and neutrality ?",
        "to word senses in their newly derived resource, SentiWordNet.",
        "(Wordnet-affect also supports these three dimensions as a-labels, and adds a fourth, ambiguous).",
        "Esuli & Sebastiani (2007) improve on their affect scores by running a variant of the PageRank algorithm (see also Mihal-cea and Tarau, 2004) on the graph structure that tacitly connects word-senses in WordNet to each other via the words used in their textual glosses.",
        "These lexica attempt to capture the affective profile of a word/sense when it is used in its most normative and stereotypical guise, but they do so without an explicit model of stereotypical mean-ing.",
        "Veale & Hao (2007) describe a web-based approach to acquiring such a model.",
        "They note that since the simile pattern ?as ADJ as DET NOUN?",
        "presupposes that NOUN is an exemplar of ADJness, it follows that ADJ must be a highly salient property of NOUN.",
        "Veale & Hao harvested tens of thousands of instances of this pattern from the Web, to extract sets of adjectival properties for thousands of commonplace nouns.",
        "They show that if one estimates the pleasantness of a term like snake or artist as a weighted average of the pleasantness of its properties (like sneaky or creative) in a resource like Whissell's DoA, then the estimated scores show a reliable correlation with the DoA's own scores.",
        "It thus makes computational sense to calculate the affect of a word-concept as a function of the affect of its most salient properties.",
        "Veale (2011) later built on this work to show how a prop-erty-rich stereotypical representation could be used for non-literal matching and retrieval of creative texts, such as metaphors and analogies.",
        "Both Liu et al. (2003) and Veale & Hao (2010) argue for the importance of common-sense knowledge in the determination of affect.",
        "We incorporate ideas from both here, while choosing to build mainly on the latter, to construct a nuanced, two-level model of the affective lexicon.",
        "3 An Affective Lexicon of Stereotypes We construct the stereotype-based lexicon in two stages.",
        "For the first layer, a large collection of stereotypical descriptions is harvested from the web.",
        "As in Liu et al. (2003), our goal is to acquire a lightweight common-sense representation of many everyday concepts.",
        "For the second layer, we link these common-sense qualities in a support graph that captures how they mutually support each other in their co-description of a stereotypical idea.",
        "From this graph we can estimate pleasantness and unpleasantness valence scores for each property and behavior, and for the stereotypes that exhibit them.",
        "Expanding on the approach in Veale (2011), we use two kinds of query for harvesting stereotypes from the web.",
        "The first, ?as ADJ as a NOUN?, acquires typical adjectival properties for noun con-cepts; the second, ?VERB+ing like a NOUN?",
        "and ?VERB+ed like a NOUN?, acquires typical verb behaviors.",
        "Rather than use a wildcard * in both positions (ADJ and NOUN, or VERB and NOUN), which gives limited results with a search engine like Google, we generate fully instantiated similes from hypotheses generated via the Google n-grams (Brants & Franz, 2006).",
        "Thus, from the 3-gram ?a drooling zombie?",
        "we generate the query ?drooling like a zombie?, and from the 3-gram ?a mindless zombie?",
        "we generate ?as mindless as a zombie?.",
        "Only those queries that retrieve one or more Web documents via the Google API indicate the most promising associations.",
        "This still gives us over 250,000 web-validated simile associations for our stereotypical model, and we filter these manu-ally, to ensure that the lexicon is both reusable and",
        "of the highest quality.",
        "We obtain rich descriptions for many stereotypical ideas, such as Baby, which is described via 163 typical properties and behav-iors like crying, drooling and guileless.",
        "After this phase, the lexicon maps each of 9,479 stereotypes to a mix of 7,898 properties and behaviors.",
        "We construct the second level of the lexicon by automatically linking these properties and behav-iors to each other in a support graph.",
        "The intuition here is that properties which reinforce each other in a single description (e.g. ?as lush and green as a jungle?",
        "or ?as hot and humid as a sauna?)",
        "are more likely to have a similar affect than properties which do not support each other.",
        "We first gather all Google 3-grams in which a pair of stereotypical properties or behaviors X and Y are linked via co-ordination, as in ?hot and humid?",
        "or ?kicking and screaming?.",
        "A bidirectional link between X and Y is added to the support graph if one or more stereotypes in the lexicon contain both X and Y.",
        "If this is not so, we also ask whether both descriptors ever reinforce each other in Web similes, by posing the web query ?as X and Y as?.",
        "If this query has non-zero hits, we still add a link between X and Y.",
        "Let N denote this support graph, and N(p) denote the set of neighboring terms to p, that is, the set of properties and behaviors that can mutually support a property p. Since every edge in N represents an affective context, we can estimate the likelihood that p is ever used in a positive or negative context if we know the positive or negative affect of enough members of N(p).",
        "So if we label enough vertices of N with + / ?",
        "labels, we can interpolate a positive/negative affect for all vertices p in N. We thus build a reference set R of typically negative words, and a set +R of typically positive words.",
        "Given a few seed members of R (such as sad, evil, etc.)",
        "and a few seed members of +R (such as happy, wonderful, etc.",
        "), we find many other candidates to add to +R and R by considering neighbors of these seeds in N. After just three iterations, +R and R contain ~2000 words each.",
        "For a property p, we define N+(p) and N-(p) as (1) N+(p) = N(p) ?",
        "+R (2) N-(p) = N(p) ?",
        "-R We assign pos/neg valence scores to each property p by interpolating from reference values to their neighbors in N. Unlike that of Takamura et al. (2005), the approach is non-iterative and involves no feedback between the nodes of N, and thus, no interdependence between adjacent affect scores: (3) pos(p) = |N+(p) ||N+(p) ?",
        "N-(p) |(4) neg(p) = 1 - pos(p) If a term S denotes a stereotypical idea and is described via a set of typical properties and behaviors typical(S) in the lexicon, then:",
        "(5) pos(S) = ?p?typical(S) pos(p) |typical(S)| (6) neg(S) = 1 - pos(S) Thus, (5) and (6) calculate the mean affect of the properties and behaviors of S, as represented via typical(S).",
        "We can now use (3) and (4) to separate typical(S) into those elements that are more negative than positive (putting an unpleasant spin on S in context) and those that are more positive than negative (putting a pleasant spin on S in context): (7) posTypical(S) = {p |p ?",
        "typical(S) ?",
        "pos(p) > 0.5} (8) negTypical(S) = {p |p ?",
        "typical(S) ?",
        "neg(p) > 0.5} 4 Empirical Evaluation In the process of populating +R and -R, we identify a reference set of 478 positive stereotype nouns (such as saint and hero) and 677 negative stereotype nouns (such as tyrant and monster).",
        "We can use these reference stereotypes to test the effectiveness of (5) and (6), and thus, indirectly, of (3) and (4) and of the affective lexicon itself.",
        "Thus, we find that 96.7% of the stereotypes in +R are correctly assigned a positivity score greater than 0.5 (pos(S) > neg(S)) by (5), while 96.2% of the stereotypes in R are correctly assigned a negativity score greater than 0.5 (neg(S) > pos(S)) by (6).",
        "We can also use +R and R as a gold standard for evaluating the separation of typical(S) into distinct positive and negative subsets posTypical(S) and negTypical(S) via (7) and (8).",
        "The lexicon contains 6,230 stereotypes with at least one property in +R?-R. On average, +R?-R contains 6.51 of the properties of each of these stereotypes, where, on average, 2.95 are in +R while 3.56 are in -R. In a perfect separation, (7) should yield a positive subset that contains only those properties in",
        "typical(S)?+R, while (8) should yield a negative subset that contains only those in typical(S)?-R. Macro Averages (6230 stereotypes) Positive properties Negative properties Precision .962 .98 Recall .975 .958 F-Score .968 .968 Table 1.",
        "Average P/R/F1 scores for the affective retrieval of +/- properties from 6,230 stereotypes.",
        "Viewing the problem as a retrieval task then, in which (7) and (8) are used to retrieve distinct positive and negative property sets for a stereotype S, we report the encouraging results of Table 1 above."
      ]
    },
    {
      "heading": "5 Reshaping Affect in Figurative Contexts The Google n-grams are a rich source of affective metaphors of the form Target is Source, such as ?politicians are crooks?, ?Apple is a cult?, ?racism is a disease? and ?Steve Jobs is a god?. Let src(T) denote the set of stereotypes that are commonly used to describe T, where commonality is defined as the presence of the corresponding copula metaphor in the Google n-grams. Thus, for example: src(racism) = {problem, disease, poison, sin, crime, ideology, weapon, ?} src(Hitler) = {monster, criminal, tyrant, idiot, madman, vegetarian, racist, ?} Let srcTypical(T) denote the aggregation of all properties ascribable to T via metaphors in src(T):",
      "text": [
        "(9) srcTypical (T) = M?src(T)typical(M) We can also use the posTypical and negTypical variants in (7) and (8) to focus only on metaphors that project positive or negative qualities onto T. In effect, (9) provides a feature representation for a topic T as viewed through the prism of meta-phor.",
        "This is useful when the source S in the metaphor T is S is not a known stereotype in the lexicon, as happens e.g. in Apple is Scientology.",
        "We can also estimate whether a given term S is more positive than negative by taking the average pos/neg valence of src(S).",
        "Such estimates are 87% correct when evaluated using +R and R examples.",
        "The properties and behaviors that are contextually relevant to the interpretation of T is S are given by (10) salient (T,S) = |srcTypical(T) ?",
        "typical(T) |?",
        "|srcTypical(S) ?",
        "typical(S) |In the context of T is S, the figurative perspective M ?",
        "src(S)?src(T)?",
        "{S} is deemed apt for T if: (11) apt(M, T,S) = |salient(T,S) ?",
        "typical(M) |> 0 and the degree to which M is apt for T is given by: (12) aptness(M,T,S) = |salient(T, S) ?",
        "typical(M) ||typical(M) |We can construct an interpretation for T is S by considering not just {S}, but the stereotypes in src(T) that are apt for T in the context of T is S, as well as the stereotypes that are commonly used to describe S ?",
        "that is, src(S) ?",
        "that are also apt for T: (13) interpretation(T, S) = {M|M ?",
        "src(T)?src(S)?",
        "{S} ?",
        "apt(M, T, S)} The elements {Mi} of interpretation(T, S) can now be sorted by aptness(Mi T, S) to produce a ranked list of interpretations (M1, M2 ?",
        "Mn).",
        "For any interpretation M, the salient features of M are thus: (14) salient(M, T,S) = typical(M) ?",
        "salient (T,S) So interpretation(T, S) is an expansion of the affective metaphor T is S that includes the common metaphors that are consistent with T qua S. For instance, ?Google is -Microsoft?",
        "(where - indicates a negative spin) produces {monopoly, threat, bully, giant, dinosaur, demon, ?}.",
        "For each Mi in inter-pretation(T, S), salient(Mi, T, S) is an expansion of Mi that includes all of the qualities that are apt for T qua Mi (e.g. threatening, sprawling, evil, etc.).",
        "6 Concluding Remarks Metaphor is the perfect tool for influencing the perceived affect of words and concepts in context.",
        "The web application Metaphor Magnet provides a proof-of-concept demonstration of this reshaping process at work, using the stereotype lexicon of ?3, the selective highlighting of (7)?",
        "(8), and the model of metaphor in (9)?(14).",
        "It can be accessed at: http://boundinanutshell.com/metaphor-magnet ?"
      ]
    }
  ]
}
