{
  "info": {
    "authors": [
      "Alessandro Lenci",
      "Giulia Benotto"
    ],
    "book": "SemEval",
    "id": "acl-S12-1012",
    "title": "Identifying hypernyms in distributional semantic spaces",
    "url": "https://aclweb.org/anthology/S12-1012",
    "year": 2012
  },
  "references": [
    "acl-C04-1146",
    "acl-C08-1107",
    "acl-C92-2082",
    "acl-J09-3004",
    "acl-J10-4006",
    "acl-P05-1014",
    "acl-P06-1015",
    "acl-P09-2018",
    "acl-P98-2127",
    "acl-W03-1011",
    "acl-W09-0215",
    "acl-W09-1109",
    "acl-W09-3711",
    "acl-W11-2501"
  ],
  "sections": [
    {
      "text": [
        "tuple.",
        "Then, we applied the 4 directional similarity measures in section 2 to BLESS, with the goal of evaluating their ability to discriminate hy-pernyms from other semantic relations, in particular co-hyponymy.",
        "In fact, differently from hypernyms, coordinate terms are not related by inclusion.",
        "Therefore, we want to test whether directional similarity measures are able to assign higher scores to hypernyms, as predicted by the Distributional Inclusion Hypothesis.",
        "We used the Cosine as our baseline, since it is a symmetric similarity measure and it is commonly used in DSMs.",
        "We adopt two different evaluation methods.",
        "The first is based on the methodology described in Ba-roni and Lenci (2011).",
        "Given the similarity scores for a concept with all its relata across all relations in our test set, we pick the relatum with the highest score (nearest neighbour) for each relation.",
        "In this way, for each of the 200 BLESS concepts, we obtain 4 similarity scores, one per relation.",
        "In order to factor out concept-specific effects that might add to the overall score variance, we transform the 8 similarity scores of each concept onto standardized z scores (mean: 0; s.d: 1) by subtracting from each their mean, and dividing by their standard deviation.",
        "After this transformation, we produce a box-plot summarizing the distribution of scores per relation across the 200 concepts.",
        "Boxplots for each similarity measure are reported in Figure 1.",
        "They display the median of a distribution as a thick horizontal line within a box extending from the first to the third quartile, with whiskers covering 1.5 of the interquartile range in each direction from the box, and values outside this extended range ?",
        "extreme outliers ?",
        "plotted as circles (these are the default boxplotting option of the R statistical package).",
        "To identify significant differences between relation types, we also performed pairwise comparisons with the Tukey Honestly Significant Difference test, using the standard ?",
        "= 0.05 significance threshold.",
        "In the boxplots we can observe that all measures (either symmetric or not) are able to discriminate truly semantically related pairs from unrelated (i.e. random) ones.",
        "Crucially, Cosine shows a strong tendency to identify coordinates among the nearest neighbors of target items.",
        "This is actually consistent with its being a symmetric similarity measure.",
        "Instead, directional similarity measures significantly promote hypernyms over coordinates.",
        "The only exception is represented by cosWeeds, which again places coordinates at the top, though now the difference with hypernyms is not significant.",
        "This might be due to the cosine component of this measure, which reduces the effectiveness of the asymmetric WeedsPrec.",
        "The difference between coordinates and hypernyms is slightly bigger in invCL, and the former appear to be further downgraded than with the other directional measures.",
        "From the box-plot analysis, we can therefore conclude that similarity measures based on the Distributional Inclusion Hypothesis do indeed improve hypernym identification in context-feature semantic spaces, with respect to other types of semantic relations, such as COORD.",
        "by-concept z-normalization).",
        "The second type of evaluation we have performed is based on Kotlerman et al. (2010).",
        "The similarity measures have been evaluated with Average Precision (AP), a method derived from Information Retrieval and combining precision, relevance ranking and overall recall.",
        "For each similarity measure, we computed AP with respect to the 4 BLESS relations.",
        "The best possible score (AP = 1) for a given relation (e.g., HYPER) corresponds to the ideal case in which all the relata belonging to that relation have higher similarity scores than the relata belonging to the other relations.",
        "For every relation, we calculated the AP for each of the 200 BLESS target concepts.",
        "In Table 1, we report the AP values averaged over the 200 concepts.",
        "On the one hand, these results confirm the trend illustrated by the boxplots, in particular the fact that directional similarity measures clearly outperform Cosine (or cosine-based measures such as cosWeeds) in identifying hypernyms, with no significant differences among them.",
        "However, a different picture emerges by comparing the"
      ]
    },
    {
      "heading": "measure COORD HYPER MERO RANDOM-NCosine 0.79 0.23 0.21 0.30WeedsPrec 0.45 0.40 0.31 0.32cosWeeds 0.69 0.29 0.23 0.30ClarkeDE 0.45 0.39 0.28 0.33invCL 0.38 0.40 0.31 0.34",
      "text": [
        "ported by the different similarity scores.",
        "AP values for HYPER with those for COORD.",
        "since in this case important distinctions among the directional measures emerge.",
        "In fact, even if Weed-sPrec and ClarkeDE increase the AP for HYPER, still they assign even higher AP values to COORD.",
        "Conversely, invCL is the only measure that assigns to HYPER the top AP score, higher than COORD too.",
        "The new directional similarity measure we have proposed in this paper, invCL, thus reveals a higher ability to set apart hypernyms from other relations, coordinates terms included.",
        "The latter are expected",
        "to share a large number of contexts and this is the reason why they are strongly favored by symmetric similarity measures, such as Cosine.",
        "Asymmetric measures like cosWeeds and ClarkeDE also fall short of distinguishing hypernyms from coordinates because the condition of feature inclusion they test is satisfied by coordinate terms as well.",
        "If two sets share a high number of elements, then many elements of the former are also included in the latter, and vice versa.",
        "Therefore, coordinate terms too are expected to have high values of feature inclusions.",
        "Conversely, invCL takes into account not only the inclusion of u into v, but also the amount of v that is not included in u.",
        "Thus, invCL provides a better distributional correlate to the central property of hypernyms of having a broader semantic content than their hyponyms.4 Conclusions and ongoing research The experiments reported in this paper support the Distributional Inclusion Hypothesis as a viable approach to model hypernymy in semantic vector spaces.",
        "We have also proposed a new directional measure that actually outperforms the state-of-the-art ones.",
        "Focusing on the contexts that broader terms do not share with their narrower terms thus appear to be an interesting direction to explore to improve hypernym identification.",
        "Our ongoing research includes testing invCL to recognize lexical entailments and comparing it with the balAPinc measured proposed by Kotlerman et al. (2010) for this task, as well as designing new distributional methods to discriminate between various other types of semantic relations.Acknowledgments We thank the reviewers for their useful and insightful comments on the paper.References"
      ]
    }
  ]
}
