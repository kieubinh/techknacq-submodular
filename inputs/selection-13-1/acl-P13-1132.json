{
  "info": {
    "authors": [
      "Mohammad Taher Pilehvar",
      "David Jurgens",
      "Roberto Navigli"
    ],
    "book": "ACL",
    "id": "acl-P13-1132",
    "title": "Align, Disambiguate and Walk: A Unified Approach for Measuring Semantic Similarity",
    "url": "https://aclweb.org/anthology/P13-1132",
    "year": 2013
  },
  "references": [
    "acl-C10-1005",
    "acl-D07-1061",
    "acl-D07-1107",
    "acl-J06-1003",
    "acl-J11-2003",
    "acl-J12-1003",
    "acl-J12-1005",
    "acl-J13-3008",
    "acl-N06-2015",
    "acl-N09-1003",
    "acl-N13-1130",
    "acl-P06-1014",
    "acl-P08-2067",
    "acl-P11-2087",
    "acl-P95-1026",
    "acl-P98-2127",
    "acl-S12-1051",
    "acl-S12-1059",
    "acl-S12-1060",
    "acl-W05-1203",
    "acl-W06-2503",
    "acl-W09-3204"
  ],
  "sections": [
    {
      "heading": "Abstract",
      "text": [
        "Semantic similarity is an essential component of many Natural Language Processing applications.",
        "However, prior methods for computing semantic similarity often operate at different levels, e.g., single words or entire documents, which requires adapting the method for each data type.",
        "We present a unified approach to semantic similarity that operates at multiple levels, all the way from comparing word senses to comparing text documents.",
        "Our method leverages a common probabilistic representation over word senses in order to compare different types of linguistic data.",
        "This unified representation shows state-of-the-art performance on three tasks: semantic textual similarity, word similarity, and word sense coarsening."
      ]
    },
    {
      "heading": "1 Introduction",
      "text": [
        "Semantic similarity is a core technique for many topics in Natural Language Processing such as Textual Entailment (Berant et al., 2012), Semantic Role Labeling (Fu?rstenau and Lapata, 2012), and Question Answering (Surdeanu et al., 2011).",
        "For example, textual similarity enables relevant documents to be identified for information retrieval (Hliaoutakis et al., 2006), while identifying similar words enables tasks such as paraphrasing (Glickman and Dagan, 2003), lexical substitution (McCarthy and Navigli, 2009), lexical simplification (Biran et al., 2011), and Web search result clustering (Di Marco and Navigli, 2013).",
        "Approaches to semantic similarity have often operated at separate levels: methods for word similarity are rarely applied to documents or even single sentences (Budanitsky and Hirst, 2006; Radinsky et al., 2011; Halawi et al., 2012), while document-based similarity methods require more linguistic features, which often makes them inapplicable at the word or microtext level (Salton et al., 1975; Maguitman et al., 2005; Elsayed et al., 2008; Turney and Pantel, 2010).",
        "Despite the potential advantages, few approaches to semantic similarity operate at the sense level due to the challenge in sense-tagging text (Navigli, 2009); for example, none of the top four systems in the recent SemEval-2012 task on textual similarity compared semantic representations that incorporated sense information (Agirre et al., 2012).",
        "We propose a unified approach to semantic similarity across multiple representation levels from senses to documents, which offers two significant advantages.",
        "First, the method is applicable independently of the input type, which enables meaningful similarity comparisons across different scales of text or lexical levels.",
        "Second, by operating at the sense level, a unified approach is able to identify the semantic similarities that exist independently of the text's lexical forms and any semantic ambiguity therein.",
        "For example, consider the sentences: t1.",
        "A manager fired the worker.",
        "t2.",
        "An employee was terminated from work by his boss.",
        "A surface-based approach would label the sentences as dissimilar due to the minimal lexical overlap.",
        "However, a sense-based representation enables detection of the similarity between the meanings of the words, e.g., fire and terminate.",
        "Indeed, an accurate, sense-based representation is essential for cases where different words are used to convey the same meaning.",
        "The contributions of this paper are threefold.",
        "First, we propose a new unified representation of the meaning of an arbitrarily-sized piece of text, referred to as a lexical item, using a sense-based probability distribution.",
        "Second, we propose a novel alignment-based method for word sense dis",
        "ambiguation during semantic comparison.",
        "Third, we demonstrate that this single representation can achieve state-of-the-art performance on three similarity tasks, each operating at a different lexical level: (1) surpassing the highest scores on the SemEval-2012 task on textual similarity (Agirre et al., 2012) that compares sentences, (2) achieving a near-perfect performance on the TOEFL synonym selection task proposed by Landauer and Dumais (1997), which measures word pair similarity, and also obtaining state-of-the-art performance in terms of the correlation with human judgments on the RG-65 dataset (Rubenstein and Goodenough, 1965), and finally (3) surpassing the performance of Snow et al. (2007) in a sense-coarsening task that measures sense similarity."
      ]
    },
    {
      "heading": "2 A Unified Semantic Representation",
      "text": [
        "We propose a representation of any lexical item as a distribution over a set of word senses, referred to as the item's semantic signature.",
        "We begin with a formal description of the representation at the sense level (Section 2.1).",
        "Following this, we describe our alignment-based disambiguation algorithm which enables us to produce sense-based semantic signatures for those lexical items (e.g., words or sentences) which are not sense annotated (Section 2.2).",
        "Finally, we propose three methods for comparing these signatures (Section 2.3).",
        "As our sense inventory, we use WordNet 3.0 (Fell-baum, 1998)."
      ]
    },
    {
      "heading": "2.1 Semantic Signatures",
      "text": [
        "The WordNet ontology provides a rich network structure of semantic relatedness, connecting senses directly with their hypernyms, and providing information on semantically similar senses by virtue of their nearby locality in the network.",
        "Given a particular node (sense) in the network, repeated random walks beginning at that node will produce a frequency distribution over the nodes in the graph visited during the walk.",
        "To extend beyond a single sense, the random walk may be initialized and restarted from a set of senses (seed nodes), rather than just one; this multi-seed walk produces a multinomial distribution over all the senses in WordNet with higher probability assigned to senses that are frequently visited from the seeds.",
        "Prior work has demonstrated that multi-nomials generated from random walks over WordNet can be successfully applied to linguistic tasks such as word similarity (Hughes and Ramage, 2007; Agirre et al., 2009), paraphrase recognition, textual entailment (Ramage et al., 2009), and pseudoword generation (Pilehvar and Navigli, 2013).",
        "Formally, we define the semantic signature of a lexical item as the multinomial distribution generated from the random walks over WordNet 3.0 where the set of seed nodes is the set of senses present in the item.",
        "This representation encompasses both when the item is itself a single sense and when the item is a sense-tagged sentence.",
        "To construct each semantic signature, we use the iterative method for calculating topic-sensitive PageRank (Haveliwala, 2002).",
        "Let M be the adjacency matrix for the WordNet network, where edges connect senses according to the relations defined in WordNet (e.g., hypernymy and meronymy).",
        "We further enrich M by connecting a sense with all the other senses that appear in its disambiguated gloss.1 Let ~v(0) denote the probability distribution for the starting location of the random walker in the network.",
        "Given the set of senses S in a lexical item, the probability mass of ~v(0) is uniformly distributed across the senses si ?",
        "S, with the mass for all sj /?",
        "S set to zero.",
        "The PageRank may then be computed using:",
        "where at each iteration the random walker may jump to any node si ?",
        "S with probability ?/|S|.",
        "We follow standard convention and set ?",
        "to 0.15.",
        "We repeat the operation in Eq.",
        "1 for 30 iterations, which is sufficient for the distribution to converge.",
        "The resulting probability vector ~v(t) is the semantic signature of the lexical item, as it has aggregated its senses?",
        "similarities over the entire graph.",
        "For our semantic signatures we used the UKB2 off-the-shelf implementation of topic-sensitive PageRank."
      ]
    },
    {
      "heading": "2.2 Alignment-Based Disambiguation",
      "text": [
        "Commonly, semantic comparisons are between word pairs or sentence pairs that do not have their lexical content sense-annotated, despite the potential utility of sense annotation in making semantic comparisons.",
        "However, traditional forms of word sense disambiguation are difficult for short texts and single words because little or no contextual information is present to perform the disambiguation task.",
        "Therefore, we propose a novel",
        "is taken as the disambiguated sense of its corresponding word).",
        "alignment-based sense disambiguation that leverages the content of the paired item in order to disambiguate each element.",
        "Leveraging the paired item enables our approach to disambiguate where traditional sense disambiguation methods can not due to insufficient context.",
        "We view sense disambiguation as an alignment problem.",
        "Given two arbitrarily ordered texts, we seek the semantic alignment that maximizes the similarity of the senses of the context words in both texts.",
        "To find this maximum we use an alignment procedure which, for each word type wi in item T1, assigns wi to the sense that has the maximal similarity to any sense of the word types in the compared text T2.",
        "Algorithm 1 formalizes the alignment process, which produces a sense disambiguated representation as a result.",
        "Senses are compared in terms of their semantic signatures, denoted as function R. We consider multiple definitions ofR, defined later in Section 2.3.",
        "As a part of the disambiguation procedure, we leverage the one sense per discourse heuristic of Yarowsky (1995); given all the word types in two compared lexical items, each type is assigned a single sense, even if it is used multiple times.",
        "Additionally, if the same word type appears in both sentences, both will always be mapped to the same sense.",
        "Although such a sense assignment is potentially incorrect, assigning both types to the same sense results in a representation that does no worse than a surface-level comparison.",
        "We illustrate the alignment-based disambiguation procedure using the two example sentences t1 and t2 given in Section 1.",
        "Figure 1(a) illustrates example alignments of the first sense of manager to the first two senses of the word types in sentence t2 along with the similarity of the two senses?",
        "Algorithm 1 Alignment-based Sense Disambiguation Input: T1 and T2, the sets of word types being compared Output: P , the set of disambiguated senses for T1",
        "1: P ?",
        "?",
        "2: for each token ti ?",
        "T1 3: max sim?",
        "0 4: best si?",
        "null 5: for each token tj ?",
        "T2 6: for each si ?",
        "Senses(ti), sj ?",
        "Senses(tj) 7: sim?R(si, sj) 8: if sim > max sim then 9: max sim = sim 10: best si = si 11: P ?",
        "P ?",
        "{best si} 12: return P",
        "semantic signatures.",
        "For the senses of manager, sense manager1n obtains the maximal similarity value to boss1n among all the possible pairings of the senses for the word types in sentence t2, and as a result is selected as the sense labeling for manager in sentence t1.3 Figure 1(b) shows the final, maximally-similar sense alignment of the word types in t1 and t2.",
        "The resulting alignment produces the following sets of senses:",
        "where Px denotes the corresponding set of senses of sentence x."
      ]
    },
    {
      "heading": "2.3 Semantic Signature Similarity",
      "text": [
        "Cosine Similarity.",
        "In order to compare semantic signatures, we adopt the Cosine similarity measure as a baseline method.",
        "The measure is computed by treating each multinomial as a vector and then calculating the normalized dot product of the two signatures?",
        "vectors.",
        "However, a semantic signature is, in essence, a weighted ranking of the importance of WordNet senses for each lexical item.",
        "Given that the WordNet graph has a non-uniform structure, and also given that different lexical items may be of different sizes, the magnitudes of the probabilities obtained may differ significantly between the two multinomial distributions.",
        "Therefore, for computing the similarity of two signatures, we also consider two nonparametric methods that use the ranking of the senses, rather than their probability values, in the multinomial.",
        "Weighted Overlap.",
        "Our first measure provides a nonparametric similarity by comparing the similarity of the rankings for intersection of the senses in both semantic signatures.",
        "However, we additionally weight the similarity such that differences in the highest ranks are penalized more than differences in lower ranks.",
        "We refer to this measure as the Weighted Overlap.",
        "Let S denote the intersection of all senses with non-zero probability in both signatures and rji denote the rank of sense si ?",
        "S in signature j, where rank 1 denotes the highest rank.",
        "The sum of the two ranks r1i and r2i for a sense is then inverted, which (1) weights higher ranks more and (2) when summed, provides the maximal value when a sense has the same rank in both signatures.",
        "The unnormalized weighted overlap is then calculated as?|S|i=1(r1i + r2i )?1.",
        "Then, to bound the similarity value in [0, 1], we normalize the sum by its maximum value, ?|S|i=1(2i)?1, which occurs when each sense has the same rank in both signatures.",
        "Top-k Jaccard.",
        "Our second measure uses the ranking to identify the top-k senses in a signature, which are treated as the best representatives of the conceptual associates.",
        "We hypothesize that a specific rank ordering may be attributed to small differences in the multinomial probabilities, which can lower rank-based similarities when one of the compared orderings is perturbed due to slightly different probability values.",
        "Therefore, we consider the top-k senses as an unordered set, with equal importance in the signature.",
        "To compare two signatures, we compute the Jaccard Index of the two signatures?",
        "sets:",
        "(2) whereUk denotes the set of k senses with the highest probability in the semantic signature U .",
        "Dataset MSRvid MSRpar SMTeuroparl OnWN SMTnews"
      ]
    },
    {
      "heading": "3 Experiment 1: Textual Similarity",
      "text": [
        "Measuring semantic similarity of textual items has applications in a wide variety of NLP tasks.",
        "As our benchmark, we selected the recent SemEval2012 task on Semantic Textual Similarity (STS), which was concerned with measuring the semantic similarity of sentence pairs.",
        "The task received considerable interest by facilitating a meaningful comparison between approaches."
      ]
    },
    {
      "heading": "3.1 Experimental Setup",
      "text": [
        "Data.",
        "We follow the experimental setup used in the STS task (Agirre et al., 2012), which provided five test sets, two of which had accompanying training data sets for tuning system performance.",
        "Each sentence pair in the datasets was given a score from 0 to 5 (low to high similarity) by human judges, with a high inter-annotator agreement of around 0.90 when measured using the Pearson correlation coefficient.",
        "Table 1 lists the number of sentence pairs in training and test portions of each dataset.",
        "Comparison Systems.",
        "The top-ranking participating systems in the SemEval-2012 task were generally supervised systems utilizing a variety of lexical resources and similarity measurement techniques.",
        "We compare our results against the top three systems of the 88 submissions: TLsim and TLsyn, the two systems of S?aric?",
        "et al (2012), and the UKP2 system (Ba?r et al., 2012).",
        "UKP2 utilizes extensive resources among which are a Distributional Thesaurus computed on 10M dependency-parsed English sentences.",
        "In addition, the system utilizes techniques such as Explicit Semantic Analysis (Gabrilovich and Markovitch, 2007) and makes use of resources such as Wiktionary and Wikipedia, a lexical substitution system based on supervised word sense disambiguation (Biemann, 2013), and a statistical machine translation system.",
        "The TLsim system uses the New York Times Annotated Corpus, Wikipedia, and Google Book Ngrams.",
        "The TLsyn system also uses Google Book Ngrams, as well as dependency parsing and named entity recognition.",
        "son correlation r for individual datasets, i.e., MSRpar (Mpar), MSRvid (Mvid), SMTeuroparl (SMTe), OnWN (OnWN) and SMTnews (SMTn).",
        "We also provide scores according to the three official evaluation metrics (i.e., ALL, ALLnrm, and Mean).",
        "Rankings are also presented based on the three metrics.",
        "System Configuration.",
        "Here we describe the configuration of our approach, which we have called Align, Disambiguate and Walk (ADW).",
        "The STS task uses human similarity judgments on an ordinal scale from 0 to 5.",
        "Therefore, in ADW we adopted a similar approach to generating similarity values to that adopted by other participating systems, whereby a supervised system is trained to combine multiple similarity judgments to produce a final rating consistent with the human annotators.",
        "We utilized the WEKA toolkit (Hall et al., 2009) to train a Gaussian Processes regression model for each of the three training sets (cf. Table 1).",
        "The features discussed hereafter were considered in our regression model.",
        "Main features.",
        "We used the scores calculated using all three of our semantic signature comparison methods as individual features.",
        "Although the Jaccard comparison is parameterized, we avoided tuning and instead used four features for distinct values of k: 250, 500, 1000, and 2500.",
        "String-based features.",
        "Additionally, because the texts often contain named entities which are not present in WordNet, we incorporated the similarity values produced by four string-based measures, which were used by other teams in the STS task: (1) longest common substring which takes into account the length of the longest overlapping contiguous sequence of characters (substring) across two strings (Gusfield, 1997), (2) longest common subsequence which, instead, finds the longest overlapping subsequence of two strings (Allison and Dix, 1986), (3) Greedy String Tiling which allows reordering in strings (Wise, 1993), and (4) the character/word n-gram similarity proposed by Barro?n-Ceden?o et al. (2010).",
        "We followed S?aric?",
        "et al (2012) and used the models trained on the SMTeuroparl and MSRpar datasets for testing on the SMTnews and OnWN test sets, respectively."
      ]
    },
    {
      "heading": "3.2 STS Results",
      "text": [
        "Three evaluation metrics are provided by the organizers of the SemEval-2012 STS task, all of which are based on Pearson correlation r of human judgments with system outputs: (1) the correlation value for the concatenation of all five datasets (ALL), (2) a correlation value obtained on a concatenation of the outputs, separately normalized by least square (ALLnrm), and (3) the weighted average of Pearson correlations across datasets (Mean).",
        "Table 2 shows the scores obtained by ADW for the three evaluation metrics, as well as the Pearson correlation values obtained on each of the five test sets (rightmost columns).",
        "We also show the results obtained by the three top-ranking participating systems (i.e., UKP2, TLsim, and TLsyn).",
        "The leftmost three columns show the system rankings according to the three metrics.",
        "As can be seen from Table 2, our system (ADW) outperforms all the 88 participating systems according to all the evaluation metrics.",
        "Our system shows a statistically significant improvement on the SMTnews dataset, with an increase in the Pearson correlation of over 0.10.",
        "MSRpar (MPar) is the only dataset in which TLsim (S?aric?",
        "et al, 2012) achieves a higher correlation with human judgments.",
        "Named entity features used by the TLsim system could be the reason for its better performance on the MSRpar dataset, which contains a large number of named entities."
      ]
    },
    {
      "heading": "3.3 Similarity Measure Analysis",
      "text": [
        "To gain more insight into the impact of our alignment-based disambiguation approach, we carried out a 10-fold cross-validation on the three training datasets (cf. Table 1) using the systems described hereafter.",
        "ADW-MF.",
        "To build this system, we utilized our main features only; i.e., we did not make use of additional string-based features.",
        "DW.",
        "Similarly to ADW-MF, this system utilized the main features only.",
        "In DW, however, we replaced our alignment-based disambiguation phase with a random walk-based WSD system that disambiguated the sentences separately, without performing any alignment.",
        "As our WSD system, we used UKB, a state-of-the-art knowledge-based WSD system that is based on the same topic-sensitive PageRank algorithm used by our approach.",
        "UKB initializes the algorithm from all senses of the words in the context of a word to be disambiguated.",
        "It then picks the most relevant sense of the word according to the resulting probability vector.",
        "As the lexical knowledge base of UKB, we used the same semantic network as that utilized by our approach for calculating semantic signatures.",
        "Table 3 lists the performance values of the two above-mentioned systems on the three training sets in terms of Pearson correlation.",
        "In addition, we present in the table correlation scores for four other similarity measures reported by Ba?r et al. (2012): ?",
        "Pairwise Word Similarity that comprises of a set of WordNet-based similarity measures proposed by Resnik (1995), Jiang and Con-rath (1997), and Lin (1998b).",
        "The aggregation strategy proposed by Corley and Mi-halcea (2005) has been utilized for extending these word-to-word similarity measures for calculating text-to-text similarities.",
        "?",
        "Explicit Semantic Analysis (Gabrilovich and Markovitch, 2007) where the high-dimensional vectors are obtained on Word",
        "Net, Wikipedia and Wiktionary.",
        "?",
        "Distributional Thesaurus where a similarity score is computed similarly to that of Lin (1998a) using a distributional thesaurus obtained from a 10M dependency-parsed sentences of English newswire.",
        "?",
        "Character n-grams which were also used as",
        "one of our additional features.",
        "As can be seen from Table 3, our alignment-based disambiguation approach (ADW-MF) is better suited to the task than a conventional WSD approach (DW).",
        "Another interesting point is the high scores achieved by the Character n-grams",
        "tem with conventional WSD (DW) and with the alignment-based disambiguation approach (ADW-MF) vs. four other similarity measures, using 10- fold cross validation on the training datasets MSRpar (Mpar), MSRvid (Mvid), and SMTeuroparl (SMTe).",
        "measure.",
        "This confirms that string-based methods are strong baselines for semantic textual similarity.",
        "Except for the MSRpar (Mpar) dataset, our system (ADW-MF) outperforms all other similarity measures.",
        "The scores obtained by Explicit Semantic Analysis and Distributional Thesaurus are not competitive on any dataset.",
        "On the other hand, Pairwise Word Similarity achieves a high performance on MSRpar and MSRvid datasets, but performs surprisingly low on the SMTeuroparl dataset."
      ]
    },
    {
      "heading": "4 Experiment 2: Word Similarity",
      "text": [
        "We now proceed from the sentence level to the word level.",
        "Word similarity has been a key problem for lexical semantics, with significant efforts being made by approaches in distributional semantics to accurately identify synonymous words (Turney and Pantel, 2010).",
        "Different evaluation methods exist in the literature for evaluating the performance of a word-level semantic similarity measure; we adopted two well-established benchmarks: synonym recognition and correlating word similarity judgments with those from human annotators.",
        "For synonym recognition, we used the TOEFL dataset created by Landauer and Dumais (1997).",
        "The dataset consists of 80 multiple-choice synonym questions from the TOEFL test; a word is paired with four options, one of which is a valid synonym.",
        "Test takers with English as a second language averaged 64.5% correct.",
        "Despite multiple approaches, only recently has the test been answered perfectly (Bullinaria and Levy, 2012), underscoring the challenge of synonym recognition.",
        "Synonym test.",
        "ADWJac, ADWWO, and ADWCos correspond to results with the Jaccard, Weighted Overlap and Cosine signature comparison measures, respectively.",
        "For the similarity judgment evaluation, we used as benchmark the RG-65 dataset created by Rubenstein and Goodenough (1965).",
        "The dataset contains 65 word pairs judged by 51 human subjects on a scale of 0 to 4 according to their semantic similarity.",
        "Ideally, a measure's similarity judgments are expected to be highly correlated with those of humans.",
        "To be consistent with the previous literature (Hughes and Ramage, 2007; Agirre et al., 2009), we used Spearman's rank correlation in our experiment."
      ]
    },
    {
      "heading": "4.1 Experimental Setup",
      "text": [
        "Our alignment-based sense disambiguation transforms the task of comparing individual words into that of calculating the similarity of the best-matching sense pair across the two words.",
        "As there is no training data we do not optimize the k value for computing signature similarity with the Jaccard index; instead, we report, for the synonym recognition and the similarity judgment evaluations, the respective range of accuracies and the average correlation obtained upon using five values of k randomly selected in the range [50, 2500]: 678, 1412, 1692, 2358, 2387."
      ]
    },
    {
      "heading": "4.2 Word Similarity Results: TOEFL dataset",
      "text": [
        "Table 4 lists the accuracy performance of the system in comparison to the existing state of the art on the TOEFL test.",
        "ADWWO, ADWCos, and ADWJac correspond to our approach when Weighted Overlap, Cosine, and Jaccard signature comparison measures are used, respectively.",
        "Despite not being tuned for the task, our model achieves near-perfect performance, answering all but three questions correctly with the Cosine measure.",
        "Among the top-performing approaches, only Word Synonym choices (correct in bold) fanciful familiar apparent?",
        "imaginative?",
        "logical verbal oral?",
        "overt fitting verbose?",
        "resolved settled?",
        "forgotten?",
        "publicized examined percentage volume sample proportion profit??",
        "figure list solve?",
        "divide?",
        "express highlight alter?",
        "imitate accentuate?",
        "restore",
        "approach.",
        "Symbols ?",
        "and ?",
        "correspond to the choices of our approach with the Weighted Overlap and Cosine signature comparisons respectively.",
        "We do not include the mistakes made when the Jaccard measure was used as they vary with the k value.",
        "that of Rapp (2003) uses word senses, an approach that is outperformed by our method.",
        "The errors produced by our system were largely the result of sense locality in the WordNet network.",
        "Table 5 highlights the incorrect responses.",
        "The synonym mistakes reveal cases where senses of the two words are close in WordNet, indicating some relatedness.",
        "For example, percentage may be interpreted colloquially as monetary value (e.g., ?give me my percentage?)",
        "and elicits the synonym of profit in the economic domain, which ADW incorrectly selects as a synonym."
      ]
    },
    {
      "heading": "4.3 Word Similarity Results: RG-65 dataset",
      "text": [
        "Table 6 shows the Spearman's ?",
        "rank correlation coefficients with human judgments on the RG-65 dataset.",
        "As can be seen from the Table, our approach with the Weighted Overlap signature comparison improves over the similar approach of Hughes and Ramage (2007) which, however, does not involve the disambiguation step and considers a word as a whole unit as represented by the set of its senses.",
        "5 Experiment 3: Sense Similarity WordNet is known to be a fine-grained sense inventory with many related word senses (Palmer et al., 2007).",
        "Accordingly, multiple approaches have attempted to identify highly similar senses in order to produce a coarse-grained sense inventory.",
        "We adopt this task as a way of evaluating our similarity measure at the sense level."
      ]
    },
    {
      "heading": "5.1 Coarse-graining Background",
      "text": [
        "Earlier work on reducing the polysemy of sense inventories has considered WordNet-based sense relatedness measures (Mihalcea and Moldovan, 2001) and corpus-based vector representations of",
        "with human judgments on the RG-65 dataset.",
        "ADWJac, ADWWO, and ADWCos correspond to results with the Jaccard, Weighted Overlap and Cosine signature comparison measures respectively.",
        "word senses (Agirre and Lopez, 2003; McCarthy, 2006).",
        "Navigli (2006) proposed an automatic approach for mapping WordNet senses to the coarse-grained sense distinctions of the Oxford Dictionary of English (ODE).",
        "The approach leverages semantic similarities in gloss definitions and the hierarchical relations between senses in the ODE to cluster WordNet senses.",
        "As current state of the art, Snow et al. (2007) developed a supervised SVM classifier that utilized, as its features, several earlier sense relatedness techniques such as those implemented in the WordNet::Similarity package (Pedersen et al., 2004).",
        "The classifier also made use of resources such as topic signatures data (Agirre and de Lacalle, 2004), the WordNet domain dataset (Magnini and Cavaglia`, 2000), and the mappings of WordNet senses to ODE senses produced by Navigli (2006)."
      ]
    },
    {
      "heading": "5.2 Experimental Setup",
      "text": [
        "We benchmark the accuracy of our similarity measure in grouping word senses against those of Navigli (2006) and Snow et al. (2007) on two datasets of manually-labeled sense groupings of WordNet senses: (1) sense groupings provided as a part of the Senseval-2 English Lexical Sample WSD task (Kilgarriff, 2001) which includes nouns, verbs and adjectives; (2) sense groupings included in the OntoNotes project4 (Hovy et al., 2006) for nouns and verbs.",
        "Following the evaluation methodology of Snow et al. (2007), we combine the Senseval-2 and OntoNotes datasets into a third dataset.",
        "Snow et al. (2007) considered sense grouping as a binary classification task whereby for each word every possible pairing of senses has to be classified",
        "three hand-labeled datasets: OntoNotes (Onto), Senseval-2 (SE-2), and combined (Onto+SE-2).",
        "Results are reported for all three of our signature comparison measures and also for two previous works (last two rows).",
        "as either merged or not-merged.",
        "We constructed a simple threshold-based classifier to perform the same binary classification.",
        "To this end, we calculated the semantic similarity of each sense pair and then used a threshold value t to classify the pair as merged if similarity ?",
        "t and not-merged otherwise.",
        "We sampled out 10% of the dataset for tuning the value of t, thus adapting our classifier to the fine granularity of the dataset.",
        "We used the same held-out instances to perform a tuning of the k value used for Jaccard index, over the same values of k as in Experiment 1 (cf.",
        "Section 3)."
      ]
    },
    {
      "heading": "5.3 Sense Merging Results",
      "text": [
        "For a binary classification task, we can directly calculate precision, recall and F-score by constructing a contingency table.",
        "We show in Table 7 the F-score performance of our classifier as obtained by an averaged 10-fold cross-validation.",
        "Results are presented for all three of the measures of semantic signature comparison and for the three datasets: OntoNotes, Senseval-2, and the two combined.",
        "In addition, we show in Table 7 the F-score results provided by Snow et al. (2007) for their SVM-based system and for the mapping-based approach of Navigli (2006), denoted by ODE.",
        "Table 7 shows that our methodology yields improvements over previous work on both datasets and for all parts of speech, irrespective of the semantic signature comparison method used.",
        "Among the three methods, Weighted Overlap achieves the best performance, which demonstrates that our transformation of semantic signatures into ordered lists of concepts and calculating similarity by rank comparison has been helpful."
      ]
    },
    {
      "heading": "6 Related Work",
      "text": [
        "Due to the wide applicability of semantic similarity, significant efforts have been made at different lexical levels.",
        "Early work on document-level similarity was driven by information retrieval.",
        "Vector space methods provided initial successes (Salton et al., 1975), but often suffer from data sparsity when using small documents, or when documents use different word types, as in the case of paraphrases.",
        "Later efforts such as LSI (Deer-wester et al., 1990), PLSA (Hofmann, 2001) and Topic Models (Blei et al., 2003; Steyvers and Grif-fiths, 2007) overcame these sparsity issues using dimensionality reduction techniques or modeling the document using latent variables.",
        "However, such methods were still most suitable for comparing longer texts.",
        "Complementary approaches have been developed specifically for comparing shorter texts, such as those used in the SemEval-2012 STS task (Agirre et al., 2012).",
        "Most similar to our approach are the methods of Islam and Inkpen (2008) and Corley and Mihalcea (2005), who performed a word-to-word similarity alignment; however, they did not operate at the sense level.",
        "Ramage et al. (2009) used a similar semantic representation of short texts from random walks on WordNet, which was applied to paraphrase recognition and textual entailment.",
        "However, unlike our approach, their method does not perform sense disambiguation prior to building the representation and therefore potentially suffers from ambiguity.",
        "A significant amount of effort has also been put into measuring similarity at the word level, frequently by approaches that use distributional semantics (Turney and Pantel, 2010).",
        "These methods use contextual features to represent semantics at the word level, whereas our approach represents word semantics at the sense level.",
        "Most similar to our approach are those of Agirre et al. (2009) and Hughes and Ramage (2007), which represent word meaning as the multinomials produced from random walks on the WordNet graph.",
        "However, unlike our approach, neither of these disambiguates the two words being compared, which potentially conflates the meanings and lowers the similarity judgment.",
        "Measures of sense relatedness have frequently leveraged the structural properties of WordNet (e.g., path lengths) to compare senses.",
        "Budanit-sky and Hirst (2006) provided a survey of such WordNet-based measures.",
        "The main drawback with these approaches lies in the WordNet structure itself, where frequently two semantically similar senses are distant in the WordNet hierarchy.",
        "Possible solutions include relying on wider-coverage networks such as WikiNet (Nastase and Strube, 2013) or multilingual ones such as Babel-Net (Navigli and Ponzetto, 2012b).",
        "Fewer works have focused on measuring the similarity ?",
        "as opposed to relatedness ?",
        "between senses.",
        "The topic signatures method of Agirre and Lopez (2003) represents each sense as a vector over corpus-derived features in order to build comparable sense representations.",
        "However, topic signatures often produce lower quality representations due to sparsity in the local structure of WordNet, especially for rare senses.",
        "In contrast, the random walk used in our approach provides a denser, and thus more comparable, representation for all WordNet senses."
      ]
    },
    {
      "heading": "7 Conclusions",
      "text": [
        "This paper presents a unified approach for computing semantic similarity at multiple lexical levels, from word senses to texts.",
        "Our method leverages a common probabilistic representation at the sense level for all types of linguistic data.",
        "We demonstrate that our semantic representation achieves state-of-the-art performance in three experiments using semantic similarity at different lexical levels (i.e., sense, word, and text), surpassing the performance of previous similarity measures that are often specifically targeted for each level.",
        "In future work, we plan to explore the impact of the sense inventory-based network used in our semantic signatures.",
        "Specifically, we plan to investigate higher coverage inventories such as BabelNet (Navigli and Ponzetto, 2012a), which will handle texts with named entities and rare senses that are not in WordNet, and will also enable cross-lingual semantic similarity.",
        "Second, we plan to evaluate our method on larger units of text and formalize comparison methods between different lexical levels."
      ]
    },
    {
      "heading": "Acknowledgments",
      "text": [
        "The authors gratefully acknowledge the support of the ERC Starting Grant MultiJEDI No.",
        "259234.",
        "We would like to thank Sameer S. Pradhan for providing us with an earlier version of the OntoNotes dataset."
      ]
    }
  ]
}
