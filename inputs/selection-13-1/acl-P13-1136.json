{
  "info": {
    "authors": [
      "Lu Wang",
      "Hema Raghavan",
      "Vittorio Castelli",
      "Radu Florian",
      "Claire Cardie"
    ],
    "book": "ACL",
    "id": "acl-P13-1136",
    "title": "A Sentence Compression Based Framework to Query-Focused Multi-Document Summarization",
    "url": "https://aclweb.org/anthology/P13-1136",
    "year": 2013
  },
  "references": [
    "acl-C00-1072",
    "acl-E06-1038",
    "acl-H05-1083",
    "acl-H05-1115",
    "acl-J96-1002",
    "acl-N03-1020",
    "acl-N04-1001",
    "acl-N04-1019",
    "acl-N07-1023",
    "acl-N09-1041",
    "acl-P04-1018",
    "acl-P05-1036",
    "acl-P06-1039",
    "acl-P07-2015",
    "acl-P11-1049",
    "acl-P11-1050",
    "acl-P11-1052",
    "acl-W03-0501",
    "acl-W03-1101",
    "acl-W09-1801",
    "acl-W09-1802"
  ],
  "sections": [
    {
      "heading": "Abstract",
      "text": [
        "We consider the problem of using sentence compression techniques to facilitate query-focused multi-document summarization.",
        "We present a sentence-compression-based framework for the task, and design a series of learning-based compression models built on parse trees.",
        "An innovative beam search decoder is proposed to efficiently find highly probable compressions.",
        "Under this framework, we show how to integrate various indicative metrics such as linguistic motivation and query relevance into the compression process by deriving a novel formulation of a compression scoring function.",
        "Our best model achieves statistically significant improvement over the state-of-the-art systems on several metrics (e.g. 8.0% and 5.4% improvements in ROUGE-2 respectively) for the DUC 2006 and 2007 summarization task."
      ]
    },
    {
      "heading": "1 Introduction",
      "text": [
        "The explosion of the Internet clearly warrants the development of techniques for organizing and presenting information to users in an effective way.",
        "Query-focused multi-document summarization (MDS) methods have been proposed as one such technique and have attracted significant attention in recent years.",
        "The goal of query-focused MDS is to synthesize a brief (often fixed-length) and well-organized summary from a set of topic-related documents that answer a complex question or address a topic statement.",
        "The resulting summaries, in turn, can support a number of information analysis applications including open-ended question answering, recommender systems, and summarization of search engine results.",
        "As further evidence of its importance, the Document Understanding Conference (DUC) has used query-focused MDS as its main task since 2004 to foster new research on automatic summarization in the context of users?",
        "needs.",
        "To date, most top-performing systems for multi-document summarization?whether query-specific or not?remain largely extractive: their summaries are comprised exclusively of sentences selected directly from the documents to be summarized (Erkan and Radev, 2004; Haghighi and Vanderwende, 2009; Celikyilmaz and Hakkani-Tu?r, 2011).",
        "Despite their simplicity, extractive approaches have some disadvantages.",
        "First, lengthy sentences that are partly relevant are either excluded from the summary or (if selected) can block the selection of other important sentences, due to summary length constraints.",
        "In addition, when people write summaries, they tend to abstract the content and seldom use entire sentences taken verbatim from the original documents.",
        "In news articles, for example, most sentences are lengthy and contain both potentially useful information for a summary as well as unnecessary details that are better omitted.",
        "Consider the following DUC query as input for a MDS system:1 ?In what ways have stolen artworks been recovered?",
        "How often are suspects arrested or prosecuted for the thefts??",
        "One manually generated summary includes the following sentence but removes the bracketed words in gray: A man suspected of stealing a million-dollar collection of [hundreds of ancient] Nepalese and Tibetan art objects in New York [11 years ago] was arrested [Thursday at his South Los Angeles home, where he had been hiding the antiquities, police said].",
        "In this example, the compressed sentence is rela",
        "tively more succinct and readable than the original (e.g. in terms of Flesch-Kincaid Reading Ease Score (Kincaid et al., 1975)).",
        "Likewise, removing information irrelevant to the query (e.g. ?11 years ago?, ?police said?)",
        "is crucial for query-focused MDS.",
        "Sentence compression techniques (Knight and Marcu, 2000; Clarke and Lapata, 2008) are the standard for producing a compact and grammatical version of a sentence while preserving relevance, and prior research (e.g. Lin (2003)) has demonstrated their potential usefulness for generic document summarization.",
        "Similarly, strides have been made to incorporate sentence compression into query-focused MDS systems (Zajic et al., 2006).",
        "Most attempts, however, fail to produce better results than those of the best systems built on pure extraction-based approaches that use no sentence compression.",
        "In this paper we investigate the role of sentence compression techniques for query-focused MDS.",
        "We extend existing work in the area first by investigating the role of learning-based sentence compression techniques.",
        "In addition, we design three types of approaches to sentence-compression?",
        "rule-based, sequence-based and tree-based?and examine them within our compression-based framework for query-specific MDS.",
        "Our top-performing sentence compression algorithm incorporates measures of query relevance, content importance, redundancy and language quality, among others.",
        "Our tree-based methods rely on a scoring function that allows for easy and flexible tailoring of sentence compression to the summarization task, ultimately resulting in significant improvements for MDS, while at the same time remaining competitive with existing methods in terms of sentence compression, as discussed next.",
        "We evaluate the summarization models on the standard Document Understanding Conference (DUC) 2006 and 2007 corpora 2 for query-focused MDS and find that all of our compression-based summarization models achieve statistically significantly better performance than the best DUC 2006 systems.",
        "Our best-performing system yields an 11.02 ROUGE-2 score (Lin and Hovy, 2003), a 8.0% improvement over the best reported score (10.2 (Davis et al., 2012)) on the 2We believe that we can easily adapt our system for tasks (e.g. TAC-08's opinion summarization or TAC-09's update summarization) or domains (e.g. web pages or wikipedia pages).",
        "We reserve that for future work.",
        "DUC 2006 dataset, and an 13.49 ROUGE-2, a 5.4% improvement over the best score in DUC 2007 (12.8 (Davis et al., 2012)).",
        "We also observe substantial improvements over previous systems w.r.t.",
        "the manual Pyramid (Nenkova and Passonneau, 2004) evaluation measure (26.4 vs. 22.9 (Jagarlamudi et al., 2006)); human annotators furthermore rate our system-generated summaries as having less redundancy and comparable quality w.r.t.",
        "other linguistic quality metrics.",
        "With these results we believe we are the first to successfully show that sentence compression can provide statistically significant improvements over pure extraction-based approaches for query-focused MDS."
      ]
    },
    {
      "heading": "2 Related Work",
      "text": [
        "Existing research on query-focused multi-document summarization (MDS) largely relies on extractive approaches, where systems usually take as input a set of documents and select the top relevant sentences for inclusion in the final summary.",
        "A wide range of methods have been employed for this task.",
        "For unsupervised methods, sentence importance can be estimated by calculating topic signature words (Lin and Hovy, 2000; Conroy et al., 2006), combining query similarity and document centrality within a graph-based model (Otterbacher et al., 2005), or using a Bayesian model with sophisticated inference (Daume?",
        "and Marcu, 2006).",
        "Davis et al.",
        "(2012) first learn the term weights by Latent Semantic Analysis, and then greedily select sentences that cover the maximum combined weights.",
        "Supervised approaches have mainly focused on applying discriminative learning for ranking sentences (Fuentes et al., 2007).",
        "Lin and Bilmes (2011) use a class of carefully designed submodular functions to reward the diversity of the summaries and select sentences greedily.",
        "Our work is more related to the less studied area of sentence compression as applied to (single) document summarization.",
        "Zajic et al. (2006) tackle the query-focused MDS problem using a compress-first strategy: they develop heuristics to generate multiple alternative compressions of all sentences in the original document; these then become the candidates for extraction.",
        "This approach, however, does not outperform some extraction-based approaches.",
        "A similar idea has been studied for MDS (Lin, 2003; Gillick and Favre, 2009),",
        "but limited improvement is observed over extractive baselines with simple compression rules.",
        "Finally, although learning-based compression methods are promising (Martins and Smith, 2009; Berg-Kirkpatrick et al., 2011), it is unclear how well they handle issues of redundancy.",
        "Our research is also inspired by probabilistic sentence-compression approaches, such as the noisy-channel model (Knight and Marcu, 2000; Turner and Charniak, 2005), and its extension via synchronous context-free grammars (SCFG) (Aho and Ullman, 1969; Lewis and Stearns, 1968) for robust probability estimation (Galley and McKe-own, 2007).",
        "Rather than attempt to derive a new parse tree like Knight and Marcu (2000) and Galley and McKeown (2007), we learn to safely remove a set of constituents in our parse tree-based compression model while preserving grammatical structure and essential content.",
        "Sentence-level compression has also been examined via a discriminative model McDonald (2006), and Clarke and Lapata (2008) also incorporate discourse information by using integer linear programming."
      ]
    },
    {
      "heading": "3 The Framework",
      "text": [
        "We now present our query-focused MDS framework consisting of three steps: Sentence Ranking, Sentence Compression and Post-processing.",
        "First, sentence ranking determines the importance of each sentence given the query.",
        "Then, a sentence compressor iteratively generates the most likely succinct versions of the ranked sentences, which are cumulatively added to the summary, until a length limit is reached.",
        "Finally, the post-processing stage applies coreference resolution and sentence reordering to build the summary.",
        "Sentence Ranking.",
        "This stage aims to rank sentences in order of relevance to the query.",
        "Unsurprisingly, ranking algorithms have been successfully applied to this task.",
        "We experimented with two of them ?",
        "Support Vector Regression (SVR) (Mozer et al., 1997) and Lamb-daMART (Burges et al., 2007).",
        "The former has been used previously for MDS (Ouyang et al., 2011).",
        "LambdaMart on the other hand has shown considerable success in information retrieval tasks (Burges, 2010); we are the first to apply it to summarization.",
        "For training, we use 40 topics (i.e. queries) from the DUC 2005 corpus (Dang, 2005) along with their manually generated abstracts.",
        "As in previous work (Shen and Li, Basic Features relative/absolute position is among the first 1/3/5 sentences?",
        "number of words (with/without stopwords) number of words more than 5/10 (with/without stopwords)",
        "average/sum of mutual information average/sum of number of topic signature words (Lin and Hovy, 2000) basic/improved sentence scorers from Conroy et al. (2006) Content Features contains verb/web link/phone number?",
        "contains/portion of words between parentheses Table 1: Sentence-level features for sentence ranking.",
        "2011; Ouyang et al., 2011), we use the ROUGE2 score, which measures bigram overlap between a sentence and the abstracts, as the objective for regression.",
        "While space limitations preclude a longer discussion of the full feature set (ref.",
        "Table 1), we describe next the query-relevant features used for sentence ranking as these are the most important for our summarization setting.",
        "The goal of this feature subset is to determine the similarity between the query and each candidate sentence.",
        "When computing similarity, we remove stopwords as well as the words ?discuss, describe, specify, explain, identify, include, involve, note?",
        "that are adopted and extended from Conroy et al. (2006).",
        "Then we conduct simple query expansion based on the title of the topic and cross-document coref-erence resolution.",
        "Specifically, we first add the words from the topic title to the query.",
        "And for each mention in the query, we add other mentions within the set of documents that corefer with this mention.",
        "Finally, we compute two versions of the features?one based on the original query and another on the expanded one.",
        "We also derive the semantic role overlap and relation instance overlap between the query and each sentence.",
        "Cross-document coreference resolution, semantic role la-beling and relation extraction are accomplished via the methods described in Section 5.",
        "Sentence Compression.",
        "As the main focus of this paper, we propose three types of compression methods, described in detail in Section 4 below.",
        "Post-processing.",
        "Post-processing performs coreference resolution and sentence ordering.",
        "Basic Features Syntactic Tree Features first 1/3/5 tokens (toks)?",
        "POS tag last 1/3/5 toks?",
        "parent/grandparent label first letter/all letters capitalized?",
        "leftmost child of parent?",
        "is negation?",
        "second leftmost child of parent?",
        "is stopword?",
        "is headword?",
        "Dependency Tree Features in NP/VP/ADVP/ADJP chunk?",
        "dependency relation (dep rel) Semantic Features parent/grandparent dep rel is a predicate?",
        "is the root?",
        "semantic role label has a depth larger than 3/5?"
      ]
    },
    {
      "heading": "Rule-Based Features",
      "text": [
        "For each rule in Table 2 , we construct a corresponding feature to indicate whether the token is identified by the rule.",
        "Table 3: Token-level features for sequence-based compression.",
        "We replace each pronoun with its referent unless they appear in the same sentence.",
        "For sentence ordering, each compressed sentence is assigned to the most similar (tf-idf) query sentence.",
        "Then a Chronological Ordering algorithm (Barzilay et al., 2002) sorts the sentences for each query based first on the time stamp, and then the position in the source document."
      ]
    },
    {
      "heading": "4 Sentence Compression",
      "text": [
        "Sentence compression is typically formulated as the problem of removing secondary information from a sentence while maintaining its grammaticality and semantic structure (Knight and Marcu, 2000; McDonald, 2006; Galley and McKeown, 2007; Clarke and Lapata, 2008).",
        "We leave other rewrite operations, such as paraphrasing and reordering, for future work.",
        "Below we describe the sentence compression approaches developed in this research: RULE-BASED COMPRESSION,"
      ]
    },
    {
      "heading": "SEQUENCE-BASED COMPRESSION, and TREE-BASED COMPRESSION.",
      "text": []
    },
    {
      "heading": "4.1 Rule-based Compression",
      "text": [
        "Turner and Charniak (2005) have shown that applying hand-crafted rules for trimming sentences can improve both content and linguistic quality.",
        "Our rule-based approach extends existing work (Conroy et al., 2006; Toutanova et al., 2007) to create the linguistically-motivated compression rules of Table 2.",
        "To avoid ill-formed output, we disallow compressions of more than 10 words by each rule."
      ]
    },
    {
      "heading": "4.2 Sequence-based Compression",
      "text": [
        "As in McDonald (2006) and Clarke and Lapata",
        "the root of the gray subtree (a ?PP?)",
        "would be labeled REMOVE.",
        "Its siblings and parent are labeled RETAIN and PARTIAL, respectively.",
        "The trimmed tree is realized as ?Malaria causes millions of deaths.?",
        "view compression as a sequential tagging problem and make use of linear-chain Conditional Random Fields (CRFs) (Lafferty et al., 2001) to select the most likely compression.",
        "We represent each sentence as a sequence of tokens, X =",
        "kept, using a BIO label format: {B-RETAIN denotes the beginning of a retained sequence, I-RETAIN indicates tokens ?inside?",
        "the retained sequence, O marks tokens to be removed}.",
        "The CRF model is built using the features shown in Table 3.",
        "?Dependency Tree Features?",
        "encode the grammatical relations in which each word is involved as a dependent.",
        "For the ?Syntactic Tree?, ?Dependency Tree?",
        "and ?Rule-Based?",
        "features, we also include features for the two words that precede and the two that follow the current word.",
        "Detailed descriptions of the training data and experimental setup are in Section 5.",
        "During inference, we find the maximally likely sequence Y according to a CRF with parameter ?",
        "(Y = argmaxY ?",
        "P (Y ?|X; ?",
        ")), while simultaneously enforcing the rules of Table 2 to reduce the hypothesis space and encourage grammatical compression.",
        "To do this, we encode these rules as features for each token, and whenever these feature functions fire, we restrict the possible label for that token to ?O?."
      ]
    },
    {
      "heading": "4.3 Tree-based Compression",
      "text": [
        "Our tree-based compression methods are in line with syntax-driven approaches (Galley and McKeown, 2007), where operations are carried out on parse tree constituents.",
        "Unlike previous work (Knight and Marcu, 2000; Galley and McKeown, 2007), we do not produce a new parse tree,"
      ]
    },
    {
      "heading": "Rule Example",
      "text": [
        "Header [MOSCOW , October 19 ( Xinhua ) ?]",
        "Russian federal troops Tuesday continued...",
        "Relative dates ...Centers for Disease Control confirmed [Tuesday] that there was... Intra-sentential attribution ...fueling the La Nina weather phenomenon, [the U.N. weather agency said].",
        "Lead adverbials [Interestingly], while the Democrats tend to talk about... Noun appositives Wayne County Prosecutor [John O?Hara] wanted to send a message... Nonrestrictive relative clause Putin, [who was born on October 7, 1952 in Leningrad], was elected in the presidential election... Adverbial clausal modifiers [Starting in 1998], California will require 2 per cent of a manufacturer... (Lead sentence) [Given the short time], car makers see electric vehicles as...",
        "Within Parentheses ...to Christian home schoolers in the early 1990s [(www.homecomputermarket.com)].",
        "but focus on learning to identify the proper set of constituents to be removed.",
        "In particular, when a node is dropped from the tree, all words it subsumes will be deleted from the sentence.",
        "Formally, given a parse tree T of the sentence to be compressed and a tree traversal algorithm, T can be presented as a list of ordered constituent nodes, T = t0t1 .",
        ".",
        ".",
        "tm.",
        "Our objective is to find a set of labels, L = l0l1 .",
        ".",
        ".",
        "lm, where li ?",
        "{RETAIN, REMOVE, PARTIAL}.",
        "RETAIN (RET) and REMOVE (REM) denote whether the node ti is retained or removed.",
        "PARTIAL (PAR) means ti is partly removed, i.e. at least one child subtree of ti is dropped.",
        "Labels are identified, in order, according to the tree traversal algorithm.",
        "Every node label needs to be compatible with the labeling history: given a node ti, and a set of labels l0 .",
        ".",
        ".",
        "li?1 predicted for nodes t0 .",
        ".",
        ".",
        "ti?1, li =RET or li =REM is compatible with the history when all children of ti are labeled as RET or REM, respectively; li =PAR is compatible when ti has at least two descendents tj and tk (j < i and k < i), one of which is RETained and the other, REMoved.",
        "As such, the root of the gray subtree in Figure 1 is labeled as REM; its left siblings as RET; its parent as PAR.",
        "As the space of possible compressions is exponential in the number of leaves in the parse tree, instead of looking for the globally optimal solution, we use beam search to find a set of highly likely compressions and employ a language model trained on a large corpus for evaluation.",
        "A Beam Search Decoder.",
        "The beam search decoder (see Algorithm 1) takes as input the sentence's parse tree T = t0t1 .",
        ".",
        ".",
        "tm, an ordering O for traversing T (e.g. postorder) as a sequence of nodes in T , the set L of possible node labels, a scoring function S for evaluating each sentence compression hypothesis, and a beam size N .",
        "Specifically, O is a permutation on the set {0, 1, .",
        ".",
        ".",
        ",m}?each element an index onto T .",
        "Following O, T is reordered as tO0tO1 .",
        ".",
        ".",
        "tOm , and the decoder considers each ordered constituent tOi in turn.",
        "In iteration i, all existing sentence compression hypotheses are expanded by one node, tOi , labeling it with all compatible labels.",
        "The new hypotheses (usually sub-sentences) are ranked by the scorer S and the top N are preserved to be extended in the next iteration.",
        "See Figure 2 for an example.",
        "Input : parse tree T , ordering O = O0O1 .",
        ".",
        ".",
        "Om, L ={RET, REM, PAR}, hypothesis scorer S, beam size N Output: N best compressions stack?",
        "?",
        "(empty set); foreach node tOi in T = tO0 .",
        ".",
        ".",
        "tOm doif i == 0 (first node visited) then foreach label lO0 in L donewHypothesis h?",
        "?",
        "[lO0 ];put h?",
        "into Stack;",
        "foreach hypothesis h in stack do foreach label lOi in L doif lOi is compatible thennewHypothesis h?",
        "?",
        "h + [lOi ];put h?",
        "into newStack;",
        "stantiates the beam search decoder with postorder traversal and a hypothesis scorer that takes a possible sentence compression?",
        "a sequence of nodes (e.g. tO0 .",
        ".",
        ".",
        "tOk ) and their labels (e.g. lO0 .",
        ".",
        ".",
        "lOk )?and returns?k j=1 logP (lOj |tOj ) (denoted later as ScoreBasic).",
        "The probability is estimated by a Maximum Entropy classifier (Berger et al.,",
        "postorder traversal, the three nodes are visited in a bottom-up order.",
        "The associated compression hypotheses (boxed) are ranked based on the scores in parentheses.",
        "Beam scores for other nodes are omitted.",
        "Basic Features Syntactic Tree Features projection falls w/in first 1/3/5 toks??",
        "constituent label projection falls w/in last 1/3/5 toks??",
        "parent left/right sibling label subsumes first 1/3/5 toks??",
        "grandparent left/right sibling label subsumes last 1/3/5 toks??",
        "is leftmost child of parent?",
        "number of words larger than 5/10??",
        "is second leftmost child of parent?",
        "is leaf node??",
        "is head node of parent?",
        "is root of parsing tree??",
        "label of its head node has word with first letter capitalized?",
        "has a depth greater than 3/5/10?",
        "has word with all letters capitalized?",
        "Dependency Tree Features has negation?",
        "dep rel of head node?",
        "has stopwords?",
        "dep rel of parent's head node?",
        "Semantic Features dep rel of grandparent's head node?",
        "the head node has predicate?",
        "contain root of dep tree??",
        "semantic roles of head node has a depth larger than 3/5?",
        "?"
      ]
    },
    {
      "heading": "Rule-Based Features",
      "text": [
        "For each rule in Table 2 , we construct a corresponding feature to indicate whether the token is identified by the rule.",
        "Table 4: Constituent-level features for tree-based compression.",
        "?",
        "or ?",
        "denote features that are concatenated with every Syntactic Tree feature to compose a new one.",
        "1996) trained at the constituent level using the features in Table 4.",
        "We also apply the rules of Table 2 during the decoding process.",
        "Concretely, if the words subsumed by a node are identified by any rule, we only consider REM as the node's label.",
        "Given the N best compressions from the decoder, we evaluate the yield of the trimmed trees using a language model trained on the Giga-word (Graff, 2003) corpus and return the compression with the highest probability.",
        "Thus, the decoder is quite flexible ?",
        "its learned scoring function allows us to incorporate features salient for sentence compression while its language model guarantees the linguistic quality of the compressed string.",
        "In the sections below we consider additional improvements.",
        "CONTEXT-aware search is based on the intuition that predictions on preceding context can be leveraged to facilitate the prediction of the current node.",
        "For example, parent nodes with children that have all been removed (retained) should have a label of REM (RET).",
        "In light of this, we encode these contextual predictions as additional features of S, that is, ALL-CHILDREN"
      ]
    },
    {
      "heading": "REMOVED/RETAINED, ANY-LEFTSIBLINGREMOVED/RETAINED/PARTLY REMOVED,",
      "text": [
        "LABEL-OF-LEFT-SIBLING/HEAD-NODE.",
        "HEAD-driven search modifies the BASIC postorder tree traversal by visiting the head node first at each level, leaving other orders unchanged.",
        "In a nutshell, if the head node is dropped, then its modifiers need not be preserved.",
        "We adopt the same features as CONTEXT-aware search, but remove those involving left siblings.",
        "We also add one more feature: LABEL-OF-THE-HEAD-NODE-IT-MODIFIES.",
        "The current scorer ScoreBasic is still fairly naive in that it focuses only on features of the sentence to be compressed.",
        "However extra-sentential knowledge can also be important for query-focused MDS.",
        "For example, information regarding relevance to the query might lead the decoder to produce compressions better suited for the summary.",
        "Towards this goal, we construct a compression scoring function'the multi-scorer (MULTI)?that allows the incorporation of multiple task-specific scorers.",
        "Given a hypothesis at any stage of decoding, which yields a sequence of words W = w0w1...wj , we propose the following component scorers.",
        "Query Relevance.",
        "Query information ought to guide the compressor to identify the relevant content.",
        "The query Q is expanded as described in Section 3.",
        "Let |W ?",
        "Q |denote the number of unique overlapping words betweenW andQ, then",
        "Importance.",
        "A query-independent importance score is defined as the average Sum-Basic (Toutanova et al., 2007) value in W , i.e. scoreim =?ji=1 SumBasic(wi)/|W |.",
        "Language Model.",
        "We let scorelm be the probability of W computed by a language model.",
        "Cross-Sentence Redundancy.",
        "To encourage diversified content, we define a redundancy score to discount replicated content: scorered = 1?",
        "|W ?",
        "C|/|W |, whereC is the words already selected for the summary.",
        "The multi-scorer is defined as a linear combination of the component scorers: Let",
        "The parameters ~?",
        "are tuned on a held-out tuning set by grid search.",
        "We linearly normalize the score of each metric, where the minimum and maximum values are estimated from the tuning data."
      ]
    },
    {
      "heading": "5 Experimental Setup",
      "text": [
        "We evaluate our methods on the DUC 2005, 2006 and 2007 datasets (Dang, 2005; Dang, 2006; Dang, 2007), each of which is a collection of newswire articles.",
        "50 complex queries (topics) are provided for DUC 2005 and 2006, 35 are collected for DUC 2007 main task.",
        "Relevant documents for each query are provided along with 4 to 9 human MDS abstracts.",
        "The task is to generate a summary within 250 words to address the query.",
        "We split DUC 2005 into two parts: 40 topics to train the sentence ranking models, and 10 for ranking algorithm selection and parameter tuning for the multi-scorer.",
        "DUC 2006 and DUC 2007 are reserved as held out test sets.",
        "Sentence Compression.",
        "The dataset from Clarke and Lapata (2008) is used to train the CRF and MaxEnt classifiers (Section 4).",
        "It includes 82 newswire articles with one manually produced compression aligned to each sentence.",
        "Preprocessing.",
        "Documents are processed by a full NLP pipeline, including token and sentence segmentation, parsing, semantic role labeling, and an information extraction pipeline consisting of mention detection, NP coreference, cross-document resolution, and relation detection (Florian et al., 2004; Luo et al., 2004; Luo and Zitouni, 2005).",
        "Learning for Sentence Ranking and Compression.",
        "We use Weka (Hall et al., 2009) to train a support vector regressor and experiment with various rankers in RankLib (Dang, 2011)3.",
        "As Lamb-daMART has an edge over other rankers on the held-out dataset, we selected it to produce ranked sentences for further processing.",
        "For sequence-based compression using CRFs, we employ Mallet (McCallum, 2002) and integrate the Table 2 rules during inference.",
        "NLTK (Bird et al., 2009) 3Default parameters are used.",
        "If an algorithm needs a validation set, we use 10 out of 40 topics.",
        "MaxEnt classifiers are used for tree-based compression.",
        "Beam size is fixed at 2000.4 Sentence compressions are evaluated by a 5-gram language model trained on Gigaword (Graff, 2003) by SRILM (Stolcke, 2002)."
      ]
    },
    {
      "heading": "6 Results",
      "text": [
        "The results in Table 5 use the official ROUGE software with standard options5 and report ROUGE2 (R-2) (measures bigram overlap) and ROUGE-SU4 (R-SU4) (measures unigram and skip-bigram separated by up to four words).",
        "We compare our sentence-compression-based methods to the best performing systems based on ROUGE in DUC 2006 and 2007 (Jagarlamudi et al., 2006; Pingali et al., 2007), system by Davis et al. (2012) that report the best R-2 score on DUC 2006 and 2007 thus far, and to the purely extractive methods of SVR and LambdaMART.",
        "Our sentence-compression-based systems (marked with ?)",
        "show statistically significant improvements over pure extractive summarization for both R-2 and R-SU4 (paired t-test, p < 0.01).",
        "This means our systems can effectively remove redundancy within the summary through compression.",
        "Furthermore, our HEAD-driven beam search method with MULTI-scorer beats all systems on DUC 20066 and all systems on DUC 2007 except the best system in terms of R-2 (p < 0.01).",
        "Its R-SU4 score is also significantly (p < 0.01) better than extractive methods, rule-based and sequence-based compression methods on both DUC 2006 and 2007.",
        "Moreover, our systems with learning-based compression have considerable compression rates, indicating their capability to remove superfluous words as well as improve summary quality.",
        "Human Evaluation.",
        "The Pyramid (Nenkova and Passonneau, 2004) evaluation was developed to manually assess how many relevant facts or Summarization Content Units (SCUs) are captured by system summaries.",
        "We ask a professional annotator (who is not one of the authors, is highly experienced in annotating for various NLP tasks, and is fluent in English) to carry out a Pyramid evaluation on 10 randomly selected topics from",
        "preserved.",
        "R-2 (ROUGE-2) and R-SU4 (ROUGE-SU4) scores are multiplied by 100.",
        "???",
        "indicates that data is unavailable.",
        "BASIC, CONTEXT and HEAD represent the basic beam search decoder, context-aware and head-driven search extensions respectively.",
        "ScoreBasic and MULTI refer to the type of scorer used.",
        "Statistically significant improvements (p < 0.01) over the best system in DUC 06 and 07 are marked with ?.",
        "?",
        "indicates statistical significance (p < 0.01) over extractive approaches (SVR or LambdaMART).",
        "HEAD + MULTI outperforms all the other extract-and compression-based systems in R-2.",
        "(ROUGE)), and Lacatusu et al. (2006) (Best DUC system (LQ)).",
        "Our system can synthesize more relevant content according to Pyramid (?100).",
        "We also examine linguistic quality (LQ) in Grammaticality (Gra), Non-redundancy (Non-Red), Referential clarity (Ref), Focus (Foc), and Structure and Coherence (Coh) like Dang (2006), each rated from 1 (very poor) to 5 (very good).",
        "Our system has better non-redundancy than Jagarlamudi et al. (2006) and is comparable to Jagarlamudi et al. (2006) and Lacatusu et al. (2006) in other metrics except grammaticality.",
        "the DUC 2006 task with gold-standard SCU annotation in abstracts.",
        "The Pyramid score (see Table 6) is recalculated for the system with best ROUGE scores in DUC 2006 (Jagarlamudi et al., 2006) along with our system by the same annotator to make a meaningful comparison.",
        "We further evaluate the linguistic quality (LQ) of the summaries for the same 10 topics in accordance with the measurement in Dang (2006).",
        "Four native speakers who are undergraduate students in computer science (none are authors) performed the task, We compare our system based on HEAD-driven beam search with MULTI-scorer to the best systems in DUC 2006 achieving top ROUGE scores (Jagarlamudi et al., 2006) (Best DUC system (ROUGE)) and top linguistic quality scores (Lacatusu et al., 2006) (Best DUC system (LQ))7.",
        "The average score and standard deviation for each metric is displayed in Table 6.",
        "Our system achieves a higher Pyramid score, an indication that it captures more of the salient facts.",
        "We also 7Lacatusu et al. (2006) obtain the best scores in three linguistic quality metrics (i.e. grammaticality, focus, structure and coherence), and overall responsiveness on DUC 2006. attain better non-redundancy than Jagarlamudi et al.",
        "(2006), meaning that human raters perceive less replicative content in our summaries.",
        "Scores for other metrics are comparable to Jagarlamudi et al. (2006) and Lacatusu et al. (2006), which either uses minimal non-learning-based compression rules or is a pure extractive system.",
        "However, our compression system sometimes generates less grammatical sentences, and those are mostly due to parsing errors.",
        "For example, parsing a clause starting with a past tense verb as an adverbial clausal modifier can lead to an ill-formed compression.",
        "Those issues can be addressed by an-alyzing k-best parse trees and we leave it in the future work.",
        "A sample summary from our multi-scorer based system is in Figure 3.",
        "Sentence Compression Evaluation.",
        "We also evaluate sentence compression separately on (Clarke and Lapata, 2008), adopting the same partitions as (Martins and Smith, 2009), i.e. 1, 188 sentences for training and 441 for testing.",
        "Our compression models are compared with Hedge Trimmer (Dorr et al., 2003), a discriminative model proposed by McDonald (2006) and a",
        "all use single-scorer.",
        "Our context-aware and head-driven tree-based approaches outperform all the other systems significantly (p < 0.01) in precision (Uni-Prec) without sacrificing the recalls (i.e. there is no statistically significant difference between our models and McDonald (2006) / M & S (2009) with p > 0.05).",
        "Italicized numbers for unigram F1 (Uni-F1) are statistically indistinguishable (p > 0.05).",
        "Our head-driven tree-based approach also produces significantly better grammatical relations F1 scores (Rel-F1) than all the other systems except the rule-based method (p < 0.01).",
        "Topic D0626H: How were the bombings of the US embassies in Kenya and Tanzania conducted?",
        "What terrorist groups and individuals were responsible?",
        "How and where were the attacks planned?",
        "WASHINGTON, August 13 (Xinhua) ?",
        "President Bill Clinton Thursday condemned terrorist bomb attacks at U.S. embassies in Kenya and Tanzania and vowed to find the bombers and bring them to justice.",
        "Clinton met with his top aides Wednesday in the White House to assess the situation following the twin bombings at U.S. embassies in Kenya and Tanzania, which have killed more than 250 people and injured over 5,000, most of them Kenyans and Tanzanians.",
        "Local sources said the plan to bomb U.S. embassies in Kenya and Tanzania took three months to complete and bombers destined for Kenya were dispatched through Somali and Rwanda.",
        "FBI Director Louis Freeh, Attorney General Janet Reno and other senior U.S. government officials will hold a news conference at 1 p.m. EDT (1700GMT) at FBI headquarters in Washington ?to announce developments in the investigation of the bombings of the U.S. embassies in Kenya and Tanzania,?",
        "the FBI said in a statement.",
        "...",
        "scorer based summarizer for topic D0626H (DUC 2006).",
        "Grayed out words are removed.",
        "Query-irrelevant phrases, such as temporal information or source of the news, have been removed.",
        "dependency-tree based compressor (Martins and Smith, 2009)8.",
        "We adopt the metrics in Martins and Smith (2009) to measure the unigram-level macro precision, recall, and F1-measure with respect to human annotated compression.",
        "In addition, we also compute the F1 scores of grammatical relations which are annotated by RASP (Briscoe and Carroll, 2002) according to Clarke and Lapata (2008).",
        "In Table 7, our context-aware and head-driven tree-based compression systems show statistically significantly (p < 0.01) higher precisions (Uni-8Thanks to Andre?",
        "F.T.",
        "Martins for system outputs.",
        "Prec) than all the other systems, without decreasing the recalls (Uni-Rec) significantly (p > 0.05) based on a paired t-test.",
        "Unigram F1 scores (Uni-F1) in italics indicate that the corresponding systems are not statistically distinguishable (p > 0.05).",
        "For grammatical relation evaluation, our head-driven tree-based system obtains statistically significantly (p < 0.01) better F1 score (Rel-F1 than all the other systems except the rule-based system)."
      ]
    },
    {
      "heading": "7 Conclusion",
      "text": [
        "We have presented a framework for query-focused multi-document summarization based on sentence compression.",
        "We propose three types of compression approaches.",
        "Our tree-based compression method can easily incorporate measures of query relevance, content importance, redundancy and language quality into the compression process.",
        "By testing on a standard dataset using the automatic metric ROUGE, our models show substantial improvement over pure extraction-based methods and state-of-the-art systems.",
        "Our best system also yields better results for human evaluation based on Pyramid and achieves comparable linguistic quality scores."
      ]
    },
    {
      "heading": "Acknowledgments",
      "text": [
        "This work was supported in part by National Science Foundation Grant IIS-0968450 and a gift from Boeing.",
        "We thank Ding-Jung Han, Young"
      ]
    }
  ]
}
