{
  "info": {
    "authors": [
      "Xipeng Qiu",
      "Qi Zhang",
      "Xuanjing Huang"
    ],
    "book": "ACL",
    "id": "acl-P13-4009",
    "title": "FudanNLP: A Toolkit for Chinese Natural Language Processing",
    "url": "https://aclweb.org/anthology/P13-4009",
    "year": 2013
  },
  "references": [
    "acl-C04-1081",
    "acl-W04-3236",
    "acl-W09-1201"
  ],
  "sections": [
    {
      "heading": "Abstract",
      "text": [
        "The growing need for Chinese natural language processing (NLP) is largely in a range of research and commercial applications.",
        "However, most of the currently Chinese NLP tools or components still have a wide range of issues need to be further improved and developed.",
        "FudanNLP is an open source toolkit for Chinese natural language processing (NLP), which uses statistics-based and rule-based methods to deal with Chinese NLP tasks, such as word segmentation, part-of-speech tagging, named entity recognition, dependency parsing, time phrase recognition, anaphora resolution and so on."
      ]
    },
    {
      "heading": "1 Introduction",
      "text": [
        "Chinese is one of the most widely used languages in this world, and the proportion that Chinese language holds on the Internet is also quite high.",
        "Under the current circumstances, there are greater and greater demands for intelligent processing and analyzing of the Chinese texts.",
        "Similar to English, the main tasks in Chinese NLP include word segmentation (CWS), part-of-speech (POS) tagging, named entity recognition (NER), syntactic parsing, anaphora resolution (AR), and so on.",
        "Although the general ways are essentially the same for English and Chinese, the implementation details are different.",
        "It is also non-trivial to optimize these methods for Chinese NLP tasks.",
        "There are also some toolkits to be used for NLP, such as Stanford CoreNLP1, Apache OpenNLP2, Curator3 and NLTK4.",
        "But these toolkits are developed mainly for English and not optimized for Chinese.",
        "In order to customize an optimized system for Chinese language process, we implement an open source toolkit, FudanNLP5, which is written in Java.",
        "Since most of the state-of-the-art methods for NLP are based on statistical learning, the whole framework of our toolkit is established around statistics-based methods, supplemented by some rule-based methods.",
        "Therefore, the quality of training data is crucial for our toolkit.",
        "However, we find that there are some drawbacks in currently most commonly used corpora, such as CTB (Xia, 2000) and CoNLL (Haji?",
        "et al, 2009) corpora.",
        "For example, in CTB corpus, the set of POS tags is relative small and some categories are derived from the perspective of English grammar.",
        "And in CoNLL corpus, the head words are often interrogative particles and punctuations, which are unidiomatic in Chinese.",
        "These drawbacks bring more challenges to further analyses, such as information extraction and semantic understanding.",
        "Therefore, we first construct a corpus with a modified guideline, which is more in accordance with the common understanding for Chinese grammar.",
        "In addition to the basic Chinese NLP tasks",
        "mentioned above, the toolkit also provides many minor functions, such as text classification, dependency tree kernel, tree pattern-based information extraction, keywords extraction, translation between simplified and traditional Chinese, and so on.",
        "Currently, our toolkit has been used by many universities and companies for various applications, such as the dialogue system, social computing, recommendation system and vertical search.",
        "The rest of the demonstration is organized as follows.",
        "We first briefly describe our system and its main components in section 2.",
        "Then we show system performances in section 3.",
        "Section 4 introduces three ways to use our toolkit.",
        "In section 5, we summarize the paper and give some directions for our future efforts."
      ]
    },
    {
      "heading": "2 System Overview",
      "text": [
        "The components of our system have three layers of structure: data preprocessing, machine learning and natural language processing, which is shown in Figure 1.",
        "We will introduce these components in detail in the following subsections."
      ]
    },
    {
      "heading": "2.1 Data Preprocessing Component",
      "text": [
        "In the natural language processing system, the original input is always text.",
        "However, the statistical machine learning methods often deal with data with vector-based representation.",
        "So we firstly need to preprocess the input texts and transform them to the required format.",
        "Due to the fact that text data is usually discrete and sparse, the sparse vector structure is largely used.",
        "Similar to Mallet (McCallum, 2002), we use the pipeline structure for a flexible transformation of various data.",
        "The pipeline consists of several serial or parallel modules.",
        "Each module, called ?pipe?, is aimed at a single and simple function.",
        "For example, when we transform a sentence into a vector with ?bag-of-words?, the transformation process would involve the following",
        "serial pipes: 1.",
        "String2Token Pipe: to transform a string into word tokens.",
        "2.",
        "Token2Index Pipe: to look up the word alphabet to get the indices of the words.",
        "3.",
        "WeightByFrequency Pipe: to calculate",
        "the vector weight for each word according to its frequency of occurrence.",
        "With the pipeline structure, the data preprocessing component has good flexibility, extensibility and reusability."
      ]
    },
    {
      "heading": "2.2 Machine Learning Component",
      "text": [
        "The outputs of NLP are often structured, so the structured learning is our core module.",
        "Structured learning is the task of assigning a structured label y to an input x.",
        "The label y can be a discrete variable, a sequence, a tree or a more complex structure.",
        "To illustrate by a sample x, we define the feature as ?(x,y).",
        "Thus, we can label x with a score function,",
        "where w is the parameter of function F (?).",
        "The feature vector ?",
        "(x,y) consists of lots of overlapping features, which is the chief benefit of a discriminative model.",
        "For example, in sequence labeling, both x = x1, .",
        ".",
        ".",
        ", xL and y = y1, .",
        ".",
        ".",
        ", yL are sequences.",
        "For first-order Markov sequence labeling, the feature can be denoted as ?k(yi?1, yi,x, i), where i is the position in the sequence.",
        "Then the score function can be rewritten as",
        "where L is the length of x.",
        "Different algorithms vary in the definition of F (?)",
        "and the corresponding objective function.",
        "F (?)",
        "is usually defined as a linear or exponential family function.",
        "For example, in conditional random fields (CRFs) (Lafferty et al., 2001), F (?)",
        "is defined as:",
        "where Zw is the normalization constant such that it makes the sum of all the terms one.",
        "In FudanNLP, the linear function is universally used as the objective function.",
        "Eq.",
        "(1) is written as:",
        "In the training stage, we use the passive-aggressive algorithm to learn the model parameters.",
        "Passive-aggressive (PA) algorithm (Crammer et al., 2006) was proposed for normal multi-class classification and can be easily extended to structure learning (Crammer et al., 2005).",
        "Like Perceptron, PA is an online learning algorithm.",
        "For consistency with statistical machine learning, we call the process to calculate the Eq.",
        "(1) as ?inference?.",
        "In structured learning, the number of possible solutions is very huge, so dynamic programming or approximate approaches are often used for efficiency.",
        "For NLP tasks, the most popular structure is sequence.",
        "To label the sequence, we use Viterbi dynamic programming to solve the inference problem in Eq.",
        "(4).",
        "Our system can support any order of Viterbi decoding.",
        "In addition, we also implement a constrained Viterbi algorithm to reduce the number of possible solutions by predefined rules.",
        "For example, when we know the probable labels, we delete the unreachable states from state transition matrix.",
        "It is very useful for CWS and POS tagging with sequence labeling.",
        "When we have a word dictionary or know the POS for some words, we can get more accurate results.",
        "Apart from the core modules of structured learning, our system also includes several traditional machine learning algorithms, such as Perceptron, Adaboost, kNN, k-means, and so on."
      ]
    },
    {
      "heading": "2.3 Natural Language Processing Components",
      "text": [
        "Our toolkit provides the basic NLP functions, such as word segmentation, part-of-speech tagging, named entity recognition, syntactic parsing, temporal phrase recognition, anaphora resolution, and so on.",
        "These functions are trained on our developed corpus.",
        "We also develop a visualization module to displaying the output.",
        "Table 1 shows the output representation of our toolkit.",
        "Different from English, Chinese sentences are written in a continuous sequence of characters without explicit delimiters such as the blank space.",
        "Since the meanings of most Chinese characters are not complete, words are the basic syntactic and semantic units.",
        "Therefore, it is indispensable step to segment the sentence into words in Chinese language processing.",
        "We use character-based sequence labeling (Peng et al., 2004) to find the boundaries of words.",
        "Besides the carefully chosen features, we also use the meaning of character drawn from HowNet(Dong and Dong, 2006), which improves the performance greatly.",
        "Since unknown words detection is still one of main challenges of Chinese word segmentation.",
        "We implement a constrained Viterbi algorithm to allow users to add their own word dictionary.",
        "Chinese POS tagging is very different from that in English.",
        "There are no morphological changes for a word among its different POS tags.",
        "Therefore, most of Chinese words may have multiple POS tags.",
        "For example, there are different morphologies in English for the word ???",
        "(destroy)?, such as ?destroyed?, ?destroying?",
        "and ?destruction?.",
        "But in Chinese, there is just one same form(Xia, 2000).",
        "There are two popular guidelines to tag the word's POS: CTB (Xia, 2000) and PKU (Yu et al., 2001).",
        "We take into account both the weaknesses and the strengths of these two guidelines, and propose our guideline for better subsequent analyses, such as parser and named entity recognition.",
        "For example, the proper name is labeled as ?NR?",
        "in CTB, while we label it with one of four categories: person,",
        "location, organization and other proper name.",
        "Conversely, we merge the ?VC?",
        "and ?VE?",
        "into ?VV?",
        "since there is no link verb in Chinese.",
        "Finally, we use a tag set with 39 categories in total.",
        "Since a POS tag is assigned to each word, not to each character, Chinese POS tagging has two ways: pipeline method or joint method.",
        "Currently, the joint method is more popular and effective because it uses more flexible features and can reduce the error propagation (Ng and Low, 2004).",
        "In our system, we implement both methods for POS tagging.",
        "Besides, we also use some knowledge to improve the performance, such as Chinese surname and the common suffixes of the names of locations and organizations.",
        "In Chinese named entity recognition (NER), there are usually three kinds of named entities (NEs) to be dealt with: names of persons (PER) , locations (LOC) and organizations (ORG).",
        "Unlike English, there is no obvious identification for NEs, such as initial capitals.",
        "The internal structures are also different for different kinds of NEs, so it is difficult to build a unified model for named entity recognition.",
        "Our NER is based on the results of POS tagging and uses some customize features to detect NEs.",
        "First, the number of NEs is very large and the new NEs are endlessly emerging, so it is impossible to store them in dictionary.",
        "Since the internal structures are relatively more important, we use language models to capture the internal structures.",
        "Second, we merge the continuous NEs with some rule-based strategies.",
        "For example, we combine the continuous words ???/NN???/NN?",
        "into ?",
        "????",
        "?/LOC?.",
        "Our syntactic parser is currently a dependency parser, which is implemented with the shift-reduce deterministic algorithm based on the work in (Yamada and Matsumoto, 2003).",
        "The syntactic structure of Chinese is more complex than that of English, and semantic meaning is more dominant than syntax in Chinese sentences.",
        "So we select the dependency parser to avoid the minutiae in syntactic constituents and wish to pay more attention to the subsequent semantic analysis.",
        "Since the structure of the Chinese language is quite different from that of English, we use more effective features according to the characteristics of Chinese sentences.",
        "The common used corpus for Chinese dependency parsing is CoNLL corpus (Haji?",
        "et al., 2009).",
        "However, there are some illogical cases in CoNLL corpus.",
        "For example, the head words are often interrogative particles and punctuations.",
        "Our guideline is based on common understanding for Chinese grammar.",
        "The Chinese syntactic components usually include subject, predicate, object, attribute, adverbial modifier and complement.",
        "Figure 2 and 3 show the differences between the trees of CoNLL and our Corpus.",
        "Table 2 shows some",
        "primary dependency relations in our guideline.",
        "..?",
        ".?",
        ".???",
        ".?",
        ".?",
        ".?",
        ".",
        "?.want to .go to .Hehuanshan .to see .the snow .",
        ".",
        "?"
      ]
    },
    {
      "heading": "2.3.5 Temporal Phrase Recognition and Normalization",
      "text": [
        "Chinese temporal phrases is more flexible than English.",
        "Firstly, there are two calendars: Gregorian and lunar calendars.",
        "Both of them are frequently used.",
        "Secondly, the forms of same temporal phrase are various, which often consists of Chinese characters, Arabic numerals and English letters, such as ???",
        "10 ??",
        "and ?10:00 PM?.",
        "Different from the general process based on machine learning, we implement the time phrase recognizer with a rule-based method.",
        "These rules include 376 regular expressions and nearly a hundred logical judgments.",
        "After recognizing the temporal phrases, we normalize them with a standard time format.",
        "For a phrase indicating a relative time , such as ?????",
        "and ?",
        "????",
        "?, we first find the base time in the context.",
        "If no base time is found, or there is also no temporal phrase to indicate the base time (such as ????",
        "), we set the base time to the current system time.",
        "Table 3 gives examples for our temporal phrase recognition module.",
        "Input: 08 ????????",
        "?8 ?",
        "8 ??????????",
        "????????????",
        "The Beijing Olympic Games took place from August 8, 2008.",
        "Four years later, the London Olympic Games took place from July 21.",
        "????????",
        "9 ?????????????",
        "I'm busy today, and have to come off duty after 9:00 PM.",
        "And I also have to work this Sunday.",
        "Output:"
      ]
    },
    {
      "heading": "Recognition 2.3.6 Anaphora Resolution",
      "text": [
        "Anaphora resolution is to detect the pronouns and find what they are referring to.",
        "We first find all pronouns and entity names, then use a classifier to predict whether there is a relation between each pair of pronoun and entity name.",
        "Table 4 gives examples for our anaphora resolution module."
      ]
    },
    {
      "heading": "3 System Performances",
      "text": [
        "In this section, we investigate the performances for the six tasks: Chinese word segmentation (CWS), POS tagging (POS),",
        "named entity recognition (NER) and dependency parser(DePar), Temporal Phrase Recognition (TPR) and Anaphora Resolution (AR).",
        "We use 5-fold cross validation on our developed corpus.",
        "The corpus includes 65, 745 sentences and 959, 846 words.",
        "The performances are shown in Table 5."
      ]
    },
    {
      "heading": "4 Usages",
      "text": [
        "We provide three ways to use our toolkit.",
        "Firstly, our toolkit can be used as library.",
        "Users can call application programming interfaces (API) in their own applications.",
        "Secondly, users can also invoke the main NLP modules to process the inputs (strings or files) from the command line directly.",
        "Thirdly, the web services are provided for platform-independent and language-independent use.",
        "We use a REST (Representational State Transfer) architecture, in which the web services are viewed as resources and can be identified by their URLs."
      ]
    },
    {
      "heading": "5 Conclusions",
      "text": [
        "In this demonstration, we have described the system, FudanNLP, which is a Java-based open source toolkit for Chinese natural language processing.",
        "In the future, we will add more functions, such as semantic parsing.",
        "Besides, we will also optimize the algorithms and codes to improve the system performances."
      ]
    },
    {
      "heading": "Acknowledgments",
      "text": [
        "We would like to thank all the people6 involved with our FudanNLP project.",
        "This work was funded by NSFC (No.61003091"
      ]
    }
  ]
}
