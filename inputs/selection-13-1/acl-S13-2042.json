{
  "info": {
    "authors": [
      "Yoan Gutiérrez",
      "Yenier Castañeda",
      "Andy González",
      "Rainel Estrada",
      "Dennys D. Piug",
      "Jose I. Abreu",
      "Roger Pérez",
      "Antonio Fernández Orquín",
      "Andrés Montoyo",
      "Rafael Muñoz",
      "Franc Camara"
    ],
    "book": "*SEM",
    "id": "acl-S13-2042",
    "title": "UMCC_DLSI: Reinforcing a Ranking Algorithm with Sense Frequencies and Multidimensional Semantic Resources to solve Multilingual Word Sense Disambiguation",
    "url": "https://aclweb.org/anthology/S13-2042",
    "year": 2013
  },
  "references": [
    "acl-E09-1005",
    "acl-H05-1052",
    "acl-P10-1023",
    "acl-S10-1095",
    "acl-S12-1090",
    "acl-S13-2040",
    "acl-W11-1718"
  ],
  "sections": [
    {
      "heading": "Abstract",
      "text": [
        "This work introduces a new unsupervised approach to multilingual word sense disambiguation.",
        "Its main purpose is to automatically choose the intended sense (meaning) of a word in a particular context for different languages.",
        "It does so by selecting the correct Babel synset for the word and the various Wiki Page titles that mention the word.",
        "BabelNet contains all the output information that our system needs, in its Babel synset.",
        "Through Babel synset, we find all the possible Synsets for the word in WordNet.",
        "Using these Synsets, we apply the disambiguation method Ppr+Freq to find what we need.",
        "To facilitate the work with WordNet, we use the ISR-WN which offers the integration of different resources to WordNet.",
        "Our system, recognized as the best in the competition, obtains results around 69% of Recall."
      ]
    },
    {
      "heading": "1 Introduction Word Sense Disambiguation (WSD) focuses on",
      "text": [
        "resolving the semantic ambiguity of a given word.",
        "This is an important task in Natural Language Processing (NLP) because in many applications, such as Automatic Translation, it is essential to know the exact meaning of a word in a given context.",
        "In order to solve semantic ambiguity, different systems have been developed.",
        "However, we can categorize them in two main groups: supervised and unsupervised systems.",
        "The supervised ones need large quantity of hand-tagged data in order to gather enough information to build rules, train systems, and so on.",
        "Unsupervised systems, on the other hand, do not need such a large amount of hand-tagged datasets.",
        "This means that, when there aren't enough corpora to train the systems, an unsupervised system is a good option.",
        "A subtask of WSD is Multilingual Word Sense Disambiguation (MWSD) (Navigli et al., 2013) that aims at resolving ambiguities in different languages.",
        "In a language, there are words that have only one sense (or meaning), but in other languages, the same words can have different senses.",
        "For example, ?patient?",
        "is a word that in English can be either a noun or an adjective, but in German, it only has one sense - ?viz?",
        "(a person that needs treatment).",
        "This shows that the information obtained by combining two languages can be more useful for WSD because the word senses in each language can complement each other.",
        "For it to be useful, MWSD needs a multilingual resource that contains different languages, such as BabelNet (Navigli and Ponzetto, 2010; 2012) and EuroWordNet (Vossen, 1998).",
        "As the preferred disambiguation method, we decided to use the Ppr+Freq (Personalized Page Rank combined with Frequencies of senses) (Guti?rrez, 2012) method because, among unsupervised systems, graph-based methods have obtained more promising results.",
        "It is worth mentioning the relevant approaches used by the scientific community to achieve promising results.",
        "One approach used is structural interconnections, such as Structural Semantic Interconnections (SSI), which create structural specifications of the possible senses for each word in a context (Navigli and Velardi, 2005).",
        "The other approaches used are ?Exploring the integration of WordNet?",
        "(Miller et al., 1990), FrameNet (Laparra et al., 2010) and those using Page-Rank such as (Sinha and Mihalcea, 2007) and (Agirre and Soroa, 2009).",
        "The aforementioned types of graph based approaches have achieved relevant results in both the SensEval-2 and SensEval-3 competitions (see",
        "calculated recalls using SensEval-2 (English All Word task) guidelines over.",
        "Experiments using SensEval-2 and SensEval-3 corpora suggest that Ppr+Freq (Guti?rrez, 2012) can lead to better results by obtaining over 64% of Recall.",
        "Therefore we selected Ppr+Freq as the WSD method for our system.",
        "The key proposal for this work is an unsupervised algorithm for MWSD, which uses an unsupervised method, Ppr+Freq, for semantic disambiguation with resources like BabelNet (as sense inventory only) (Navigli and Ponzetto, 2010) and ISR-WN (as knowledge base) (Guti?rrez et al., 2011a; 2010a).",
        "ISR-WN was selected as the default knowledge base because of previous NLP research, which included: (Fern?ndez et al., 2012; Guti?rrez et al., 2010b; Guti?rrez et al., 2012; 2011b; 2011c; 2011d), which achieved relevant results using ISR-WN as their knowledge base."
      ]
    },
    {
      "heading": "2 System architecture",
      "text": [
        "By using one of BabelNet (BN) features, our technique begins by looking for all the Babel synsets (Bs) linked to the lemma of each word in the sentence that we need to disambiguate.",
        "Through the Bs offsets, we can get its corresponding WordNet Synset (WNS), which would be retrieved from WordNet (WN) using the ISR-WN resource.",
        "As a result, for each lemma, we have a WordNet Synset List (WNSL) from which our Word Sense Disambiguation method obtains one WNS as the correct meaning.",
        "Our WSD method consists of applying a modification of the Personalizing PageRank (Ppr) algorithm (Agirre and Soroa, 2009), which involves the senses frequency.",
        "More specifically, the key proposal is known as Ppr+Freq (see Section 2.3).",
        "Given a set of WNSLs of WNSL, as words window, we applied the Synsets ranking method, Ppr+Freq, which ranks in a descending order, the Synsets of each lemma according to a calculated factor of relevance.",
        "The first Synset (WNS) of each WNSL (the most relevant) is established as the correct one and its associated Babel synset (Bs) is also tagged as correct.",
        "To determine the Wiki Page Titles (WK), we examine the WIKI (Wikipedia pages) and WIKIRED (Wikipedia pages redirections) in the correct Babel synset obtained.",
        "Figure 1 shows a general description of our system that is made up of the following steps: I.",
        "Obtaining lemmas II.",
        "Obtaing WN Synset of selected lemmas III.",
        "Applying Ppr+Freq method IV.",
        "Assigning Synset, Babel synset and Wiki page title Note that ISR-WN contains WN as its nucleus.",
        "This allows linking both resources, BabelNet and ISR-WN."
      ]
    },
    {
      "heading": "2.1 Obtaining lemmas",
      "text": [
        "For each input sentence, we extract the labeled lemmas.",
        "As an example, for the sentence, ?The struggle against the drug lords in Colombia will be a near thing,?",
        "the selected lemmas are: ?struggle,?"
      ]
    },
    {
      "heading": "2.2 Obtaing WN Synset of selected lemmas",
      "text": [
        "For each lemma obtained in the previous section, we look through BabelNet to recover the Bs that contains the lemma among its labels.",
        "When BSs are mapped to WN, we use the ISR-WN resource to find the corresponding Synset.",
        "Since a lemma can appear in a different Bs, it can be mapped with several WNS.",
        "Thus, we get a Synset list for each lemma in the sentence.",
        "In case the lemma does not have an associated Bs, its list would be empty.",
        "An example of this step is shown on Figure 2."
      ]
    },
    {
      "heading": "2.3 Applying Ppr+Freq method",
      "text": [
        "In the above case, Ppr+Freq modifies the ?classic?",
        "Page Rank approach instead of assigning the same weight for each sense of WN in the disambiguation graph (??).",
        "The PageRank (Brin and Page, 1998) adaptation, Ppr , which was popularized by (Agirre",
        "and Soroa, 2009) in Word Sense Disambiguation thematic, and which has obtained relevant results, was an inspiration to us in our work.",
        "The main idea behind this algorithm is that, for each edge between ?i and ?j in graph ?, a vote is made from ?i to ?j.",
        "As a result, the relevance of ?j is increased.",
        "On top of that, the vote strength from ?",
        "to ?",
        "depends on ????",
        "relevance.",
        "The philosophy behind it is that, the more important the vertex is, the more strength the voter would have.",
        "Thus, PageRank is generated by applying a random walkthrough from the internal interconnection of ?, where the final relevance of ??",
        "represents the random walkthrough probability over ?, and ending on ??.",
        "Ppr+Freq includes the existent semantic and frequency patterns of each sense of the word to disambiguate while finding a way to connect each one of these words in a knowledge base.",
        "The new graph-based approach of WSD generates a graph of disambiguated words for each input sentence.",
        "For that reason, it is necessary to classify the word senses according to the other words that compose the context.",
        "The general method is shown in Figure 3.",
        "This method is divided into three steps: I.",
        "Creation of a disambiguation graph II.",
        "Application of Ppr+Freq in the generated graph III.",
        "Selection of the correct answer Creation of a disambiguation graph: In the first step, a disambiguation graph is built by means of a Breath First Search (BFS) over the ?super?",
        "graph composed by all the resources integrated into ISR-WN.",
        "The components involved in this process are:",
        "2001).",
        "This search aims to recover all senses (nodes), domain labels (from WordNet Domain and WordNet Affects), SUMO categories, and Semantic Classes labels through the shortest path between every pair of senses in the WNSL set associated with the input sentence.",
        "Using ISR-WN as the KB, through experimentation, we obtained the shortest paths with a length of five edges.",
        "For a better understanding of this process, see (Guti?rrez, 2012).",
        "Application of Ppr+Freq in the generated graph: In the second step, we use the weighted Personalized PageRank.",
        "Here, all the vertices from vector ?",
        "in ??",
        "are initialized with the value",
        "where ?",
        "is the number of nodes in ??.",
        "On the other hand, the vertices that represent word senses in the analyzed sentence are not initialized with this value.",
        "Instead, they are initialized with values in the range [0?1], which are associated to their occurrence frequency in SemCor1 (Corpus and sense frequencies knowledge).",
        "In the last step, after applying the Ppr+Freq algorithm over ?",
        "?, we get a representative vector which contains ISR-WN nodes in ??",
        "sorted in a descending order by a ranking score computed by this algorithm.",
        "For a better description, see (Guti?rrez, 2012).",
        "Selection of the correct answer: As the correct sense, we take the highest ranked sense of each target word involved in this vector.",
        "Note that domain labels, SUMO categories, semantic class labels, and affect labels are ranked too.",
        "They could be used in the future to determine relevant conceptualizations that would be useful for text classification and more.",
        "In our system, we assume the following configuration: dumping factor ?",
        "= 0.85 and like in (Agirre and Soroa, 2009) we used 30 iterations.",
        "A detailed explanation about PageRank algorithm can be found in (Agirre and Soroa, 2009).",
        "Table 2 shows an example that analyzes the Synset for each word in the sentence and also shows how the higher ranked Synsets of the target words are selected as the correct ones.",
        "For a detailed explanation of Ppr+Freq, see (Guti?rrez, 2012)."
      ]
    },
    {
      "heading": "2.4 Assigning Synset, Babel synset and Wiki Pages",
      "text": [
        "In this step, English is handled differently from other languages because WordNet Synsets are available only for English.",
        "The following sections explain how we proceed in each case.",
        "Once the Synsets list is obtained for each lemma in section 2.3, selecting the correct answer for the lemma is all that's left to do.",
        "Given a lemma, we go through its Synset list from beginning to end looking for the first Synset that contains a key2 for the lemma.",
        "If such Synset exists, it is designated as the Synset for the lemma.",
        "Otherwise, no Synset is assigned.",
        "As already explained, each Synset in the list is connected to a Bs.",
        "Therefore, the lemma linked with the correct WNS selected in the previous step, is chosen as the correct lemma.",
        "In case no Synsets were designated as the correct ones, we take the first Bs in BN, which contains the lemma among its labels.",
        "To determine the Wiki pages titles (WK) we examine the WIKIRED and WIKI labels in the correct Bs selected in the preceding step.",
        "This search is restricted only to labels corresponding to the analyzed language and discriminating upper and lower case letters.",
        "Table 2 shows some sample results of the WSD process.",
        "semantic tagging or other systems that refer to WordNet senses.",
        "sense_key's are independent of WordNet sense numbers and synset_offset?s, which vary between versions of the database.",
        "For this scenario, we introduce a change in the first step discussed in the previous section.",
        "The reason is that the Synsets do not contain any keys in any other language than English.",
        "Thus, the correct Synset for the lemma is the first in the Synset list for the lemma obtained, as described, in section 2.3."
      ]
    },
    {
      "heading": "3 Results",
      "text": [
        "We tested three versions (runs) of the proposed approach and evaluated them through a trial dataset provided by Task123 of Semeval-2013 using babelnet-1.0.1.",
        "Table 3 shows the result for each run.",
        "Note that the table results were calculated with the traditional WSD recall measure, being this measure which has ranked WSD systems on mostly Semeval competitions.",
        "On the other hand, note that our precision and recall results are different because the coverage is not 100%.",
        "See Table 5.",
        "As can be noticed on Table 3, results of different versions do not have big differences, but in general, Run2 achieves the best results; it's better",
        "than Run1 in the WK with a 78% in English and Bs with 60% in French.",
        "The best results are in the WK in French with a value of 85%.",
        "Since we can choose to include different resources into ISR-WN, it is important to analyze how doing so would affect the results.",
        "Table 4 shows comparative results for Run 2 of a trial dataset with BabelNet version 1.1.1.",
        "As can be observed in Table 4, the result does not have a significant change even though we used the ISR-WN with all resources.",
        "A better analysis of Ppr+Freq in, as it relates to the influence of each resource involved in ISR-WN (similar to Table 4 description) assessing SensEval-2 and SensEval-3 dataset, is shown in (Guti?rrez, 2012).",
        "There are different resource combinations showing that only XWN1.7 and all ISR-WN resources obtain the highest performance.",
        "Other analysis found in (Guti?rrez, 2012) evaluates the influence of adding the sense frequency for Ppr+Freq.",
        "By excluding the Factotum Domain, we obtain the best result in Bs 54% for French (only 1% more than the version used in the competition).",
        "The other results are equal, with a 69% in WNS, 66% in Bs, 64% in WK for English, and 69% in"
      ]
    },
    {
      "heading": "3.1 Run1",
      "text": [
        "In this Run, WNSLs consist of all the target words involved in each sentence.",
        "This run is applied at the sentence level.",
        "The results for the competition are shown in Table 5.",
        "For this Run, the best result was obtained for Spanish with a 70.3% in Bs and 49.3% in WK of Recall.",
        "As we can see, for Run1 the precision is high for Wikipedia disambiguation, obtaining for French the best result of the ranking.",
        "The low Recall in Wikipedia is due to the exact mismatching of labels between our system output and the gold standard.",
        "This fact, affects the rest of our runs."
      ]
    },
    {
      "heading": "3.2 Run2",
      "text": [
        "In this Run, WNSLs consist of all the target words involved in each domain.",
        "We can obtain the target words because the training and test dataset contain the sentences grouped by topics.",
        "For instance, for English, 13 WNSLs are established.",
        "This Run is applied at the corpora level.",
        "The results for the competition are shown in Table 5.",
        "It is important to emphasize that our best results ranked our algorithm as first place among all proposed approaches for the MWSD task.",
        "For this run, the best Recall was obtained for Spanish with a 70.8% in Bs and 50.2% in WK.",
        "This Run also has the best result of the three runs.",
        "For the English competition, it ended up with a 64.5% in WNS, 68.5% in Bs, and 48.7% in WK.",
        "This Run obtained promising results, which took first place in the competition.",
        "It also had better results than that of the First Sense (Most Frequent Sense) baseline in Bs results for all languages, except for German.",
        "In Bs, it only obtained lower results in German with a 62% of Recall for our system and 67.3% for the First Sense baseline."
      ]
    },
    {
      "heading": "3.3 Run3",
      "text": [
        "In this run, WNSLs consist of all the words included in each sentence.",
        "This run uses target words and non-target words of each sentence, as they are applied to the sentence level.",
        "The results for the competition are shown in Table 5.",
        "As we can see, the behavior of this run is similar to the previous runs."
      ]
    },
    {
      "heading": "4 Conclusions and Future work",
      "text": [
        "The above results suggest that our proposal is a promising approach.",
        "It is also important to notice that a richer knowledgebase can be built by combining different resources such as BabelNet and ISR-WN, which can lead to an improvement of the results.",
        "Notwithstanding, our system has been recognized as the best in the competition, obtaining results around 70% of Recall.",
        "According to the Task12 results4, only the baseline Most Frequent Sense (MFS) could improve our scores in order to achieve better WK and German (DE) disambiguation.",
        "Therefore, we plan to review this point to figure out why we obtained better results in other categories, but not for this one.",
        "At the same time, further work will use the internal Babel network to run the Ppr+Freq method in an attempt to find a way to enrich the semantic network obtained for each target sentence to disambiguate.",
        "On top of that, we plan to compare Ppr (Agirre and Soroa, 2009) with Ppr+Freq using the Task12 dataset.",
        "Availability of our Resource In case researchers would like to use our resource, it is available at the GPLSI5 home page or by contacting us via email."
      ]
    },
    {
      "heading": "Acknowledgments",
      "text": [
        "This research work has been partially funded by"
      ]
    }
  ]
}
