{
  "info": {
    "authors": [
      "Steve L. Manion",
      "Raazesh Sainudiin"
    ],
    "book": "*SEM",
    "id": "acl-S13-2043",
    "title": "DAEBAK!: Peripheral Diversity for Multilingual Word Sense Disambiguation",
    "url": "https://aclweb.org/anthology/S13-2043",
    "year": 2013
  },
  "references": [
    "acl-E09-1005",
    "acl-H05-1052",
    "acl-P12-3012",
    "acl-W07-2006"
  ],
  "sections": [
    {
      "heading": "Abstract",
      "text": [
        "We introduce Peripheral Diversity (PD) as a knowledge-based approach to achieve multilingual Word Sense Disambiguation (WSD).",
        "PD exploits the frequency and diverse use of word senses in semantic subgraphs derived from larger sense inventories such as BabelNet, Wikipedia, and WordNet in order to achieve WSD.",
        "PD's f measure scores for SemEval 2013 Task 12 outperform the Most Frequent Sense (MFS) baseline for two of the five languages: English, French, German, Italian, and Spanish.",
        "Despite PD remaining underdeveloped and under-explored, it demonstrates that it is robust, competitive, and encourages development."
      ]
    },
    {
      "heading": "1 Introduction",
      "text": [
        "By reading out aloud ?A minute is a minute division of time?",
        "(Nelson, 1976), we can easily make the distinction between the two senses of the homograph minute.",
        "For a machine this is a complex task known as Word Sense Disambiguation (WSD).",
        "Task 12 of SemEval 2013 (Navigli et al., 2013) calls for a language-independent solution to WSD that utilises a multilingual sense inventory.",
        "Supervised approaches to WSD have dominated for some time now (Ma`rquez et al., 2007).",
        "Homographs such as minute are effortlessly disambiguated and more polysemous words such as bar or line can also be disambiguated with reasonable competence (Agirre and Edmonds, 2007).",
        "However our approach is purely knowledge-based and employs semantic graphs.",
        "This allows us to avoid the notorious predicament Gale et al. (1992) name the information bottleneck, in which supervised approaches fail to be portable across alternative languages and domains if the annotated corpora do not exist.",
        "Conversely, knowledge-based approaches for WSD are usually applicable to all words in unrestricted text (Mihal-cea, 2007).",
        "It is this innate scalability that motivates us to pursue knowledge-based approaches.",
        "Regardless of whether sense inventories can maintain knowledge-richness as they grow, their continued refinement by contributors is directly beneficial.",
        "Knowledge-based approaches that employ semantic graphs increasingly rival leading supervised approaches to WSD.",
        "They can beat a Random or LESK (Lesk, 1986) baseline (see Mihalcea (2005), Navigli and Lapata (2007), Sinha and Mihalcea (2007), Navigli and Lapata (2010)) and can compete with or even beat the Most Frequent Sense (MFS) baseline in certain contexts which is by no means an easy task (see Navigli et al. (2007), Eneko Agirre and Aitor Soroa (2009), Navigli and Ponzetto (2012a))."
      ]
    },
    {
      "heading": "2 Methodology",
      "text": [
        "PD is a framework for knowledge-based WSD approaches that employ semantic graphs.",
        "However before we can elaborate we must first cover the fundamental resources it is built upon."
      ]
    },
    {
      "heading": "2.1 Fundamental Resource Definitions",
      "text": [
        "At a glance across the text of any language, we absorb meaning and new information through its lexical composition.",
        "Depending on the length of text",
        "we are reading, we could interpret it as one of many structural subsequences of writing such as a paragraph, excerpt, quote, verse, sentence, among many others.",
        "LetW = (wa, ..., wb) be this subsequence of words, which we will utilise as a sliding window for PD.",
        "Again let W = (w1, ..., wm) be the larger body of text of length m, such as a book, newspaper, or corpus of text, that our sliding window of length b?a moves through.",
        "In SemEval Task 12 on Multilingual Word Sense Disambiguation all words are lemmatised, which is the process of unifying the different inflected forms of a word so they can be analysed as a consolidated lemma (or headword).",
        "Therefore words (or lexemes) such as runs and ran are all mapped to their unifying lemma run1.",
        "To express this, let `w : W ?",
        "L be a many-to-one mapping from the sequence of words W to the sequence of lemmas L, in which (wa, ..., wb) 7?",
        "(`wa , ..., `wb) = (`a, ..., `b).",
        "To give an example from the test data set2, the word sequenceW = (And, it, ?s, nothing, that, runs, afoul, of, ethics, rules, .)",
        "maps to the lemma sequence L = (and, it, be, nothing, that, run, afoul, of, ethic, rule, .).",
        "In order to complete this SemEval task we disambiguate a large sequence of lemmas L = (`1, ..., `m), via our lemma-based sliding window L = (`a, ..., `b).",
        "Each lemma `i ?",
        "L may refer up to k senses in S(`i) = {si,1, si,2, ..., si,k} = S .",
        "Furthermore each sense si,j ?",
        "S maps to a set of unique concepts in the human lexicon.",
        "To clarify let us consider one of the earliest examples of modern ambiguity taken from Bar-Hillel's (1960) critique of Machine Translation: W = (The, box, was, in, the, pen, .).",
        "The sense of pen could be either a) a certain writing utensil or b) an enclosure where small children can play, therefore {senclosure, sutensil} ?",
        "S(`pen) = S. Humans can easily resolve the ambiguity between the possible senses of pen by accessing their own internal lexicon and knowledge of the world they have built up over time.",
        "In the same vein, when accessing sense inventories such as BabelNet, WordNet (Fellbaum, 1998),",
        "and Wikipedia which are discrete representations of the human lexicon, we refer to each sense si,j ?",
        "S as a synset.",
        "Depending on the sense inventory the synset belongs to, it may contain alternative or translated lexicalisations, glosses, links to other semantic resources, among a collection of semantically defined relations to other synsets.",
        "PD makes use of subgraphs derived from a directed graph G = (V, E) that can be crafted from a sense inventory, such as BabelNet, WordNet, or Wikipedia.",
        "We construct subgraphs using the BabelNet API which accesses BabelNet3 and Babel synset paths4 indexed into Apache Lucene5 to ensure speed of subgraph construction.",
        "This process is described in Navigli and Ponzetto (2012a) and demonstrated in Navigli and Ponzetto (2012b).",
        "Our formalisation of subgraphs is adapted into our own notation from the original papers of Navigli and Lapata (2007) and Navigli and Lapata (2010).",
        "We refer the reader to these listed sources if they desire an extensive explanation of our subgraph construction as we have built PD on top of the same code base therefore we do not deviate from it.",
        "For a given lemma sequence L = (`i, ..., `n) and",
        "directed graph G = (V, E) we construct our subgraph GL = (VL, EL) in two steps: 1.",
        "Initialize VL := ?n i=1 S(`i) and EL := ?.",
        "2.",
        "For each node v ?",
        "VL, we perform a depth",
        "first search (DFS) of G, such that, every time we encounter a node v?",
        "?",
        "VL (v?",
        "6= v) along a path v, v1, ..., vk, v?",
        "of length ?",
        "L in G, we add all intermediate nodes and edges on the path from v to v?, i.e., VL := VL ?",
        "{v1, ..., vk} and"
      ]
    },
    {
      "heading": "2.2 Interpretation of Problem",
      "text": [
        "For the lemmatisation of any word wi 7?",
        "`i : wi ?",
        "W, `i ?",
        "L, we must estimate the most appropriate synset si,?",
        "?",
        "S(`i) = {si,1, si,2, ..., si,k}.",
        "Our system associates a PD score ?",
        "(si,j) for each",
        "si,j ?",
        "S(`i) by taking GL as input.",
        "We estimate si,?, the most appropriate sense for `i, by s?i,?",
        "= argmaxsi,j?S(`i) ?(si,j).",
        "It's worth noting here that GL ensures the estimation of s?i,?",
        "is not an independent scoring rule, since GL embodies the context surrounding `i via our sliding lemma-based window L."
      ]
    },
    {
      "heading": "2.3 Peripheral Diversity Framework",
      "text": [
        "PD is built on the following two ideas that are explained in the following subsections: 1.",
        "For a subgraph derived from one lone lemma `i, in which no other lemmas can provide context, the synset si,j ?",
        "G`i that has the largest and most semantically diverse set of peripheral synset nodes is assumed to be the MFS for `i.",
        "2.",
        "For a larger subgraph derived from a sliding lemma window L, in which other lemmas can provide context, the synset si,j ?",
        "GL that observes the largest increase in size and semantic diversity of its peripheral synset nodes is estimated to be si,?, the most appropriate synset for lemma `i.",
        "Therefore PD is merely a framework that exploits these two assumptions.",
        "Now we will go through the process of estimating si,?",
        "for a given lemma `i.",
        "First, for each synset si,j ?",
        "S, we need to acquire a set of its peripheral synsets.",
        "We do this by travelling a depth of up to d (stopping if the path ends), then adding the synset we reach to our set of peripheral synsets P?d = {sj,1, sj,2, ..., sj,k?}.",
        "Next for every pair of synsets v and v?",
        "that are not direct neighbours in P?d such that v 6= v?, we calculate their Pairwise Semantic Dissimilarity (PSD) ?",
        "(v, v?)",
        "which we require for a synset's PD score.",
        "To generate our results for this task we have used the complement to Cosine Similarity, commonly known as the Cosine Distance as our",
        "where O(v) is the outgoing (out-neighbouring) synsets for v ?",
        "P?d, and |O(v) |denotes the number of elements in O(v).",
        "Once we have PSD scores for every permitted pairing of v and v?, we have a number of ways to generate our ?",
        "(si,j) values.",
        "To generate our results for this task, we chose to score synsets on the sum of their minimum PSD values, which is expressed formally below:",
        "The idea is that this summing over the peripheral synsets in P?d(si,j) accounts for how frequently synset si,j is used, then each increment in size is weighted by a peripheral synset's minimumal PSD across all synsets in P?d(si,j).",
        "Therefore peripheral set size and semantic diversity are rewarded simultaneously by ?.",
        "To conclude, the final estimated synset sequence for a given lemma sequence (`1, ..., `m) based on ?",
        "is (s?1,?, s?2,?, ..., s?m,?",
        ").",
        "Wikipedia's Did You Mean?",
        "We account for deviations and errors in spelling to ensure lemmas have the best chance of being mapped to a synset.",
        "Absent synsets in subgraph GL will naturally degrade system output.",
        "Therefore if `i 7?",
        "?, we make an HTTP call to Wikipedia's Did you mean?",
        "and parse the response for any alternative spellings.",
        "For example in the test data set6 the misspelt lemma: ?feu de la rampe?",
        "is corrected to ?feux de la rampe?.",
        "Custom Back-off Strategy As back-off strategies7 have proved useful in (Navigli and Ponzetto, 2012a) and (Navigli et al., 2007), we designed our own back-off strategy.",
        "In the event our system provides a null result, the Babel synset si,j ?",
        "S(`i) = S with the most senses associated with it will be chosen with preference to its region in BabelNet such that WIKIWN WN WIKI.",
        "Input Parameters We set our sliding window length (b?",
        "a) to encompass 5 sentences at a time, in which the step size is also 5 sentences.",
        "For subgraph construction the maximum lengthL = 3.",
        "Finally we set our peripheral search depth d = 3.",
        "Filters For the purposes of reproducibility only we briefly mention two filters we apply to our subgraphs that ship with the BabelNet API.",
        "We remove WordNet contributed domain relations with the ILLEGAL POINTERS filter and apply the SENSE SHIFTS filter.",
        "For more information on these filters we suggest the reader consult the BabelNet API documentation."
      ]
    },
    {
      "heading": "3 Results & Discussion",
      "text": []
    },
    {
      "heading": "3.1 Results of SemEval Submission",
      "text": [
        "As can be seen in Table 1, the results of our single submission were varied and competitive.",
        "The worst result was for German in which our system fell behind the MFS baseline by a margin of 9.50.",
        "Again for French and Italian we exceeded the MFS baseline by a margin of 3.70 and 4.10 respectively.",
        "Our Daebak back-off strategy contributed anywhere between 1.12% (for French) to 2.70% (for Spanish) in our results, which means our system outputs a result without the need for a back-off strategy at least 97.30% of the time.",
        "Overall our system was slightly outperformed by the MFS baseline by a margin of 2.26.",
        "Overall PD demonstrated to be robust across a range of European languages.",
        "With these preliminary results this surely warrants further investigation of what can be achieved with PD."
      ]
    },
    {
      "heading": "3.2 Exploratory Results",
      "text": [
        "The authors observed some inconsistencies in the task answer keys across different languages as Table 2 illustrates.",
        "For each Babel synset ID found in the answer key, we record where its original source synsets are from, be it Wikipedia (WIKI), WordNet (WN), or both (WIKIWN).",
        "This is not a critical observation but rather an empirical enlightenment on the varied mechanics of different languages and the amount of development/translation effort that has gone into the contributing subparts of BabelNet: Wikipedia and WordNet.",
        "The heterogeneity of hybrid sense inventories such as BabelNet creates new obstacles for WSD, as seen in (Medelyan et al., 2013) it is difficult to create a disambiguation policy in this context.",
        "Future work we would like to undertake would be to investigate the heterogenous nature of BabelNet and how this affects various WSD methods."
      ]
    },
    {
      "heading": "4 Conclusion & Future Directions",
      "text": [
        "To conclude PD has demonstrated in its early stages that it can perform well and even outperform the MFS baselines in certain experimental contexts.",
        "Furthermore it leaves a lot left to be explored in terms of what this approach is capable of via adjusting subgraph filters, strategies, and input parameters across both heterogenous and homogenous semantic graphs."
      ]
    },
    {
      "heading": "Acknowledgments",
      "text": [
        "This research was completed with the help of the Korean Foundation Graduate Studies Fellowship8."
      ]
    },
    {
      "heading": "5 Resources",
      "text": [
        "The code base for this work can be found in the near"
      ]
    }
  ]
}
