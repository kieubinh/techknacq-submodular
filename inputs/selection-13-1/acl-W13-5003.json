{
  "info": {
    "authors": [
      "Sumit Bhagwani",
      "Shrutiranjan Satapathy",
      "Harish Karnick"
    ],
    "book": "TextGraphs Workshop on Graph Based Methods for Natural Language Processing",
    "id": "acl-W13-5003",
    "title": "Merging Word Senses",
    "url": "https://aclweb.org/anthology/W13-5003",
    "year": 2013
  },
  "references": [
    "acl-D07-1107",
    "acl-I05-7009",
    "acl-J98-1006",
    "acl-N06-2015",
    "acl-P03-1058",
    "acl-P06-1014",
    "acl-P94-1019",
    "acl-W00-0103",
    "acl-W04-0811",
    "acl-W04-0827",
    "acl-W04-0838",
    "acl-W04-0856",
    "acl-W04-0864",
    "acl-W06-2503",
    "acl-W07-2006"
  ],
  "sections": [
    {
      "heading": "Abstract",
      "text": [
        "WordNet, a widely used sense inventory for Word Sense Disambiguation(WSD), is often too fine-grained for many Natural Language applications because of its narrow sense distinctions.",
        "We present a semi-supervised approach to learn similarity between WordNet synsets using a graph based recursive similarity definition.",
        "We seed our framework with sense similarities of all the word-sense pairs, learnt using supervision on human-labelled sense clusterings.",
        "Finally we discuss our method to derive coarse sense inventories at arbitrary granularities and show that the coarse-grained sense inventory obtained significantly boosts the disambiguation of nouns on standard test sets."
      ]
    },
    {
      "heading": "1 Introduction",
      "text": [
        "With different applications requiring different levels of word sense granularity, producing sense clustered inventories with the requisite level of sense granularity has become important.",
        "The subtleties of sense distinctions captured by WordNet(Miller, 1995) are helpful for language learners (Snow et al., 2007) and in machine translation of languages as diverse as Chinese and English (Ng et al., 2003).",
        "On the other hand, for tasks like Document Categorization and Information Retrieval (Buitelaar, 2000), it may be sufficient to know if a given word belongs to a coarsely defined class of WordNet senses.",
        "Using the fine grained sense inventory of WordNet may be detrimental to the performance of these applications.",
        "Thus developing a framework which can generate sense inventories with different granularities can improve the performance of many applications.",
        "To generate a coarse sense inventory, many researchers have focused on generating coarse senses for each word by merging the fine-grained senses (Chugur et al., 2002) (Navigli, 2006).",
        "This approach has two problems.",
        "First, it requires a stopping criterion for each word ?",
        "for example the number of final classes.",
        "The right number of classes for each word cannot usually be predetermined even if the application is known.",
        "So such systems cannot be used to derive coarse senses for all the words.",
        "Second, inconsistent sense clusters are obtained because coarse senses are independently generated for each word.",
        "This leads to transitive closure errors and suggests that for deriving consistent coarse senses, instead of clustering senses for each word separately we should cluster synsets.",
        "We propose a framework that derives a coarse sense inventory by learning a synset similarity metric.",
        "We focus on coarsening the noun synsets of WordNet and show that the obtained coarse-grained sense inventory greatly improves the noun sense disambiguation.",
        "Our approach closely resembles (Snow et al., 2007) for supervised learning of synset similarity.",
        "But to learn similarity between synset pairs which do not share a word we use a variant of the SimRank framework (Jeh and Widom, 2002) and avoid giving them zero similarity.",
        "Thus the similarity learnt is more than a binary decision and is reflective of a more comprehensive semantic similarity between the synsets.",
        "The use of SimRank for learning synset similarity is inspired by the success of graph-centrality algorithms in WSD.",
        "We do not modify the WordNet ontology, unlike (Snow et al., 2007), as it may introduce spurious relations and remove some manually encoded information.",
        "In section 2, we discuss past work in sense clustering.",
        "In section 3 and 4, we describe our framework of learning synset similarity using SimRank.",
        "In section 5, we discuss our methodology of producing coarse senses using the learnt similarity metric.",
        "Section 6 describes the experimental setup and evaluates the framework described.",
        "Section 7 contains conclusions and discusses the directions for future work."
      ]
    },
    {
      "heading": "2 Related Work",
      "text": [
        "A wide variety of automatic methods have been proposed for coarsening fine-grained inventories.",
        "The earliest attempt on WordNet include (Mihalcea and Moldovan, 2001) which merged synsets on semantic principles like sharing a pertainym, antonym or verb group.",
        "We discuss some of the ideas which are related to our work.",
        "Though promising, many of these techniques are severely limited by the amount of available manually annotated data.",
        "(Chugur et al., 2002) constructed sense similarity matrices using translation equivalences in four languages.",
        "With the advent of WordNets being developed in multiple languages1 as well as multilingual ontologies like BabelNet (Navigli and Ponzetto, 2012), this seems a promising area.",
        "(McCarthy, 2006) estimated sense similarities using a combination of word-to-word distributional similarity combined with the JCN WordNet based similarity measure (Jiang and Conrath, 1997).",
        "They introduce a more relaxed notion of sense relatedness which allows the user to control the granularity for the application in hand.",
        "(Navigli, 2006) produced a fixed set sense clusters by mapping WordNet word senses to Oxford English Dictionary(OED) word senses exploiting similarities in glosses and semantic relationships in the sense inventories.",
        "It is expected that the different WordNet senses that are semantically close mapped to the same sense in the other ontology via an efficient mapping that is able to capture the semantic similarity between the concepts in both the ontolo",
        "html.",
        "gies.",
        "The drawback of this method is the generation of inconsistent sense clusters.",
        "(Snow et al., 2007) presented a novel supervised approach in which they train a Support Vector Ma-chine(SVM) using features derived from WordNet and other lexical resources, whose predictions serve as a distance measure between synsets.",
        "Assuming zero similarity between synset pairs with no common words, they cluster synsets using average link agglomerative clustering and the synset similarity model learnt."
      ]
    },
    {
      "heading": "3 SimRank",
      "text": [
        "SimRank (Jeh and Widom, 2002) is a graph based similarity measure applicable in any domain with object-to-object relationships.",
        "It uses the intuition that ?two objects are similar if they are related to similar objects?.",
        "Since SimRank has a recursive structure, the base cases play an important role.",
        "Let us denote the SimRank similarity between objects ?",
        "and ?",
        "by s(?, ?).",
        "It is defined as 1 if ?",
        "= ?, otherwise it is given by:",
        "where C ?",
        "(0, 1) is a constant decay factor and I(v) is the set consisting of in-neighbours of node v, whose individual members are referred to as Ij(v),"
      ]
    },
    {
      "heading": "3.1 Solution and its Properties",
      "text": [
        "(Jeh and Widom, 2002) proved that a solution s(?, ?)",
        "to the SimRank equations always exists and is unique.",
        "For a graphG(V,E), the solution is reached by iteration to a fixed-point.",
        "For each iteration k, we keep |V |2 entries Sk(?, ?",
        "), where Sk(?, ?)",
        "is the estimate of similarity between ?",
        "and ?",
        "at the kth iteration.",
        "We start with S0(?, ?)",
        "which is 1 for singleton nodes like (x, x), 0 otherwise.",
        "We successively compute Sk+1(?, ?)",
        "based on Sk(?, ?)",
        "using equation 1.",
        "Regarding the convergence of the above computation process, (Lizorkin et al., 2010) proved that the difference between the SimRank theoretical scores",
        "and iterative similarity scores decreases exponentially in the number of iterations and uniformly for every pair of nodes i.e.",
        "s(?, ?)?",
        "Sk(?, ?)",
        "?",
        "Ck+1 ?",
        "?, ?",
        "?",
        "V ; k = 0, 1, 2 .",
        ".",
        ".",
        "(2)"
      ]
    },
    {
      "heading": "3.2 Personalizing SimRank",
      "text": [
        "In many scenarios we do not have complete information about the objects and thus have similarities for only some pairs of objects.",
        "These similarities may be independently learnt and may not directly conform with the underlying graph.",
        "In such situations, we would like to get a more complete and consistent similarity metric between objects while simultaneously using the existing information.",
        "For this we propose a personalized framework for SimRank where we bias the SimRank by changing the initialization.",
        "If we know similarities of some pairs, we fix them in our set of equations and let the rest of the values be automatically learnt by the system.",
        "Let us call the map of node pairs to their similarity values as InitStore.",
        "It also contains all the singleton nodes like (x, x) which have values equal to 1.",
        "For other node pairs, the system of equations is the same as equation 1.",
        "In the personalized framework, we have no constraints on the initialization as long as all values initialized are in the range [0, C]."
      ]
    },
    {
      "heading": "3.3 Learning Synset Similarity using SimRank",
      "text": [
        "The Personalized SimRank framework requires an underlying graph G(V,E), where V is the set of objects to be clustered and E is the set of semantic links connecting these objects and an InitStore containing the similarity values over some pairs from V ?",
        "V learnt or known otherwise.",
        "Note that the values in the InitStore have an upper bound of C. For learning synset similarity, V is the set of synsets to be clustered and E is the set of WordNet relations connecting these synsets.",
        "We use the Hypernymy, Hyponymy, Meronymy and Holonymy relations of WordNet as the semantic links.",
        "The method for seeding the InitStore is described in section 4 and can be summed up as follows: ?",
        "We train the SVMs from synset-merging data from OntoNotes (Hovy et al., 2006) to predict the similarity values of all the synset pairs which share at least one word.",
        "?",
        "We estimate the posterior probabilities from the SVM predictions by approximating the posterior by a sigmoid function, using the method discussed in (Lin et al., 2003).",
        "?",
        "We scale the posterior probabilities obtained to range between [0, C] by linear scaling, where C is the SimRank decay parameter."
      ]
    },
    {
      "heading": "4 Seeding SimRank with supervision 4.1 Outline",
      "text": [
        "We learn semantic similarity between different senses of a word using supervision, which allows us to intelligently combine and weigh the different features and thus give us an insight into how humans relate word senses.",
        "We obtain pairs of synsets which human-annotators have labeled as ?merged?",
        "or ?not merged?",
        "and describe each pair as a feature vector.",
        "We learn a synset similarity measure by using an SVM on this extracted dataset, where positive examples are the pairs which were merged and negative examples are the ones which were not merged by the annotators.",
        "We then calculate the posterior probability using the classifier score which is used as an estimate of the similarity between synsets constituting the pair.",
        "4.2 Gold standard sense clustering dataset Since our methodology depends upon the availability of labelled judgements of synset relatedness, a dataset with a high Inter-Annotator agreement is required.",
        "We use the manually labelled mappings from the Omega ontology2 (Philpot et al., 2005) to the WordNet senses, provided by the OntoNotes project (Hovy et al., 2006).",
        "The OntoNotes dataset creation involved a rigorous iterative annotation process producing a coarse sense inventory which guarantees at least 90% Inter-Tagger agreement on the sense-tagging of the sample sentences used in the annotation process.",
        "Thus we expect the quality of the final clustering of senses and the derived labelled judgements to be reasonably high.",
        "We use OntoNotes Release 3.0 3 for extracting WordNet sense clusters.4.",
        "The dataset consists of senses for selected words in sense files.",
        "The senses in OntoNotes are mapped to WordNet senses, if a good mapping between senses exists.",
        "The steps involved in extraction are as follows:",
        "1.",
        "OntoNotes has mappings to 4 WordNet versions: 1.7, 2.0, 2.1 and 3.0.",
        "We mapped all the senses5 to WordNet 3.0.",
        "2.",
        "Validating clusters on WN3.0: ?",
        "We removed the sense files which did not contain all the senses of the word i.e. the clustering was not complete.",
        "?",
        "We removed the sense files in which the clusters had a clash i.e. one sense belonged to multiple clusters.",
        "3.",
        "We removed instances that were present in both",
        "positive and negative examples.",
        "This situation arises because the annotators were working with word senses and there were inconsistent sense clusters."
      ]
    },
    {
      "heading": "4.3 Feature Engineering",
      "text": [
        "In this section, we describe the feature space construction.",
        "We derive features from the structure of WordNet and other available lexical resources.",
        "Our features can be broadly categorized into two parts: derived from WordNet and derived from other corpora.",
        "Many of the listed features are motivated by (Snow et al., 2007) and (Mihalcea and Moldovan, 2001).",
        "Other synset and sense based features include number of lemmas common in two synsets, SenseC-ount: maximum polysemy degree among the lemmas shared by the synsets, SenseNum: number of lemmas having maximum polysemy degree among the lemmas shared by the synsets, whether two synsets have the same lexicographer file, number of common hypernyms, autohyponymy: whether the two synsets have a hyponym-hypernym relation between them and merging heuristics by (Mihalcea and Moldovan, 2001).7",
        "?",
        "eXtended WordNet Domains Project (Gonza?lez et al., 2012) provides us the score of a synset with respect to 169 hierarchically organized domain-labels(excluding factotum label).",
        "We obtain a representation of a synset in the domain label space and use cosine similarity, L1 distance and L2 distance computed over the weight representations of the synsets as features.",
        "?",
        "BabelNet (Navigli and Ponzetto, 2012) provides us with the translation of noun word senses in 6 languages namely: English, German, Spanish, Catalan, Italian and French and the mapping of noun synsets to DBpedia8 entries.",
        "For features we use counts of common",
        "lemmas in all 6 languages and count of common DBpedia entries.",
        "?",
        "SentiWordNet (Baccianella et al., 2010) provides us with a mapping from a synset to a triad of three weights.",
        "The weights correspond to the score given to a synset based on its objectivity and subjectivity(positive and negative).",
        "We use cosine similarity, L1 distance and L2 distance of the weight representations of the synsets as features.",
        "?",
        "We use the sense clusterings produced by mapping WordNet senses to OED senses by the organizers of the coarse-grained AW task in SemEval-20079 (Navigli et al., 2007).",
        "For each pair of synsets, we check if there are senses in the synsets that belong to the same cluster in the OED mapping."
      ]
    },
    {
      "heading": "4.4 Classifier and Training",
      "text": [
        "We train SVMs using the features above on the synset pairs extracted from OntoNotes, where every synset pair is given either a ?merged?",
        "or ?not-merged?",
        "label.",
        "Because of the skewed class distribution in the dataset, we randomly generated balanced datasets (equal number of positive and negative instances) and then divided them in a ratio of 7:3 for training and testing respectively.",
        "We repeated the process multiple number of times and report the average.",
        "To train the SVMs we used an implementation by (Joachims, 1998), whose java access is provided by JNI-SVMLight 10 library.",
        "For all experiments reported, we use the linear kernel with the default parameters provided by the library.",
        "11 We scale the ranges of all the features to a common range [-1,1].",
        "The main advantage offered by scaling is that it prevents domination of attributes with smaller numeric ranges by those with greater numeric ranges.",
        "It also avoids numerical difficulties like overflow errors caused by large attribute values.",
        "Note that both training and testing data should be scaled with the same parameters.",
        "results were obtained with the linear kernel(Bhagwani, 2013)"
      ]
    },
    {
      "heading": "4.5 Estimating Posterior Probabilities from SVM Scores",
      "text": [
        "For seeding SimRank, we need an estimate of the posterior probability Pr(y = +1|x) instead of the class label.",
        "(Platt, 1999) proposed approximating the posterior by a sigmoid function",
        "We use the method described in (Lin et al., 2003), as it avoids numerical difficulties faced by (Platt, 1999)."
      ]
    },
    {
      "heading": "5 Coarsening WordNet",
      "text": [
        "We construct an undirected graph G(V,E) where the vertex set V contains the synsets of WordNet and edge set E comprises of edges obtained by thresh-olding the similarity metric learnt using the personalized SimRank model (see section 3.2).",
        "On varying the threshold, we obtain different graphs which differ in the number of edges.",
        "On these graphs, we find connected components12, which gives us a partition over synsets.",
        "All the senses of a word occurring in the same component are grouped as a single coarse sense.",
        "We call our approach Connected Components Clustering(CCC).",
        "For lower thresholds, we obtain denser graphs and thus fewer connected components.",
        "This small number of components translates into more coarser senses.",
        "Therefore, using this threshold as a parameter of the system, we can control the granularity of the coarse senses produced."
      ]
    },
    {
      "heading": "6 Experimental Setup and Evaluation",
      "text": []
    },
    {
      "heading": "6.1 Feature Analysis",
      "text": [
        "We analyze the feature space used for SVMs in two ways.",
        "We evaluate Information Gain(IG) and Gain Ratio(GR) functions over the features and do a feature ablation study.",
        "The former tries to capture the discrimination ability of the feature on its own and the latter measures how a feature corroborates with other features in the feature space.",
        "12a connected component of an undirected graph is a sub-graph in which any two vertices are connected to each other by paths, and which is connected to no additional vertices in the supergraph.",
        "We extracted all the features over the complete OntoNotes dataset without any normalization and evaluated them using IG and GR functions.",
        "We report the top 7 features of both the evaluators in table 213.",
        "We divide our features into 6 broad categories and report the average F-Score of both the classes observed by removing that category of features from our feature space.",
        "The SVMs are trained with features normalized using MinMax Normalization for this study.",
        "From tables 2 and 3, we observe that the most significant contributors in SVM performance are WordNet similarity measures and domain cosine similarity.",
        "The former highlights the importance of the ontology structure and the gloss definitions in WordNet.",
        "The latter stresses the fact that approximately matching the domain of two senses is a strong cue about whether the two senses are semantically related enough to be merged.",
        "13Table lists only 11 features as 3 features are common in top 7 features of both the evaluators Other notable observations are the effectiveness of the OED feature and the low Information Gain and Gain Ratio of multilingual features.",
        "We also found that SentiWordNet features were non-discriminatory as most of the noun synsets were described as objective concepts."
      ]
    },
    {
      "heading": "6.2 Estimating Posterior Probabilities from SVM Scores",
      "text": [
        "We learn parameters A and B of the sigmoid that transforms SVM predictions to posterior probabilities (see section 4.5).",
        "Since using the same data set that was used to train the model we want to calibrate will introduce unwanted bias we calibrate on an independently generated random balanced subset from OntoNotes.",
        "The values of A and B obtained are -1.1655 and 0.0222 respectively.",
        "Using these values, the SVM prediction of value 0 gets mapped to 0.4944."
      ]
    },
    {
      "heading": "6.3 Semi-Supervised Similarity Learning",
      "text": [
        "We learn similarity models using the SimRank variant described in section 3.",
        "(Jeh and Widom, 2002) use C = 0.8 and find that 5-6 iterations are enough.",
        "(Lizorkin et al., 2010) suggest lower values of C or more number of iterations.",
        "We vary the values for C between 0.6, 0.7 and 0.8 and we run all systems for 10 iterations to avoid convergence issues."
      ]
    },
    {
      "heading": "6.4 Coarsening WordNet",
      "text": [
        "We assess the effect of automatic synset clustering on the English all-words task at Senseval-3 (Snyder and Palmer, 2004) 14.",
        "The task asked WSD systems to select the apt sense for 2,041 content words in running texts comprising of 351 sentences.",
        "Since the BabelNet project provided multilingual equivalences for only nouns, we focussed on nouns and used the 890 noun instances.",
        "We consider the three best performing WSD systems: GAMBL (Decadt et al., 2004), SenseLearner (Mihalcea and Faruque, 2004) and Koc University (Yuret, 2004) - and the best unsupervised system: IRST-DDD (Strapparava et al., 2004) submitted in the task.",
        "The answer by the system is given full 14This evaluation is similar to the evaluation used by (Navigli, 2006) and (Snow et al., 2007)",
        "ing at the same granularity credit if it belongs to the cluster of the correct answer.",
        "Observe that any clustering will only improve the WSD performance.",
        "Therefore to assess the improvement obtained because of our clustering, we calculate the expected F-Score, the harmonic mean of expected precision and expected recall, for a random clustering at the same granularity and study the improvement over the random clustering.",
        "Let the word to be disambiguated have N senses, each mapped to a unique synset.",
        "Let the clustering of these N synsets on a particular granularity give us k clusters C1, .",
        ".",
        ".",
        "Ck.",
        "The expectation that an incorrectly chosen sense and the actual correct sense would belong to same cluster is",
        "We experiment with C = 0.6, 0.7 and 0.8.",
        "The SVM probability boundaries when scaled to [0, C] for these values are 0.30, 0.35 and 0.40.",
        "To find the threshold giving the best improvement against the random clustering baseline, we use the search space [C ?",
        "0.35, C].",
        "The performance of the systems at these thresholds for different values of C is reported in table 4.",
        "Commenting theoretically about the impact of C on the performance is tough as by changing C we are changing all the |V |2 simultaneous equations to be solved.",
        "Empirically, we observe that across all systems improvements over the baseline keep decreasing as C increases.",
        "This might be due to the slow convergence of SimRank for higher values of C. Figure 1 shows that by varying thresholds the improvement of the Connected Components Clustering over the random clustering baseline at the same granularity first increases and then decreases.",
        "This behaviour is shared by both supervised and unsupervised systems.",
        "Similar figures are obtained for other values of C (0.7 and 0.8), but are omitted because of lack of space.",
        "Across supervised and unsupervised systems, we observe higher improvements for unsupervised systems.",
        "This could be because the unsupervised system was underperforming compared to the supervised systems in the fine grained WSD task setting."
      ]
    },
    {
      "heading": "7 Conclusions and Future Work",
      "text": [
        "We presented a model for learning synset similarity utilizing the taxonomy information and information learnt from manually obtained sense clustering.",
        "The framework obtained is generic and can be applied to other parts of speech as well.",
        "For coarsening senses, we used one of the simplest approaches to cluster senses but the generic nature of the similarity gives us the flexibility to use other clustering algorithms",
        "vised System in Senseval-3 using Connected Component Clustering Vs Random Clustering at the same granularity with C = 0.6 for experimentation.",
        "We show that the clustering obtained by partitioning synsets in connected components gives us a maximum improvement of 5.78% on supervised systems and 7.18% on an unsupervised system.",
        "This encourages us to study graph based similarity learning methods further as they allow us to employ available wide-coverage knowledge bases.",
        "We use the WordNet relations Hypernymy, Hyponymy, Meronymy and Holonymy without any differentiation.",
        "If we can grade the weights of the relations based on their relative importance we can expect an improvement in the system.",
        "These weights can be obtained by annotator feedback from cognitive experiments or in a task based setting.",
        "In addition to the basic WordNet relations, we can also enrich our relation set using the Princeton WordNet Gloss Corpus15, in which all the WordNet glosses have been sense disambiguated.",
        "Any synset occur-ing in the gloss of a synset is directly related to that synset via the gloss relation.",
        "This relation helps make the WordNet graph denser and richer by capturing the notion of semantic relatedness, rather than just the notion of semantic similarity captured by the basic WordNet relations."
      ]
    },
    {
      "heading": "Acknowledgments",
      "text": [
        "The authors would like to thank the anonymous reviewers for their valuable comments and suggestions to improve the quality of the paper."
      ]
    }
  ]
}
