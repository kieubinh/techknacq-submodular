{
  "info": {
    "authors": [
      "Thorsten Brants"
    ],
    "book": "Applied Natural Language Processing Conference and Meeting of the North American Association for Computational Linguistics",
    "id": "acl-A00-1031",
    "title": "TnT - A Statistical Part-Of-Speech Tagger",
    "url": "https://aclweb.org/anthology/A00-1031",
    "year": 2000
  },
  "references": [
    "acl-A92-1018",
    "acl-A97-1014",
    "acl-J93-2004",
    "acl-P98-1081",
    "acl-W96-0102",
    "acl-W96-0213"
  ],
  "sections": [
    {
      "text": [
        "reliable assignments are much higher than for unreliable assignments.",
        "This distinction is, e.g., useful for annotation projects during the cleaning process, or during pre-processing, so the tagger can emit multiple tags if the best tag is classified as unreliable."
      ]
    },
    {
      "heading": "3.2 Tagging the Penn Treebank",
      "text": [
        "We use the Wall Street Journal as contained in the Penn Treebank for our experiments.",
        "The annotation consists of four parts: 1) a context-free structure augmented with traces to mark movement and discontinuous constituents, 2) phrasal categories that are annotated as node labels, 3) a small set of grammatical functions that are annotated as extensions to the node labels, and 4) part-of-speech tags (Marcus et al., 1993).",
        "This evaluation only uses the part-of-speech annotation.",
        "The Wall Street Journal part of the Penn Treebank consists of approx. 50,000 sentences (1.2 million tokens).",
        "Tagging accuracies for the Penn Treebank are shown in table 5.",
        "Figure 6 shows the learning curve of the tagger, i.e., the accuracy depending on the amount of training data.",
        "Training length is the number of tokens used for training.",
        "Each training length was tested ten times.",
        "Training and test sets were disjoint, results are averaged.",
        "The training length is given on a logarithmic scale.",
        "As for the NEGRA corpus, tagging accuracy is very high for known tokens even with small amounts of training data.",
        "We exploit the fact that the tagger not only determines tags, but also assigns probabilities.",
        "Figure 7 shows the accuracy when separating assignments with quotients larger and smaller than the threshold (hence reliable and unreliable assignments).",
        "Again, we find that accuracies for reliable assignments are much higher than for unreliable assignments."
      ]
    },
    {
      "heading": "3.3 Summary of Part-of-Speech Tagging Results",
      "text": [
        "Average part-of-speech tagging accuracy is between 96% and 97%, depending on language and tagset, which is at least on a par with state-of-the-art results found in the literature, possibly better.",
        "For the Penn Treebank, (Ratnaparkhi, 1996) reports an accuracy of 96.6% using the Maximum Entropy approach, our much simpler and therefore faster HMM approach delivers 96.7%.",
        "This comparison needs to be re-examined, since we use a tenfold crossvalidation and averaging of results while Ratnaparkhi only makes one test run.",
        "The accuracy for known tokens is significantly higher than for unknown tokens.",
        "For the German newspaper data, results are 8.7% better when the word was seen before and therefore is in the lexicon, than when it was not seen before (97.7% vs. 89.0%).",
        "Accuracy for known tokens is high even with very small amounts of training data.",
        "As few as 1000 tokens are sufficient to achieve 95%-96% accuracy for them.",
        "It is important for the tagger to have seen a word at least once during training.",
        "Stochastic taggers assign probabilities to tags.",
        "We exploit the probabilities to determine reliability of assignments.",
        "For a subset that is determined during processing by the tagger we achieve accuracy rates of over 99%.",
        "The accuracy of the complement set is much lower.",
        "This information can, e.g., be exploited in an annotation project to give an additional treatment to the unreliable assignments, or to pass selected ambiguities to a subsequent processing step."
      ]
    },
    {
      "heading": "4 Conclusion",
      "text": [
        "We have shown that a tagger based on Markov models yields state-of-the-art results, despite contrary claims found in the literature.",
        "For example, the Markov model tagger used in the comparison of (van Halteren et al., 1998) yielded worse results than all other taggers.",
        "In our opinion, a reason for the wrong claim is that the basic algorithms leave several decisions to the implementor.",
        "The rather large amount of freedom was not handled in detail in previous publications: handling of start and end-of-sequence, the exact smoothing technique, how to determine the weights for context probabilities, details on handling unknown words, and how to determine the weights for unknown words.",
        "Note that the decisions we made yield good results for both the German and the English Corpus.",
        "They do so for several other corpora as well.",
        "The architecture remains applicable to a large variety of languages.",
        "According to current tagger comparisons (van Halteren et al., 1998; Zavrel and Daelemans, 1999), and according to a comparsion of the results presented here with those in (Ratnaparkhi, 1996), the Maximum Entropy framework seems to be the only other approach yielding comparable results to the one presented here.",
        "It is a very interesting future research topic to determine the advantages of either of these approaches, to find the reason for their high accuracies, and to find a good combination of both.",
        "TnT is freely available to universities and related organizations for research purposes (see http://www.coli.uni-sb.derthorstenAnt)."
      ]
    },
    {
      "heading": "Acknowledgements",
      "text": [
        "Many thanks go to Hans Uszkoreit for his support during the development of TnT.",
        "Most of the work on TnT was carried out while the author received a grant of the Deutsche Forschungsge-meinschaft in the Graduiertenkolleg Kognitionswissenschaft Saarbriicken.",
        "Large annotated corpora are the prerequisite for developing and testing part-of-speech taggers, and they enable the generation of high-quality language models.",
        "Therefore, I would",
        "like to thank all the people who took the effort to annotate the Penn Treebank, the Susanne Corpus, the Stuttgarter Referenzkorpus, the NEGRA Corpus, the Verbmobil Corpora, and several others.",
        "And, last but not least, I would like to thank the users of TnT who provided me with bug reports and valuable suggestions for improvements."
      ]
    }
  ]
}
