{
  "info": {
    "authors": [
      "Mark-Jan Nederhof",
      "Giorgio Satta"
    ],
    "book": "Applied Natural Language Processing Conference and Meeting of the North American Association for Computational Linguistics",
    "id": "acl-A00-2036",
    "title": "Left-To-Right Parsing and Bilexical Context-Free Grammars",
    "url": "https://aclweb.org/anthology/A00-2036",
    "year": 2000
  },
  "references": [
    "acl-E87-1037",
    "acl-J97-3004",
    "acl-P94-1017",
    "acl-P96-1023",
    "acl-P96-1032",
    "acl-P97-1003",
    "acl-P98-1035",
    "acl-P99-1059",
    "acl-W97-0301"
  ],
  "sections": [
    {
      "heading": "Abstract",
      "text": [
        "We compare the asymptotic time complexity of left-to-right and bidirectional parsing techniques for bilexical context-free grammars, a grammar formalism that is an abstraction of language models used in several state-of-the-art real-world parsers.",
        "We provide evidence that left-to-right parsing cannot be realised within acceptable time-bounds if the so called correct-prefix property is to be ensured.",
        "Our evidence is based on complexity results for the representation of regular languages."
      ]
    },
    {
      "heading": "1 Introduction",
      "text": [
        "Traditionally, algorithms for natural language parsing process the input string strictly from left to right.",
        "In contrast, several algorithms have been proposed in the literature that process the input in a bidirectional fashion; see (van Noord, 1997; Satta and Stock, 1994) and references therein.",
        "The issue of parsing efficiency for left-to-right vs. bidirectional methods has longly been debated.",
        "On the basis of experimental results, it has been argued that the choice of the most favourable strategy should depend on the grammar at hand.",
        "With respect to grammar formalisms based upon context-free grammars, and when the rules of these formalisms strongly depend on lexical information, (van Noord, 1997) shows that bidirectional strategies are more efficient than left-to-right strategies.",
        "This is because bidirectional strategies are most effective in reducing the parsing search space, by activating as early as possible the maximum number of lexical constraints available in the grammar.",
        "In this paper we present mathematical arguments in support of the above empirically motivated thesis.",
        "We investigate a class of lexicalized grammars that, in their probabilistic versions, have been widely adopted as language models in state-of-the-art real-world parsers.",
        "The size of these grammars usually grows with the square of the size of the working lexicon, and thus can be very large.",
        "In these cases, the primary goal in the design of a parsing algorithm is to achieve asymptotic time performance sublinear in the size of the working grammar and independent of the size of the lexicon.",
        "These desiderata are met by existing bidirectional algorithms (Alshawi, 1996; Eisner, 1997; Eisner and Satta, 1999).",
        "In contrast, we show the following two main results for the asymptotic time performance of left-to-right algorithms satisfying the so called correct-prefix property.",
        "• In case off-line compilation of the working grammar is not allowed, left-to-right parsing cannot be realised within time bounds independent of the size of the lexicon.",
        "• In case polynomial-time, off-line compilation of the working grammar is allowed, left-to-right parsing cannot be realised in polynomial time, and independently of the size of the lexicon, unless a strong conjecture based on complexity results for the representation of regular languages is falsified.",
        "The first result implies that the well known Earley algorithm and related standard parsing techniques that do not require grammar precompilation cannot be directly extended to process the above mentioned grammars (resp.",
        "language models) within an acceptable time bound.",
        "The second result provides evidence that well known parsing techniques as left-corner parsing, requiring polynomial-time preprocessing of the grammar, also cannot be directly extended to process these formalisms within an acceptable time bound.",
        "The grammar formalisms we investigate are based upon context-free grammars and are called bilexical context-free grammars.",
        "Bilexical context-free grammars have been presented in (Eisner and Satta, 1999) as an abstraction of language models that have been adopted in several recent real-world parsers, improving state-of-the-art parsing accuracy (Alshawi, 1996; Eisner, 1996; Charniak, 1997; Collins, 1997).",
        "Our results directly transfer to all these language models.",
        "In a bilexical context-free grammar, possible arguments of a word are always specified along with possible head words for those arguments.",
        "Therefore a bilexical grammar requires the grammar writer to make stipulations about the compatibil",
        "ity of particular pairs of words in particular roles, something that was not necessarily true of general context-free grammars.",
        "The remainder of this paper is organized as follows.",
        "We introduce bilexical context-free grammars in Section 2, and discuss parsing with the correct-prefix property in Section 3.",
        "Our results for parsing with on-line and off-line grammar compilation are presented in Sections 4 and 5, respectively.",
        "To complete the presentation, Appendix A shows that left-to-right parsing in time independent of the size of the lexicon is indeed possible when an off-line compilation of the working grammar is allowed that has an exponential time complexity."
      ]
    },
    {
      "heading": "2 Bilexical context-free grammars",
      "text": [
        "In this section we introduce the grammar formalism we investigate in this paper.",
        "This formalism, originally presented in (Eisner and Satta, 1999), is an abstraction of the language models adopted by several state-of-the-art real-world parsers (see Section 1).",
        "We specify a non-stochastic version of the formalism, noting that probabilities may be attached to the rewrite rules exactly as in stochastic CFG (Gonzales and Thomason, 1978; Wetherell, 1980).",
        "We assume that the reader is familiar with context-free grammars.",
        "Here we follow the notation of (Harrison, 1978; Hoperoft and Ullman, 1979).",
        "A context-free grammar (CFG) is a tuple G = (VN, VT P, S), where VN and VT are finite, disjoint sets of nonterminal and terminal symbols, respectively, S E VN is the start symbol, and P is a finite set of productions having the form A 4 a, where A E VN and a E (VN U VT)*.",
        "A \"derives\" relation, written is associated with a CFG as usual.",
        "We use the reflexive and transitive closure of written and define L(G) accordingly.",
        "The size of a CFG G is defined as 'GI = E(A4a)EP jAal.",
        "If every production in P has the form A BC or A 4 a, for A, B,C E VN, a E VT, then G is said to be in Chomsky Normal Form (CNF).",
        "A CFG G = (VN, VT, 13, S[$]) in CNF is called a bilexical context-free grammar if there exists a set VD, called the set of delexicalized nontermi-nals, such that nonterminals from VN are of the form A[a], consisting of A E VD and a E VT, and every production in P has one of the following two forms:",
        "(i) A[a] B[b] C[c], a E (ii) A[a] 4 a.",
        "A nonterminal A[a] is said to have terminal symbol a as its lexical head.",
        "Note that in a parse tree for G, the lexical head of a nonterminal is always \"inherited\" from some daughter symbol (i.e., from some symbol in the right-hand side of a production).",
        "In the sequel, we also refer to the set VT as the lexicon of the grammar.",
        "A bilexical CFG can encode lexically specific preferences in the form of binary relations on lexical items.",
        "For instance, one might specify P as to contain the production VP[solve] 4 V[solve] NP[puzzles] but not the production VP[eat] 4 V[eat] NP[puzzles].",
        "This will allow derivation of some VP constituents such as \"solve two puzzles\", while forbidding \"eat two puzzles\".",
        "See (Eisner and Satta, 1999) for further discussion.",
        "The cost of this expressiveness is a very large grammar.",
        "Indeed, we have VI = O(IVDI3 • IVTI2 )1 and in practical applications IVT1 >> 11/131 > 1.",
        "Thus, the grammar size is dominated in its growth by the square of the size of the working lexicon.",
        "Even if we conveniently group lexical items with distributional similarities into the same category, in practical applications the resulting grammar might have several thousand productions.",
        "Parsing strategies that cannot work in sublinear time with respect to the size of the lexicon and with respect to the size of the whole input grammar are very inefficient in these cases."
      ]
    },
    {
      "heading": "3 Correct-prefix property",
      "text": [
        "So called left-to-right strategies are standaidly adopted in algorithms for natural language parsing.",
        "Although intuitive, the notion of left-to-right parsing is a concept with no precise mathematical meaning.",
        "Note that in fact, in a pathological way, one could read the input string from left-to-right, storing it into some data structure, and then perform syntactic analysis with a non-left-to-right strategy.",
        "In this paper we focus on a precise definition of left-to-right parsing, known in the literature as correct-prefix property parsing (Sippu and Soisalon-Soininen, 1990).",
        "Several algorithms commonly used in natural language parsing satisfy this property, as for instance Earley's algorithm (Earley, 1970), tabular left-corner and PLR parsing (Nederhof, 1994) and tabular LR parsing (Tomita, 1986).",
        "Let VT be some alphabet.",
        "A generic string over VT is denoted as w = al • • an, with n > 0 and ai E VT (1 < i < n); in case n 0, w equals the empty string e. For integers i and j with 1 < i < j < n, we write w[i, j] to denote string ajai+i • • • ai; if i > j, we define W[i j] = e. Let G (VN, P, S) be a CFG and let w al • • • an with n > 0 be some string over VT. A recognizer for the CFG class is an algorithm R that, on input (G, w), decides whether w E L(G).",
        "We say that R satisfies the correct-prefix property (CPP) if the following condition holds.",
        "Algorithm R processes the input string from left-to-right, \"consuming\" one symbol a, at a time.",
        "If for some i, 0 < i < n, the set of derivations in G having the form S w[1, E (VN U VT)*, is empty, then R rejects and halts, and it does so before consuming symbol at+i, if i < n. In this case, we say that R",
        "has detected an error at position i in w. Note that the above property forces the recognizer to do relevant computation for each terminal symbol that is consumed.",
        "We say that w[1, i] is a correct-prefix for a language L if there exists a string z such that w[1, i]z E L. In the natural language parsing literature, the CPP is sometimes defined with the following condition in place of the above.",
        "If for some i, 0 < i < n, w[1, is not a correct prefix for L(G), then R rejects and halts, and it does so before consuming symbol a,,+1, if i < n. Note that the latter definition asks for a stronger condition, and the two definitions are equivalent only in case the input grammar G is reduced.1 While the above mentioned parsing algorithms satisfy the former definition of CPP, they do not satisfy the latter.",
        "Actually, we are not aware of any practically used parsing algorithm that satisfies the latter definition of CPP.",
        "One needs to distinguish CPP parsing from some well known parsing algorithms in the literature that process symbols in the right-hand sides of each grammar production from left to right, but that do not exhibit any left-to-right dependency between different productions.",
        "In particular, processing of the right-hand side of some production may be initiated at some input position without consultation of productions or parts of productions that may have been found to cover parts of the input to the left of that position.",
        "These algorithms may also consult input symbols from left to right, but the processing that takes place to the right of some position i does not strictly depend on the processing that has taken place to the left of i.",
        "Examples are pure bottom-up methods, such as left-corner parsing without top-down filtering (Wiren, 1987).",
        "Algorithms that do satisfy the CPP make use of some form of top-down prediction.",
        "Top-down prediction can be implemented at parse-time as in the case of Earley's algorithm by means of the \"predictor\" step, or can be precompiled, as in the case of left-corner parsing (Rosenkrantz and Lewis, 1970), by means of the left-corner relation, or as in the case of LR parsers (Sippu and Soisalon-Soininen, 1990), through the closure function used in the construction of LR states."
      ]
    },
    {
      "heading": "4 Recognition without precompilation",
      "text": [
        "In this section we consider recognition algorithms that do not require off-line compilation of the input grammar.",
        "Among algorithms that satisfy the CPP, the most popular example of a recognizer that does 1A context-free grammar G is reduced if every nonterminal of G can be part of at least one derivation that rewrites the start symbol into some string of terminal symbols.",
        "not require grammar precompilation is perhaps Ear-ley's algorithm (Earley, 1970).",
        "We show here that methods in this family cannot be extended to work in time independent of the size of the lexicon, in contrast with bidirectional recognition algorithms.",
        "The result presented below rests on the following, quite obvious, assumption.",
        "There exists a constant c, depending on the underlying computation model, such that in k > 0 elementary computation steps any recognizer can only read up to c• k productions from set P. In what follows, and without any loss of generality, we assume c 1.",
        "Apart from this assumption, no other restriction is imposed on the representation of the input grammar or on the access to the elements of sets VN , VT and P.",
        "Proof.",
        "Assume the existence of a recognizer R satisfying the CPP and running in f (IVD I , IwI) steps or less.",
        "We show how to derive a contradiction.",
        "Let q > 1 be an integer.",
        "Define a bilexical CFG Gq = Pq , Atbip where VI contains q + 2 distinct symbols {b1, , bq+2} and",
        "and where set Pq contains all and only the following productions:",
        "(i) A[bi] A[bi+i]T[bi], 1 < q; (ii) A[bq+i] – ÷ T[bq+2]T[bg-Fi]; (iii) T[b] 4 b, b E",
        "Productions in (i) are called bridging productions.",
        "Note that there are q bridging productions in Gq.",
        "Also, note that VD = IA, T1 does not depend on the choice of q.",
        "Thus, we will simply write VD.",
        "Choose q > max{ f ((VD I , 2), 1}.",
        "On input (Gq, bq+2bq+1), R does not detect any error at position 1, that is after having read the first symbol bq+2 of the input string.",
        "This is because A[b1] bq+2^/ with 7 = T[bq+1]T[bdT[bq_i]- • -T[bil is a valid derivation in G. Since R executes no more than f (IVDI , 2) steps, from our assumption that reading a production takes unit time it follows that there must be an integer k, 1 < k < q, such that bridging production A[bk] – + A[bk±i] T[bk] is not read from Gq.",
        "Construct then a new grammar Gig by replacing in Gq the production A[bk] 4 A[bk+l] T[bk] with",
        "the new production A[bk) T[bk] A[bk+i], leaving everything else unchanged.",
        "It follows that, on input (Gig,bq+2N+1), R behaves exactly as before and does not detect any error at position 1.",
        "But this is",
        "a contradiction, since there is no derivation in Gig of the form A[bi] bq+2-y, y E (VN U VT)*, as can be easily verified.",
        "■ We can use the above result in the comparison of left-to-right and bidirectional recognizers.",
        "The recognition of bilexical context-free languages can be carried out by existing bidirectional algorithms in time independent of the size of the lexicon and without any precompilation of the input bilexical grammar.",
        "For instance, the algorithms presented in (Eisner and Satta, 1999) allow recognition in time 0(1VD131w14).2 Theorem 1 states that this time bound cannot be met if we require the CPP and if the input grammar is not precompiled.",
        "In the next section, we will consider the possibility that the input grammar is in a precompiled form."
      ]
    },
    {
      "heading": "5 Recognition with precompilation",
      "text": [
        "In this section we consider recognition algorithms that satisfy the CPP and allow off-line, polynomial-time compilation of the working grammar.",
        "We focus on a class of bilexical context-free grammars where recognition requires the stacking of a number of unresolved lexical dependencies that is proportional to the length of the input string.",
        "We provide evidence that the above class of recognizers perform much less efficiently for these grammars than existing bidirectional recognizers.",
        "We assume that the reader is familiar with the notions of deterministic and nondeterministic finite automata.",
        "We follow here the notation in (Hoperoft and Tillman, 1979).",
        "A nondeterministic finite automaton (FA) is a tuple M (Q,E,O,q0,F), where Q and E are finite, disjoint sets of state and alphabet symbols, respectively, qo E Q and F C Q are the initial state and the set of final states, respectively, and is a total function mapping Q x E to 2Q, the power-set of Q.",
        "Function 6. represents the transitions of the automaton.",
        "Given a string w = al • • • an, n > 0, an accepting computation in M for w is a sequence q0, al, , a2, q2, , an, q„ such that qi E az) for 1 < i < n, and q,„ E F. The language L(M) is the set of all strings in E* that admit at least one accepting computation in M. The size of M is defined as 1M1 = EqEQ,a€E15(q,a)1.",
        "The automaton M is deterministic if, for every q E Q and a E E, we have 1(5(q, a)1 = 1.",
        "We call quasi-determinizer any algorithm A that satisfies the following two conditions:",
        "1.",
        "A takes as input a nondeterministic FA M = (Q, E, go, F) and produces as output a device DM that, when given a string w as input, decides whether w E L(M); and",
        "2. there exists a polynomial pA such that every DM runs in an amount of time bounded by PA Owl ).",
        "We remark that, given a nondeterministic FA M specified as above, known algorithms allow simulation of M on an input string w in time 0(IMIlwl) (see for instance (Aho et al., 1974, Thm.",
        "9.5) or (Sippu and Soisalon-Soininen, 1988, Thm.",
        "3.38)).",
        "In contrast, a quasi-determinizer produces a device that simulates M in an amount of time independent of the size of M itself.",
        "A standard example of a quasi-determinizer is the so called power-set construction, used to convert a nondeterministic FA into a language-equivalent deterministic FA (see for instance (Hoperoft and Ullman, 1979, Thm.",
        "2.1) or (Sippu and Soisalon-Soininen, 1988, Thm.",
        "3.30)).",
        "In fact, there exist constants c and c' such that any deterministic FA can be simulated on input string w in an amount of time bounded by c Iwl + c'.",
        "This requires function (5 to be stored as a IQ!",
        "x 1E1, 2-dimensional array with values in Q.",
        "This is a standard representation for automata-like structures; see (Gusfield, 1997, Sect.",
        "6.5) for discussion.",
        "We now pose the question of the time efficiency of a quasi-determinizer, and consider the amount of time needed in the construction of DM.",
        "In (Meyer and Fisher, 1971; Stearns and Hunt, 1981) it is shown that there exist (infinitely many) nondeterministic FAs with state set Q, such that any language-equivalent deterministic FA must have at least 21Q1 states.",
        "This means that the power-set construction cannot work in polynomial time in the size of the input FA.",
        "Despite of much effort, no algorithm has been found, up to the authors' knowledge, that can simulate a nondeterministic FA on an input string w in linear time in 1w1 and independently of IM1, if only polynomial-time precompilation of M is allowed.",
        "Even in case we relax the linear-time restriction and consider recognition of w in polynomial time, for some fixed polynomial, it seems unlikely that the problem can be solved if only polynomial-time precompilation of M is allowed.",
        "Furthermore, if we consider precompilation of nondeterministic FAs into \"partially determinized\" FAs that would allow recognition in polynomial (or even exponential) time in lwl, it seems unlikely that the analysis required for this precompilation could consider less than exponentially many combinations of states that may be active at the same time for the original nondeterministic FA.",
        "Finally, although more powerful formalisms have been shown to represent some regular languages much more succinctly than FAs (Meyer and Fisher, 1971), while allowing polynomial-time parsing, it seem unlikely that this could hold for regular languages in general.",
        "Conjecture There is no quasi-determinizer that works in polynomial time in the size of the input automaton.",
        "Before turning to our main result, we need to develop some additional machinery.",
        "Let M = (Q, E, 6, go, F) be a nondeterministic FA and let w al an E L(M), where n > 0.",
        "Let go, al, , an, qn be an accepting computation for w in M, and choose some symbol $ E. We can now encode the accepting computation as ($, )(ai qi) • • • (an, qn) where we pair alphabet symbols to states, prepend-ing $ to make up for the difference in the number of alphabet symbols and states.",
        "We now provide a construction that associates M with a bilexical CFG GM.",
        "Strings in L(GM) are obtained by pairing strings in L(M) with encodings of their accepting computations (see below for an example).",
        "(i) VN = {T[al o E VT} U {C[a),Cla] a E A}; (ii) Vr =AUEU{#}; (iii) P contains all and only the following productions: (a) for each a E VT, nil 4 a; (b) for each (a,q),(at,q1) E A such that q' E 6(q, a') , CRa, q)] – + CT& , q1)1 T[(a , q)]; (c) for each (a, g) E A, C' [(a, g)1 4 T[a] CRa, q)1; (d) for each (a, q) E A such that q E F, CRa, q)] T[#1 T [(a, q)].",
        "We give an example of the above construction.",
        "Consider an automaton M and a string w = aia2a3 such that w E L(M).",
        "Let ($, go)(al, g1)(a2, q2)(a3, g3) be the encoding of an accepting computation in M for w. Then the string ai a2a3#(a3, g3)(a2 , q2)(ai , )($, go) belongs to L(GM).",
        "The tree depicted in Figure 1 represents a derivation in GM of such a string.",
        "The following fact will be used below.",
        "Lemma 1 For each w E E*, w# is a correct-prefix for L(GM) if and only if w E L(M).",
        "Outline of the proof.",
        "We claim the following fact.",
        "For each k > 0, al, a2, , ak E E and go, qi, , qk E Q we have",
        "The claim can be proved by induction on k, using productions (a) to (c) from Definition 1.",
        "Let R denote the reverse operator on strings.3 From the above claim and using production (d) from Definition 1, one can easily show that L(GM) = {w#u i w E L(M), uR encodes an accepting computation for w}.",
        "The lemma directly follows from this relation.",
        "■ We can now provide the main result of this section.",
        "To this end, we refine the definition of recognizer presented in Section 3.",
        "A recognizer for the CFG class is an algorithm R that has random access to some data structure C(G) obtained by means of some off-line precompilation of a CFG G. On input w, which is a string on the terminal symbols of G, R decides whether w E L(G).",
        "The definition of the CPP extends in the obvious way to recognizers working with precompiled grammars.",
        "Theorem 2 Let p be any polynomial in two variables.",
        "If the conjecture about quasi-determinizers holds true, then no recognizer exists that",
        "(i) has random access to data structure C(G) precompiled from a bilexical CFG G in polynomial time in IG1, (ii) runs in an amount of time bounded by",
        "PaVD1 '14, where VD is the set of delexicalized nonterminals of G and w is the input string, and (iii) satisfies the CPP.",
        "Proof.",
        "Assume there exists a recognizer R that satisfies conditions (i) to (iii) in the statement of the theorem.",
        "We show how this entails that the conjecture about quasi-determinizers is false.",
        "We use algorithm R to specify a quasi-determinizer A.",
        "Given a nondeterministic FA M, A goes through the following steps.",
        "1.",
        "A constructs grammar GM as in Definition 1.",
        "2.",
        "A precompiles GM as required by R, producing data structure C(GM).",
        "3.",
        "A returns a device DM specified as follows.",
        "Given a string w as input, DM runs R on string w#.",
        "If R detects an error at any position i, 0 < i < 1w#1, then DM rejects and halts, otherwise DM accepts and halts.",
        "From Lemma 1 we have that DM accepts w if and only if w E L(M).",
        "Since R runs in time Pa3/431,10 and since GM has a set of delexicalized nonterminals independent of M, we have that there exists a polynomial pA such that every DM works in an amount of time bounded by pA(IwI).",
        "We therefore conclude that A is a quasi-determinizer.",
        "It remains to be shown that A works in polynomial time in WI.",
        "Step 1 can be carried out in time 0(IMI).",
        "The compilation at Step 2 takes polynomial time in 'Gm], following our hypotheses on R, and hence polynomial time in (MI, since IGmi = O(IMi).",
        "Finally, the construction of DM at Step 3 can easily be carried out in time 0(I MI) as well.",
        "■ In addition to Theorem 1, Theorem 2 states that, even in case the input grammar is compiled off-line and in polynomial time, we cannot perform CPP recognition for bilexical context-free grammars in time polynomial in the grammar and the input string but independent of the lexicon size.",
        "This is true with at least the same evidence that supports the conjecture on quasi-determinizers.",
        "Again, this should be contrasted with the time performance of existing bidirectional algorithms, allowing recognition for bilexical context-free grammars in time 0(IVD13 (w().",
        "In order to complete our investigation of the above problem, in Appendix A we show that, when we drop the polynomial-time restriction on the grammar precompilation, it is indeed possible to get rid of any WTI factor from the running time of the recognizer."
      ]
    },
    {
      "heading": "6 Conclusion",
      "text": [
        "Empirical results presented in the literature show that bidirectional parsing strategies can be more time efficient in cases of grammar formalisms whose rules are specialized for one or more lexical items.",
        "In this paper we have provided an original mathematical argument in favour of this thesis.",
        "Our results hold for bilexical context-free grammars and directly transfer to several language models that can be seen as stochastic versions of this formalism (see Section 1).",
        "We perceive that these results can be extended to other language models that properly embed bilexical context-free grammars, as for instance the more general history-based models used in (Rat-naparkhi, 1997) and (Chelba and Jelinek, 1998).",
        "We leave this for future work."
      ]
    },
    {
      "heading": "Acknowledgements",
      "text": [
        "We would like to thank Jason Eisner and Mehryar Mohri for fruitful discussions.",
        "The first author is supported by the German Federal Ministry of Education, Science, Research and Technology (BMBF) in the framework of the VERBMOBIL Project under Grant 01 IV 701 VO, and was employed at AT&T Shannon Laboratory during a part of the period this paper was written.",
        "The second author is supported by MURST under project PRIN: Biolnformatica e Ricerca Genomica and by University of Padua, under project Sviluppo di Sistemi ad Addestramento Automatico per l'Analisi del Linguaggio Naturale."
      ]
    }
  ]
}
