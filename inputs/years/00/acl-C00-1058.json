{
  "info": {
    "authors": [
      "Kyo Kageura",
      "Keita Tsuji",
      "Akiko Aizawa"
    ],
    "book": "International Conference on Computational Linguistics",
    "id": "acl-C00-1058",
    "title": "Automatic Thesaurus Generation Through Multiple Filtering",
    "url": "https://aclweb.org/anthology/C00-1058",
    "year": 2000
  },
  "references": [
    "acl-A94-1006",
    "acl-C94-1084",
    "acl-C94-1100",
    "acl-C96-2130",
    "acl-E93-1015",
    "acl-H91-1026",
    "acl-J93-1003",
    "acl-J96-1001",
    "acl-P93-1003",
    "acl-P95-1032"
  ],
  "sections": [
    {
      "heading": "Abstract",
      "text": [
        "In this paper, we propose a method of generating bilingual keyword clusters or thesauri from parallel or comparable bilingual corpora.",
        "The method combines morphological and lexical processing, bilingual word alignment, and graph-theoretic cluster generation.",
        "An experiment shows that the method is promising."
      ]
    },
    {
      "heading": "1 Introduction",
      "text": [
        "In this paper, we propose a method of automatic bilingual thesaurus generation by a combination of methods or multiple filtering.",
        "The procedure consists of three modules: (i) a morphological and lexical processing module, (ii) a translation pair extraction module, and (iii) a cluster generation module.",
        "The method takes parallel or comparable corpora as input, and produces as output bilingual keyword clusters with a reasonable computational cost.",
        "Our aim is to construct domain-oriented bilingual thesauri, which are much in need both for cross-language IR and for technical translators.",
        "We assume domain-dependent parallel or comparable corpora as a source of information, which are abundant in case of Japanese and English.",
        "The techniques used in each module are reasonably well developed, including statistical word alignment methods.",
        "However, there remain at least three problems: (i) ambiguity of multiple hapax combinations in an alignment, which cannot be resolved by purely statistical methods, (ii) syntagmatic unit mismatches, especially in such cases as English and Japanese, .and (iii) difficulty in final cleaning-up' .",
        "In this paper, we show that the proper combination of the above modules can be useful especially for resolving the cleaning-up problem and can produce good results in bilingual cluster or thesaurus generation."
      ]
    },
    {
      "heading": "2 Method",
      "text": [
        "The procedure for thesaurus generation consists of the following three main modules.",
        "(1) Morphological and lexical processing module: keyword units for English and Japanese are extracted separately.",
        "(2) Translation pair extraction module: statistical weighting is applied to a corpus which has been through the morphological and lexical processing module.",
        "The aim of this stage is not to determine unique translation pairs, but to restrict translation candidates to a reasonable extent.",
        "(3) Cleaning and cluster generation module: a bilingual keyword graph is constructed on the basis of the pairs extracted at translation pair extraction module, and a graph-theoretic method is applied to the keyword graph, to generate proper keyword clusters by removing erroneous links.",
        "If we want to obtain a clean lexicon, minor translation variations tend to be omitted, while many errors would be included if we want to retain minor variations.",
        "2 The word 'keyword' implies words that are important with respect to documents or domains.",
        "In this paper, we use the word for convenience, roughly in the same sense as \"content-bearing words\".",
        "If necessary, a module of keyword or term weighting (e.g. Prantzi"
      ]
    },
    {
      "heading": "2.1 Morphological & lexical processing",
      "text": [
        "At this stage, basic lexical units or keyword candidates are extracted.",
        "We separately extract minimum or shortest units and maximum or longest complex units as syntagmatic units for keyword candidates.",
        "So two outputs are produced from this module, i.e. a bilingual keyword corpora of minimum units and another of maximum units.",
        "The processing proceeds as follows:"
      ]
    },
    {
      "heading": "(a) Morphological analysis",
      "text": [
        "First, the corpus is morphologically analysed and POS-tagged.",
        "Currently, JUMAN3.5 (Kurohashi Nagao 1998) is used for Japanese and LT_POS/LT_CHUNK (Mikheev 1996) is used for English."
      ]
    },
    {
      "heading": "(b1) Extraction of minimum units",
      "text": [
        "Minimum units in English are simply defined as non-functional simple words extracted from the output of LT_POS.",
        "Minimum meaningful units in Japanese are defined as:",
        "where C_ indicates that the unit should consist of either Chinese characters or Katakana3 ."
      ]
    },
    {
      "heading": "(b2) Extraction of maximum units",
      "text": [
        "Maximum complex units for English are the units extracted by LT_CHUNK, with some ad-hoc modifications.",
        "Maximum complex units for Japanese are defined by the following basic pattern,",
        "where C means that the unit should begin with either Chinese character or Katakana.",
        "The pattern remains deliberately coarse, to absorb errors by JUMAN.",
        "Coarse patterns with simple character type restrictions produce better results than grammatically well-defined syntagmatic patterns.",
        "A separate stop word list for affixes is also prepared together with an exceptional treatment routine, to make the Japanese units better correspond to English units4 .",
        "After these processes, two corpora, one consisting of minimum units and the other of max",
        "imuna units, are created.",
        "Intermediate constituent units are not extracted, because their interlingual unit correspondence is less reliable.",
        "Also, many important intermediate units of longer complex units appear themselves as an independent complex unit in a large domain-specific corpus, and, even if they do not, intermediate units can be extracted on the basis of minimum and maximum translation pairs if necessary."
      ]
    },
    {
      "heading": "2.2 Extraction of translation candidates",
      "text": [
        "The module for extracting translation candidate pairs consists of statistical weighting and postprocessing.",
        "These are applied to the data of minimum units and maximum units separately.",
        "After that, the two data are merged to make input for the cluster generation module.",
        "(a) Statistical weighting",
        "Many methods of extracting lexical translation pairs have been proposed (Daille, Gaussier Lange 1994; Eijk 1993; Fung 1995; Gale & Church 1991; Hiemstra 1996; Hull 1998; Ku-piec 1993; Melamed 1996; Smadja, McKeown & Hatzivassiloglou 1996).",
        "Though it is difficult to evaluate the performance of existing methods as they use different corpora for evaluations , the performance does not seem to be radically different.",
        "We adopted log-likelihood ratio (Dan-fling 1993), which gave the best performance among crude non-iterative methods in our test experiments6 ."
      ]
    },
    {
      "heading": "(b) Postprocessing filter",
      "text": [
        "As the output of statistical weighting is simply a weighted list of all English and Japanese co-occurring pairs, it is necessary to restrict translation candidates so that they can be effectively used in the graph-theoretic cluster generation module.",
        "In addition to restricting possible translation pairs, it is necessary to determine unique translation pairs for hapax legomena.",
        "We use both macro and micro-filtering heuristics to restrict translation candidates.",
        "5 A common testbed exists for French-English alignment (Veronis 1996-99) but not for Japanese-English.",
        "6 At the time of writing this paper, we have finished a preliminary comparative experiments of various methods, among which the method proposed by Melamed (1996) gave by far the best result.",
        "We are thus planning to replace this module with the method proposed by Melamed (1996).",
        "Two macro heuristics, applied to the overall list of pairs, are defined, i.e. (i) a proper translation should have a statistical score higher than the threshold Xs, and (ii) a keyword should have maximally Xe translations or Xp x token frequency when the frequency is less than X. Micro heuristics uses the information within each alignment; we assume that a keyword in one language only has one translation within an alignment7 .",
        "Selecting unique pairs in each alignment is achieved by recursively taking a pair with the highest score within an alignment, each time deleting other pairs which have the same English or Japanese elements8 .",
        "After this process, the data of minimum units and maximum units are merged, which constitutes input for the next stage."
      ]
    },
    {
      "heading": "2.3 Graph-theoretic cluster generation",
      "text": [
        "Up to this stage, the cooccurrence information used to extract pairs has the depth of only one.",
        "In order to eliminate erroneous translations, we reorganise the extracted pairs into graph and use multilevel topological information by applying the graph-theoretic method.",
        "For explanation, let us assume that we obtained the data in Table I. from the previous module as an input to this module.",
        "Firstly, the initial keyword graph is constructed, where each node represents an English or Japanese keyword, and a link or edge represents the pairwise relation of corresponding keywords.",
        "We define the capacity or strength of a. link by the frequency of occurrence of the pair in the corpus, i.e. the number of alignments in which the pair occurs9 .",
        "Figure 1 shows the 7 This is not true for longer alignment units such as full texts.",
        "However, this will apply to parallel titles and abstracts which are readily available.",
        "Many lexical alignment methods starting from sentence-level alignments assume this or some variations of this.",
        "8 Many maximum unit pairs in fact have the same score.",
        "We used the arithmetic mean of the constituent minimum units to resolve alignment ambiguity.",
        "9 The score of likelihood ratio is a possible alternative for link capacity, but the result of a preliminary experiment was no better.",
        "In addition, after selecting pairs by threshold, whether a pair constitutes a proper translation or not is not a matter of weight, because threshold setting implies that all pairs above that are regarded as correct.",
        "So we adopt simple frequency as the link capacity.",
        "However, we notice a lack of affinity between the",
        "initial keyword graph made from the data in Table I.",
        "The task now is to detect and VC-Move erroneous links to generate independent graphs or clusters consisting of proper translation pairsl° .",
        "The detection algorithm is based on the simple principle that sets of links, which decompose a connected keyword cluster into disjoint sub-clusters when they are removed from the original cluster, are candidates for improper translations.",
        "In graph theory, such a link set is called an edge cut and the edge cut with the minimal total capacity is called a minimum edge cut.",
        "A minimum edge cut does not necessarily imply a single translation error.",
        "An efficient al-statistical alignment method we used here and the definition of link capacity, which is currently under examination and will he improved by renewing the alignment module.",
        "1° This approach is radically different from statistically oriented word clustering (Deerwester et.",
        "al 1990; Finch 1993; Grefenstette 1994; Schiitze & Pedersen 1997; Strzalkowski 1994); this is why we use the word 'cluster generation' instead of 'clustering'.",
        "gorithm exists for minimum edge cut detection (Nagamochi 1993).",
        "Our procedure first checks links that should not be eliminated, using the conditions: (i) the frequency is no less than N0, (ii) the Japanese and English notations are identical, or (iii) either of the Japanese or English expressions have only one corresponding translation (Figure 2 (a); it is assmned that .AT,, = Nc = 3).",
        "Secondly, core keywords whose frequency is no less than No are checked (Figure 2 (b)).",
        "This is used for the restriction that each cluster should include at least one core keyword.",
        "Lastly, edge cuts with a total capacity of less than NE are detected and removed (Figure 2 (c)).",
        "This procedure is repeated recursively until no further application is possible.",
        "Figure 3 shows the state after these steps are applied."
      ]
    },
    {
      "heading": "3 Experiment",
      "text": []
    },
    {
      "heading": "3.1 Settings and procedures",
      "text": [
        "We applied the method to Japanese and English bilingual parallel corpus consisting of 25534 title pairs in the field of computer science.",
        "Table 2 shows the basic quantitative information after morphological and lexical filtering was applied.",
        "In the pair extraction module, the threshold XS was set to 1011.",
        "The parameter A7c was set to 10 and X p to 0.5.",
        "As a result, 28905 translation candidate pairs were obtained, with 24855 Japanese and 23430 English keywords.",
        "Of these, 20071 pairs occurred only once and 3581 only twice.",
        "The most frequent pair occurred 3196 times in the corpus.",
        "8242 (28.5%) were minimum unit pairs, and 20663 (71.5%) were maximum unit pairs.",
        "Table 3 shows the number of keywords which had N translations.",
        "On average, a Japanese keyword had 1.16 English translations, while an English keyword had 1.23 Japanese translations.",
        "Evaluating recall and precision on the basis of 100 randomly selected title pairs, which consisted of 778 keyword token pairs, the precision tokenwise was 84.06% (654 correct translations) and the recall was 87.08% (654 of 751 correct pairs).",
        "Typewise precision was 81.65% (543 correct of 665 pairs).",
        "The initial keyword graph generated from these 28905 translation candidates consisted of 19527 independent subgraphs, with the largest cluster containing 2701 pairs (i.e. 9.3% of all the pairs).",
        "The cluster generation method wa.s applied with parameters N, 4, N€ = 10 and N13 112 .",
        "As a result, 893 translation pairs were removed, and 20357 bilingual clusters were generated.",
        "The maximum cluster now contained only 64 pairs.",
        "Table 4 shows the number of clusters by size given by number of pairs."
      ]
    },
    {
      "heading": "3.2 Overall evaluation",
      "text": [
        "The result was manually evaluated from two points of view, i.e. consistency of clusters and correctness of link removal\" .",
        "(1) To check the internal consistency, clusters",
        "were classified into three groups by size, and were separately evaluated.",
        "2000 'small' clusters, consisting of only one pair, were randomly sampled and evaluated as 'correct' (c), 'more or less correct' (m) or 'wrong' (w).",
        "400 medium size clusters consisting of 2-9 pairs and all the 74 large clusters consisting of 10 or more pairs were evaluated as 'consistent' (c: consisting only of closely related keywords), 'mostly consistent' (rn: consisting mostly of related keywords), 'hybrid' (lc consisting of two or more different keyword groups: h) or 'bad' (w).",
        "Table 5 shows the result of the evaluation.",
        "The general performance is very good, with more or less 80% of the clusters being meaningful.",
        "17 This is again determined heuristically.",
        "For an examination of the effect of parameters, see Aizawa Kageura (to appear).",
        "13 'r he evaluation was done by the first author.",
        "Currently no cross-checking has been carried out.",
        "For small clusters, the performance was separately evaluated for minimum and maximum unit pairs.",
        "Note that the ratio of maximum unit pairs is comparatively higher in the small cluster than the overall average.",
        "Most pairs evaluated as partially correct, as well as some wrong pairs, suffered from mismatch of the syntagmatic units.",
        "730-0 of the medium sized clusters were 'correct', 'mostly correct' or 'hybrid'.",
        "Among the `mostly correct' and 'hybrid' clusters, 97 (91 and 6 respectively) were mainly caused by the mismatch of the units.",
        "For instance, in the case: { ecAi iyav-c, optimization, optimal, optimisation, optimum, network optimization }, the last English keyword has the excess unit 'network'.",
        "Other 'mostly correct' and 'hybrid' clusters were due to the problem of corpus frequencies.",
        "Among the large clusters, more than half were 'hybrid'I'l.",
        ".",
        "Among the 'mostly correct.'",
        "and 'hybrid' large clusters, only 8 (3+5) were due to unit.",
        "mismatch, while 53 (15+38) were due to quantitative factors.",
        "This shows a striking contrast to the medium sized clusters.",
        "Large hybrid clusters tended to include many common word pairs which occur frequently.",
        "For instance, in the largest cluster, A r I. system' (3196), `114R development' (1097), design' (1073), and q,,7.±12 environment' (890) are included due to indirect associations.",
        "The following are two examples of hybrid clusters, whose hybridness comes front quantitative factors and unit mismatches respectively:",
        "In the first case, the 'overall' group and the `summary' group are mixed up.",
        "In the second case, the mismatch of syntagmatic units is caused by borrowed words.",
        "In fact, many errors caused by the mismatch of syntagmatic units involve borrowed words written in Katakana.",
        "(2) To look at the performance of graph-theoretic cluster generation, we examined the removed pairs from two points of view, i.e. the correctness of link reinoval and the internal consistency of clusters generated by link removal.",
        "For the former, we introduced three categories for evaluation: mismatched pairs correctly removed (c), proper translation pairs wrongly removed (w), and pairs of related meaning removed (p).",
        "The consistency of newly generated clusters were evaluated in the same manner as above.",
        "Table 6 shows the result of evaluation of all the 893 removed pairs.",
        "`c' `p' and 'w' in the top row indicate types of removed links, and 'cc', 'cm' etc.",
        "in the leftmost column indicate internal consistencies of two clusters generated by link removal.",
        "A total of 157 (17.6%) of the removed links were correct links wrongly removed, but among them, 115 links did not produce `bad' clusters.",
        "If we consider them to he tolerable, only 42 removals (4.7%) were fatal errors.",
        "By examining the removed links, we found that the links removed at the higher edge capacity included more wrongly removed pairs.",
        "For instance, among 142 edges removed at capacity 4 (which is the maximum deletable value set by NJ, 41 or 28.9% were wrongly removed correct translations, while among 288 links removed at capacity I, only 15 or 5.2 % were correct translations."
      ]
    },
    {
      "heading": "4 Discussion",
      "text": [
        "From the experiment, we have found some factors that affect performance.",
        "(1) Many errors were produced at the stage of extracting keyword units, by syntagmatic mismatch.",
        "A substantial number of them involved Japanese Katakana keywords.",
        "Therefore, in addition to the.",
        "general refinement of the morphological processing module, the performance will be improved if we use string proximity information to determine syntagmatic units15 (2) We expect that some errors produced by statistical weighting and filtering could be removed by applying stemming and orthographic normalisations, which are not fully exploited in the current implementation.",
        "Looking back from the cluster generation stage, frequently occurring keywords tend to cause problems due to indirect associations.",
        "At the time of writing, we are radically changing the statistical alignment module based on Melame.d (1996) and incorporating iterative alignment anchoring routine so that the method can be applied not only to titles but also to abstracts, etc.",
        "Used in conjunction with string in-oximity and stemming information, we in g lit be able to retain minor variations properly.",
        "(3) At the cluster generation stage, we observed that correct links tend to be wrongly removed for higher capacities of edge cut.",
        "In the current implementation, the parameter values remain the same for all the clusters.",
        "Performance will be improved by introducing a method of dynamically changing the parameter values according to the cluster size and the frequencies of their constituent pairs."
      ]
    },
    {
      "heading": "5 Conclusion",
      "text": [
        "We have proposed a method of constructing bilingual thesauri automatically, front parallel or comparable corpora.",
        "The experiment showed that the performance is fairly good.",
        "We are currently improving the method further, along the lines discussed in the previous section.",
        "Further experiments arc currently being carried out, using the data of narrower domains (e.g. artificial",
        "intelligence) as well as abstracts instead of titles.",
        "At the next stage, we arc planning to evaluate the method from the point of view of performance of generated clusters in practical applications.",
        "We are currently planning to apply the generated clusters to query expansion and user navigation in cross-lingual as well as to on-line dictionary lookup systems used as translation aids."
      ]
    },
    {
      "heading": "Acknowledgement",
      "text": [
        "This research is a part of the research project \"A Study on Ubiquitous Information Systems for Utilization of Highly Distributed Information Resources\", funded by the Japan Society for the Promotion of Science."
      ]
    }
  ]
}
