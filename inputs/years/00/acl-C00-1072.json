{
  "info": {
    "authors": [
      "Chin-Yew Lin",
      "Eduard Hovy"
    ],
    "book": "International Conference on Computational Linguistics",
    "id": "acl-C00-1072",
    "title": "The Automated Acquisition of Topic Signatures for Text Summarization",
    "url": "https://aclweb.org/anthology/C00-1072",
    "year": 2000
  },
  "references": [
    "acl-J90-1003",
    "acl-J93-1003",
    "acl-J97-1003"
  ],
  "sections": [
    {
      "heading": "Abstract",
      "text": [
        "In order to produce a good summary, one has to identify the most relevant portions of a given text.",
        "We describe in this paper a method for automatically training topic signatures sets of related words, with associated weights, organized around head topics and illustrate with signatures we created with 6,194 TREC collection texts over 4 selected topics.",
        "We describe the possible integration of topic signatures with ontologies and its evaluaton on an automated text summarization system."
      ]
    },
    {
      "heading": "1 introduction",
      "text": [
        "This paper describes the automated creation of what we call topic.",
        "NilptatliTCS, constructs that can play a central role in automated text summarization and information retrieval.",
        "Topic signatures can be used to identify the presence of a complex concept--a concept that consists of several related components in fixed relationships.",
        ".1?■-st,frarant- visit, for example, involves at least the concepts menu, cal, pay, and possibly waiter, and Drag oft Boot Festival (in Taiwan) involves the concepts tqh171131.S (a talisman to ward off evil), mole (something- with the power of preventing pestilence and strengthening health), pictures of Ch1.171.9 Koci (a nemesis of evil spirits), eggs standing on end, etc.",
        "Only when_ the ronciTts reoccur is one licensed to infer the complex concept ; cat Or moxri alone, for example, are not sufficient.",
        "At tins time, we do not consider the interrelationships among the concepts.",
        "Since many texts may describe all the components of a complex concept without ever explicitly mentioning the underlying complex concept----a topic – itself, systems that have to identify topic(s), for summarization or information retrieval, require a method of inferring complex concepts from their component words in the text."
      ]
    },
    {
      "heading": "2 Related Work",
      "text": [
        "In late 1970's, Deiong (DeJong, 1982) developed a system called FRUMP (Fast Reading Understanding and Memory Program) to skim newspaper stories and extract the main details.",
        "FRUMP uses a data structure called sketchy script to organize its world knowledge.",
        "Each sketchy script is what FRUMP knows about.",
        "what can occur in particular situations such as demonstrations, earthquakes, labor strikes, and so on.",
        "FRUMP selects a particular sketchy script based on clues to styled events in news articles.",
        "In other words, FRUMP selects all empty template' whose slots will be filled on the fly as FRUMP reads a news article.",
        "A summary is generated based on what has been raptured or filled in the template.",
        "The recent success of information extraction research has encouraged the FRUMP approach.",
        "The SUMMONS (SUMMarizing Online NewS articles) system (McKeown and Radev, 1999) takes template outputs of information extraction systems developed for MUC conference and generating summaries of multiple news articles.",
        "FRUMP and SUMMONS both rely on prior knowledge of their domains.",
        "However, to acquire such prior knowledge is labor-intensive and time-consuming.",
        "For example, the University of Massachusetts CIRCUS sys-turn used in the MUC-3 (SAIL, 1998) terrorism domain required about 1500 person-hours to define extraction patterns' (Filloll, 1996).",
        "In order to make them practical, we need to reduce the knowledge err-gi,w,,ring bottleneck and improve the portability of FRUMP or SUMMONS-like systems.",
        "Since the world contains thousands, or perhaps millions, of complex concepts, it is important to be able to learn sketchy scripts or extraction patterns automatically from corpora ---11C1 existing knowledge base contains nearly enough information.",
        "(Riloff and Lorenzen, 1999) present a system AutoSlog-TS that generates extraction patterns and learns lexical constraints witomatically front predassified text to alleviate the knowledge engineering bottleneck mentioned above_ Although Riloff applied AntoSing-TS \"Ne viewed sicetchy scripts and Leinnhttes as equivalent cDustructs in the sense that they specify high level entities and relationships for specific!",
        "topics.",
        "21n extraction pattern is essentially a case frame contains its trigger word, Enabling conditions, variable slots, and slot constraints.",
        "CIRCUS uses a database of extraction patterns to parse 1.,ext.",
        "(Rilolt, 1996).",
        "to text categorization and information extraction, the concept of relevancy signatures introduced by her is very similar to the topic signatures we proposed in this paper.",
        "Relevancy signatures and topic signatures arc both trained on preclassified documents of specific topics and used to identify the presence of the learned topics in previously unseen documents.",
        "The main differences to our approach are: relevancy signatures require a parser.",
        "They are sentence-based and applied to text categorization.",
        "On the contrary, topic signatures only rely on corpus statistics, are document-based' and used in text summarization.",
        "In the next section, we describe the automated text, summarization system SUMMARIST that we used in the experiments to provide the context of discussion.",
        "We then define topic signatures and detail the procedures for automatically constructing topic signatures.",
        "In Section 5, we give an overview of the corpus used in the evaluation.",
        "In Section 6 we present the experimental results and the possibility of enriching topic signatures using an existing ontology.",
        "Finally, we end this paper with a conchision."
      ]
    },
    {
      "heading": "3 SUMMARIST",
      "text": [
        "SUMMARIST (Hovy and Lin, 1999) is a system designed to generate summaries of multilingual input texts.",
        "At this time, SUMMARIST can process English, Arabic, Bahasa Indonesia, Japanese, Korean, and Spanish texts.",
        "It combines robust natural language processing methods (morphological transformation and part-of-speech tagging), symbolic world knowledge, and information retrieval techniques (term distribution and frequency) to achieve high robustness and better concept-level generalization.",
        "The core of SUMMARIST is, based on the following 'equation': summarization topic identification topic interpretation + generation.",
        "These three stages are: Topic Identification: Identify the most important (central) topics of the texts.",
        "SUMMARIST uses positional importance, topic signature, and term frequency.",
        "Importance based on discourse structure1 w... be added later.",
        "This is the most developed stage in SUMMARIST.",
        "Topic Interpretation: To fuse concepts such as waiter, menu, and fond into one generalized concept restaurant, we need more than the simple word aggregation used in traditional information retrieval.",
        "We have investigated concept 3We would like to use only the relevant, parts of documents to generate topic signatures in the future.",
        "Text segmentation algorithms suck as TextTiling (Ilearst, 1907) can lie used to find subLopic segments in text.",
        "ABC-4,i LVV.S.com ,.",
        "Delay I.. H9p5ling Flight 090 Probe to F•131 N\"I'SB Chairinall James Hall ernes Egyptian official two – .",
        "nt II, review reprits cif the 1171',5[18,1-, i[11111110 the rash of Egypt Arr Flight DUO Lefore the case nett over t the E131.",
        "Nlel ov.",
        "10 - U s. invertigpiOr5 iSpecEir ig: he leaporg not, than ever tuvitrd the possibility that one of the orepiloit of EgyptAir Flight dd 111.1Y thane deiiierately crashed the plane lar:t month, killing all 217 people ■,111.70Nrd.",
        "However, LT S. erificinis any the National Trai,;,,,,Atico.",
        "Safety lbrard will tierlay tran.ferring the itrvert igro ion .->f the Oct.",
        "I cotorli to the ['131- Ore ageney that svotild :cadacrintitipl probe for nt least it few clay, to allow Ee,yptiao r-xperts ta review evideirce or thefn,c_ Skispici,,tis of foulpia?'",
        "..cre 1,65cd c.f.i.",
        ":, invextrgalitit5 1.,tetil15 t.,a tape front the evekpit voice re,o5dei i6blote51 5, reli,ion5 1',a,27 or 5taterneut made by the er,;5i]ot _hurt before the place., aritcruillot r, a5 tames.",
        "off atd the plane l,gar, it, initial plungePito ,11,- A,1-,Iti, 0,:re3 off Sias-sric190ttr.",
        "Nantucket island.",
        "55 iver the pact week.",
        "after truck effort, tire itirtili anti the Navy succeeded in Incatico; the plane's two \"black boxe5,\" the cockpit voice recorder and the flight tiara recorder.",
        "The tape indicates that :portly after the plane leveled riff at its ernicing altitude of :12,000 feet, the ei if Clint or the aircraft left the plane•s Lo,kpit.",
        "1,1ving .1-5c M. the rivr.",
        "c..-pilots alone there, n.5 tit, aircraft L, ,,I1 itA de3t.,1.",
        "counting and topic signatures to tackle the fusion problem.",
        "Summary Generation: SUMMAR1ST can produce keyword and extract type summaries.",
        "Figure 1 shows an ABC News page summary about EgyptAir night 990 by SUMMARIST.",
        "SUMMARIST employs several different heuristics in the topic identification stage to score terms and sentences.",
        "The score of a sentence is simply the sum of all the scores of content-bearing terms in the sentence.",
        "These heuristics are implemented in separate modules using inputs from preprocessing modules such as tokcnizcr, part-of-speech Gagger, morphological analyzer, term frequency and tfirlf weights calculator, sentence length calculator, and sentence location identifier.",
        "We only activate the position module, the tfidf module, and the topic signature module for comparison.",
        "We discuss the effectiveness of these modules in Section 6."
      ]
    },
    {
      "heading": "4 Topic Signatures",
      "text": [
        "Before addressing the problem of world knowledge acquisition head-on, we decided to investigate what type of knowledge would be useful for summarization.",
        "After all, one can spend a Lifetime acquiring knowledge in just a small domain.",
        "But what, is the minimum amount of knowledge we need to enable effective topic identification as illustrated by the restaurant-visit example?",
        "Our idea is simple.",
        "We would collect a set of terms4 that were typically highly correlated with a target concept from a preclassified corpus such as TREC collections, and then, during summarization, group the occurrence of the related terms by the target concept.",
        "For example, we would replace joint instances of tubk, waiter, order, cat, pay, tip, and so on, by the single phrase restaarant-vzsit, in producing an indicative"
      ]
    },
    {
      "heading": "I•errns can he stemmed words, higrams, or trigrams.",
      "text": [
        "summary.",
        "We thus defined a topic signature as a family of related terms, as follows:",
        "where topic is the target concept and signature is a vector of related terms.",
        "Each ti is an term highly correlated to topic with association weight The number of related terms n can he set empirically according to a cutoff associated weight.",
        "We describe how to acquire related terms and their associated weights in the next section."
      ]
    },
    {
      "heading": "4.1 Signature Term Extraction and Weight Estimation",
      "text": [
        "On the assumption that semantically related terms tend to co-occur, one can construct, topic signatures from preclassified text using the y2 test, mutual information, or other standard statistic tests and information-theoretic measures.",
        "Instead of X2, we use likelihood ratio (Dunning, 1993) A, since A is more appropriate for sparse data than X2 test and the quantity – 21o.qA is asymptotically X2 dis-tributed\".",
        "Therefore, we can determine the confidence level for a specific – 210.0A value by looking up X2 distribution table and use the value to select an appropriate cutoff associated weight.",
        "We have documents preclassified into a set R. of relevant texts and a set R. of nonrelevant texts for a given topic.",
        "Assuming the following two hypotheses: Hypothesis 1 (H1): P(Riti) = p = P(R16), i.e. the relevancy of a document is independent of ti Hypothesis 2 (H2): P(RIti) = p1 m = P(R.16), i.e. the presence of ti indicates strong relevancy assuming m > p2.",
        "and the following 2-by--2 contingency table: where Oil is the frequency of term ti occurring in the relevant set, 019 is the frequency of term ti occurring in the nonrelevant set, 0,1 is the frequency of term ti ti occurring in the relevant set, 0,9 is the frequency of term ti ti occurring in the nonrelevant set.",
        "Assuming a binomial distribution:",
        "'This assumes that, the ratio is between the maximum likelihood estimate over a subpart of the parameter space and the MaX11/11.1/11 likelihood estimate over the entire parameter space.",
        "See (Manning and Schiitze, 1999) pages 172 to 175 for details.",
        "then the likelihood for Hi is: L(HI) = b(011; 01 + 012,1)b(021; 02/ + 0,2,p) and for 112 is:",
        "where N = OI1 + OI, + 0,1 + 0,, is the total number of term occurrence in the corpus, I-1(R) is the entropy of terms over relevant and nonrelevant sets of documents, R(RIT) is the entropy of a given term over relevant and nonrelevant sets of documents, and I(1?.",
        "; T) is the mutual information between document relevancy and a given term.",
        "Equation 5 inch-cates that mutual information' is an equivalent measure to likelihood ratio when we assume a binomial distribution and a 2-by-2 contingency table.",
        "To create topic signature for a given topic, we:",
        "1. classify documents as relevant or nonrelevant according to the given topic 2. compute the – 21ogA value using Equation 3 for each term in the document collection 3. rank terms according to their – 2log A value 4. select a confidence level from the X2 distribution table; determine the cutoff associated weight and the number of terms to be included in the signatures"
      ]
    },
    {
      "heading": "5 The Corpus",
      "text": [
        "The training data derives from the Question and Answering summary evaluation data provided by TIPSTER-SUMMAC (Main et al., 1998) that is a subset of the TR.EC collections.",
        "The TREC data is a collection of texts, classified into various topics, used for formal evaluations of information retrieval systems in a series of annual.",
        "comparisons.",
        "This data set contains essential text, fragments (phrases, clauses, and sentences) which must be included in summaries to answer some TREC topics.",
        "These fragments are each judged by a human judge.",
        "As described in Section 3, SUMMARIST employs several independent modules to assign a score to each sentence, and then combines the scores to decide which sentences to extract from the input text,.",
        "One can gauge the efficacy (The mutual information is defined according to chapter 2 of (Cover and Thomas, 1991) and is not the pairwise mutual information used in (Church and Hanks, 1999).",
        "of each module by comparing, for different amounts of extraction, how many `good' sentences the module selects by itself.",
        "We rate a sentence as good simply if it also occurs in the ideal human-made extract, and measure it using combined recall and precision (F-score).",
        "We used four topics7 of total 6,194 documents from the TREC collection.",
        "138 of them are relevant documents with TIPSTER-SUMMAC provided answer keys for the question and answering evaluation.",
        "Model extracts are created automatically from sentences containing answer keys.",
        "Table 1 shows TREC topic description for topic 151, test questions expected to be answered by relevant doc-uments', and a sample relevant document with answer keys markup."
      ]
    },
    {
      "heading": "6 Experimental Results",
      "text": [
        "In order to assess the utility of topic signatures in text summarization, we follow the procedure described at the end of Section 4.1 to create topic signature for each selected TREC topic.",
        "Documents are separated into relevant and nonrelevant, sets according to their TREC relevancy judgments for each topic.",
        "We then run each document through a part-of-speech tagger and convert each word into its root form based on the WordNet lexical database.",
        "We also collect individual root word (unigram) frequency, two consecutive non-stopword9 (bigram) frequency, and three consecutive non-stopwords (trigram) frequency to facilitate the computation of the – 2logA value for each term.",
        "We expect high ranking bigram and trigram signature terms to be very informative.",
        "We set the cutoff associated weight at 10.83 with confidence level cs = 0.001 by looking up a x2 statistical table.",
        "Table 2 shows the top 10 unigram, bigram, and trigram topic signature terms for each topic 10.",
        "Several conclusions can be drawn directly.",
        "Terms with high – 2logA are indeed good indicators for their corresponding topics.",
        "The – 2logA values decrease as the number of words in a term increases.",
        "This is reasonable, since longer terms usually occur less often than their constituents.",
        "However, bigram terms are more informative than unigram terms as we can observe: jail/prison overcrowding of topic 151, tobacco industry of topic 257, computer security of topic 258, and solar energy/power of topic 271.",
        "These automatically generated signature terms closely resemble or equal the given short TREC topic descriptions.",
        "Although trigram terms shown in the table, such as federal court order, philip morris rjr, jet propulsion laboratory, and mobile telephone system are also meaningful, they do not demonstrate the closer term relationship among other terms in their respective topics that is seen in the bigram cases.",
        "We expect that more training data can improve the situation.",
        "We notice that the – 2logA values for topic 258 are higher than those of the other three topics.",
        "As indicated by (Mani et al., 1998) the majority of relevant documents for topic 258 have the query topic as their main theme; while the others mostly have the query topics as their subsidiary themes.",
        "This implies that it is too liberal to assume all the terms in relevant documents of the other three topics are relevant.",
        "We plan to apply text segmentation algorithms such as TextTiling (Hearst, 1997) to segment documents into subtopic units.",
        "We will then perform the topic signature creation procedure only on the relevant units to prevent inclusion of noise terms."
      ]
    },
    {
      "heading": "6.1 Comparing Summary Extraction Effectiveness Using Topic Signatures, TFIDF, and Baseline Algorithms",
      "text": [
        "In order to evaluate the effectiveness of topic signatures used in summary extraction, we compare the summary sentences extracted by the topic signature module, baseline module, and Ifidfinoilules with Int-ina.0 annotated model summaries.",
        "We measure the performance using a combined measure of recall (I?)",
        "and precision (I'), F-score is defined by:",
        "N„„, # of sentences e:rtrated that also appear in the model summary #of sentences in the model summary # of sentences extracted by the system relative importance of 1?",
        "and P We assume equal importance of recall and precision and set 1 to I in our experiments.",
        "The baseline (position) module scores each sentence by its position in the text.",
        "The first sentence gets the highest score, the last sentence the lowest.",
        "The baseline method is expected to be effective for news genre.",
        "The tlidf module assigns a score to a term ti according to the product, of its frequency within a document j (t fib) and its inverse document frequency (idfi = log ).",
        "N is the total number of documents in the corpus and (Ili is the number of documents containing term The topic signature module scans each sentence, assigning to each \\void that, occurs in a topic signature the weight of that keyword in the topic signa-tu•e.",
        "Each sentence then receives a topic signature score equal to the total of all signature word scores it contains, normalized by the highest sentence score.",
        "This score indicates the relevance of the sentence to the signature topic.",
        "SCNINIARIST produced extracts of the same texts separately for each module, for a series of extracts ranging from 0% to 100% of the original text.",
        "Although many relevant documents are available for each topic, only some of them have answer key where",
        "markups.",
        "The number of documents with answer keys are listed in the row labeled: \"# of Relevant Does Used in Training\".",
        "To ensure we utilize all the available data and conduct a sound evaluation, we perform a threefold cross validation.",
        "We reserve one-third of documents as test set, use the rest as training set, and repeat I hree tunes with non-overlapping test set.",
        "Furthermore, we use only unigrain topic signatures for evaluation.",
        "The result is shown in Figure 2 and Table 3.",
        "We find that, the topic signature method outperforms the other two methods and the tfidf method performs poorly.",
        "Among 40 possible test tioints for four topics with 10% summary length increment (0% means select at least one sentence) as shown in Table 3, the topic signature method beats the baseline method 34 times.",
        "This result is really encouraging and indicates that the topic signature method is a. worthy addition to a variety of text summarization methods."
      ]
    },
    {
      "heading": "6.2 Enriching Topic Signatures Using Existing Ontologies",
      "text": [
        "We have shown in the previous sections that topic signatures can be used to approximate topic identification at tile lexical level.",
        "Although the automatically acquired signature terms for a specific topic seem to he bound by unknown relationships as shown in Table 2, it is hard to image how we can enrich the inherent flat structure of topic signatures as defined in Equation 1 to a construct as complex as a MUC template or script.",
        "As discussed in (Agirre et al., 2000), we propose using an existing ontology such as SENSUS (Knight and Luk, 1994) to identify signature term relations.",
        "The external hierarchical framework can be used to generalize topic signatures and suggest richer representations for topic signatures.",
        "Automated entity recognizers can be used to classify unknown entities into their appropriate SENSUS concept nodes.",
        "We are also investigating other approaches to automatically learn signature term relations.",
        "The idea mentioned in this paper is just a starting point."
      ]
    },
    {
      "heading": "7 Conclusion",
      "text": [
        "In this paper we presented a procedure to automatically acquire topic signatures and valuated the effectiveness of applying topic signatures to extract topic relevant sentences against two other muthods.",
        "The topic signature method outperforms the baseline and the (Pt methods for all test topics.",
        "Topic signatures can not only recognize related terms (topic identification), but group related terms together under one target concept (topic: interpretation).",
        "Topic identification and interpretation are two essential steps in a typical automated text summarization system as we present in Section 3.",
        "Topic signatures can also been viewed as an inverse process of query expansion.",
        "Query expansion intends to alleviate the word mismatch problem in information retrieval, since documents are normally written in different vocabulary_ flow to automatically identify highly correlated terms and use them to improve information retrieval performance has been a main research issue since late 1960's.",
        "Recent advances in the query expansion (XII and Croft., 1996) can also shed some light on the creation of topic signatures.",
        "Although we focus the use of topic signatures to aid text summarization in this paper, we plan to explore the possibility of applying topic signatures to perform query expansion in the future.",
        "The results reported are encouraging enough to allow us to continue with topic signatures as the vehicle for a first approximation to world knowledge.",
        "We are now busy creating a large number of signatures to overcome the world knowledge acquisition problem and use them in topic interpretation."
      ]
    },
    {
      "heading": "8 Acknowledgements",
      "text": [
        "We thank the anonymous reviewers for very useful suggestions.",
        "Thus work is supported in part by DARPA contract, N6(3001-97-9538."
      ]
    }
  ]
}
