{
  "info": {
    "authors": [
      "Yutaka Sasaki",
      "Yoshihiro Matsuo"
    ],
    "book": "International Conference on Computational Linguistics",
    "id": "acl-C00-2101",
    "title": "Learning Semantic-Level Information Extraction Rules by Type-Oriented ILP",
    "url": "https://aclweb.org/anthology/C00-2101",
    "year": 2000
  },
  "references": [
    "acl-M92-1021",
    "acl-P99-1062",
    "acl-W97-1002"
  ],
  "sections": [
    {
      "heading": "Abstract",
      "text": [
        "This paper describes an approach to using semantic representations for learning information extraction (IE) rules by a type-oriented inductive logic programming (11,1)) system.",
        "NLP components of a machine translation system are used to automatically generate semantic representations of text corpus that can be given directly to an ILP system.",
        "The latest experimental results show high precision and recall of the learned rules."
      ]
    },
    {
      "heading": "1 Introduction",
      "text": [
        "Information extraction (IE) tasks in this paper involve the MUC-3 style IE.",
        "The input for the information extraction task is an empty template and a set of natural language texts that describe a restricted target domain., such as corporate mergers or terrorist attacks in South America.",
        "Templates have a record-like data structure with slots that have names, e.g., \"company name\" and \"merger date\", and values.",
        "The output is a set of filled templates.",
        "IE tasks are highly domain-dependent, so rules and dictionaries for filling values in the template slots depend on the domain.",
        "It is a heavy burden.",
        "for IE system developers that such systems depend on handmade rules, which cannot be easily constructed and.",
        "changed.",
        "For example, Um.ass/MUC-3 needed.",
        "about 1,500 person-hours of highly skilled labor to build the IE rules and represent them as a dictionary (Lehnert, 1992).",
        "All the rules must be reconstructed from scratch when the target domain is changed.",
        "To cope with this problem, some pioneers have studied methods for learning information extraction rules (Riloff,1996; Soderland et al., 1995; Kim et al., 1995; Huffman, 1996; Califf and Mooney, 1997).",
        "Along these lines, our approach is to apply an inductive logic programming (IL.P) (Muggleton, 1991.)",
        "system to the learning of IE rules, where information is extracted.",
        "from semantic representations of news articles.",
        "The I.LP system that we employed is a type-oriented ILP system 111113+ (Sasaki and Haruno, 1.997), which can efficiently and effectively handle type (or sort) information in training data.",
        "2 Our Approach to IE Tasks This section describes our approach to IF tasks.",
        "Figure 1. is an overview of our approach to learning IF, rules using an ILP system from semantic representations.",
        "First, training articles are analyzed and converted into semantic representations, which are filled case frames represented as atomic formulae.",
        "Training templates are prepared by hand as well.",
        "The ILP system learns rules in the form of logic programs with type information.. To extract key information from a new article, semantic representations automatically generated from the article is matched by the IE rules.",
        "Extracted information is filled into the template slots."
      ]
    },
    {
      "heading": "3 NLP Resources and Tools",
      "text": []
    },
    {
      "heading": "3.1 The Semantic Attribute System",
      "text": [
        "We used the semantic attribute system of \"GoiTaikei A Japanese Lexicon\" (Ikehara et al., 1.997a; Kurohashi and.",
        "Sakai, 1999) compiled by the NTT Communication Science Laboratories for a Japanese-to-English machine translation system, ALT-J/E (Ikehara et al., 1994).",
        "The semantic attribute system is a sort of hierarchical concept thesaurus represented as a tree structure in which each node is called a semantic category.",
        "Am edge in the tree represents an is_a or has_a relation between two categories.",
        "The semantic attribute system is 12 levels deep and",
        "contains about 3,000 semantic category nodes.",
        "More than 300,000 Japanese words are linked to the category nodes."
      ]
    },
    {
      "heading": "3.2 Verb Case Frame Dictionary",
      "text": [
        "The japanese-to-Ehglish valency pattern dictionary of \"Goi-Taildei\" (ikehara et al., 1997b; Kuroltashi and Sakai, 1999) was also originally developed for ALT-J/E.",
        "The valency dictionary contains about 15,000 case frames with semantic restrictions on their arguments for 6,000 Japanese verbs.",
        "Each case frame consists alone predicate and one or more case elements that have a list of semantic categories."
      ]
    },
    {
      "heading": "3.3 Natural Language Processing Tools",
      "text": [
        "We used the NLP components of ALT-1/E for text analysis.",
        "These include the morphological analyzer, the syntactic analyzer, and the case analyzer for Japanese.",
        "Tile components are robust and generic tools, mainly targeted to newspaper articles."
      ]
    },
    {
      "heading": "3.3.1 Generic Case Analyzer",
      "text": [
        "Let us examine the case analysis in more detail.",
        "The case analyzer reads a set of parse tree candidates produced by the Japanese syntactic analyzer.",
        "The parse tree is represented as a dependency of phrases (i.e., Japanese bunsetsu).",
        ":first, it divides the parse tree into unit sentences, where a unit sentence consists of one predicate and its noun and adverb dependent phrases.",
        "Second, it compares each.",
        "unit sentence with a verb case frame dictionary.",
        "Each frame consists a predicate condition and several case elements conditions.",
        "The predicate condition specifies a verb that matches the frame and each case-role has a case element condition which specifies particles and semantic categories of 11 OUTI phrases.",
        "The preference value is defined as the summation of noun phrase preferences which are calculated from the distances between the categories of the input sentences and the categories written in the :frames.",
        "The case analyzer then chooses the most preferable parse tree and the idlost preferable combination.",
        "of case frames.",
        "The valency dictionary also has case-roles (Table 1) for :noun phrase conditions.",
        "The case-roles of adjuncts are determined by using the particles of adjuncts and the semantic categories of noun phrases.",
        "As a, result, the output of the case analysis is a set of case frames for each unit sentence.",
        "The noun phrases in frames are labeled by case-roles in Table 1.",
        "For simplicity, we 1.1 se case-role codes, such as N1 and N2, as the labels (or slot names) to represent case frames.",
        "The relation between sentences and case-roles is described in detail in (11Alara et al., 1993)."
      ]
    },
    {
      "heading": "3.3.2 Logical Form Translator",
      "text": [
        "We developed a logical form translator FEP that generates semantic representations expressed as atomic formulae front the case frames and parse trees.",
        "For later use, document ID and tense information are also added to the case frames.",
        "For example, the case frame in Table 2 is obtained after analyzing the following sentence of document Dl:",
        "the agent/experiencer of an event/situation the object of an event another object of an event source location of a movement goal location of a movement the purpose of an action the result of an event the location of an event co-experiencer quoted expression.",
        "material/ingredient the reason_ for an event a concrete instrument an abstract instrument the time of an event the starting time of an.",
        "event the end time of an event quantity of something I throw a ball.",
        "I throw a ball.",
        "I compare it with them.",
        "I start from Japan.",
        "1 go to Japan.",
        "go shopping.",
        "It results in failure.",
        "It occurs at the station.",
        "I share a room with him.",
        "I say that ....",
        "I fill the glass with water.",
        "It collapsed from the weight.",
        "I speak with a microphone.",
        "I speak in Japanese.",
        "I. go to bed at 10:00.",
        "I work from Monday.",
        "It continues until Monday.",
        "I spend $10.",
        "shokuba(the office) kara(from) kuko(the airport) ni(to) hakobu(carry)\" (\"Jack carries a suitcase from the office to the airport.\")",
        "N1: Jakku (Jack) N2: sutsukesu (suitcase) N4: shokuba (the office) N5: kuko (the airport)"
      ]
    },
    {
      "heading": "4 Inductive Learning Tool",
      "text": [
        "Conventional ILP systems take a set of positive and negative examples, and background knowledge.",
        "The output is a set of hypotheses in the form of logic programs that covers positives and do not cover negatives.",
        "We employed the type-oriented ILP system RHB+."
      ]
    },
    {
      "heading": "4.1 Features of Type-oriented ILP System RHB+",
      "text": [
        "The type-oriented ILP system has the following features that match the needs for learning IE rules.",
        "• A type-oriented ILP system can efficiently and effectively handle type (or semantic category) information in training data.",
        "This feature is advantageous in controlling the generality and accuracy of learned.",
        "IE rules.",
        "• It can directly use semantic representations of the text as background knowledge.",
        "• It can learn from only positive examples.",
        "• Predicates are allowed to have labels (or keywords) for readability and ex.pressibility."
      ]
    },
    {
      "heading": "4.2 Summary of Type-oriented ILP System RHB+",
      "text": [
        "This section summarizes the employed type-oriented ILP system RIM+.",
        "The input of RH13+ is a set of positive examples and background knowledge including type hierarchy (or",
        "the semantic attribute system).",
        "The output is a set of Horn clauses (Lloyd, 1.987) having variables with type information.",
        "That is, the term is extended to the 7-term.",
        "4.3 r-terms 7-terms are the restricted form of 0-terms (AR-Kaci and Nasr, 1986; Alt-I.Klaci.",
        "et al., 1994).",
        "Informally, r-terms are Prolog terms whose variables are replaced with.",
        "variable Far of type T, which is denoted as Var:T. Predicate and.",
        "function symbols are allowed.",
        "to have features (or labels).",
        "For example, speak(agentX:human,objectY:language) is a clause based.",
        "on 7-terms winch has labels agent and object, and types human and language."
      ]
    },
    {
      "heading": "4.4 Algorithm",
      "text": [
        "The algorithm of ItH13+ is basically a greedy covering algorithm.",
        "It constructs clauses on.e-by-one by calling inner_loop (Algorithm 1.)",
        "which returns a hypothesis clause.",
        "A hypothesis clause is represented in the form of head :- body.",
        "Covered examples are removed from.",
        "P in.",
        "each.",
        "cycle.",
        "The inner loop consists of two phases: the head C.011 struction.",
        "phase and the body construction.",
        "phase.",
        "It constructs heads in a bottom-up manner and constructs the body in a top-clown manner, following the result described in (Celle et al., 1.994).",
        "The search heuristic PW/ is weighted.",
        "infor-mativity employing the Laplace estimate.",
        "Let",
        "where IP1 denotes the number of positive examples covered by T and Q(2') is the empirical content.",
        "The smaller the value of PW1, the candidate clause is better.",
        "Q(T) is defined as the set of atoms (1) that are derivable from T and (2) whose predicate is the target predicate, i.e., the predicate name of the head.",
        "The dynamic type restriction by positive examples uses positive examples currently covered in order to determine appropriate types to variables for the current clause.",
        "1.",
        "Given positives P, original positives Po, background knowledge BK.",
        "2.",
        "Decide types of variables in a head by computing the typed least general generalizations (lgg) of N pairs of elements in P, and select the most general head as Head.",
        "3.",
        "If the stopping condition is satisfied, return II cad.",
        "Lel Body be empty.",
        "5.",
        "Create a set of all possible literals L using variables in Head and Body.",
        "6.",
        "Lel BEAM be top K literals la, of L with respect to the positive weighted informativity PW I.",
        "7.",
        "Do later steps, assuming that lk is added to Body for each literal la; in BEAM.",
        "8.",
        "Dynamically restrict types in Body by calling the dynamic type restriction by positive examples.",
        "9.",
        "If the stopping condition is satisfied, return (Bead : – Body).",
        "10.",
        "Gob 5.",
        "5 Illustration of a Learning Process",
        "Now, we examine the two short notices of new products release in Table 3.",
        "The following table shows a sample template for articles reporting a new product release.",
        "Template",
        "1. article id: 2. company: 3. product: 4. release date:"
      ]
    },
    {
      "heading": "5.1 Preparation",
      "text": [
        "Suppose that the following semantic representations is obtained from Article I.",
        "1. article id: 1 2. company: ABC Corp. 3. product: a color printer 4. release date: Jan. 20",
        "Suppose that the following semantic representation is obtained from Article 2.",
        "n2 => \"a color scanner\" ).",
        "The filled template for Article 2 is as follows.",
        "Template 2",
        "1. article id: 2 2. company: XYZ Corp. 3. product: a color scanner 4. release date: last month"
      ]
    },
    {
      "heading": "5.2 Head Construction",
      "text": [
        "Two positive examples are selected for the template slot \"company\".",
        "By computing a least general generalization (lgg)sasaki97, the following head is obtained: company( article-number => Art: number name => Co: organization) ."
      ]
    },
    {
      "heading": "5.3 Body Construction",
      "text": [
        "Generate possible literals' by combining predicate names and variables, then check the PWI 1\"literals\" here means atomic formulae or negated ones.",
        "values of clauses to which one of the literal.",
        "added.",
        "In this case, suppose that adding the following literal with predicate release is the best one.",
        "After the dynamic type restriction., the current clause satisfies the stopping condition.",
        "Finally, the rule for extracting \"company name\" is returned.",
        "Extraction rules for other slots \"product\" and \"release date\" can be learned in the same manner.",
        "Note that several literals may be needed in the body of the clause to satisfy the stopping condition."
      ]
    },
    {
      "heading": "5.4 Extraction",
      "text": [
        "Now, we have the following semantic representation extracted from the new article: Article 3: \"MN Corp. has released a new CD player.\" 2",
        "Applying the learned IE rules and other rules, we can obtain the filled template for Article 3.",
        "Template 3",
        "1. article id: 3 2. company: JPN Corp. 3. product: CD player 4. release date:"
      ]
    },
    {
      "heading": "6 Experimental Results",
      "text": []
    },
    {
      "heading": "6.1 Setting of Experiments",
      "text": [
        "We extracted articles related to the release of new products front a one-year newspaper corpus written i:n. Japanese 3.",
        "One-hundred articles were randomly selected from 362 relevant articles.",
        "The template we used consisted of five slots: company name, product name, release date, announce dale, and price.",
        "We also filled one template for each article.",
        "After analyzing sentences, case frames were converted into atomic formulae .representing semantic representations as described in Section 2 and 3.",
        "All the semantic representations were given to the learner as background knowledge, and the filled templates were given as positive examples.",
        "To speed-up the learning process, we selected predicate names that are relevant to the words in the templates as the target predicates to be used by the .1.1,1' system, and we also restricted the number of literals in the body of hypotheses to one.",
        "Precision and recall, the standard metrics for 1E tasks, are counted by using the remove-one-out cross validation on the examples for each item.",
        "We used a VArStation with the Pentium II Xeon (450 MHz) for this experiment."
      ]
    },
    {
      "heading": "6.2 Results",
      "text": [
        "Table 4 shows the results of our experiment.",
        "In the experiment of learning from.",
        "semantic representations, including errors in case-role selection and semantic category selection, precision was",
        "very high.",
        "The precision of the learned rules for price was low because the semantic category name automatically given to the price expressions in the data were not quite appropriate.",
        "For the five items, 67-82% recall was achieved.",
        "With the background knowledge having semantic representations corrected by hand, precision was very high and 70-88% recall was achieved.",
        "The precision of price was markedly improved.",
        "It is important that the extraction of five different pieces of information showed good results.",
        "This indicates that the ILP system R 1113+ has a high.",
        "potential in LIE tasks."
      ]
    },
    {
      "heading": "7 Related Work",
      "text": [
        "Previous researches on generating rules from.",
        "texts with templates include AutoSlog-TS (Riloff,1996), C11.ZYSTAL (Soderland et al., 1.995), PALKA (Kim et al., 1995), LIEP (Huffman, 1996) and RAPIER (Califf and Mooney, 1997).",
        "In our approach, we use the type-oriented ILP system RIIB+, which is independent of natural language analysis.",
        "This point differentiates our approach from the others.",
        "Learning semantic-level IF, rules using an.",
        "11 P system from semantic representations is also a new challenge in 1E studies.",
        "Sasaki (Sasaki and Haruno, 1997) applied.",
        "R1113+ to the extraction of the number of deaths and injuries from twenty five articles.",
        "That experiment was sufficient to assess the performance of the learner, but not to evaluate its feasibility in IE tasks."
      ]
    },
    {
      "heading": "8 Conclusions and Remarks",
      "text": [
        "This paper described a use of semantic representations for generating information extraction rules by applying a type-oriented ILP system.",
        "Experiments were conducted on the data generated from 100 news articles in the domain of new product release.",
        "The results showed very high precision, recall of 67-82% without data correction and 70-88% recall with correct semantic representations.",
        "The extraction of five different pieces of information showed good results.",
        "This indicates that our learner RHB+ has a high potential in 1E tasks."
      ]
    }
  ]
}
