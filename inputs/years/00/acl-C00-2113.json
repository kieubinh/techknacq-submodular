{
  "info": {
    "authors": [
      "Sayori Shimohata"
    ],
    "book": "International Conference on Computational Linguistics",
    "id": "acl-C00-2113",
    "title": "An Empirical Method for Identifying and Translating Technical Terminology",
    "url": "https://aclweb.org/anthology/C00-2113",
    "year": 2000
  },
  "references": [
    "acl-C90-3001",
    "acl-C96-1089",
    "acl-J93-1007",
    "acl-P96-1020",
    "acl-P97-1061",
    "acl-P98-1010",
    "acl-W95-0107"
  ],
  "sections": [
    {
      "heading": "Abstract",
      "text": [
        "This paper describes a method for retrieving patterns of words and expressions frequently used in a specific domain and building a dictionary for machine translation(MT).",
        "The method uses an untagged text corpus in retrieving word.",
        "sequences and simplified part-of-speech templates in identifying their syntactic categories.",
        "The paper presents experimental results for applying the words and expressions to a pattern-based machine translation system."
      ]
    },
    {
      "heading": "1 Introduction",
      "text": [
        "There has been a continuous interest hi corpus-based approaches which retrieve words and expressions in connection with a specific domain (we call them technical terms hereafter).",
        "They may correspond to syntactic phrases or components of syntactic relationships and have been found useful in various application areas, including information extraction, text summarization, and machine translation.",
        "Among others, a knowledge of technical terminology is indispensable for machine translation because usage and meaning of technical terms are often quite different from their literal interpretation.",
        "One approach for identifying technical terminology is a rule-based approach which learns local syntactic patterns from a training corpus.",
        "A variety of methods have been developed within this framework, (Ramshaw, 1995) (A.rgamon et a]., 1999) (Cardie and Pierce, 1999) and achieved good results for the considered task.",
        "Surprisingly, though, little work has been devoted to learning local syntactic patterns besides noun phrases.",
        "Another drawback of this approach is that it requires substantial training corpora, in many cases with part-of-speech tags.",
        "An.",
        "alternative approach is a statistical one which retrieves recurrent word sequences as collocations (Smadja, 1993)(llaruno et al., 1996)(Shimohata et al., 1997).",
        "This approach is robust and practical because it uses plain text corpora without any information dependent on a language.",
        "Unlike the former approach, this approach extracts various types of local patterns at the same time.",
        "Therefore, post-processing, such as part of speech tagging and syntactic category identification, is necessary when we apply them to NIT applications.",
        "This paper presents a method for identifying technical terms from a corpus and applying them to a machine translation system.",
        "The proposed method retrieves local patterns by utilizing the n-gram statistics and identifies their syntactic categories with.",
        "simple part-of-speech templates.",
        "We make a machine translation dictionary from.",
        "the retrieved patterns and translate documents in the same domain as the original corpus.",
        "In the next section, we briefly describe a pattern-based machine translation.",
        "The following section explains how the proposed method works in detail.",
        "We then present experimental results and conclude with a discussion."
      ]
    },
    {
      "heading": "2 Pattern-based MT system",
      "text": [
        "A. pattern-based MT system uses a set of bilingual patterns(CFG rules) (Abeille et al., 1990) (Takeda, 1996) (Shimohata et al., 1999).",
        "In the parsing process, the engine performs a CFG-parsing for an input sentence and rewrites trees by applying the source patterns.",
        "Terminals and non-terminals are processed under the same framework but lexicalized patterns have priority over symbolized patterns 1 .",
        "A. plausible parse 1 We define a symbolized pattern as a pattern without a terminal and a lexicalized pattern as that with more than one terminal.",
        "we prepares 1000 symbolized patterns and 130,000 lexicalized patterns as a system",
        "tree will be selected among possible parse trees by the number of patterns applied.",
        "Then the parse tree is transferred into target language by using target patterns which correspond to the Source patterns.",
        "Figure 1 shows an example of translation patterns between English and Japanese.",
        "Each English pattern(a left-half CFG rule) has corresponding Japanese pattern(a right-half CFG rule).",
        "Non-terminals are bracketed with index numbers which represents correspondence of non-terminals between the source and target pattern.",
        "The pattern format is simple but highly descriptive.",
        "It can represent complicated linguistic phenomena and even correspondences between the languages with quite different structures.",
        "Furthermore, all the knowledge necessary for the translation, whether syntactic or lexical, are compiled in the same pattern format.",
        "Owing to these features, we can easily apply the retrieved technical terms to a real MT system."
      ]
    },
    {
      "heading": "3 Algorithm",
      "text": [
        "Figure 2 shows an outline of the proposed method.",
        "The input is an untagged monolingual corpus, while the output is a domain dictionary for machine translation.",
        "The process is comprised of 3 phases: retrieving local patterns, assigning their syntactic categories with part-of-speech(POS) templates, and making translation patterns.",
        "The dictionary is used when an MT system translates a text in the same domain as the corpus.",
        "We assume that the input is an English corpus and the dictionary is used for an English-Japanese MT system.",
        "In the remainder of this section, we will explain each phase in detail with English and Japanese examples.",
        "dictionary."
      ]
    },
    {
      "heading": "3.1 Retrieving local patterns",
      "text": [
        "We have already proposed a method for retrieving word sequences (Shimohata et al., 1997).",
        "This method generates all n-character (or n-word) strings appearing in a text and filters out fragmental strings with the distribution of words adjacent to the strings.",
        "This is based on the idea that adjacent words are widely distributed if the string is meaningful, and are localized if the string is a substring of a meaningful string.",
        "The method introduces entropy value to measure the word distribution.",
        "Let the string be sir, the adjacent words w1...w„, and the frequency of str f req(sir).",
        "The probability of each possible adjacent word p(w.i) is then:",
        "Calculating the entropy of both sides of sir, tire lower one is used as If (sir).",
        "Then the strings whose entropy is larger than a given threshold are retrieved as local patterns."
      ]
    },
    {
      "heading": "3.2 Identifying syntactic categories",
      "text": [
        "Since the strings are just word sequences, the process gives them syntactic categories.",
        "For each str sir,",
        "1. assign part-of-speech tags to the component words 2. match tag sequence 11, i„ with part-of-speech templates Ti 3. give sir corresponding syntactic category S if it matches Ti"
      ]
    },
    {
      "heading": "3.2.1 Assigning part-of-speech tags",
      "text": [
        "The process uses a simplified part-of-speech set shown in table 1.",
        "Function words are assigned as they are, while content words except for adverb are fallen into only one part of speech.",
        "word.",
        "Four kinds of words \"be\", \"do\", \"not\", and \"to\" are assigned to special tags be, do, not, and to respectively.",
        "There are several reasons to use the simplified PUS tags:",
        "• it may sometimes be difficult to identify precise parts of speech in such a local pattern.",
        "• words are often used beyond parts of speech in technical terminology • it is empirically found that word sequences retrieved through n-gram statistics have distributional concentration on several syn",
        "tactic categories.",
        "Therefore, we think the simplified POS tags are sufficient to identify syntactic categories.",
        "The word sequence w„ is represented for a part-of-speech tag sequence Figure 3 shows examples of POS tagging.",
        "Italic the fuel tank art word word do this step : do det,prn word punc to oprn the",
        "lines are given word sequences and bold lines are POS tag sequences.",
        "If a word falls into two or more parts of speech, all possible POSs will be assigned like \"this\" in the second example."
      ]
    },
    {
      "heading": "3.2.2 Matching POS templates",
      "text": [
        "The process identifies a syntactic category(SC) of sir by checking if sir's tag sequence t„ matches a given POS template If they",
        "match, sir is given a syntactic category SCE corresponding to Table 2 shows examples If SC is N, delete art and generate: of POS templates and.",
        "corresponding SCs 2 .",
        "NP str NP str",
        "The templates are described in the form.",
        "of regular expressions(RE) .",
        "The first template in table 2, for example, :matches a string whose tag sequence begins with an article, contains 0 or more repetitions of content words or conjunctions, and ends with a content word.",
        "\"the fuel tank\" in figure 3 is applied to this templates and given a SC \"N\"."
      ]
    },
    {
      "heading": "3.3 Making translation patterns",
      "text": [
        "The process converts the strings into translation patterns.",
        "The problem here is that we need to generate bilingual translation patterns from monolingual strings.",
        "We use heuristic: rules on borrowing words from foreign languages .",
        "Figure 4 is an example of conversion rules for generating English-Japanese translation patterns.",
        "To give an example, \"to open the\" in figure 3, whose SC is VT, is converted into the following patterns in accordance with the second rule in figure 4.",
        "2 Note that the POS templaIes arc strongly dependent on the features of n-grain strings.",
        "3 \"*\" causes the resulting RE to match 0 or more repetitions of the preceding RE.",
        "\"+\" causes the resulting RE to match 1 or more repetitions of the preceding RE.",
        "\"I\" creates a RE expression that will match either right or left of \"I\".",
        "\"(...)\" indicates the start and end of a group.",
        "4 In Japanese, foreign words, especially in technical terminology, are often used as they arc in katakana (the phonetic spelling for foreign words) followed by function words which indicate their parts of speech For example, English verbs are followed by \"saru\" , a verb which means \"do\" in English."
      ]
    },
    {
      "heading": "4 Evaluation",
      "text": [
        "We have tested our algorithm in building a, domain dictionary and making a translation with.",
        "it.",
        "A corpus used in the experiment is a computer manual comprising 167,023 words (in 22,041 sentences).",
        "The corpus contains 24,137 n-grams which appear more than twice.",
        "Among them, 7,616 strings are extracted over the entropy threshold 1.",
        "Table 3 is a list of top 20 strings (except for single words and function word sequences) retrieved from the test corpus.",
        "These strings are categorized into :1,239 POS patterns.",
        "Table 4 is a list of top 10 POS patterns and the numbers of strings classified into them.",
        "In this experiment, the top :1.0 POS patterns account for 99.4 % of all PUS patterns.",
        "It substantiates the fact that the retrieved strings tend to concentrate in certain.",
        "POS patterns."
      ]
    },
    {
      "heading": "PUS",
      "text": [
        "In the matching process, we prepared 15 templates and 6 SCs.",
        "Table 5 is a result of SC identification.",
        "2,462 strings(32.3 %) are not matched to any templates.",
        "The table indicates that most strings retrieved.",
        "in.",
        "this method are identified as N and NP.",
        "It is quite reasonable because the majority of the technical terms are supposed to be nouns and noun phrases.",
        "SC number of patterns",
        "The retrieved translation patterns total 1,219.",
        "Figure 5 shows an example of translation patterns retrieved by our method.",
        "We, then, converted them to an MT dictionary and made a translation with and without it.",
        "Table 6 summarizes the evaluation results translating randomly selected 1,000 sentences from the test corpus.",
        "Compared with the translations without the dictionary, the translations with the dictionary improved 571 in parsing and word selection.",
        "Figure 6 illustrates changes in translations.",
        "Each column consists of an input sentence, a translation without the dictionary, and a translation with the dictionary.",
        "Bold English words improved in parsing 104 improved in word selection 467 about the same 160 same 21.2 not improved.",
        "57 total 1000",
        "correspond to underlined Japanese.",
        "First two examples show improvement in word selection.",
        "The translations of \"ntap(verb)\" and \"exec\" are changed from word-for-word translations to non-translation word sequences.",
        "Although \"to make a map\" and \"exective\" are not wrong translations, they are irrelevant in the computer manual context.",
        "On the contrary, the domain dictionary reduces confusion caused by the wrong word selection.",
        "Wrong parsing and incomplete parsing are also reduced as shown in the next two examples.",
        "In the third example, \"Next\" should be a noun, while it is usually used as an adverb.",
        "The domain dictionary solved the syntactic ambiguity properly because it has exclusive priority over system dictionaries.",
        "In the forth example, \"double-click\" is an unknown word which could cause incomplete parsing.",
        "But the phrase was parsed as a verb correctly.",
        "The last one is an wrong example of Japanese verb selection.",
        "That was a main cause of errors and declines.",
        "The reason why the undesirable Japanese verbs were selected.",
        "is that",
        "the method added default semantic information to the retrieved nouns and noun phrases.",
        "We hope to overcome it by a model that classifies lions phrases, for example using verb-noun or adjective-noun relations."
      ]
    },
    {
      "heading": "5 Related work",
      "text": [
        "As mentioned in section 1, there are two approaches in corpus-based technical term retrieval: a rule-based approach and a statistical approach.",
        "Major differences between the two arc:",
        "• the former uses a tagged corpus while tile latter uses an untagged one.",
        "• the former retrieves words and phrases with",
        "a designated syntactic category while the latter retrieves that with various syntactic categories at the same time.",
        "Our method uses the latter approach because we think it more practical both in resources and in applications.",
        "For comparison, we refer here to Smadja's method (1993) because this method and the proposed method have much in.",
        "common.",
        "In both cases, technical terms are retrieved from au untagged corpus with n-gram statistics and given syntactic categories for NLP applications.",
        "The methods are different in that Smadja uses a",
        "parser for syntactic category identification while we use POS templates.",
        "A parser may add more precise syntactic category than.",
        "POS templates.",
        "However, we consider it not to be critical under the specific condition that the variety of input patterns is very small.",
        "In terms of portability, the proposed method has an advantage.",
        "Actually, adding POS templates is not so time consuming as developing a parser.",
        "We have applied the translation patterns retrieved by this method to a real MT system.",
        "As a result, 57.1 % of translations were improved with 1,219 translation patterns.",
        "To our knowledge, little work has gone into quantifying its effectiveness to NLP applications.",
        "We recognize that the method leaves room for improvement in making translation patterns.",
        "We, therefore, plan to introduce techniques for finding translational equivalent from bilingual corpora (Melamed, 1998) to our method."
      ]
    },
    {
      "heading": "6 Conclusion",
      "text": [
        "We have presented a method for identifying technical terminology and building a d.omain dictionary for MT.",
        "Applying the method to a technical manual in English yielded positive results.",
        "We have found that the proposed method would dramatically improve the performance of translation.",
        "In the future work, we plan to investigate the availability of POS patterns which are not categorized into any SCs."
      ]
    }
  ]
}
