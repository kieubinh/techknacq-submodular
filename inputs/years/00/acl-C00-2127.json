{
  "info": {
    "authors": [
      "Yoshihiro Ueda",
      "Mamiko Oka",
      "Takahiro Koyama",
      "Tadanobu Miyauchi"
    ],
    "book": "International Conference on Computational Linguistics",
    "id": "acl-C00-2127",
    "title": "Toward the \"At-A-Glance\" Summary: Phrase-Representation Summarization Method",
    "url": "https://aclweb.org/anthology/C00-2127",
    "year": 2000
  },
  "references": [
    "acl-C96-2166",
    "acl-P98-2151",
    "acl-W00-0407",
    "acl-W97-0702"
  ],
  "sections": [
    {
      "heading": "Abstract",
      "text": [
        "We have developed a summarization method that creates a summary suitable for the process of sifting information retrieval results.",
        "Unlike conventional methods that extract important sentences, this method constructs short phrases to reduce the burden of reacting long sentences.",
        "We have developed a prototype summarization system for Japanese.",
        "Through a rather large-scale task-based experiment, the summary this system creates proved to be effective to sift IR results.",
        "This summarization method is also applicable to other languages such as English."
      ]
    },
    {
      "heading": "Introduction",
      "text": [
        "Summaries are used to select relevant information from information retrieval results.",
        "The goal of summarization for such \"indicative\" use is to provide fast and accurate judgement.",
        "Most automatic summarization systems adopt the \"sentence selection\" method, which gives a score to every sentence on the basis of its characteristics, such as word frequency, the position in which it appears, etc.",
        "and selects sentences with high scores.",
        "The sentences collected in such a way tend to he so long and complex that the reader must reconstruct the structure while reading them.",
        "Reading such sentences involves some annoyance.",
        "Our aim is to reduce this burden by providing an \"at-a-glance\" summary.",
        "Phrase-representation summarization is a method to create the \"at-a-glance\" summary for the Japanese language.",
        "Here we present the concept, the algorithm, and evaluation of the efficacy of the summary produced by a prototype based on this method.",
        "Extension to English is also discussed."
      ]
    },
    {
      "heading": "1 The Concept",
      "text": [
        "Examples of an \"at-a-glance summary are the headlines of news articles.",
        "The headline provides information for judging whether the",
        "article is to be read or not and, in this sense, it is really \"indicative.\" The characteristics are: • Brevity (short in length) • Simplicity (less embedded sentences)",
        "We use \"phrases\" to represent the simplicity characteristic' and set our goal to create phrase-represented summaries, which provide the reader with an outline of the document, avoiding reading stress by enumerating short phrases containing the important words and concepts composed from these words.",
        "The method we adopted to achieve this goal is to construct such phrases from the relations between words rather than extracting important sentences from the original document."
      ]
    },
    {
      "heading": "2 Summarization Method",
      "text": []
    },
    {
      "heading": "2.1 Outline of the Algorithm",
      "text": [
        "Here we give a short description of the outline of this method using the example shown in Fig. 1.2 The word \"phrase\" used here is not of the linguistic sense but an expression for \"short\" and \"simple.\" In Japanese, there is no rigid distinction between \"phrase\" and \"clause.\" 2 In this paper, Japanese words are represented in English as much as possible.",
        "The words left in Japanese are shown in italics, such as \"ga\" (a particle for AGENT), (\"era\"), etc.",
        "Each relation name is constructed Toni a Japanese particle and its function (shown as a case name or an equivalent English",
        "The method consists of the following four major steps:",
        "(1) Syntactic analysis to extract the relations between words (2) Selection of the core relation (3) Adding relations necessary for the unity of the phrase's meaning (4) Generating the surface phrase from the constructed graph",
        "First, the sentences in the given document are analyzed to produce directed acyclic graphs (DAGs) constructed from relation units, each of which consists of two nodes (words) and an arc (relation between the words).",
        "Each node is not only a single word but also can be a word sequence (noun group).",
        "Then an important relation is selected as a \"core\" relation.",
        "In Fig. 1, the arc connecting the two shaded nodes is selected as the \"core.\" The core relation alone carries insufficient information to convey the content of the original document.",
        "Additional arcs (represented by preposition).",
        "double lines) are attached to narrow the information the phrase supplies.",
        "The following short phrase can be generated from the selected nodes and arcs in the graph: PICORP licenses (its) environment protection technology to AMICO.3 Phrase-representation summarization enumerates such short phrases to give the readers enough information to grasp the outline of a document.",
        "This algorithm is explained in the next section."
      ]
    },
    {
      "heading": "2.2 Further description of each step",
      "text": [
        "The steps shown in the previous section consists of a cycle that produces a single phrase.",
        "The cycles are repeated until the generated phrases satisfy a predefined condition (e.g. the length of the summary).",
        "The scores of the words used in the cycle are reduced by a predefined cut-clown",
        "ratio to avoid frequent use of the same words in the summary.",
        "The basic algorithm is shown in Fig. 2."
      ]
    },
    {
      "heading": "Relation Analysis",
      "text": [
        "Syntactic analysis is applied to each sentence in the document to produce a DAG of the relations of words.",
        "We use a simple parser based on pattern matching (Miyauchi, et al.",
        "1995), one of whose rules always judges each case dependent on its nearest verb.",
        "Some of the misanalysis will be hidden by \"ambiguity packing\" in the \"additional relation attachment\" step."
      ]
    },
    {
      "heading": "Relation Scoring",
      "text": [
        "An importance score is provided for each relation unit (two nodes and an arc connecting them).",
        "First, every word is scored by its importance.",
        "This score is calculated based on the WIDE value (Salton, 1989)4.",
        "Then, the relation score is calculated as follows:",
        "Here, SI and S2 are the scores of the two words connected by relations.",
        "The score of a word sequence is calculated by decreasing the sum of the scores of its constituent words according to the length of the word sequence.",
        "WI and W2 are the weights given to each word.",
        "Currently, all words are equally treated (W W2 = 1).",
        "Srel is the importance factor of the relation.",
        "The relations that play central roles in the meaning, such as verb cases, are given high scores, and the surrounding relations, such as \"AND\" relations, are scored low.",
        "The relation scores for modifier-modified relations such as adverbs are set to 0 to avoid selecting them as the core relations.",
        "Core relation selection The relation unit with the highest score among all relations is selected as the \"core relation.\"",
        "The information that the core relation carries is usually insufficient.",
        "Additional relations are attached to make the information the phrase IDF is calculated from I million WWW documents gathered by a Web search enuine.",
        "supplies more specific and to give the reader sufficient information to infer the content of the original document.",
        "The following relations are a part of the relations to be attached.",
        "Mandatory cases Relations that correspond to mandatory cases are attached to verbs.",
        "Mandatory case lists are defined for verbs except for those that share the common mandatory case list, which includes \"ga\"-AGENT, \"wo\"-OBJ and \"ni\"DATIVE.",
        "\"M\"-THEME, \"mo\"-ALSO, and null-marker relations are also treated as mandatory, because they can appear in place of the mandatory relations.",
        "Ex.)",
        "AMICO \"ga\"-AGENT release AMIGO \"ga\"-AGENT PDA \"wo\"-OBJ release (AMIGO releases PDA.)",
        "Noun modified by a verb In Japanese, the \"verb - noun\" structure represents an embedded sentence, and the noun usually fills some gap in the embedded sentence.",
        "If the verb in the core relation (noun -- verb) consists of such a verb – noun relation, the modified noun is also assumed to carry important information, even if it does not fill the mandatory case (though the case is not",
        "(a plan to release PDA) Ambiguity packing The analysis trees often contain errors because the pattern-base parser doesn't resolve ambiguities.",
        "For example, the structure V 0-THAT N1 \"rio\"-OF N2 (Virg N l's N2) is ambiguous in Japanese (V can modify either N1 or N2 but the parser always analyzes N2 as modified).",
        "If the V-N I relation is selected as the core, the N1-N2 relation is always attached to the core to include the possible V-N2 relation.",
        "Modifiers of generic nouns The concepts brought by generic nouns such as \"mono\" (thing), \"koto\" (\"that- of that-clause), \"haat\" (case), jiorai\" (era) are not so specific that they usually accompany modifiers to be informative.",
        "Here such modifiers are attached to make them informative.",
        "Ex.)",
        "era \"M\"-TIME emerge confusion \"no\"-OE era \"ni\"-TIME emerge (emerged in the era of confusion)"
      ]
    },
    {
      "heading": "Termination condition",
      "text": [
        "Judges whether the summaries created so far are sufficient.",
        "Currently the termination condition is defined by either the number of produced phrases or the total summary length.",
        "If the condition is not fulfilled, these steps from selection of the core relation must he repeated to create another phrase.",
        "Before selecting a new core, the scores of the words used in this cycle are reduced to increase the possibility for other words to he used in the next phrase.",
        "Score reduction is achieved by multiplying the predefined cut-down ratio R (0 < R < 1) by the scores of the words \"0\" shows that there are no particles or any other words connecting two words.",
        "Japanese doesn't require anything like relative pronouns.",
        "used.",
        "Relation scores are recalculated using the new word scores.",
        "Generation of surface phrases This process produces DAGs each of which consists of one core relation and several attached relations.",
        "In Japanese, the surface phrases can be easily obtained by connecting the surface string of the nodes in their original order.",
        "See Chapter 5 for the generation method for English."
      ]
    },
    {
      "heading": "3 The Prototype",
      "text": [
        "We developed a prototype of the summarization system based on this algorithm.",
        "The development language is Java and the system is working on Windows 95/98/NT and Solaris 2.66.",
        "The time consumed by summarization process is in proportion to the text length and it takes about 700 msec to generate a summary for an A4 sized document (2000 Japanese characters) using a PC with a Celeron processor (500 MHz).",
        "Over 95% of the time is consumed in the relation analysis step."
      ]
    },
    {
      "heading": "4 Evaluation",
      "text": [
        "We have conducted an experiment to evaluate the system.",
        "This section is a short summary of the experiment reported in (Oka and Ueda, 2000).",
        "The aim of a phrase-represented summary is to give fast and accurate sifting of IR results.",
        "To evaluate whether the aim was achieved, we adopted a task-based evaluation (Jing, et al.",
        "1998, Mani, et al.",
        "1998).",
        "One of the problems of those experiments using human subjects as assessors is inaccuracy caused by the diversity of assessment.",
        "To reduce the diversity, first we assign 10 subjects (experiment participants) for each summary sample.",
        "The number of subjects was ‘just I or 2 in the previous task-based experiments.",
        "Second, we gave the subjects a detailed instruction including the situation that led them to search the W \\A/W."
      ]
    },
    {
      "heading": "4.1 Experiment Method",
      "text": [
        "The outline of the evaluation is as follows: Java and Solaris are the trademarks of Sun Microsystems.",
        "Windows and Celeron are the trademarks or Microsoft and Intel, respectively.",
        "• Assume an Information need and make a query for the information need • Prepare simulated WWW search results with different types of summaries; (A) first 80 characters, (B) important sentence selection (Zechner, 1996), (C) phrase-represented summary, (D) keyword enumeration.",
        "The documents in the simulated search result set are selected so that the set includes an appropriate number of relevant documents and irrelevant documents.",
        "• Have subjects judge from the summaries the relevance between the search results and the given information need.",
        "The judgement is expressed in four levels (from higher to lower: L3, L2, LI, and LO, which is judged to be irrelevant).",
        "• Compare the relevance with the one that we assumed.",
        "The documents the user judges to be relevant compose a subset of the IR results and it should be more relevant to the information need than the IR results themselves.",
        "Because we have introduced three relevance levels, we can assume three kinds of the subsets; L3 only, L3+1,2, and L3+L2+L .",
        "The subset composed only from the documents with L3 judgement should have a high precision score and the subset including LI documents should get a high recall score."
      ]
    },
    {
      "heading": "4.2 Result",
      "text": [
        "Because recall and precision are in a trade-off relation, here we show the result using f-measure, the balanced score of the two indexes.",
        "The f-measure averages of the experiment result of three different tasks are shown in Fig. 3.",
        "It shows that the phrase-represented summaries (C) are more suitable for sifting search results than any other summaries in all cases."
      ]
    },
    {
      "heading": "4.3 Discussion",
      "text": [
        "The result can be explained using the number of summaries that contain clues to the information need.",
        "Summaries consisting of short units (phrases (C) and keywords (D)) are gathered from the wide range of the original text and accordingly have many chances to include the clues.",
        "The actual average numbers of summaries that",
        "contain the clues are 2.0, 4.3 and 4.7 for (B) sentence, (C) phrases and (D) keywords, respectively.",
        "In spite that (D) keywords include more clues than any other samples, they don't get a good f-score.",
        "The reason is considered to be due to the lack of information about the relations among keywords."
      ]
    },
    {
      "heading": "5 Applicability to Other Languages",
      "text": [
        "Although this algorithm was first developed for the Japanese language, the concept of phrase-representation summarization is also applicable to other languages.",
        "Here we show the direction toward its extension to English.",
        "English has a clear concept of \"phrase,\" and simply connected words do not produce well-formed phrases.",
        "This requires semantic analysis and generation from the semantic structure.",
        "We will consider the following example again.",
        "Ex.)",
        "A venture company PICORP announced to license their environment protection technology to AMICO, a U.S. top company.",
        "If \"PICORP\" and \"license\" must be included in the summary and \"announce\" is not so important, \"PICORP license(s)\" is the core of the desired phrase.",
        "Generating it requires subject resolution of \"license\" and thus semantic level analysis is required.",
        "Moreover, predicate-argument structures are preferable to syntactic trees because the subject and the object are represented in the same level.",
        "Unification grammar frameworks such as LEG (Kaplan and Bresnan, 1982) and HPSCi (Pollard and Sag, 1994) fulfill these requirements.",
        "Fig.",
        "4 is a part of the analysis result represented in LF(i.",
        "A score is calculated for each feature structure and the core feature structure will he selected by its score instead of selecting a core relation and attaching mandatory relations.",
        "In the core feature structure, index.",
        "[I] is replaced by SUDJ of the top feature structure.",
        "Generating phrases from the feature structure requires templates7.",
        "Several patterns can be selected to generate phrases: V-ing (gerund) form ARG1's PRED-ing ARG2 to ARG3 noun form ARG1's noun (PRED) of ARG2 to ARG3 to-infinitive form For ARG1 to PRED ARG2 to ARG3 In this case, the noun form \" PICORP's license of the protection technology to AMIGO\"' is avoided because the noun \"license\" lacks the meaning of \"action\" or \"event.\" Other rules specific to headlines such as \"to-in Fin itive represents future'' can also be introduced."
      ]
    },
    {
      "heading": "6 Related Work",
      "text": [
        "Most summarization studies (including lechner, 1996) are based on important sentence selection and seek better selection methods.",
        "We have",
        "pointed out that summaries made by this method tend to he burdensome to read, and have proposed phrase-representation summarization as an alternative.",
        "The following studies bear some relation to our study.",
        "The summarization method by Boguraev and Kennedy (1997) adopts \"phrasal expression\" rather than sentences or paragraphs.",
        "However, it begins to create a phrase not from a core relation but a core word (in their words, \"topic stamp\") and produces multiple phrases containing the same core word; it is therefore not suitable for summaries for sifting IR results.",
        "In addition, because it does not consider the roles and importance of the attaching arcs when enriching the core, less important words are often attached to the core.",
        "They aimed at supporting fast reading rather than sifting IR results.",
        "Sonic studies are similar to ours in that they make sentences short.",
        "Wakao, et al.",
        "(1998) and Mikami, et al.",
        "(1998) aim to create closed captioning from an announcer's manuscript by paraphrasing and removing modifiers.",
        "This method doesn't remove the \"trunk\" of the analysis tree and the summaries cannot he made as short as in phrase-representation.",
        "Nagao, et al.",
        "(1998) also proposed a method to create summarization based on the relations",
        "between words.",
        "They utilize GDA (Global Document Annotation), a tag set that the document author inserts into the document and that contains linguistic information such as sentence structures and reference information.",
        "Although this method is similar to ours in some points, the summary consists of sentences and thus does not have \"at-a-glance\" capability.",
        "Most of all, the expectation that every document is tagged linguistically will not be fulfilled until special editors with automatic linguistic tagging become popular."
      ]
    },
    {
      "heading": "Conclusion",
      "text": [
        "We introduced the concept of \"at-a-glance\" summary and showed an algorithm of phrase-representation summarization as a realization of the concept.",
        "An experiment shows that the summaries are effective for sifting IR results.",
        "We continue to fine-tune the prototype for further efficacy."
      ]
    },
    {
      "heading": "Acknowledgement",
      "text": [
        "We would like to thank our laboratory members who give us valuable suggestions and participated in the experiment."
      ]
    }
  ]
}
