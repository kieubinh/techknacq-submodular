{
  "info": {
    "authors": [
      "Hideo Watanabe",
      "Sadao Kurohashi",
      "Eiji Aramaki"
    ],
    "book": "International Conference on Computational Linguistics",
    "id": "acl-C00-2131",
    "title": "Finding Structural Correspondences from Bilingual Parsed Corpus for Corpus-Based Translation",
    "url": "https://aclweb.org/anthology/C00-2131",
    "year": 2000
  },
  "references": [
    "acl-C90-3044",
    "acl-C92-2101",
    "acl-C92-2115",
    "acl-C96-1078",
    "acl-C96-2211",
    "acl-J80-1003",
    "acl-J94-4001",
    "acl-P93-1004",
    "acl-P96-1020",
    "acl-P98-2223"
  ],
  "sections": [
    {
      "heading": "Abstract",
      "text": [
        "In tins paper, we describe a system and methods for finding structural correspondences from the paired dependency structures of a source sentence and its translation in a target language.",
        "The system we have developed finds word correspondences first, then finds phrasal correspondences based on word correspondences.",
        "We have also developed a GUI system with winch a user can check and correct the correspondences retrieved by the system.",
        "These structural correspondences will be used as raw translation patterns in a corpus-based translation system."
      ]
    },
    {
      "heading": "1 Introduction",
      "text": [
        "So far, a number of methodologies and systems for machine translation using large corpora exist.",
        "They include example-based approaches [7, 8, 9, 12], pattern-based approaches [10, 11, 14], and statistical approaches.",
        "For instance, example-based approaches use a large set of translation patterns each of winch is a pair of parsed structures of a source-language fragment and its target-language translation fragment.",
        "Figure 1 shows an example of translation by an example-based method, in winch translation patterns (p1) and (p2) are selected as similar to a (left hand) Japanese dependency structure, and an (right hand) English dependency structure is constructed by merging the target parts of these translation patterns'.",
        "In this kind of system, it is very important to collect a large set of translation patterns easily and efficiently.",
        "Previous systems, however, collect such translation patterns mostly manually.",
        "Therefore, they have problems in terms of the development cost.",
        "'Words in parenthesis at the nodes of the Japanese dependency structure are representative English translations, and are for explanation.",
        "This paper tries to provide solutions for this issue by proposing methods for finding structural correspondences of parsed trees of a translation pair.",
        "These structural correspondences are used as bases of translation patterns in corpus-based approaches.",
        "Figure 2 shows an example of extracting structural correspondences.",
        "In this figure, the left tree is a Japanese dependency tree, the right tree is a dependency tree of its English translation, dotted arrows represent word correspondence, and a pair of boxes connected by a solid line represent phrasal correspondence.",
        "We would like to extract these",
        "word and phrasal correspondences automatically.",
        "In what follows, we will describe details of procedures for finding these structural correspondences."
      ]
    },
    {
      "heading": "2 Finding Structural Correspondences",
      "text": [
        "Tins section describes methods for finding structural correspondences for a paired parsed trees."
      ]
    },
    {
      "heading": "2.1 Data Structure",
      "text": [
        "Before going into the details of finding structural correspondences, we describe the data format of a",
        "dependency structure.",
        "A dependency structure as used in tins paper is a tree consisting of nodes and links (or arcs), where a node represents a content word, while a link represents a functional word or a relation between content words.",
        "For instance, as shown in Figure 2, a preposition \"at\" is represented as a link in English."
      ]
    },
    {
      "heading": "2.2 Finding Word Correspondences",
      "text": [
        "The, first task for finding structural correspondences is to find word correspondences between the nodes of a source parsed tree and the nodes of a target parsed tree.",
        "Word correspondences are found by consulting a source-to-target translation dictionary.",
        "Most words call find a unique translation candidate in a target tree, but there are cases such that there are many translation candidates in a target parsed tree for a source word.",
        "Therefore, the main task of finding word correspondences is to determine the most plausible translation word among candidates.",
        "We call a pair of a source word and its translation candidate word in a target tree a word correspondence candidate denoted by WC(s, t), where s is a source word and t is a target word.",
        "If WC(s, t) is a word correspondence candidate such that there is no other WC originating from s, then it is called WA word correspondence.",
        "The basic idea to select the most plausible word correspondence candidate is to select a candidate which is near to another word correspondence whose source is also near to a source word in question.",
        "Suppose a source wor translation target words ti (i = 1, ..., it), that is, there are multiple WCs originating from s. We denote these multiple word correspondence candidates by Il7C(8,4).",
        "For each WC of s, tins procedure finds the neighbor WA correspondence whose distance to WC is below a threshold.",
        "The distance between WC(si, t1) and WA(s2, i2) is defined as the distance between si and s• plus the distance between 52 and t2 where a distance between two nodes is defined as the number of nodes in the path whose ends are the two nodes.",
        "Among Wes of s for which neighbor W A is found, the one with the smallest distance is chosen as the word correspondence of s, and WCs which are not chosen are invalidated (or deleted).",
        "We call a word correspondence found by this procedure T'VX.",
        "We use 3 as the distance threshold of the above procedure currently.",
        "This procedure is applied to all source nodes which have multiple WCs.",
        "Figure 3 shows an example of WX word correspondence.",
        "In this example, since the Japanese word \"ki\" has two English translation word candidates \"time\" and \"period,\" there are two WCs (WCI and WC2).",
        "The direct parent node \"yuuryo\" of \"ki\" has a WA correspondence (Will) to \"concern,\" and the direct child node \"ikou\" has also a WA correspondence (WA2) to \"transition.\"",
        "In this case, since the distance between WC2 and WA2 is smaller than the distance between Wel and , WC• is changed to a W X, and WC1 is adandoned.",
        "In addition to W X correspondences, we consider a special case such that given a word correspondence W(s, t), if s has only one child node which is d s has multiple candidate",
        "a leaf and t has also only one child node winch is a leaf, then we construct a new word correspondence called WS from these two leaf nodes.",
        "This WS procedure is applied to all word correspondences.",
        "Note that this word correspondence is not to select one of candidates, rather it is a new finding of word correspondence by utilizing a special structure.",
        "For instance, in Figure 3, if there is a word correspondence between \"ki\" and \"period\" and there is no word correspondence between \"ikou\" and \"transition,\" then II7S(ikou, transition) will be found by this procedure.",
        "These 1VX and W S procedures are continuously applied until no new word correspondences are found.",
        "After applying the above I47X and WS procedures, there are sonic target words t such that t is a destination of a TVC(s, t) and there is no other WC whose destination is t. In tins case, the IFC(s, /;) correspondence candidate is chosen as a valid word correspondence between s and 1, and it is called a IVZ word correspondence.",
        "We call a source node or a target node of a word correspondence an anchor node in what follows.",
        "The above procedures for finding word correspondences are summarized as follows: Find WCs by consulting translation dictionary; Find WAs; while (true) { find WXs; find 147Ss; if no new word corresp.",
        "is found, then break; } find W Zs;"
      ]
    },
    {
      "heading": "2.3 Finding Phrasal Correspondences",
      "text": [
        "The next step is to find phrasal correspondences based on word correspondences found by procedures described in the previous section.",
        "What we would like to retrieve here is a set of phrasal correspondences which covers all elements of a paired dependency trees.",
        "In what follows, we call a portion of a tree winch consists of nodes in a path from.",
        "a node am to another node n2 which is a descendant; of 71,1 a linear tree denoted by LT(711,71,2), and we denote a minimal subtree including specified nodes ni , by T(ni , nx).",
        "For instance, in the English tree structure (the right tree) in Figure 4, LT(technology, science) is a rectangular area covering \"technology,\" and \"science,\" and T(f actor, country) is a polygonal area covering \"factor,\" \"affect,\" \"policy,\" and \"country.\"",
        "The first step is to find a pair of word correspondences Wi(s1,1,1) and 1472 (s2, 12) such that si and s2 constructs a linear tree LT (si, s9) and there is no anchor node in the path from si to s2 other than si and s9, where Wi and W., denote any type of word correspondences2 and we assume there is a word correspondence between roots of source and target trees by default.",
        "We construct a phrasal correspondence from source nodes in LT (s1, s9) and target nodes in IV] , t9), denoted by P(LT(si , s9), T(tt, 12)).",
        "For instance, in Figure 4, Pi 2, P9, P3 and P4 are source portions of phrasal correspondences found in this step.",
        "The next step checks, for each P, if all anchor nodes of word correspondences whose source or target node is included in P are also included in P. If a phrasal correspondence satisfies this condition, then it is called closed, otherwise it is called open.",
        "Further, nodes which are not included in the P in question are called open nodes.",
        "If a 1' is open, then it is merged with other phrasal correspondences having open nodes of P so that the merged phrasal correspondence becomes closed.",
        "Next, each pa, is checked if there is another P., which shares any nodes other than anchor nodes with Pa,.",
        "If this is the case, these and Py are merged into one phrasal correspondence.",
        "In Figure 4, phrasal correspondences 1 iu and P12 are merged into P1, since their source portions LT (haikei, 1;706) and LT (haikei, seisaku) share \"doukou\" which is not an anchor node.",
        "Finally, any path whose nodes other than the root are not included in any Ps but the root node is included in a P is searched for.",
        "Tins procedure 2 Since 147C is not a word correspondence (it is a candidate Of word correspondence), it is not considered here.",
        "is applied to both source and target trees.",
        "A path found by this procedure is called an open path, and its root node is called a pivot.",
        "If such an open path is found, it is processed as follows: For each pivot node, (a) if the pivot is not an anchor node, then open paths originating from the pivot is merged into a P having the pivot, (b) if the pivot is an anchor node, then a new phrasal correspondence is created from.",
        "open paths originating from the anchor nodes of the word correspondence.",
        "In Figure 4, we get finally four phrasal correspondences 1 i, 1'3, and P4.",
        "spondences The above procedures for finding phrasal correspondences are summarized as follows: Find initial Ps; Merge an open with other Ps having open nodes of Pi; Create new Ps by merging Ps which have more than 2 common nodes; Find open path, and if the pivot is an anchor, then merge the path to having the anchor, otherwise create new 1' by merging all open paths having the pivot;"
      ]
    },
    {
      "heading": "3 Experiments",
      "text": []
    },
    {
      "heading": "3.1 Corpus and Dictionary",
      "text": [
        "We used documents from White Papers on Science mid Technology (1.994 to 1996) published by the Science and Technology Agency (STA) of the :Japanese government.",
        "STA published these White Papers in both Japanese and English.",
        "The Communications Research Laboratory of the Ministry of Posts and Telecommunication of the Japanese government supplied us with the bilingual corpus which is already roughly aligned.",
        "We made a bilingual corpus consisting of parsed dependency structures by using the KNP [2] Japanese parser (developed by Kyoto University) for Japanese sentences and the ESG[5] English parser (developed by 173M Watson.",
        "Research Center) for English sentences.",
        "We made about 500 sentence pairs, each of which has a one-to-one sentence correspondence, from the raw data of the White Papers, and selected randomly about 130 sentence pairs for experiments.",
        "However, since a parser does not always produce correct parse trees, we excluded some sentence pairs which have severe parse errors, and finally got 11.5 sentence pairs as a test set.",
        "As a translation word dictionary between Japanese and English, we first used J-to-1 translation dictionary which has more than 100,000 entries, but we found that there are some word correspondences not covered in this dictionary.",
        "Therefore, we merged entries from llt-to-.1 translation (fictional-3, in order to get nruch broad coverage.",
        "The total nuniber of entries are now more than 150,000."
      ]
    },
    {
      "heading": "3.2 Experimental Results",
      "text": [
        "Table 1 shows the result of experiment for finding word correspondences.",
        "A row with ALL in the type column shows the total accuracy of word correspondences mud other rows show the accuracy of each type.",
        "It is clear that WA correspondences have a very high accuracy.",
        "Other word correspondences also have a relatively high accuracy.",
        "Table 2 shows the result of experiments for finding phrasal correspondences.",
        "The row with ALL in the type column shows the total accuracy of phrasal correspondences found by the proposed procedure.",
        "This accuracy level is not promising and it is not useful for later processes since it needs human checking, and correction.",
        "Therefore, we subcategorize each phrasal correspondences, and check the accuracy for each subcategory.",
        "We consider the following subcategories for phrasal correspondences:",
        "• MIN ...",
        "The minimal phrasal correspondence, that is, P(Ll'(si, s9), , t2)) such that there",
        "are word correspondences TV (31,14) and IV (s2, t2), 32 is a direct child of si and t2 is a direct child of t1.",
        "• LTX P(LT (81, 82), LT (t.1, t2)) such that all nodes other than 32 and t2 have only one child node.",
        "• LTY P(LT(si, 82), LT(ti, t2)) such that",
        "all nodes other than s2, ti and t2 have only one child node.",
        "LTX is a special case of LTY, since si and t1 of LTX must have only one child node, on the other hand, ones of LTY may have more than two child nodes.",
        "A subcategory test for a phrasal correspondence is done in the above order.",
        "Examples of these subcategories are shown in Fig 5.",
        "The result of these subcategories are also shown in Table 2.",
        "Subcategories MIN and LTX have very high accuracy and this result is very promising, since we can avoid manual checking for these phrasal correspondences, or we would check only these types of phrasal correspondences manually and discard other types.",
        "As stated earlier, since we removed only sentences with severe parsing errors from the test set, please note that the above numbers of experimental results are calculated for a bilingual parsed corpus including parsing errors."
      ]
    },
    {
      "heading": "4 Discussion",
      "text": [
        "There have been some studies on structural alignment of bilingual texts such as [1, 4, 13, 3, 6].",
        "Our work is similar to these previous studies at the conceptual level, but different in some aspects.",
        "[1] reported a method for extracting translation templates by CKY parsing of bilingual sentences.",
        "Tins work is to get phrase-structure level phrasal correspondences, but our work is to get dependency-structure level phrasal correspondences.",
        "[4] proposed a method for extracting structural matching (pairs of dependency trees) by calculating matching similarities of two dependency structures.",
        "Their work focuses on the parsing ambiguity resolution by calculating structural matching.",
        "Further, [3, 6] proposed structural alignment of dependency structures.",
        "Their work assumed that least common ancestors of each fragment of a structural correspondence are preserved, but our work does not have such structural restriction.",
        "[13] is different to others in that it tries to find phrasal correspondences by comparing a MT result and its manual correction.",
        "In addition to these differences, the main difference is to find classes (or categories) of phrasal correspondences which have high accuracy.",
        "In general, since bilingual structural alignment is very complicated and difficult task, it is very hard to get more than 90% accuracy in total.",
        "If we get only such an accuracy rate, the result is not useful, since we need manual checks for the all correspondences retrieved.",
        "But, if we can get some classes of phrasal correspondence with, for instance, more than 90% accuracy rate, then we can reduce manual checking for phrasal correspondences in such classes, and this reduces the development cost of translation patterns used in later corpus-based translation process.",
        "As shown in the previous section, we could find that all classes of word correspondences and two subclasses of phrasal correspondences are more than 90% accurate.",
        "When actually using this automatically retrieved structural correspondence data, we must consider how to manually correct; the incomplete parts and how to reuse manual correction data if the parser results are changed.",
        "As for the former issue, we need an easy-to-use tool to modify correspondences to reduce the cost of manual operation.",
        "We have developed a GUI tool as shown in Figure 6.",
        "In tins figure, the bottom half presents a pair of source and target dependency structures with word correspondences (solid lines) and phrasal correspondences (sequences of shaded circles).",
        "You can easily correct correspondences by looking at this graphical presentation.",
        "As for the latter issue, we must develop methods for reusing the manual correction data as much as possible even if the parser outputs are changed.",
        "We have developed a tool for attaching phrasal correspondences by using existing phrasal correspondence data.",
        "This is implemented as follows: Each phrasal correspondence is assigned a signature which is a pair of source and target sentences, each of which has bracketed segments which are included in the phrasal correspondence.",
        "For instance,",
        "the following signature is made for a phrasal correspondence (c) in Figure 5: (sig) [korera no kanten karano] kagaku [gi-jutu] ... science and [technology from this purpose] ... (/siq) In the above example, segments between '[' and ']' represent a phrasal correspondence.",
        "If new parsed dependency structures for a sentence pair is given, for each phrasal correspondence signature of the sentence pair, nodes in the structures which are inside brackets of the signature are marked, and if there is a minimal subtree consisting of only marked nodes, then a phrasal correspondence is reconstructed from the phrasal correspondence signature.",
        "By using this tool, we can efficiently reuse the manual efforts as much as possible even if parsers are updated."
      ]
    },
    {
      "heading": "5 Conclusion",
      "text": [
        "in this paper, we have proposed methods for finding structural correspondences (word correspondences and phrasal correspondences) of bilingual parsed corpus.",
        "Further, we showed that the precision of word correspondences and some categories of phrasal correspondences found by our methods are highly accurate, and these correspondences can reduce the cost of translation pattern accumulation.",
        "In addition to these results, we showed a GUI tool for manual correction and a tool for reusing previous correspondence data.",
        "As future directions, we will find more subclasses with high accuracy to reduce the cost for translation pattern preparation.",
        "We believe that these methods and tools can accelerate the collection of a large set of translation patterns and the development of a corpus-based translation system.",
        "• .",
        ".",
        "..... ... .",
        ".rel id=\"28\" type=\"P4\" src=\"3,4,9,10,11,12,13\" tgt=\"1,2,3,4,8,9,1 7 evat=\"TRUE\" score=\"0\" generation, – stiblype=\"org\" or g=\"'\" comment, – > \"rel id=\"29\" type=\"P5\" src=\"1,2,3\" tgt,\"10,11,1 T eyal=\"TRUP score=\"0\" generation,- subtype=\"org\" org,\"\" comment,\"\"\" srel id=\"30\"type=\"P5\" src=\"5,6,7\" tgt=\"5,6,7\" eva\"TRUE\" score=\"0\" generation, – sublype=\"org\" org=\"\" comment.\"'\"",
        "srel id=\"31\" type=\"P5\" src=\"7,8,9\" tgl=\"7,8\" eyal=\"TRUE\" score=\"0\" generation. – subtype=\"org\" org=\"\" comment, – \" srel id=\"32\" type=\"P5\" src=\"3,4,9,10,11,12,13\" tgt=\"1,2,3,4,8,9,12\" eyal=\"TRUE\" score=\"0\" generation, – subtype=\"org\" org,'\" comment,'\"\""
      ]
    }
  ]
}
