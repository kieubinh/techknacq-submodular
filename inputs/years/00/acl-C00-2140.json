{
  "info": {
    "authors": [
      "Klaus Zechner",
      "Alex Waibel"
    ],
    "book": "International Conference on Computational Linguistics",
    "id": "acl-C00-2140",
    "title": "DIASUMM: Flexible Summarization of Spontaneous Dialogues in Unrestricted Domains",
    "url": "https://aclweb.org/anthology/C00-2140",
    "year": 2000
  },
  "references": [
    "acl-A00-1043",
    "acl-A00-2025",
    "acl-A97-1003",
    "acl-J97-1003",
    "acl-P98-2237",
    "acl-W97-0702",
    "acl-W97-0703",
    "acl-W98-1421"
  ],
  "sections": [
    {
      "heading": "Abstract",
      "text": [
        "in this paper, we present a summarization system for spontaneous dialogues which consists of a. novel multi-stage architecture.",
        "It is specifically aimed at addressing issues related to the nature of the texts being spoken vs. written and being dialogical vs. monological.",
        "The system is embedded in a graphical user interface and was developed and tested on transcripts of recorded telephone conversations in English and Spanish (CALI.,00m)."
      ]
    },
    {
      "heading": "1 Introduction",
      "text": [
        "Summarization of written documents has recently been a. focus for much research in NLP (e.g., (Mani and Maybury, 1997; AAA1, 1998; Mani et al., 1998; ACL, 2000), to name some of the major events in this field in the past few years).",
        "However, very little attention has been given so far to the summarization of spoken language, even less of conversations vs. monological texts.",
        "We believe that summarization of speech will become increasingly more important, as the amount of online audio data grows and demand for rapid browsing, skimming, and access of speech data increases.",
        "Another application which particularly pertains to our interest in spoken dialogue summarization would be the generation of meeting minutes for archival purposes and/or to update participants joining at later stages on the progress of the conversation so far.",
        "Summarization of dialogues within limited domains has been attempted within the context of the VERBMOBIL project (\"protocol generation\", (Alexandersson and Pallor, 1998)) or by SRI's MIMI summarizer (Kameyama et al., 1996).",
        "Recent work on spoken language summarization in unrestricted domains has focused almost exclusively on Broadcast News, mostly due to the spoken language track of recent TREC evaluations (Garofalo et al., 1997; Garofalo et al., 1999).",
        "(Waibel et al., 1998) describe a Meeting Browser where summaries can be generated using technology established for written texts.",
        "(Valenza et al., 1.999) go one step further and incorporate knowledge from the speech recognizer (confidence scores) into their summarization system, as well.",
        "We argue that the nature of spoken dialogues, together with their textual representations as speech recognizer hypotheses, requires a. set of specific approaches to make summarization feasible for this text genre.",
        "As a demonstrable proof of concept, we present the multi-stage architecture of the summarization system DIASUMM which can flexibly deal with spoken dialogues in English and Spanish, without any restrictions of domain.",
        "Since it cannot rely on any domain specific knowledge base, it uses shallow statistical approaches and presents (possibly modified) extracts from the original text as summary.",
        "We present results of several evaluations of our system using human transcripts of spontaneous telephone conversations in English and Spanish from the CALLnomE corpus ((LDC), 1996), in particular the accuracy of the topic segmentation and information condensing components (sections 6 and 7).",
        "Also, for the purpose of a global evaluation, a user study was performed which addressed information access time and accuracy of retained information comparing different versions of summaries (section 10).",
        "This paper is organized as follows: in the next section, we provide an overview about the main issues for summarization of spoken dialogues and indicate the approaches we are taking in our system.",
        "We then present the system architecture (section 3), followed by a detailed description of the major building blocks (sections 4 to 8).",
        "After a brief characterization of the GUI (section 9) we describe a user study for global system evaluation in section 10.",
        "We conclude the paper with a summary and a brief outlook in section 11.."
      ]
    },
    {
      "heading": "2 issues and Approaches: Overview",
      "text": [
        "In this section, we give an overview about the main issues that any summarization system for spoken dialogues has to address and indicate the approach we are taking for each of these in DIASumm.",
        "In a. general sense, when dealing with written texts, usually there is plenty of information available which can be used for the purpose of summa",
        "fixation, such as capitalization, punctuation marks, titles, passage headers, paragraph boundaries, or other mark-ups.",
        "Unfortunately, however, nonc of this holds for speech data which arrives as a stream of word tokens from a recognizer, (lt into \"utterantes \" by using a silence heuristic."
      ]
    },
    {
      "heading": "2.1 Lack of (111150 boundaries",
      "text": [
        "One of the most serious issues is the lack of sentence or clause boundaries in spoken dialogues which is particularly problematic since sentences, clauses, or paragraphs are considered the \"minimal units\" in virtually all existing summarization systems.",
        "When humans speak, they sometimes pause during a clause, and not always at the end of a clause, which means that the output of a recognize!.",
        "(which usually uses some silence-heuristics to cut the segments) frequently does not match logical sentence or clause boundaries.",
        "Looking at five English CA1,1,1101\\11,', dialogues with an average number of 320 utterances each, we find On average 30 such \"continuations\" of logical clauses over automatically determined acoustic segment boundaries.",
        "In a summary, this can cause a reduction in coherence mid readability of the output.",
        "We address this issue by linking adjacent, turns of the same speaker together if the silence between them is less than a given constant (section 1).",
        "2.2 Distributed information Since we have multi-party conversations as opposed to monological texts, sometimes the crucial illation is found in a question-answer-pair, i.e., it involves more than one speaker; extracting only the question or only the answer would be meaningless ill many cases.",
        "We found that on average about 10% of the speaker turns belong to such question-answer pairs in five examined :English CALLITOME dialogues.",
        "Often, either the question or the answer is very short, and does not contain any words with high relevance.",
        "In order not to \"lose\" these short, turns at a later stage, when only the most.",
        "relevant turns are extracted, we link them to the matching question/answer ahead of Lillie, using two different methods to detect questions and their answers (section 4)."
      ]
    },
    {
      "heading": "2.3 Disfluera speech",
      "text": [
        "Speech disfluencies in spontaneous conversations such as fillers, repetitions, repairs, or unfinished clauses --- can make transcripts (and summary ex tracts) quite hard to read and also introduce an unwanted bias to relevance computations (e.g., word repetitions would cause a higher word count for the repeated content words; words in unfinished clauses would be included in the word count.)",
        "lfo alleviate this problem, we employ a clean-up filter pipeline, which eliminates filler words and repetitions, and segments the turns into short clauses (section 5).",
        "We also remove incomplete clauses, typically sentence-initial repairs, at this stage of our system.",
        "This \"cleaning-up\" serves two main purposes: (i) it increases the readability (for the finally extracted segments); and (ii) it makes the text more tractable by subsequent modules.",
        "'Ile following example compares a turn before and after the clean-up component:"
      ]
    },
    {
      "heading": "2.4 Lack of topic boundaries",
      "text": [
        "CALLHO E speech data is multi-topical hut does not include mark-up for paragraphs, nor any topic-inlbrmative headers.",
        "Typically, we find about 5--.10 different topics within a 10-minute segment of a dialogue, i.e., the topic changes about every 1.- 2 minutes in these conversations.",
        "To facilitate browsing and sminnarization, we thus have to discover topically coherent segments automatically.",
        "This is done using a TextTiling approach, adapted from (Hearst, 1997) (section 6).",
        "2.5 Speech recognize]: errors Last but not least, we face the problem of imperfect word accuracy of speech recognizers, particularly when dealing with spontaneous speech over a. large vocabulary mid over a low bandwidthcharuiel such as the CALI,nomE databases which we mainly used for development, testing, !Ind evaluation of our system.",
        "Current recognizers typically exhibit word error rates for these corpora in the order of 50%.",
        "In DiASumm's information condensation component, the relevance weights of speaker turns can be adjusted to take into account their word confidence scores front the speech recognizer.",
        "'I'hat way we can reduce the likelihood of extracting passages with a larger amount of word misrecognitions (Zechner and Waibel, 2000).",
        "hi this paper, however, the focus will be exclusively on results of our evaluations on lin-Illall generated transcripts.",
        "No information front the speech recognizer nor from the acoustic signal (other than inter-utterance pause durations) are used.",
        "We are aware that in particular prosodic information may be of help for tasks such as the detection of sentence boundaries, speech acts, or topic boundaries (Hirschberg' and Nakatani, 1998; Shriberg et al., 1998; Stolcke et al., 2000), but the investigation of the integration of this additional source of information is beyond the scope of this paper and left for future work."
      ]
    },
    {
      "heading": "3 System Architecture",
      "text": [
        "The global system architecture of DIASumm is a, pipeline of the following four major components:",
        "turn linking; clean-up filter; topic segmentation; and information condensation.",
        "A. fifth component is added at the end for the purpose of telegraphic reduction, so that we can maximize the information content in a given amount of space.",
        "The system architecture is shown in Figure 1.",
        "It also indicates the three major types of summaries which can be generated by DIA SUMM: TRANS (\"transcript\"): not using the linking and clean-up components; CLEAN: using the main four components; TELE (\"telegraphic\" summary): additionally, using the telegraphic reduction component.",
        "The following sections describe the components of DIASumm in more detail."
      ]
    },
    {
      "heading": "4 Turn Linking",
      "text": [
        "The two main objectives of this component are: (i) to form turns which contain a. set of full (and not partial) clauses; and (ii) to form turn-pairs in cases where we have a question-answer pair in the dialogue.",
        "To achieve the first objective, we scan the input for adjacent turns of one speaker and link them together if their time-stamp distance is below a pre-specified threshold 0.",
        "If the threshold is too small, we don't get most of the (logical) turn continuations across utterance boundaries, if it is too large, we run the risk of \"skipping\" over short but potentially relevant fragments of the speaker on the other channel.",
        "We experimented with thresholds between 0.0 and 2.0 seconds and determined a local performance maximum around 0 = 1.0.",
        "For the second objective, to form turn-pairs which comprise a question-answer information exchange between two dialogue participants, we need to detect wh- and yes-no-questions in the dialogue.",
        "We tested",
        "two approaches: (a) a HIVIM based speech act (SA) classifier (Ries, 1999) and (b) a set of part-of-speech (POS) based rules.",
        "The SA.",
        "classifier was trained on dialogues which were manually annotated for speech acts, using parts of the SWITCHBOARD corpus (Godfrey et al., 1992) for English and CALLHOME for Spanish.",
        "The corresponding answers for the detected questions were hypothesized in the first turn with a different speaker, following the question-turn.",
        "Table 1 shows the results of these experiments for 5 English and 5 Spanish CALLBOME dialogues, compared to a baseline of randomly assigning n question speech acts, n being the number of question-turns marked by human annotators.",
        "We report Fr-scores, where F1 = 21'11 with P=precision and 1?..=recall.",
        "P+R We note that while the results for the SA-classifier and the rule-based approach are very similar for English, the rule-based approach yields better results for Spanish.",
        "The much higher random baseline for Spanish can be explained by the higher incidence of questions in the Spanish data (14.9% vs. 5.3% for English)."
      ]
    },
    {
      "heading": "5 Clean-up Filter",
      "text": [
        "The clean-up component is a sequence of modules which serve the purposes of (a) rendering the transcripts more readable, (b) simplifying the input for subsequent components, and (c) avoiding unwanted bias for relevance computations (see section 2).",
        "All this has to happen without losing essential information that could be relevant in a summary.",
        "While other work (Heeman et al., 1.996; Stolcke et al., 1.998) was concerned with building classifiers that can detect and possibly correct various speech disfluencies, our implementation is of a much simpler design.",
        "It does not require as much manual annotated train-Mg data and uses individual components for every major category of disfluency.1",
        "Single or multiple word repetitions, fillers (e.g., \"uhm\"), and discourse markers without semantic content (e.g., \"you know\") are removed from the input, some short forms are expanded (e.g., \"we'll\" 4 \"we will\"), and frequent word sequences are combined into a single token (e.g., \"a lot of\" \"a-lot_of\").",
        "Longer turns are segmented into short clauses, which are defined as consisting of at least a. subject and an inflected verbal form.",
        "While (Stolcke and Shriberg, 1996) use n-grain models for this task, and (GavaMa, et al., 1997) use neural networks, we decided to use a rule-based approach (using word and POS information), whose performance proved to be comparable with the results in the cited papers (Fi > 0.85, error < 0.05).2 For several of the clean-up filter's components, we make use of Brill's POS tagger (Brill, 1994).",
        "For English, we use a modified version of Brill's original tag set, and the tagger was adapted and retrained for spoken language corpora (CALLHOME and SWITCHBOARD) (Zechner, 1997).",
        "For Spanish, we created our own tag set, derived from the ILDC lexicon and from the CRATER project (Lean, 1991), and trained the tagger on manually annotated CAI,I,nomE dialogues.",
        "Furthermore, a POS based shallow chunk parser (Zechner and Waibel, 1998) is used to filter out likely candidates for incomplete clauses due to speech repair or interruption by the other speaker."
      ]
    },
    {
      "heading": "6 Topic Segmentation",
      "text": [
        "Since CA fill OIVIE dialogues are always multi-topical, segmenting them into topical units is an important step in OU• summarization system.",
        "allows us to provide \"signature\" information (frequent content words) about every topic to the user as a help for faster browsing and accessing the data.",
        "Furthermore., the subsequent information condensation component can work on smaller parts of the dialogue and thus operate more efficiently.",
        "Following (Boguraev and Kennedy, 1997; Barzi-lay and Elhadad, 1997) who use Textl'iling (Hearst, 1.997) for their summarization systems of written text, we adapted this algorithm (its block comparison version) for speech data: we choose turns to be minimal units and compute block similarity between blocks of k turns every d turns.",
        "We use 9 English and 15 Spanish CALLimmE dialogues, manually annotated for topic boundaries, to determine the optimum values for a set of TextTiling parameters and at the same time to evaluate the accuracy of this algorithm.",
        "To do this, we ran an n-fold cross-validation (\"jack-knifing\") where all dialogues but one are used to determine the best parameters (\"train set\") and the remaining dialogue is used as",
        "a held-out data set for evaluation (\"test set\").",
        "This process is repeated n times and average results are reported.",
        "Table 2 shows the set of parameters which worked best for most dialogues and Table 3 shows the evaluation results of the cross-validation experiment.",
        "1,1i-scores improve by 18-'24% absolute over the random baseline for unseen and by 23-35% for seen data, the performance for English being better than for Spanish.",
        "'nese results, albeit achieved on a quite different text genre, are well in line with the results in (Hearst, 1997) who reports an absolute improvement of about 20% over a random baseline for seen data."
      ]
    },
    {
      "heading": "7 Information Condensation",
      "text": [
        "The information condensation component is the core of our system.",
        "Its purpose is to determine weights for terms and turns (or linked turn-pairs) and then to rank the turns according to their relevance within each topical segment of the dialogue.",
        "For term-weighting, tf*idf-inspired formulae (Salton and Buckley, 1990) are used to emphasize words which are in the \"middle range\" of frequency in the dialogue and do not appear in a stop list.'",
        ":For turn-ranking, we use a version of the \"maximal marginal relevance\" (MMR) algorithm (Carbonell and Goldstein, 1998), where emphasis is given to turns which contain many highly weighted terms for the current segment (\"salience\") and are sufficiently dissimilar to previously ranked turns (to minimize redundancy) .",
        "For 9 English and 14 Spanish dialogues, the \"most relevant\" turns were marked by human coders.",
        "We ran a series of cross-validation experiments to (a) optimize the parameters of this component related to tfsidf and MMR computation and to (b) determine",
        "how well this information condensing component can match the human relevance annotations.",
        "Summarization results are computed using ill-pt-avg precision scores for ranked turn lists where the maximum precision of the list of retrieved turns is averaged in the 11 evenly spaced intervals between recall=[0,0.1),[0.1,0.2), ... [1.0,1.1) (Salton and McGill, 1983).4 Table 4 shows the results from these experiments.",
        "Similar to other experiments in the summarization literature (Mani et al., 1998), we find a wide performance variation across different texts."
      ]
    },
    {
      "heading": "8 Telegraphic Reduction",
      "text": [
        "The purpose of this component is to maximize information in a fixed amount of space.",
        "We shorten the output of the summarizer to a \"telegraphic style\"; that way, more information can be included in a. summary of k words (or 7/ bytes).",
        "Since we only use shallow methods for textual analysis that do not generate a. dependency structure, we cannot use complex methods for text reduction as described, e.g., in (Ding, 2000).",
        "Our method simply excludes words occurring in the stop list from the summary, except for some highly informative words such as \"1\" or \"not\"."
      ]
    },
    {
      "heading": "9 User Interface and System Performance",
      "text": [
        "Since we want to enable interactive summarization which allows a user to browse through a dialogue quickly to search for information he is interested in, we have integrated our summarization system into a JAVA-based graphical user interface (\"Meeting Browser\") (13ett et al., 2000).",
        "This interface also integrates the output of a speech recognize]: (Yu ct al., 1999), and can display a wide variety of information about a conversation, including speech acts, dialogue games, and emotions.",
        "For summarization, the user can determine the size of the summary and which topical segments lie wants to have displayed.",
        "He can also focus the summary on particular content words (\"querybased summary\") or exclude words from consideration (\"dynamic stop list expansion\").",
        "Summarizing a 10 minute segment of a CALL-IIOME dialogue with our system takes on average less than 30 seconds on a 167 MHz 320 MB Sun Ultral workstation.5 ' We arc aware that this annotation and evaluation scheme is far from optimal: it does neither reflect the fact that turns are not necessarily the best units for extraction nor that the 11-pt-avg precision score is not optimally suited for the summarization task.",
        "We thus have recently developed a new word-based method for annotation and evaluation of spontaneous speech (Zechner, 2000).",
        "'The average was computed over five English dialogues."
      ]
    },
    {
      "heading": "10 Human Study",
      "text": []
    },
    {
      "heading": "10.1 Experiment Setup",
      "text": [
        "In order to evaluate the system as a. whole, we conducted a study with humans in the loop to be able to compare three types of summaries (TRANS, CLEAN, TELE, see section 3) with the full original transcript.",
        "We address these two main questions in this study: (i) how fast can information be identified using different types of summaries?",
        "(ii) how accurately is the information preserved, comparing different types of summaries?",
        "We did not only ask the user \"narrow\" questions for a specific piece of information along the lines of the Q-A-evaluation part of the SUMMAC conference (Mani et al., 1998) -- but also very \"global\", non-specific questions, tied to a particular (topical) segment of the dialogue.",
        "The experiment was conducted as follows: Subjects were given 24 texts each, accompanied by either a generic question (\"What is the topic of the discussion in this text segment?\")",
        "or three specific questions (e.g., \"Which clothes did speaker A buy?\").",
        "The texts were drawn from five topical segments each from five English CALLEOME dialogues!\"",
        "They have four different formats: (a) full transcripts (i.e., the transcript of the whole segment) (EuLL); (b) summary of the raw transcripts (without linking and clean-up) (TRANs); (c) cleaned-up summary (using all four major components of our system) (cLEAN); and (d) telegram summary (derived from (c), using also the telegraphic reduction component) (TELE).",
        "The texts of formats (b), (c), and (d) Were generated to have the same length: 40% of (a), i.e., we use a 60% reduction rate.",
        "All these formats can be accompanied by either a generic or three specific questions, hence there are eight types of tasks for each of the 24: texts.",
        "We divided the subjects in eight groups such that no subject had to perform more than one task on the same text and we distributed the different tasks evenly for each group.",
        "Thus we can make unbiased.",
        "comparisons across texts and tasks.",
        "The answer accuracy vs. a predefined answer key was manually assessed on a.",
        "6 point discrete scale between 0.0 and 1.0."
      ]
    },
    {
      "heading": "10.2 Results and Discussion",
      "text": [
        "Of the 27 subjects taking part in this experiment, we included 24 subjects in the evaluation; 3 subjects were excluded who were extreme outliers with respect to average answer time or score (not within p – 2stdd.ev).",
        "From the results in Table 5 we observe the following trends with respect to answer accuracy and response time: cone of the 25 segments was set aside for demonstration purposes.",
        ")aties",
        "• generic questions (\"indicative summaries\", the task being to identify the topic of a text): The two cleaned up summaries took about the same time to process but had lower accuracy scores than the version directly using the transcript.",
        "• .specific questions (\"informative summaries\", the task being lo End specific infbritialion in the text): ( 1 ) The accuracy advantage of the raw transcript summaries (PRA Ns) over the cleaned up versions (GLEAN) is only small (not statistically significant: E=0.748)'.",
        "(2) There is a superiority of the TELE-summary to both other kinds (TELL is significantly more accurate than CLEAN for p < 0.05).",
        "From this we conjecture that our methods for (ms-tornization of the summaries to spoken dialogues is mostly relevant for informativc, Init not so much for indicative summarization.",
        "We think that other methods, such as lists of signature phrases would he more effective to use for the latter purpose.",
        "Table 6 shows the answer accuracy for the three different summary types relative to the accuracy of the full transcript texts of the same segments (\"relative answer accuracy\").",
        "We observe that the relative accuracy reduction for all summaries is ma.rkedly lower than the reduction of text size: all summaries were reduced froth the full transcripts by 60%, whereas the answer accuracy only drops between 9% (TRANS) and 24% (cLEAN) for the generic questions, 71n fact, in 2 of 5 dialogues, Hie CLEAN summary scores are higher than those of the TRANS summaries.",
        "and between 20% (TELL) and 29% (GLEAN) for the specific questions.",
        "This proves that our system is able to retain most, of the relevant information in the summaries.",
        "As for average answer times, we see a marked reduction (30%) of all summaries compared to the full texts in the generic case; for the specific case, the time reduction is somewhat smaller (15(70-25%).",
        "One shortcoming of the current system is that it operates on turns (or turn-pairs) as minimal units for extraction.",
        "In future work, we will investigate possibilities to reduce the minimal units of extraction to the level of clauses or sentences, without giving up the idea of linking cross-speaker information."
      ]
    },
    {
      "heading": "11 Summary and Future Work",
      "text": [
        "We have presented a summarization system for spoken dialogues which is constructed to address key differences of spoken vs. written language, dialogues vs. monologues, and multi-topical vs. mono-topical texts.",
        "The system cleans up the input for speech disfluencies, links turns together into coherent information units, determines topical segments, and extracts the most relevant pieces of' information in a user-customizable way.",
        "Evaluations of major system components and of the system as a whole were performed.",
        "'lite results of' a user study show that with a. summary size of'10%, between 71% and 91% of' the information of the full text is retained in the summary, depending on the type of summary and the types of questions being asked.",
        "We are currently extending the system to be able to handle different levels of granularity for extraction (clauses, sentences, turns).",
        "Furthermore, we plan to investigate the integration of prosodic information into several components of OUI• system."
      ]
    },
    {
      "heading": "12 Acknowledgements",
      "text": [
        "We want to thank the annotators for their efforts and Klaus Ries rot.",
        "providing the automatic speech act",
        "tagger.",
        "We appreciate comments and suggestions from Alon Lavie, Marsal Gavalda, Jade Goldstein, Thomas MacCracken, and the anonymous reviewers on earlier drafts of this paper.",
        "Tins work was funded in part by the VERI3M011H, project of the Federal Republic of Germany, ATR Interpreting Telecommunications Research Laboratories of Japan, and the US Department of Defense."
      ]
    }
  ]
}
