{
  "info": {
    "authors": [
      "Marc Dymetman",
      "Frederic Tendeau"
    ],
    "book": "International Conference on Computational Linguistics",
    "id": "acl-C00-2149",
    "title": "Context-Free Grammar Rewriting and the Transfer of Packed Linguistic Representations",
    "url": "https://aclweb.org/anthology/C00-2149",
    "year": 2000
  },
  "references": [
    "acl-J93-4001",
    "acl-P89-1018",
    "acl-P97-1050",
    "acl-P98-1060"
  ],
  "sections": [
    {
      "heading": "Abstract",
      "text": [
        "We propose an algorithm for the transfer of packed linguistic structures, that is, finite collections of labelled graphs which share certain subparts.",
        "A labelled graph is seen as a word over a vocabulary of description elements (nodes, arcs, labels), and a collection of graphs as a set of such words, that is, as a language over description elements.",
        "A packed representation for the collection of graphs is then viewed as a context-free grammar which generates such a language.",
        "We present an algorithm that uses a conventional set of transfer rules but is capable of rewriting the CFG representing the source packed structure into a CFG representing the target packed structure that preserves the compaction properties of the source CFG."
      ]
    },
    {
      "heading": "1 Introduction",
      "text": [
        "There is currently much interest in translation models that support some amount of ambiguity preservation between source and target texts, so as to minimize disambiguation decisions that the system, or an interactive user, has to make during the translation process (Kay et al., 1994).. An important aspect of such models is the ability to handle, during all the stages of the translation process, packed linguistic structures, that is, structures which factorize in a compact fashion all the different readings of a sentence and obviate the need to list and treat all these readings in isolation of each other (as is standard in more traditional models for machine translation).",
        "In the case of parsing, and more specifically, parsing with unification-based formalisms such as LFG, techniques for producing packed structures have been in existence for some time (Maxwell and Kaplan, 1991; Maxwell and Kaplan, 1993; Maxwell and Kaplan, 1996; DOrre, 1997; Dymetman, 1997).",
        "More recently, techniques have been appearing for the generation from packed structures (Shemtov, 1997), the transfer between packed structures (Emele and Dorna, 1998; Rayner and Bouillon, 1995), and the integration of such mechanisms into the whole translation process (Kay, 1999; Frank, 1999).",
        "This paper focuses on the problem of transfer.",
        "The method proposed is related to those of (Emele and Dorna, 1998) and (Kay, 1999).",
        "As in these approaches, we view packed representations as being descriptions of a finite collection of directed labelled graphs (similar to the functional structures of LFG), each representing a different non-ambiguous reading, which share certain subparts.",
        "The representations of (Emele and Dorna, 1998) and (Kay, 1999) are based on a notion of propositional contexts (see (Maxwell and Kaplan, 1991)), where each possible non-ambiguous reading included in the packed source representation is extracted by selecting the value (true or false) of a certain number of propositional variables that index elements of the labelled source graph.",
        "Transfer is then seen as a process of rewriting source graph elements (e.g, nodes labelled with French lexemes) into target graph elements (e.g. nodes labelled with English lexemes), while preserving the propositional contexts in which these graph elements were selected.",
        "In contrast, our approach, following (Dymetman, 1997), views a packed representation as being a grammar (more specifically, a context-free grammar) over the vocabulary of graph elements (labelled nodes and edges), where each word (in the sense of formal language theory) generated by the grammar represents one of the possible non-ambiguous readings of the packed representation.",
        "In other terms, the collection of non-ambiguous graphs belonging to the packed representation is seen as a language over a vocabulary of graph elements, and a packed representation is seen as a grammar which generates such a language.",
        "Packing comes from the fact that a context-free grammar is an efficient representation for the language it generates.",
        "Another essential feature of such a representation is that it is interaction-free, that is, each nondeterministic top-down traversal of the grammar succeeds without ever backtracking and it results in a certain reading, without the need for checking the consistency of a set of associated propositional constraints: the representation for the collection of readings is as direct as can be while permitting a factorization of common parts.",
        "Based on this notion, we present an algorithm for transfer which, starting from a finite set of rewriting patterns (the transfer lexicon), associates with a given context-free grammar representing the source packed structure a context-free grammar representing the target packed structure.",
        "Therefore, the target representation remains interaction-free and transparently encodes the target structures; furthermore, under certain natural \"locality\" conditions on the rewriting rules (the graph elements in their left-hand sides tend be be \"close\" from each other in the source grammar derivations), the target grammar preserves much of the factorization and compaction properties of the source grammar.",
        "The paper is structured in the following way.",
        "Sec1016 lion 2 explains how ambiguous graphs can be seen as commutative languages over graph description elements, and how context-free grammars provide concise specifications for these languages.",
        "Section 3 extends the standard notion of non-ambiguous transfer to that of ambiguous transfer.",
        "Section 4 presents the basic language-theoretic formalism needed and introduces some operators on languages.",
        "Section 5 presents the detailed rewriting algorithm, which applies these operators not directly to languages, but to the context-free grammars specifying them.",
        "Section 6 gives an example of the algorithm in operation.",
        "possible analyses for \"I saw the green light on the hill with a telescope\".",
        "Let's consider the sentence \"I saw the green light on the hill with a telescope\".",
        "In Fig. 1, we have represented informally the set of possible analyses for this sentence.",
        "Labels on the nodes correspond to predicate names (`on', 'hill', etc).",
        "A slash is used to indicate different possible readings for a node; for instance, we assume that the surface form \"saw\" can correspond to the verbs \"to see\" or \"to saw\", and that \"green\" is ambiguous between the color adjective \"green I\" and the noun \"green2\" (grassy lawn).",
        "Relations between nodes are indicated by labels on the edges joining two nodes: 'argl' and 'arg2' for first and second argument, 'mod' for modifier.",
        "The solid edges correspond to relations which are satisfied in all the readings for the sentence, clotted edges to relations that are satisfied only for certain readings.",
        "Thus, the preprositional phrase \"on the hill\" can modify either \"light\" or \"see/saw\", the phrase \"with a telescope\" either \"hill\", \"light\", or \"see/saw\".",
        "The informal picture of Fig. 1 does not make explicit exactly which structures are actually possible analyses of the sentence.",
        "For instance the two crossing edges moc103 and moc125 (where indices are used to denote the origin and destination of the edge) cannot appear together in a reading of the given sentence.",
        "As a consequence only five of the apparent 2 x 3 prepositional attachments combinations are possible, which multiplied by the four possible lexical variants for \"saw\" and \"green\" gives 20 possible readings for the sentence.",
        "Each of these readings is a graph where nodes 0 and 7 now carry one label, and where one 'mod' edge has been selected for the attachment of nodes 3 and 5.",
        "One way to describe such a graph is by listing a collection of' \"description elements\" for it, where each such element is either a labelled node such as seep or a labelled edge such as mod27.",
        "Using this format, the pragmatically preferred analysis for our sentence is the set {seen, &glob arg2o2,mod27, green 17, mod23, on3, arg234, mod05,zug256, telescopes;}.",
        "If we consider the collection of all possible analyses, we then obtain a collection of sets of description elements.",
        "It is convenient to view such a collection as a commutative language over the vocabulary of all possible description elements; each word in such a language corresponds to one analysis and is a list of description elements the order of which is considered irrelevant.",
        "The main advantage of taking this view of ambiguous structures is that formal language theory provides standard tools for representing languages compactly.",
        "Thus it is well-known in computational lexicography that a large list of word strings can be represented efficiently by means of a finite-state automaton which factorizes common substrings.",
        "Such a representation is both compact and \"explicit\": accessing and using it is as direct as the flat list of words would be.",
        "Although one might think of using finite-state models for representing compactly the language associated with a collection of graphs, they do not seem as relevant as context-free models for our purposes.",
        "The reason is that the source packed representations are typically obtained as the results of chart-parsing processes.",
        "A chart used in the parsing of a context-free grammar can itself be viewed as a context-free grammar, which is a specialization of the original grammar for the string being parsed, and which directly generates the derivation trees for this string relative to the original grammar (13illot and Lang, 1989).1 The generalization of this approach to unification grammars (of the LPG or DCG type) proposed in (Dymetman, 1997) shows that, in turn, chart-parsing with these unification grammars conducts naturally to packed representations for the parse results very close to the ones we arc about to introduce.",
        "Let's consider the CFG Co:",
        "Nonterminals of that grammar are written in uppercase, terminals (which are graph description elements) in lowercase.",
        "It can be verified that the language generated by this grammar is the collection of commutative words I This context-free grammar has polynomial size relative to the length of the string.",
        "While it is also possible in principle to use a finite-state model for representing the same set of derivation trees, it can be shown that such a model may be exponential relative to string length (remark clue to John Maxwell).",
        "corresponding precisely to all the possible analyses for the sentence.",
        "The fact that there arc 20 such words can be established by a simple bottom-up computation involving multiplications and sums.",
        "If we call ambiguity degree ad(N) of a nonterminal N the number of words it generates, then it is obvious that, for instance, ad(D30) = 2, ad(D3) = 2+3, ad(S) = 4.1.1.5 = 20.",
        "In fact, it is the multiplications which appear in such computations which are responsible for the compactness of the grammar as compared to the direct listing of the words: each time a multiplication appears, a factorization is being cashed in.2 3 Transfer as language rewriting When working with non-ambiguous structures, transfer is a rewriting process which takes as input a source-language graph and constructs a target-language graph by applying transfer rules of the form tits rhs, where ibis and rhs are finite sets of description elements for source graph and target graph respectively.",
        "In outline, the \"non-ambiguous\" transfer process works in the following way: for each non-overlapping covering of the source graph with left-hand sides of transfer rules, the corresponding right-hand sides are produced and taken together represent a target graph (this is a non-deterministic function as there can be several such coverings).",
        "In the case of ambiguous structures, the aim of transfer is to take as input a language of source graphs and to produce a language of target graphs.",
        "The language of target graphs should be equal to the union of all the graphs that would have obtained if one had enumerated one-by-one the source graphs, applied non-ambiguous transfer, and taken the collection of all target graphs obtained.",
        "The goal of ambiguous transfer is to perform the same task on the basis of a compact representation for the collection of source graphs, yielding a compact representation for the collection of target graphs.",
        "For illustration purposes, we will consider the following collection of transfer rules: secvoiro,sawosciero, green 17vert7, green27gazon7, light2, mod27, green17 > leu2, mod'27, vert7, light2Ininie.re2, etc.",
        "We have only listed a few rules, and have assumed that the remaining ones are straighforward one-to-one correspondences (I' modus mod'03 [we prime labels such as mod, arg 1 ,... in order to have disjointness of source and target vocabulary], etc.",
        ").3 2 As the example shows, context-free representations of ambiguous structures have the important property (related to their interaction-freeness as described in the introduction) of being easily \"countable\".",
        "This is to be contrasted with other possible representations for ambiguous structures, such as ones based on propositional axioms determining which description elements can be jointly present in a given analysis.",
        "In these representations, the problem of determining whether there exists one structure satisfying the specification can be of high complexity, let alone the problem of counting such structures."
      ]
    },
    {
      "heading": "Formal aspects",
      "text": [
        "The commutative monoid over an alphabet A is denoted by C(A*), and its words are represented by vectors of NA, indexed by A and with entries in N. For each w NA, the component indexed by a E A is denoted by wfril and tells how many a's occur in w. The product (concatenation) of w1 and w2 in C(A*) is the vector w NA s.t.",
        "Va E A: In101 = w1 [a] + w2[a].",
        "A language of the commutative monoid is a subset of C(A*).",
        "The subword relation is denoted byFor a language L, we write: 7)--a iff there exists w E L s.t.",
        "The rewriting is performed from a source language Es over an alphabet Es to a target language .C7, over an alphabet ET (disjoint from Es) w.r.t.",
        "a set of rewriting rules R C Es+ x ET* (rules have the form A>p).",
        "We assume in the sequel that any a E Es appears at most once in any left-hand side of each rule of R and also at most once in any word of Es.",
        "This property is preserved by all the rewritings that we are going to introduce.",
        "Let's define LH S (Ay) = A.",
        "For R C R., we define 1_,S4/?)",
        "= {a E Es I 1 E R s.t.",
        "a-<LHS(r)}.",
        "The rewriting is a function OR, taking Es and yielding ET, defined as:"
      ]
    },
    {
      "heading": "5 Algorithm",
      "text": [
        "In order to implement the function OR, it is useful to introduce rewriting functions OA and 0,7.",
        "They apply to any language L over C(r,*), where E = Es U ET.",
        "They are defined as:",
        "The OA-- p functions are applied so that source symbols are guaranteed to be removed one by one from Es: we consider Es is totally ordered by < and we write Es =a2,aN], with ai < aj+1; then consider the partition of R.: R.2, ..., RN s.t.",
        "RI contains all R. rules with al in LHS, R.2 contains all R. rules with a2 but not al in LHS, etc, RN contains all R rules with only aN in LHS.",
        "Then we define a third rewriting function OR: ORS (L) = (1),-T(L) U Urozi (L).",
        "Lemma.",
        "ET can be obtained from ES by applying the TZ,i iteratively in the following manner:",
        "It is clear that EN = ET.",
        "Furthermore, we have OR,i(Es), and it is easy to show that, for 2 < it < N,",
        "In order to obtain ET, we will start from Es and actually apply the OR,i's not on languages directly but on min ground rules as the ones we are considering, a simple preprocessing step is necessary.",
        "the grammars that define them.",
        "This computation is performed by the algorithm that we now present.",
        "Let Gs be defined by the CFG Go = (X, Aro, Po, So) For A.",
        "C Al0, the set of all rules having A as I,HS is notated A-+ YA._+,,,E,po a.",
        "This additive notation is a formal represention of A-ai a2 ...",
        "Hence A-40 means that no rule defines A.",
        "First OR, is applied on Go, which builds G1 = (X, , , SO, then OR., is applied on Gi to produce G2 and so forth.",
        "Each time, new non-terminals are introduced: of the form (A)-R, (A)),_40 or (A)a, where A CA E X+, p E 27,7,*, and a C Xs.",
        "Each one is defined by a formal sum as we saw above.",
        "The order of symbols in the RHSs of grammar rules is irrelevant since we consider commutative languages.",
        "Hence the RI-ISs of grammar rules can be denoted by x/3 s.t.",
        "x e C(Y,*) and /3 e C (Al* ), where Ai is the set of all non-terminals considered.",
        "The algorithm consists of the procedure and functions described below and uses an agenda which contains new non-terminals to be defined in The agenda is handled with a table: each non-terminal is treated once.",
        "procedure main is for i C {1,...,N} do Initialize 'Pi with Pi_i; if 7?4, then",
        "when (A)7z; : add to \"Pi EA yo.cp,_, 437z, (o); when (A.",
        ")A__>0: add to Pi (A)X per(1?A-0(0; when (A)w: add to Pi (A)w>4'7(L'); end case; until Agenda is empty Reduce Gi whose axiom is Si = Yrzi; l'''remove non-terminals that are non-productive (f(A) 0) or inaccessible from S. */ end for; end procedure;",
        "function 4ER., (313) is/0 = 'Ilk if 3j E {1, ...,s.t.",
        "Va C 1_,11.50(1?-i),a-<.C(Aj) // if all rewritings in Rican only affect then add (i1j)R, to Agenda; return xAl (Ai )/^,i Aj+1 ' Ak ;(I) else return 4)(43) + Ereni tbr (I: 0);(2) end function; function 4.-6,-(43) is///3 = A,- Ak if aj E {1,s.t.",
        "a L(Ai) thenis unique, see below*I add (Ai to Agenda;",
        "else if a -0: then return 0; else return 43; end function; function (1.",
        "),-_,,(x,13) is//0 = Al Ak // A is searched within a:A, Ac if 3/s.t.",
        "Ha-<A, a-<f.(A:i) // A frills //entirely within E(Ari) then the rewriting applies only to Ai",
        "then add (Aj)A+1 to Agenda; return 3:A1--1-4;(4) else //A is searched within several symbols Consider A = y wl w2 Ink s.t.",
        "- the longest common subword of a: and A is y, - Va-<tui,//wt is Ai contribution to A",
        "if such decomposition of A exists //that is, it is //entirely covered by 3: and some's then Pi' it is unique: see below *I add to Agenda all (Ai).,i-4, s.t.",
        "wic; //all those that contribute return :Ely (11jc (A.1)wi(11=c Ai) P;(5) //The rewriting is actually applied: y is deleted front :r; //each contributing (i.e. non c)mi is to be deleted // (i.e. rewritten to c in Ai); non-contributing Al 's // remain untouched; and p is inserted.",
        "else //A cannot be produced by 3:11 return 0; //No rewriting is applicable end function; Unicity of j in 4,w, and unicity of the sequence in (1,),_41,: consider A---3xX-11-7 ; as each source symbol occurs at most once in every word of E(Si_1), the same holds for f(A) hence the sets of source symbols occurring in L(X) and L(Y) are disjoint."
      ]
    },
    {
      "heading": "6 Example",
      "text": [
        "Consider >],s = [4, green 17, green27, see, _1 so that R. is partitioned in 7?jei\"R.9{green 17-- yea-, 7, green17 mod27mod27 vert7}, etc.",
        "Each other ki contains a single rule.",
        "The first iteration of the algorithm computes the grammar",
        "WITIIwith; dig256 Ielescope6, etc.",
        "We see that the only nonterminals which have been redefined are S So and SAW.",
        "The computation of (So)R, has been done through step (1) in the algorithm.",
        "This is because the terminals in left-hand sides ofnamely the single terminal are all \"concentrated\" on the single nonterminal SAW on the right-hand side of So.",
        "This leads in turn to a requirement for a definition of (SAW)R1 which is fulfilled by step (5) in the algorithm, at which time the rewriting of it into Pi is performed.",
        "For any group of rules 'Rh as long as all terminals in the left-hand sides of rules orki are thus concentrated on at most one nonterminal in a right-hand side, no expansion of rules is necessary.",
        "It is only when the terminals start to be distributed on several RHS terminals or nonterminals that an expansion is required.",
        "This situation is illustrated by the second iteration which maps C-1 into G2 = 4 R,2 PO.",
        "The result is:",
        "This time, the terminals in left-hand sides of TZ,2 arc green 17, mod27 and light2.",
        "We first need to compute (( 0)-Rin2 .",
        "Again, our three terminals are all concentrated on (SAw)7z1 .",
        "We thus only have to define ((SAw)R,1),R2.",
        "Once again, the three terminals are concentrated on Liurr, and we have to define (I At this point, something interesting happens.",
        "It is not the case any more that one nonterminal on the right-hand side of the rule defining Lion concentrates all our terminals.",
        "In fact, GREEN only \"touches\" green 17, but not the other two terminals.",
        "The algorithm then has recourse to step (2), which leads it to define three rules for (LIGIIT)R, , involving recursive calls to green17 , first (II green 17 ) ven7 41green17 moc127 light2feti2 mocry vert7 The of these calls involves step (3), the second, step (4), and the third, step (5), leading to the three expansions shown for (LIGHT)R2, and eventually to the definitions for the three variants of the nonterminal Gums,.",
        "The remaining iterations of the rewriting procedures are of the same type as the first iteration.",
        "They lead finally to a target grammar of the form:",
        "which is only slightly less compact than the source grammar.",
        "It can be checked that this grammar enumerates 30 target graphs, the difference of 10 with the source grammar being due to the addition of the French variant \"feu vert\" along with \"Iumiere verte\" for translating \"green light\"."
      ]
    },
    {
      "heading": "7 Conclusion",
      "text": [
        "We have presented a model and an algorithm for the transfer of packed linguistic representations based on the view that: (1) packed representations are best seen as context-free grammars over graph description elements, an approach which permits factorization of common parts while maintaining a transparent, easily computable, relationship to the set of structures represented (interaction-freeness, countability)4, and (2) transfer is a rewriting process that takes as input such a context-free representation and that outputs a target context-free 4Properties that we believe are essential to all such representations, whether they are made explicit or not.",
        "representation which maintains these beneficial properties.",
        "Although proofs have not been provided here, the algorithm can be shown to satisfy our initial formal definition of transfer as nondeterministic, exhaustive, non-overlapping replacement of description elements in the source structure by their counterparts as specified in the rewriting rules.",
        "The method described in this paper bears some obvious analogy to the classical problem of mapping a context-free language into another context-free language by way of a finite-state transducer (Harrison, 1978).",
        "It would be an interesting research question to make this analogy formal, the main difference here being the need to work with a commutative concatenation, as opposed to the standard non-commutative concatenation which is more directly connected with the automaton view of transductions."
      ]
    },
    {
      "heading": "Acknowledgments",
      "text": [
        "Thanks to our colleagues Eric de la Clergerie, Max Copper-man, Andreas Eisele, Martin Emele, Anette Frank, Pierre Isabelle, Ron Kaplan, Martin Kay, Bernard Lang, John Maxwell and Hadar Shemtov for extended discussions and comments at various stages in the preparation of this paper."
      ]
    }
  ]
}
