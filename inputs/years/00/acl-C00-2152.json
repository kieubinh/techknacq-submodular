{
  "info": {
    "authors": [
      "Alexander M. Franz",
      "Keiko Horiguchi",
      "Lei Duan",
      "Doris Ecker",
      "Eugene Koontz",
      "Kazami Uchida"
    ],
    "book": "International Conference on Computational Linguistics",
    "id": "acl-C00-2152",
    "title": "An Integrated Architecture for Example-Based Machine Translation",
    "url": "https://aclweb.org/anthology/C00-2152",
    "year": 2000
  },
  "references": [
    "acl-C90-3044",
    "acl-C92-2115",
    "acl-C96-1070",
    "acl-P98-2223"
  ],
  "sections": [
    {
      "heading": "Abstract",
      "text": [
        "This paper describes a machine translation architecture that integrates the use of examples for flexible, idiomatic translations with the use of linguistic rules for broad coverage and grammatical accuracy.",
        "We have implemented a prototype for English-to-Japanese translation, and our evaluation shows that the system has good translation quality, and only requires reasonable computational resources."
      ]
    },
    {
      "heading": "1 Introduction",
      "text": [
        "Machine translation by analogy to pairs of corresponding expressions in the source and target languages, or \"example-based translation\", was first proposed by (Nagao 1984).",
        "Recent work in the example-based framework includes memory-based translation (Sato & Nagao 1990), similarity-driven translation (Watanabe 1992), transfer-driven machine translation (Furuse & Lida 1996), and pattern-based machine translation (Watanabe & Takeda 1998).",
        "The example-based approach promises easy translation knowledge acquisition, more flexible transfer than brittle rule-based approaches, and idiomatic translations.",
        "At the same time, the use of linguistic rules offers a number of important benefits.",
        "Detailed linguistic analysis can allow an example-based machine translation system to handle a wide variety of input, since rules can be used to factor out all linguistic variations that do not influence the example-based transfer.",
        "Rule-based language generation from detailed linguistic representations can lead to higher grammatical output quality.",
        "Finally, a modular system architecture that uses domain-independent linguistic regularities in separate linguistic modules allows extending the system to much broader domains.",
        "The HARMONY architecture for hybrid analogical and rule-based machine translation of naturally occurring colloquial language combines the advantages of both these approaches."
      ]
    },
    {
      "heading": "2 The Travel Domain",
      "text": [
        "Our prototype implementation of the HARMONY architecture was designed to cover the \"travel domain\".",
        "This is composed of words, phrases, expressions, and sentences related to international travel, similar to what is covered by typical travel phrase books.",
        "Two principles guided our detailed definition of the translation domain.",
        "First, the translation domain should not he limited to a narrow sub-domain, such as appointment scheduling or hotel reservations.",
        "Second, the expressions considered in the domain should reflect the fact that people quickly adapt to limitations in human-machine or machine-mediated communication by simplifying the input.",
        "For example, (Sugaya et al.",
        "1999) found that the average length of actual human utterances in a hotel reservation task using speech translation was only 6.1 words, much shorter than some of the data that has been used in previous work on speech translation.",
        "The current vocabulary of 7,500 words is divided into a group of general words, a number of extensible word groups (such as names of food items or diseases), and a number of area-specific word groups (such as names of cities or tourist destinations).The travel domain.",
        "is divided into eight \"situations\": A general situation (including everyday conversation); transportation; accommodation; sightseeing;",
        "shopping; wining, dining, and nightlife; banking and postal; and doctor and pharmacy.",
        "We created a corpus for this domain, and divided it into a development set of 7,000 expressions, and a separate, unseen test set of 5,000 expressions.",
        "The development set is used for creation and refinement of the translation knowledge sources, and the test set is only used for evaluations.",
        "(Each evaluation uses a new, random 500-word sample from the 5,000 word test set.)",
        "The corpus was balanced to illustrate the widest possible variety of types of words, phrases, syntactic structures, semantic patterns, and pragmatic functions.",
        "The average length of the expressions in the corpus is 6.5 words.",
        "Some examples from the development corpus arc shown below.",
        "Even though this domain might seem rather limited, it still contains many challenges for machine translation.",
        "• Can I have your last name, please?",
        "• Is this the bus for Shinagawa station?",
        "• I would like to make a reservation for two people for eight nights.",
        "• Can you tell us where we can see some Buddhist temples?",
        "• Most supermarkets sell liquor.",
        "• Can you recommend a good Chinese restaurant in this area?",
        "• I'd like to change 500 Dollars in traveller's checks into Yen.",
        "• Are there any English-speaking doctors at the hospital?"
      ]
    },
    {
      "heading": "3 NLP Infrastructure",
      "text": [
        "The prototype implementation is constructed out of components that are based on a powerful infrastructure for natural language processing and language engineering.",
        "The three main aspects of this infrastructure arc the Grammar Programming Language (GPL), the GPL compiler, and the GPL runtime environment."
      ]
    },
    {
      "heading": "3.1 The Grammar Programming Language",
      "text": [
        "The Grammar Programming Language (GPL) is an imperative programming language for feature-structure-based rewrite grammars.",
        "GPL is a formalism that allows the direct expression of linguistic algorithms for parsing, transfer, and generation.",
        "Some ideas in GPL can be traced back to Tomita's pseudo-unification formalism (Tomita 1988), and to Lexical-Functional Grammar (Dalrymple et al.",
        "1995).",
        "GPL includes variables, simple and complex tests, and various manipulation operators.",
        "GPL also includes control flow statements including if-then-else, switch, iteration over sub-feature-structures, and other features.",
        "An example of a simplified GPL rule for English generation is shown in Figure 1."
      ]
    },
    {
      "heading": "3.2 The GPL Compiler",
      "text": [
        "GPL grammars arc compiled into C code by the GPL compiler.",
        "The GPL compiler was created using the Unix tools lex and yacc (Levine et al.",
        "1990).",
        "For each rewrite rule, the .GPL compiler creates a main action function, which carries out most of the tests and manipulations specified by the GPL statements.",
        "The GPL compiler handles disjunctive feature structures in an efficient manner by keeping track of sub-feature-structure references within each GPL rule, and by generating an expansion function that is called once before the action function.",
        "The compiler also tracks variable references, and generates and tracks separate test functions for nested test expressions."
      ]
    },
    {
      "heading": "3.3 The GPL Runtime Environment",
      "text": [
        "The result of compiling a GPL grammar is an encapsulated object that can be accessed via a public interface function.",
        "This interface function serves as the link between the compiled GPL grammars, and the various language-independent and domain-independent software engines for parsing, transfer, generation, and others.",
        "This is illustrated in Figure 2.",
        "The compiled GPL, grammars use the feature structure library, which provides services for efficiently representing, testing, manipulating, and managing memory for feature structures.",
        "A special-purpose memory manager maintains separate stacks of memory pages for each object size.",
        "This scheme allows garbage collection that is so fast that it can he performed after every attempted GPL rule execution.",
        "in our experiments with Japanese and English parsing, we found that per-rule garbage collection reduced the overall read/write memory requirements by as much as a factor of four to six."
      ]
    },
    {
      "heading": "4 Source Language Analysis",
      "text": [
        "Translation is divided into the steps of analysis, transfer, and generation.",
        "Source-language analysis is illustrated in Figure 3.",
        "English analysis begins with tokenization and morphological analysis, which creates a lattice that contains lexical feature structures.",
        "During multi-word matching, expressions from the multi-word lexicon (such as White House or take on) are detected in the word lattice, and new arcs with the appropriate lexical feature structures are added.",
        "Lexical ambiguity reduction reduces the number of arcs in the word lattice.",
        "This module carries out part-of-speech tagging over the lattice, and reduces the lattice to those lexical feature structures that are part of the number of best paths that represents the best speed/accuracy trade-off (currently two).",
        "This calculation is based on the usual lexical and contextual bigram probabilities that were estimated from a training corpus, but it also takes into account manual costs that can be added to lexicon entries, or to individual part-of-speech bigrams.",
        "The resulting reduced lattice with lexical single-word and multi-word feature structures is parsed using the GLR parsing algorithm extended to lattice input (Tomita 1986).",
        "The English parsing grammar consists of 540 GPL rules.",
        "The output is a sentential feature structure that represents the input to the transfer component."
      ]
    },
    {
      "heading": "5 Transfer",
      "text": [
        "Transfer from the source-language sentential feature structure to the target-language sentential feature structure is accomplished with a hybrid rule-based and example-based method.",
        "This is illustrated in Figure 4.",
        "The input feature structure is passed to the linguistic transfer procedure.",
        "This consists of a rule-rewriting software engine that executes the compiled English-to-Japanese transfer grammar.",
        "The transfer grammar consists of 140 GPL rules, and its job is to specify linguistic constraints on examples, combine multiple examples, transfer information that is beyond the scope of the example database, and perform various other transformations.",
        "The overall effect is to broaden the linguistic coverage, and to raise the grammatical accuracy far beyond the level of a traditional example-based transfer procedure.",
        "The linguistic transfer procedure operates on the input feature structure in a recursive manner, and it invokes the example matching procedure to find the best translation example for various parts of the input.",
        "The example matching procedure retrieves the best translation examples from the example database, which contains 14,000 example pairs ranging from individual words to entire sentences.",
        "In an off-line step, the example pairs are parsed, disambiguated, and indexed for corresponding constituents using a Treebanking tool.",
        "At each invocation of the example matching procedure, linguistic constraints from the transfer grammar are used to limit the search space to appropriate examples.",
        "In an off-line step, these constraints are pre-compiled into a complex index that allows a preliminary fast match.",
        "Examples that survive the fast match arc matched and aligned with the input feature structure (or sub-feature-structure, during recursive invocations) using the thesaurus to calculate word similarity, and using various other constraints and costs for inserting, deleting, or altering slots and features.",
        "Rather than rely on the exact distance in the thesaurus to calculate lexical similarity, we use a scheme that is based on the information content of thesaurus nodes, similar to (Resnik 1995)."
      ]
    },
    {
      "heading": "6 Target-language Generation",
      "text": [
        "The Japanese target-language feature structure forms the input to the generation module, which is summarized in Figure 5 below.",
        "This module also consists of a rule-rewriting software engine, executing the compiled GPL Japanese generation grammar, which consists of 200 GPL rules.",
        "The generator uses the Japanese lexicon to create the Japanese target-language expression."
      ]
    },
    {
      "heading": "7 Evaluation and Conclusions",
      "text": [
        "We evaluated the translation system using a random 500-expression sample from the unseen test set (see Section 2 above).",
        "The translations were manually assigned to one of the following categories of translation quality: Failure.",
        "Complete translation failure, due to lack of coverage of a rule-based component.",
        "Wrong.",
        "A translation that is completely wrong, or that has major errors in an important part, such as in the main clause.",
        "Major Problem.",
        "A translation that has a missing, extra, or incorrect constituent, such as a subject, object, or adjectival/prepositional predicate.",
        "Minor Problem.",
        "A translation that has a missing, extra, or incorrect minor part, such as an intensifier, tense, aspect, temporal or locative adjunct, adverb, adjective or other prenominal modifier, prepositional phrase, verb conjugation form, adjective form, or required word or constituent order.",
        "Stylistic Problem.",
        "Stylistic problems include awkward but tolerable word order, incorrect Japanese particles, incorrect idioms, and similar.",
        "Flawless.",
        "A translation that does not exhibit any of the above problems is considered flawless.",
        "The results of the evaluation are shown in Table 1 below.",
        "Overall, 84% of the translations convey the meaning in an acceptable manner.",
        "We also evaluated the computational resource requirements of the system.",
        "On a Pentium Ill running at 500 MHz, the average translation speed was 0.44 seconds.",
        "The memory requirements are summarized in Table 2 below.",
        "Our plans for further work include extending the size of the input vocabulary, and developing mechanisms for closer integration with speech recognition and speech synthesis components for speech-to-speech translation.",
        "We are also working on the Japanese-to-English translation direction, and we plan to report results on this in the future."
      ]
    },
    {
      "heading": "Acknowledgements",
      "text": [
        "Our thanks go to Robert Bowen, Benjamin Hartwell, Chigusa Inaba, Kaori Shibatani, Hirono Stonelake, and Kazue Watanabe for their language engineering efforts, and to Edward Ho for user interface and application development."
      ]
    }
  ]
}
