{
  "info": {
    "authors": [
      "George Foster"
    ],
    "book": "Annual Meeting of the Association for Computational Linguistics",
    "id": "acl-P00-1006",
    "title": "A Maximum Entropy/Minimum Divergence Translation Model",
    "url": "https://aclweb.org/anthology/P00-1006",
    "year": 2000
  },
  "references": [
    "acl-J93-2003",
    "acl-J96-1002",
    "acl-P98-2158",
    "acl-W00-0707",
    "acl-W99-0604"
  ],
  "sections": [
    {
      "text": [
        "A Maximum Entropy/Minimum Divergence T�ranslation Model George Foster RALI, Universite de Montreal foster@iro.umont real.",
        "ca Abstract I present empirical comparisons between a linear combination of standard statistical language and translation models and an equivalent Maximum Entropy/Minimum Divergence (MEMD) model, using several different methods for automatic feature selection.",
        "The MEMD model significantly outperforms the standard model in test corpus perplexity, even though it has far fewer parameters."
      ]
    },
    {
      "heading": "1 Introduction",
      "text": [
        "Statistical Machine Translation (SMT) systems use a model of p(tls), the probability that a text s in the source language will translate into a text t in the target language, to determine the best translation for a given source text.",
        "The standard approach to modeling this distribution relies on a \"noisy channel\" decomposition into a language model p(t) and a translation model p(sIt), which correspond respectively to prior and likelihood components in a Bayesian formulation:",
        "where proportionality holds when searching for the optimum target text t for a given source text s. This equation has been called the \"fundamental equation of SMT\" (Brown et al., 1993).",
        "In this paper, I investigate an alternate technique for modeling p(tls), based on a direct chain-rule expansion of the form: Itl",
        "where ti denotes the ith token in t.l The objects to be modeled in this case belong to the family of conditional distributions p(wIh, s), where w is a target word at a particular position in t, and h denotes the tokens which precede it in t. The main motivation for this approach is that it simplifies the \"decoding\" problem of finding the most likely target text according to the model.",
        "In particular, if h is known, the problem of finding the best word at the current position requires only a straightforward search through the target vocabulary, and simple and efficient dynamic-programming based heuristics can be used to extend this to sequences of words.",
        "This is very important for applications such as TransType (Foster et al., 1997; Langlais et al., 2000), where the task is to make real-time predictions of the text a human translator will type next, based on the source text under translation and some prefix of the target text that has already been typed.",
        "The main drawback to modeling p(tIs) in terms of p(wlh, s) is that the latter distribution is conditioned on two very disparate sources of information which are difficult to combine in a complementary way.",
        "One simple strategy is to use a linear combination of 'This ignores the issue of normalization over target texts of all possible lengths, which can be easily enforced when desired by using a stop token or a prior distribution over lengths.",
        "language and translation components, of the form:",
        "where A E [0, 1] is a combining weight.",
        "However, this is a weak model because it averages over the relative strengths of its components; when p(w1h) is likely to be a more accurate estimate than p(wIs), it is obvious that the model should rely more heavily on p(w1h), and vice versa, rather than using a fixed weight.",
        "In theory this could be partially remedied by making A depend on h and s, but in practice significant improvements with this technique have proven elusive (Langlais and Foster, 2000).",
        "The noisy channel model avoids this problem by making predictions based on h the responsibility of the language model p(t), and those based on s the responsibility of the translation model p(sIt), and combining the two in an optimum way.",
        "But this comes at the cost of increased decoding complexity, because the chain rule can no longer be applied as in (1) due to the reversed direction of the translation model.",
        "Much recent research in SMT, eg (Garcia-Varea et al., 1998; Niessen et al., 1998; Och et al., 1999; Wang and Waibel, 1998) deals with the decoding problem, either directly or indirectly because of constraints imposed on the form of the translation model.",
        "A statistical technique which has recently become popular for NLP is Maximum Entropy/Minimum Divergence (MEMD) modeling (Berger et al., 1996).",
        "One of the main strengths of MEMD is that it allows information from different sources to be combined in a principled and effective way, so it is a natural choice for modeling p(w1h, s).",
        "In this paper, I describe a MEMD model for p(wIh, s) and compare its performance to that of an equivalent linear model.",
        "I also evaluate several different methods for MEMD feature selection, including a new algorithm due to Printz (1998).",
        "To my knowledge, this is the first application of MEMD to building a large-scale translation model, and one of the few direct comparisons between a MEMD model and an almost exactly equivalent linear model.2"
      ]
    },
    {
      "heading": "2 Models",
      "text": []
    },
    {
      "heading": "2.1 Linear Model",
      "text": [
        "The baseline model is a linear combination as in (2) of a standard interpolated trigram (Je-linek and Mercer, 1980) for p(w1h) and the IBM model 1 (IBM1) (Brown et al., 1993) for p(wIs).",
        "As originally formulated, IBM1 models the distribution p(tIs), but since target text tokens are predicted independently, it can also be used for p(wIs).",
        "The underlying generative process is as follows: 1) pick a token s at random in s, independent of the positions of w and s; 2) choose w according to a word-for-word translation probability p(wIs).",
        "Summing over all choices for s gives the complete model:",
        "where sj is the jth token in s for j > 0, and so is a special null token prepended to each source sentence to account for target words which have no direct translations.",
        "The word-pair parameters p(wIs) can be estimated from a bilingual corpus of aligned sentence pairs using the EM algorithm, as described in (Brown et al., 1993)."
      ]
    },
    {
      "heading": "2.2 MEMD Model",
      "text": [
        "A MEMD model for p(w1h, s) has the general form:",
        "where q(wlh, s) is a reference distribution, f(w, h, s) maps (w, h, s) into an n-dimensional feature vector, a is a corresponding vector of feature weights (the parameters of the model), and Z(h, s) _ Ew q(wIh, s) exp(a • f(w, h)) is a normalizing factor.",
        "2Rosenfeld (1996) reports a greater perplexity reduction (23% versus 10%) over a baseline trigram language model due the use of ME versus linear word triggers.",
        "However, since the models tested apparently differed in other aspects, it is hard to determine how much of this gain can be attributed to the use of ME.",
        "It can be shown (Berger et al., 1996) that the use of this model with maximum likelihood parameter estimation is justified on information-theoretic grounds when q represents some prior knowledge about the true distribution and when the expected values of f in the training corpus are identical to their true expected values.",
        "There is no requirement that the components of f represent disjoint or statistically independent events.",
        "This result motivates the use of MEMD models, but it offers only weak guidance on how to select q or f. In practice, q is usually chosen on the basis of efficiency considerations (when the information it captures would be computationally expensive to represent as components of f), and f is established using heuristics such as described in the next section.",
        "Once q and f have been chosen, the IIS algorithm (Della Pietra et al., 1995) can be used to find maximum likelihood parameter values.",
        "In the current context, since the aim was to compare equivalent linear and MEMD models, I used an interpolated trigram as the reference distribution q and boolean indicator functions over bilingual word pairs as features (ie, components of f).",
        "A pair of source,target",
        "Using the notational convention that ast is 0 whenever the corresponding feature ft does not exist in the model, the final MEMD model can be written compactly as: p(wI h, s) = q(wIh) exp(Y asw)/Z(h, s).",
        "SEs This model is structurally quite similar to the one defined in the previous section:",
        "3Another interpretation, which has been less well publicized in the NLP literature, is that of a single-layer neural net with certain weight constraints and a \"softmax\" output function (Bishop, 1995).",
        "with the MEMD feature weights asw playing the role of the IBM1 probabilities p(wls), and the MEMD model summing over contributions from source sentence words rather than tokens for efficiency.",
        "If there are m free parameters in the trigram and n word pairs, the MEMD model will contain m + n free parameters and the linear model will contain m + n + 1 – I VS I + I Vt I – V free parameters, so if the source and target vocabulary sizes IVs I and I Vt I are equal the two models will contain precisely the same number of free parameters.",
        "One important practical difference between the two models is the requirement to calculate the MEMD normalizing factor Z(h, s) for each context in which this model is used.",
        "This makes the MEMD model much more computationally expensive than the linear model, so that it is not feasible to have it incorporate all available word-pair features (ie all bilingual pairs of words which cooccur in some aligned sentence pair in the training corpus).",
        "Moreover, since the empirical expectations of features are supposed to reflect their true values, having a feature for every cooccurring pair in the corpus would be theoretically inadvisable even if it were computationally feasible.",
        "Some method of selecting a subset of reliable features is therefore required, as described in the next section."
      ]
    },
    {
      "heading": "3 Feature Selection",
      "text": [
        "I experimented with three methods for selecting bilingual word pairs for inclusion in the models.",
        "All methods assign scores to individual pairs, so feature subsets of any desired size can be extracted by taking the highest-ranked pairs."
      ]
    },
    {
      "heading": "3.1 Mutual Information",
      "text": [
        "The simplest scoring method was mutual information (MI), defined for a pair (s,t) as:",
        "constraint per source word, andVt J – 1 free parameters from p(wIso) where p(s, t) is the probability that a randomly chosen pair of cooccurring source and target tokens in the corpus is (s, t); p(s, 0 is the probability that the source token is s and the target token is not t; etc; and p(x) and P(y) are the left and right marginals of p(x, y).",
        "Mutual information measures the degree to which s and t are non-independent, so it is a reasonable choice for scoring pairs."
      ]
    },
    {
      "heading": "3.2 MEMD Gains",
      "text": [
        "The second scoring method was an approximation of the MEMD gain for feature ft, defined as the log-likelihood difference between a MEMD model which includes this feature and one which does not:",
        "where the training corpus (S, T) consists of a set of (statistically independent) sentence pairs (s, t), and pst is the model which includes ft.",
        "Since MEMD models are trained by finding the set of feature weights which maximizes the likelihood of the training corpus, it is natural to rate features according to how much they contribute to this likelihood.",
        "A powerful strategy for using gains is to build a model iteratively by adding at each step the feature which gives the highest gain with respect to those already added.",
        "Berger et al. (1996) describe an efficient algorithm for accomplishing this in which approximations to pst(TIS) are computed in parallel for all (new) features ft by holding all weights in the existing model fixed and optimizing only over ast.",
        "However, this method requires many expensive passes over the corpus to optimize the weights for the set of features under consideration at each step, and it adds only one feature per step, so it is not practical for constructing models containing thousands of features or more.",
        "In a recent paper (Printz, 1998), Printz argues that it is usually sufficient to perform the iteration described in the previous paragraph only once, in other words that features can be ranked simply according to their gain with respect to some initial model.",
        "He also gives an algorithm for computing gains using a numerical approximation which requires only a single pass over the training corpus.",
        "I adopted Printz' method for computing MEMD gains, using the reference trigram as the initial model."
      ]
    },
    {
      "heading": "3.3 IBM1 Gains",
      "text": [
        "The final scoring method involved the gain of each word-pair parameter p(tI s) within IBM1.",
        "Instead of taking gains with respect to an initial model as in the previous section, I computed them with respect to a \"full\" model which incorporated all available word pairs: __ 1 p(TIS) Gst ITI log pst(T I S)' where pt denotes the full IBM1 model p with the parameter p(tI s) set to zero and the resulting distribution p(w Is) renormalized.",
        "The advantage of this method is that it gives a measure of each parameter's worth in the presence of other parameters.",
        "As is the previous section, this is an approximation because determining the true gain would require retraining pst and not merely renormalizing.",
        "A problem with IBM1 gains is that they are",
        "not very robust.",
        "If the corpus contains a sentence pair (s, t) which consists only of a single word pair (s, t), then Gst will contain the term",
        "Ito p(t1s)+p(t1s0) so if p(tI so) is close to zero FT-1 g p(tJso) (as is frequently the case), Gst will be close to infinity, even though (s, t) may occur only once in the training corpus.",
        "To remedy this, I computed gains with respect to a linear combination of IBM1 and a smoothing model u, of the form Ap(wI s) + (1 – A)u(wl h, s).",
        "In the experiments reported below, I used a uniform distribution for u, with A = .99.5 Smoothed IBM1 gains can be computed in parallel in a single pass over the training corpus using the algorithm in figure 1.",
        "The line marked with an asterisk takes into account the increase in p(tI s) due to renormalizing the distribution p(wI s) after setting p(t'I s) to",
        "terpolated trigram, which would make the method described here more similar to the MEMD gain ranking described in the previous section.",
        "the trigram and the overall linear model; the train segment was used for all other training.",
        "for all word pairs (s, t) : Gst �-- 0 for each sentence pair (s, t) E (S, T) :",
        "gives the number of times s occurs in s. zero, for each word t' # t in the vocabulary.",
        "To speed up the algorithm, I performed this step only for those t' such that p(t'18) > .01.",
        "This causes the gains for pairs (s, t') such that p(t'ls) < .01 to be slightly overestimated, but since the gains of such pairs are low in any case, the ranking of the most valuable pairs is unlikely to be radically affected."
      ]
    },
    {
      "heading": "4 Experiments",
      "text": [
        "I ran experiments on the Canadian Hansard corpus, with English as the source language and French as the target language.",
        "After sentence alignment using the method described in (Simard et al., 1992), the corpus was split into disjoint segments as shown in table 1.",
        "To evaluate performance, I used perplexity: p(TIS)-1/1 7-1, where p is the model being evaluated, and (S, T) is the test corpus.",
        "Perplexity is a good indicator of performance for the TransType application described in the introduction, and it has also been used in the evaluation of full-fledged SMT systems (Al-Onaizan et al., 1999).",
        "To ensure a fair comparison, all models used the same target vocabulary.",
        "of features for various feature-selection methods.",
        "To compare MEMD feature-selection methods, I first ranked all 35 million bilingual word pairs cooccurring within aligned sentence pairs in the training corpus using the MI and IBM1 gains methods.",
        "Because the MEMD gains method was much more expensive, it was used to rank only a short list of approximately 160,000 pairs derived by merging the top 100,000 candidates from each of the other methods.",
        "As shown in table 2, the three methods give substantially different rankings, even among the top-ranked pairs.",
        "For each method, I trained MEMD models on a sequence of successively larger feature sets consisting of the top-ranked word pairs for that method.",
        "The results are shown in figure 2.",
        "Due to time constraints,6 20,000- and 30,000- feature models were trained only for the IBM1 feature sets, which outperformed the other",
        "versus number of IBM1 parameters.",
        "methods by a small margin.",
        "Since the number of features in the MEMD models was much smaller than the number of parameters in the full IBM1, before comparing the MEMD and linear models I wanted to be sure that any performance difference was not due to IBM1 overfitting the training corpus.",
        "To eliminate this possibility, I optimized the number of IBM1 parameters by training linear models with various sizes of translation parameter sets obtained from the IBM1 gain ranking.",
        "As shown in figure 3, the larger linear models do exhibit a very slight overtraining effect, with the optimum parameter set size around 1M, compared to 35M parame",
        "The word pairs column gives the number of word pairs selected by the IBM1 gain ranking method, the ppx column gives test corpus perplexity, and the A column gives the perplexity drop as a percentage of the baseline.",
        "3G is the trigram model and '+' denotes linear interpolation.",
        "ters in the full model.",
        "Table 3 presents final results for various linear and MEMD models.",
        "The MEMD models give a striking improvement over the linear models, with a 1000-feature MEMD model performing better than the best linear model (despite containing 1000 times fewer word-pair parameters), and the best MEMD model yielding a perplexity reduction of more than 45% over the baseline linear model."
      ]
    },
    {
      "heading": "5 Discussion",
      "text": [
        "The main result of this paper MEMD framework appears to more effective way to combine from different sources than linear interpolation, at least for the problem studied here.",
        "It is fairly easy to see intuitively why this should 50 is that the be a much information be the case: MEMD essentially multiplies predictive scores arising from different sources rather than averaging them.",
        "This gives information sources which assign either very high or very low scores much more influence over the final result.",
        "When such scores are based upon reliable evidence, this will lead to better models.",
        "One somewhat surprising result of these experiments was that the IBM1 gains feature selection method resulted in better models than the MEMD gains method, despite the fact that the latter is based on a much more direct measure of each feature's worth within the MEMD model.",
        "A possible explanation for this is that the gain over the reference trigram is not a good predictor of the gain in the presence of many other features; this is borne out by the fact that, for very small feature sets (on the order of 100 words and less), the MEMD method did outperform the IBM1 method.",
        "Another explanation is inaccuracies in the gain approximations computed by Printz' method, which involves many numerical parameters that require tuning.",
        "Further investigation is required into this and other techniques for finding valid word pairs, since all methods tested yielded significant quantities of noise beyond 30,000 pairs.",
        "Because the source vocabulary contains about 50,000 words this is obviously an unrealistically small number of translations.",
        "Although the main use for the model I have described in this paper is in applications like TransType which need to make rapid predictions of upcoming target text, it is interesting to speculate about whether a MEMD model for p(wIh, s) could also be useful for SMT.",
        "Compared to the standard noisy channel approach, this has the advantage of permitting much less complex search procedures; of allowing any information which is directly observable in the training corpus to be very easily incorporated into the model via boolean features; and of an estimation procedure where translation model parameters can be optimized for use with an existing language model.?",
        "Disadvantages include the high cost of training MEMD models, the fact that p(wlh, s) is somewhat less general than p(sIt) for building realistic translation models; and the lack of a mechanism equivalent to the EM algorithm for incorporating \"hidden\" variables into MEMD models (see (Foster, 2000) for a discussion of this problem)."
      ]
    },
    {
      "heading": "6 Conclusion",
      "text": [
        "The problem of searching for the best target text in statistical translation applications can be greatly simplified if the fundamental distribution p(tIs) is expanded directly in terms of the distribution p(wIh, s), rather than using the standard noisy-channel approach.",
        "I compared a simple linear model for p(w1h, s) based on IBM's model 1 with an equivalent MEMD model, and found that the MEMD model has over 45% lower test corpus perplexity, despite using two orders of magnitude fewer parameters.",
        "I also compared several methods for selecting MEMD word-pair features, and found that a simple method which ranks pairs according to their gain within model 1 offers slightly better performance and significantly lower computational cost than a more general MEMD feature-selection algorithm due to Printz.",
        "Finally, I suggest that it may be fruitful to explore the idea of using a MEMD model for p(w1h, s) as an alternative to the noisy-channel approach to SMT.",
        "Acknowledgements This work was carried out as part of the TransType project at RALI, funded by the Natural Sciences and Engineering Research Council of Canada.",
        "I wish to thank Guy La-palme and Andreas Eisele for comments on the paper, and Philippe Langlais for inspiring discussions."
      ]
    }
  ]
}
