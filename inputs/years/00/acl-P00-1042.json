{
  "info": {
    "authors": [
      "Kiyotaka Uchimoto",
      "Qing Ma",
      "Masaki Murata",
      "Hiromi Itoh Ozaku",
      "Hitoshi Isahara"
    ],
    "book": "Annual Meeting of the Association for Computational Linguistics",
    "id": "acl-P00-1042",
    "title": "Named Entity Extraction Based on a Maximum Entropy Model and Transformation Rules",
    "url": "https://aclweb.org/anthology/P00-1042",
    "year": 2000
  },
  "references": [
    "acl-A97-1029",
    "acl-E99-1026",
    "acl-J95-4004",
    "acl-J96-1002",
    "acl-M95-1012",
    "acl-M95-1013",
    "acl-M98-1006",
    "acl-M98-1018",
    "acl-W96-0213",
    "acl-W97-0301",
    "acl-W98-1118",
    "acl-W98-1120",
    "acl-X98-1014"
  ],
  "sections": [
    {
      "heading": "Abstract",
      "text": [
        "This paper describes named entity (NE) extraction based on a maximum entropy (M.E.)",
        "model and transformation rules.",
        "There are two types of named entities when focusing on the relationship between morphemes and NEs as defined in the NE task of the IREX competition held in 1999.",
        "Each NE consists of one or more morphemes, or includes a substring of a morpheme.",
        "We extract the former type of NE by using the M.E.",
        "model.",
        "We then extract the latter type of NE by applying transformation rules to the text."
      ]
    },
    {
      "heading": "1 Introduction",
      "text": [
        "Named entity (NE) extraction is one basic technique used in information extraction.",
        "It can also help to improve the accuracy of morphological and syntactic analysis.",
        "The competition held at the MUC (Message Understanding Conference) (SAIC, 1998) since 1980 in the U.S. has helped to improve the technique.",
        "In Japan, the \"IREX (Information Retrieval and Extraction Exercise)\" project began sponsoring a similar competition in 1998.",
        "NE extraction is one of two tasks in the competition.",
        "The targets for extraction in this task are the names of organizations such as \"*W( (the Ministry of Posts and Telecommunications),\" people's names such as \")11 FAA (Yasunari Kawabata),\" names of locations such as \"VP (Kobe),\" names of artifacts such as \",t 0 – '7- (Toyota's Corolla car),\" and expressions which represent dates, times, sums of money, and percentages, such as \"9 128 H (September 28th),\" \"q-fk 3 (3 p. m.),\" \"100 T7 F9 (one million yen),\" and \"10%.\"",
        "There are many and various NEs, and new ones are produced all of the time, so it is impossible to add all of them to a dictionary.",
        "There are also ambiguities in usage so that a given expression may be used as a location name in one context and as a person's name in another context.",
        "Therefore, it is not easy to identify NEs, and to identify the type of each NE, in a given sentence.",
        "There are two main approaches to extracting NEs, one based on hand-crafted rules and the other based on a machine-learning.",
        "The former approach is costly because definitions differ across applications, and the rules have to be changed according to the application.",
        "The machine-learning approach requires a training corpus, but a high accuracy can be achieved without requiring a large amount of data if we use a learning model which includes ways of overcoming the data sparseness problem.",
        "Therefore, we have taken the latter approach.",
        "Many methods based on maximum entropy (M.E.)",
        "models have been very accurate (Ratnaparkhi, 1996; Ratnaparkhi, 1997; Borthwick et al., 1998a; Uchimoto et al., 1999), and the M.E.",
        "model can be adapted to deal with the data sparseness problem effectively.",
        "We have thus used the M.E.",
        "model to extract NEs.",
        "After identifying NEs in a given text by applying our model, we apply transformation rules which have been acquired by an error-driven learning method to the text.",
        "2 Named Entity Extraction Algorithm We have used the definition of NEs which is used in the IREX-NE task (IREX Executive Committee, 1999).",
        "Eight types of NE, \"ORGANIZATION\", \"PERSON\", \"LOCATION\" �\"ARTIFACT\" �\"DATE\" �\"TIME\" \"MONEY\", and \"PERCENT\" are defined.",
        "This section describes the method of identifying NEs in a given text and assigning one of eight SGML tags which represent the type of NE to each one.",
        "Each NE consists of one or more morphemes, or includes a substring of a morpheme.",
        "We define 40 NE labels, as explained below, and extract an NE which consists of one or more morphemes by estimating the appropriate NE labels according to an M.E.",
        "model.",
        "The trained M.E.",
        "model detects the relationship between features and the NE labels assigned to morphemes.",
        "The features are clues used for estimating the labels.",
        "After estimating the NE labels according to the M.E.",
        "model, we extract an NE, which includes a substring of a morpheme, by using transformation rules that will be explained later.",
        "In detail, the following steps are used to extract NEs.",
        "1.",
        "Morphological analysis of a given text.",
        "We used JUMAN (Kurohashi and Na-gao, 1998) for morphological analysis.",
        "For example, the phrase \"A *Aft t. r ,",
        "vided into the morphemes shown in the first line of Table 1, and morphological information as shown in the second and third lines of Table 1 is assigned to each morpheme.",
        "2.",
        "Assigning NE labels to each morpheme.",
        "We defined the following 40 NE labels, and the rules for connectivity between the labels, which we call connectivity rules, as shown in Table 2.",
        "(a) We added an \"OPTIONAL\" tag to the eight NE tags, then divided each into four types of sub labels which represented the beginning, middle, and end of an NE, or an NE which consisted of a single morpheme.",
        "We thus defined 9x4=36 NE labels.",
        "For example, the \"PERSON\" tag was divided into \"PERSON:BEGIN\", \"PERSON:MIDDLE\", \"PERSON:END\", and \"PERSON: SINGLE\".",
        "We divided the NE tags into four types because several morphemes can constitute a single NE.",
        "The \"OPTIONAL\" tag was defined because, in some cases, even a human judge would find it difficult to decide which tag should be assigned to a string, or whether a string is or is not an NE.",
        "For example, should :5: (The Tokyo high court)\" be tagged as \"LOCATION\" or \"ORGANIZATION\"?",
        "Should \"H ,U (Nikkei, the abbreviation of the name of a newspaper publishing company in Japan)\" in the expression \"H U*i-J fN (Nikkei stock average)\" be tagged as \"ORGANIZATION\" or not?",
        "In these cases, � � rk A \" and \"H U\" are tagged as \"OPTIONAL\", and are not extracted as NEs.",
        "The definition of the \"OPTIONAL\" tag is also the same as that which is used in the IREX-NE task.",
        "We defined the tag to learn its characteristics and to avoid assigning NE tags to strings in such difficult cases as those explained above.",
        "(b) We defined three more NE labels, \"PRE\", \"POST\", and \"MID\", to distinguish morphemes to the left and right, and between NEs, respectively, from the other morphemes.",
        "For example, \"�k P9 (Osaka)\" and \"VP (Kobe)\" in the phrase \" V� H �k P9 L *P T (Yesterday in Osaka and Kobe...)\" are the names of locations, so the whole phrase is tagged in the following way.",
        "(In this table, \"ORG\" and \"ART\" indicate \"ORGANIZATION\" and \"ARTIFACT,\" respectively.)",
        "(In this table, \"ORG\" and \"ART\" indicate \"ORGANIZATION\" and \"ARTIFACT,\" respectively.)",
        "relationship at index t in the test corpus as: relationship at index t in the test corpus as:",
        "P(f Pub) = P(f lInformation derivable from the test corpus related to relationship t) The computation of P(f Ih) in M.E.",
        "is dependent on a set of \"features\" which should be helpful in making a prediction about the future.",
        "Like most current M.E.",
        "models in computational linguistics, our model is restricted to the features which are binary functions of the history and the future.",
        "For instance, one of our features is The computation of P(f Ih) in M.E.",
        "is dependent on a set of \"features\" which should be helpful in making a prediction about the future.",
        "Like most current M.E.",
        "models in computational linguistics, our model is restricted to the features which are binary functions of the history and the future.",
        "For instance, one of our features is",
        "Here \"has(h,x)\" is a binary function which returns true if the history h has the attribute x. g(h, f ) in Eq.",
        "(1) can return 1 when the major part-of-speech of the target morpheme is verb.",
        "We use the following information as features on the target morpheme: a lexical item and the parts-of-speech it belongs to, and the same information on the four closest morphemes, the two on the left and the two on the right of the target morpheme.",
        "In our experiments, we used 12,368 lexical items that appeared five times or more in the training corpus.",
        "The part-of-speech Here \"has(h,x)\" is a binary function which returns true if the history h has the attribute x. g(h, f ) in Eq.",
        "(1) can return 1 when the major part-of-speech of the target morpheme is verb.",
        "We use the following information as features on the target morpheme: a lexical item and the parts-of-speech it belongs to, and the same information on the four closest morphemes, the two on the left and the two on the right of the target morpheme.",
        "In our experiments, we used 12,368 lexical items that appeared five times or more in the training corpus.",
        "The part-of-speech",
        "\"OPTIONAL\" or the other eight tags defined for the IBEX-NE task.)",
        "categories are the same as those used by JUMAN.",
        "We used 27,370 features that were found three times or more in the training corpus.",
        "Given a set of features and some training data, the maximum entropy estimation process produces a model in which every feature gi has associated with it a parameter a2.",
        "This allows us to compute the conditional probability as follows (Berger et al., 1996): The maximum entropy estimation technique guarantees that for every feature gi, the expected value of gi according to the M.E.",
        "model will equal the empirical expectation of gi in the training corpus.",
        "In other words:",
        "Here P �is an empirical probability and PALE.",
        "is the probability assigned by the M.E.",
        "model.",
        "Let us assume that a given sentence consists of n morphemes.",
        "One of the NE labels as defined above is assigned to each morpheme mi (1 < i < n) by using the morphological information acquired in the first step of the process we are describing.",
        "The NE label assigned to the i-th morpheme mi is selected according to probabilities estimated by a trained M.E.",
        "model.",
        "We call the probability of a particular NE label being assigned to a morpheme, the labeling probability.",
        "The labeling probability is represented by Eq.",
        "(2).",
        "We assume that a labeling probability for a whole sentence can be determined as the product of all labeling probabilities in the sentence.",
        "We employ the Viterbi algorithm to find the optimal set of assigned NE labels in a sentence with the condition that the placement of labels satisfies connectivity rules shown in Table 2.",
        "3.",
        "Post-processing by using transformation rules.",
        "The boundaries between morphemes which result from analysis by JUMAN do not always correspond to the boundaries between named entities as defined in the IREX-NE task.",
        "So after the NEs have been labeled in the second step, we use transformation rules which are automatically determined to extract NEs with boundaries that are not same as those between morphemes.",
        "Transformation rules are acquired by an error-driven learning method which is similar to that used by Brill (Brill, 1995) for POS tagging.",
        "The difference between our method of rule acquisition and Brill's is that Brill",
        "uses templates to acquire rules and we do not.",
        "In our method, rules are automatically acquired by investigating the difference between two sets of data, NE labels in a tagged corpus and those extracted during the previous step from the same corpus without tags.",
        "We extract all of the differences in places where the two data sets are broken up into a different number of units or morphemes even though the strings are the same, and use them as transformation rules.",
        "For example, the rule shown in Figure 1 was acquired.",
        "The antecedent and consequent interpretations are from the result of the previous step and a tagged corpus, respectively.",
        "If several different rules have the same antecedent part, only the rule with the highest frequency is chosen.",
        "If several rules share the highest frequency, all of the rules are removed from transformation rules.",
        "Furthermore, if there are rules which decrease the accuracy of the method on the training corpus, they are removed.",
        "4.",
        "Transforming NE labels to NE tags.",
        "After transforming NE labels to NE tags, the \"OPTIONAL\" tag is removed because it is not a target of the task.",
        "For example, \"A* (OTHER)\" on the first candidate in Table 1 is transformed to \"A (PRE) * (LOCATION: SINGLE)\" in the third step.",
        "We get the following output after transforming NE labels to NE tags."
      ]
    },
    {
      "heading": "3 Experiments and Discussion",
      "text": []
    },
    {
      "heading": "3.1 Data Used in Our Experiments",
      "text": [
        "For training, we used the CRL (Communications Research Laboratory) NE data, IREX-NE dry-run training data, IREX-NE dry-run data, and IREX-NE formal-run domain-specific data.",
        "The total number of sentences is about 12,000, and the total number of morphemes is about 303,200.",
        "All data consist of articles from the Mainichi newspaper, and are tagged with the nine NE tags in SGML format.",
        "We used these data after morphologically analyzing the text and transforming the NE tags into our new NE labels.",
        "For testing, we used the IREX-NE formal-run data, which consists of articles of two kinds, 71 (about 400 sentences) in a general domain and 20 (about 100 sentences) in a specific domain, the topic being an arrest.",
        "They were selected from the Mainichi newspaper articles which appeared from April 14th to May 13th in 1999, and were also tagged with NE tags 1.",
        "The definition of tags is that of the IREX-NE task."
      ]
    },
    {
      "heading": "3.2 Experimental Results",
      "text": [
        "The results are shown in Table 3.",
        "The first and second columns show the results for the specific domain (ARREST) and the general domain (GENERAL), respectively.",
        "We did not tune our model to either domain.",
        "Comparing the results with those of experiments carried out without transformation rules, we found the accuracy for the formal experiments had an F-measure, for both domains, one or two points better than those without transformation rules, as shown in Table 3.",
        "In the IREX-NE formal-run, any tags assigned by a system within the region tagged \"OPTIONAL\" in the formal-run data are ignored in the evaluation.",
        "When a region tagged by a system and the region tagged \"OPTIONAL\" overlap, it is counted as an error.",
        "Our evaluation followed this standard."
      ]
    },
    {
      "heading": "3.3 Transformation Rules and",
      "text": [
        "Accuracy We applied the transformation rules to NEs which included a substring of a morpheme.",
        "The rules were applied to 18 such NEs in the specific domain, and 79 in the general domain.",
        "Each of the figures represents about 5% of the NEs in the formal-run data, for each domain.",
        "362 rules were automatically acquired from the training corpus.",
        "Nine rules were applied eleven times in processing of the specific domain data, with one error.",
        "The re-'All data are available on the IBEX web site (IBEX",
        "call and precision were 56% (10/18) and 91% (10/11), respectively.",
        "Twelve rules were applied 42 times in processing of the general domain data.",
        "There were 10 errors.",
        "The recall and precision were 41% (32/79) and 76% (32/42), respectively.",
        "We found the following two types of errors.",
        "• A substring of an NE was extracted as",
        "an NE by mistake in one case.",
        "The substring \"H (nichi, Japan)\" was extracted as LOCATION from the name of a location \"A H* V Fi It t (zainichi_beigun_gokota_kichi, an American military base in Yokota).\"",
        "The whole of \"A H * V Fi It t\" should have been extracted as LOCATION according to the IREX-NE definition.",
        "The M.E.",
        "model was not able, however, to achieve this.",
        "Consequently, a transformation rule was applied to the whole string, and the substring was extracted by mistake.",
        "To reduce such errors, the M.E.",
        "model needs to be improved.",
        "• Definitions assigned in the test data differed from those in the training data (10 cases). \"\"",
        "in the word \"A (houjin, Japa-nese)\" and \"A\" in the word \"A t0 'JI;",
        "(gaisou_kaidan, Foreign Office Minister conference)\" were defined as LOCATION and ORGANIZATION, respectively, in the training corpus while they were not NEs in the test data.",
        "To reduce such errors, maintenance of the training corpus is essential.",
        "We obtained an improvement of about two points in the F-measure for the specific domain, and about 1.5 points in the F-measure for the general domain, by applying transformation rules.",
        "In our experiments, the system automatically acquired rules with consequent parts that always have NEs which include a substring of a morpheme, but did not acquire rules with consequent parts that do not have NEs which include a substring of a morpheme.",
        "So we carried out the experiments with all of the rules.",
        "We then obtained F-measures of 72.23 for the specific domain and 73.12 for the general domain.",
        "For the specific domain the results were ten points worse, and for the general domain five points worse, than the accuracies of the experimental results obtained without transformation rules.",
        "This result shows that the transformation rules acquired for any types of NEs do not have the ability to correctly revise NE labels assigned by our M.E.",
        "model.",
        "However, our rule ac",
        "quisition method is simple and we obtained good results with the rules acquired for NEs which include a substring of a morpheme.",
        "So we can conclude that the transformation rules acquired by our method are effective in extracting NEs which include a substring of a morpheme, which cannot be extracted by our M.E.",
        "model.",
        "3.4 Features and Accuracy This section describes how much each feature set contributes to improving the accuracy.",
        "We carried out the experiments with each feature set alone, and with all feature sets but one, omitting each in turn.",
        "We used transformation rules in those experiments.",
        "Table 4 shows the performance under these conditions.",
        "In this table, \"F\" indicates the F-measure and \"Difference\" indicates the degradation from the results for the formal experiment.",
        "We achieved high accuracy with lexical items, and the accuracy decreased significantly when lexical items were not used.",
        "This result shows that the lexical items are the most important features for improving the accuracy.",
        "Table 5 is a comparison with performance of the analysis for features of the target morpheme alone, and for performance with the features of surrounding morphemes as well.",
        "In this table, \"On only (0)\" indicates that we used features of the target morpheme alone, \"On (-1) to (1)\" indicates that we used features of the target morpheme and two adjacent morphemes.",
        "\"On (-2) to (2)\" indicates that we used features of the target morpheme and four other morphemes, the two on the left and the two on the right of the target.",
        "\"On (-3) to (3)\" indicates that we used features of the target morpheme and the six nearest morphemes, i.e., the three on the left and the three on the right.",
        "The best accuracy was achieved when we used the features of the target morpheme and the four nearest morphemes.",
        "The accuracy decreased when we used the features of the target morpheme and the six nearest morphemes.",
        "We believe that it is due to the data sparseness problem."
      ]
    },
    {
      "heading": "3.5 Amount of Training Data and Accuracy",
      "text": [
        "Figure 2 shows the relationship between the amount of training data (the number of sentences) and accuracy.",
        "The horizontal axis indicates the number of sentences in training data, and the vertical axis indicates the F-measure.",
        "In this figure, the notation \"arrest\" and \"general\" are used to indicate the results",
        "in the specific and general domains, respectively, and \"with-rules\" and \"without-rules\" are used to indicate the results obtained with and without transformation rules, respectively.",
        "These learning curves suggest that we can expect a certain amount of improvement with the use of more training data."
      ]
    },
    {
      "heading": "3.6 Use of an NE dictionary",
      "text": [
        "Borthwick (Borthwick, 1999) and Nobata (Nobata, 1999) have developed other systems for extracting NEs.",
        "They have obtained improved accuracy by using an NE dictionary.",
        "We carried out an experiment with an NE dictionary.",
        "We used whether or not the target morpheme is in the NE dictionary as a feature.",
        "We used the same dictionary as used by Borthwick and Nobata, available on Sekine's web site (Sekine, 1999) This is an NE dictionary of the names of organizations and locations, with about 1,000 entries.",
        "We also extracted NEs which appeared three or more times in a training corpus and added them to the NE dictionary.",
        "About 1,400 NEs were extracted (ORGANIZATION: 272, PERSON: 336, LOCATION: 339, ARTIFACT: 45, DATE: 233, TIME: 31, MONEY: 21, PERCENT: 45, OPTIONAL: 56).",
        "The total number of NEs in the NE dictionary was then about 2,400.",
        "We used JUMAN to morphologically analyze the NEs in the dictionary, and assigned one of the NE labels that we defined in Section 2 to each morpheme.",
        "There was a total of about 10,000 morphemes in the NE dictionary.",
        "When a string for a target morpheme was found in the dictionary, we used the NE label assigned to the corresponding morpheme in the dictionary as a feature value.",
        "Table 6 shows the result obtained with the NE dictionary.",
        "The accuracy as expressed by the F-measure improved by about two points in the specific domain and about one point in the general domain, over the accuracy obtained without the NE dictionary.",
        "If we had an NE dictionary with more entries, we could achieve yet higher accuracies."
      ]
    },
    {
      "heading": "3.7 Related Works",
      "text": [
        "With regard to named entity extraction from English sentences, statistical methods based on a hidden Markov model (HMM) (Bikel et al., 1997; Miller et al., 1998), a decision tree model (Cowie, 1995), an M.E.",
        "model",
        "(Borthwick et al., 1998a), collocation statistics (Lin, 1998), and a transformation-based error-driven learning model (Aberdeen et al., 1995) have been proposed so far.",
        "In the MUC competition, the highest accuracy has been achieved by a system called Nymble (Bikel et al., 1997) which is based on an HMM.",
        "This system extracts NEs by applying the following procedure.",
        "A finite-state transition network is prepared.",
        "Each state of the network represents an NE defined in the MUC-NE task, such as PERSON or ORGANIZATION, or represents NOT-A-NAME which means the word is not a defined NE.",
        "Each transition has a transition probability, which represents the transition's conditional probability for a given input word.",
        "The analysis is a search for the optimal path in the network which uses the Viterbi algorithm.",
        "The states in the optimal path give us NEs.",
        "In the other systems, named entities are extracted by a similar procedure, except that the way of estimating the probability varies.",
        "Borthwick and his coworkers selected several systems which obtained a high accuracy in the MUC-NE task from among those based on statistical methods and those based on hand-crafted rules, and obtained better results than any of the individual systems by integrating them on the basis of the M.E.",
        "model (Borthwick et al., 1998a).",
        "They reported that a good accuracy which surpassed human performance could be obtained for a certain data set by integrating several systems (Borthwick et al., 1998b).",
        "With regard to named entity extraction from Japanese sentences, similar statistical methods have been proposed, including methods based on an HMM (Shinnou, 1999), a decision tree model (Sekine et al., 1998; Nobata, 1999), and an M.E.",
        "model (Borthwick, 1999).",
        "Borthwick's approach is similar to ours except that he used hand-crafted transformation rules while we use automatically acquired rules alone.",
        "The accuracy we reported in Section 3.6 is better than that which Borthwick obtained.",
        "Our method is more accurate than any other system based on a statistical method that participated in the last IREX-NE workshop, and is close to that obtained by the system which obtained the highest accuracy for the IREX-NE task.",
        "➉ ➊onclusion This paper described the extraction of named entities on the basis of an M.E.",
        "(maximum entropy) model and transformation rules.",
        "Eight types of NE are defined by IREX-NE, and each NE consists of one or more morphemes, or includes a substring of a morpheme.",
        "We defined 40 NE labels to indicate the beginning, middle, and end of NEs, and extract NEs which consist of one or more morphemes by estimating the labels according to an M.E.",
        "model.",
        "After this estimation, we extract NEs, which include a substring of a morpheme, by using transformation rules.",
        "These rules are automatically acquired by investigating the difference between NE labels in a tagged corpus and those extracted from the same corpus without tags by our system.",
        "Through our experiments, we found that the transformation rules contribute to an improved accuracy, lexical items are the most important features, and the best accuracy was achieved when we used the features of the target morpheme and the four morphemes closest to it, i.e., the two on the left and the two on the right, when a training corpus with 12,000 sentences was used.",
        "These results were obtained with the information in the training corpus alone.",
        "When we used an NE dictionary which is available on the web as well, we achieved an F-measure of 85.75 for a specific domain, and 80.17 for a general domain, for IREX-NE formal-run data.",
        "There are several possible future directions.",
        "In particular, we are interested in the following issues.",
        "❥ Finding effective features We expect that we can achieve higher accuracy by using information that we are not using at the moment, such as information on dependencies between phrasal units called 'bunsetsu', anaphoric relations, and the information given in the process of analyzing text.",
        "• Corpus revision and an NE dictionary",
        "We found that errors in a training corpus will lead to a lower accuracy, and that dictionary information helps to improve the accuracy.",
        "Therefore, corpus revision should be actively studied, and larger NE dictionaries will also be helpful.",
        "We may be able to tune the model to a particular domain by preparing an NE dictionary adapted to the domain.",
        "We would like to try this, and see how well an adapted dictionary works.",
        "Acknowledgments The authors would like to thank Satoshi Sekine and Andrew Borthwic for fruitful comments and helpful discussions during the progress of this work."
      ]
    }
  ]
}
