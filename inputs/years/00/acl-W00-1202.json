{
  "info": {
    "authors": [
      "Hsin-Hsi Chen",
      "Chi-Ching Lin"
    ],
    "book": "Chinese Language Processing Workshop",
    "id": "acl-W00-1202",
    "title": "Sense-Tagging Chinese Corpus",
    "url": "https://aclweb.org/anthology/W00-1202",
    "year": 2000
  },
  "references": [
    "acl-P96-1006"
  ],
  "sections": [
    {
      "heading": "Abstract",
      "text": [
        "Contextual information and the mapping from WordNet synsets to Cilin sense tags deal with word sense disambiguation.",
        "The average performance is 63.36% when small categories are used, and 1, 2 and 3 candidates are proposed for low, middle and high ambiguous words.",
        "The performance of tagging unknown words is 34.35%, which is much better than that of baseline mode.",
        "The sense tagger achieves the performance of 76.04%, when unambiguous, ambiguous, and unknown words are tagged."
      ]
    },
    {
      "heading": "1 Introduction",
      "text": [
        "Tagging task, which adds lexical, syntactic or semantic information to raw text, makes materials more valuable.",
        "The researches on part of speech (POS) tagging have been a long history, and achieve very good results.",
        "Many POS tagged corpora are available.",
        "The accuracy for POS-tagging is in the range of 95% to 97%1.",
        "In contrast, although the researches on word sense disambiguation (WSD) are also very early (Kelly and Stone, 1975), large-scale sense-tagged corpus is relatively few.",
        "In English, only some sense-tagged corpora such as HECTOR (Atkins, 1993), DSO (Ng and Lee, 1996), SEMCOR (Fellbaum, 1997), and SENSEVAL (Kilgarriff, 1998) are available.",
        "For evaluating word sense disambiguation systems, the first SENSEVAL (Kilgarriff and Rosenzweig, 2000) reports that the performance for a fine-grained word sense disambiguation task is at around 75%.",
        "1 The performance includes tagging unambiguous words.",
        "Marshall (1987) reported that the performance of CLAWS tagger is 94%.",
        "Approximately 65% of words were tagged unambiguously, and the disambiguation program achieved better than 80% success on the ambiguous words."
      ]
    },
    {
      "heading": "Chi-Ching Lin",
      "text": [
        "Three approaches have been proposed for WSD, including dictionary/thesaurus-based approach, supervised learning, and unsupervised learning.",
        "The major differences are what kinds of resources are used, i.e., dictionary versus text corpus, and sense-tagged corpus versus untagged corpus.",
        "A good survey refers to the paper (Ide and Veronis, 1998).",
        "Compared with English, Chinese does not have large-scale sense-tagged corpus.",
        "The widely available corpus is Academic Sinica Balanced Corpus abbreviated as ASBC hereafter (Huang and Chen, 1995), which is a POS-tagged corpus.",
        "Thus, a computer-aided tool to sense-tag Chinese corpus is indispensable.",
        "This paper presents a sense tagger for Mandarin Chinese.",
        "It is organized as follows.",
        "Section 2 discusses the degree of polysemy in Mandarin Chinese from several viewpoints.",
        "Section 3 presents WSD algorithms for tagging ambiguous words and unknown words.",
        "Section 4 shows our experimental results.",
        "Finally, Section 5 concludes the remarks."
      ]
    },
    {
      "heading": "2 Degree of Polysemy in Mandarin Chinese",
      "text": [
        "The degree of polysemy is defined as the average number of senses of words.",
        "We adopt tagging set from tong2yi4ci2ci2lin2 ( ral ti-1161 *) abbreviated as Cilin (Mei, et al., 1982).",
        "It is composed of 12 large categories, 94 middle categories, and 1,428 small categories.",
        "Small categories (more fine granularity) are used to compute the distribution of word senses.",
        "Besides Cilin, ASBC is employed to count frequency of a word.",
        "Total 28,321 word types appear both in Cilin and in ASBC corpus.",
        "Here a word type corresponds to a dictionary",
        "entry.",
        "Of these, 5,922 words are polysemous, i.e., they have more than one sense.",
        "Table 1 lists the statistics.",
        "We divide the ambiguity degree into three levels according to the number of senses of a word.",
        "It includes low (2-4), middle (5-8), and high ambiguity (>8).",
        "The statistics shows that 93.77% of word types belong to the class of low ambiguity.",
        "We further consider POS when computing the distribution of word senses.",
        "Table 2 shows the statistics.",
        "N, V, A, F, and K denote nouns, verbs, adjectives, numerals, and auxiliaries (adverbs), respectively.",
        "We can find most of words belong to the class of low ambiguity no matter which POSes they are.",
        "Besides, the ambiguity is decreased when POS is considered.",
        "The number of polysemous words is down to 4,132.",
        "For A and K, the number of senses is no more than 7, and the percentages in the class of low degrees are 98.22% and 97.08%, respectively.",
        "For N and V, there are some high ambiguous words.",
        "In particular, the verb (#T, da3) has 19 senses2.",
        "The percentages in the class of low degrees are 97.53% and 94.70%, respectively.",
        "Then, the frequency of word types is considered.",
        "ASBC corpus is used to compute the occurrences of word types.",
        "Table 3 lists the statistics.",
        "A word token is an occurrence of a type in the corpus.",
        "On the average, the words of low, middle and high ambiguity appear 205.96, 1926.65, and 4480.28 times, respectively.",
        "Table 1 shows 93.77% of polysemous words belong to the class of low ambiguity, but Table 3 illustrates they only 2 The word (#I-, da3) has 20 senses.",
        "Besides verb usage, it also functions as an auxiliary.",
        "occupy 58.52% of tokens in ASBC corpus.",
        "Table 4 summarizes the distribution of word senses and frequencies.",
        "Low frequency denotes the number of occurrences less than 100, middle frequency denotes the number of occurrences between 100 and 1000, and high frequency denotes the number of occurrences more than 1000.",
        "Rows C and A in Table 4 denote number of word types and word tokens, respectively.",
        "The last column denotes percentage for each ambiguity degree.",
        "For example, the percentage of word types with low ambiguity is 96.64% (i.e., 3993/4132).",
        "This table shows the following two phenomena:",
        "(1) POS information reduces the degree of ambiguities.",
        "Total 8.94% of word tokens are high ambiguous in Table 3.",
        "It decreases to 0.47% in Table 4.",
        "(2) High ambiguous words tend to be high frequent.",
        "From the row of low ambiguity, there are 3,112 low-frequent words.",
        "They",
        "occur 70,131 times in ASBC corpus.",
        "Comparatively, there are only 881 middle or high-frequent words, but they occur 966,774 times.",
        "That is, 23.67% of word types are middle or high-frequent words, and they occupy 94.06% of word tokens.",
        "From the row of high ambiguity, there are only a few words, but they occur frequently in the ASBC corpus.",
        "It shows that semantic tagging is a challengeable problem in Mandarin Chinese."
      ]
    },
    {
      "heading": "3 Semantic Tagging",
      "text": []
    },
    {
      "heading": "3.1 Tagging Unambiguous Words",
      "text": [
        "In the semantic tagging, the small categories are selected.",
        "We postulate that the sense definition for each word in Cilin is complete.",
        "That is, a word that has only one sense in Cilin is called an unambiguous word or a monosemous word.",
        "If POS information is also considered, a word may be unambiguous under a specific POS.",
        "Because we do not have a semantically tagged corpus for training, we try to acquire the context",
        "for each semantic tag starting from the unambiguous words.",
        "ASBC corpus is the target we study.",
        "At the first stage, only those words that are unambiguous in Cilin, and also appear in ASBC corpus are tagged.",
        "Figure 1 shows this case."
      ]
    },
    {
      "heading": "Unambiguous Words",
      "text": [
        "An unambiguous word (and hence its sense tag) is characterized by the words surrounding it.",
        "The window size is set to 6, and stop words are removed.",
        "A list of stop words is trained from ASBC corpus.",
        "The words of POSes Neu (It 119), DE (0 -t. 4 3,6), SHI (k),FW ate), C (i1.4141), T (-1,ยง0,09), and I (Alt)) are regarded as stop words.",
        "A sense tag Ctag is in terms of a vector (wl, w2, wn), where n is the vocabulary size and wi is a weight of word cw.",
        "The weight can be determined by the following two ways.",
        "(1) MI metric (Church, et al., 1989) MI (Ctag ,cw).",
        "where P(Ctag) is the probability of Ctag, P(cw) is the probability of cw, P(Ctag, cw) is the cooccurrence probability of Ctag and cw, J(Ctag) is the frequency of Ctag, J(cw) is the frequency of cw, f(Ctag, cw) is the cooccurrence frequency of Ctag and cw, and Nis total number of words in the corpus.",
        "(2) EM metric (Ballesteros and Croft, 1998) em (Crag, cw) = ("
      ]
    },
    {
      "heading": "3.2 Tagging Ambiguous Words",
      "text": [
        "At the second stage, we deal with those words that have more than one sense in the Cilin.",
        "Figure 2 shows the words we consider.",
        "The approach we adopted on semantic tagging rests on an underlying assumption: each sense has a characteristic context that is different from the context of all the other senses.",
        "In addition, all words expressing the same sense share the same characteristic context.",
        "We will apply the information trained at the first stage to selecting the best sense tag from the candidates of each ambiguous word.",
        "Recall that a vector corresponds to a sense tag.",
        "We employ the similar way specified in Section 3.1 to identify the context vector of an ambiguous word.",
        "A cosine formula shown as follows measures the similarity between a sense vector and a context vector, where w and v are a sense vector and a context vector, respectively.",
        "The sense tag of the highest similarity score is chosen.",
        "We retrain the sense vector for each sense tag after the unambiguous words are resolved."
      ]
    },
    {
      "heading": "3.3 Tagging Unknown Words",
      "text": [
        "Those words that appear in ASBC corpus, but are not gathered in Cilin are called unknown words.",
        "All the 1,428 sense tags are the possible candidates.",
        "Intuitively, the algorithm in Section 3.2 can be applied directly to select a sense tag from the 1,428 candidates.",
        "However, the candidate set is very large.",
        "Here we adopt outside evidences from the mapping among WordNet synsets (Fellbaum, 1998) and Cilin",
        "sense tags to narrow down the candidate set.",
        "Figure 3 summarizes the flow of our algorithm.",
        "It is illustrated as follows.",
        "(1) Find all the English translations of an unknown Chinese word by looking up a Chinese-English dictionary.",
        "(2) Find all the synsets of the English translations by looking up WordNet.",
        "We do not resolve translation ambiguity and target polysemy at these two steps, thus the retrieved synsets may cover more senses than that of the original Chinese word.",
        "(3) Transform the synsets back to Cilin sense tags by looking up a mapping table.",
        "How the mapping table is set up will be discussed in Section 3.3.1.",
        "(4) Select a sense tag from the candidates proposed at step (3) by using the WSD in Section 3.2.",
        "Figure 4 shows the unknown words we deal with at this stage.",
        "Those words that are not gathered in our Chinese-English dictionary are not considered, so that only parts of unknown words are resolved.",
        "In other words, there remain words without sense tags."
      ]
    },
    {
      "heading": "Unambiguous Words",
      "text": [
        "At first, we put unambiguous words (specified in Section 3.1) into WordNet by looking up a Chinese-English dictionary.",
        "Although these words do not have translation ambiguity, the corresponding English translation may have target polysemy problem.",
        "In other words, the English translation may cover irrelevant senses besides the correct one.",
        "The following algorithm will find the most similar synset with Chinese sense tag.",
        "(1) If the English translation corresponds to only one synset, this synset is the solution.",
        "(2) If the English translation corresponds to more than one synset, POS is considered: (a) If the Chinese sense tag belongs to one of categories AD in Cilin (i.e., a noun sense), and there is only one noun synset, then the synset is adopted.",
        "Otherwise, we translate the context vector of the Chinese sense into English, compare it with vectors of the synsets, and select the most similar synset.",
        "(b) If the Chinese sense tag belongs to one of categories F-J.",
        "in Cilin (i.e., a verb sense), we try to find a verb synset in the similar way as (a).",
        "If it fails, we try noun and adjective synsets instead.",
        "(c) If the Chinese sense tag belongs to category E in Cilin (i.e., an adjective sense), we try adjective, adverb, noun and verb synsets in sequence.",
        "(d) If the Chinese sense tag belongs to category K in Cilin (i.e., an adverb sense), only adverb synsets are considered.",
        "Next, we consider the ambiguous words.",
        "Chinese-English dictionary lookup finds all the English translations.",
        "WordNet search collects",
        "the synset candidates for the translations.",
        "Some synsets are selected and regarded as the mapping of the Cilin sense tag.",
        "Here the problems of translation ambiguity and target polysemy must be faced.",
        "In other words, not all English translations cover the Cilin sense.",
        "Because the goal is to find a mapping table between WordNet synsets and Cilin sense tags, we neglect the problem of translation ambiguity and follow the method in the previous paragraph to choose the most similar synsets.",
        "During mapping, English translations of a word may not be found in the Chinese-English dictionary, and WordNet may not gather the English translations even dictionary lookup is successful.",
        "Thus, only 1,328 of 1,428 Cilin tags are mapped to WordNet synsets.",
        "From the other view, there remains some WordNet synsets that do not correspond to any Cilin sense tags.",
        "Let such a synset be Si.",
        "We follow the relational pointers like hypemym, hyponym, similar, derived, antonym, or participle to collect the neighboring synsets denoted by The following method selects suitable Chin tag(s) for Si.",
        "(1) If S; is the only one synset that has been mapped to Cilin tags, we choose a Chin tag and map Si to it.",
        "(2) If there exists more than one S; (say, Sp,",
        "Si2, ..., SO that has been mapped to Cilin tags, we choose the Cilin tags that more synsets map to.",
        "The above method is called a more restrictive scheme.",
        "An alternative method (called less restrictive method) is: all the Cilin tags that the neighboring synsets map to are selected.",
        "If Cilin tags cannot be found from neighboring synsets, we extend the range one more, and repeat the selection procedure again until all the synsets are considered."
      ]
    },
    {
      "heading": "4 Experiments",
      "text": []
    },
    {
      "heading": "4.1 Test Materials",
      "text": [
        "We sample documents of different categories from ASBC corpus, including philosophy (10%), science (10%), society (35%), art (5%), life (20%) and literary (20%).",
        "There are 35,921 words in the test corpus.",
        "Research associates tag this corpus manually.",
        "At first, they mark up the ambiguous words by looking up the Chin dictionary.",
        "Next, they tag the unknown words.",
        "A list of candidates is proposed by looking up the mapping table.",
        "Because the mapping table may have errors, the annotators assign a tag \"none\" when they cannot choose a solution from the proposed candidates.",
        "Total 435 of 1,979 words are tagged with \"none\" with the more restrictive method.",
        "In contrast, only 346 words are labeled with \"none\" with the less restrictive method.",
        "The tag mapper achieves 82.52% of performance approximately."
      ]
    },
    {
      "heading": "4.2 Tagging Ambiguous Words",
      "text": [
        "Table 5 shows the performance of tagging ambiguous words.",
        "MI defined in Section 3.1 is used.",
        "Total 11,101 words are tagged.",
        "The performance of tagging low, middle, and high ambiguous words are 62.60%, 31.36%, and 27.00%, respectively.",
        "Table 6 shows that the performance is improved, in particular, the classes of middle and high ambiguity, when EM (defined in Section 3.1) is used.",
        "The overall performance is increased from 49.55% to 52.85%.",
        "In the previous experiments, only one sense is reported for each word.",
        "If we report more than one sense for middle and high ambiguous words, the performance is improved.",
        "Table 7 shows that the first 2 and 3 candidates are selected.",
        "From the diagonal of this table, the performance for tagging low ambiguity (2-4), middle ambiguity (5-8) and high ambiguity (>8) is similar (i.e., 63.98%, 60.92% and 67.95%) when 1 candidate, 2 candidates, and 3 candidates are proposed, respectively.",
        "In this case, 7,034 of 11,101 words are tagged correctly.",
        "That is, the performance is 63.36%.",
        "In the next experiment, we adopt middle categories (i.e., 94 categories) rather than the above small categories (i.e., 1428 categories).",
        "Table 8 shows that the overall performance is improved by 11.05%.",
        "It also lists the results with the combinations of first-n and middle categories.",
        "Under the middle categories and 1-3 proposed candidates, the performance for tagging low, middle and high ambiguous words are 71.02%, 73.88%, and 75.94%, respectively.",
        "Total 8,033 of 11,101 words are tagged correctly.",
        "In other words, the performance is 72.36%."
      ]
    },
    {
      "heading": "4.3 Tagging Unknown Words",
      "text": [
        "There are 1,979 unknown words in our test corpus.",
        "Total 1,663 words have been tagged manually.",
        "In the experiments, we consider the effects from training corpus and mapping table.",
        "Table 9 shows the performance.",
        "Ml and P1 employ more restrictive mapping table, while M2 and P2 adopt less restrictive mapping table.",
        "M1 and M2 use the training result in Section 3.1 (i.e., unambiguous words), while P1 and P2 utilize the training result in Section 3.2 (i.e., unambiguous and ambiguous words).",
        "In the baseline model, all 1428 Cilin tags are the candidates of unknown words.",
        "The performance is worse.",
        "On the average, the precision is 1.22%.",
        "Ml is the best because more restrictive mapping table reduces the possibility of mapping errors.",
        "This table also lists the performance of each category.",
        "It meets our expectation, i.e., tagging verb is harder than tagging other categories.",
        "Next we use POS to improve the performance.",
        "POS narrows down the number of candidates, so that the overall performance is enhanced from 27.13%% to 34.35%%.",
        "In summary, we consider the overall performance of tagging our sample data.",
        "Recall that there are 35,921 words in the test corpus.",
        "Except the stop words that are not tagged by the sense tagger, there remain 13,586 unambiguous words, 11,101 ambiguous words, and 1,633 unknown words for tagging.",
        "From Tables 6 and 9, we know 5,867 unambiguous words and 561 unknown words are tagged correctly.",
        "The sense tagger achieves the performance of 76.04%."
      ]
    },
    {
      "heading": "5. Conclusion",
      "text": [
        "This paper analyzes the polysemy degree in Mandarin Chinese.",
        "We consider the distribution of word senses from POS and frequency.",
        "Under the Cilin small categories, 23.67% of word types in ASBC corpus are",
        "middle or high frequent words, but they occupy 94.06% of word tokens.",
        "We adopt contextual information and mapping from WordNet synsets to Cilin sense tags to deal with this challengeable problem.",
        "The performances for tagging low, middle and high ambiguous words are 63.98%, 60.92%, and 67.95% when small proposed.",
        "Comparatively, the performances categories are used and 1-3 candidates are 71.02%, 73.88%, and 75.94% by using middle categories.",
        "The performance of tagging unknown words is 34.35%.",
        "It is worse than that of tagging ambiguous words, but is much better than that of the baseline mode.",
        "The overall performance is the sense tagger is 76.04%.",
        "Although sense tagging does not achieve the performance of POS tagging, the sense tagger proposed in this paper is still a useful computer-aided tool to reduce the human cost on tagging a large-scale corpus."
      ]
    }
  ]
}
