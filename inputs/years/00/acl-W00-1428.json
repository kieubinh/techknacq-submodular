{
  "info": {
    "authors": [
      "Hongyan Jing",
      "Yael Dahan Netzer",
      "Michael Elhadad",
      "Kathleen R. McKeown"
    ],
    "book": "International Conference on Natural Language Generation",
    "id": "acl-W00-1428",
    "title": "Integrating a Large-Scale, Reusable Lexicon With a Natural Language Generator",
    "url": "https://aclweb.org/anthology/W00-1428",
    "year": 2000
  },
  "references": [
    "acl-C94-1042",
    "acl-J98-3003",
    "acl-P98-1099",
    "acl-W94-0319",
    "acl-W96-0501",
    "acl-W98-0718",
    "acl-W98-1426"
  ],
  "sections": [
    {
      "heading": "Abstract",
      "text": [
        "This paper presents the integration of a large-scale, reusable lexicon for generation with the FUF/SURGE unification-based syntactic realizer.",
        "The lexicon was combined from multiple existing resources in a semi-automatic process.",
        "The integration is a multi-step unification process.",
        "This integration allows the reuse of lexical, syntactic, and semantic knowledge encoded in the lexicon in the development of lexical chooser module in a generation system.",
        "The lexicon also brings other benefits to a generation system: for example, the ability to generate many lexical and syntactic paraphrases and the ability to avoid non-grammatical output."
      ]
    },
    {
      "heading": "1 Introduction",
      "text": [
        "Natural language generation requires lexical, syntactic, and semantic knowledge in order to produce meaningful and fluent output.",
        "Such knowledge is often hand-coded anew when a different application is developed.",
        "We present in this paper the integration of a large-scale, reusable lexicon with a natural language generator, FUF/SURGE (Elhadad, 1992; Robin, 1994); we show that by integrating the lexicon with FUF/SURGE as a tactical component, we can reuse the knowledge encoded in the lexicon and automate to some extent the development of the lexical realization component in a generation application.",
        "The integration of the lexicon with FUF/SURGE also brings other benefits to generation, including the possibility to accept a semantic input at the level of WordNet synsets, the production of lexical and syntactic paraphrases, the prevention of non-grammatical output.",
        "reuse across applications, and wide coverage.",
        "We present the process of integrating the lexicon with FITF/SURGE_ including how to represent.",
        "the lexicon in FUF format, how to unify input with the lexicon incrementally to generate more sophisticated and informative representations, and how to design an appropriate semantic input format so that the integration of the lexicon and FUF/SURGE can be done easily.",
        "This paper is organized as follows.",
        "In Section 2, we explain why a reusable lexical chooser for generation needs to be developed.",
        "In Section 3, we present the large-scale, reusable lexicon which we combined from multiple resources, and illustrate its benefits to generation by examples.",
        "In Section 4, we describe the process of integrating the lexicon with FUF/SURGE, which includes four unification steps, with each step adding additional lexical or syntactic information.",
        "Other applications and comparison with related work are presented in Section 5.",
        "Finally, we conclude by discussing future work.",
        "2 Building a reusable lexical chooser for generation While reusable components have been widely used in generation applications, the concept of a \"reusable lexical chooser\" for generation remains novel.",
        "There are two main reasons why such a lexical chooser has not been developed in the past:",
        "1.",
        "In the overall architecture of a generator, the lexical chooser is an internal component that depends on the semantic representation and for-,rnalism and on the syntactic realizer used by the application.",
        "2.",
        "The lexical chooser links conceptual elements to lexical items.",
        "Conceptual elements are by definition domain and application dependent (they are the primitive concepts used in an application knowledge base).",
        "These pritnitives are not easily ported from application to application.",
        "The emergence of standard architectures for generators (RAGS, (Reiter, 1994)) and the possibility to use a standard syntactic realizer answer the first issue.",
        "To address the second issue, one must realize that if the whole lexical chooser can not be made domain-independent, major parts can be made reusable.",
        "The main argument is that lexical knowledge is modular.",
        "Therefore, while choice of words is constrained by domain-specific conceptual knowledge (what information the sentences are to represent) on the one hand, it is also affected by several other dimensions:",
        "® inter-lexical constraints: collocations among words * pragmatic constraints: connotations of words ® stylistic constraints: familiarity of words ® syntactic constraints: government patterns of words, e.g., thematic structure of verbs.",
        "We show in this paper how the separation of the syntactic and conceptual interfaces of lexical item definitions allows us to reuse a large amount of lexical knowledge across applications."
      ]
    },
    {
      "heading": "3 The lexicon and its benefits to generation",
      "text": []
    },
    {
      "heading": "3.1 A large-scale, reusable lexicon for generation",
      "text": [
        "Natural Language generation starts from semantic concepts and then finds words to realize such semantic concepts.",
        "Most existing lexical resources, however, are indexed by words rather than by semantic concepts.",
        "Such resources, therefore, can not be used for generation directly.",
        "Moreover, generation needs different types of knowledge, which typically are encoded in different resources.",
        "However, the different representation formats used by these resources make it impossible to use them simultaneously in a single system.",
        "To overcome these limitations, we built a large-scale, reusable lexicon for generation by combining multiple existing resources.",
        "The resources that are combined include:",
        "o The WordNet Lexical Database (Miller et al., 1990).",
        "WordNet is the largest lexical database to date, consisting of over 120,000 unique words (version 1.6).",
        "It also encodes many types of lexical relations between words, including syn-on■;in y. antony, my, and many more.",
        "• English Verb Classes and Alternations (EVCA) (Levin, 1993)_ It categorized 3.104 verbs into classes based on their syntactic properties and studied verb alternations.",
        "An alternation is a variation in the realization Of verb arguments.",
        "For example, the alternation \"there-insertion\" transforms A ship appeared on the horizonzto There,appeared ship_ on.the horizon.",
        "A total of 80 alternations for 3,104 verbs were studied.",
        "® The COMLEX syntax dictionary (Grishman et al., 1994).",
        "COMLEX contains syntactic information for over 38,000 English words.",
        "® The Brown Corpus tagged with WordNet senses (Miller et al., 1993).",
        "We use this corpus for frequency measurement.",
        "In combining these resources, we focused on verbs, since they play a more important role in deciding sentence structures.",
        "The combined lexicon includes rich lexical and syntactic knowledge for 5,676 verbs.",
        "It is indexed by WordNet synsets(which are at the semantic concept level) as required by the generation task.",
        "The knowledge in the lexicon includes:",
        "® A complete list of subcategorizations for each sense of a verb.",
        "o A large variety of alternations for each sense of a verb.",
        "O Frequency of lexical items and verb suheatego-rizations in the tagged Brown corpus * Rich lexical relations between words",
        "The sample entry for the verb \"appear\" is shown in Figure 1.",
        "It shows that the verb appear has eight senses (the sense distinctions come from WordNet).",
        "For each sense, the lexicon lists all the applicable subcategorization for that particular sense of the verb.",
        "The subcategorizations are represented using the same format as in COMLEX.",
        "For each sense, the lexicon also lists applicable alternations, which we encoded based on the information in EVCA.",
        "In addition, for each subcategorization and alternation, the lexicon lists the semantic category constraints on verb arguments.",
        "In the figure, we omitted the frequency information derived from Brown Corpus and lexical relations (the lexical relations are encoded in WordNet).",
        "The construction of the lexicon is seini-automatic.",
        "First, COMLEX and EVCA were merged, producing a list of syntactic subcategorizations and alternations for each verb.",
        "Distinctions in these syntactic restrictions according to each sense of a verb are achieved in the second stage, where WordNet is merged with the result of the first step.",
        "Finally, the corpus information is added, complementing the static resources with actual usage counts for each syntactic pattern.",
        "For a detailed description of the combination process, refer to Ping and kr R tic 1998)."
      ]
    },
    {
      "heading": "3.2 The benefits of the lexicon",
      "text": [
        "There are a number of benefits that this combined lexicon can bring to language generation.",
        "First, the use of synsets as semantic tags can help map an application conceptual model to lexical items.",
        "Whenever application concepts are represented at the abstraction level of a WordNet synset, they can be directly accepted as input to the lexicon.",
        "By this way, the lexicon can actually lead to the generation of many lexical paraphrases.",
        "For example, {look, seem, appear} is a WordNet synset; it includes a list of words that can convey the semantic concept \"give an impression of \".",
        "We can use synsets to find words that can lexicalize the semantic concepts in the semantic input.",
        "By choosing different words in a synset.",
        "we can therefore generate lexical paraphrases.",
        "For instance, using the above synset, the system can generate the following paraphrases: \"He seems happy.\" 'Re looks happy.",
        "\"He appears happy.",
        "Secondly, the subcategorization information in the lexicon prevents generating a non-grammatical output_ As shown in Figure 1, the lexicon lists applicable subcategorizations for each sense of a verb.",
        "It will not allow the generation of sentences like \"'Re convinced me in his innocence\" (wrong preposition) \"*He convinced to go to the party\" (missing object) *The bread cuts\" (missing adverb (e.g., \"easily\" )) *The book consists three parts-(missing preposition) In addition, alternation information can help generate syntactic paraphrases.",
        "For instance, using the \"simple reciprocal intransitive\" alternation, the system can generate the following syntactic paraphrases: \"Brenda agreed with Molly.\" \"Brenda and Molly agreed.\" \"Brenda and Molly agreed with each other.\" Finally, the corpus frequency information can help _the lexicalRehoice process,- When.",
        "_multiple words can be used to realize a semantic concept, the system can use corpus frequency information in addition to other constraints to choose the most appropriate word.",
        "The knowledge encoded in the lexicon is general, thus it can be used in different applications.",
        "The lexicon has wide coverage: the final lexicon consists of 5,676 verbs in total, over 14,100 senses (on average 2.5 senses/verb), and over 11,000 semantic concepts (synsets).",
        "It uses 147 patterns to represent the subcategorizations and includes 80 alternations.",
        "To exploit the lexicon's many benefits, its format must be made compatible with the architecture of a generator.",
        "We have integrated the lexicon with the FUF/SURGE syntactic realizer to form a combined lexico-grammar."
      ]
    },
    {
      "heading": "4 Integration Process",
      "text": [
        "In this section, we first explain how lexical choosers are interfaced with FUF/SURGE.",
        "We then describe step by step how the lexicon is integrated with FUF/SURGE and show that this integration process helps to automate the development of a lexical realization component.",
        "4.1 FUF/SURGE and the lexical chooser FUF (Elhadad, 1992) uses a functional unification formalism for generation.",
        "It unifies the input.",
        "that a user provides with a grammar to generate sentences.",
        "SURGE (Elhadad and Robin, 1996) is a comprehensive English Grammar written in FUF.",
        "The role of a lexical realization component is to map a semantic representation drawn from the application domain to an input format acceptable by SURGE, adding necessary lexical and syntactic information during this process.",
        "Figure 2 shows a sample semantic input (a), the lexicalization module that is used to map this semantic input to SURGE input (h), and the final SURGE input (c) – taken from a real application system(Passoneau et al., 1996).",
        "The functions of the lexicalizaticin module include selecting words that can be used to realize the semantic concepts in the input, adding syntactic features, and mapping the arguments in the semantic input to the thematic rules in SURGE.",
        "The development of the lexicalizer component was done by hand in the past.",
        "Furthermore, for_ each new application, a new lexicalizer component had to be written despite the fact that some lexical and syntactic information is repeatedly used in different applications.",
        "The integration process we describe, however, partially automates this process."
      ]
    },
    {
      "heading": "4.2 The integration steps",
      "text": [
        "The integration of the lexicon with FUF/SURGE is done through incremental unification, using four unification steps as shown in Figure 3.",
        "Each step adds information to the semantic input, and at the end of the four unification steps, the semantic input has been mapped to the SURGE input format.",
        "(1) The semantic input Different generation systems usually use different representation formats for semantic input.",
        "Some systems use case roles ; some systems use flat attribute-value representation (Kukich et al., 1994).",
        "For the integrated lexicon and FUF/SURGE package to be easily pluggable in applications, we need to define a standard semantic input format.",
        "It should be designed in such a way that applications can easily adapt their particular semantic inputs to this standard format.",
        "It should also be easily mapped to the SURGE input format.",
        "In this paper, we only consider the issue of semantic input format for the expression of the predicate-argument relation.",
        "Two questions need to be answered in the design of the standard semantic input format: one, how to represent semantic concepts: and two, how to represent the predicate-argument relation.",
        "We use WordNet synsets to represent semantic concepts.",
        "The input can refer to synsets in several ways: either using a globally unique synset num-ber' or by specifying a word and its sense number in WordNet.",
        "The representation of verb arguments is a more complicated issue.",
        "Case roles are frequently used in generation systems to represent verb arguments in semantic inputs.",
        "For example, (Dorn et al., 1998) used 20 case roles in their lexical conceptual structure corresponding to underlying positions in a compositional lexical structure.",
        "(Langkilde and Knight.",
        "1998) use a list of case roles in their interlingua representations.",
        "We decided to use numbered arguments (similar to the DSyntR, in MTT (Nlercuk and Perstov, 1987)) instead of case roles.",
        "The difference between the two 'Since there are a huge number of svnsets in WordNet, we will provide a searchable database of synsets so that users can look up a synset and its index number easily_ For a particular application, users can adapt the svnsets to their specific main, such as reinovi rig non-relevant synset 5. merging synsets.",
        "arid relabeling the svnsets for convenience, as discilissed in (.ling, 1998).",
        "is not critical but the numbered argument approach avoids the need.",
        "to commit the lexicon to a specific ontology and seems to be easier to learn.",
        "Figure 4 shows a sample semantic input.",
        "For easy understanding, we refer to the semantic concepts using their definitions rather than numerical index numbers.",
        "There are two arguments in the input.",
        "The intended output sentence for this semantic input is \"A boat appeared on the horizon\" or its paraphrases.",
        "(2) Lexical unification",
        "In this step, we map the semantic concepts in the semantic input to concrete words.",
        "To do this, we use the synsets in WordNet.",
        "All the words in the same synset can be used to convey the same semantic concept.",
        "For the above example, the semantic concepts \"become visible\" and \"a small vessel for travel on water\" can be realized by the the verb appear and the noun boat respectively.",
        "This is the step that can produce lexical paraphrases.",
        "Note that when the system chooses a word, it also determines the particular sense number of the word, since a word as it belongs to a synset has a unique sense number in WordNet.",
        "We represented all the synsets in Wordnet in FUF format.",
        "Each synset includes its numerical index number and the list of word senses included in the synsets.",
        "This lexical unification.",
        "works for both nouns and verbs.",
        "(3) Structural unification",
        "After the system has chosen a verb (actually a particular sense of a verb), it uses that information as an index to unify with the subcategorization and alternations the particular verb sense has.",
        "This step adds additional syntactic information to the original input and has the capacity to produce syntactic paraphrases using alternation information.",
        "(4) Constraints on the number of arguments",
        "Next, we use the constraints that a subcategorization has on the number of arguments it requires to restrict unification with subcategorization patterns.",
        "We use 147 possible patterns.",
        "For example, the input in Figure 4 has two arguments.",
        "Although INTRANS (meaning intransitive) is listed as a possible subcategorization pattern for \"appear\" (see sense 2 in Figure 1), the input will fail to unify with it since INTRANS requires a single argument only.",
        "This prevents the generation of non-grammatical sentences.",
        "This step adds a feature which specifies the transitivity of the verb to FUF/SURGE input, selecting one from the lexicon when there is more than one possibility for the given verb.",
        "`The difference between numbered arguments and labeled roles is similar to that between named semantic primitives and synsets in kVordNet.",
        "Verb classes share the same definition of which argument is denoted by 1, 2 etc.",
        "if they share some syntactic properties as far as argument taking properties are concerned."
      ]
    },
    {
      "heading": "Semantic input Synsets verbs lexicon si,ucts input for SURGE",
      "text": [
        "(5) Mapping structures to SURGE input In the last step, the subcategorization and alternations are mapped to SURGE input format.",
        "The mapping from subcategorizations to SURGE input was manually encoded in the lexicon for each one of the 147 patterns.",
        "This mapping information can be reused for all applications, which is more efficient than composing SURGE input in the lexicalization component of each different application.",
        "Figure 5 shows how the subcategorization NP-WITH-NP (e.g., The clown amused the children with his antics) is mapped to the SURGE input format.",
        "This mapping mainly involves matching the numbered arguments in the semantic input to appropriate lexical roles and syntactic categories so that FUF/SURGE can generate them in the correct order.",
        "The final SURGE input for the sentence \"A boat appeared on the horizon\" is shown in Figure 6.",
        "Using the \"THERE-INSERTION\" alternation that the verb \"appear\" (sense 2) authorizes, the system can also generate the syntactic paraphrase \"There appeared a boat on the horizon\" .",
        "The SURGE input the system generates for \"There appeared a boat on the horizon\" is very different from that for \"A boat appeared on the horizon\" .",
        "It.",
        "is possible that for a given application some generated paraphrases are not appropriate.",
        "In this case, users can edit the sunsets and the alternations to filter out the paraphrases they do riot want The four unification steps are completely automatic.",
        "The system can send feedback upon failure",
        "of unification."
      ]
    },
    {
      "heading": "5 Related Work",
      "text": [
        "The lexicon, after it is integrated with FUF/SURGE, can also be used for other tasks in language generation.",
        "[\"or example, revision (Robin, 1994) is a technique for building semantic inputs incrementally.",
        "The revision process decides whether it is appropriate to attach a new constituent to the current semantic input.",
        "for example.",
        "by adding an",
        "concept 'a small vessel for travel on water\" word \"boat\"' concept I the line at which the sky and Earth appear to meet word \"horizon\"' object or an adverb.",
        "Such decisions are constrained by syntactic properties of verbs.",
        "The integrated lexicon is useful to verify these properties.",
        "Nitrogen (Langkilde and Knight, 1998), a natural language generation system developed at ISI, also includes a large-scale lexicon to support the generation process.",
        "Given that Nitrogen and FUF/SURGE use very different methods for generation, the way that we integrate the lexicon with the generation system is also very different.",
        "Nitrogen combines symbolic rules with statistics learned from text corpora, while FUF/SURGE is based on Functional Unification Grammar.",
        "Other related work includes (Stede, 1998), which suggests a lexicon structure for multilingual generation in a knowledge-based generation system.",
        "The main idea is to handle multilingual generation in the same way as paraphrasing of the same language.",
        "Stede's work concerns mostly the lexical semantics of the transitivity alternations."
      ]
    },
    {
      "heading": "6 Conclusion",
      "text": [
        "We have presented in this paper the integration of a large-scale, reusable lexicon for generation with FUF/SURGE, a unification-based natural language generator.",
        "This integration makes it possible to reuse major parts of a lexical chooser, which is the component in a generation system that is responsible for mapping semantic inputs to surface generator inputs.",
        "We show that although the whole lexical chooser can not be made domain-independent, it is possible to reuse a large amount of lexical, syntactic, and semantic knowledge across applications.",
        "In addition, the lexicon other benefits to a generation system, including t he abilities to generate many-lexical paraphrases automatically, generate syntactic paraphrases.",
        "avoid olio-grammatical output, and choose the most frequently used word when there is more than one candidate words.",
        "Since the lexical, syntactic, and semantic knowledge encoded in the • lexicon is general and the lexicon has a wide coverage, it can be reused for different applications.",
        "In.",
        "the future, we plan to validate the paraphrases the lexicon can generate by asking human subjects to read the generated paraphrases and judge whether they are acceptable.",
        "We would like to investigate ways that can systematically filter out paraphrases that are considered unacceptable.",
        "We are also interested in exploring the usage of this system in multilingual generation."
      ]
    }
  ]
}
