{
  "info": {
    "authors": [
      "Kiyoshi Sudo",
      "Satoshi Sekine",
      "Ralph Grishman"
    ],
    "book": "Human Language Technology Conference",
    "id": "acl-H01-1009",
    "title": "Automatic Pattern Acquisition for Japanese Information Extraction",
    "url": "https://aclweb.org/anthology/H01-1009",
    "year": 2001
  },
  "references": [
    "acl-A00-1039",
    "acl-W98-1120"
  ],
  "sections": [
    {
      "heading": "ABSTRACT",
      "text": [
        "One of the central issues for information extraction is the cost of customization from one scenario to another.",
        "Research on the automated acquisition of patterns is important for portability and scalability.",
        "In this paper, we introduce Tree-Based Pattern representation where a pattern is denoted as a path in the dependency tree of a sentence.",
        "We outline the procedure to acquire Tree-Based Patterns in Japanese from unannotated text.",
        "The system extracts the relevant sentences from the training data based on TF/IDF scoring and the common paths in the parse tree of relevant sentences are taken as extracted patterns."
      ]
    },
    {
      "heading": "Keywords",
      "text": []
    },
    {
      "heading": "1. INTRODUCTION",
      "text": [
        "Information Extraction (IE) systems today are commonly based on pattern matching.",
        "New patterns need to be written when we customize an IE system for a new scenario (extraction task); this is costly if done by hand.",
        "This has led to recent research on automated acquisition of patterns from text with minimal pre-annotation.",
        "Riloff [4] reported a successful result for her procedure that needs only a pre-classified corpus.",
        "Yangarber [6] developed a procedure for unannotated natural language texts.",
        "One of their common assumption is that the relevant documents include good patterns.",
        "Riloff implemented this idea by applying the predefined heuristic rules to pre-classified (relevant) documents and Yangarber advanced further so that the system can classify the documents by itself given seed patterns specific to a scenario and then find the best patterns from the relevant document set.",
        "Considering how they represent the patterns, we can see that, in general, Riloff and Yangarber relied on the sentence structure of English.",
        "Riloffs predefined heuristic rules are based on syntactic structures, such as <subj> active-verb and active-verb <dobj>.",
        "Yangarber used triples of a predicate and some of its arguments, such as <pred> <subj> <obj>.",
        "The Challenges Our careful examination of Japanese revealed some of the challenges for automated acquisition of patterns and information extraction on Japanese(-like) language and other challenges which arise regardless of the languages.",
        "Free Word-ordering Free word order is one of the most significant problems in analyzing Japanese.",
        "To capture all the possible patterns given a predicate and its arguments, we need to permute the arguments and list all the patterns separately.",
        "For example, for <subj> <dobj> <iobj> <predicate> with the constraint that the predicate comes last in the sentence, there would be six possible patterns (permutations of three arguments).",
        "The number of patterns to cover even simple facts would rise unacceptably high.",
        "Flexible case marking system There is also a difficulty in a language with a flexible case marking system, like Japanese.",
        "In particular, we found that, in Japanese, some of the arguments that are usually marked as object in English were variously marked by different post-positions, and some case markers (postpositions) are used for marking more than one grammatical category in different situations.",
        "For example, the topic marker in Japanese, wa, can mark almost any entity that would have been variously marked in English.",
        "It is difficult to deal with this variety by simply fixing the number of arguments of a predicate for creating patterns in Japanese.",
        "Relationships beyond direct predicate-argument Furthermore, we may want to capture the relationship between a predicate and a modifier of one of its arguments.",
        "In previous approaches, one had to introduce an ad hoc frame for such a relationship, such as verb obj [PP <head-noun>], to extract the relationship between to assume and <organization> in the sentence <person> will assume the <post> of <organization>.",
        ".",
        "Relationships beyond clausal boundaries Another problem lies in relationships beyond clause boundaries, especially if the event is described in a subordinate clause.",
        "For example, for a sentence like <organization> announced that <person> retired from <post>, it is hard to find a relationship between <organization> and the event of retiring without the global view from the predicate announce.",
        "These problems lead IE systems to fail to capture some of the arguments needed for filling the template.",
        "Overcoming the problems above makes the system capable of finding more patterns from the training data, and therefore, more slot-fillers in the template.",
        "In this paper, we introduce Tree-based pattern representation and consider how it can be acquired automatically."
      ]
    },
    {
      "heading": "2. TREE-BASED PATTERN REPRESENTATION (TBP)",
      "text": [
        "predicate.",
        "For example, the pattern <organization>of><post>to>appoint can capture the relationship between <organization> and to be appointed in the sentence <person> was appointed to <post> of <organization>.",
        "Relationships beyond clausal boundaries TBP can capture relationships beyond clausal boundaries.",
        "The pattern <post>>toappointC - Pannounce can find the relationship between <post> and to announce.",
        "This relationship, later on, can be combined with the relationship <organization> and to announce and merged into one event."
      ]
    },
    {
      "heading": "3. ALGORITHM",
      "text": [
        "In this section, we outline our procedure for automatic acquisition of patterns.",
        "We employ a cascading procedure, as is shown in Figure 3.",
        "First, the original documents are processed by a morphological analyzer and NE-tagger.",
        "Then the system retrieves the relevant documents for the scenario as a relevant document set.",
        "The system, further, selects a set of relevant sentences as a relevant sentence set from those in the relevant document set.",
        "Finally, all the sentences in the relevant sentence set are parsed and the paths in the dependency tree are taken as patterns."
      ]
    },
    {
      "heading": "3.1 Document Preprocessing Morphological analysis and Named Entity (NE) tagging is performed on the training data at this stage. We used JUMAN [2] for the former and a NE-system which is based on a decision tree algorithm [5] for the latter. Also the part-of-speech information given by JUMAN is used in the later stages. 3.2 Document Retrieval",
      "text": [
        "The system first retrieves the documents that describe the events of the scenario of interest, called the relevant document set.",
        "A set of narrative sentences describing the scenario is selected to create a query for the retrieval.",
        "For this experiment, we set the size of the relevant document set to 300 and retrieved the documents using CRLs stochastic-model-based IR system [3], which performed well in the IR task in IREX, Information Retrieval and Extraction evaluation project in Japan 2.",
        "All the sentences used to create the patterns are retrieved from this relevant document set."
      ]
    },
    {
      "heading": "3.3 Sentence Retrieval",
      "text": [
        "The system then calculates the TF/IDF-based score of relevance to the scenario for each sentence in the relevant document set and retrieves the n most relevant sentences as the source of the patterns, where n is set to 300 for this experiment.",
        "The retrieved sentences will be the source for pattern extraction in the next subsection.",
        "First, the TF/IDF-based score for every word in the relevant document set is calculated.",
        "TF/IDF score of word w is:",
        "where N is the number of documents in the collection, TF(w) is the term frequency of w in the relevant document set and DF(w) is the document frequency of w in the collection.",
        "Second, the system calculates the score of each sentence based on the score of its words.",
        "However, unusually short sentences and",
        "unusually long sentences will be penalized.",
        "The TF/IDF score of sentence s is: quency higher than some threshold as extracted patterns.",
        "Figure 5 shows examples of the acquired patterns.",
        "where length(s) is the number of words in s, and AVE is the average number of words in a sentence."
      ]
    },
    {
      "heading": "3.4 Pattern Extraction",
      "text": [
        "Based on the dependency tree of the sentences, patterns are extracted from the relevant sentences retrieved in the previous subsection.",
        "Figure 4 shows the procedure.",
        "First, the retrieved sentence is parsed into a dependency tree by KNP [1] (Stage 1).",
        "This stage also finds the predicates in the tree.",
        "Second, the system takes all the predicates in the tree as the roots of their own subtrees, as is shown in (Stage 2).",
        "Then each path from the root to a node is extracted, and these paths are collected and counted across all the relevant sentences.",
        "Finally, the system takes those paths with fre 4.",
        "EXPERIMENT It is not a simple task to evaluate how good the acquired patterns are without incorporating them into a complete extraction system with appropriate template generation, etc.",
        "However, finding a match of the patterns and a portion of the test sentences can be a good measure of the performance of patterns.",
        "The task for this experiment is to find a bunsetsu, a phrasal unit, that includes slot-fillers by matching the pattern to the test sentence.",
        "The performance is measured by recall and precision in terms of the number of slot-fillers that the matched patterns can find; these are calculated as follows.",
        "The procedure proposed in this paper is based on bunsetsus, and an individual bunsetsu may contain more than one slot filler.",
        "In such cases the procedure is given credit for each slot filler.",
        "Strictly speaking, we dont know how many entities in a matched pattern might be slot-fillers when, actually, the pattern does not contain any slot-fillers (in the case of over-generating).",
        "We approximate the potential number of slot-fillers by assigning 1 if the (falsely) matched pattern does not contain any Named-Entities, or assigning the number of Named-Entities in the (falsely) matched pattern.",
        "For example, if we have a pattern go to dinner for a management succession scenario and it matches falsely in some part of the test sentences, this match will gain one at the number of All Matched Slot-fillers (the denominator of the precision).",
        "On the other hand, if the pattern is <post> <person> laugh and it falsely matches President Clinton laughed, this will gain two, the number of the Named Entities in the pattern.",
        "For the sake of comparison, we defined the baseline system with the patterns acquired by the same procedure but only from the direct relationships between a predicate and its arguments (PA in Figure 6 and 7).",
        "We chose the following two scenarios.",
        "Executive Management Succession: events in which corporate managers left their positions or assumed new ones regardless of whether it was a present (time of the report) or past event.",
        "Items to extract: Date, person, organization, title.",
        "Robbery Arrest: events in which robbery suspects were arrested.",
        "Items to extract: Date, suspect, suspicion."
      ]
    },
    {
      "heading": "4.1 Data Management Succession",
      "text": [
        "For all the experiments, we used the Mainichi-Newspaper-95 corpus for training.",
        "As described in the previous section, the system retrieved 300 articles for each scenario as the relevant document set from the training data and it further retrieved 300 sentences as the relevant sentence set from which all the patterns were extracted.",
        "Test data was taken from Mainichi-Newspaper-94 by manually reviewing the data for one month.",
        "The statistics of the test data are shown in Table 1 and 2."
      ]
    },
    {
      "heading": "4.2 Results",
      "text": []
    },
    {
      "heading": "5. DISCUSSION Low Recall",
      "text": [
        "It is mostly because we have not made a class of types of crimes that the recall on the robbery arrest scenario is low.",
        "Once we have a classifier as reliable as Named-Entity tagger, we can make a significant gain in the recall of the system.",
        "And in turn, once we have a class name for crimes in the training data (automatically annotated by the classifier) instead of a separate name for each crime, it becomes a good indicator to see if a sentence should be used to acquire patterns.",
        "And also, incorporating the classes in patterns can reduce the noisy patterns which do not carry any slot-fillers of the template.",
        "For example on the management succession scenario, all the slot-fillers defined there were able to be tagged by the Named Entity tagger [5] we used for this experiment, including the title.",
        "Since we knew all the slot-fillers were in one of the classes, we also knew those patterns whose argument was not classified any of the classes would not likely capture slot-fillers.",
        "So we could put more weight on those patterns which contained <person>, <organization>, <post> and <date> to collect the patterns with higher performance, and therefore we could achieve high precision.",
        "Erroneous Case Analysis We also investigated other scenarios, namely train accident and airplane accident scenario, which we will not report in this paper.",
        "However, some of the problems which arose may be worth mentioning since they will arise in other, similar scenarios.",
        "Results or Effects of the Target Event Especially for the airplane accident scenario, most errors were identified as matching the effect or result of the incident.",
        "A typical example is Because of the accident, the airport had been closed for an hour.",
        "In the airplane accident scenario, the performance of the document retrieval and the sentence retrieval is not as good as the other two scenarios, and therefore, the frequency of relevant acquired patterns is rather low because of the noise.",
        "Further improvement in retrieval and a more robust approach is necessary.",
        "Related but Not-Desired Sentences If the scenario is specific enough to make it difficult as an IR task, the result of the document retrieval stage may include many documents related to the scenario in a broader sense but not specific enough for IE tasks.",
        "In this experiment, this was the case for the airplane accident scenario.",
        "The result of document retrieval included documents about other accidents in general, such as traffic accidents.",
        "Therefore, the sentence retrieval and pattern acquisition for these scenarios were affected by the results of the document retrievals."
      ]
    },
    {
      "heading": "6. FUTURE WORK Information Extraction",
      "text": [
        "To apply the acquired patterns to an information extraction task, further steps are required besides those mentioned above.",
        "Since the patterns are a set of the binary relationships of a predicate and another element, it is necessary to merge the matched elements into a whole event structure.",
        "We have not yet attempted any (lexical) generalization of pattern candidates.",
        "The patterns can be expanded by using a thesaurus and/or introducing a new (lexical) class suitable for a particular domain.",
        "For example, the class of expressions of flight number clearly helps the performance on the airplane accident scenario.",
        "Especially, the generalized patterns will help improve recall.",
        "The presented results show that our procedure of automatic pattern acquisition is promising.",
        "The procedure is quite general and addresses problems which are not specific to Japanese.",
        "With an appropriate morphological analyzer, a parser that produces a dependency tree and an NE-tagger, our procedure should be applicable to almost any language."
      ]
    },
    {
      "heading": "7. ACKNOWLEDGMENTS",
      "text": [
        "This research is supported by the Defense Advanced Research Projects Agency as part of the Translingual Information Detection, Extraction and Summarization (TIDES) program, under Grant N66001-00-1-8917 from the Space and Naval Warfare Systems Center San Diego.",
        "This paper does not necessarily reflect the position or the policy of the U.S. Government."
      ]
    },
    {
      "heading": "8. REFERENCES",
      "text": []
    }
  ]
}
