{
  "info": {
    "authors": [
      "Manuel Bodirsky",
      "Katrin Erk",
      "Alexander Koller",
      "Joachim Niehren"
    ],
    "book": "Annual Meeting of the Association for Computational Linguistics",
    "id": "acl-P01-1011",
    "title": "Underspecified Beta Reduction",
    "url": "https://aclweb.org/anthology/P01-1011",
    "year": 2001
  },
  "references": [
    "acl-C00-1067",
    "acl-P83-1020",
    "acl-P95-1021"
  ],
  "sections": [
    {
      "heading": "Abstract",
      "text": [
        "For ambiguous sentences, traditional semantics construction produces large numbers of higher-order formulas, which must then be , reduced individually.",
        "Underspecified versions can produce compact descriptions of all readings, but it is not known how to perform , reduction on these descriptions.",
        "We show how to do this using , reduction constraints in the constraint language for A-structures (CLLS)."
      ]
    },
    {
      "heading": "1 Introduction",
      "text": [
        "Traditional approaches to semantics construction (Montague, 1974; Cooper, 1983) employ formulas of higher-order logic to derive semantic representations compositionally; then , reduction is applied to simplify these representations.",
        "When the input sentence is ambiguous, these approaches require all readings to be enumerated and , - reduced individually.",
        "For large numbers of readings, this is both inefficient and unelegant.",
        "Existing underspecification approaches (Reyle, 1993; van Deemter and Peters, 1996; Pinkal, 1996; Bos, 1996) provide a partial solution to this problem.",
        "They delay the enumeration of the readings and represent them all at once in a single, compact description.",
        "An underspecification formalism that is particularly well suited for describing higher-order formulas is the Constraint Language for Lambda Structures, CLLS (Egg et al., 2001; Erk et al., 2001).",
        "CLLS descriptions can be derived compositionally and have been used to deal with a rich class of linguistic phenomena (Koller et al., 2000; Koller and Niehren, 2000).",
        "They are based on dominance constraints (Marcus et al., 1983; Rambow et al., 1995) and extend them with parallelism (Erk and Niehren, 2000) and binding constraints.",
        "However, lifting , reduction to an operation on underspecified descriptions is not trivial, and to our knowledge it is not known how this can be done.",
        "Such an operation which we will call underspecified , reduction would essentially , - reduce all described formulas at once by deriving a description of the reduced formulas.",
        "In this paper, we show how underspecified , reductions can be performed in the framework of CLLS.",
        "Our approach extends the work presented in (Bodirsky et al., 2001), which defines , reduction constraints and shows how to obtain a complete solution procedure by reducing them to parallelism constraints in CLLS.",
        "The problem with this previous work is that it is often necessary to perform local disambiguations.",
        "Here we add a new mechanism which, for a large class of descriptions, permits us to perform underspecified , reduction steps without disambiguating, and is still complete for the general problem.",
        "Plan.",
        "We start with a few examples to show what underspecified , reduction should do, and why it is not trivial.",
        "We then introduce CLLS and , reduction constraints.",
        "In the core of the paper we present a procedure for underspecified , reduction and apply it to illustrative examples."
      ]
    },
    {
      "heading": "2 Examples",
      "text": [
        "In this section, we show what underspecified ~- reduction should do, and why the task is nontrivial.",
        "Consider first the ambiguous sentence Every student didnt pay attention.",
        "In first-order logic, the two readings can be represented as",
        "A classical compositional semantics construction first derives these two readings in the form of two HOL-formulas: (Every std) Ax (--,payatt x) ((Every std) Ax (payatt x)) where Every is an abbreviation for the term",
        "An underspecified description of both readings is shown in Figure 2.",
        "For now, notice that the graph has all the symbols of the two HOL formulas as node labels, that variable binding is indicated by dashed arrows, and that there are dotted lines indicating an outscopes relation; we will fill in the details in Section 3.",
        "Now we want to reduce the description in Figure 2 as far as possible.",
        "The first , reduction step, with the redex at Xo is straightforward.",
        "Even though the description is underspecified, the reducing part is a completely known A-term.",
        "The result is shown on the left-hand side of Figure 1.",
        "Here we have just one redex, starting at Yo, which binds a single variable.",
        "The next reduction step is less obvious: The ~ operator could either belong to the context (the part between Rl and Yo)",
        "or to the argument (below Y ) Still, it is not difficult to give a correct description of the result: it is shown in the middle of Fig. 1.",
        "For the final step, which takes us to the rightmost description, the redex starts at Z Note that now the ~ might be part of the body or part of the context of this redex.",
        "The end result is precisely a description of the two readings as first-order formulas.",
        "So far, the problem does not look too difficult.",
        "Twice, we did not know what exactly the parts of the redex were, but it was still easy to derive correct descriptions of the reducts.",
        "But this is not always the case.",
        "Consider Figure 3, an abstract but simple example.",
        "In the left description, there are two possible positions for the",
        "as above, we arrive at the right-hand description in Fig. 3.",
        "But this description is also satisfied by the term f (~(b(a)) which cannot be obtained by reducing any of the terms described on the left-hand side.",
        "More generally, the nav grap rewriting approach is unsound; the resulting descriptions can have too many readings.",
        "Similar problems arise in (more complicated) examples from semantics, such as the coordination in Fig. 8.",
        "The underspecified ~-reduction operation we propose here does not rewrite descr ptions.",
        "Instead, we describe the result of the step using a , reduction constraint that ensures that the reduced terms are captured correctly.",
        "Then we use a saturation calculus to make the description more explicit."
      ]
    },
    {
      "heading": "3 Tree descriptions in CLLS",
      "text": [
        "In this section, we briefly recall the definition of the constraint language for A-structures (CLLS).",
        "A more thorough and complete introduction can be found in (Egg et al., 2001).",
        "We assume a signature E _ If, g.... } of function symbols, each equipped with an arity",
        "is the arity of the label of 7.",
        "A single node E, the root of 0, is not the child of any other node."
      ]
    },
    {
      "heading": "3.1 Lambda structures",
      "text": [
        "The idea behind A-structures is that a A-term can be considered as a pair of a tree which represents the structure of the term and a binding function encoding variable binding.",
        "We assume E contains symbols var (arity 0, for variables), lam (arity 1, for abstraction), @ (arity 2, for application), and analogous labels for the logical connectives.",
        "Definition 1.",
        "A A-structure r is a pair (0, A) of a tree 0 and a bindingfunction A that maps every node 7 with label var to a node with label lam, V, or El dominating 7r.",
        "The binding function A explicitlylam-maps nodes representing variables toi the nodes representing their binders.i When we draw A-structures, we rep-fyr resent the binding function using dashed arrows, as in the picture to the right, which represents the A-term Ax.",
        "f (x).",
        "A A-structure corresponds uniquely to a closed A-term modulo a-renaming.",
        "We will freely consider A-structures as first-order model structures with domain DB.",
        "This structure defines the following relations.",
        "The labeling relation 7: f, 7,,,) holds in 0 if LB(7) = f and",
        "era* 7r' holds iff there is a path 7\" such that 77\" = 7'.",
        "Inequality zA is simply inequality of nodes; disjointness 717' holds iff neither 7a*7' nor 7'a*7."
      ]
    },
    {
      "heading": "3.2 Basic constraints",
      "text": [
        "Now we define the constraint language for A-structures (CLLS) to talk about these relations.",
        "X: f (X,,... , X.)",
        "(ar(f) = n) A(X)=Y I A-1(Xo)= JX1, ... , Xn} A constraint co is a conjunction of literals (for dominance, labeling, etc).",
        "We use the abbreviations Xa+Y for Xa*Y n X :7~ Y and X = Y for Xa*Y n Ya*X.",
        "The A-binding literal A(X)=Y expresses that Y denotes a node which the binding function maps to X.",
        "The inverse A-binding literal A-1(Xo)={X1, ... , X1J states that X1,... ~Xn denote the entire set of variable nodes bound by Xo.",
        "A pair (-r, a) of a A-structure r and a variable assignment a satisfies a A-structure iff it satisfies each literal, in the obvious way.",
        "We draw constraints as graphs (Fig.",
        "4) in which nodes represent variables.",
        "Labels and solid lines indicate labeling literals, while dotted lines represent dominance.",
        "Dashed arrows indicate the binding relation; disjointness and inequality literals are not represented.",
        "The informal diagrams from Section 2 can thus be read as constraint graphs, which gives them a precise formal meaning."
      ]
    },
    {
      "heading": "3.3 Segments and Correspondences",
      "text": [
        "Finally, we define segments of A-structures and correspondences between segments.",
        "This allows us to define parallelism and , reduction constraints.",
        "A segment is a contiguous part of a A-structure that is delineated by several nodes of the structure.",
        "Intuitively, it is a tree from which some subtrees have been cut out, leaving behind holes.",
        "Definition 2 (Segments).",
        "A segment a of a A-structure",
        "of holes.",
        "The set b(a) of nodes of a is b(a) _ 17r E D, I r(a)a*7r, and not 7i<+ 7 for all 1 < i < n} To exempt the holes of the segment, we define b(a) = b(a) hs(a).",
        "If hs(a) is a singleton sequence then we write h(a) for the unique hole of a, i.e. the unique node with h(a) E hs(a).",
        "For instance, a = 71/72, 73 is a segment in Fig. 5; its root is 7r1, its holes are 72 and 73, and it contains the nodes b (a) _ 17r1, 75 1 72 1 73 } Two tree segments a, overlap properly iff b (a) n b (,) zA 0.",
        "The syntactic equivalent of a segment is a segment term Xo/Xl.... X1,.",
        "We use the letters A, B, C, D for them and extend r(A), hs(A) , and h(A) correspondingly.",
        "A correspondence function is intuitively an isomorphism between segments, mapping holes to holes and roots to roots and respecting the structures of the trees:",
        "Definition 3.",
        "A correspondence function between the segments a, ~ is a bijective mapping c : b(a) --~ b(,) such that c maps the i-th hole of a to the i-th hole of, for each i, and for every 7 E b (a) and every label f, 7: f (7r1 ... 7n) <=> c(7r): f (c(7r1).... c(7n)).",
        "There is at most one correspondence function between any two given segments.",
        "The correspondence literal co(C, D) (X)=Y expresses that a correspondence function c between the segments denoted by C and D exists, that X and Y denote nodes within these segment, and that these nodes are related by c. Together, these constructs allow us to define parallelism, which was originally introduced for the analysis of ellipsis (Egg et al., 2001).",
        "The parallelism relation a ~ holds iff there is a correspondence function between a and ~ that satisfies some natural conditions on A-binding which we cannot go into here.",
        "To model parallelism in the presence of global A-binders relating multiple parallel segments, Bodirsky et al.",
        "(2001) generalize parallelism to group parallelism.",
        "Group parallelism",
        "by the conjunction A2 jai ~i of ordinary parallelisms, but imposes slightly weaker restrictions on A-binding.",
        "By way of example, consider the A-structure in Fig. 5, where (7o /71, 72 /74, 73 /) ^ (moo/~i ~i/~4 7C4/) holds.",
        "On the syntactic side, CLLS provides group parallelism literals (Al, ... , A1,) (Bl, ... , B1z) to talk about (group) parallelism."
      ]
    },
    {
      "heading": "4 Beta reduction constraints",
      "text": [
        "Correspondences are also used in the definition of , reduction constraints (Bodirsky et al., 2001).",
        "A , reduction constraint describes a single , - reduction step between two A-terms; it enforces correct reduction even if the two terms are only partially known.",
        "Standard , reduction has the form C((ax.B) A) --~p C(B[x/A]) x free for A.",
        "The reducing A-term consists of context C which contains a redex (Ax.B)A.",
        "The redex itself is an occurrence of an application of a A-abstraction ax.B with body B to argument A. , reduction then replaces all occurrences of the bound variable x in the body by the argument while preserving the context.",
        "We can partition both redex and reduct into argument, body, and context segments.",
        "Consider",
        "term can be found at 7ro.",
        "Writing -y,~-y' for the context,for the body and a, a' for the argument tree segments of the reducing and the reduced term, respectively, we find",
        "Because we have both the reducing term and the reduced term as parts of the same A-structure, we can express the fact that the structure below 70' can be obtained by , reducing the structure below 70 by requiring that a corresponds to a', ~ to , ', and y to -y', again modulo binding.",
        "This is indeed true in the given A-structure, as we have seen above.",
        "More generally, we define the , reduction relation (rya)al, ... , a'n) for a body ~ with n holes (for the variables bound in the redex).",
        "The , reduction relation holds iff two conditions are met: (-y, , , a) must form a reducing term, and the structural equalities that we have noted above must hold between the tree segments.",
        "The latter can be stated by the following group parallelism relation, which also represents the correct binding behaviour: (Ya, ... , a)(yal, ... , an) Note that any A-structure satisfying this relation must contain both the reducing and the reduced term as substructures.",
        "Incidentally, this allows us to accommodate for global variables in A-terms; Fig. 5 shows this for the global variable z.",
        "We now extend CLLS with , reduction constraints (C, B, A)(C', B', A..... , A''), which are interpreted by the , reduction relation.",
        "The reduction steps in Section 2 can all be represented correctly by , reduction constraints.",
        "Consider e.g. the first step in Fig. 1.",
        "This is repre~ sented by the constraint (Rl/Yo, Y2/Y3i Y4/) ~ (R2/Zo, Zo/Z3, Z3/).",
        "The entire middle constraint in Fig. 1 is entailed by the , reduction literal.",
        "If we learn in addition that e.g. Y7a*Yo, the , reduction literal will entail Z7 <* Zo because the segments must correspond.",
        "This correlation between parallel segments is the exact same effect (quantifier parallelism) that is exploited in the CLLS analysis of Hirschbuhler sentences, where ellipses and scope interact (Egg et al., 2001).",
        ", reduction constraints also represent the problematic example in Fig. 3 correctly.",
        "The spurious solution of the right-hand constraint does not usb(co, X) = if all syntactic redexes in co below X are reduced then return (co, X) else pick a formula redexy (C, B, A) in co that is unreduced, with X=r(C) in co add (C,B,A) 4 (C',B',A..... ,A'') to co where C', B', Ai, ... A'' are new segment terms with fresh variables add X1r(C') to co for all co' E solve(co) do usb(co', r(C'))",
        "satisfy the , reduction constraint, as the bodies would not correspond."
      ]
    },
    {
      "heading": "5 Underspecified Beta Reduction",
      "text": [
        "Having introduced , reduction constraints, we now show how to process them.",
        "In this section, we present the procedure us b, which performs a sequence of underspecified , reduction steps on CLLS descriptions.",
        "This procedure is parameterized by another procedure solve for solving , - reduction constraints, which we discuss in the following section.",
        "A syntactic redex in a constraint co is a subfor-mula of the following form: redexy(C, B, A) =df h(C):@(Y, r(A)) A Y:lam(r(B)) n A-1(Y) = hs(B) A context C of a redex must have a unique hole h(C).",
        "An nary redex has n occurrences of the bound variable, i.e. the length of hs(B) is n. We call a redex linear if n = 1.",
        "The algorithm usb is shown in Figure 6.",
        "It starts with a constraint co and a variable X, which denotes the root of the current A-term to be reduced.",
        "(For example, for the redex in Fig. 2, this root would be Ro.)",
        "The procedure then selects an unreduced syntactic redex and adds a description of its reduct at a disjoint position.",
        "Then the solve procedure is applied to resolve the , - reduction constraint, at least partially.",
        "If it has to disambiguate, it returns one constraint for each reading it finds.",
        "Finally, usb is called recursively with the new constraint and the root variable of the new A-term.",
        "Intuitively, the solve procedure adds entailed literals to co, making the new , reduction literal more explicit.",
        "When presented with the left-hand constraint in Fig. 1 and the root variable Rl, usb will add a , reduction constraint for the redex at Yl; then solve will derive the middle constraint.",
        "Finally, usb will call itself recursively with the new root variable R2 and try to resolve the redex at Z3, etc.",
        "The partial solving steps do essentially the same as the nave graph rewriting approach in this case; but the new algorithm will behave differently on problematic constraints as in Fig. 3."
      ]
    },
    {
      "heading": "6 A single reduction step",
      "text": [
        "In this section we present a procedure solve for solving , reduction constraints.",
        "We go through several examples to illustrate how it works.",
        "We have to omit some details for lack of space; they can be found in (Bodirsky et al., 2001).",
        "The aim of the procedure is to make explicit information that is implicit in , reduction constraints: it introduces new corresponding variables and copies constraints from the reducing term to the reduced term.",
        "We build upon the solver for , reduction constraints from (Bodirsky et al., 2001).",
        "This solver is complete, i.e. it can enumerate all solutions of a constraint; but it disambiguates a lot, which we want to avoid in underspecified , -reduction.",
        "We obtain an alternative procedure solve by disabling all rules which disambiguate and adding some new non-disambiguating rules.",
        "This allows us to perform a complete underspecified , - reduction for many examples from underspecified semantics without disambiguating at all.",
        "In those cases where the new rules alone are not sufficient, we can still fall back on the complete solver."
      ]
    },
    {
      "heading": "6.1 Saturation",
      "text": [
        "Our constraint solver is based on saturation with a given set of saturation rules.",
        "Very briefly, this means that a constraint is seen as the set of its literals, to which more and more literals are added according to saturation rules.",
        "A saturation rule of the form coo --~ Vz lco2 says that we can add one of the (pi to any constraint that contains at least the literals in coo.",
        "We only apply rules where each possible choice adds new literals to the set; a constraint is saturated under a set S of saturation rules if no rule in S can add anything else.",
        "solve returns the set of all possible saturations of its input.",
        "If the rule system contains nondeterministic distribution rules, with n > 1, this set can be non-singleton; but the rules we are going to introduce are all deterministic propagation rules (with n = 1)."
      ]
    },
    {
      "heading": "6.2 Solving Beta Reduction Constraints",
      "text": [
        "The main problem in doing underspecified ~- reduction is that we may not know to which part of a redex a certain node belongs (as in Fig. 1).",
        "We address this problem by introducing underspecified correspondence literals of the form co({(Cl,Dl),... (Cn D,,,)})(X)=Y.",
        "Such a literal is satisfied if the tree segments denoted by the Cs and by the Ds do not overlap properly, and there is an i for which co(CZ, DZ) (X) = Y is satisfied.",
        "In Fig. 7 we present the rules UB for underspecified , -reduction; the first five rules are the core of the algorithm.",
        "To keep the rules short, we use the following abbreviations (with 1 < i < n): beta =def (C, B, A)(C', B', Ai, ... , An) cot =def co({ (C, C'), (B, B'), (A, AZ)}) The procedure solve consists of UB together with the propagation rules from (Bodirsky et al., 2001).",
        "The rest of this section shows how this procedure operates and what it can and cannot do.",
        "First, we discuss the five core rules.",
        "Rule (Beta) states that whenever the , reduction relation holds, group parallelism holds, too.",
        "(This allows us to fall back on a complete solver for group parallelism.)",
        "Rule (Var) introduces a new variable as a correspondent of a redex variable, and (Lab) and (Dom) copy labeling and dominance literals from the redex to the reduct.",
        "To understand the exceptions they make, consider e.g.",
        "Fig.",
        "5.",
        "Every node below 7ro has a correspondent in the reduct, except for 73.",
        "Every labeling relation in the redex also holds in the reduct, except for the labelings of the (0-node 71, the lam-node 73, and the var-node 74.",
        "For the variables that possess a correspondent, all dominance relations in the redex hold in the reduct too.",
        "The rule (..Inv) copies inverse A-binding literals, i.e. the information that all variables bound by a A-binder are known.",
        "For now,",
        "it is restricted to linear redexes; for the nonlinear case, we have to take recourse to disambiguation.",
        "It can be shown that the rules in UB are sound in the sense that they are valid implications when interpreted over A-structures."
      ]
    },
    {
      "heading": "6.3 Some Examples",
      "text": [
        "To see what the rules do, we go through the first reduction step in Fig. 1.",
        "The , reduction constraint that belongs to this reduction is (C, B, A) -0--> (C', B', Ai) with",
        "Now saturation can add more constraints, for example the following:",
        "We get (1), (2), (5) by propagation rules from (Bodirsky et al., 2001): variables bearing different labels must be different.",
        "Now we can apply (Var) to get (3) and (4), then (Lab) to get (6).",
        "Finally, (7) shows one of the dominances added by (Dom).",
        "Copies of all other variables and literals can be computed in a completely analogous fashion.",
        "In particular, copying gives us another redex starting at Z8, and we can continue with the algorithm usb in Figure 6.",
        "Note what happens in case of a nonlinear redex, as in the left picture of Fig. 8: as the redex is 2 ary, the rules produce two copies of the ~ labeling constraint, one via col and one via cot.",
        "The result is shown on the right-hand side of the figure.",
        "We will return to this example in a minute."
      ]
    },
    {
      "heading": "6.4 More Complex Examples",
      "text": [
        "The last two rules in Fig. 7 enforce consistency between scoping in the redex and scoping in the reduct.",
        "The rules use literals that were introduced in (Bodirsky et al., 2001), of the forms X E b(A), X 0 i(B), etc., where A, B are segment terms.",
        "We take X E b(A) to mean that X must be inside the tree segment denoted by A, and we take X E i(B) (i for interior) to mean that X E b(B) and X denotes neither the root nor a hole of B.",
        "As an example, reconsider Fig. 3: by rule (Par.part), the reduct (right-hand picture of Fig. 3) cannot represent the term f (~(b(a))) because that would require the ~ operator to be in i (Y).",
        "Similarly in Fig. 8, where we have introduced two copies of the ~ label.",
        "If the ~ in the redex on the left ends up as part of the context, there should be only one copy in the reduct.",
        "This is brought about by the rule (Par.all) and the fact that correspondence is a function (which is enforced by rules from (Erk et al., 2001) which are part of the solver in (Bodirsky et al., 2001)).",
        "Together, they can be used to infer that Zo can have only one correspondent in the reduct context."
      ]
    },
    {
      "heading": "7 Conclusion",
      "text": [
        "In this paper, we have shown how to perform an underspecified , reduction operation in the CLLS framework.",
        "This operation transforms underspecified descriptions of higher-order formulas into descriptions of their , -reducts.",
        "It can be used to essentially , reduce all readings of an ambiguous sentence at once.",
        "It is interesting to observe how our underspecified , reduction interacts with parallelism constraints that were introduced to model ellipses.",
        "Consider the elliptical three-reading example Peter sees a loophole.",
        "Every lawyer does too.",
        "Under the standard analysis of ellipsis in CLLS (Egg et al., 2001), Peter must be represented as a generalized quantifier to obtain all three readings.",
        "This leads to a spurious ambigu~ lameslam var @ peter var @mary laugh i",
        "ity in the source sentence, which one would like to get rid of by , reducing the source sentence.",
        "Our approach can achieve this goal: Adding , reduction constraints for the source sentence leaves the original copy intact, and the target sentence still contains the ambiguity.",
        "Under the simplifying assumption that all redexes are linear, we can show that it takes time 0(kn3) to perform k steps of underspecified , - reduction on a constraint with n variables.",
        "This is feasible for large k as long as n < 50, which should be sufficient for most reasonable sentences.",
        "If there are non-linear redexes, the present algorithm can take exponential time because sub-terms are duplicated.",
        "The same problem is known in ordinary A-calculus; an interesting question to pursue is whether the sharing techniques developed there (Lamping, 1990) carry over to the underspecification setting.",
        "In Sec. 6, we only employ propagation rules; that is, we never disambiguate.",
        "This is conceptually very nice, but on more complex examples (e.g. in many cases with nonlinear redexes) disambiguation is still needed.",
        "This raises both theoretical and practical issues.",
        "On the theoretical level, the questions of completeness (elimination of all redexes) and confluence still have to be resolved.",
        "To that end, we first have to find suitable notions of completeness and confluence in our setting.",
        "Also we would like to handle larger classes of examples without disambiguation.",
        "On the practical side, we intend to implement the procedure and disambiguate in a controlled fashion so we can reduce completely and still disambiguate as little as possible."
      ]
    }
  ]
}
