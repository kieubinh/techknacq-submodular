{
  "info": {
    "authors": [
      "Dan Moldovan",
      "Vasile Rus"
    ],
    "book": "Annual Meeting of the Association for Computational Linguistics",
    "id": "acl-P01-1052",
    "title": "Logic Form Transformation of WordNet and Its Applicability to Question Answering",
    "url": "https://aclweb.org/anthology/P01-1052",
    "year": 2001
  },
  "references": [
    "acl-A88-1032",
    "acl-C92-4189",
    "acl-J86-3006",
    "acl-P85-1037",
    "acl-P98-2180",
    "acl-P98-2181",
    "acl-W99-0501"
  ],
  "sections": [
    {
      "heading": "Abstract",
      "text": [
        "WordNet is a rich source of world knowledge from which formal axioms can be derived.",
        "In this paper we present a method for transforming the WordNet glosses into logic forms and further into axioms.",
        "The transformation of WordNet glosses into logic forms is useful for theorem proving and other applications.",
        "The paper demonstrates the utility of the WordNet axioms in a question answering system to rank and extract answers."
      ]
    },
    {
      "heading": "1 Introduction 1.1 Motivation",
      "text": [
        "It is well understood and agreed that world knowledge is necessary for many common sense reasoning problems.",
        "In this paper we argue that WordNet is an important source of world knowledge and show how this knowledge can be put to work for open-domain Question Answering systems.",
        "Consider the TREC-QA question (NIST, 2000): Q198: How did Socrates die?",
        "The answer to this question appears in the text \"...Socrates' death came when he chose to drink poisoned wine... \".",
        "To prove that this is a plausible answer one needs to know that drinking poisoned wine may be a cause of death.",
        "This extra knowledge is found in WordNet glosses (Miller, 1995).",
        "The gloss of concept poison:vII2 (the second sense of verb poison) contains {kill with poison} and the first sense of verb kill:v111 is {cause to die}, which collectively justify the answer.",
        "This paper presents a simple but consistent logic notation suitable for representing the English texts of the WordNet glosses.",
        "The WordNet logic forms supply us with a rich set of axioms essential for boosting the performance of a Question Answering system."
      ]
    },
    {
      "heading": "1.2 Research Goal",
      "text": [
        "The goal of this research project is to transform all the WordNet glosses into logic representations that enables reasoning mechanisms for many practical applications.",
        "In this paper we limit the discussion to the definitions and ignore the gloss examples.",
        "The logic form is an intermediary step between the syntactic parse and the deep semantic form.",
        "The Logic Form Transformation (LFT) codification acknowledges syntax-based relationships such as: (1) syntactic subjects, (2) syntactic objects, (3) prepositional attachments, (4) complex nominals, and (5) adjectival/adverbial adjuncts.",
        "The main problems encountered are the selection of an appropriate logic representation and the actual implementation of the rules that transform the English definitions into logic forms.",
        "Before the rules are applied, the glosses are passed through a preprocessing phase consisting of tokenization, part-of-speech tagging and syntactic parsing."
      ]
    },
    {
      "heading": "1.3 Approach",
      "text": [
        "There are two criteria that guide our approach: (1) the notation be as close as possible to English, and (2) the notation be syntactically simple.",
        "Our approach is to derive the LFT directly from the output of the syntactic parser.",
        "The parser resolves the structural and syntactic ambiguities.",
        "This way, we avoid the very hard problems of logic representation of natural language.",
        "We follow closely the successful representation used by Hobbs in TACITUS (Hobbs, 1986).",
        "Hobbs explains that for many linguistic applications it is acceptable to relax ontological scruples, intricate syntactic explanations, and the desire for efficient deductions in favor of a simpler notation closer to English.",
        "For the logic representation of WordNet glosses we ignore: plurals and sets, verb tenses, auxiliary verbs, quantifiers and modal operators, comparatives and negation.",
        "This decision is based on our desire to provide manageable and consistent logic representation that otherwise would be unfeasible.",
        "We have not noticed that these simplifications had any adverse effect on the TREC questions."
      ]
    },
    {
      "heading": "1.4 Related Work",
      "text": [
        "This work is part of a larger project to extend WordNet outlined in (Harabagiu et al., 1999).",
        "Our work of processing WordNet glosses resembles previous efforts of extracting lexical information from machine readable dictionaries (MRD), as LDOCE (Longman Dictionary of Contemporary English) or Webster's 2nd International Dictionary (W2).",
        "Different parsing methods of dictionary definitions were used: pattern-matching (Chodorow et al., 1985), genus disambiguation (Bruce and Guthrie, 1992), especially constructed definition parsers (Wilks et al., 1996) or broad coverage parsers (Richardson et al., 1998), (Rigau et al., 1998), (ISI, 1998).",
        "All those efforts were limited to extracting genus terms, unlabeled or labeled relations, or build taxonomies."
      ]
    },
    {
      "heading": "2 LFT Definitions",
      "text": []
    },
    {
      "heading": "Predicates",
      "text": [
        "A predicate is generated for every noun, verb, adjective or adverb encountered in any gloss.",
        "The name of the predicate is a concatenation of the morpheme's base form, the part-of-speech and the WordNet semantic sense, thus capturing the full lexical and semantic disambiguation.",
        "For example, the LFT of the gloss of {student, pupil, educatee} is (a learner who is enrolled in an educational institution).",
        "It will contain the predicates learner:n, enroll:v and educational_institution:n. Fix slot-allocation In the spirit of the Davidsonian treatment of the action predicates (Davidson, 1967), all verb predicates (as well as the nominalizations representing actions, events or states) have three arguments:",
        "action/state/event-predicate(e,x1,X2), where: • e represents the eventuality of the action, state or event stated by the verb to take place, • x1 represents the syntactic subject of the action, event or state, and • X2 represents the syntactic direct object of the action, event or state.",
        "X3).",
        "For example: professor gives students the grades is represented as: professor(x1) & give(e1,X1,X2,X3) & grade(X2) & student(X3).",
        "This condition is detected by the presence of two noun phrases following a verb in active voice.",
        "(b) The arguments of verb predicates are always in the order: subject, direct object, indirect object.",
        "In the case when one of these syntactic roles is missing, its respective argument appears under the verb predicate, but that argument will not be used by any other predicate.",
        "This is a so-called \"slot-allocation\" representation since the position of the arguments is fixed for the purpose of a simpler notation.",
        "Since in WordNet glosses not many verbs have indirect objects, the argument X3 is used only when necessary, otherwise is ommited.",
        "However, the arguments for the subjects and direct objects are always present, even when the verb does not have these syntactic roles.",
        "We found that this simple but consistant representation is easy to derive and use.",
        "Modifiers The role of complements within a phrase is replicated in the LFTs.",
        "Predicates generated from modifiers share the same arguments with the predicates corresponding to the phrase heads.",
        "Adjective predicates share the same argument as the predicate corresponding to the noun they modify.",
        "An exemplification is the LFT of the gloss of {artifact, artifact}, which maps (a man-made object) into [ object:n(x1) & man-made:a(x1)].",
        "Similarly, the argument of adverbial predicate is the argument marking the eventuality of the event/state/action they modify.",
        "For example, the gloss of the verb synset {hare} is (run quickly), producing the LFT = [run(e1,X1,X2) & quickly(el)].",
        "Conjunctions Conjunctions are transformed in predicates, which enable the aggregation of several predicates under the same syntactic role (e.g. subject, object or prepositional object).",
        "By convention, conjunction-predicates have a variable number of arguments, since they cover a variable number of predicates.",
        "The first argument represents the \"result\" of the logical operation induced by the conjunction (e.g. a logical and in the case of the and conjunction, or a logical or in the case of the or conjunction).",
        "The rest of the arguments indicate the predicates covered by the conjunction, as they are arguments of those predicates as well.",
        "Table 1 provides examples of conjunction predicates.",
        "We also generate predicates for every preposition",
        "encountered in the gloss.",
        "The preposition predicates always have two arguments: the first argument corresponding to the predicate of the head of the phrase to which prepositional phrase is attached, whereas the second argument corresponds to the prepositional object.",
        "This predicative treatment of prepositional attachments was first reported in (Bear and Hobbs, 1988).",
        "Table 2 shows some examples of preposition predicates.",
        "Complex nominals Many complex nominals are encoded currently in WordNet as synset entries comprising several words, known as WordNet collocations (e.g. flea market, baseball team, joint venture).",
        "Still, many compound nouns are not encoded as WordNet entries, and need to be recognized as a single nominal.",
        "The way of doing this was first devised in TACITUS (Hobbs, 1986), when the predicate nn was first introduced.",
        "Similar to conjunction predicates, the nn predicates can have a variable number of arguments, with the first one representing the result of the aggregation of the nouns corresponding to the rest of the arguments.",
        "Examples from Table 3 show the transformation of some complex nominals."
      ]
    },
    {
      "heading": "3 Logic Form Transformation Rules",
      "text": [
        "The implementation of LFTs relies on information provided by the syntactic parser.",
        "We have developed a set of transformation rules that create predicates and assign them arguments.",
        "There are two classes of rules: (1) intra-phrase and (2) inter-phrase transformation rules.",
        "The intea-phrase transformation rules generate predicates for every noun, verb, adjective or adverb.",
        "They also assign the variables that describe dependencies local to the phrase.",
        "The inter-phrase transformation rules provide the arguments of the verb predicates, preposition predicates and inter-phrasal conjunctions.",
        "Verb predicate arguments are identified by recognizing the syntactic subject and object of the respective verb, based on a few grammar rules and relative pronoun interpretation.",
        "Dependencies between adjectival (adverbial) phrases and noun (verb) phrases are predicted based on vicinity.",
        "Both intra and inter-phrase transformation rules are produced from the parser.",
        "Examples of transformation rules are shown in Table 4.",
        "Implementation The system consists of several modules: preprocessing, POS tagging, parsing, rules selection and logic form transformation.",
        "The preprocessing module extracts definitions from glosses, discards comments from definitions and eliminates unimportant particles.",
        "An effort was made to develop a highly accurate POS tagging dedicated to the processing of WordNet glosses.",
        "By using several taggers and a voting scheme we can automatically tag 92.48% with an accuracy of 98.5% and the remaining 7.52% words are tagged manually.",
        "Since the logic form transformations rely on the output of a parser we have developed a highly accurate syntactic parser specialized for WordNet glosses.",
        "Glosses were extended to full sentences.",
        "For example for noun glosses the first word of the synset followed by be is added to the definition.",
        "For instance the definition of prophet, oracle becomes Prophet is an authoritative person who divines the future.",
        "Other improvements to the syntactic parser include the special treatment of compound concepts and idioms.",
        "These improvements led to an over 90% precision in parsing WordNet glosses.",
        "This precision is measured at constituent level.",
        "The parser output is further transformed to prepare for the derivation of logic forms.",
        "Two ba",
        "sic techniques are used: (1) tag reduction and (2) transformations of parse trees.",
        "Tag reduction is motivated by the simplifications in notation: (1) determiners are eliminated, (2) plurals are ignored and we can replace NNS with NN, (3) proper nouns are treated identically as common nouns and thus NNP is changed into NN and (4) everything in a prenominal position plays the function of a modifier.",
        "Examples of rule reduction due to tag reduction are illustrated in Table 5.",
        "For verbs we ignore tenses; VBG, VBP, VBZ, VBN, VB are all mapped into VB.",
        "Keeping the passive information is important for syntactic role detection and thus we add a new tag VP-PASS to indicate that the head of the VP is passive.",
        "Modals and auxiliaries are eliminated and negations are ignored.",
        "The second technique consists of rearranging the parse trees so that more complex structures are reduced to simpler ones (see Figure 1)."
      ]
    },
    {
      "heading": "4 Results",
      "text": [
        "To validate our procedure we experimented on a subset of WordNet 1.6 noun glosses.",
        "The set of rules is formed by taking the most frequent rules for each grammar phrase detected in a corpus of 10,000 noun glosses randomly selected from the noun data file of WordNet 1.6.",
        "From parse trees we extract automatically all grammar rules and their number of occurrences then select the most frequent ones up to the point where the gain in coverage is less than 1%.",
        "Then we manually derived the LFTs corresponding to the selected rules",
        "(around 70 rules).",
        "The initial grammar rules are enhanced with other syntactic and lexical information in order to be able to properly detect the position of arguments for a predicate.",
        "For example, for a rule as VP -+ VP PP, the voice of the VP and the preposition itself are essential for establishing the syntactic role the prepositional object fulfills: subject if the voice of VP is passive and the preposition is by, or indirect object if VP is in active voice.",
        "To test the overall performance of the rules selected we built a corpus of 400 noun glosses from the artifact hierarchy.",
        "We expanded the glosses' definitions, corrected the tags and parsed them.",
        "Finally, we obtained the LFT for each expanded gloss manually.",
        "Then we run the system on our test data and compared the output with the LFTs obtained by hand.",
        "An overall accuracy of 81% was obtained.",
        "The main sources of errors were: gloss irregularities, tag errors which lead to parse errors, errors of the parser itself, errors resulting from uncovered rules and from untreated cases of comparatives.",
        "5 Applicability of LFT to Question Answering The LFT of WordNet glosses are used in our Question Answering system (Harabagiu et al., 2000) to extract some answers and provide answer explanations.",
        "To be useful the glosses logic forms need to be transformed in axioms.",
        "One possibility is to generate several axioms for each gloss, from simple to more complex, as illustrated in Table 6.",
        "5.1 From logic forms to axioms There are some specific aspects in the derivation of axioms for each part of speech.",
        "Usually the nouns definition consists of a genus and differentia.",
        "The template for deriving noun axioms is: concept(X) -+ genus(x) V differentia (x).",
        "Notice the propagation of arguments from the left hand side to the genus and differentia, without significant syntactic changes.",
        "The verbs also exhibit the same structural properties and the derivation is simple for the case of definitions containing only one verb.",
        "In the case of definitions consisting of a series of verbs, the derivation of axioms should take care of the syntactic function changes of the arguments on the right hand side from their counterparts on the left hand side.",
        "Consider kill:v111 -+ { \"cause to die\"}.",
        "The axiom is kill:vlll (el, x1, x2, x3) -+ cause(e2, x1, e3, x3) & die(e3, x2).",
        "One notices the change of x2 from a direct object role for kill to a subject role for die.",
        "Also event el expands in two other events e2, e3.",
        "In the case of adjectives which modify nouns, the axioms borrow a virtual head noun as shown here: American:a//1(x1) -+ of(x1, x2) V United_States_of_America(x2).",
        "Similarly, since adverbs modify verbs - their arguments borrow the event of the verb.",
        "Adverb",
        "fast:rlll has an axiom: fast:rIll (e) -+quickly(e).",
        "5.2 Answer extraction procedure 1.",
        "Transform questions and answers in logic forms.",
        "For each question, the information retrieval part of the QA system provides a set of candidate paragraphs that may contain the question answer.",
        "Thus, the input to the logic prover consists of the question and a candidate paragraph that needs to be evaluated.",
        "The first step here is to transform the question and paragraph into logic forms called QLF and ALF (from answer logic form).",
        "2.",
        "Form lexical chains between pairs of concepts.",
        "If all the keywords from a question are found in the answer paragraph we only need to check for the syntactic relation preservation.",
        "This is done via unification - explained later.",
        "Otherwise, we attempt to establish possible lexical chains between pair of concepts, one in QLF and one in ALF, to check whether or not they are semantically linked.",
        "A chain between a pair of concepts is a sequence of other concepts that are linked via hypernymy relation and/or axioms.",
        "A chain is establised when two paths each starting from different concepts intersect, that is have a WordNet concept in common.",
        "Many chains may be found that link a pair of concepts.",
        "To evaluate all of them would be too costly and unnecessary.",
        "Thus a filtering mechanism is required.",
        "We do this using two heuristics: (1) keep only the shortest lexical chains (2) if several short chains exist, pick those that contain more hypernymy relations.",
        "The rationale behind these is that the shorter the chain, the stronger the semantic relation between the pair of concepts, and hypernymy relation is preferred over axioms.",
        "3.",
        "Apply unification on lexical chains.",
        "Once chains are established between a pair of concepts from the QLF and ALF, the logic form representation provides us with a mechanism for performing agreement unification.",
        "This checks the syntactic constraints.",
        "Two concepts along the chain are unified if their predicates and arguments match.",
        "In a successful unification the arguments of question predicate will be bound to the arguments of answer predicate and the QLF and ALF updated to reflect the new status of arguments.",
        "Step 0 in Table 8 shows the QLF, respectively ALF.",
        "In step 1, the matching is peformed between some predicates, e.g. Lucelly-Garcia from QLF, respectively ALF, and x1 is bound to x1' which is reflected in the new QLF shown in step 1.",
        "4.",
        "Extract inferences to provide explanation.",
        "The concepts along those lexical chains that survive the unification test lead to inferences that explain the answer.",
        "It is only necessary to retrieve the concepts along the chain and the hypernymy and axioms explain the relation between them."
      ]
    },
    {
      "heading": "5.3 Examples Example 1",
      "text": [
        "Consider the TREC question: QO45: When did Lucelly Garcia, former ambassador of Colombia to Honduras, die?",
        "The answer is found in \"Several gunmen on a highway leading to the Colombian city of Ibague murdered Colombian Ambassador to Honduras Lucelly Garcia today\".",
        "As illustrated in Table 8 at Step 0 we are able to match a few predicates: Lucelly-Garcia, ambassador, TIME-STAMP.",
        "With the help of the axioms, chains are found: from Colombian in the answer to Colombia in the question, respectively from murder to die (see Figure 1).",
        "For former there was no link to a concept in the answer and we just ignore it (as being a modifier of an already matched predicate ambassador).",
        "The ALF in Step 1 shows Colombian expanded with axioms from WordNet (see Table 6).",
        "The new QLF to be proven contains only the predicate die.",
        "Step 2 in Table 8 shows the ALF after the expansion of murder with its corresponding axiom:",
        "Then Step 3 is derived using: kill(e,x1,x2) H cause(el,xl,e2) & die(0,x2).",
        "As explained earlier, the subject of kill is propagated as subject of cause and the object of kill, which is Lucelly-Garcia, as the subject to die.",
        "Also, we replicate the TIME-STAMP predicate to modify both e2 and e3.",
        "The QLF is successfully proven as it becomes empty."
      ]
    },
    {
      "heading": "Example 2",
      "text": [
        "Consider the TREC-9's question:"
      ]
    },
    {
      "heading": "Q481: Who shot Billy the Kid?",
      "text": [
        "The Q/A system identifies a few paragraphs that contain all the keywords from the question and the answer type.",
        "Two such paragraphs are:",
        "• P1: The scene called for Phillips ' character to be saved from a lynching when Billy the Kid ( Emilio Estevez ) shot the rope in half just as he was about to be hanged .",
        "• P2: In 1881 , outlaw William H. Bonney Jr. , alias Billy the Kid , was shot and killed by Sheriff Pat Garrett in Fort Sumner , N.M.",
        "The answer is provided by paragraph P2 and is depicted by the system as follows.",
        "Using LFT, the question has a representation of the",
        "Billy_the_Kid(x2) where xl is a variable that is to be unified with an entity of type PERSON from paragraphs.",
        "The paragraphs have the following LFT (we show only the relevant part):",
        "• P1: Billy_the_Kid(x1') & shoot(el', x1', x2') & rope(x2) • P2: Billy_the_Kid(x1') & shoot(el', x2', x1') & Sheriff_Pat_Garrett(x2')",
        "The logic prover attempts to prove the question starting from the paragraph.",
        "The logic proof for P1 fails because Billy-the-Kid is the agent of shooting, not the object as requested by the question.",
        "The logic proof for P2 succeeds and the agent of shooting Sheriff_Pat_Garrett unifies with PERSON from the question.",
        "The prover yields el = el', xl = x2' and x2 = x1'.",
        "Note that our logic form representation based on slot-allocation played a crucial role in this proof.",
        "r"
      ]
    },
    {
      "heading": "5.4 QUA Results",
      "text": [
        "Table 9 shows five randomly selected questions for which all the keywords from the question are found in the answer and for which the system found the correct answer in top five ranked answers (initial rank) just by matching keywords.",
        "The logic prover boosts the performance by eliminating the wrong answers and bringing the correct answer to the first place.",
        "Table 10 shows the results on 10 questions for which we successfully retrieved chains between unmatched concepts in the question.",
        "To better evaluate the impact of the logic prover the word sense",
        "disambiguation task has been done manually for the questions, answers and for a set of targeted glosses.",
        "The Pairs of Concepts column illustrates the number of pairs of concepts from the question, respectively answer paragraph (ground concepts).",
        "The paths column shows the number of paths retrieved: these are paths that originate in the ground concepts, some of which intersect and form lexical chains.",
        "The chains column shows how many lexical chains were established.",
        "The next column, shows how many concepts were encountered along those paths.",
        "The Chains used column shows how many chains were selected to perform unification.",
        "In each case, one chain led to the correct answer."
      ]
    },
    {
      "heading": "6 Conclusions",
      "text": [
        "We have presented here a procedure to transform WordNet glosses into logic forms.",
        "The notation used is first order logic and contains syntactic information as positional arguments.",
        "An overall precision of 81% on 400 WordNet glosses was obtained.",
        "The paper demonstrates how WordNet glosses provide world knowledge axioms essential for boosting the performance of a Question Answering system."
      ]
    }
  ]
}
