{
  "info": {
    "authors": [
      "Sven Hartrumpf"
    ],
    "book": "Workshop on Computational Natural Language Learning CoNLL",
    "id": "acl-W01-0717",
    "title": "Coreference Resolution With Syntactico-Semantic Rules and Corpus Statistics",
    "url": "https://aclweb.org/anthology/W01-0717",
    "year": 2001
  },
  "references": [
    "acl-A00-1020",
    "acl-C90-3063",
    "acl-C96-1021",
    "acl-J00-4003",
    "acl-J00-4005",
    "acl-J94-4002",
    "acl-J95-2003",
    "acl-M95-1005",
    "acl-M98-1029",
    "acl-P98-2143",
    "acl-W95-0103",
    "acl-W97-1306",
    "acl-W99-0611",
    "acl-W99-0614",
    "acl-W99-0634"
  ],
  "sections": [
    {
      "heading": "Abstract",
      "text": [
        "A new hybrid approach to the coreference resolution problem is presented.",
        "The COR.UDIS system (COreference R.Ules with DIsambiguation Statistics) combines syntactico-semantic rules with statistics derived from an annotated corpus.",
        "First, the rules and corpus annotations are described and exemplified.",
        "Then, the coreference resolution algorithm and the involved statistics are explained.",
        "Finally, the proposed method is evaluated against a baseline model and some directions for further research are indicated."
      ]
    },
    {
      "heading": "I Introduction",
      "text": [
        "Coreference resolution is a central problem in natural language understanding since coreference links play an important role for text coherence.' In sentence (1) for instance, one wants to know what the German personal pronouns sic and il6% refer to.",
        "Both can refer to MCYdCl6c,G or Zeitung because grammatical gender agreement in German can be overruled by natural gender agreement in certain cases.",
        "`The girl reads the newspaper; afterwards she goes to the office with it.' lI would like to thank Hermann Helbig, Rainer Oss-wald, and the anonymous reviewers for their helpful comments and suggestions.",
        "The task in this paper is similar to the MUC coreference task (Hirschman and Chin-chor, 1997)2: ■ only identity coreference is treated (and not part-whole or other complex semantic relationships); ■ only noun phrases (NPs) are considered as markables for coreference (and not situations expressed by clauses etc.).",
        "This kind of coreference is an equivalence relation so that coreference resolution comes down to finding the correct partition3 of markables.",
        "If there exists a genuine ambiguity for human readers (and not just a spurious one for computers), several partitions of markables would be the correct answer to the coreference problem.",
        "But since such ambiguities are rare the disambiguation method described in this paper always delivers only one partition.",
        "In this paper, the full MUC coreference task is tackled with a new hybrid approach combining syntactico-semantic rules with rule statistics derived from an annotated corpus.",
        "Two question might arise.",
        "Why not a purely statistical approach: first, because why throw away traditional linguistic knowledge, and second, because statistics on rules reduce the sparse data problem since the applicability of one rule classifies combinations of many relevant features into one feature value.",
        "Why not a purely rule-based approach: because it would leave too many alternatives and would not indicate which to choose.",
        "ence resolution method described in section 3: hand-crafted rules defining whether two markables can corefer or not and a corpus annotated with coreference information.",
        "The rules license possible coreferences; the corpus is used for scoring alternative coreference partitions with estimated probabilities."
      ]
    },
    {
      "heading": "2.1 Coreference rules",
      "text": [
        "The coreference rules are designed to license possible coreference relations among two markables.",
        "Some rules are language-dependent, some are universal; in this paper, the rules (and the corpus) are for German, but the approach suits other languages as well.",
        "Each rule consists of a unique name, a premise, and a conclusion.",
        "For development and maintenance reasons, a rule is accompanied by a description, some positive example texts, and some negative example texts.",
        "A positive example shows that the rule premise is satisfied and the conclusion that the two markables at hand are coreferential would be correct, whereas a negative example shows that the rule premise is not satisfied and the conclusion would indeed be incorrect for the example.",
        "The rule premise is a conjunction of (possibly negated) constraints; these can be constituent constraints (c-constraints) referring to feature values of one markable and interconstituent constraints (ic-constraints) referring to feature values of both markables that are to be tested for coreference.",
        "Both types of constraints can be attribute-value equations.",
        "The features used in coreference rules are listed in Table 1; the feature values for markables stem from a parser using a semantically oriented lexicon currently containing 14000 German lexemes (HaGenLex).",
        "A feature value can be a single type or a disjunction of types.",
        "Furthermore, one can construct constraints with predicates.",
        "The most important predicates are given in Table 2: they realize concepts from Dependency Grammar (depend/2) and Government and Binding Theory (c-command/2) or define simple relationships between constituents (e. g. compatible-gend-ngend/2).",
        "The conclusion of a rule expresses a coreference relation with a semantic network (based on the MultiNet formalism defined by Helbig (2001) which has been applied in several other projects, see (Hartrumpf, 1000; Knoll et al., 1008)).",
        "For identity coreference, a relation named ECRU (equivalence) leading from the anaphor (called c2 in rules)4 to the antecedent (called c1 in rules) suffices.",
        "Seven rules from the eighteen rules currently used are given in Figure 1.",
        "The rule ident.gend_conflict would license a link between das Madc16cri and sic in sentence (1).",
        "The premise and conclusion can also be viewed as one attribute value matrix employing structure sharing for expressing ic-constraints."
      ]
    },
    {
      "heading": "2.2 Annotated corpus",
      "text": [
        "A corpus (a collection of German newspaper articles from the Suddcutsc16c ZcitUrag) is annotated for coreference according to the guidelines for the MUC coreference task adapted from English to German.",
        "The annotations are inserted as SGML tags into the corpus, which is already marked up according to the Corpus Encoding Standard (Ide et al., 1006).",
        "The annotation for"
      ]
    },
    {
      "heading": "3 Coreference resolution",
      "text": []
    },
    {
      "heading": "3.1 Algorithm overview",
      "text": [
        "To resolve coreference ambiguities, one must find the partition of markables that corresponds to the correct coreference equivalence relation.",
        "The search space is huge since the number of different partitions for n markables is equal to the Bell number B(n).",
        "These numbers are also called Exponential numbers, see (Bell, 1034); some example values are: B(1) – 1, B(2) – 2, B(3) – 5, B(4) – 15, B(5) – 52, B(10) – ",
        "feature name use* description CAT c syntactic category (n (noun), perspro (personal pronoun), possdet (possessive determiner), reflpro (reflexive pronoun), etc.)",
        "ENTITY ic semantic classification comprising the semantic sort (feature SORT) and semantic Boolean features (currently 16, all defined for the MultiNet (mul-tilayered extended semantic network) formalism by Helbig (2001)) ETYPE ic extension type (0 (an individual), 1 (a set), 2 (a set of sets), etc.",
        "), part of the complex feature LAY containing other extensional and intensional layer features like CARD (cardinality)",
        "The values are unifiable.",
        "The first argument (a constituent) c-commands the second.",
        "The grammatical gender value at the first argument position is compatible with the natural gender value at the second argument position.",
        "The first argument (a possessive determiner) can refer to the second argument (a constituent).",
        "The arguments (two constituents) are related by a copula.",
        "The first argument (a constituent) depends on the second.",
        "Numerical difference between two feature values is greater than a third value.",
        "Two constituents containing (possibly complex) names match.",
        "The argument (a feature value) is maximal, i. e., a leaf node in the type hierarchy.",
        "One argument (a constituent) is a compound suffix of the other argument (a constituent) or both arguments have the same nominal head.",
        "The evaluated algorithm for coreference resolution is implemented as the COR.UDIS system (COreference R.Ules with DIsambiguation Statistics) and works as follows:",
        "tified.",
        "For this task and for gaining the syntactico-semantic feature values to be accessed by rules in step 2, each sentence in the text is parsed independently.",
        "If a sentence parse fails, a chunk parse is gener",
        "ated.",
        "(In such cases, constraints in rule premises that involve predicates requiring full parses (e. g. c-command) are ignored in step 2.)",
        "For details on the parser, see (Helbig and Hartrumpf, 1997).",
        "2.",
        "All possible coreference rule activations that link an anaphor to an antecedent can",
        "didate are collected.",
        "This is done by testing rule premises on all markable pairs (constituent c1 must precede constituent c2).",
        "For two markables, one rule (at most) is activated since the rules have disjoint premises for real text purposes.",
        "3.",
        "For each anaphor, one antecedent candidate is selected.",
        "This decision is based on rule statistics gained from the annotated training corpus.",
        "The sparse data problem is alleviated by backed-off estimation (se for example (Katz, 1987; Collins and Brooks, 1995)).",
        "The algorithm deals with three sets of objects: first, the possible anaphors (all identified markables); second, the candidate antecedents for each possible anaphor (all preceding markables and the artificial nonreferable markable explained below); third, the coreference rules.",
        "The nonreferable markable is used as the artificial anaphor of a nonreferring markable in order to represent all alternative references for a possible anaphor as a pair.",
        "For first-mentions, the disambiguation algorithm should select a coreference with the nonreferable markable as antecedent.",
        "Currently, one rule licenses the nonreferable markable as antecedent.",
        "But it might be useful to apply more finely grained rules and not just one rough licensing rule, as indicated by promising research results for definite descriptions referring to discourse-new entities (see (Vieira and Poesio, 2000))."
      ]
    },
    {
      "heading": "3.2 Disambiguating between",
      "text": [
        "antecedent candidates Step 3 of the algorithm given in section 3.1 is the most interesting one and needs some explanation.",
        "Leaving the issue of search algorithms aside for a moment, all possible and licensed partitions of identified markables are generated, filtered, and finally scored using estimated probabilities.",
        "The partitions are generated incrementally starting with the first possible anaphor in a singleton partition element.",
        "For each antecedent candidate licensed by a coreference rule in step 2, an extended partition with this antecedent in the same partition element as the anaphor in question is introduced.",
        "This process is iterated until all possible anaphors have been investigated.",
        "Partitions are filtered out if they violate one of the following distance and compatibility constraints: sentence distance The distance between the anaphor and the antecedent measured in sentences must be below the limit for the linking coreference rule.",
        "These limits have been learned from the training corpus.",
        "paragraph distance The distance between the linked markables measured in paragraphs must be below the limit learned for the licensing coreference rule.",
        "Typically, pronominal anaphoras can span only two paragraphs, while for example coreferences between named entities can span arbitrary distances.",
        "semantic compatibility All markables in a partition element must bear compatible semantics (unifiable ENTITY and LAY feature values, see Table 1).",
        "Because of the huge search space (see section 3.1), the generation of partitions and the filtering is intertwined in a heuristic search algorithm so that impossible alternatives in the search tree are pruned early.",
        "Also the scoring described below is done during the search so that alternatives with low (bad) scores can be delayed and possibly discarded early by the search algorithm.",
        "The score for a partition is constructed as the sum of estimated probabilities for adding the possible anaphor m currently under investigation to one of the antecedent candidates C _ (cl, cz, ... , ckk�.",
        "The candidates are ordered by distance; each c-i is a feature structure representing the parse result from algorithm step 1 for the corresponding markable.",
        "Each coreference between m and c-i is licensed by a coreference rule r-i so that this coreference alternative can be represented as the triple (m, c-i, r-i).",
        "In order to generalize from the token-based representation (m, c-i, r-i) and to make useful statistics from an annotated corpus, an abstraction function a is applied that abstracts from the given anaphor, antecedent candidate, and linking coreference rule to a type-based representation.",
        "The abstraction function in equation (3) turned out to be a good compromise between limited sparseness of statistical matrices and distinctiveness for disambiguation purposes: It reduces a coreference alternative (m, c-i, r-i) to the candidate antecedent position i and the licensing coreference rule r-i: a(m, c-i, r-i) : _ (i, r-i) (3) Let a-i be the abstracted coreference alternative a(m, c-i, r-i) and A be the list (aI, a2, ... , akk of abstracted coreference alternatives for the possible anaphor m. Then, the probability that a-i corresponds to the closest correct antecedent for m is estimated as the relative frequency rf(i, A):",
        "The equation uses the statistical values f(i, A), which count how many times in the annotated training corpus the abstracted coreference alternative a-i wins as the one with the closest correct antecedent in the context of abstracted coreference alternatives A.",
        "Further experiments have shown that looking at more than 5 antecedent candidates does not improve disambiguation results.",
        "Therefore, k is reduced to 5 if necessary.",
        "Backed-off estimation can alleviate sparse data problems.",
        "The basic idea is that if for a context A no statistical values are known, they are estimated by looking at increasingly smaller parts of A until statistical values are found.",
        "One might call such a backed-off estimation backed",
        "of the fj (i, A) becomes positive (then, the rfj(i, A) are used as scores for the antecedent candidates) or j reaches k – 1 (in this case, all candidates receive equal scores).",
        "If the back-off process stops at j – b, the relative frequencies rf '(i, A) are used as estimates for the conditional probabilities p(iIC) that c-i is the closest correct antecedent given antecedent candidates C:",
        "One could add other scores to those based on estimated probabilities.",
        "In the literature, syntactic parallelism between anaphor and antecedent (based on syntactic case), semantic parallelism (based on semantic roles), and maximality of antecedent NPs are proposed among others.",
        "In several experiments, such additional scores have been applied for certain rules (e. g. rules involving pronouns).",
        "Small improvements have been achieved, but this topic has not been investigated completely yet."
      ]
    },
    {
      "heading": "4 Evaluation",
      "text": [
        "Evaluation results from 12-fold cross-validation for 502 anaphors are listed in Table 3.",
        "The standard definitions for recall and precision used in information retrieval are as follows:",
        "For coreference resolution, true positives are correct coreference links found, false negatives are correct coreference links not reported, and false positives are incorrect coreference links reported.",
        "Vilain et al.",
        "(1005) illustrate that these definitions sometimes yield counter-intuitive results for coreference evaluations and propose model-theoretic definitions of recall and precision.",
        "The values in Table 3 are calculated with these modified definitions.",
        "There are three different evaluation results.",
        "The first is the full coreference task.",
        "The second one could be called markable-relative evaluation since the numbers are calculated only for the markables that have been successfully identified (in some sense, this concentrates on the coreference relation aspect of the coreference task).",
        "And the final evaluation result comes from a baseline model: \"always select the closest antecedent candidate that is licensed by a rule and fulfills the distance and compatibility constraints from section 3.2\"."
      ]
    },
    {
      "heading": "5 Related Work",
      "text": [
        "There are many recent approaches to this problem, e. g. syntax-based approaches (Lappin and Leass, 1004), cooccurrence-based approaches (Dagan and Itai, 1000), machine-learning approaches (Connolly et al., 1004; Aone and Bennett, 1006; Soon et al., 1000), uncertainty reasoning approaches (Mitkov, 1005; Mitkov, 1007), and robust knowledge-poor approaches (Kennedy and Boguarev, 1006; Baldwin, 1007;",
        "method evaluation results in percentage recall precision F-measure",
        "è+é.",
        "Mitkov, 1998b; Mitkov, 1999).6 The following two systems tackle the MUC coreference task and bear some similarities to CORUDIS.",
        "The system described by Cardie and Wagstaff (1999) resembles the presented system in that it views coreference resolution in a text as partitioning (or clustering).",
        "The difference in terms of clustering is that the first system uses greedy clustering while CORUDIS optimizes using global scores.",
        "The fundamental difference is that the first system partitions based on a similarity function over markable representations as attribute value pairs, while CORUDIS applies linguistic rules to license possible coreference links and applies corpus statistics to choose one link because typically alternatives exist.",
        "The SWIZZLE system (Harabagiu and Maio-rano, 2000) applies heuristics and heuristic ordering by bootstrapping to pick one antecedent per anaphor; in the CORUDIS system, rules license alternatives and one is selected based on a learned statistical model.",
        "CORUDIS uses sentence parsing, SWIZZLE as an intentionally knowledge-poor approach only approximate Phrasal parsing."
      ]
    },
    {
      "heading": "6 Conclusion",
      "text": [
        "I have presented a disambiguation method which combines traditional linguistically motivated rules and a backed-off statistical model derived form an annotated corpus in a powerful way.",
        "Comparison to other approaches is difficult since evaluation results for German are not available for the MUC coreference task.",
        "But the results presented seem to be competitive com",
        "anaphors, except the approaches by Aone and Bennett (1996), Baldwin (1997), Connolly et al.",
        "(1994), and Soon et al.",
        "(1999).",
        "pared to the 60% F-measure results for English in MUC-7.",
        "Additional filtering conditions, additional scores (preferences), and features from Centering Theory (Grosz et al., 1995) might improve the results reported in this paper significantly.",
        "The use of a large lexical-semantic network like GermaNet would solve some problematic coreference cases.",
        "More sophisticated evaluations centered around different error types as recommended by Mitkov (1998a) and larger data sets are planned for the future."
      ]
    }
  ]
}
