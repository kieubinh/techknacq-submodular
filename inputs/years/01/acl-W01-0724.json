{
  "info": {
    "authors": [
      "Erik F. Tjong Kim Sang"
    ],
    "book": "Workshop on Computational Natural Language Learning CoNLL",
    "id": "acl-W01-0724",
    "title": "Memory-Based Clause Identification",
    "url": "https://aclweb.org/anthology/W01-0724",
    "year": 2001
  },
  "references": [
    "acl-E99-1023",
    "acl-P95-1037",
    "acl-W00-0733",
    "acl-W01-0708"
  ],
  "sections": [
    {
      "heading": "1 Introduction",
      "text": [
        "We apply a memory-based learner to the CoNLL-2001 shared task: clause identification (Tjong Kim Sang and De�jean, 2001).",
        "The task is divided in three parts.",
        "The first two parts are classification tasks: identifying the positions of clause starts and clause ends given a word, its part-of-speech tag and the syntactic base chunk it belongs to.",
        "Our memory-based learner can be applied to these tasks in a straightforward way.",
        "The third part of the shared task is identifying complete embedded clauses.",
        "We will perform this task by first identifying clause starts and clause ends and then combining these to clauses with a set of conversion rules."
      ]
    },
    {
      "heading": "2 Approach",
      "text": [
        "The first two parts of the CoNLL-2001 shared task are similar to the CoNLL-2000 shared task: classify words in context according to some tagging scheme.",
        "We have participated in the latter shared task (Tjong Kim Sang, 2000) and we will use a similar approach for the first two parts of the 2001 shared task.",
        "The goal of these parts is to predict if a word is the first word of a clause or not (part 1) and if it is the final word of a clause or not (part 2).",
        "We have used the memory-based classifier TiMBL (Daelemans et al., 2000) for predicting the most likely classification of each word.",
        "Memory-based learners store all training data and determine a classification for new data by examining the classifications of training data which are similar to the new data.",
        "Each item is represented by a set of feature-value pairs.",
        "The features have weights which encode their relevance to the classification of the training data items (Daelemans et al., 2000).",
        "Although the memory-based learner is able to find a sensible feature weight set, it is not guaranteed to find the best feature weight set.",
        "In an earlier study (Tjong Kim Sang and Veen-stra, 1999), we have reported that the number of features supplied to the system has an influence on the performance and that the maximal number of features not necessarily provided the best results.",
        "In order to maximize the system's performance, we have evaluated seven combinations of the available three feature types (words, part-of-speech (POS) tags and clause tags):",
        "1. words only (w) 2.",
        "POS tags only (p) 3. clause tags only (c) 4. words and POS tags (wp) 5. words and clause tags (wc) 6.",
        "POS tags and clause tags (pc) 7. words, POS tags and clause tags (wpc)",
        "In our CoNLL-2000 work, we have shown that it is useful to evaluate combinations of classifiers since these often tend to perform better than their best individual member (Tjong Kim Sang, 2000).",
        "We will also use this approach here and will evaluate majority votes of the classifier combinations 1+2+3 (8), 4+5+6 (9) and 7+8+9 (10).",
        "This means, for example, that we will look at the output of the classifiers 1, 2 and 3 of the list above.",
        "Each of these classifiers predicts that a word starts a clause or not (task 1).",
        "We generate a new data classification (8) by choosing for each word the classification which is predicted most frequently.",
        "The ten set-ups we have described above, use information about all words.",
        "However, clauses are a high-level structures which might not need all this information.",
        "It might be useful to replace the chunks by a single token since our fixed-context system might be able to make better judgements when it is able to examine a",
        "validation experiments with the training data of part 1 of the shared task.",
        "We used different combinations of information (w: words, p: POS tags and c: chunk tags) and different context sizes (0-3).",
        "The best results have been obtained with a majority vote of three information pairs while using context size 1 (row 9).",
        "larger part of a sentence.",
        "We have tested this by removing all chunks from the data and replacing them by their head word and the chunk tag.",
        "The head words have been generated by a set of rules put forward by (Magerman, 1995) and modified by (Collins, 1999)1.",
        "Words that are outside of a base chunk receive their POS tag as chunk tag.",
        "This approach consists of three feature combinations: words only (w-), chunk tags only (c-) and words and chunk tags (wc-).",
        "The evaluation has been performed with 10- fold cross-validation on the training data to avoid tuning the system parameters on the test data.",
        "This means that we have split the training data in 10 parts and tested each of the parts after having trained with the other nine.",
        "The 10 results have been concatenated and processed by the evaluation software for the shared task.",
        "In this evaluation process we have also tested different symmetric sizes of the context: 0, 1, 2 and 3.",
        "For example, while classifying the fourth word of the phrase But analysts reckon underlying support for sterling, we used only one feature for context size 0 (underlying) and five for con",
        "validation experiments with the training data of part 2 of the shared task.",
        "We used different combinations of information (w: words, p: POS tags and c: chunk tags) and different context sizes (0-3).",
        "The best results have been obtained with words and POS tags after compressing the chunks and while using context size 3 (row 13).",
        "text size 2 (analysts, reckon, underlying, support, for): the focus word and the two previous and the two next words.",
        "In our previous work we found that the performance increased for larger context sizes until some task-dependent size after which the performance dropped gradually (Tjong Kim Sang and Veenstra, 1999).",
        "In principle, the third part of the shared task can also be interpreted as a classification task.",
        "However, the task is more difficult since besides predicting where clauses start and end, it requires as well predicting how many clauses start or end at a certain position.",
        "This is a sheer impossible task for a system which examines no more than 7 tokens at a time but needs to process sentences with an average length of more than 20 tokens.",
        "Rather than solving the impossible, we have tried to use the results of the other two parts of the shared task, start and end positions of clauses, for building a complete clause structure.",
        "For this purpose we have used the following heuristic rules:",
        "1.",
        "Assume that exactly one clause starts at each clause start position.",
        "2.",
        "Assume that exactly one clause ends at each clause end position but 3. ignore all clause end positions when currently no clause is open, and 4. ignore all clause ends at non-sentence-final positions which attempt to close a clause started at the first word of the sentence.",
        "5.",
        "If clauses are opened but not closed at the end of the sentence then close them at the penultimate word of the sentence.",
        "These rules generate complete and consistent embedded clause structures from the clause boundary output of our experiments."
      ]
    },
    {
      "heading": "3 Results",
      "text": [
        "We have performed the evaluations described in the previous section in a 10-fold cross-validation experiment on the training data of parts 1 and 2 of the shared task.",
        "The results can be found in tables 1 and 2.",
        "For the clause start prediction part (1), we obtained the best performance with a majority vote of the results for the feature combinations wp, wc and pc (row 9) for context size 1 (F,3_1 = 88.83).",
        "The clause end prediction part (2) worked best with the compressed chunk format while using feature combination wc (row 13) with context size 3 (F,3_1 = 81.61).",
        "Table 2 shows a monotonic increase of the F rates for increasing context size.",
        "Indeed, the increase goes on for context size 4 but its maximal F rate (81.72) is probably not significantly higher than the one for context size 3.",
        "We have combined the two results with the heuristic rules to a complete clause structure which obtained F,3_1 = 71.34 on part 3 of the shared task (training data only)2.",
        "After finding the best training configurations for the training data, we have applied these to the development and the test data for the shared task.",
        "The results can be found in table 3.",
        "All F rates are better than the baseline scores (Tjong Kim Sang and De�jean, 2001).",
        "Recall scores are lower than precision scores, like we have observed in our earlier work.",
        "Predicting clause ends seems to be more difficult than predicting clause starts.",
        "We do not know what could be causing this."
      ]
    },
    {
      "heading": "4 Concluding Remarks",
      "text": [
        "We have put forward a method for identifying clauses in sentences given the words, their part-of-speech tags and a base chunk structure of the sentence: the CoNLL-2001 shared task.",
        "It uses a memory-based learner for predicting positions of clause starts and clause ends.",
        "After this, a list of heuristic rules is used for converting these positions to a consistent embedded clause structure.",
        "Our approach obtains F,3_1 = 66.67 on the test data of the third part of the shared task."
      ]
    }
  ]
}
