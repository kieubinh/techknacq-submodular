{
  "info": {
    "authors": [
      "Widad Mustafa El Hadi",
      "Ismail Timimi",
      "Annette Beguin",
      "Marcilio De Brito"
    ],
    "book": "Workshop on Evaluation Methodologies for Language and Dialogue Systems",
    "id": "acl-W01-0907",
    "title": "The ARC A3 Project: Terminology Acquisition Tools: Evaluation Method and Task",
    "url": "https://aclweb.org/anthology/W01-0907",
    "year": 2001
  },
  "references": [
    "acl-A94-1006"
  ],
  "sections": [
    {
      "text": [
        "mustafa@univ-lille3.fr timimi@univ-lille3.fr beguin@univ-lille3.fr mdebrito@noos.fr UFR IDIST & CERSATES (CNRS UMR 8529) Université Charles De Gaulle, Lille 3 BP 149, F-59 653 Villeneuve D'Ascq, France"
      ]
    },
    {
      "heading": "Abstract",
      "text": [
        "This paper describes the work achieved in the Concerted Research Project ARC A3 supported and coordinated by the AUF1, former Aupelf-Uref2.",
        "The project deals with the evaluation of term and semantic relation extraction from corpora in French.",
        "Eight participants, both from public institutions and industrial corporations were involved in this project and were responsible for producing corpora suitable for extraction tasks and elaborating a protocol in order to evaluate objectively terminology acquisition tools.",
        "This expression covers respectively, term extractors, classifiers and semantic relation extractors.",
        "The paper also reports on the methodology used for comparing four term extractors, one classifier and three semantic relation extractors during the 2000 evaluation campaign.",
        "There are also several by-products of this campaign: first, two corpora which can be used for NLP system development and evaluation as the AUF recommended; and then terminology products: for each corpus a list of terms characterizing the field is available.",
        "We are not giving details about the results but rather an assessment of what the evaluation of Terminology Extraction Tools is: how was it done, what were the difficulties, which are the advantages and disadvantages of the adopted protocol, what are the limits and how should we proceed for future testing."
      ]
    },
    {
      "heading": "1 The ARC A3 Program",
      "text": [
        "ARC A3 is a project of the ILEC3 group coordinated and founded by AUF.",
        "It was started in 1995 in order to promote research in the field of terminology acquisition.",
        "The ARC A3, “Term and Semantic Relation Extraction from Corpora in French” project aim is to test software capabilities in term and semantic relation extraction from corpora in French.",
        "Systems submitted to this evaluation are designed by French and Canadian research institutions (National Scientific Research Center and Universities) and/or private businesses.",
        "These systems have been extensively described in our previous work (cf. Béguin, et al., 1997, 2000; Jouis et al., 1997; Mustafa El Hadi et al., 1996a, 1996b, 1997 & 1998;).",
        "The first phase of the project has been directed towards testing the systems on one corpus4 (trial run) and towards elaborating a workable protocol based on this experience.",
        "The first results were presented during the first conference of JST5 (cf. Béguin et al., 1997, 2000).",
        "This article reports on the second and final evaluation campaign."
      ]
    },
    {
      "heading": "2 ARC A3 Organization",
      "text": [
        "ARC A3 brings together four kinds of actors: a coordinator who plays an organizational role (schedule, quality control of corpora, data production, etc.",
        "), corpora providers; participants of the test and two scientific advisors.",
        "The action has been coordinated by the University of Lille 3.",
        "The organizing team in cooperation with the discussion group made up of representatives of each participating team and two scientific",
        "advisors are supposed to cooperate in defining a methodology for testing the systems."
      ]
    },
    {
      "heading": "2.1 Participating Systems",
      "text": [
        "The systems are designed by French and Canadian research institutions.",
        "There were ten registered participants at the beginning of the project and three withdrew later for a variety of reasons.",
        "The organizers then launched another call for participation in July 1999 and three more participants joined the project (two private enterprises (Xerox and Logos) and a public institution (the University of Grenoble).",
        "Logos and the University team later dropped out for reasons unrelated to the program.",
        "When the final campaign was launched in 2000 there were eight systems remaining under evaluation."
      ]
    },
    {
      "heading": "2.2 Overview of the Tested Tools",
      "text": [
        "Terminology plays a major role in information processing and management and in specialized communication.",
        "Its role has been enhanced by the spread of automation and by the availability of electronic corpora.",
        "These two factors have had a massive impact on many different applications: systematic terminology7 building, natural-language interface design, lexical units management for specific use in some sub",
        "languages and technical writing, thesaurus construction, translation and indexing as well as the recent growth of cross-language information retrieval (CLIR).",
        "If we focus on the tools, presented in our evaluation project, from the point of view of their functions and of the purposes for which they were designed), there are three categories: \"Term Extractors\", \"Classifying Tools\", and \"Semantic relations extraction tools\".",
        "As we already mentioned, these systems were extensively described in our previous publications."
      ]
    },
    {
      "heading": "2.2.1 Term Extractors (TE)",
      "text": [
        "We will briefly describe the basic idea underlying TE tools.",
        "Most of the extracting tools consider terms as noun phrases.",
        "Systems identify terms by using frequency, distribution and category-pattern matching (Daille et al.",
        "1995; Dagan, 1996; Lauriston, 1994).",
        "All lexical units contained in a given text are analyzed and matched to patterns (typical forms of terminological units) described in rules.",
        "More term extractors are accounted for elsewhere (L'Homme, 1996; Kageura et al., 1996; Dagan et al., 1994).",
        "Some of the systems described by these authors are tested in the framework of our valuation project (Acabit, Lexter, and Ana)."
      ]
    },
    {
      "heading": "2.2.2 Classifiers and Semantic Relation Extractors (SRE)",
      "text": [
        "Terminology resources are increasingly seen as structured data i.e. as a network of terms organized by relations.",
        "Pure alphabetical lists can hardly be used except for bilingual reference tools.",
        "The variety of tools, their functions and the different possible uses offered within the framework of ARC A3 shows this need.",
        "Consequently such lists of terms are quite difficult to evaluate except by specialists in the relevant fields which makes it a rather constraining process.",
        "Structuring terms by semantic relations or in classes is useful for the following applications: Index-making for on-line technical documentation; browsing; information access and retrieval; building thesaurus and ontologies for information systems.",
        "Many applications and extraction methods relevant to these tools have been described in the literature.",
        "The systems tested in the AUF framework are geared towards a variety of applications ranging from rough semantic relation extraction, through indexing, thesaurus construction to knowledge-based system modeling (see figure 2).",
        "Classifiers and semantic relation extractors are tested within the same framework as the one used for evaluating term extractors.",
        "The first category is characterized as classifying tools.",
        "Their role is to build classes of networks of terms linked to a major one.",
        "This category consists of statistical and/or connectionist models such as Conterm.",
        "It is the only classifier tested within the framework of this campaign.",
        "The second category includes semantic relation extractors which focus particularly on semantic relations (Iota, Loria and Seek-Java).",
        "A complete description of all the systems which were tested (main characteristics and purposes, description as far as approaches are concerned) is documented in previous work."
      ]
    },
    {
      "heading": "3 Evaluation paradigm",
      "text": [
        "Evaluation activities are a corollary of the quick development of NLP tools in general and of terminology extraction in particular.",
        "It thus became necessary to evaluate these tools on objectively based criteria in order to have a clear picture of the state-of-the-art, assess the needs in this sector and hence promote research in this specific field.",
        "Moreover, the principal aim of existing testing methods, as reported in the literature, is to come across software errors and then try to adapt them for a particular user environment.",
        "Evaluation paradigm is basically dependant upon two major steps: (i) Creation of textual data: raw or tagged corpora and test material.",
        "A corpus-based research is part of the infrastructure for the development of advanced language processing applications; (ii) Test and comparison of systems on a similar data (Cavazza, 1993; Adda et al., 2000)."
      ]
    },
    {
      "heading": "3.1 The ARC A3 Evaluation Approach",
      "text": [
        "The approach we adopted is a black-box qualitative approach8 The results are compared",
        "with the human performance of a task (either experts examining results or using reference lists or both).",
        "Moreover comparisons are made with other systems performing the same task.",
        "The results are finally calculated and translated in terms of traditional IR measures9.",
        "The conventional distinction between black-box and glass-box is the following: the former considers only system input-out-put relations without regard to the specific mechanisms by which the outputs were obtained while the latter examines the mechanisms linking input and output.",
        "(Sparck-Jones, 1996 p. 26; King, 1996; 1999, among many others).",
        "The qualitative evaluation measures as described by Sparck-Jones 1996, pp.",
        "61-122, are based on observation or interviewing and are broadly designed to obtain a more holistic, less reductive or fragmented view of the situation.",
        "It is moreover more naturalistic.",
        "This type of evaluation naturally fits an end-free style.",
        "In our case the quality of the results is evaluated by domain experts.",
        "We distinguish two types of experts: experts for the three applications tested (systematic terminology, translation and indexing); and experts in the two domains of corpora (biotechnology and pedagogy).",
        "Both quantitative and qualitative approaches are goal-oriented, that is focusing on discrepancies between performance results and initial system requirements.",
        "Sparck-Jones points out how the two types of measures are deeply interwoven although different in their nature: - Recall is a quantitative measure of system performance while - Declared Satisfaction is a qualitative one (i.e. such a measure is really qualitative even if the result of applying it to a set of users is a percentage figure).",
        "The qualitative approach in the evaluation process is the easiest one for end users.",
        "It means giving a value judgment on how the system globally works (Cavazza, 1993; Chaudiron, 2000).",
        "The dominant approach today is towards quantitative evaluations which are considered as more objective and reproducible than the qualitative approach (EAGLES-1 1996; ISLE 2001).",
        "The main attempt of these approaches is 9 We chose to accompany the qualitative approach (mainly based on manual evaluations) by a translation of the manual evaluations into numerical scales of values (see below for more details).",
        "to translate the concepts of relevance and quality into numerical data.",
        "Statistical approaches such as MUC 2 and TREC 3 are frequently used for this type of evaluation.",
        "(Chaudiron, 2000).",
        "Obviously this approach has its pros and cons.",
        "But it can be justified on the following basis: - Since most developers cannot provide us (as test organizers) with their systems, the only way was to send them the text corpora and let them provide us with the results.",
        "A glass-box evaluation would have required an examination of the systems by the organizers which would have been impossible except for Xerox’s TermFinder and Logos System’s Knowledge Discovery, two commercialized systems.",
        "- Even if this approach may be criticized on account of its subjective side, end-users like it because of its usefulness when comparing two or more systems which differ in all their parameter settings.",
        "(Chaudiron 2000; Cavazza 1993).",
        "- A black-box evaluation is more oriented towards system’s end-user when compared to a glass-box evaluation.",
        "For the latter the test will involve analyzing the system’s functioning by looking at its different components.",
        "Each component is evaluated separately in itself.",
        "Such an approach allows for spotting and understanding the causes of dysfunctional results.",
        "It is a long term process which requires access to the internal parts of the system and an understanding of the architecture and global strategy of the software.",
        "This is obviously a developer oriented approach and not an end-user one (Chaudiron 2000; Cavazza 1993).",
        "- In spite of its limited scope the evaluation protocol we adopted is used in more complicated NLP tools, such as MT tools.",
        "Evaluators examine the systems’ output without considering the differences between them (cf. L’Homme, 2001).",
        "Last Spring our team took part in a workshop organized by ISSCO (University of Geneva) where we and all the other participants adopted this approach."
      ]
    },
    {
      "heading": "3.2 Elements of the Evaluation Protocol of the 2000 Campaign 3.2.1 Evaluation Task",
      "text": [
        "The extraction of terms, of classes and of semantic relations was necessary to test the tools performance in the three following tasks: Systematic terminology (characterizing the tested corpora); (ii) Translation; (iii) Indexing.",
        "This means in practice: what is the relevance of terms, classes and semantic relations provided by the systems being tested?",
        "Do the terms, classes and semantic relations satisfy minimum requirements?",
        "Do we need to define a minimum level of terms, classes, semantic production?",
        "Are discrepancies meaningful?",
        "For example, it could be that most of the systems being tested are having qualitatively poor outputs, while only one or two produce worthwhile results.",
        "Within this perspective the idea was to submit the results to specialists.",
        "We distinguished for the purpose of this campaign two types of human expertise as we mentioned above."
      ]
    },
    {
      "heading": "3.2.2 Test material",
      "text": [
        "Evaluation data can normally be divided into two different categories (i) representative samples of the tested corpora (ii) test material, which, in our evaluation framework, is made up of both custom-designed lists and real life lists / thesaurus."
      ]
    },
    {
      "heading": "3.2.2.1 Corpus",
      "text": [
        "Two corpora were tested: Spirale10 and INRA11.",
        "We have chosen a sample representing 10% of each corpus: for Spirale n° 19 was chosen.",
        "As for INRA corpus, the providers of this corpus suggested 8 articles (603, 604, 607, 609, 631, 666, 732, 740)."
      ]
    },
    {
      "heading": "3.2.2.2 Reference Lists",
      "text": [
        "These lists are standard human professional results which can be used as performance exemplars or norms for comparison.",
        "This type of data is considered to be a gold standard (see SensEval, Kilgarrif 1998; ISLE 2001).",
        "For the INRA corpus the following lists have been created: For translation two lists were processed (i) a list created by a novice translator (ii) another one by a confirmed professional translator.",
        "For indexing: six lists were created both by professional and by non professional indexers.",
        "We are not developing these lists in this paper given the limited scope of this type of evaluation from an indexing point of view.",
        "Hence the limited interest of term extraction tools for human indexing.",
        "We will however comment on the terminology lists provided by the two corpus providers, INRA (Institut National pour la Recherche Agronomique i.e. National Institute for Agronomic Research), the Francis list of INIST12) and the translation lists.",
        "As far as INRA corpus is concerned: We think that our evaluation task could have given better results if the lists had been more representative of a systematic terminology activity.",
        "For the INRA corpora, for example, only 113 terms were chosen by the experts to represent their terminology.",
        "Our estimation is that, 113 terms only constitute a poor representation of an activity.",
        "It would have been a good idea to have specialists establish the lists of terms and to compare those to the systems’ output.",
        "Even if this work is time consuming it makes for a better evaluation of the systems’ productivity.",
        "As far as indexing is concerned the interest of these lists is quite limited and we think that a lot of time has been lost in drawing them up and even grooming them.",
        "From a general point of view the tools we have considered, especially term extraction ones, only have a limited interest for indexing contrary to other tools (semantic relation extractors) they have not been conceived for this purpose.",
        "This point of view is shared by their own designers.",
        "However, some of the semantic extraction tools are adapted for indexing among their other applications (Iota and Loria, for instance).",
        "As for Spirale corpus: Terminology (i) Thesaurus Mobis, (educational sciences section) (ii) Francis list (of the INIST, covering the complete volume on educational sciences section).",
        "Three lists for indexing: - Dictionnaire encyclopédique de l'éducation et de la formation 13.",
        "- CRDP list14 de Lille.",
        "- Bréhier list (PRCE in documentation )."
      ]
    },
    {
      "heading": "3.2.2.3 Unified Presentation Format",
      "text": [
        "The protocol we suggested was based on the previous evaluation sessions.",
        "The layout of some results could at times make the task of evaluation difficult.",
        "In some cases, good graphic presentation (conceptual graphs, etc.)",
        "could hide a poor term extraction and hence influence the evaluation.",
        "Conversely a system which has the capacity to extract relevant terms and semantic relations but whose layout is poor can influence the evaluation process.",
        "To prevent this, participants have been asked to adopt a unified format for their presentations for 2000 evaluation campaign."
      ]
    },
    {
      "heading": "3.2.2.4. Non-unified Tagging",
      "text": [
        "Given the fact that system designers have different processing possibilities, some of the systems use an independent tagger, others have an integrated one which is part and parcel of their system.",
        "The organizers decided to allow the participants their own choice in terms of tagging methods."
      ]
    },
    {
      "heading": "3.2.2.5. Evaluation Measures",
      "text": [
        "Given the three tasks to be performed (indexing, systematic terminology and translation), the usual notions of recall and precision can be used to evaluate the quality of results when matched with a manually-produced reference list.",
        "Performance failure at this level can be interpreted in terms of silence and noise (see below)."
      ]
    },
    {
      "heading": "3.2.2.6. Automatic Matching by EvalTerm",
      "text": [
        "If the qualitative approach offers the easiest form of systems evaluation it nevertheless retains two major drawbacks: (i) it makes up for a very boring job when there are too many results (ii) judgments can easily be slanted by the subjective approach of the expert.",
        "Our protocol being based on the qualitative black-box principle where parameters are hard to quantify we chose to apply traditional IR measures, recall and precision which normally accompany qualitative evaluations:",
        "Since the manual matching of lists proved to be long and complicated due to the huge size of the 15 Or their equivalents in terms of noise and silence: Silence = 1 – Recall, Noise = 1 – Precision processed data and to a variety of other inconveniences, we chose to automatically calculate these measures.",
        "We then decided to duplicate the manual evaluation with its conversion into numerical scales of values.",
        "For this purpose we developed a program which matches the results provided by the software with the reference lists16 The program compares two lists: L1 represents the results given by a software and list L2 is a reference list proposed by an expert 17.",
        "The program output consists of two files: file (a) which contains the elements of L2 found in L1 (the relevant terms which the software was able to find).",
        "And file (b) which contains some elements of L2 which have not been identified and consequently were not mentioned in L1 (the correct terms not found by the software).",
        "Through a simple subtraction we can get a file containing the noisy terms of each software.",
        "In our automatic matching we have not included any linguistic treatment for fear of introducing new parameters which would influence the results.",
        "Right from the beginning we have noticed that over-productive systems such as Ana or Term Finder are difficult to compare with reference lists because the noise rate becomes irrelevant."
      ]
    },
    {
      "heading": "4 An Overview of the Results",
      "text": []
    },
    {
      "heading": "4.1 Term Extraction on the two Corpora",
      "text": [
        "We will now comment globally on how the term extractors performed when run on the two corpora for the three different tasks (indexing, systematic terminology and translation): First, automatic matching concurred with human experience which notices that the systems produce many “ noisy ” terms while on the contrary there are many terms not included in the reference lists but which the experts considered as relevant for systematic terminology.",
        "Hence the interest of some of these “ noisy ” terms for enriching and updating reference lists and terminology data bases.",
        "Matching the results of the different systems has",
        "showed a great similarity between Lexter and Acabit.",
        "As for indexing, if the systems could generally provide relevant and effective help for terminology (systematic terminology, and translation) their contribution to indexing is less obvious.",
        "Indexing supposes other mental operations than those needed for terminology construction and simply picking out candidate-descriptors is not enough to supply a reliable form of indexing.",
        "The three core criteria of good indexing are: reliability, selectivity and exhaustiveness.",
        "The indexer must hold a balance between exhaustiveness and selectivity.",
        "Having too many terms leads to noise and too few to silence.",
        "It is on this criteria of selectivity that human processing varies.",
        "Softwares based on term extraction offer a large number of potential candidate terms, connecting them with more or less precise criteria of relevance, mostly of a statistical nature.",
        "At this level of processing the indexer has recourse to authorized lists and thesauri i.e. he or she refers to the work of terminologists in structuring the field and attributing a label to each and every concept.",
        "The systems which we tried to assess are not yet likely to provide a very effective help to indexing since the results are over-productive in view of the needs."
      ]
    },
    {
      "heading": "5 The Classifier and the Semantic Relation",
      "text": []
    },
    {
      "heading": "Extraction (SRE) Tools",
      "text": [
        "The protocol we adopted specifies the evaluation of semantic relation and class validity, coherence and comprehensiveness on all of the three tasks (i.e. semantic relations examined from the point of view of systematic terminology, translation and indexing).",
        "The classes and semantic relations extracted were subject to a comparison with the human performance of these tasks (experts and reference lists), plus a comparison with other systems performing the same task.",
        "This qualitative evaluation is measured by the traditional IR performance measures (silence, noise, recall and precision).",
        "The first thing we can remark on is that it is very difficult to fulfill the evaluation within our proposed terms of reference.",
        "We are presenting hereunder the reasons limiting the scope of our protocol when applied to SRE results."
      ]
    },
    {
      "heading": "5.1 An Overview of the Results of SRE on the Two Corpora",
      "text": [
        "What we observed is that these tools are too different to allow a useful comparison for the following reasons: - SRE extract different types of relations and hence are incomparable.",
        "- This difference is linked to the different forms of semantic model implementation.",
        "Conversely some extractors are based on models that will not allow the type of relations required for the three evaluation tasks.",
        "- SRE are designed for different functions and have different objectives or carry out different tasks.",
        "- These differences are reflected in the type of output or results.",
        "- Another problem came from the fact that INRA could not provide us with a structured list corresponding to the eight selected texts.",
        "Even if this list had been available, comparing it to the results would have been of limited interest only.",
        "The remaining solution was to submit the results to a field specialist.",
        "- Difficulties in interpreting the non-labeled Semantic Relations.",
        "Fig.",
        "Two shows these differences:",
        "by with Relations on the one hand and a triplet frequency between terms of argument-relation-Terminology Classes of argument on the other networks terms assembled in a relational database - Moreover, it is difficult or even impossible to measure silence using a protocol based on IR systems performance measure.",
        "• Without a prior knowledge of the missing possible relations one cannot account for the silence measure.",
        "• To account for noise, a thorough knowledge of both the semantic model and the field of knowledge is required.",
        "• These observation are also valid for recall and precision measures.",
        "We can thus say for the time being that SRE cannot be assessed by the protocol since their results cannot be matched.",
        "The field specialist18 gave the following account: “It is essential to have an interface to manipulate and interpret the relations.",
        "Everything seemed somewhat inconclusive.",
        "At times the relation “fits well”, at times it does not at all.",
        "Results are not always relevant and it is difficult to trust this type of analysis on its own if one is not at the same time be conversant with the domain, since some of the relations can be wrong.",
        "For Iota, concept extraction seems generally quite relevant.",
        "However one has to wonder about the relevance of a number of extracted concepts which are not at all relevant to the field.",
        "How did these non-specific concepts get extracted more easily than others ?",
        "As for the table on Conceptual Semantic Dependence19 it is hard to draw any conclusions from it since it offers only one semantic label for any relation.",
        "The Iota approach is more global than the Seek-Java one since the relations are based on the whole document and not only at the level of one sentence.",
        "These two softwares are thus difficult to compare since their purpose is not the same”."
      ]
    },
    {
      "heading": "5.2 Conterm, the Classifier: an ad hoc Evaluation",
      "text": [
        "Given the difficulties we listed above and the fact that it was impossible to compare Conterm with other systems performing the same task.",
        "The only possible evaluation for Conterm would have been a progress evaluation for this sole classifier of the campaign 20.",
        "This problem shows again the limits of our Protocol.",
        "The Conterm lists were matched to an automatically produced"
      ]
    },
    {
      "heading": "18 Patricia Volland-Neil, from INRA-Tours",
      "text": [
        "19 The evaluator is referring to the tables accompanying the results provided by the system’s designer.",
        "20 The protocol is not suitable for its evaluation.",
        "After the withdrawal of another participant who had also presented a classifier, only this one remained.",
        "untagged list of terms which corresponds to the eight texts of the INRA corpus.",
        "The most important element in its evaluation is not that we matched its results with a tagged list but that the results had been matched with indexers’ and/or experts lists and that we could observe the correspondence between Conterm’s output and the lists.",
        "It does not mean that Conterm is good for indexing but that the classes suggested by this tool embody conceptual attributes which are close to the logic underlying the human selection of candidate-terms suitable for indexing, namely its rich lexico-semantic network."
      ]
    },
    {
      "heading": "6 Concluding Remarks",
      "text": [
        "- This evaluating action provided us with an awareness of the State-of-the-art in the field of terminology acquisition tools.",
        "It also allowed us to test evaluation paradigms, demonstrating how difficult it was to apply a single evaluation protocol to a variety of systems operating along different lines.",
        "- The discussions among participants aiming at the creation of a testing protocol resulted in the definition of an evaluation procedure and in an assessment of their relative merits.",
        "The comparative study of the systems’ output also enabled a better understanding of the performances of the wide range of techniques involved.",
        "As by-products of the project two corpora can be used in further evaluation campaigns and a set of material tests (real-life and constructed or specifically tailored one that can be shared during future evaluations).",
        "- The evaluation results can be used predictively for system design, development or modification The limits of our evaluation approach can be sketched in the following manner: - If the adopted protocol based upon reference list can be applicable to the two tasks (translation and terminology) it is hardly applicable to indexing tasks.",
        "- It is not adequate to account neither for the classifiers nor for the SRE.",
        "- Several questions remain unanswered: a) first, is it possible to fully automate evaluation procedures?",
        "Then is it possible to abandon test material, such as reference lists or other type of human-made data, which are considered as a kind of gold standard reusable for other evaluation campaigns?",
        "(see our recent experience in MT evaluation workshop, April 200121.",
        "b) As far as semantic relation extraction is concerned, is it possible to automate SRE valuation procedure in the way Grefensttete (1994) does?",
        "7 Future Directions 1.",
        "Exploiting Results: the Campaign’s Side Benefits:",
        "Full treatment of the Spirale corpus will allow the creation of an index of all the reviews past numbers, which fulfills the moral contract made with its Editorial Board in exchange for getting the corpus free of charge.",
        "In addition, these results can help broaden the terminological repository for the education sciences, especially in drawing up the Francis Thesaurus which covers all education sciences.",
        "2.",
        "Towards Trans-Systemic Integration: The output of the systems are divergent but can in",
        "some cases be complementary.",
        "In fact the preliminary results drawn from the first evaluation in 1997 (cf. Béguin et al.",
        "2000) have led us to consider the feasibility of trans-systemic integration for strengthening their automatic terms identification capabilities.",
        "The idea is to combine two or three different types of systems in order to specify various integrated production processes.",
        "Systems could 21 “Setting a methodology for Machine Translation evaluation”.",
        "The context: evaluation of a translation made by an MT System on the following source text: INRA corpus text N°604 “ corpus biotechnologique sur la reproduction chez l’animal ” Source language: French - Target language: English.",
        "We carried out some manual testing but with the objective of setting a rough methodology that might be irrelevant for translating huge size corpora.",
        "The tool we used was a non interactive French / English MT System with a basic French/English dictionary that does not include any specific terminology.",
        "We had two indexes (a French index and an English index of domain specific expressions, but they are not aligned).",
        "They have been provided by the INRA and considered as gold standard.",
        "We used the indexes to create a specific dictionary in order to feed the MT systems with this specific lexical data.",
        "The next step is to assess the impact of specific terminology when integrated to an MT system by comparing the results of the two translations we get: with and without specific terminology.",
        "increasingly be seen as parts of these integrated production processes.",
        "3.",
        "Towards User-Oriented Evaluations: in the light of the results obtained in this campaign the most suitable type of evaluation would be a user-oriented one.",
        "Other types of approaches22 can be designed, such as adequacy evaluation 23 which can to some extent be adopted for our case but we have to define a more strict user profile.",
        "4.",
        "Towards developing interfaces for validating the results: even if we opted for a unified presentation format for the reasons mentioned in section 3.2.2.3, we however think it is essential for future campaign organizers to have an interface to manipulate and interpret the results (validating term, relations and classes).",
        "This type of interface can dramatically facilitate the interaction with the evaluators and the end-user of these tools.",
        "5.",
        "Designing tools for generic bilingual production, allowing ad hoc extractions through ad hoc interfaces.",
        "6.",
        "Capability to share resources in the future (test material such as gold standard lists, real-life and/or constructed ones).",
        "7.",
        "Developing automatic evaluation tools such",
        "as Evalterm which can be reused in similar future evaluations.",
        "8.",
        "Hypothesis are still to be tested for semantic relations extraction: results of the various semantic extractors will be of different quality depending on the type and nature of corpora (domain and genre) chosen (cf. also Condamines et al.",
        "98; Davidson et al. 98, among many others)."
      ]
    },
    {
      "heading": "8 Acknowledgements",
      "text": [
        "The authors gratefully acknowledge the financial assistance provided by the AUF (Association des Universités Francophones) in funding the general research project within which this paper was written.",
        "22 Spark-Jones et al.",
        "1996; King 1999, among many others, identified more three types of evaluation processes: the progress evaluation, the adequacy evaluation and the diagnostic evaluation.",
        "The first and second types are used for comparative benchmarking.",
        "23 Adequacy evaluation aims at finding out whether a system or product is adequate to someone’s needs.",
        "This type is typically done when thinking of acquiring a system."
      ]
    },
    {
      "heading": "9. References",
      "text": []
    }
  ]
}
