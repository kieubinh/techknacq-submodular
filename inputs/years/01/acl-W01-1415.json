{
  "info": {
    "authors": [
      "Masaki Murata",
      "Kiyotaka Uchimoto",
      "Qing Ma",
      "Hitoshi Isahara"
    ],
    "book": "Workshop on Data-Driven Methods in Machine Translation",
    "id": "acl-W01-1415",
    "title": "Using a Support-Vector Machine for Japanese-To-English Translation of Tense, Aspect, And Modality",
    "url": "https://aclweb.org/anthology/W01-1415",
    "year": 2001
  },
  "references": [
    "acl-A97-1015",
    "acl-C00-1082",
    "acl-W00-0730"
  ],
  "sections": [
    {
      "text": [
        "g`0 !-'ZtItJbJbK,A.lf`3a3h)1;4 O1;LbN.",
        "This child always talks back to me, and this <v>is</v> why I hate him.",
        "d � � Jb Jb � � � � 3 i' P It � � � h) � VI <v>did not think</v> he was so timid.",
        "c JbJb'ftL <ZIttt'Oit)�bNIt-fi'.",
        "Such a busy man as he <v>cannot have</v> any spare time."
      ]
    },
    {
      "heading": "Abstract",
      "text": [
        "This paper describes experiments carried out using a variety of machine-learning methods, including the k-nearest neighborhood method that was used in a previous study, for the translation of tense, aspect, and modality.",
        "It was found that the support-vector machine method was the most precise of all the methods tested."
      ]
    },
    {
      "heading": "1 Introduction",
      "text": [
        "Tense, aspect, and modality are known to cause problems in machine translation.",
        "In traditional approaches tense, aspect, and modality have been translated using manually constructed heuristic rules.",
        "Recently, however, corpus-based approaches such as the example-based method (k-nearest neighborhood method) have also been used (Murata et al., 1999).",
        "For our study, we carried out experiments on the translation of tense, aspect, and modality by using a variety of machine-learning methods, in addition to the k-nearest neighborhood method, and then determined which method was the most precise.",
        "In our previous research, in which we studied the utilization of the k-nearest neighborhood method, only the strings at the ends of sentences were used to translate tense, aspect, and modality.",
        "In this study, however, we used all of the morphemes from each of the sentences as information, as well as used the strings at the ends of the sentences.",
        "In connection with our approach, we would like to emphasize the following points:",
        "• We obtained better translation of tense, aspect, and modality by using a support-vector machine method than we could by using the k-nearest neighborhood method that we used in our previous study (Murata et al., 1999).",
        "• In our previous study (Murata et al., 1999) we only used the strings at the ends of sentences to translate tense, aspect, and modality.",
        "Here, however, we used all of the morphemes in each of the sentences as information, in addition to the strings at the ends of the sentences.",
        "Using a statistical test, we were able to confirm that adding the morpheme information from each of the sentences was significantly effective in improving the precision of the translations."
      ]
    },
    {
      "heading": "2 Task Descriptions",
      "text": [
        "For this study we used the modality corpus described in one of our previous papers (Murata et al., 2001).",
        "Part of this modelity corpus is shown in Figure 1.",
        "It consists of a Japanese-English bilingual corpus, and the main verb phrase in each English sentence is tagged with <v>.",
        "The symbols placed at the beginning of each Japanese sentence, such as \"c\" and",
        "\"d,\" indicate categories of tense, aspect, and modality for the sentence.",
        "(For example, \"c\" and \"d\" indicate \"can\" and past tense, respec",
        "The following categories were used for tense, aspect, and modality.",
        "1.",
        "All combinations of each auxiliary verb (\"be able to,\" \"be going to,\" \"can,\" \"have to,\" \"had better,\" \"may,\" \"must,\" \"need,\" \"ought,\" \"shall,\" \"used to,\" and \"will') and forms for {present tense, past tense}, {progressive, non-progressive}, {perfect, non-perfect} (215 categories) 2.",
        "Imperative mood (1 category)",
        "These categories of tense, aspect, and modality are defined on the basis of the surface expressions of the English sentences.",
        "Therefore, if we are able to determine the correct category from a Japanese sentence, we should also be able to translate the Japanese tense, aspect, and modality into English.",
        "In this study, only the tags indicating the categories of tense, aspect, and modality and the Japanese sentences were used.",
        "The following two types of corpora were used to construct the modality corpus.",
        "• Example sentences in the Kodansha Japanese-English dictionary (39,660 sentences, 46 categories) • White papers (5,805 sentences, 30 categories)",
        "The occurrence rates of major categories are shown in Table 1.",
        "As can be seen in the table, the present tense occurs most frequently."
      ]
    },
    {
      "heading": "3 Machine-Learning Methods",
      "text": [
        "We used the following four machine-learning method for our study.'",
        "'Although there are also decision-tree learning methods such as C4.5, we did not use them for the",
        "• k-nearest neighborhood method • decision-list method • maximum-entropy method • support-vector machine method",
        "In this next section, we will be explaining each of these machine-learning methods."
      ]
    },
    {
      "heading": "3.1 k-nearest neighborhood method",
      "text": [
        "The domain of machine translation includes a method called an example-based method.",
        "In this method, the example most similar to the input sentence is searched for, and the category of the input sentence is chosen based on the example.",
        "However, this method only uses one example, so it is weak with respect to noise (i.e. errors in the corpus or other exceptional phenomenon).",
        "The k-nearest neighborhood method prevents this problem by using the most similar examples (a total of k examples) instead of using only the most similar example.",
        "The category is chosen on the basis of \"voting\"2 on k examples.",
        "Since this method uses multiple examples, it is capable of providing a stable solution even if a corpus includes noise.",
        "In the k-nearest neighborhood method, since it is necessary to collect similar examples, it is also necessary to define the similarity between each pair of examples.",
        "The definition of similarity used in this paper is discussed in the section on features (Section 4).",
        "When there is an example that has the same similarity as the selected k examples, that example is also used in the \"voting.\""
      ]
    },
    {
      "heading": "3.2 Decision-List Method",
      "text": [
        "In this method, the probability of each category is calculated using one feature fj (E F,1 < j < k), and the category with the highest probability is judged to be the correct category.",
        "The probability that produces following two reasons.",
        "First, a decision-tree learning method performs worse than other methods for several tasks (Murata et al., 2000; Taira and Haruno, 2000).",
        "Second, the number of attributes used in this study was too large, and the performance of C4.5 would become evne worse if the number of attributes was decreased so that it could be used.",
        "2 \"Voting\" means a decision made by the majority."
      ]
    },
    {
      "heading": "Small Margin Large Margin",
      "text": [
        "where x is the context (a set of features) of an input example, xi and gi (i = 1, ...,1, gi E {1, – 1}) indicate the context of the training data and its category, and the function sgn is",
        "Each ai (i = 1, 2...) is fixed as the value of ai when the value of L(a) in Equation (7) is at its maximum under the conditions of Equa",
        "Although the function K is called a kernel function and various types of kernel functions are used, we used the following polynomial function:",
        "C and d are constants set by experimentation, and in this paper, C is fixed as 1 for all of the experiments.",
        "Two values, d = 1 and d = 2, are used for d. A set of xi that satisfies ai > 0 is called a support vector, and the portion performing the sum in Equation (5) is calculated using only examples that are support vectors."
      ]
    },
    {
      "heading": "Support-vector machine methods are capa",
      "text": [
        "ble of handling data consisting of two categories.",
        "In general, data consisting of more than two categories is handled using the pairwise method (Kudoh and Matsumoto, 2000).",
        "In this method, for data consisting of N categories, pairs of two different categories (N(N1)/2 pairs) are constructed.",
        "The better category is determined using a 2-category classifier.",
        "In this paper, a support-vector machine4 was used as the 2-category classifier.",
        "Finally, the correct category is determined on the basis of \"voting\" on the N(N-1)/2 pairs analyzed by the 2-category classifier.",
        "The support-vector machine method used in this paper was performed by combining the support-vector machine method and the pairwise method described above.",
        "4 Features (information used in classification)",
        "Although we have already explained the four machine-learning methods in the previous section, we must also define the features (information used in classification).",
        "In this section, we will explain these features.",
        "As mentioned in Section 2, when a Japanese sentence is input, we then output the category of the tense, aspect, and modality.",
        "Therefore, features are extracted from the input Japanese sentence.",
        "We tested the following three kinds of feature sets in our experiments.",
        "• Feature-set 1",
        "the sentences.",
        "e.g. \"Lto V,\" (do not), \" (today).",
        "(The number of features is 230,134 in the Kodansha Japanese-English dictionary and 25,958 in the white papers.)",
        "• Feature-set 2",
        "e.g. \"L to V,� (do not), \"L to h` - � \" (did not).",
        "(The number of features is 199,199 in the Kodansha Japanese-English dictionary and 16,610 in the white papers.)",
        "• Feature-set 3",
        "The Japanese morphological analyzer JU-MAN (Kurohashi and Nagao, 1998) was used to divide the input sentences into morphemes.",
        "Feature-set 1 is the combination of Feature-sets 2 and 3.",
        "Feature-set 2 was constructed based on our previous research (Murata et al., 1999).",
        "In Japanese sentences the tense, aspect, and modality are often indicated by the verbs at the ends of sentences.",
        "Therefore, in our previous study, the strings at the ends of the sentences were used as features.",
        "Feature-set 3 was constructed by taking into consideration the fact that adverbs such as \"tomorrow\" and \"yesterday\" can also indicate tense, aspect, and modality, and must therefore be used.",
        "Defining the feature sets is sufficient for enabling the use of decision-list, maximum-entropy, and support-vector machine methods.",
        "For the k-nearest neighborhood method, however, it is also necessary to define the similarities between examples, in addition to the feature sets.",
        "For Feature-sets 1 and 3, which use all of the morphemes from the entire input sentence, it is difficult to define the similarity.",
        "Therefore, we decided to only use Feature-set 2 for the k-nearest neighborhood method.",
        "In terms of defining similarity for Feature-set 2, when two examples match for x-gram characters, the value of the similarity between them is x."
      ]
    },
    {
      "heading": "5 Experiments",
      "text": [
        "This section describes our experiments on the translation of tense, aspect, and modality that were conducted using the machine-learning methods described in Section 3 with the feature sets described in Section 4 for the tasks described in Section 2.",
        "First, we conducted experiments using the example sentences in the Kodansha Japanese-English dictionary.",
        "The results for these experiments are shown in Table 2.",
        "We conducted two types of experiments, closed and open6.",
        "The open experiments were performed using 10-fold cross-validation.",
        "In the table, the values in parentheses indicate the precisions for the closed experiments and the values outside the parentheses are for the precisions for the open experiments.",
        "(We used the baseline method for comparison.",
        "This method is used to judge cases in which the end of the sentence is \"k , \" which is a Japanese particle used for the past tense, as the past tense, and judges other cases to be the present tense.)",
        "We were able to learn the following from the experimental results.",
        "• The cases of k > 1 performed better than the case of k = 1, which is the example-based method.",
        "We thus found that the k-nearest neighborhood method was more precise than the example-based method.",
        "(This had also been confirmed in our previous research (Murata et al., 1999).)",
        "• The decision-list method had almost the same precisions as the k-nearest neigh-'30osed means experiments that uses the tested data when learning.",
        "Open means experiments that do not use the tested data when learning.",
        "borhood method when Feature-set 2 was used.",
        "• The maximum-entropy method was more precise than both the k-nearest neighborhood and decision-list methods.",
        "• The support-vector machine method obtained higher precisions than all the other methods.",
        "• In terms of comparing feature sets, the maximum-entropy and decision-list methods obtained their highest precisions when Feature-set 2 was used.",
        "They produced lower precisions when morpheme information was added, as in Feature-set 1.",
        "This would be because the number of unnecessary features increases as the total number of features increases.",
        "• In terms of comparing feature sets for the support-vector machine method,",
        "Feature-set 1 obtained the highest precisions.",
        "This indicates that adding the morpheme information was effective in improving precision.",
        "Since adding the morpheme information produced lower precisions for the other methods, we assume that the support-vector machine method is more capable of eliminating unnecessary features and selecting effective features than the other methods.",
        "We can provide the following explanations for these results based on the theoretical aspects of each of the methods.",
        "Because the decision-list method chooses the category by using only one feature, it is likely that only one unnecessary feature will be used, and that the precisions are likely to decrease when there are many unnecessary features.",
        "Because the maximum-entropy method always uses almost all of the features, the precisions decrease when there are many unnecessary features.",
        "However, because the support-vector machine includes a function that eliminates examples, such that it only uses examples that are support vectors and does not use any other examples, it eliminates many unnecessary features along with these examples.",
        "The precisions are thus unlikely to decrease even if there are many unnecessary features.",
        "• The method with the higest precision among all the methods was the support",
        "vector machine method using d = 1 and Feature-set 1.",
        "To confirm that using Feature-set 1 was better than using Feature-set 2, (in other words, to confirm that adding the morpheme information was effective) we conducted a sign test.",
        "This was done for the case of d = 1, which produced better results than d = 2.",
        "Among all of the 39,660 examples, the number for which the category was chosen incorrectly with Feature-set 1 and correctly with Feature-set 2 was 648.",
        "For the opposite case (chosen incorrectly with Feature-set 2 and correctly with Feature-set 1), the number was 427.",
        "We performed the sign test by using this statistical data and obtained results showing that a significant difference existed at a significance level of 1%.",
        "We can thus be almost completely sure that adding the morpheme information was effective.",
        "Next, we examined which features were effective among all the features using the morpheme information.",
        "This was done by examining the features that appeared relatively frequently among the 648 examples for which the category was chosen incorrectly with Feature-set 1 and correctly with Feature-set 2.",
        "We used a binomial test to choose an example whose occurrence rate among the 648 ex",
        "amples was significantly larger than among all the examples at a significant level of 1% as a relatively frequently appearing example.",
        "The 20 most frequently occurring features are listed in Table 3.",
        "As shown in the table, we were able to obtain features that are thought to be effective in determining tense, aspect, and modality, such as \"t -) \" (already), \"I ☎\" (recently), \"k ✞ -) \" (will), \"t k \" (yet), \" ✌✎ ✑ bjf\" (if not), \"t L✗ -) \" (let✚s) and \"A ✢\" (tomorrow), and we believe that such features improved precisions.",
        "Next, we carried out experiments using the white papers.",
        "These experiments were performed using the support-vector machine method that produced good precisions for the Kodansha data.",
        "The open precisions were calculated using 10-fold cross-validation in these experiments as well.",
        "The experimental results are shown in Table 4.",
        "We learned the following from the results.",
        "• The highest precision for the white paper data was 64.67%.",
        "• Feature-set 1 produced higher precisions than Feature-set 2.",
        "Moreover, Feature-set 3 also produced higher precisions than Feature-set 2.",
        "These results again confirmed that adding the morpheme information for each of the sentences was effective in improving precisions.",
        "We next performed experiments in which different-domain data was used as training data, such that the Kodansha data was used as the training data and the white paper data was used as the test data.✣ We then examined how the precisions changed under these conditions.",
        "These experiments were performed using support-vector machine methods with d=1 or d=2, which both obtained good precisions.",
        "When the training data and the test data overlapped, 10-fold cross-validation was used for the overlapping part.",
        "The experimental results are shown in Table 5.",
        "We learned the following from these results.",
        "• When we used different-domain data as",
        "training data, the precisions greatly decreased.",
        "When the Kodansha data was analyzed using the White paper data as training data or the white paper data was analyzed using the Kodansha data as training data, the precisions decreased about 15% (82.48% ✥ 65.31% or 64.67% ✥ 49.53%).",
        "We thus found that using same-domain data is more effective in terms of precision.",
        "It is difficult to construct a system adapted for different-domain data with a method that uses handwritten rules.",
        "However, for methods using machine-learning, such as those described in this paper, since it is easy to change the training data to different-domain data and then have the data learned again, it is ✧Sekine had carried out domain-dependent★ domain-independent experiments on parsing (Sekine, 1997).",
        "easy to construct a system adapted for different-domain data.",
        "• When both the Kodansha and the white paper data were used as training data, the precisions were almost the same or slightly decreased.",
        "We thus found increasing the size of training data is not always better and adding different-domain data is not effective."
      ]
    },
    {
      "heading": "6 Conclusion",
      "text": [
        "Tense, aspect, and modality are known to present difficult problems in machine translation.",
        "In traditional approaches, tense, aspect, and modality have been translated using manually constructed heuristic rules.",
        "Recently, however, corpus-based approaches such as the example-based method (k-nearest neighborhood method) have also been applied (Murata et al., 1999).",
        "We carried out experiments on the translation of tense, aspect, and modality by using a variety of machine-learning methods, as well as the k-nearest neighborhood method, and we determined which method was the most precise.",
        "In our previous research, in which we used the k-nearest neighborhood method, only the strings at the ends of sentences were used to translate tense, aspect, and modality.",
        "However, in this study we used all of the morphemes in each of the sentences as information, as well as the strings at the ends of each of the sentences.",
        "The support-vector machine method was found to produce the highest precisions of all the methods we tested.",
        "We were also able to obtained better translations of tense, aspect and modality than we could by using the k-nearest neighborhood method.",
        "Furthermore, we used a statistical test to confirm that adding the morpheme information for the entire sentence, which was not used in our previous study, was effective in improving precision.",
        "We also carried out experiments using a different-domain corpus.",
        "In these experiments, we confirmed that using a different-domain corpus as the training data produced very low precisions, and that we must construct a system for translating the tense, aspect, and modality for each domain.",
        "This also indicates that approaches using machine-learning methods, such as those described in this paper, are appropriate because it would be too difficult to construct systems adapted for different domains by hand."
      ]
    }
  ]
}
