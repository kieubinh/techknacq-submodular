{
  "info": {
    "authors": [
      "Hyun Ah Lee",
      "Gilchang Kim"
    ],
    "book": "International Conference on Computational Linguistics",
    "id": "acl-C02-1046",
    "title": "Translation Selection Through Source Word Sense Disambiguation and Target Word Selection",
    "url": "https://aclweb.org/anthology/C02-1046",
    "year": 2002
  },
  "references": [
    "acl-C00-2094",
    "acl-J90-2002",
    "acl-J94-4003",
    "acl-J95-4004",
    "acl-P97-1007",
    "acl-W01-0504",
    "acl-W99-0707"
  ],
  "sections": [
    {
      "heading": "Abstract",
      "text": [
        "A word has many senses, and each sense can be mapped into many target words.",
        "Therefore, to select the appropriate translation with a correct sense, the sense of a source word should be disambiguated before selecting a target word.",
        "Based on this observation, we propose a hybrid method for translation selection that combines disambiguation of a source word sense and selection of a target word.",
        "Knowledge for translation selection is extracted from a bilingual dictionary and target language corpora.",
        "Dividing translation selection into the two sub-problems, we can make knowledge acquisition straightforward and select more appropriate target words."
      ]
    },
    {
      "heading": "1 Introduction",
      "text": [
        "In machine translation, translation selection is a process that selects an appropriate target language word corresponding to a word in a source language.",
        "Like other problems in natural language processing, knowledge acquisition is crucial for translation selection.",
        "Therefore, many researchers have endeavored to extract knowledge from existing resources.",
        "As masses of language resources become available, statistical methods have been attempted for translation selection and shown practical results.",
        "Some of the approaches have used a bilingual corpus as a knowledge source based on the idea of Brown et al.",
        "(1990), but they are not preferred in general since a bilingual corpus is hard to come by.",
        "Though some latest approaches have exploited word co-occurrence that is extracted from a monolingual corpus in a target language (Dagan and Itai, 1994; Prescher et al., 2000; Koehn and Knight, 2001), those methods often fail in selecting appropriate words because they do not consider sense ambiguity of a target word.",
        "In a bilingual dictionary, senses of a word are classified into several sense divisions and also its translations are grouped by each sense division.",
        "Therefore, when one looks up the translation of a word in a dictionary, she/he ought to resolve the sense of a word in a source language sentence, and then choose a target word among translations corresponding to the sense.",
        "In this paper, the fact that a word has many senses and each sense can be mapped into many target words (Lee et al., 1999) is referred to as the `word-to-sense and sense-to-word' relationship, based on which we propose a hybrid method for translation selection.",
        "In our method, translation selection is taken as the combined problem of sense disambiguation of a source language word and selection of a target language word.",
        "To disambiguate the sense of a source word, we employ both a dictionary based method and a target word co-occurrence based method.",
        "In order to select a target word, the co-occurrence based method is also used.",
        "We introduce three measures for translation selection: sense preference, sense probability and word probability.",
        "In a bilingual dictionary, example sentences are listed for each sense division of a source word.",
        "The similarity between those examples and an input sentence can serve as a measure for sense disambiguation, which we define as sense preference.",
        "In the bilingual dictionary, target words are also recorded for each sense division.",
        "Since the set of those words can model each sense, we can calculate the probability of the sense by applying the co-occurrence based method to the set of words.",
        "We define the estimated probability as sense probability, which is taken for the other measure of sense disambiguation.",
        "Using co-occurrence, the probability of selecting a word from the set of trans",
        "lations can be calculated.",
        "We define it as word probability, which is a measure for word selection.",
        "Merging sense preference, sense probability and word probability, we compute preference for each translation, and then choose a target word with the highest translation preference as a translation.",
        "2 Translation Selection based on `word-to-sense and sense-to-word'",
        "The `word-to-sense and sense-to-word' relationship means that a word in a source language could have multiple senses, each of which might be mapped into various words in a target language.",
        "As shown in examples below, a Korean verb `meok-da' has many senses (work, deaf, eat, etc.).",
        "Also `kkae-da' has three senses (break, hatch, wake), among which the break sense of `kkae-da' is mapped into multiple words such as `break', `smash' and `crack'.",
        "In that case, if `hatch' is selected as a translation of `kkae-da' in a sentence jeobsi-reul kkae-da', the translation must be wrong because the sense of `kkae-da' in the sentence is break rather than hatch.",
        "In contrast, any word of the break sense of `kkae-da' forms a well-translated sentence.",
        "However, selecting a correct sense does not always guarantee a correct translation.",
        "If the sense of `meok-da' in jeomsim-eul meok-da' is correctly disambiguated as eat but an inappropriate target word is selected, an improper or unnatural translation will be produced like `eat a lunch'.",
        "Therefore, in order to get a correct translation, such a target word must be selected that has the right sense of a source word and forms a proper target language sentence.",
        "Previous approaches on translation selection usually try to translate a source word directly into a target word without considering the sense.",
        "Thus, they increase the complexity of the problem and suf",
        "fer from the problem of knowledge acquisition and incorrect selection of translation.",
        "In this paper, we propose a method for translation selection that reflects `word-to-sense and sense-to-word' relationship.",
        "We divide the problem of translation selection into sense disambiguation of a source word and selection of a target word.",
        "Figure 1 shows our process of selecting translation.",
        "We introduce three measures for translation selection: sense preference (80 and sense probability (sp) for sense disambiguation, and word probability (wp) for word selection.",
        "Figure 2 shows a part of an English English-Korean Dictionary (EssEEK, 1995)1.",
        "As shown in the figure, example sentences and definition sentences are listed for each sense of a source word.",
        "In the figure, example sentences of the destroy sense of `break' consist of words such as `cup', `piece', and `thread', and those for the violate sense consist of words such as `promise' and `contract', which can function as indicators for the sense of `break'.",
        "We calculate sense preference of a word for each sense by estimating similarity between words in an input sentence and words in example and definition sentences.",
        "Each sense of a source word can be mapped into a set of translations.",
        "As shown in the example, the break sense of `kkae-da' is mapped into the set {`break', `smash', `crack'} and some words in the set can replace each other in a translated sentence like `break/smash/crack a 'The English-English-Korean Dictionary used here is an English-Korean one, where English definitions are paired with Korean translations.",
        "break [breik] v.(broke, brok •en) vt. 1 (P6.7) cause (something) to come to pieces by a blow or strain; destroy; crack; smash.",
        "°.",
        "ill ` zl k 'A'k, _T'k TL] '� z14.",
        "9 ~ a cup Id ° gill l ~ a glass to [into] piece �1 �1 � � H 4 ~a thread 1 °.",
        "� °1 zl 'k l ~ one's arm 13 °.",
        "41 14 �~ a stick in two 141 T",
        "bank.",
        "Ii��] � Tt1 V4.2 (P6) hurt; injure.... ° 1�?1171 11711 [v} ]7lll a}v}.",
        "¶ ~ the skin 91 i °ll 1�?",
        "1 H'k.3 (P6) put (something) out of order; make useless by rough handling, etc.",
        "11 ;3I * r Ill [ '1 t}Ill1 44.",
        "9 ~ a watch 1 /11' 11,H 4 l ~ a line ',A °.",
        "t _el4 l ~ the peace I - 11 314.4 (P6) fail to keep or follow; act against (a rule, law, etc) ; violate; disobey.",
        "(;111-\"1 1471) ° °l 71It /~ one'spromise °Ffi 1171y} l ~ acontract /11'1 A\"'4It.",
        "5 ....",
        "dish'.",
        "Therefore, we can expect the behavior of those words to be alike or meaningfully related in a corpus.",
        "Based on this expectation, we compute sense probability by applying the target word co-occurrence based method to all words in the same sense division.",
        "Word probability represents how likely a target word is selected from the set of words in the same sense division.",
        "In the example `jeomsim-eul meok-da', the sense of `meok-da' is eat, which is mapped into three words {`eat', `have', `take'}.",
        "Among them, `have' forms a natural phrase while `eat' makes an awkward phrase.",
        "We could judge the naturalness from the fact that `have' and `lunch' co-occurs in a corpus more frequently than `eat' and `lunch'.",
        "In other words, the level of naturalness or awkwardness of a phrase can be captured by word co-occurrence.",
        "Based on this observation, we use target word co-occurrence to get word probability."
      ]
    },
    {
      "heading": "3 Calculation of each measure",
      "text": []
    },
    {
      "heading": "3.1 Sense Preference",
      "text": [
        "Given a source word s and its k-th sense sk, we calculate sense preference spf (sk) using the equation (1).",
        "In the equation, SNT is a set of all content words except s in an input sentence.",
        "DEF, k is a set of all content words in definition sentences of s , and EX,k is a set of all content words in example sentences of sk, both of which are extracted from the dictionary.",
        "Sense preference is obtained by calculating similarity between words in SNT and words in DEF and EX.",
        "For all words in an input sentence (wiESNT), we sum up the maximum similarity between wi and all clue words (i.e. wd and we).",
        "To get similarity between words (sim(wi, wj)), we use WordNet and the metric proposed in Rigau et al.",
        "(1997).",
        "Senses in a dictionary are generally ordered by frequency.",
        "To reflect distribution of senses in common text, we use a weight factor 0(sk) that is inversely proportional to the order of a sense skin a dictionary.",
        "Then, we calculate normalized sense preference to combine sense preference and sense probability."
      ]
    },
    {
      "heading": "3.2 Sense Probability",
      "text": [
        "Sense probability represents how likely target words with the same sense co-occur with translations of other words within the input sentence.",
        "Let us suppose that the i-th word in an input sentence is si and the k-th sense of si is s!",
        "�.",
        "Then, sense probability sp(s�) is computed as follows: _m f (t q, t9P, 0",
        "In the equation, O(si) signifies a set of words that co-occur with si on syntactic relations.",
        "In an element (sj, m, c) of 0(si), sj is a word that co-occurs with si in an input sentences, c is a syntactic relation between si and sj, and m is the number of translations of sj.",
        "Provided that the set of translations of a sense s!",
        "�is Tik and a member of Tip is tq the frequency of co-occurring tq and t - with a syntactic relation c is denoted as f (tq tjp c), which is extracted from target language corpora.",
        "Therefore,",
        "n(t q) in the equation (4) represents how frequently t q co-occurs with translations of sj.",
        "By summing up n(t q) for all target words in Tk, we obtain sense probability of s�."
      ]
    },
    {
      "heading": "3.3 Word Probability",
      "text": [
        "Word probability represents how frequently a target word in a sense division co-occurs in a corpus with translations of other words within the input sentence.",
        "We denote word probability as wp(t q) that is a probability of selecting t q from Tk.",
        "Using n(t q) in the equation (4), we calculate word probability as follows:"
      ]
    },
    {
      "heading": "3.4 Translation Preference",
      "text": [
        "To select a target word among all translations of a source word, we compute translation preference (tp f) by merging sense preference, sense probability and word probability.",
        "We simply sum up the value of sense preference and sense probability as a measure of sense disambiguation, and then multiply it with word probability as follows:",
        "In the equation, ?I(Ti) is a normalizing factor for wp(t q)4, and 6 is a weighting factor for sense preference.",
        "We select a target word with the highest tpf as a translation.",
        "When all of the n(t q) in the equation (4) are 0, we use the following equation for smoothing, which uses only frequency of a target word.",
        "f(tq) si, 4, verb-obj) in the example of `jeobsi-reul kkae-da', and then the following frequencies will be used: f (break, plate, verb-obj ), f (break, dish, verb-obj ),..., f (crack, platter, verb-obj) .",
        "prevent discounting translation preference of a word, the sense of which has many corresponding target words."
      ]
    },
    {
      "heading": "4 Evaluation",
      "text": [
        "We evaluated our method on English-to-Korean translation.",
        "EssEEK (1995) was used as a bilingual dictionary.",
        "We converted this English-English Korean dictionary into a machine readable form, which has about 43,000 entries, 34,000 unique words and 80,000 senses.",
        "From the dictionary, we extracted sense definitions, example sentences and translations for each sense.",
        "Co-occurrence of Korean was extracted from Yonsei Corpus, KAIST corpus and Se-jong Corpus using the method proposed in Yoon (2001).",
        "The number of extracted co-occurrence is about 600,000.",
        "To exclude any kind of human intervention during knowledge extraction and evaluation, we evaluated our method similarly with Koehn and Knight (2001).",
        "English-Korean aligned sentences were collected from novels, textbooks for high school students and sentences in a Korean-to-English bilingual dictionary.",
        "Among those sentences, we extracted sentence pairs in which words in the English sentence satisfy the following condition: if the paired Korean sentence contains a word that is defined in the dictionary as a translation of the English word.",
        "We randomly chose 945 sentences as an evaluation set, in which 3,081 words in English sentences satisfy the condition.",
        "Among them, 1,653 are nouns, 990 are verbs, 322 are adjectives, and 116 are adverbs.",
        "We used Brill's tagger (Brill, 1995) and Memory-Based Shallow Parser (Daelemans et al., 1999) to analyze English sentences.",
        "To analyze Korean sentences, we used a POS tagger for Korean (Kim and Kim, 1996).",
        "First, we evaluated the accuracies of sense preference (spf) and sense probability (SP).",
        "If any target word of the sense with the highest value is included in an aligned target language sentence, we regarded it as correct result.",
        "The accuracy of sense preference is shown in Table 1.",
        "In the table, a w/o DEF row shows the result produced by removing the DEF clue in the equation (1), and a w/o ORDER row is the result produced without the weight factor 0(8k) of the equation (2).",
        "As shown in the table, the result with the weight factor and without a sense definition sentence is best for all cases.",
        "We will discuss this result in the next section.",
        "The accuracy of sense probability is shown in",
        "syntactic relations to get sense probability.",
        "In the table, the result obtained by using words on a syntactic relation (with case coot word) is compared to that obtained by using all words within a sentence (with all coot word).",
        "As shown, the accuracy for nouns is higher when using all words in a sentence, whereas the accuracy for others is higher when considering syntactic relations.",
        "Table 3 shows the result of translation selection.7 We set three types of baseline - random selection, most frequent, 1st translation of 1st senses.",
        "We conducted the experiment al",
        "tering the combination of spf, sp and wp.",
        "An spf row shows the accuracy of selecting the first translation of the sense with the highest spf, and an sp row shows the accuracy of selecting the first translation of the sense with the highest sp.",
        "A wp row shows the accuracy of using only word probability.",
        "In other words, it is obtained through assuming all translations of a source word to have the same sense.",
        "Therefore, the result in a wp row can be regarded as a result produced by the method that uses only target word co-occurrence.",
        "An spxwp row is the result obtained without spf,,,,,, and an spfxwp row is the result obtained without spin the equation (8).",
        "An (,pf+spxwp row is the result of combining all measures.",
        "For the best case, the accuracy for nouns is 55.23%, that for verbs is 42.22% and that for adjectives is 42.86%.",
        "Although we use a simple method for sense disambiguation, our results of translation selection are superior to the results that are produced using only target word co",
        "occurrence (wp rows).",
        "5 Discussion",
        "We could summarize the advantage of our method as follows:",
        "• reduction of the problem complexity • simplifying knowledge acquisition • selection of more appropriate translation • use of a mono-bilingual dictionary • integration of syntactic relations • guarantee of robust result",
        "The figure below shows the average number of senses and translations for an English word in EssEEK (1995).",
        "The left half of the graph is for all English words in the dictionary, and the right half is for the words that are marked as frequent or significant words in the dictionary.",
        "On the average, a frequently appearing English word has 2.82 senses, each sense has 1.96 Korean translations, and consequently an English word has 5.55 Korean translations.",
        "Moreover, in our evaluation set, a word has 6.86 senses and a word has 14.78 translations.",
        "Most approaches on translation selection have tried to translate a source word directly into a target word, thus the complexity of their method grows proportional to the number of translations per word.",
        "In contrast, the complexity of our method is proportional to only the number of senses per word or the number of translations per sense.",
        "Therefore, we could reduce the complexity of translation selection.",
        "When the degree of ambiguity of a source language is n and that of a target language is m,",
        "the complexity of translation is nearly n x m. Therefore, knowledge acquisition for translation is more complicated than other problems of natural language processing.",
        "Although the complexity of knowledge acquisition of the methods based on a target language corpus is only m, ignorance of a source language results in selecting inappropriate target words.",
        "In contrast, by splitting translation selection into two sub-problems, our method uses only existing resources - a bilingual dictionary and a target language monolingual corpus.",
        "Therefore, we could alleviate the complexity of knowledge acquisition to around n+m.",
        "As shown in the previous section, our method could select more appropriate translation than the method based on target word co-occurrence, although we used coarse knowledge for sense disambiguation.",
        "It is because the co-occurrence based method does not consider sense ambiguity of a target word.",
        "Consider the translation of the English phrase `have a car'.",
        "A word `car' is translated into a Korean word `cha', which has many meanings including car and tea.",
        "A word `have' has many senses - posses, eat, drink, etc., among which the drink sense is mapped into a Korean verb `masi-da'.",
        "Because of the tea sense of `cha', the frequency of co-occuring `cha' and `masi-da' is dominant in a corpus over that of all other translations of `car' and `have'.",
        "In that case, the method that uses only word co-occurrence (wp in our experiment) translated `have a car' into an incorrect sentence `cha-reul masi-da' that means `have a tea'.",
        "In contrast, our method produced a correct translation `cha-reul kaji-da', because we disambiguate the sense of `have' as posses by employing sense preference before using co-occurrence.",
        "In the experiment, the combination spfxwp gets higher accuracy than (spf+sp) x wp for most cases.",
        "It is due to the low accuracy of sp, which is also caused by the ambiguity of a target word as shown in the example of `have a car'.",
        "Nevertheless, we do not think it means sense probability is useless.",
        "The accuracies of spx wp are almost better than those of wp, therefore sense probability can work as a countermeasure when no knowledge of a source language exists for disambiguating the sense of a word.",
        "In this paper, we used a mono-bilingual dictionary, which has more information than a common bilingual dictionary including sense definitions in a source language and syntactic patterns for the predicate.",
        "While previous research on sense disambiguation that exploits those kinds of information has shown reliable results, in our experiment, the use of sense definitions lowers the accuracy.",
        "It is likely because we used sense definitions too primitively.",
        "Therefore, we expect that we could increase the accuracy by properly utilizing additional information in the dictionary.",
        "Many studies on translation selection have concerned with translation of only nouns.",
        "In particular, some of them use all co-occurring words within a sentence, and others use a few restricted types of syntactic relations.",
        "Even more, each syntactic relation is utilized independently.",
        "In this paper, we proposed a statistical model that integrates various syntactic relations, with which the accuracies for verbs, adjectives, and adverbs increase.",
        "Nevertheless, since the accuracy for nouns is higher when using all words in a sentence, it seems that syntactic relations may be differently used for each case.",
        "The other advantage of our method is robustness.",
        "Since our method disambiguates the sense of a source language word using reliable knowledge in a dictionary, we could avoid selecting or generating a target word the meaning of which is definitely improper in given sentences like `hatch a dish' for 'jeobsi-reul hhae-da' and `cha-reul masi-da' for `have a car'."
      ]
    },
    {
      "heading": "6 Conclusion",
      "text": [
        "In this paper, we proposed a hybrid method for translation selection.",
        "By dividing translation selection into sense disambiguation of a source word and selection of a target word, we could simplify knowledge acquisition and select more appropriate translation.",
        "Acknowledgement We are grateful to Sabine Buchholz, Bertjan Busser at Tilburg University and professor Walter Daelemans at University of Antwerp for the aid to use the Memory-Based Shallow Parser (MBSP)."
      ]
    }
  ]
}
