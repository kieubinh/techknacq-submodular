{
  "info": {
    "authors": [
      "Markus Becker",
      "Anette Frank"
    ],
    "book": "International Conference on Computational Linguistics",
    "id": "acl-C02-1093",
    "title": "A Stochastic Topological Parser for German",
    "url": "https://aclweb.org/anthology/C02-1093",
    "year": 2002
  },
  "references": [
    "acl-A00-1031",
    "acl-A00-1033",
    "acl-A97-1012",
    "acl-P02-1056",
    "acl-P97-1003",
    "acl-W97-0307"
  ],
  "sections": [
    {
      "heading": "Abstract",
      "text": [
        "We present a new approach to topological parsing of German which is corpus-based and built on a simple model of probabilistic CFG parsing.",
        "The topological field model of German provides a linguistically motivated, flat macro structure for complex sentences.",
        "Besides the practical aspect of developing a robust and accurate topological parser for hybrid shallow and deep NLP, we investigate to what extent topological structures can be handled by context-free probabilistic models.",
        "We discuss experiments with systematic variants of a topological treebank grammar, which yield competitive results.1"
      ]
    },
    {
      "heading": "1 Introduction",
      "text": [
        "We present a new approach to topological parsing for German which is corpus-based and built on a simple model of probabilistic CFG parsing.",
        "Topological parsing is of special interest for shallow preprocessing of languages like German, which exhibit free word order and the so called verb-second (V2) property.",
        "The topological field model (ohle, 1983) is a theory-neutral model of clausal syntax that provides a linguistically well-motivated, but flat macro structure for complex sentences.",
        "As opposed to chunk based partial parsing, the topological model is compatible with deep syntactic analysis, and thus perfectly suited for integrated shallow and deep NLP, by guiding deep syntactic analysis by partial, topological bracketing (Crysmann et 'The ideas that led to this paper grew from discussions with Feiyu Xu and Jakub Piskorski.",
        "The work was in part supported by a BMBF grant to the DFKI project WHITEBOARD (FKZ 01 IW 002).",
        "Special thanks go to Bernd Kiefer for providing us with a CFG parser and for his support in technical issues, and to Hubert Schlarb and Holger Neis for manual correction of our test corpus.",
        "al., 2002), or for pre-structuring of complex sentences for chunk-based processing (Neumann et al., 2000), as a divide and conquer strategy.",
        "Previous approaches to topological parsing of German make use of hand-coded grammars (Wauschkuhn, 1996; Braun, 1999).",
        "In this paper we pursue a corpus-based, statistical approach, aiming at a robust parser with high accuracy.",
        "We make use of a treebankinduced probabilistic non-lexicalised CFG, following (Charniak, 1996).",
        "While this simple model is clearly outperformed by more refined stochastic models for full constituent-structure parsing,2 our experiment is interesting in showing that for topological parsing a robust parser with high accuracy figures can be obtained with a standard stochastic model of non-lexicalised context-free treebank grammars.",
        "Topological structures are partial or under specified in that they do not encode internal structure and demarcation of subsentential constituents, i.e. NP, AP, PP or VP constituents.",
        "Topological base clauses3 are characterised by morphological and categorial properties.",
        "Still, the topological parsing task is not trivial, in that the boundaries and relative embedding of base clauses and the demarcation of fields in general are not deterministic, and also lexically, or semantically determined .",
        "Thus, the complexity of topological parsing lies somewhere between chunk parsing and full constituent structure parsing.",
        "The interesting question we are exploring in our approach is whether this type of syntactic structure can be successfully dealt with using a non-lexicalised PCFG model.",
        "The aim of this paper is threefold.",
        "Besides the practical aspect of (i) developing a robust 2E.g.",
        "(Collins, 1997) and later work, see (Belt, 2001).",
        "3I.e.",
        "sentential clauses, see Section 2 for more detail.",
        "and accurate topological parser, to be used for integration with deep syntactic analysis or for cascaded shallow analysis systems, we (ii) investigate how well topological structures can be modeled by context-free probabilistic grammars, while (iii) trying to detect specific phenomena that require more sophisticated models.",
        "The paper is structured as follows.",
        "In Section 2 we present the field model for German and describe the creation of a topologically structured treebank, which we derive from the NEGRA corpus (Brants et al., 1997).",
        "Section 3 discusses previous work.",
        "Section 4 describes our corpus-based stochastic approach to topological parsing.",
        "In Section 5 we introduce formal variants of our treebank grammar, which illustrate problematic aspects in topological stochastic parsing, and possible strategies to their solution.",
        "Section 6 presents the testing setup and evaluation results for different grammar variants.",
        "The results are analysed in detail in Section 7.",
        "Section 8 concludes."
      ]
    },
    {
      "heading": "2 A Topological Corpus of German German sentence structure is traditionally analysed in terms of its \"field\" or topological structure, which is determined by the position of the finite verb in left (LB) or right (RB) bracket position (1). In main clauses the finite verb typically occupies the second constituent position, following the so-called \"Vorfeld\" (VF) (V2 clauses). The Vorfeld can be missing in yes/no questions or embedded conditional clauses (V1 clauses), as well as in subordinate clauses with complementizer. In subordinate clauses the complementizer (or wh-/rel-phrase) demarcates the LB position, the finite verb is in RB position (VL clauses). Arguments and modifiers between LB and RB occupy the \"middle field\" (MF), extraposed material is found to the right of the right bracket, in the \"Nachfeld\" (NF).",
      "text": [
        "verbconstituents All modern theories of syntax rely in one way or the other on this descriptive model of German sentence structure.",
        "It is thus straightforward to define mappings from topological to deep syntactic structures of almost any syntactic framework.",
        "Its compatibility with deep syntactic analysis makes topological syntactic structure an ideal candidate for interleaving of shallow and deep NLP (Crysmann et al., 2002).",
        "For our corpus-based approach, no topologically annotated corpus of German was available.",
        "The NEGRA treebank (Brants et al., 1997), a large annotated corpus of German newspaper text, follows an annotation scheme which combines structural and dependency annotations.",
        "However, the crucial topological clues, in particular the distinction between fronted or clause final verb position, as well as the delimitation of pre-, middle and post-fields are not encoded.",
        "To derive a topological \"treebank grammar\" from the NEGRA corpus, we applied the treebank conversion method of (Frank, 2000).",
        "This method is built on a general tree description language, and allows the definition of fine-grained rules for structure conversion.",
        "Conversion rules specify partial structural constraints and actions for tree modifications, which are applied by removing or adding tree description predicates from the trees that satisfy the constraints.",
        "We derived a topological corpus from the NEGRA treebank, by defining linguistically informed conversion rules which exploit additional annotations in the corpus, i.e. indirect linguistic evidence, to assign topological clues.",
        "In a second step we induced topological structures by flattening irrelevant internal structure within topological fields and introducing topological category nodes DF, VF, MF, and NF as well as LB and RB for left and right brackets.4 Basic clauses are marked with labels CL which expand to various patterns of DF, VF, LB, MF, LB, and NF nodes.",
        "Basic clauses can be embedded within phrasal fields VF, MF, NF.",
        "The resulting structures give (i) an internal structure of basic clauses in terms of fields which are internally flattened to POS sequences, and (ii) an overall hierarchical structure of clausal embedding, including coordination.",
        "(2) gives an example of a complex topological struc4DF marks a special \"discourse field\" preceding VF, as in Naja, er kommt halt spdter-Well, he will come later."
      ]
    },
    {
      "heading": "VF-WH MF RB-VFIN PWAV NE VVFIN Wie BBC meldete",
      "text": [
        "As BBC reported ordered Souza the police ture.",
        "It illustrates the use of parameterised category nodes, which distinguish various types of clauses: CLV2,V1,INF,REL,WH, pre-fields: VFTOPIC,WH,REL, left: LBCOMPL,VFIN and right brackets: RBVFIN,VINF,VPART,PTK.",
        "The automatically derived topological corpus is used for extraction of a stochastic treebank grammar with reserved development and test sections.",
        "The test corpus was manually checked and corrected by two independent annotators.",
        "Manual correction of the test section yielded 93.0% labelled precision and 93.7% labelled recall of the automatic conversion procedure."
      ]
    },
    {
      "heading": "3 Topological Parsing of German While partial parsers for detection of clausal structure are now available in many varieties",
      "text": [
        "and for many languages,5 this type of parsing approach has always been considered difficult for languages like German.",
        "(Wauschkuhn, 1996) was among the first to present a partial parser for German.",
        "In a first step, the coarse syntactic clause structure is detected, using indicators like verbs, conjunctions, punctuation, etc.",
        "A fine grained analysis is carried out in the second step, by grouping the remaining fields into sequences of minimal \"base\" NPs or PPs.",
        "The analysis is still partial in that attachments of base NPs and PPs are not determined .",
        "The grammar is defined as a CFG with feature structures, where grammar rules are annotated with manually adjusted weights for parse ranking.",
        "Grammar rules, including the associated weights, are handcoded.",
        "(Wauschkuhn, 1996) reports coverage of 85.7% for clausal analysis.",
        "No figures are given for precision or recall.",
        "(Braun, 1999; Neumann et al., 2000) report an approach to topological parsing of German, based on cascaded finite state automata.",
        "In 'See for example (Ait-Mokhtar and Chanod, 1997; Gala-Pavia, 1999) for English, French, and Spanish."
      ]
    },
    {
      "heading": "MFRB-VFIN PRELS PRFVVPP VVFIN",
      "text": [
        "der sich versteckt halt the chieftain to catch who himself hidden keeps a first pass, possible verb groups are identified.",
        "A second pass identifies subordinate clause structures, using similar cues as (Wauschkuhn, 1996).",
        "(Braun, 1999) carried out an evaluation over 400 sentences and reports coverage of 94.3%, precision of 89.7% and recall of 84.75%.",
        "While these approaches are similar to our work in inducing topological structure from key linguistic indicators, they suffer from several problems.",
        "(i) Hand-coding of rules is laborious6 and likely to miss out rare or exceptional phenomena, including ungrammatical constructions.",
        "(ii) Ambiguities are either resolved by manually assigned weights, or simply by using a greedy strategy (Braun, 1999).",
        "(iii) These approaches heavily exploit prescriptive punctuation rules.",
        "This is problematic for performance influenced deviations from standard punctuation or less standardised text sorts, leading to either a loss of coverage, or accuracy."
      ]
    },
    {
      "heading": "4 A Stochastic Topological Parser",
      "text": [
        "In response to these problems we investigate a corpus-based, stochastic approach to topological parsing.",
        "It has been demonstrated that stochastic parsing can achieve high figures of robustness and accuracy, while mostly restricted to purely constituent-based syntactic analysis.",
        "For our task of topological parsing, we investigate the adequacy of the very simple, nonlexicalised model of (Charniak, 1996), if applied to rather flat, topological structures.",
        "Our working hypothesis was that the model should perform well, even if not lexicalised, since (i) there are less attachment decisions, due to the rather flat target structures.",
        "(ii) Topological structures as such, as well as attachment decisions for base clauses are less dependent on lexical information, than, e.g., attachment of PPs.",
        "Finally, (iii) a corpus-based stochastic grammar has a",
        "context (cf. (Belz, 2001)): for example, a relative pronoun in VF-REL predicts (through coocurrence data in the corpus) that it is dominated by a grandfather category CL-REL, which takes a right bracket daughter RB-VFIN, as opposed to a left bracket daughter.",
        "We extract grammar variants with and without parameterised categories, to investigate to which extent a more fine-grained and implicitly contextualised grammar helps to increase accuracy in a topological model of syntax.",
        "(b) Punctuation The maximal decoration of a tree contains punctuation marks like commas, quotes, colons, etc.8 While the correct attachment of punctuation marks is not part of our evaluation, the guiding intuition was that punctuation should help to identify clause boundaries.",
        "On the other hand, irregularities in punctuation setting cause noise in the data, increases grammar size, and could cause coverage problems.",
        "We compare the performance of grammar variants with and without punctuation.",
        "(c) Binarisation Phrasal topological fields VF, MF, NF are underspecified for constituent boundaries of NPs, PPs, etc.",
        "The fields are radically flattened, directly expanding to sequences of POS categories.",
        "We expect a great variety of POS sequences as expansions of field categories, but at the same time reckon with considerable sparseness problems, due to unseen POS sequences."
      ]
    },
    {
      "heading": "6 Experiments and Results Experimental setup The NEGRA corpus was",
      "text": [
        "split into randomised sections for training (16476), development (1000) and testing (1058), plus further held-out data for later experiments.",
        "For training and development we used the automatically derived topological corpus, while the test data was manually corrected (Section 2).",
        "To test the performance of the grammar independently from a tagger, the input to the parser consists of the manually disambiguated POS sequences of the test corpus.9 Evaluation Measures For evaluation we employ the PARSEVAL measures of labeled recall and precision and crossing brackets, as well as complete match, i.e. full structure identity.10 To accommodate for the differences between grammar versions, evaluation was conducted as follows.",
        "The evaluation measures in Tables 1 and 2 disregard punctuation and are based on simple node labels, i.e. category parameters are stripped.",
        "Finally, to allow clear comparison between binarised and flat grammar versions binarised parse trees are compiled to flat trees before evaluation against flat target trees.11 Results We conducted systematic tests for all combinations of grammar variants: para (parameterised categories), bin (binarised), pnct (punctuation), prun (pruning single rule occurrences), see results in Table 1.",
        "Tables 2 and 3 give more detailed evaluation figures for the best performing model (v1) para+.bin+.pnct+.prun+.",
        "Table 2 lists labeled recall and precision results for individual topological categories.",
        "Field categories VF ... NF receive high figures above 90%, to the exception of NF, yet with lower overall proportion (quota).",
        "Table 3 reports alternative evaluation figures, namely evaluation by disregarding category parameters (param ), or by evaluating on complex category labels (param +); and by taking or not punctuation into account (punct +/).",
        "Finally, Fig. 4 displays a learning curve for stepwise extension of the training corpus.",
        "98 sentences were set apart due to wrong POS tags.",
        "10We verified our results using the evaluation tool evalb by Satoshi Sekine http://www.cs.nyu.edu/cs/projects/proteus/evalb/.",
        "\"Evaluating labeled recall and precision on binarised trees would yield unduly high figures, due to a high number of field-internal trivial assignments.",
        "7 Discussion of Results Table 1 shows better performance of grammars v1-8 using parameterised categories, as opposed to the complementary versions v9-16.",
        "Parameterised grammars make use of a richer structure, which is mapped to coarser topological categories for evaluation.",
        "12 The implicit contextualisation in category labels clearly improves parsing results.",
        "While the rule set grows, a relative loss of coverage is only visible for non-binarised versions v5-8 as opposed to v13-16.",
        "Binarisation shows dramatic effects in coverage and accuracy.",
        "Binarised grammars are smaller than their flat counterparts, but far less constrained, allowing the derivation of virtually any POS sequence.",
        "Flat grammars suffer from lack of coverage, especially those using rich category labels and/or punctuation.",
        "We see dramatic differences of about 100% complete match improvement between v6/v2, v8/v4, v16/v12, and significant contrasts in LP/LR and CB measures.",
        "Thus, binarisation solves the sparseness problem for flat topological CFGs without jeopardising accuracy.",
        "Using punctuation in parsing leads to improved accuracy measures, yet only in binarised grammars, where sparseness problems are circumvented.",
        "Flat grammars with punctuation show lower coverage than their counterparts higher accuracy measures are probably due to lower coverage.",
        "Use of punctuation is similar to parameterisation of labels, in that grammar internally it helps to discriminate fields, while for evaluation it is filtered from the parse trees.",
        "Pruning of single rule occurrences leads to significant reduction in grammar size, in particular for non-binarised grammars.",
        "Here, pruning incurs significant loss in coverage.",
        "This is expected, since extremely flat rules are likely not to reoccur several times.",
        "For binarised grammars pruning yields rule sets of about 1/3, with almost unchanged 100% coverage.",
        "Our hypothesis was that pruning improves the quality of the grammar by eliminating noise imported by automatic treebank conversion.",
        "This is confirmed, in all binary grammars, by improved accuracy measures.",
        "Since in binary grammars generic field rules are binarised and frequently occuring, rule pruning is likely to eliminate noise.",
        "In sum, our best performing model (vl) makes use of a maximally discriminative symbolic grammar (parameterised categories, punctuation), resolves sparseness problems by rule binarisation, and can afford rule pruning to eliminate noise.",
        "Applied to full sentence lengths (vlb) we note a drop in performance, 13S-categories were used for non-standard base clauses, e.g. gapping, that did not fit the topological model.",
        "but insignificantly so for coverage, and only by 1% in LP and 0.7% in LR.",
        "Table 3 details alternative evaluation measures.",
        "Evaluation on parameterised categories incurs a slight drop in accuracy, but in high ranges.",
        "14 Evaluation of punctuation attachment - which is of little importance - yields a further drop.",
        "The learning curve in Fig. 4 is surprising in that we obtain relatively high performance from rather small training corpora and grammar sizes (size grows almost linearly from 313 to 2308).15 Saturation regarding coverage and accuracy is obtained around training size 6000.",
        "Finally, we determined phenomena that call for stronger contextualisation or lexicalisation.",
        "A case in point are verb-second (V2) sentences with a fronted V2 clause in Vorfeld position (i.e. with VF-V2 categories), which allow an alternative analysis as coordinate clauses with shared subjects.",
        "This type of construction was frequently misanalysed as a coordination structure since this structural ambiguity cannot be 14 These measures are relevant for integration of shallow and deep NLP (Crysmann et al., 2002), as parameterised categories provide highly discriminative information that can be used to guide deep syntactic processing.",
        "15Note, however, that the curve pertains to a robust, binarised grammar.",
        "We chose v2 (prun-) in order not to unduly penalise small grammars.",
        "Lack of pruning could explain the scattered values for lower training sizes."
      ]
    }
  ]
}
