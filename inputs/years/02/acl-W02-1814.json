{
  "info": {
    "authors": [
      "Jing Xiao",
      "Jimin Liu",
      "Tat-Seng Chua"
    ],
    "book": "SIGHAN Workshop on Chinese Language Processing",
    "id": "acl-W02-1814",
    "title": "Extracting Pronunciation-Translated Names from Chinese Texts Using Bootstrapping Approach",
    "url": "https://aclweb.org/anthology/W02-1814",
    "year": 2002
  },
  "references": [
    "acl-P01-1049",
    "acl-W99-0613"
  ],
  "sections": [
    {
      "heading": "Abstract",
      "text": [
        "Pronunciation-translated names (P-Names) bring more ambiguities to Chinese word segmentation and generic named entity recognition.",
        "As there are few annotated resources that can be used to develop a good P-Name extraction system, this paper presents a bootstrapping algorithm, called PN-Finder, to tackle this problem.",
        "Starting from a small set of P-Name characters and context cue-words, the algorithm iteratively locates more P-Names from the Internet.",
        "The algorithm uses a combination of P-Name and context word probabilities to identify new P-Names.",
        "Experiments show that our PN-Finder is able to locate a large number of P-Names (over 100,000) from the Internet with a high recognition accuracy of over 85%.",
        "Further tests on the MET-2 test set show that our PN-Finder can achieve a performance of over 90% in F1 value in locating P-Names.",
        "The results demonstrate that our PN-Finder is effective."
      ]
    },
    {
      "heading": "1 Introduction",
      "text": [
        "Pronunciation-translated names (P-Names) are those foreign names that are translated to Chinese characters according to their pronunciations.",
        "A P-Name sometimes forms part of but not a complete named entity.",
        "For instance, in the place name “)QAf11 ” (Berkeley University), only the term “PQAf11” (Berkeley) is a P-Name, while “)�,�” (University) is not since it is translated semantically.",
        "The ability to recognize P-Names helps to reduce ambiguities in word segmentation and improve the performance of Chinese information retrieval since many unknown words are P-Names, especially for international Chinese news.",
        "Unlike English, there is no blank between words in Chinese, in which a word is a linguistic token consisting of one or more characters.",
        "In addition, the same characters may appear in multiple context with different meanings (Chua and Liu, 2002).",
        "The presence of P-Names brings more ambiguities to Chinese word segmentation since every character in a P-Name can be used as a common character.",
        "Intuitively, we can extract the P-Names based on the distinctive sequence of characters that they are used as compared to common words.",
        "In addition, we can use local context around the P-Names to confirm and classify them into person or part of location and organization names.",
        "One way to perform these tasks effectively is to rely on statistics derived from a large corpus in which the P-Names are annotated.",
        "While some annotated corpuses with general named entities are available such as the PKUC (Yu, 1999) and MET-2 (Chinchor, 2001), there is no such annotated corpus for P-Names.",
        "While annotated data is difficult to obtain, unannotated data is readily available and plentiful, especially on the Internet.",
        "To take advantage of that, we need to tackle two major problems.",
        "The first is how to gather sufficient distinct P-Names from the Internet, and the second is how to use the available resources to derive reliable statistical information to characterize the P-Names.",
        "The problem of gathering sufficient reliable information from a small initial set of seed resources has been tackled in bootstrapping research for information extraction (Agichtein and Gravano, 2000; Brin, 1998; Collins and Singer, 1999; Mihalcea and Moldovan, 2001; Riloff and Jones, 1999).",
        "Bootstrapping approach aims to perform unsupervised text processing to extract information from open resources such as the Internet using minimum manual labor.",
        "Given the lack of annotated training samples for P-Name extraction, this paper introduces a bootstrapping algorithm, called PN-Finder.",
        "It starts from a small set of seed samples, and iteratively locates, extracts and classifies the new and more P-Names.",
        "It works in conjunction with a general Chinese named entity recognizer (Chua and Liu, 2002) to extract general named entities.",
        "In the remaining parts of this paper, we describe the details of PN-Finder in Section 2 and its application in locating P-Names from new documents in Section 3.",
        "Section 4 presents the experimental results using the MET-2 test corpus.",
        "Section 5 contains our conclusion and outline for future work."
      ]
    },
    {
      "heading": "2 Bootstrapping Algorithm for Locating P-Names",
      "text": [
        "Currently, there is no standard corpus that annotates all P-Names.",
        "Since annotating thousands of P-Names is more difficult than collecting thousands of P-Names from the Internet, we recur to using the Internet search engine to collect a large set of P-Names.",
        "Figure 1 illustrates our main components in bootstrapping process."
      ]
    },
    {
      "heading": "Seed P Name characters Seed context cue words Search Engine",
      "text": [
        "Generate new P-Name characters And new context cue words",
        "The inputs to the PN-Finder are:",
        "a) A seed P-Name character set Cs(0) consisting of 5 characters {“R7”, “�j”, “L”, “lr”, “�”}.",
        "b) A set of seed context cue words CW(0) consisting of 60 context words, such as {“NULL”, “iM”, “tiA”, “C”, “A”, “PJ”}.",
        "These are typical context words found around person, location and organization names in PKUC1 (the PoS Corpus of Peking University), which contains one month of news from the People Daily.",
        "c) A set of P-Name candidates P(0), which is null at the beginning.",
        "d) A common word dictionary extracted from PKUC by removing proper nouns, numbers and non-Chinese symbols.",
        "It contains about 37,000 words.",
        "From the initial seeds, we perform the followings: a) We use every two characters in Cs(i-1) as query to retrieve relevant web pages from the Internet using a commercial search engine.",
        "We then extract possible P-Names from the returned web pages to update P(i).",
        "b) We find a most probable new P-Name character.",
        "Update Cs(i-1) to Cs(i) by adding the new character.",
        "c) We bootstrap new context words around the new P-Names found to derive CW(i).",
        "We then perform the lexical chaining to generalize these context words to generate semantic classes.",
        "d) We repeat the process from step (a) until any of the following conditions is satisfied: (i) when no new P-Name is found; (ii) when the desired number of iterations is reached; or (iii) when the number of P-Names found exceeds a desired number.",
        "The following subsections discuss the details of the bootstrapping process."
      ]
    },
    {
      "heading": "2.1 Querying and Extracting the P-Names from the Web",
      "text": [
        "The first step of the algorithm is to derive good queries from the character set Cs(m-1) to search the Internet to obtain new web pages.",
        "If we use all single characters from Cs(m-1) to perform the search, we are likely to get too many pages containing irrelevant information.",
        "As a compromise, we use every two characters cicj in Cs(m-1) (except those combinations that have been used in the previous iterations) to search the Internet using Google (by using its language tool2).",
        "We consider only up to 300 entries returned by Google.",
        "We divide the content of the web pages into text segments by using the non-alphanumeric characters as delimiters.",
        "We extract those text segments that contain the search characters ci, cj or both and store them in R(m).",
        "For example, from the web page given in Figure 2, the text segments extracted include: strings “A",
        "�” and “ POWOOMM, g 1 1 i1��7” from the first entry; and strings “ Mf4MO”, “t)\" a p �A �rYMAA0A-8r-V_-M, F IV” and “iE tMW, 5� ViAHE” from the second entry.",
        "Given R(m), we next extract the possible P-Names.",
        "Firstly, we segment those entries in R(m) by performing the longest forward match using the common word dictionary.",
        "We then remove all",
        "non-Chinese letters and common words containing more than one character.",
        "From the remaining string segments in R(m), we locate all sub-strings with at",
        "least 2-character in length and contain the query terms ci, cj or cicj.",
        "We extract those sub-strings that appear at least n (we use 3) times as P-Name candidates by string matching.",
        "We store the new P-Name candidates found in P(m-1) to obtain P(m).",
        "For example, if we use “fir, M” obtained from Cs(0) as query to Google, among the returned entries, we will have:",
        "Here the bracketed words are common words or English letters and they are removed from string matching.",
        "The sub-string “E° -kMtA” appears 5 times and it is matched as a possible P-Name."
      ]
    },
    {
      "heading": "2.2 Deriving New P-Name Characters",
      "text": [
        "Given the set of P-Name candidates in P(m), we next use both the context words and corpus statistics to confirm the P-Name and extract new P-Name characters.",
        "From observation, context information is useful to comfirm a P-Name and determine its left and right boundary.",
        "Thus we use one-word context to confirm and classify P-Name candidates into person names or part of location or organization names.",
        "For each context word wc in CW(m), we first compute its probability vector of occurrences, PV(wc), around person, location and organization names in PKUC as follows:",
        "n+o) respectively give the number of times wc appears at the left (or right) boundary of person (p), location (l) and organization (o) names in PKUC.",
        "c-x (or c+x) gives the probability that the P-Name is of type x, if this cue-word is at the left (or right) boundary of the P-Name.",
        "Given a P-Name candidate pk(m) in P(m), we extract the set of its left and right context words as Wcl and Wcr.",
        "We then derive the average probability vectors",
        "of Wc' = <c -p, c +p, c -l, c l, c -o, c +o> and Wc = <cr -p, cr+p, cr-l, cr+l, cr-o, cr+o>, and use these to compute the confidence vector of pk(m ) as:",
        "where cp=cl-p+cr+p, cl=cl-l+cr+l, co=cl-o+cr+o.",
        "Here we simply average the probabilities of the left and right context words to derive the final probability vector.",
        "We assign pk(m) to be part of a named entity of type x, if cx > p for x {p, l, o}.",
        "Here we set p to be 0.8.",
        "In case that there are more than one value greater than tip, we select the one with the highest value in the type vector as the type of that P-Name.",
        "We next derive an objective measure to evaluate how likely a candidate in P(m) could be a P-Name.",
        "We observe that a string is likely to be a P-Name if: (a) it contains some sub-strings that frequently appear in typical P-Names such as “R7�111 ”, “10M”, “� �”, etc; and (b) it has context words in CW(m-1) set that indicates that it has high probability of being part of a named entity.",
        "Thus for each P-Name candidate pk(m) (pk(m)=c1c2...cn) in P(m), we compute:",
        "where n is the number of characters in pk (m), and N equals |P(m)|.",
        "nj(ci) , nj(cici+ 1) and nj(cici+ 1ci+2) are respectively number of times the character strings ci, cici+1 and cici+1ci+2 in pk(m) also appear in other P-Name candidates in P(m).",
        "and are predefined constants (here we use =0.5 and =1.5).",
        "Equation (3.1) gives higher weight to pk(m) that has better match with longer string sequence of, say, cici+1ci+2 with other known P-Names candidates.",
        "Equation (3.2) selects the highest confidence value of context words around pk(m) as support for pk(m).",
        "As s1 and s2 are of different scales, we normalize s1 by dividing it by M, the maximum s1 values found in the current iteration, before fusing the two values in Equation (3).",
        "Since we would like to obtain more new P-Names during bootstrapping, in each iteration, we would like to expand the P-Name character set.",
        "In order to select the most likely P-Name characters, we derive a quasi-probability, Conf(ci(m)), to estimate how likely a character ci(m) in the P-Name candidate set P(m) could be used as a P-Name character.",
        "To do this, we make use of both the PKUC corpus and P(m).",
        "We observe that most characters in P(m) also appear in the PKUC corpus, sometimes as P-Name characters sometimes as common characters.",
        "Thus, intuitively we estimate Conf(ci(m)) by its occurrences in both PKUC and",
        "Here we assume that there are Nc P-Name candidates in P(m) that contain ci(m); and Nneg is the number of times that ci(m) is used as single-character word in PKUC.",
        "Equation (4) aims to identify characters that appear frequently as part of P-Names, but rarely as part of common words.",
        "It also favors characters that appear in more probable P-Names through the s(pk(m)) measures.",
        "Although Equation (4) is effective in identifying individual P-Name characters, it is not good at locating the sequences of P-Name characters that form the P-Names.",
        "This is because there are many characters that have low Conf(ci(m)) values that are part of a P-Name.",
        "For example, in a P-Name “ & J � �”, the character “T” has low confidence to be a P-Name character as defined by Equation (4).",
        "However, it co-occurs with high confident P-Name characters such as “ ” and “A”.",
        "To overcome this problem, we modify the confidence value of each character by considering its neighbors (context) to derive a smoothed confidence measure in Equation (5).",
        "where is a predefined constant (we use = 1),",
        "Conf(ci) is defined in Equation (4); C(ci) and C(cicj) is respectively the co-occurrence of characters ci and cicj in the P-Name set.",
        "Equation (5) tries to supplement the confidence of ci by its context, that is, it uses the higher of the bi-gram statistics with its preceding and succeeding word to enhance its confidence.",
        "We rank all the characters in P(m) using Equation (5) and add the top new character into CS(m-1) to obtain CS(m)."
      ]
    },
    {
      "heading": "2.3 Deriving New Context Words",
      "text": [
        "In addition to finding new P-Name characters, there is also a need to expand the context word set CW(m-1) in order to help identify more P-Names.",
        "As mentioned before, if at least one of cp, cl, co values of a P-Name candidate in Equation (2) is greater than a threshold p, we regard it as part of a named entity.",
        "For these P-Names which could be possible part of named entities, the following steps are performed:",
        "a) We retrieve all their context words in R(m).",
        "b) We add all new context words to form CW(m).",
        "c) We update probability vectors of the new context words using Equation (1).",
        "d) We group these context words under the category of c-x or c+x (for x {p, l, o}) if their probabilities under that category is greater than a threshold g (say, 0.5).",
        "e) We then perform lexical chaining using HowNet to generalize the context words under each of the 6 categories separately.",
        "The general lexical chaining algorithm is given in detail in Chua and Liu (2002).",
        "f) After lexical chaining, some semantically related words are grouped together.",
        "We update the confidence vectors of the semantic groups by averaging the confidence values of words in each of the semantic groups.",
        "At the end of this process, we obtain a new set of context word CW(m) which contains some generalized context word classes."
      ]
    },
    {
      "heading": "3 Identifying P-Names from New Texts",
      "text": [
        "At the end of the bootstrapping process, we obtain expanded lists of likely P-Name characters Cs(m), context cue words CW(m) and P-Names P(m).",
        "Given a new document, we want to use these resources to identify all P-Names.",
        "The process is carried out as follows:",
        "a) We first use our common word dictionary to remove all common words.",
        "b) Next we use knowledge of P-Name candidates and corpus statistics to identify a sequence of likely P-Name characters.",
        "Any sub-string in which the Sconf(ci) (see Equation (5)) of each consecutive character in that string is greater than a pre-specified threshold c (we use 5) is considered as a P-Name.",
        "c) A frequently occurring problem during testing is how to handle new characters not found in the Cs(m) set that we do not know their confidence values.",
        "Such problem occurs as a",
        "same foreign name may be translated to different P-Names with similar Chinese PinYin.",
        "For these characters, we adopt the similar homophone approach to relate unknown characters to the known characters in Cs(m) set with similar Chinese PinYin."
      ]
    },
    {
      "heading": "4 Evaluation",
      "text": [
        "We devise several tests to evaluate our extraction scheme with bootstrapping.",
        "We use the MET-2 test corpus for two of the tests, and PKUC as basic language resource to support the process.",
        "We use PKUC to extract common word dictionary, which consists of about 37,000 words.",
        "We also use PKUC to extract and evaluate typical context cue words around person, location and organization names.",
        "Our experiments start from a “seed” P-Name character set:",
        "and a set of 60 context cue words."
      ]
    },
    {
      "heading": "4.1 Obtaining P-Names from the Internet",
      "text": [
        "We perform the bootstrapping process as discussed in Section 2 to extract P-Names from the Internet, and stopped after about 650 iterations.",
        "We manually count the number of correct P-Names obtained at the end of every 65-iterations.",
        "We also use the first 100,000 P-Names found at the end of the bootstrapping process as the ground truth to compute the accuracy of P-Name identification.",
        "Figure 3 presents the results of the P-Name extraction process.",
        "From the figure, we can see that as we increased the number of iterations, the number of P-Names obtained also increased proportionally.",
        "This demonstrates that our bootstrapping process is consistent.",
        "We also observe that the system is able to maintain a high accuracy of over 85% even when the number of P-Names found approaches 100,000.",
        "This demonstrates that our method is effective."
      ]
    },
    {
      "heading": "4.2 Extracting P-Names from MET-2 set",
      "text": [
        "We use MET-2 test corpus to test the effectiveness of our approach to identify P-Names from new texts as discussed in Section 3.",
        "We consider a P-Name as correctly extracted only when every of its character are correctly identified.",
        "The results are presented in Table 1.",
        "The results show that we are able to achieve a recall of over 95% and precision of close to 90%.",
        "The results are encouraging as we did not use the training resource of MET-2 corpus to train the system, which is expected to lead to higher accuracy.",
        "As a by-product of the PN-Finder, we obtained a large set of context words.",
        "We found that we can use these context words to correctly classify about 25% of the extracted P-Names in MET-2 test set into person names or part of location or organization names using the method described in Section 2.2.",
        "The employing of context words to classify P-Names is mainly to confirm more P-Names and P-Name characters."
      ]
    },
    {
      "heading": "4.3 Contributions of PN-Finder to a Generic NE Recognition Module",
      "text": [
        "The most important contribution of PN-Finder is that it can be used to improve the performance of a generic Chinese named entity recognizer as discussed in Chua and Liu (2002).",
        "Here, we conducted several trials by using the PN-Finder to extract a different number of P-Names.",
        "We use the first 100,000 P-Names found by the PN-Finder, together with the pattern rules in the general named entity recognizer, to conduct a baseline test.",
        "This test merely performs direct table lookup to locate all possible P-Names.",
        "Table 2 lists the performance of the general NE recognition system by using an increasing number of P-Names found by the PN-Finder, together with the use of the confidence statistics, context words obtained from the current sets of P-Names and pattern rules.",
        "The results indicate that as we increase the number of P-Names found by the PN-Finder, the performance of the general NE recognition system is improved steadily until it reaches over 92% in average F1 value."
      ]
    },
    {
      "heading": "5 Conclusion and Future Work",
      "text": [
        "The presence of P-Names brings more ambiguities to Chinese word segmentation and general Chinese named entity recognition.",
        "However, there is a dearth of annotated corpus for extracting and classifying P-Names.",
        "To cope with the problem of sparse training resources, this paper presents a bootstrapping module to identify P-Names and classify them into parts of named entitites if possible.",
        "The PN-Finder could also contribute to general Chinese named entity recognition and achieve promising performance on the MET-2 test corpus.",
        "Currently, we use only a single word as the context, more context could be considered in the future research.",
        "We also aim to extend this method to extract organization names from Chinese documents obtained from the Internet."
      ]
    }
  ]
}
