{
  "info": {
    "authors": [
      "Charles Schafer",
      "David Yarowsky"
    ],
    "book": "Conference on Computational Natural Language Learning CoNLL",
    "id": "acl-W02-2026",
    "title": "Inducing Translation Lexicons Via Diverse Similarity Measures and Bridge Languages",
    "url": "https://aclweb.org/anthology/W02-2026",
    "year": 2002
  },
  "references": [
    "acl-N01-1020",
    "acl-P00-1027",
    "acl-P99-1067"
  ],
  "sections": [
    {
      "heading": "Abstract",
      "text": [
        "This paper presents a method for inducing translation lexicons between two distant languages without the need for either parallel bilingual corpora or a direct bilingual seed dictionary.",
        "The algorithm successfully combines temporal occurrence similarity across dates in news corpora, wide and local cross-language context similarity, weighted Levenshtein distance, relative frequency and burstiness similarity measures.",
        "These similarity measures are integrated with the bridge language concept under a robust method of classifier combination for both the Slavic and Northern Indian language families."
      ]
    },
    {
      "heading": "1 Lexicon Induction via Bridge Languages",
      "text": [
        "The explosive growth of the web in the past 8 years has yielded a corresponding growth in the number of world languages for which text is now available on-line.",
        "Our laboratory alone has been able to acquire 0(50,000)-0(100,000,000) words in each of 60 different languages, and increasing quantities of electronic text can readily be found in over 100 world languages.",
        "As computers and the internet grow ubiquitous, this trend is extending more and more to small linguistic communities.",
        "Universal access to this newly available wealth of information is an important goal, motivating interest in such applications as text glossing, cross-language information retrieval, and ultimately in machine translation.",
        "An essential component of each of these applications is the translation lexicon.",
        "We would like to develop such a resource between English and each of the languages for which data is available on the Internet.",
        "Yet from the perspectives of machine translation and machine learning, the problem is daunting, particularly if treated as learning tasks between k independent language pairs.",
        "Fortunately, however, languages are not unrelated, and tend to cluster into families and subfamilies with intra-group affinities that can be exploited.",
        "Mann and Yarowsky (2001) first proposed the use of these familial affinities for translingual lexicon induction using bridge languages.",
        "In particular, they decomposed the process of translation between two languages such as Serbian to English, into a two-step process utilizing another language in the Slavic family such as Czech, for which a sufficiently large and detailed translation lexicon to English is available.",
        "Thus: P(EnglishISerbian) = P(EnglishICzech) x P (Czech I Serbian) And similarly for any language Li sufficiently close to Czech:",
        "Figure 2 illustrates the paradigm of using a bridge language to create a set (ordered by string distance) of candidate English translations for a Serbian word.",
        "In Mann and Yarowsky (2001) the",
        "process of intrafamily translation was handled by weighted string distance models of cognate similarity with a probabilistic representation of common intrafamily orthographic transformations.",
        "These models were iteratively reestimated using an Expectation-Maximization algorithm (Ristad and Yanilos 1997).",
        "When intrafamily orthographic shifts are clear and systematic, such models can be quite effective on their own.",
        "In practice, the technique described suffers from the problem of faux amis â€“ false cognates.",
        "For example, Serbian-Czech faux amis such as prazan-prizen and prazan-pazen can outrank the correct but orthographically less similar prazan-prazdny, causing the English bridge pathways to the correct English translations blank and empty to be scored below the incorrect translation paths to favor, grace and patronage.",
        "This paper addresses the above-described model deficiency by proposing, developing and evaluating the use of 7 additional similarity models which successfully capture a set of complementary distributional behaviors.",
        "An algorithm combining them with weighted string distance significantly outperforms the previous bridge language approach on both English-Serbian and English-Gujarati test sets.",
        "2 Resources Our goal was to learn translation lexicons using resources that are available on the internet at no monetary cost.",
        "No seed dictionary is required between English and the language of interest; a sizeable dictionary between the bridge language and English is necessary.",
        "Our work with Serbian involved the use of a Czech-English dictionary initially containing roughly 171K Czech-English pairs, including 54K unique Czech word types and 43K unique English types.",
        "The Hindi-English dictionary contained around 74K pairs.",
        "The Serbian/ Gujarati vocabularies we used were built by extracting all word types from the respective corpora, then filtering out low-frequency words (since our similarity models require reliable corpus statistics) and very short words' (use of string distance to propose cognate candidates for very short words was seen to be unreliable in preliminary experiments).",
        "The corpora used here are composed of news data, the majority of which was downloaded from the internet.",
        "The English corpus contains 192M tokens; Serbian, 12M; Gujarati, 2M.",
        "English was lemmatized using a high-quality lemmatization utility; the Serbian, using minimally supervised morphological analysis as described in Yarowsky and Wicentowski (2000).",
        "Gujarati was not lemmatized.",
        "Where possible, date labels were extracted for news stories.",
        "This resulted in 1690 separate labeled days of news for Serbian and 233 for Gujarati.",
        "For each language task, English news data was marked as originating either locally or non-'Words with length < 5 characters were excluded.",
        "locally with respect to areas where the language is spoken, in order to facilitate computation of date-distributional similarities across both strongly related, same-region news sources (date-local) and a general, worldwide aggregate news corpus (date-all).",
        "3 Translation Similarity Models The algorithm presented here is based on the novel combination of the following 4 categories of similarity models: string similarity, context similarity, date distributional similarity, and similarity of word frequency and burstiness statistics.",
        "Three of these 4 categories are further broken down into individual similarity measures for a total of 8: weighted Levenshtein (string), wide and narrow context, world-news and local-news-based date similarities, and relative frequency, burstiness, and inverse document frequency (IDF) similarities.",
        "The algorithm used for rank-based combination of the individual models is given in Section 4.",
        "The initial set of candidate translation pairs is generated (as in Figure 2) by considering all source-language words within a low, initially-weighted string distance to entries in the given bridge-language-to-English dictionary.",
        "The resulting source-language-to-English candidate pairs are then filtered and ranked by the similarity measures described below:"
      ]
    },
    {
      "heading": "3.1 Weighted Levenshtein Similarity",
      "text": [
        "On the first iteration, Levenshtein string edit distance uses a simple language-independent matrix that assigns dist( Vowel +, Vowel +) and other vowel cluster operations one half the cost of equivalent single consonant substitutions, insertions and deletions.",
        "At the beginning of the 2nd model iteration, the character-distance matrix is reestimated as in Mann and Yarowsky (2001) using the high-confidence output from the 1st iteration as training data.",
        "For each of the top 2000 Serbian-English proposed translation pairs after the 1st iteration, the Serbian word and the Czech bridge words having lowest string distance to it (there might have been multiple possible Czech bridges at several distances) are used as a pair into the training set for learning of edit weights.",
        "Some high probability Serbian-Czech orthographic substitutions that are discovered by this process are:"
      ]
    },
    {
      "heading": "3.2 Context Similarity",
      "text": [
        "We generate bag-of-words context vectors for both wide (radius 10) and narrow (radius 1) windows surrounding each word in our corpora, for both English and the source language (Serbian, Gujarati).",
        "The source language vectors are then translated, using the current iteration's noisy translation lexicon, into English.",
        "The initial lexicon is generated by taking the Czech-English bridge dictionary, computing the set of low-edit-distance Serbian-Czech word pairs, and treating the resulting expansion of Serbian-(via Czech)-English word pairs as an initial noisy pair space.",
        "Subsequent iterations utilize the translation lexicons induced in the previous training iteration.",
        "This technique is similar to the one presented in Rapp (1999), which uses the concept of cross-language vector similarity to identify English translations of German words.",
        "However, under Rapp's method context vectors are translated using roughly 16,000 word pairs from an existing German-English dictionary.",
        "Fung (1998) used an approach similar to Rapp's, also starting from a large (20,000 entries) preexisting bilingual dictionary (Chinese-English).",
        "Our approach has the important distinction of utilizing absolutely no translation lexicons from the test language to or from any other language, making it suitable for lower density languages.",
        "vectors for each word in the Serbian and English vocabularies, with frequencies smoothed across adjacent dates to compensate for lags in reportage and to ameliorate sparse data problems.",
        "We compiled date distributions for each English word using both worldwide (all English date-labeled news) and local (English news from Serbia) news sources.",
        "Given the relatively small size of the local English corpus, incorporated both of these date-distributional models (date-local and date-all) into our framework for increased robustness.",
        "The example in Figure 4 shows graphically how a (correctly) hypothesized translation pair of nezavisnost-independence has greater synchronization in their date distributions, and hence a higher date-similarity score, than a competing incorrect candidate pair of nezavisnost-freedom, which has higher-ranked weighted-Levenshtein similarity in Table 5, but ranks lower in the final combined similarities in part due the contribution of date-similarity.",
        "comparing Serbian context vectors for the test word nezavi-nost with two candidate English translations based on the previous iteration's translation model.",
        "The correct translation of nezavinost (independence) exhibits greater cosine similarity to the nezavisnost' vector than does the competing alternative freedom."
      ]
    },
    {
      "heading": "3.3 Date-distributional Similarity",
      "text": [
        "One of the advantages of using news data as a corpus is that world and regional events (such as plane crashes, earthquakes, coups, assassinations, etc.)",
        "tend to be reported in parallel in multiple languages at reasonably close date synchronization (typically no more than 12 days' variation in the reporting of any one story, although followup references persist and degrade over time).",
        "Thus both Serbian and English terms can be represented as language-independent frequency vectors subscripted by date over a several-year window.",
        "We construct such term",
        "for the correct translation pair nezavisnost-independence (sim=0.74) and the incorrect pair nezavisnost-freedom (sim=0.42).",
        "In both cases the normalized Serbian word probability is on the positive y-axis, English on the negative y-axis."
      ]
    },
    {
      "heading": "3.4 Relative Frequency Similarity",
      "text": [
        "On average, a word and its translation are likely to have similar relative frequencies in the corpora of their respective languages 2.",
        "Because polysemous usage for one language's term may double or triple its observed raw frequency, modest frequency variations are expected.",
        "However, this measure is very useful for ruling out hypothesized pairings exhibiting several orders of magnitude difference in relative fre-2Especially when computing frequency similarity on lemmas as is done here.",
        "Although individual inflected word frequencies are quite sensitive to the inflectional fertility of the language, the total lemma frequencies for equivalent concepts should be much more consistent across languages.",
        "quency.",
        "A simple ratio of logs of frequencies proves to correlate well with translational compatibility and was found to an improvement under the rank-based combination model.",
        "for the Serbian word hvaliti.",
        "Its correct translation (in bold) scores higher than alternate hypotheses such as calibre/N and class/N.",
        "Although they outscore laud/V on weighted string similarity, their observed 13 and 989 relative frequencies are significantly lower and higher (respectively) than the 62 expected for hvaliti's translation."
      ]
    },
    {
      "heading": "3.5 Burstiness Similarity and Inverse Document Frequency",
      "text": [
        "Church and Gale (1995) describe several related measures of a word's tendency towards contagious distributions, such as illustrated in Figure 5.",
        "They include the P21(w) measure of adaptability (P(fu, >= 21f,, > 1)) and standard Inverse Document Frequency (IDF).",
        "We used the ratio of IDF's as one of the similarity measures.",
        "Given the high variability of document lengths in the corpus, we also defined and utilized a variant measure R over a moving window of H=200 words:"
      ]
    },
    {
      "heading": "3.6 Use of Additional Bridge Languages",
      "text": [
        "Use of a second bridge language within the source language's family can expand the coverage and/or precision of the bridge dictionary.",
        "We investigated",
        "iti over competitors calibre/N, quarter/V and chop/V which have a higher weighted Levenshtein score.",
        "the effect on performance of adding Bulgarian as a second bridge from Serbian to English, which increased accuracy by a relatively consistent by 5-"
      ]
    },
    {
      "heading": "4 Combining Similarity Measures",
      "text": [
        "Weighted Levenshtein distance initially proposes a set of candidate translation pairs.",
        "For each pair in this set, the above-described similarity values are computed.",
        "Specifically, the following 8 similarity variants are used: weighted Levenshtein distance (converted to a similarity, i.e., an increasing function of relatedness), wide (radius 10) bag-of-words context similarity, narrow (radius 1) context similarity, local news date distribution similarity, all news date similarity, relative frequency (RF) similarity, inverse document frequency (IDF) similarity, and burstiness ()) similarity.",
        "These individual models are integrated into a single similarity function using the method of rank-based combination.",
        "We have observed in previous studies that combining ranks rather than raw scores is more robust and accurate when scores have different dynamic ranges, as they do here.",
        "The procedure is as follows for each word sa in the Serbian vocabulary (For Gujarati, upon which no lemmatization was performed, Step 1 is omitted.",
        "):",
        "1.",
        "Part-of-Speech (POS) Consistency: When ranking translation pairs, we imposed a strong bias in favor of compatible coarse-grained parts of speech (noun, verb, adjective).",
        "Each Serbian word is assigned a POS via morphological analysis, and each English translation candidate with a dictionary POS that does not match are given a score penalty sufficient to rank them below POS-compatible candidates, but not exclude them (given possible gaps and errors in POS assignment).",
        "2.",
        "Ranking: For each similarity measure S, the English candidates are sorted in decreasing order by similarity score.",
        "The N English words in this sorted list are assigned counts starting at 0 for the first list item, through N â€“ 1 at the last item.",
        "Each English word, eb, having count value c is assigned nor",
        "malized rank rr arm (Sa, eb, S) = c/N.",
        "Where there are tied similarity values at list positions i. J, each tied word is given normalized rank rr arm (sa, eb, S) (ci + cj)/N.",
        "3.",
        "Scoring: Each similarity model S1..S8 has an",
        "associated weight (A1..As) (see Figure 6 for details).",
        "For each English word eb, the rank-based combination score is then computed:",
        "Table 5 illustrates the independent performance of the different similarity measures over three Serbian and one Gujarati example test words.",
        "Each list is sorted in rank order by descending similarity score.",
        "Additional iterations proceed by retraining the weighted string and narrow/wide context, as described above, using the translation pairs that rank highest on the previous iteration's combined score as initial training data for the next iteration."
      ]
    },
    {
      "heading": "5 Evaluation",
      "text": [
        "Three primary evaluation measures are employed in this study.",
        "The first is exact match accuracy of the first choice translation candidate.",
        "Another is the percent of cases where a correct English translation is ranked somewhere in the top k hypothesized answers.",
        "The third is median position of the per-word highest-ranked correct translation in the system output list.",
        "The latter is useful and appropriate because many applications, including cross-language information retrieval and the seeding of alignment lexicons for statistical machine translation, can tolerate some noise in the lexicon, and we want a way to judge how often there is a correct translation close enough to the top of the ranked output to be use-ful.The tables that follow provide a basis for making such a judgment.",
        "Another issue in evaluation is the accuracy and completeness of the translation lexicon used for scoring.",
        "If valid translations are omitted from the gold-standard \"truth\" set for whatever reason, then systems will be penalized for picking valid answers including a synonym or alternate translation not in the truth list.",
        "In an effort to gauge the impact of these truth-set gaps, a second evaluation was performed on a small, randomly selected set of Serbian and Gujarati test words in which a much larger comprehensive hard-copy dictionary (Serbian) or a native speaker (Gujarati) was used to identify additional valid translations.",
        "Under this more exhaustive evaluation standard a translation candidate is considered correct if it is either listed in the larger dictionary, is an English synonym of any of the listed truth words, or (for Gujarati) the native speaker judges the words to be synonymous.",
        "Serbian exact-match results from both automatic scoring on the full system output and automatic+paper-dictionary scoring on the random subset (scaled to estimate true performance on the full data set) are shown in Figure 7 and Table 3 (also including Gujarati).",
        "For many applications, such as generating new candidates for statistical MT alignment and translation models, appearance in an n-best pool of candidates may be as functionally useful as only 1-best exact matches to the limited truth set.",
        "This in-n-best accuracy is also given in Table 3.",
        "Finally, Table 4 shows the performance improvement over string distance models yielded by the additional similarity models described in this paper, for the clear case where a correct English translation is known to be in the proposed candidate set (on the basis of the online Serbian-English truth dictionary).",
        "As the table shows, for Serbian-English via the Czech bridge, a 9% improvement in exact-match accuracy over the Mann & Yarowsky (2001) trained string distance bridge model is realized in the strongest rank-based combination system.",
        "Results of ablation experiments showing the contribution of each class of similarity model are presented in Figure 8."
      ]
    },
    {
      "heading": "6 Conclusion",
      "text": [
        "This paper has presented an original technique for inducing translation lexicons via combination of iteratively trained similarity measures.",
        "Joint modeling of such a large space of 8 diverse translation-candidate similarity measures is novel and makes effective use of the independence exhibited by several of the evidence sources.",
        "In contrast to previous studies such as Fung (1998) and Rapp (1999) that have utilized large (16,000-20,000 word) dictionary subsets as functionally necessary seeds to their context-similarity models, the methods presented here require no translation lexicons from the test language to or from any other language.",
        "These methods, then, address vocabulary learning for resource limited languages such as Serbian and Gujarati.",
        "By taking all necessary supervision from unannotated monolingual texts and 3rd-language dictionary resources, these methods offer great promise for the automatic learning of minority language translation lexicons.",
        "answer appears in the top k of the system's ranked list.",
        "Note that in a significant percentage of the time (26-35%) a correct answer is not possible because no valid translation pair had a bridge word within a minimal Levenshtein threshhold to the given (Czech or Hindi) bridge dictionary.",
        "This number can be reduced by either augmenting the bridge language dictionary, adding additional bridge languages or both.",
        "Evaluation is based on a randomly selected subset scored using exact-match agreement of each hypothesis with translations in the online+paper dictionaries as in Figure 7.",
        "exact-match scoring over an online test dictionary, and manually assisted scoring that also considers an answer correct if it appears in a larger paper dictionary or is a direct synonym of an entry in either dictionary.",
        "X-axis is words covered in test vocabulary (sorted by decreasing system confidence, i.e., normalized rank sum of word's top answer).",
        "Vocabulary size is roughly 4500 for online-dictionary scoring, and extrapolated from a randomly selected 60-word test sample for manually-assisted online+paper dictionary scoring."
      ]
    }
  ]
}
