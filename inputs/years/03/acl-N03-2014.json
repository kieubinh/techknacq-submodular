{
  "info": {
    "authors": [
      "Abraham Ittycheriah",
      "Lucian Vlad Lita",
      "Nanda Kambhatla",
      "Nicolas Nicolov",
      "Salim Roukos",
      "Margo Stys-Budzikowska"
    ],
    "book": "Human Language Technology Conference and Meeting of the North American Association for Computational Linguistics – Short Papers",
    "id": "acl-N03-2014",
    "title": "Identifying and Tracking Entity Mentions in a Maximum Entropy Framework",
    "url": "https://aclweb.org/anthology/N03-2014",
    "year": 2003
  },
  "references": [
    "acl-P02-1060",
    "acl-W97-0319",
    "acl-W98-1118"
  ],
  "sections": [
    {
      "text": [
        "label , nanda , nicolas , roukos , smll@us ibm.",
        "com, *llita@cs cmu edu"
      ]
    },
    {
      "heading": "Abstract",
      "text": [
        "We present a system for identifying and tracking named, nominal, and pronominal mentions of entities within a text document.",
        "Our maximum entropy model for mention detection combines two preexisting named entity taggers (built to extract different entity categories) and other syntactic and morphological feature streams to achieve competitive performance.",
        "We developed a novel maximum entropy model for tracking all mentions of an entity within a document.",
        "We participated in the Automatic Content Extraction (ACE) evaluation and performed well.",
        "We describe our system and present results of the ACE evaluation."
      ]
    },
    {
      "heading": "1 Introduction",
      "text": [
        "We present a system for identifying entities in text.",
        "Entities are groups of mentions where mentions are textual references to objects.",
        "Mentions have one of five types (person, organization, geopolitical entity, location, facility) and can be named (as in standard Named Entity (NE) research), nominal and pronominal - the latter dimension is called the level of a mention.",
        "Additionally, mentions can be generic or specific.",
        "We break the original task into mention detection (finding all mentions in the text and their type, level and genericity) and mention tracking (combining mentions into groups of references to the same object in the document).",
        "Our work is motivated by the requirements of a NIST-run evaluation on Automatic Content Extraction (ACE, 2002) where the goal is to build systems that detect entities (groups of mentions), relations among them and events in which they participate.",
        "Our team took part in the Entity detection track.",
        "The ACE task is inherently different and arguably harder than traditional named entity recognition, because of the complexity involved in extracting non-named mentions and chaining them together with named mentions.",
        "We investigate maximum entropy models for both tasks.",
        "For mention detection we use a maximum entropy framework for learning semantic trees' (corresponding to the mentions) combining as features the output of two preexisting statistical NE taggers.",
        "These taggers have been trained on different corpora using different categories (using 31 and 3 categories respectively).",
        "In Section 2 we describe our mention detection component.",
        "Section 3 presents a novel approach for deciding when a mention will or will not be chained with previously created groups of mentions.",
        "Section 4 gives the results of our system from the last ACE evaluation."
      ]
    },
    {
      "heading": "2 Mention Detection",
      "text": [
        "We use a maximum entropy semantic parser for detecting mentions.",
        "The labels of the tree nodes correspond to the combination of type, level and genericity, giving rise to 30 = 5 x 3 x 2 categories for the learning framework.",
        "We had two preexisting statistical NE taggers (Hmm and WINNOW) built with other applications in mind.",
        "Our strategy was to combine the hypotheses of the existing NE taggers (using their original models trained on different training data and with different labels) in a MaxEnt framework as well as use additional syntactic and semantic information.",
        "The underlying semantic parser (Ratnaparkhi, 1999) works in three stages: POS tagging, chunking and structure building.",
        "During chunking (similar to bottom up parsing) the next level of constutuent structure is discovered.",
        "During structure building the rest of the tree is built.",
        "All decisions are modeled using Maximum Entropy models.",
        "The nature of mention detection puts most burden on the chunking model.",
        "The chunking model features include: unigrams of current word (w0), bigrams in w_1, w0, w+1, trigrams in w_2, w – i wo, w+1, w+2, unigrams, bigrams, trigrams on combinations of words and their POS tags in",
        "2 From an engineering perspective the particular way we take diverse information into acount is by using multiple synchronized streams as input to the MaxEnt semantic parser.",
        "[ 0, +11 window, the previous label, people and location suffixes.",
        "As additional features we used unigrams, bigrams and trigrams on the output of two models.",
        "The first is from an Hmm-based system implementing back-off strategies as in BBN's NYMBLE system (Bikel et al., 1999).",
        "It uses 31 categories and is trained on a large corpus of 1.5 million words.",
        "The system is developed as a component of a question answering system (Ittycheriah, 2001).",
        "The second system uses a generalized WINNOW approach (Zhang et al., 2002).",
        "It takes additional features: POS tags, lists of known locations, organizations, and person names.",
        "It is trained on m uc7 data and a subset of the above corpus for three common classes: person, location and organization.",
        "Additional streams we used were: flags, gazetteers, chunk, left corner and WordNet: flags specify capitalization patterns (Bikel et al., 1999; Borthwick et al., 1998; Zhou & Su, 2002); the gazetteer stream indicates presence of a word in lists; chunk states the label of the mother node of each preterminal in the parse tree3; left corner specifies whether the current word is inside an NP and the identity of the leftmost leaf if it has the tag DT (determiner); WordNet specifies whether triggers have fired for the five mention types.",
        "Here is an example sentence with its corresponding streams:"
      ]
    },
    {
      "heading": "3 Mention Tracking",
      "text": [
        "Mention tracking is the process of recognizing mentions as belonging to an entity.",
        "We used a statistical approach for tracking mentions of an entity in a document.",
        "Mentions are scored pairwise by a relevancy score and then greedily clustered together into a chain representing a single entity.",
        "Resolving pronoun mentions to their antecedents is a classic NLP problem (Hobbs, 1976; Ge, 2000; Mitkov, 2002).",
        "A method similar to ours for merging templates in the muc-6 task has been described by (Kehler, 1997).",
        "This work differs from the previous research in reference resolution in three respects: (1) instead of a restrictive search of antecedents of a given mention, we apply a greedy methodology of symmetric pairwise comparison of all link probabilities (2) we track nominal, pronominal and named mentions of different semantic types, (3) a large corpus of mentions has enabled us to produce a trainable system for mention tracking.",
        "Our approach is based on two elements (1) the relevancy model introduced in (Ittycheriah, 2001) for question answering and (2) a greedy pairwise linking strategy.",
        "In the current application of the model, we seek to link the cur",
        "where the binary-valued 1 is either 'linked' or '-'linked'.",
        "The algorithm operates on the mentions in document order and from the view of each mention there are:",
        "• partially formed clusters to the left, r • free, unlabeled mentions to the right, R.",
        "The algorithm4 for linking the current mention, in, is as follows:",
        "Separate thresholds were established for name, nominal, and pronoun merging, as well as the number of entities considered on the left and the number of mentions to the right.",
        "The model is built on binary-valued features, which are defined as functions of the form f (link decision, m, m3).",
        "The features in our model can be grouped into proxies relying on similarity (such as exact and partial matches, overlapping word tokens between mention heads), distance measures (in terms of the word and sentence number between the two mentions, and string edit distance), text location (quantized sentence number containing a mention), length (e.g. number of words within a mention head), frequency counts (number of times a mention head occurred within a given document) as well as syntactic (e.g. appositive) and semantic features (WordNet, semantic entity type, definiteness proxies).",
        "A detailed description of the algorithm along with incremental results with different features are presented in (Ittycheriah-Stys, 2003)."
      ]
    },
    {
      "heading": "4 Results",
      "text": [
        "In this section we present results of our participation in the September 2002 NIST Automatic Content Extraction",
        "evaluation (ACE, 2002).",
        "The evaluation measured the performance of systems on entity and relation extraction from newspaper and news wire articles, and broadcast news segments.",
        "We report the F-measure of mention detection and a NIST-defined value metric for entity detection (ACE, 2002) which computes a weighted cost of the misses, false alarms and errors.",
        "The cost is normalized and subtracted from 1 to arrive at a normalized \"value\", with 0 corresponding to no output and 1 corresponding to perfect entity detection.",
        "We present results only of our site's participation as per NIST guidelines for the evaluation.",
        "Our training set (provided by NIST) comprised of 417 documents, 191,501 words, 30,492 mentions and 12,630 entities and the evaluation set contained 186 documents, 104,877 words, 10,665 mentions and 4396 entities including ASR and OCR versions of broadcast news and newswire documents.",
        "We report results only on the original (not degraded) text documents.",
        "Table 1 shows F-measure and ACE value for our submission system (\"All streams\").",
        "We also show results with four other mention detection models trained without the Hmm stream (\"w/o Hmm\"), the Winnow stream (\"w/o WINNOW\"), the left corner of NPs (\"w/o Lc\"), and without the HMM, WINNOW and LC streams (\"w/o HMM-WINNOWLC\").",
        "For all experiments, we used the same mention tracking model described in Section 3.",
        "We achieved competitive scores (both F-measure and ACE value) for this task.",
        "As indicated by the results in Table 1, we were able to obtain a higher overall performance by using all streams.",
        "The Winnow NE tagger is very good at detecting person names, which the ACE value metric weights highly.",
        "This may account for the relatively sharp decrease in ACE value for the model without the Winnow stream compared to the drop in F-measure, which does not assign weights to categories.",
        "Our results suggest that our model was able to use the complementary information provided by the different streams.",
        "In particular, the Named Entity extractions of the two preexisting NE taggers were complimentary and helped the overall system."
      ]
    },
    {
      "heading": "5 Conclusions",
      "text": [
        "We have presented a system for identifying named, nominal, and pronominal mentions of entities in text and tracking them within documents.",
        "We participated in the NIST Automatic Content Extraction evaluation and performed well.",
        "For mention detection, we pulled together two existing named entity taggers trained with different categories and combined them with other syntactic and lexical sources of information using a maximum entropy framework for building semantic trees.",
        "Combining the complementary information provided by the preexisting taggers helped us rapidly achieve a high F-measure.",
        "For mention tracking, we proposed a novel statistical technique for tracking named, nominal and pronominal mentions of an entity within a document.",
        "Using a unified trainable approach helped us perfom well in the evaluation.",
        "Ongoing work includes improving the mention detection and mention tracking by adding morphological, syntactic (derived from parse trees) and semantic (e.g. WordNet) information streams, and extracting relations between the detected entities using statistical models."
      ]
    }
  ]
}
