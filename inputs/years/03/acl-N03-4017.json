{
  "info": {
    "authors": [
      "Theresa Wilson",
      "David R. Pierce",
      "Janyce Wiebe"
    ],
    "book": "Human Language Technology Conference and Meeting of the North American Association for Computational Linguistics – Demonstrations",
    "id": "acl-N03-4017",
    "title": "Identifying Opinionated Sentences",
    "url": "https://aclweb.org/anthology/N03-4017",
    "year": 2003
  },
  "references": [
    "acl-P02-1022",
    "acl-P99-1032",
    "acl-W02-1028"
  ],
  "sections": [
    {
      "heading": "1 Introduction",
      "text": [
        "Natural language processing applications that summarize or answer questions about news and other discourse need to process information about opinions, emotions, and evaluations.",
        "For example, a question answering system that could identify opinions in the news could answer questions such as the following: Was the 2002 presidential election in Zimbabwe regarded as fair?",
        "What was the worldwide reaction to the 2001 annual U.S. report on human rights?",
        "In the news, editorials, reviews, and letters to the editor are sources for finding opinions, but even in news reports, segments presenting objective facts are often mixed with segments presenting opinions and verbal reactions.",
        "This is especially true for articles that report on controversial or “lightning rod” topics.",
        "Thus, there is a need to be able to identify which sentences in a text actually contain expressions of opinions and emotions.",
        "We demonstrate a system that identifies opinionated sentences.",
        "In general, an opinionated sentence is a sentence that contains a significant expression of an opinion, belief, emotion, evaluation, speculation, or sentiment.",
        "The system was built using data and other resources from a summer workshop on multi-perspective question answering (Wiebe et al., 2003) funded under ARDA NRRC.1 'This work was performed in support of the Northeast Regional Research Center (NRRC) which is sponsored by the Advanced Research and Development Activity in Information Technology (ARDA), a U.S. Government entity which sponsors and promotes research of import to the Intelligence Community which includes but is not limited to the CIA, DIA, NSA, NINIA, and NRO."
      ]
    },
    {
      "heading": "2 Opinion Recognition System",
      "text": []
    },
    {
      "heading": "2.1 System Architecture",
      "text": [
        "The opinion recognition system takes as input a URL or raw text document and produces as output an HTML version of the document with the opinionated sentences found by the system highlighted in bold.",
        "Figure 2.1 shows a news article that was processed by the system.",
        "When the opinion recognition system receives a document, it first uses GATE (Cunningham et al., 2002) (modified to run in batch mode) to tokenize, sentence split, and part-of-speech tag the document.",
        "Then the document is stemmed and searched for features of opinionated language.",
        "Finally, opinionated sentences are identified using the features found, and they are highlighted in the output."
      ]
    },
    {
      "heading": "2.2 Features",
      "text": [
        "The system uses a combination of manually and automatically identified features.",
        "The manually identified features were culled from a variety of sources, including (Levin, 1993) and (Framenet, 2002).",
        "In addition to features learned in previous work (Wiebe et al., 1999; Wiebe et al., 2001), the automatically identified features include new features that were learned using information extraction techniques (Riloffand Jones, 1999; Thelen and Riloff, 2002) applied to an unannotated corpus of world news documents."
      ]
    },
    {
      "heading": "2.3 Evaluation",
      "text": [
        "We evaluated the system component that identifies opinionated sentences on a corpus of 109 documents (2200 sentences) from the world news.",
        "These articles were annotated for expressions of opinions as part of the summer workshop on multi-perspective question answering.",
        "In this test corpus, 59% of sentences are opinionated sentences.",
        "By varying system settings, the opinionated sentence recognizer may be tuned to be very precise (91% precision), identifying only those sentences it is very sure",
        "are opinionated (33% recall), or less precise (82% precision), identifing many more opinionated sentences (77% recall), but also making more errors."
      ]
    }
  ]
}
