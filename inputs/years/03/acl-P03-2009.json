{
  "info": {
    "authors": [
      "T. Daniel Midgley"
    ],
    "book": "Annual Meeting of the Association for Computational Linguistics – Student Research Workshop",
    "id": "acl-P03-2009",
    "title": "Discourse Chunking: A Tool in Dialogue Act Tagging",
    "url": "https://aclweb.org/anthology/P03-2009",
    "year": 2003
  },
  "references": [
    "acl-J00-3003",
    "acl-J95-2003",
    "acl-W02-0218"
  ],
  "sections": [
    {
      "text": [
        "applied to the DA tagging task.",
        "Their use amounts to a separate tagging task of its own, with the concomitant time-consuming corpus annotation.",
        "In this work, I present the results from a DA tagging project that uses a case-based reasoning system (after Kolodner 1993).",
        "I show how the results from this DA tagger are improved by the use of a concept I call \"discourse chunking.\"",
        "Discourse chunking gives information about the patterns of topic raising and negotiation in dia"
      ]
    },
    {
      "heading": "Abstract",
      "text": [
        "Discourse chunking is a simple way to segment dialogues according to how dialogue participants raise topics and negotiate them.",
        "This paper explains a method for arranging dialogues into chunks, and also shows how discourse chunking can be used to improve performance for a dialogue act tagger that uses a case-based reasoning approach."
      ]
    },
    {
      "heading": "1 Dialogue act tagging",
      "text": [
        "A dialogue act (hereafter DA) is an encapsulation of the speaker's intentions in dialogue – what the speaker is trying to accomplish by saying something.",
        "In DA tagging (similar to part-of-speech tagging), utterances in a dialogue are tagged with the most appropriate speech act from a tagset.",
        "DA tagging has application in NLP work, including speech recognition and language understanding.",
        "The Verbmobil-2 corpus was used for this study, with its accompanying tagset, shown in Table 1.1.",
        "Much of the work in DA tagging (Reithinger, 1997; Samuel, 2000; Stolcke et al.",
        "2000; Wright, 1998) uses lexical information (the words or n-grams in an utterance), and to a lesser extent syntactic and phonological information (as with prosody).",
        "However, there has traditionally been a lack of true discourse-level information in tasks involving dialogue acts.",
        "Discourse information is typically limited to looking at surrounding DA tags (Reithinger, 1997; Samuel, 2000).",
        "Unfortunately, knowledge of prior DA tags does not always translate to an accurate guess of what's coming next, especially when this information is imperfect.",
        "Theories about the structure of dialogue (for example, centering [Grosz, Joshi, & Weinstein 19951, and more recently Dialogue Macrogame Theory [Mann 2002]) have not generally been",
        "logue, and where an utterance fits within these patterns.",
        "It is also able to use existing DA tag information within the corpus, without the need for separate annotation."
      ]
    },
    {
      "heading": "2 Discourse chunking",
      "text": [
        "In order to accomplish a mutual goal (for example, two people trying to find a suitable appointment time), dialogue participants engage in predictable kinds of activity, structuring the conversation in a coherent way in order to accomplish their goals.",
        "Alexandersson et al.",
        "(1997) have noted that these conversations tend to follow certain patterns, particularly with regard to the way that topics get raised and dealt with: Hello The dialogue participants greet each other.",
        "They introduce themselves, unveil their affiliation, or the institution or location they are from.",
        "Opening The topic to be negotiated is introduced.",
        "Negotiation The actual negotiation, between opening and closing.",
        "Closing The negotiation is finished (all participants have agreed), and the agreed-upon topic is (sometimes) recapitulated.",
        "Good Bye The dialogue participants say good bye to each other.",
        "Within a conversation, the opening-negotiation-closing steps are often repeated in a cyclical pattern.",
        "This work on discourse chunking combines the opening, negotiation, and closing sections into a single chunk.",
        "One reason for this is that these parts of the conversation tend to act as a single chunk; when they appear, they regularly appear together and in the same order.",
        "Also, some of these parts may be missing; a topic of negotiation is frequently brought up and resolved without an explicit opening or closing.",
        "Very often, the act of beginning a topic of negotiation defines the opening by itself, and the act of beginning a new negotiation entails the closing of the previous one.",
        "A slightly simplified model of conversation, then, appears in Figure 2.1.",
        "In this model, participants greet each other, engage in a series of negotiations, and finish the conversation when the goals of the dialogue are satisfied.",
        "These three parts of the conversation are \"dialogue chunks\".",
        "These chunks are relevant from a DA tagging perspective.",
        "For example, the DA tags used in one of these chunks are often not used in",
        "other chunks.",
        "For an obvious example, it would be almost unheard of for the GREET tag to appear in the \"Good Bye\" chunk.",
        "Other DA's (such as FEEDBACK _PO S I T I VE) can occur in any of the three chunks Knowing which chunk we are in, and where we are within a chunk, can facilitate the tagging task.",
        "Within chunks, some patterns emerge.",
        "Note that in the example from the Verbmobil-2 corpus (shown in Table 2.1), a negotiation topic is raised, and dealt with (by an ACCEPT speech act).",
        "Then there follows a sequence of FEEDBACK PO S I T I VE s as the negotiation topic winds down.",
        "This \"winding down\" activity is common at the end of a negotiation chunk.",
        "Then a new topic is raised, and the process continues.",
        "One-word utterances such as \"okay\" or \"yeah\" are particularly problematic in this kind of task because they have rather general semantic content and they are commonly used in a wide range of contexts.",
        "The word \"yeah\" on its own, for example, can indicate acceptance of a proposition, mere Speaker ID Words DA Tag KNT some other time oh SUGGEST actually I see that I have got some free time in like the fifth sixth and seventh of January KNT how does that NOT_CLASSI FIABLE LMT yeah that is fine ACCEPT KNT great so let us do that FEEDBACK_",
        "acknowledgement of a proposition, feedback, deliberation, or a few of these at once (Core & Allen 1997).",
        "In Verbmobil-2, these utterances can be labeled either A C C E P T, FEEDBACK_POSITIVE,BACK – CHANNEL,or REQUEST_ COMMENT.",
        "Without knowing where the utterance appears within the structure of the dialogue, these utterances are very difficult to classify.",
        "Some previous work has used prosody to solve this kind of problem (as with Stolcke 2000).",
        "I propose discourse chunks as an alternative method.",
        "It can pull information from the text alone, without the computational overhead that prosody can entail."
      ]
    },
    {
      "heading": "3 Chunk segmentation",
      "text": [
        "Just where do the discourse chunk boundaries lie?",
        "For this exercise, I have constructed a very simple set of rules to determine chunk boundaries.",
        "These rules come from my observations; future work will involve automatic chunk segmentation.",
        "However, these rules do arise from a principled assumption: the raising of a new topic shows the beginning of a discourse chunk.",
        "Therefore, a speech act that (according to the definitions in Alexandersson 1997) contains a topic or proposition represents the beginning of a discourse chunk.",
        "By definition, only four DA's contain or may contain a topic or proposition.",
        "These are TNT T, EXCLUDE, REQUEST SUGGEST, and SUGGEST."
      ]
    },
    {
      "heading": "3.1 Chunking rules",
      "text": [
        "The chunking rules are as follows:",
        "1.",
        "The first utterance in a dialogue is always the start of chunk 1 (hello).",
        "2.",
        "The first TNTT or SUGGEST or REQUEST _SUGGEST or EXCLUDE in a dialogue is the start of chunk 2 (negotiation).",
        "3.",
        "INIT, SUGGEST, REQUEST_ SUGGEST, or EXCLUDE marks the start of a subchunk within chunk 2.",
        "4.",
        "If the previous utterance is also the start of a chunk, and if it is spoken by the same person, then this utterance is considered to be a continuation of the chunk, and is not marked.",
        "5.",
        "The first BYE is the start of chunk 3 (good",
        "bye).",
        "Items within a chunk are numbered evenly from 1 (the first utterance in a chunk) to 100 (the last), as shown in Table 3.1.",
        "This normalizes the chunk distances to facilitate comparison between utterances."
      ]
    },
    {
      "heading": "4 The case-based reasoning (CBR) tagger",
      "text": [
        "A thorough discussion of this CBR tagger goes beyond the scope of this paper, but a few comments are in order.",
        "Case-based reasoning (Kolodner 1993) is a form of machine learning that uses examples.",
        "In general, classification using a case-based reasoner involves comparing new instances (in this case, utterances) against a database of correctly-tagged instances.",
        "Each new instance is marked with the same tag of its \"nearest neighbour\" (that is, the closest match) from the database.",
        "A k-nearest neighbour approach selects the closest k matches from the database to be committee members, and the committee members \"vote\" on the correct classification.",
        "In this implementation, each committee member gets a vote equal to its similarity to the test utterance.",
        "Different values of k performed better in different aspects of the test, but this work uses k = 7 to facilitate comparison of results.",
        "The choice of features largely follows those of Samuel 2000, and are as follows:",
        "• Speaker change • Word number • Word similarity • n-gram similarity • Previous DA tag and the following two features not included in that study, • 2-previous DA tag",
        "Inclusion of this feature enables more complete analysis of previous DA tags.",
        "Both `previous DA tag' and `2-previous DA tag' features use the \"best guess\" for previous utterances rather than the \"right answer\", so this run allows us to test performance even with incomplete information.",
        "• Discourse chunk tag",
        "Distances for this tag were computed by dividing the larger discourse chunk number from the smaller.",
        "Comparing two \"chunk starter\" utterances would give the highest similarity of 1, and comparing a chunk starter (1) to a chunk-ender (100) would give a lower similarity (.O1).",
        "Not all features are equally important, and so an Evolutionary Programming algorithm (adapted from Fogel 1994) was used to weight the features.",
        "Weightings were initially chosen randomly for each member of a population of 100, and the 10 best performers were allowed to \"survive\" and \"mutate\" their weightings by a Gaussian random number.",
        "This was repeated for 10 generations, and the weightings from the highest performer were used for the CBR tagging runs.",
        "A total of ten stopwords were used (the, of, and, a, an, in, to, it, is, was), the ten most common words from the BNC (Leech, Rayson, & Wilson 2001).",
        "These stopwords were removed when considering word similarity, but not n-gram similarity, since these low-content words are useful for distinguishing sequences of words that would otherwise be very similar.",
        "The database consisted of 59 hand-tagged dialogues (8398 utterances) from the Verbmobil-2 corpus.",
        "This database was also automatically tagged with discourse chunks according to the rules above.",
        "The test corpus consisted of 20 dialogues (2604 utterances) from Verbmobil-2.",
        "This corpus was tagged with correct information on discourse chunks; however, no information was given on the DA tags themselves."
      ]
    },
    {
      "heading": "5 Discussion and future work",
      "text": [
        "Table 5.1 shows the results from two DA tagging runs using the case-based reasoning tagger: one run without discourse chunks, and one with.",
        "To put these results in perspective, human performance has been estimated at about 84% (Stolcke 2000), since human taggers sometimes disagree about intentions, especially when speakers perform more than one dialogue act in the same utterance.",
        "Much of the recent DA tagging work (using 18-25 tags) scores around the mid-fifty to mid-sixty percentiles in accuracy (see Stolcke 2000 for a review of similar work).",
        "This work uses the Verbmobil-2 tagset of 32 tags.",
        "It could be argued that the discourse chunk information, being based on tags, gives the DA tagger extra information about the tags themselves, and thus gives an unfair `boost' to the performance.",
        "At present it is difficult to say if this is the only reason for the performance gains.",
        "If this were the case, we would expect to see improvement in recognition for the four tags that are \"chunk start-ers\", and less of a gain in those that are not.",
        "In the test run with discourse chunks, however, we see across-the-board gains in almost all categories, regardless of whether they begin a chunk or not.",
        "Table 5.2 shows performance measured in terms of the well-known standards of precision, recall, and f-measure.",
        "One notable exception to the upward trend is EXCLUDE, a beginning-of-chunk marker, which performed slightly worse with discourse chunks.",
        "This would suggest that chunk information alone is not enough to account for the overall gain.",
        "Both"
      ]
    },
    {
      "heading": "ACCEPT and FEEDBACK_ POSITIVE improved",
      "text": [
        "slightly, suggesting that discourse chunks were able to help disambiguate these two very similar tags.",
        "Table 5.3 shows the improvement in tagging scores for one-word utterances, often difficult to tag because of their general use and low information.",
        "These words are more likely to be tagged ACCEPT when they appear near the beginning of a chunk, and FEEDBACK PO S I T I VE when they appear nearer the end.",
        "Discourse chunks help their classification by showing their place in the dialogue cycle.",
        "One weakness of this project is that it assumes knowledge of the correct chunk tag.",
        "The test corpus was tagged with the \"right answers\" for the chunks.",
        "Under normal circumstances, the corpus would be tagged with the \"best guess,\" based on the DA tags from an earlier run.",
        "However, the goal for this project was to see if, given perfect information, discourse chunking would aid DA tagging performance.",
        "The performance gains are persuasive evidence that it does.",
        "Ongoing work involves seeing how accurately a new corpus can be tagged with discourse chunks, even when the DA tags are unknown."
      ]
    },
    {
      "heading": "6 Acknowledgements",
      "text": [
        "This work was supported by an Australian Postgraduate Award.",
        "Thanks to Cara MacNish and Shelly Harrison for supervision and advice.",
        "Many thanks to Verbmobil for generously allowing use of the corpus which formed the basis of this project."
      ]
    }
  ]
}
