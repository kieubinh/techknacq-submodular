{
  "info": {
    "authors": [
      "Tim Oates"
    ],
    "book": "Workshop on Learning Word Meaning from Non-Linguistic Data",
    "id": "acl-W03-0609",
    "title": "Grounding Word Meanings in Sensor Data: Dealing With Referential Uncertainty",
    "url": "https://aclweb.org/anthology/W03-0609",
    "year": 2003
  },
  "references": [],
  "sections": [
    {
      "text": [
        "which corresponds to a point in an dimensional sensor group, a conditional probability of the form E , where E denotes the occurrence of some event.",
        "Let E denote the CPF defined over sensor group for event E. The semantics of a CPF clearly depend on the nature of E. Two events that will be of particular importance in learning the meanings of words are: utter-W - the event that word is uttered, perhaps as part of an utterance that refers to some feature of the world denoted by"
      ]
    },
    {
      "heading": "Abstract",
      "text": [
        "We consider the problem of how the meanings of words can be grounded in sensor data.",
        "A probabilistic representation for the meanings of words is defined, a method for recovering meanings from observational information about word use in the face of referential uncertainty is described, and empirical results with real utterances and robot sensor data are presented."
      ]
    },
    {
      "heading": "1 Introduction",
      "text": [
        "hear-W - the event that word is heard We are interested in how robots might learn language given qualitatively the same inputs available to children - natural language utterances paired with sensory access to the environment.",
        "This paper focuses on the sub-problem of learning word meanings.",
        "Suppose a robot has acquired a set of sound patterns that may or may not correspond to words.",
        "How is it possible to separate the words from the non-words, and to learn the meanings of the words?",
        "We assume the robot’s sensory access to its environment is through a collection of primitive sensors organized into sensor groups, where each sensor group is a set of related sensors.",
        "For example, the sensor group might return a single value representing the mean grayscale intensity of a set of pixels corresponding to an object in the visual field.",
        "The sensor group might return two values representing the height and width of the bounding box around the object.",
        "Learning the meanings of words requires a representation for meaning.",
        "We use a representation that we call a conditional probability field (CPF), which is a type of scalar field.",
        "A scalar field is a map of the following form: The mapping assigns to each vector a scalar value .",
        "A conditional probability field assigns to each , The corresponding conditional probability fields are: utter-W - the probability that word will be uttered by a competent speaker of the language to denote the feature of the physical world that is currently sensing (i.e. that results in the current value of ) hear-W - the probability that word will be heard given that is observed In this framework, the meaning of word is simply utter-W .",
        "The last plot in figure 3 shows a CPF defined over that might represent the meaning of the word “gray”.",
        "Grayscale intensities near 128 will be called gray with probability almost one, whereas intensities near 0 and 255 will never be called gray.",
        "Rather, they are “black” and “white” respectively.",
        "Learning the denotation of involves determining the identity of and then recovering utter-W .",
        "The learner does not have direct access to utter-W .",
        "Rather, the learner must gain information about utter-W indirectly, by noticing the sensory contexts in which is used and those in which it is not, i.e. via hear-W .",
        "This problem is difficult due to referential uncertainty.",
        "Even if the utterances the learner hears are true statements about aspects of its environment that are perceptually available, there are are usually many aspects of the environment that might be a given word’s referent.",
        "This is Quine’s “gavagai” problem (Quine, 1960).",
        "The algorithm described in this paper solves a restricted version of the gavagai problem, one in which the denotation of a word must be representable as a CPF defined over one of a set of predefined sensor groups."
      ]
    },
    {
      "heading": "2 A Simplified Learning Problem",
      "text": [
        "Rather than starting with the full complexity of the problem facing the learner, consider the following highly simplified version.",
        "Suppose an agent with a single sensor group, , lives in a world with a single object, , that periodically changes color.",
        "Each time the color changes, a one word utterance is generated describing the new color, which is one of “black”, “white” or “gray”.",
        "In this scenario there is no need to identify because there is only one possibility.",
        "Also, each time a word is uttered there is perfect information about its denotation; it is the current value produced by .",
        "(The notation indicates the value recorded by sensor group when it is applied to object .",
        "This assumes an ability to individuate objects in the environment.)",
        "Therefore, the probability that a native speaker of our simple language will utter to refer to is the same as the probability of hearing given .",
        "This fact makes it possible to recover the form of the CPF for each of the three words by noticing which values of co-occur with the words and applying Bayes’ rule as follows: The maximum-likelihood estimate of the quantity hear-W is simply the number of utterances containing divided by the total number of utterances.",
        "The quantities and hear-W can be estimated using a number of standard techniques.",
        "We use kernel density estimators with (multivariate) Gaussian kernels to estimate probability densities such as these.",
        "The simplified version of the word-learning problem presented in this section can be made more realistic, and thus more complex, by increasing either the number of objects in the environment or the number of sensor groups available to the agent.",
        "Section 3 explores the former, and section 4 explores the latter."
      ]
    },
    {
      "heading": "3 Multiple Objects",
      "text": [
        "When there is no ambiguity about the referent of a word, it is possible to recover the conditional probability field that represents the word’s denotational meaning by passive observation of the contexts in which it is used.",
        "Unfortunately, referential ambiguity is a feature of natural languages that we contend with on a daily basis.",
        "This ambiguity appears to be at its most extreme for young children acquiring their first language who must determine for each newly identified word the referent of the word from the infinitely many aspects of their environment that are perceptually available.",
        "Consider what happens when we add a second object, , to our example domain.",
        "If both objects change color at exactly the same time, though not necessarily to the same color, the learner has no way of knowing whether an utterance refers to the value produced by or .",
        "In the absence of any exogenous information about the referent, the best the learner can do is make a guess, which will be right only of the time.",
        "As the number of objects in the environment increases, this percentage decreases.",
        "Referential ambiguity can also take the form of uncertainty about the sensor group to which a word refers.",
        "Given two objects, and , and two sensor groups, and , a word can refer to any of the following: .",
        "Let denote the fact that is (at least in part) about , and let denote the fact that occurs in .",
        "Then the conditional probability of an utterance containing given the current value, ,",
        "realistic assumption that the learner has a priori knowledge about the sensor group to which a word refers.",
        "This assumption will be relaxed in the following section.",
        "Intuitively, referential ambiguity clouds the relationship between the denotational meaning of a word and the observable manifestations of its meaning, i.e. the contexts in which the word is used.",
        "As we will now demonstrate, it is possible to make the nature of this clouding precise, leading to an understanding of the impact of referential ambiguity on learnability.",
        "Suppose an agent hears an utterance containing word while its attention is focused on the output of sensor group .",
        "(Recall that in this section we are making the assumption that the agent knows that refers to .)",
        "Why might contain ?",
        "There are two mutually exclusive and exhaustive cases: is (at least in part) about , and is chosen to denote the current value produced by ; is not about , and contains despite this fact.",
        "The latter case might occur if, for example, has multiple meanings and the utterance uses one of the meanings of that does not denote a value produced by",
        "produced by can be expressed via equation 1 in figure",
        "1.",
        "Equation 1 is a more formal, probabilistic statement",
        "of the conditions given above under which will contain .",
        "It can be simplified as shown in the remainder of the figure.",
        "The first step in transforming equation 1 into equation 2 is to apply the fact that .",
        "The resulting joint probability is the probability of a conjunction of terms that contains both and , and is therefore 0 and can be dropped.",
        "The remaining two terms are then rewritten using Bayes’ rule.",
        "Finally, three substitutions are made: Simplification then leads directly to equation 2.",
        "Before discussing the implications of equation 2, consider the import of and .",
        "The probability that is about (i.e. ) is the probability that the speaker and the hearer are attending to the same sensory information.",
        "When , there is perfect shared attention, and the speaker always refers to those aspects of the physical environment to which the hearer is currently attending.",
        "When , there is never shared attention, and the speaker always refers to aspects of the environment other than those to which the hearer is currently attending.",
        "The probability that contains even when is not about (i.e. ) is the probability that will be used to refer to some feature of the environment other than that measured by .",
        "There are two reasons why might occur in a sentence that does not refer to : Note that comes into play only when , i.e. when there is less than perfect shared attention between the speaker and the hearer.",
        "The most significant aspect of equation 2 is from the standpoint of learnability.",
        "In our original one-object, one-sensor world there was never any doubt as to the referent of a word, and it was therefore the case that utter-W hear-W .",
        "This equivalence becomes clear in equation 2 by setting and simplifying.",
        "Because it is possible to compute hear-W from observable information via Bayes’ rule, it was possible in that world to recover utter-W rather directly.",
        "However, equation 2 tells us that even in the face of imperfect shared attention (i.e. ) and homonymy (i.e. ) it is the case that hear-W is a linear transform of utter-W .",
        "Moreover, the values of and determine the precise nature of the transform.",
        "To get a better handle on the effects of and on the manifestation of utter-W through hear-W , consider figures 2 and 3.",
        "The last plot in figure 2 shows an example of a conditional probability field utter-W ,which is also a plot of hear-W when .",
        "Figures 2 and 3 demonstrate the effects of varying and on hear-W .",
        "That is, the figures show how varying and affect the information about utter-W available to the learner.",
        "Recall from equation 2 that the conditional probability that word will be heard given the current value pro-ducedby is a linear function of utter-W which has slope and intercept .",
        "When the slope is zero (i.e. ) the speaker and the hearer never focus on the same features of the environment, and the probability of hearing is just the background probability of hearing , independent of the value of .",
        "When the slope is one (i.e. ) the speaker and the hearer always focus on the same features of the environment and so the effect of vanishes.",
        "The observable manifestation of utter-W and utter-W are equivalent.",
        "These two case are shown in the first and last graphs in utter-W is polysemous and one of the meanings that does not refer to is used in the utterance is used to refer to the value produced by for some object other than the one that is the hearer’s focus of attention (e.g. rather than ) figure 2, which contains plots of hear-W over a range of values of for various fixed values of .",
        "Figure 2 makes it clear that decreasing preserves the overall shape of utter-W as observed through hear-W , while squashing it to fit in a smaller range of values.",
        "Increasing diminishes the effect of , which is to offset the entire curve vertically.",
        "That is, the higher the level of shared attention between speaker and hearer, the less the impact of the background frequency of on the observable manifestation of utter-W .",
        "Figure 3, which shows plots of hear-W given a range of values of for various fixed values of , is another way of looking at the same data.",
        "The role of in squashing the observable manifestation of utter-W is apparent, as is the role of in vertically shifting the curves.",
        "Only when is there no information about the form of utter-W in the plot of hear-W .",
        "What does all of this have to say about the impact of and on the learnability of word meanings from sensory information about the contexts in which they are uttered?",
        "As we will demonstrate shortly, if the following expression is true for a given conditional probability field, utter-W , then it is possible to recover that CPF from observable data (i.e. from hear-W The claim is as follows.",
        "If there is both a value produced by that is always referred to as and a value that is never referred to as , one can recover the CPF that represents the denotational meaning of simply by observing the contexts in which is used.",
        "Intuitively, the above expression places two constraints on word meanings.",
        "First, for a word whose denotation is defined over sensor group , it must be the case that some value produced by is (almost) universally agreed to have no better descriptor than ; there is no other word in the language that is more suitable for denoting this value.",
        "Second, there must be some value produced by for which it is (almost) universally agreed that is not the best descriptor.",
        "It is not necessarily the case that is the worst descriptor, only that some other word or words are better.",
        "As equation 2 indicates, hear-W is a linear transform of utter-W with slope and intercept .",
        "If we know two points on the line defined by equation 2 we can determine its parameters, making it possible to reverse the transform and compute the value of utter-W given the value of hear-W .",
        "Because hear-W is a linear transform of utter-W , any value of that minimizes (maximizes) one minimizes (maximizes) the other.",
        "Recall that conditional probability fields map from sensor vectors to probabilities, which must lie in the range [0, 1].",
        "Under the assumption that utter-W takes on the value at some point, such as when , hear-W must be at its minimum value at that point as well.",
        "Let that value be .",
        "Likewise, under the assumption that utter-W takes on the value at some point, such as when , hear-W must be at its maximum value at that point as well.",
        "Let that value be .",
        "These observations lead to the following system of two equations: Recall that the goal of this exercise is to recover utter-W from its observable manifestation, hear-W .",
        "This can finally be accomplished by substituting the values for and given above into equation 2 and solving for utter-W as shown in figure 4.",
        "That is, one can recover the CPF that represents the denotational meaning of a word by simply scaling the range of conditional probabilities of the word given observations so that it completely spans the interval ."
      ]
    },
    {
      "heading": "4 Multiple Sensor Groups",
      "text": [
        "This section considers a still more complex version of the problem by allowing the learner to have more than one sensor group.",
        "Suppose an agent has two sensor groups, and , and that word refers to .",
        "The agent can observe the values produced by both sensor groups, note whether each value co-occurred with an utterance containing , compute both hear-W and hear-W , and apply equation 2 to obtain utter-W and utter-W .",
        "How is the agent to determine that utter-W represents the meaning of and utter-W is garbage?",
        "The key insight is that if the meaning of is grounded in , there will be some values of for which it is more likely that will be uttered than for others, and thus there will be some values for which it is more likely that will be heard than others.",
        "Indeed, our ability to recover utter-W from hear-W is founded on the assumption that there is some value of for which the conditional probability of uttering",
        "is zero and some other value for which that probability is one.",
        "This is not necessarily the case for the conditional probability of hearing given because the level of shared attention between the speaker and the learner, , influences the range of probabilities spanned by hear-W , with smaller values of leading to smaller ranges.",
        "Note that in our simple example with two sensor groups the speaker considers only the value of when determining whether to utter , and the learner considers only the value of when constructing hear-W .",
        "Using the terminology and notation developed in section 3, there is no shared attention between the speaker and the learner with respect to and , and it is therefore the case that and hear-W .",
        "If the exact value of hear-W is known for all ,an obviously unrealistic assumption, it is a simple matter to determine that utter-W cannot represent the meaning of by noting that it is constant.",
        "If utter-W is not constant, then the speaker is more likely to utter for some values of than for others, and the meaning of is therefore grounded in .",
        "As indicated by figure 2, the height of the bumps in the conditional probability field depend on , the level of shared attention, but if there are any bumps at all we know that the meaning of is grounded in the corresponding sensor group and we can recover the underlying conditional probability field.",
        "Under the assumption that the exact value of hear-W can be computed, an agent can identify the sensor group in which the denotation of a word is grounded by simply recovering utter-W for each of its sensor groups and looking for the one that is not constant.",
        "In practice, the exact value of hear-W will not be known, and it must be estimated from a finite number of observations.",
        "That is, an estimate of hear-W will be used to compute an estimate of utter-W .",
        "Even if there is no association between and , and utter-W is therefore truly constant, an estimate of this conditional probability based on finitely many data will invariably not be constant.",
        "Therefore, the strategy of identifying relevant sensor groups by looking for bumpy conditional probability fields will not work.",
        "The problem is that for any given word and sensor group , it is difficult to distinguish between cases in which and are unrelated and cases in which the meaning of is grounded in but shared attention is low.",
        "The solution to this problem has two parts, both of which will be described in detail shortly.",
        "First, the mutual information between occurrences of words and sensor values will be used as a measure of the degree to which hearing depends on the value produced by , and vice versa.",
        "Second, a non-parametric statistical test based on randomization testing will be used to convert the real-valued mutual information into a binary decision as to whether or not the denotation of is grounded in ."
      ]
    },
    {
      "heading": "4.1 Mutual Information",
      "text": [
        "Let denote the mutual information between occurrences of word and values produced by sensor group .",
        "The value of is defined as follows:",
        "Note that is the mutual information between two different types of random variables, one discrete ( ) and one continuous ( ).",
        "In the expression above, the summation over the two possible values of , i.e. hear-W and hear-W, is unpacked, yielding a sum of two integrals over the values of .",
        "Within each integral the value of is held constant.",
        "Finally, recall that is a vector with the same dimensionality as the sensor group from which it is drawn, so the integrals above are actually defined to range over all of the dimensions of the sensor group.",
        "When is zero, knowing whether is uttered provides no information about the value produced by , and vice versa.",
        "When is large, knowing the value of one random variable leads to a large reduction in uncertainty about the value of the other.",
        "Larger values of mutual information reflect tighter concentrations of the mass of the joint probability distribution and thus higher certainty on the part of the agent about both the circumstances in which it is appropriate to utter and the denotation of when it is uttered.",
        "Although mutual information provides a measure of the degree to which and are dependent, to understand and generate utterances containing the agent must at some point make a decision as to whether or not its meaning is in fact grounded in .",
        "How is the agent to make this determination based on a single scalar value?",
        "The next section describes a way of converting scalar mutual information values into binary decisions as to whether a word’s meaning is grounded in a sensor group that avoids all of the potential pitfalls just described."
      ]
    },
    {
      "heading": "4.2 Randomization Testing",
      "text": [
        "Given word , sensor group , and their mutual information , the task facing the learner is to determine whether the meaning of is grounded in .",
        "This can be phrased as a yes-or-no question in the following two ways.",
        "Is it the case that occurrences of and the values produced by are dependent?",
        "Is it the case that hear-W occurrences of and the values produced by are not independent?",
        "The latter question is the form used in statistical hypothesis testing.",
        "In this case the null hypothesis, , would be that occurrences of and the values produced by are independent.",
        "Given a distribution of mutual information values derived under , it is possible to determine the probability of getting a mutual information value at least as large as .",
        "If this probability is small, then the null hypothesis can be rejected with a correspondingly small probability of making an error in doing so (i.e. the probability of committing a type-I error is small).",
        "That is, the learner can determine that occurrences of and the values produced by are not independent, that the meaning of is grounded in , with a bounded probability of being wrong.",
        "We’ve now reduced the problem to that of obtaining a distribution of values of under .",
        "For most exotic distributions, such as this one, there is no parametric form.",
        "However, in such cases it is often possible to obtain an empirical distribution via a technique know as randomization testing (Cohen, 1995; Edgington, 1995).",
        "This approach can be applied to the current problem as follows - each datum corresponds to an utterance and indicates whether occurred in the utterance and the value produced by at the time of the utterance; the test statistic is ; and the null hypothesis is that occurrences of and values produced by are independent.",
        "If the null hypothesis is true, then whether or not a particular value produced by co-occurred with is strictly a matter of random chance.",
        "It is therefore a simple matter to enforce the null hypothesis by splitting the data into two lists, one containing each of the observed sensor values and one containing each of the labels that indicates whether or not occurred, and creating a new data set by repeatedly randomly selecting one item from each list without replacement and pairing them together.",
        "This gives us all of the elements required by the generic randomization testing procedure described above.",
        "Given a word and a set of sensor groups, randomization testing can be applied independently to each group to determine whether it is the one in which the meaning of is grounded.",
        "The answer may be in the affirmative for zero, one or more sensor groups.",
        "None of these outcomes is necessarily right or wrong.",
        "As noted previously, it may be that the meaning of the word is too abstract to ground out directly in sensory data.",
        "It may also be the case that a word has multiple meanings, each of which is grounded in a different sensor group, or a single meaning that is grounded in multiple sensor groups."
      ]
    },
    {
      "heading": "5 Experiments",
      "text": [
        "This section presents the results of experiments in which word meanings are grounded in the sensor data of a mobile robot.",
        "The domain of discourse was a set of blocks.",
        "There were 32 individual blocks with one block for each possible combination of two sizes (small and large), four colors (red, blue, green and yellow) and four shapes (cone, cube, sphere and rectangle).",
        "To generate sensor data for the robot, one set of human subjects played with the blocks, repeatedly selecting a subset of the blocks and placing them in some configuration in the robot’s visual field.",
        "The only restrictions placed on this activity were that there could be no more than three blocks visible at one time, two blocks of the same color could not touch, and occlusion from the perspective of the robot was not allowed.",
        "Given a configuration of blocks, the robot generated a digital image of the configuration using a color CCD camera and identified objects in the image as contiguous regions of uniform color.",
        "Given a set of objects, i.e. a set of regions of uniform color in the robot’s visual field, virtual sensor groups implemented in software extracted the following information about each object: measured the area of the object in pixels; measured the height and width of the bounding box around the object; measured the and coordinates of the centroid of the object in the visual field; measured the hue, saturation and intensity values averaged over all pixels comprising the object; returned a vector of three numbers that represented the shape of the object (Stollnitz et al., 1996).",
        "In addition, the sensor group returned the proximal orientation, center of mass orientation and distance for the pair of objects as described in (Regier, 1996).",
        "These sensor groups constitute the entirety of the robot’s sensorimotor experience of the configurations of blocks created by the human subjects.",
        "From the 120 block configurations created by the four subjects, a random sample of 50 of configurations was shown to a different set of subjects who were asked to generate natural language utterances describing what they saw.",
        "The only restriction placed on the utterances was that they had to be truthful statements about the scenes.",
        "Recurring patterns were discovered in the audio waveforms corresponding to the utterances (Oates, 2001) and these patterns were used as candidate words.",
        "Recall that a sensor group is semantically associated with a word when the mutual information between occurrences of the word and values in the sensor groups are statistically significant.",
        "Table 1 shows the values for the mutual information for a number of combinations of words and sensor groups.",
        "Note from the first column that it is clear that the meaning of the word “red” is grounded in the sensor group.",
        "It is the only one with a statistically significant mutual information value.",
        "As the second column indicates, the mutual information between the word “small” and the sensor group is significant at the 0.05 level, Table 1: For each sensor group and several words, the cells of the table show the probability of making an error in rejecting the null hypothesis that occurrences of the word and values in the sensor group are independent.",
        "and the mutual information between this word and the sensor group is not significant but is rather small.",
        "Both of these sensor groups return information about the size of an object, but the sensor group overestimates the area of non-rectangular objects because it returns the height and width of a bounding box around an object.",
        "Finally, note from the third column that the denotation of the word “above” is correctly determined to lie in the sensor group, yet there appears to be some relationship between this word and the sensor group.",
        "The reason for this is that objects that are said to be “above” tend to be much higher in the robot’s visual field than all of the other objects.",
        "How is it possible to determine the extent to which a machine has discovered and represented the semantics of a set of words?",
        "We are trying to capture semantic distinctions made by humans in natural language communication, so it makes sense to ask a human how successful the system has been.",
        "This was accomplished as follows.",
        "For each word for which a semantic association was discovered, each of the training utterances that used the word were identified.",
        "For the scene associated with each utterance, the CPF underlying the word was used to identify the most probable referent of the word.",
        "For example, if the word in question was “red”, then the mean HSI values of all objects in the scene would be computed and the object for which the underlying CPF defined over HSI space yielded the highest probability would be deemed to be the referent of that word in that scene.",
        "A human subject was then asked if it made sense for that word to refer to that object in that scene.",
        "The percentage of content words (i.e. words like “red” and “large” as opposed to “oh” and “there”) for which a semantic association was discovered was .",
        "Given a semantic association, the two ways that it can be in error are as follows: either the wrong sensor group is selected or the conditional probability field defined over that sensor group is wrong.",
        "Given all of the configurations for which a particular word was used, the semantic accuracy is the percentage of configurations that the meaning component of the word selects an aspect of the configuration that a native speaker of the language says is appropriate.",
        "The semantic accuracy was ."
      ]
    },
    {
      "heading": "6 Discussion",
      "text": [
        "This paper described a method for recovering the denotational meaning of a word, i.e. utter-W , given a set of sensory observations, each labeled according to whether it co-occurred with an utterance containing the word, i.e. hear-W .",
        "It was shown that hear-W is a linear function of utter-W where the parameters of the transform are determined by the level of shared attention and the background frequency of .",
        "Given two weak assumptions about the form of utter-W , these parameters can be recovered and the transform inverted.",
        "The use of mutual information and randomization testing to identify the particular sensor group that captures a word’s meaning was described.",
        "It is therefore possible to identify the denotational meaning of a word by simply observing the contexts in which it is and is not used, even in the face of imperfect shared attention and homonymy."
      ]
    }
  ]
}
