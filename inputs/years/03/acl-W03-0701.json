{
  "info": {
    "authors": [
      "Joyce Chai",
      "Pengyu Hong",
      "Michelle X. Zhou"
    ],
    "book": "Workshop on Research Directions in Dialogue Processing",
    "id": "acl-W03-0701",
    "title": "Combining Semantic and Temporal Constraints for Multimodal Integration in Conversation Systems",
    "url": "https://aclweb.org/anthology/W03-0701",
    "year": 2003
  },
  "references": [
    "acl-J95-1003"
  ],
  "sections": [
    {
      "heading": "Abstract",
      "text": [
        "In a multimodal conversation, user referring patterns could be complex, involving multiple referring expressions from speech utterances and multiple gestures.",
        "To resolve those references, multimodal integration based on semantic constraints is insufficient.",
        "In this paper, we describe a graph-based probabilistic approach that simultaneously combines both semantic and temporal constraints to achieve a high performance."
      ]
    },
    {
      "heading": "1 Introduction",
      "text": [
        "Multimodal conversation systems allow users to converse with systems through multiple modalities such as speech, gesture and gaze (Cohen et al., 1996; Wahlster, 1998).",
        "In such an environment, not only are more interaction modalities available, but also richer contexts are established during the interaction.",
        "Understanding user inputs, for example, what users refer to is important.",
        "Previous work on multimodal reference resolution includes the use of a focus space model (Neal et al., 1998), the centering framework (Zancanaro et al., 1997), context factors (Huls et al., 1995), and rules (Kehler 2000).",
        "These previous approaches focus on semantics constraints without fully addressing temporal constraints.",
        "In a user study1, we found that the majority of user referring behavior involved one referring expression and one gesture (as in [S2, G2] in Table 1).",
        "The earlier approaches worked well for these types of references.",
        "However, we found that 14.1% of the inputs were complex, which involved multiple referring expressions from speech utterances and multiple gestures (S3 in Table 1).",
        "To resolve those complex references, we have to not only apply semantic constraints, but also apply temporal constraints at the same time.",
        "For example, Figure 1 shows three inputs where the number of referring expressions is the same and the number of gestures is the same.",
        "The speech utterances and gestures are aligned along the time axis.",
        "The first case (Figure 1a) and the second case (Figure 1b) have the same speech utterance but different temporal alignment between the gestures and the speech input.",
        "The second case and the third case (Figure 1c) have a similar alignment, but the third case provides an additional constraint on the number of referents (from the word “two”).",
        "Although all three cases are similar, but the objects they refer to are quite different in each case.",
        "In the first case, most likely “this” refers to the house selected by the first point gesture and “these houses” refers to two houses selected by the other two gestures.",
        "In the second case, “this” most likely refers to the highlighted house on the display and “these houses” refer to three houses selected by the gestures.",
        "In the third case, “this” most likely refers to the house selected by the first point gesture and “these two houses” refers to two houses selected by the other two point gestures.",
        "simultaneously satisfying semantic constraints from inputs and the interaction contexts, and the temporal constraints between speech and gesture."
      ]
    },
    {
      "heading": "2 Graph-based Approach",
      "text": [
        "We use a probabilistic approach based on attributed relational graphs (ARGs) to combine semantic and temporal constraints for reference resolution.",
        "First, ARGs can adequately capture the semantic and temporal information (for both referring expressions and potential referents).",
        "Second, the graph match mechanism allows a simultaneous application of temporal constraints and semantic constraints.",
        "Specifically, we use two attributed relational graphs (ARGs).",
        "One graph corresponds to all referring expressions in the speech utterances, called the referring graph.",
        "The other graph corresponds to all potential referents (either coming from gestures or contexts), called the referent graph.",
        "By finding the best match between the referring graph and the referent graph, we can find the most possible referent(s) to each referring expression.",
        "An ARG consists of a set of nodes and a set of edges.",
        "For example, Figure 2(a) is the referring graph for the speech utterance in Figure 1(c).",
        "There are two nodes corresponding to two referring expressions “this” and “these two houses” respectively.",
        "Each node encodes the semantic and temporal information of the corresponding referring expression such as the semantic type of the potential referent, the number, the start and end time the expression was uttered, etc.",
        "The edge between two nodes indicates the semantic and temporal relations between these two expressions.",
        "Similarly, Figure 2(b) is the referent graph for the input in Figure 1(c).",
        "This referent graph consists of four sub-graphs.",
        "Three sub-graphs correspond to three gestures respectively.",
        "Each node in these sub-graphs corresponds to one object selected by the gesture.",
        "Each node encodes the semantic and temporal information of the selected object, as well as the probability this object is actually selected.",
        "There is also a sub-graph corresponding to the interaction context.",
        "Each node in this sub-graph represents an object in the focus in the last interaction turn.",
        "The sub-graphs are connected via semantic type and temporal relations.",
        "With the ARG representations described above, the reference resolution problem becomes matching the referent graph with the referring graph.",
        "Suppose we have two graphs to be matched: • The referent graph Gc = 〈{ax}, {rxy}〉, where {ax} is the node list and {rxy} is the edge list.",
        "The edge rxy connects nodes ax and ay.",
        "• The referring graph Gs = ({am}, {ymn}), where {am} is the node list and {ymn} is the edge list.",
        "The edge ymn connects nodes am and an.",
        "The match process is to maximize the following function:",
        "with respect to P(ax,am), the matching probabilities between the referent node ax and the referring node am.",
        "The function Q(Gc,Gs) measures the degree of the overall match between the referent graph and the referring graph.",
        "This function not only considers the similarities between nodes as indicated by the function ,;(ax,am), but also considers the similarities between edges as indicated by the function yr(rxy,ymn).",
        "Both node similarity and edge similarity functions are further defined by a combination of semantic and temporal constraints.",
        "For example, ,;(ax,am)=Sem(ax,am)Tem(ax,am), where Sem(ax,am) measures the semantic compatibility by determining whether the semantic categories of ax and am are the same, whether their attributes are compatible, and so on.",
        "Tem(ax,am) measures the temporal alignment and is empirically defined as follows: To maximize (1), we modified the graduated assignment algorithm (Gold and Rangarajan, 1996).",
        "When the algorithm converges, P(ax,am) gives us the matching probabilities.",
        "Details are described in a separate paper."
      ]
    },
    {
      "heading": "3 Discussion",
      "text": [
        "During the study, we collected 156 inputs.",
        "The Input received on port 3334: 67275921 67277343 2 69 23 3 1 2 67275921 67277343 39218 10000 0 0 255 0.28571 70 23 2 2 2 67275921 67277343 39218 10000 0 0 255 1.",
        "system assigned time stamps to each recognized word in the utterance, and each gesture.",
        "Figure 3 shows an example of an input that consisted of two gesture inputs and a speech utterance “compare this house with this house”.",
        "The first two lines represent two gestures.",
        "Each line gives information about when the gesture started and ended, as well as the selected objects with their probabilities.",
        "These data provided us information on how the speech and gesture were aligned (to the accuracy of milliseconds).",
        "These data will help us further validate the temporal compatibility function used in the matching process.",
        "We described an approach that uses graph matching algorithm to combine semantic and temporal constraints for reference resolution.",
        "The study showed that this approach worked quite well (93% accuracy) when the referring expressions were correctly recognized by the ASR.",
        "In the future, we plan to incorporate spatial constraints."
      ]
    }
  ]
}
