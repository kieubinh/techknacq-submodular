{
  "info": {
    "authors": [
      "Mu Li",
      "Jianfeng Gao",
      "Changning Huang",
      "Jianfeng Li"
    ],
    "book": "SIGHAN Workshop on Chinese Language Processing",
    "id": "acl-W03-1701",
    "title": "Unsupervised Training for Overlapping Ambiguity Resolution in Chinese Word Segmentation",
    "url": "https://aclweb.org/anthology/W03-1701",
    "year": 2003
  },
  "references": [
    "acl-A00-2009",
    "acl-P98-1029"
  ],
  "sections": [
    {
      "heading": "Abstract",
      "text": [
        "This paper proposes an unsupervised training approach to resolving overlapping ambiguities in Chinese word segmentation.",
        "We present an ensemble of adapted Naïve Bayesian classifiers that can be trained using an unlabelled Chinese text corpus.",
        "These classifiers differ in that they use context words within windows of different sizes as features.",
        "The performance of our approach is evaluated on a manually annotated test set.",
        "Experimental results show that the proposed approach achieves an accuracy of 94.3%, rivaling the rule-based and supervised training methods."
      ]
    },
    {
      "heading": "1 Introduction",
      "text": [
        "Resolving segmentation ambiguities is one of the fundamental tasks for Chinese word segmentation, and has received considerable attention in the research community.",
        "Word segmentation ambiguities can be roughly classified into two classes: overlapping ambiguity (OA), and combination ambiguity (CA).",
        "In this paper, we focus on the methods of resolving overlapping ambiguities.",
        "Consider a Chinese character string ABC, if it can be segmented into two words either as AB/C or A/BC depending on different context, ABC is called an overlapping ambiguity string (OAS).",
        "For example, given a Chinese character string “ ” (ge4 -guo2 -you3), it can be segmented as either “ |” (each state-owned) in Sentence (1) of",
        "(Regarding human rights, every country has some common ground)",
        "Our method of resolving overlapping ambiguities contains two procedures.",
        "One is to construct an ensemble of Naïve Bayesian classifiers to resolve ambiguities.",
        "The other is an unsupervised method for training the Naïve Bayesian classifiers which compose the ensemble.",
        "The main issue of the unsupervised training is how to eliminate the negative impact of the OA errors in the training data.",
        "Our solution is to identify all OASs in the training data and replace them with a single special token.",
        "By doing so, we actually remove the portion of training data that are likely to contain OA errors.",
        "The classifiers are then trained on the processed training data.",
        "Our approach is evaluated on a manually annotated test set with 5,759 overlapping segmentation ambiguities.",
        "Experimental results show that an accuracy of 94.3% is achieved.",
        "This remainder of this paper is structured as follows: Section 2 reviews previous work.",
        "Section 3 defines overlapping ambiguous strings in Chinese.",
        "Section 4 describes the evaluation results.",
        "Section 5 presents our conclusion.",
        "“"
      ]
    },
    {
      "heading": "2 Previous Work",
      "text": [
        "Previous methods of resolving overlapping ambiguities can be grouped into rule-based approaches and statistical approaches.",
        "Maximum Matching (MM) based segmentation (Huang, 1997) can be regarded as the simplest rule-based approach, in which one starts from one end of the input sentence, greedily matches the longest word towards the other end, and repeats the process with the rest unmatched character sequences until the entire sentence is processed.",
        "If the process starts with the beginning of the sentence, it is called Forward Maximum Matching (FMM).",
        "If the process starts with the end of the sentence, it is called Backward Maximum Matching (BMM).",
        "Although it is widely used due to its simplicity, MM based segmentation performs poorly in real text.",
        "Zheng and Liu (1997) use a set of manually generated rules, and reported an accuracy of 81% on an open test set.",
        "Swen and Yu (1999) presents a lexicon-based method.",
        "The basic idea is that for each entry in a lexicon, all possible ambiguity types are tagged; and for each ambiguity types, a solution strategy is used.",
        "They achieve an accuracy of 95%.",
        "Sun (1998) demonstrates that most of the overlapping ambiguities can be resolved without taking into account the context information.",
        "He then proposes a lexicalized rule-based approach.",
        "His experiments show that using the 4,600 most frequent rules, 51 % coverage can be achieved in an open test set.",
        "Statistical methods view the overlapping ambiguity resolution as a search or classification task.",
        "For example, Liu (1997) uses a word unigram language model, given all possible segmentations of a Chinese character sequence, to search the best segmentation with the highest probability.",
        "Similar approach can be traced back to Zhang (1991).",
        "But the method does not target to overlapping ambiguities.",
        "So the disambiguation results are not reported.",
        "Sun (1999) presents a hybrid method which incorporates empirical rules and statistical probabilities, and reports an overall accuracy of 92%.",
        "Li (2001) defines the word segmentation disambiguation as a binary classification problem.",
        "Li then uses Support Vector Machine (SVM) with mutual information between each Chinese character pair as a feature.",
        "The method achieves an accuracy of 92%.",
        "All the above methods utilize a supervised training procedure.",
        "However, a large manually labeled training set is not always available.",
        "To deal with the problem, unsupervised approaches have been proposed.",
        "For example, Sun (1997) detected word boundaries given an OAS using character-based statistical measures, such as mutual information and difference of t-test.",
        "He reported an accuracy of approximately 90%.",
        "In his approach, only the statistical information within 4 adjacent characters is exploited, and lack of word-level statistics may prevent the disambiguation performance from being further improved."
      ]
    },
    {
      "heading": "3 Ensemble of Naïve Bayesian Classifier",
      "text": []
    },
    {
      "heading": "for Overlapping Ambiguity Resolution 3.1 Problem Definition",
      "text": [
        "We first give the formal definition of overlapping ambiguous string (OAS) and longest OAS.",
        "An OAS is a Chinese character string O that satisfies the following two conditions: a) There exist two segmentations Seg1 and Seg2 such that`dw1 E Seg1,w2 E Seg2 , where Chinese words w1 and w2 are different from either literal strings or positions; b) 3 w1 E Seg1 , w2 E Seg2 , where w1 and w2 overlap.",
        "The first condition ensures that there are ambiguous word boundaries (if more than one word segmentors are applied) in an OAS.",
        "In the example presented in section 1, the string “ ” is an OAS but “ ” is not because the word “ ” remains the same in both FMM and BMM segmentations of “ ||” and “ ||”.",
        "The second condition indicates that the ambiguous word boundaries result from crossing brackets.",
        "As illustrated in Figure 1, words ” and “ ” form a crossing bracket.",
        "The longest OAS is an OAS that is not a sub-string of any other OAS in a given sentence.",
        "For example, in the case “ shui3 -ping2, living standard), both “ ” and longest OAS because “ ” is a substring of ”.",
        "In this paper, we only consider the longest OAS because both left and right boundaries of the longest OAS are determined.",
        "” are OASs, but only “ ” is the",
        "Furthermore, we constrain our search space within the FMM segmentation Of and BMM segmentation Ob of a given longest OAS.",
        "According to Huang (1997), two important properties of OAS has been identified: (1) if the FMM segmentation is the same as its BMM segmentation (Of = Ob), for example “ ” (sou1 -suo3 -yin3-qing2, Search Engine), the probability that the MM segmentation is correct is 99%; Otherwise, (2) if the FMM segmentation differs from its BMM segmentation (Of Ob ), for example “ ”, the probability that at least one of the MM segmentation is correct is also 99%.",
        "So such a strategy will not lower the coverage of our approach.",
        "Therefore, the overlapping ambiguity resolution can be formulized as a binary classification problem as follows: Given a longest OAS O and its context feature set C, let G(Seg, C) be a score function of Seg for seg∈ {Of,Ob}, the overlapping ambiguity resolution task is to make the binary decision: Note that Of = Ob means that both FMM and BMM arrive at the same result.",
        "The classification process can then be stated as: a) If Of = Ob, then choose either segmentation result since they are same; b) Otherwise, choose the one with the higher score G according to Equation (1).",
        "For example, in the example of “ ”, if ” is selected as the answer.",
        "In another example of “ ” in sentence (1) of Figure 1, Of = “ |”,"
      ]
    },
    {
      "heading": "3.2 Naive Bayesian Classifier for Overlapping Ambiguity Resolution",
      "text": [
        "Last section formulates the overlapping ambiguity resolution of an OAS O as the binary classification between Of and Ob.",
        "This section describes the use of the adapted Naive Bayesian Classifier (NBC) (Duda and Hart, 1973) to address problem.",
        "Here, we use the words around O within a window as features, with w-m...w-1 denoting m words on the left of the O and w1...wn denoting n words on the right of the O.",
        "Naive Bayesian Classifier assumes that all the feature variables are conditionally independent.",
        "So the joint probability of observing a set of context features C = {w-m...w-1, w1 ... wn} of a segmentation Seg (Of or Ob) of O is as follows: , yong3-qi4, courage).",
        "While the former string contains an OAS, the latter does not.",
        "We then remove all OAS from the training data, and estimate the parameters using the training data that do not contain OAS.",
        "In experiments, we replace all longest OAS that has Of Ob with a special token [ GAP ].",
        "Below, we refer to the processed corpus as tokenized corpus.",
        "Note that Seg is either the FMM or the BMM segmentation of O, and all OASs (including Seg) have been removed from the tokenized corpus, thus there are no statistical information available to estimate p(Seg) and p(w-m...w-1,w1 ... wn|Seg) based on the Maximum Likelihood Estimation (MLE) principle.",
        "To estimate them, we introduce the following two assumptions.",
        "1) Since the unigram probability of each word w can be estimated from the training data, for a given segmentation Seg=ws1...wsk, we assume that each word w of Seg is generated independently.",
        "The probability p(Seg) is approxi",
        "Assume that Equation (2) is the score function in Equation (1) G, we then have two parameters to be estimated: p(Seg) and p(wi |Seg).",
        "Since we do not have enough labeled training data, we then resort to the redundancy property of natural language.",
        "Due to the fact that the OAS occupies only in a very small portion of the entire Chinese text, it is feasible to estimate the word co-occurrence probabilities from the portion of corpus that contains no overlapping ambiguities.",
        "Consider an OAS (xin4 -xin1-de, confidently).",
        "The correct segmentation would be “ |”, if (cong1-man3, full of) were its context word.",
        "We note that appears as the left context word of in both strings and ( mated by the production of the word unigram probabilities:",
        "2) We also assume that left and right context word sequences are only conditioned on the leftmost and rightmost words of Seg, respectively.",
        "Theensemblelearning suggests thatthe ensemble classificationresults are basedonthe majorityvote ofthese classifiers: The segmentationthatis se-lectedbymost classifiers is chosen."
      ]
    },
    {
      "heading": "4.1 Settings",
      "text": [
        "We evaluateourapproachusingamanuallyanno-tatedtestset, whichwas selectedrandomlyfrom People's Dailynews articles ofyear1997, containing approximate 460,000 Chinese characters, or 247,000 words.",
        "Inthetestset, 5759 longestOAS are identified.",
        "Ourlexiconcontains 93,700 entries."
      ]
    },
    {
      "heading": "4.2 OAS Distribution",
      "text": [
        "We firstinvestigatethe distributionofdifferent types ofOAS inthetestset.",
        "Inourapproach, the performanceupperbound(i.e. oracle accuracy) cannot achieve 100% because not all the OASs' correct segmentations canbegeneratedbyFMM andBMM segmentation.",
        "So itis veryusefulto knowto whatextentourapproachcandealwith the problem.",
        "The results are shownin Table 2.",
        "We denote the entire OAS datasetas C, anddivide itinto two subsets A andBaccording to thetype ofOAS.",
        "It canbe seenfromthe tablethatindata setA (Of= Ob), the accuracyofMM segmentation achieves 98.8% accuracy.",
        "Meanwhile, indata setB (OfOb) the oraclerecall ofcandidates proposed byFMM and BMM is 95.7% (97.2% intheentire dataset C).",
        "The statistics areveryclose to those reported in Huang (1997).",
        "Table2.",
        "Distribution of OAS in the test set Here are someexamples f",
        ").",
        "For errors caused by Of Ob and Of COR n Ob COR, ( ) (chu1-xian4-zai4shi4 -ji4, ||) serves as a good example.",
        "These two types of errors are usually composed of several words and need a much more complicated search process to determine the final correct output.",
        "Since the number of such errors is very small, they are not target of our approach in this paper."
      ]
    },
    {
      "heading": "4.3 Experimental Results of Ensemble of Naive Bayesian Classifiers",
      "text": [
        "The classifiers are trained from the People’s Daily news articles of year 2000, which contain over 24 million characters.",
        "The training data is tokenized.",
        "That is, all OAS with Of Ob are replaced with the token [ GAP ] .",
        "After tokenization, there are 16,078,000 tokens in the training data in which 203,329 are [ GAP ], which is 1.26% of the entire training data set.",
        "Then a word trigram language model is constructed on the tokenized corpus, and each Bayesian classifier is built given the language model.",
        "Table 3 shows the accuracy of each classifier on data set B.",
        "The performance of the ensemble based on majority vote is 89.79% on data set B, and the overall accuracy on C is 94.13%.",
        "The ensemble consistently outperforms any of its members.",
        "Classifiers with both left and right context features perform better than the others because they are capable to segment some of the context sensitive OAS.",
        "For example, contextual information is necessary to segment the OAS “ ”(kan4-tai2-shang4, on the stand) correctly in both following sentences:",
        "(Look at the performer in the stage) (Stand in the highest stand) Both Peterson (2000) and Brill (1998) found that the ultimate success of an ensemble depends on the assumption that classifiers to be combined make complementary errors.",
        "We investigate this assumption in our experiments, and estimate the oracle accuracy of our approach.",
        "Result shows that only 6.0% (180 out of 2996) of the OAS in data set B that is classified incorrectly by all the 9 classifiers.",
        "In addition, we can see from Table 2, that 130 instances of these 180 errors are impossible to be correct because neither Of nor Ob is the correct segmentation.",
        "Therefore, the oracle accuracy of the ensemble is 94.0%, which is very close to 95.7%, the theoretical upper bound of our approach in data set B described in Section 4.2.",
        "However, our majority vote based ensemble only achieves accuracy close to 90%.",
        "This analysis thus suggests that further improves can be made by using more powerful ensemble strategies."
      ]
    },
    {
      "heading": "4.4 Lexicalized Rule Based OAS Disambiguation",
      "text": [
        "We also conduct a series of experiments to evaluate the performance of a widely used lexicalized rule-based OAS disambiguation approach.",
        "As reported by Sun (1998) and Li (2001), over 90% of the OAS can be disambiguated in a context-free way.",
        "Therefore, simply collecting large amount of correctly segmented OAS whose segmentation is independent of its context would yield pretty good performance.",
        "We first collected 730,000 OAS with Of Ob from 20 years’ People’s Daily corpus which contains about 650 million characters.",
        "Then approximately 47,000 most frequently occurred OASs were extracted.",
        "For each of the extracted OAS, 20 sentences that contain it were randomly selected from the corpus, and the correct segmentation is manually labeled.",
        "41,000 lexicalized disambiguation rules were finally extracted from the labeled data, whose either MM segmentation (Of or Ob) gains absolute majority, over 95% in our experiment.",
        "The rule set covers approximately 80% occurrences of all the OASs in the training set, which is very close to that reported in Sun (1998).",
        "Here is a sample rule extracted: => |.",
        "It means that among the 20 sentences that contain the character sequence “ ”, at least 19 of them are segmented as “ |” .",
        "The performance of the lexicalized rule-based approach is shown in Table 4, where for comparison we also include the performance of using only FMM or BMM segmentation algorithm.",
        "In Table 4, Rule + FMM means if there is no rule applicable to an OAS, FMM segmentation will be used.",
        "Similarly, Rule + BMM means that BMM segmentation will be used as backup.",
        "We can see in Table 4 that rule-based systems outperform their FMM and BMM counterparts significantly, but do not perform as well as our method, even when no context feature is used.",
        "This is because that the rules can only cover about 76% of the OASs in the test set with precision 95%, and FMM or BMM performs poorly on the rest of the OASs.",
        "Although the precision of these lexicalized rules is high, the room for further improvements is limited.",
        "For example, to achieve a higher coverage, say 90%, much more manually labeled training data (i.e. 81,000 OAS) are needed."
      ]
    },
    {
      "heading": "5 Conclusion and Future work",
      "text": [
        "Our contributions are twofold.",
        "First, we propose an approach based on an ensemble of adapted naive Bayesian classifiers to resolving overlapping ambiguities in Chinese word segmentation.",
        "Second, we present an unsupervised training method of constructing these Bayesian classifiers on an unlabeled training corpus.",
        "It thus opens up the possibility for adjusting this approach to a large variety of applications.",
        "We perform evaluations using a manually annotated test set.",
        "Results show that our approach outperforms a lexicalized rule-based system.",
        "Future work includes investigation on how to construct more powerful classifier for further improvements.",
        "One promising way is combining our approach with Sun's (1997), with a core set of context free OASs manually labeled to improve accuracy."
      ]
    },
    {
      "heading": "Acknowledgements",
      "text": [
        "We would like to thank Wenfeng Yang and Xiao-dan Zhu for helpful discussions on this project and Wenfeng's excellent work on the lexicalized disambiguation rule set construction."
      ]
    }
  ]
}
