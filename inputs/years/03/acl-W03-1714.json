{
  "info": {
    "authors": [
      "Qing Ma",
      "Yujie Zhang",
      "Masaki Murata",
      "Hitoshi Isahara"
    ],
    "book": "SIGHAN Workshop on Chinese Language Processing",
    "id": "acl-W03-1714",
    "title": "Semantic Maps for Word Alignment in Bilingual Parallel Corpora",
    "url": "https://aclweb.org/anthology/W03-1714",
    "year": 2003
  },
  "references": [
    "acl-C02-1032",
    "acl-C02-1060",
    "acl-C88-1016",
    "acl-C92-2101",
    "acl-J93-2003",
    "acl-P93-1004",
    "acl-P95-1033",
    "acl-W93-0301"
  ],
  "sections": [
    {
      "heading": "Abstract",
      "text": [
        "Effective self-organizing techniques for constructing monolingual semantic maps of Japanese and Chinese have already been developed.",
        "By extending the monolingual map to a bilingual semantic map, we have proposed a semantics-based approach for word alignment in a Japanese/ Chinese bilingual corpus."
      ]
    },
    {
      "heading": "1 Introduction",
      "text": [
        "Acquiring translation knowledge from a bilingual parallel corpus requires alignment not only at the sentence level but also at the word level.",
        "If a bilingual corpus is aligned at the word level, translation words that are not in a dictionary, such as those depending on domain or time, might be obtained, or, multiple translation candidates might be scored.",
        "Furthermore, translation patterns based on the relations of words at the phrase or clause level might be automatically acquired (Brown, 1997).",
        "Thus, alignment is a very important, fundamental task in natural language processing (NLP).",
        "The research related to this topic includes a series of statistical models (e.g., Brown, et al., 1988; Brown, et al., 1993; Macklovitch and Hanna, 1996), a method using dynamic programming (Dagan, 1993), a statistical approach introducing contextual information (Varea, et al., 2002), and structure alignment methods (Kaji, et al., 1992; Matsumoto, et al., 1993; Wu, 1995; Ima-mura, 2001).",
        "All of these approaches, however, are based on either statistical information or grammatical structure, but not on meaning.",
        "Automatic methods for constructing monoligual semantic maps of Japanese or Chinese have already been proposed (Ma, et al., 2002).",
        "In a monoligual semantic map, words with similar meanings are placed at the same or neighboring points, so that the distance between the points represents the semantic similarity of the words.",
        "If a bilingual semantic map could be automatically constructed by accepting translation pairs of sentences as inputs, word alignment would be easily obtained from the map.",
        "Since the bilingual semantic map, like the monolingual semantic map, would provide results with visibility and continuity, it would be easy to handle one-to-many or many-to-one alignment.",
        "Furthermore, bilingual maps can perhaps be expected to be applied in foreign language learning or foreign language writing by using bilingual parallel corpora.",
        "The most important factor is that the translations should usually be free.",
        "There is an evident limitation of existing alignment methods that rely on statistical or grammatical information, which suggests the necessity to develop an approach based on meaning.",
        "This paper proposes a new method for automatically constructing bilingual semantic maps of Japanese and Chinese.",
        "the method accepts translation pairs of Japanese and Chinese sentences as inputs, with the aiming of providing word alignment based on meaning' .",
        "We used the Kyoto University Japanese corpus and its translated Chinese corpus to conduct an experiment and confirm the effectiveness of the proposed method.",
        "The necessary training data for automatically constructing semantic maps was obtained from eight years of a Japanese newspaper, Mainichi Shinbun."
      ]
    },
    {
      "heading": "3.2 Learning data",
      "text": [
        "As part of the Japanese-Chinese machine translation project, we are constructing a bilingual parallel corpus based on the Kyoto University Japanese corpus (Kurohashi and Nagao, 1997).",
        "The translation pair of sentences were obtained from the corpus.",
        "Since the Kyoto University corpus has already been morphologically analyzed, the Japanese sentences were used directly without any analysis, while the translated Chinese sentences were segmented and part-of-speech tagged by using the morphological analysis tool developed by Beijing University (Zhou and Duan, 1994).",
        "To evaluate the two different languages with the same measure, the words appearing in a translated Chinese sentence were given at most five translated Japanese candidate words, which were used instead of the original Chinese words.",
        "The candidates were obtained manually from two Chinese-Japanese dictionaries: \"Han Ri Ci Dian\", published by Jilin Education Publisher, and \"Chunichi Daijiten\" s , published by Taishukan Publishing Co., Ltd.",
        "The candidates were selected according to the following order of priority: (1) a word that also appears in the Japanese original sentence; (2) a word that has the same POS as the original Chinese word; (3) a word chosen according to the order listed in the dictionary; and (4) a word that appears in the Kyoto University corpus.",
        "Thus, all the words in the translated Chinese sentence in the pair shown above can be rendered in terms of Japanese candidate words as follows:",
        "In this way, we can express a translation pair of sentences in terms of only Japanese words.",
        "As this example shows, however, we can recognize translated Japanese candidate words, such as \"`tip` � Z\" or\"`L /a�Z � 6 /Z � �\", that do not exist in the original Japanese sentence.",
        "This means that it is virtually impossible to perform word alignment by only using surface representations, even if the translation pair of sentences has been unified by a single language.",
        "The actual learning data used in self-organization were obtained in the following way.",
        "Each Japanese",
        "word appearing in a Japanese sentence was defined in terms of its co-occurrent words (the targeted word itself and the words to its immediate left and right).",
        "They were obtained from eight years (1991-1998) of the Japanese newspaper, Mainichi Shinbun, and used as learning data.",
        "Each Chinese word appearing in a translated Chinese sentence was defined in terms of the co-occurrent words of its Japanese translation candidates and the Chinese words defined in this way were used as learning data.",
        "In the next section, we explicitly describe the construction of the learning data and the coding method used to transform it into inputs for the SOM."
      ]
    },
    {
      "heading": "3.3 Data coding",
      "text": [
        "Suppose we are given a Japanese-Chinese translation pair of sentences: Jl , J2, ••• JTn Cl: Jll/ ••• /Jl..,••• C.: Jul/ ••• /J.', where the Ji (i = 1, • • • , m) are the Japanese words forming the Japanese sentence, the Ci (i = 1, • • • , n) are the Chinese words forming the translated Chinese sentence, Jij (i = 1, • • • , n, j = 1, • • • , ni) is the jth translated Japanese candidate for Ci, ni(1 < ni < t) is the number of candidates for C2, and t is the maximum number of candidates (t = 5 in the paper).",
        "Word wi (= Ji) of a Japanese sentence is defined by a set of co-occurrent information:",
        "where aj_/) is a co-occurrent word of Ji, fj_/) is the normalized (i.e., E'll f.�') = 1) co-occurrence frequency, and ai is the number of words co-occurring with Ji.",
        "Word wj (= Cj) of a translated Chinese sentence is also defined by a set of co-occurrent information:",
        "where a(j) is a co-occurrent word of either or severals of Jjl, • • • , Jj,ni, f j) is the normalized co-occurrence frequnecy (it will be the summation of the frequencies when occuring with severals), and ai is the number of words co-occuring with Ji.",
        "Since the Chinese words are also defined in terms of co-occurrent Japanese words, there is no need to distinguish between Chinese and Japanese, and it thus becomes possible to apply all existing coding methods for self-organizing monolingual semantic maps.",
        "In this paper, the semantic distance dij between any two words wi and wj appearing in a",
        "organization.",
        "translation pair of sentences is calculated by the following frequency term-weighting method: where �2 and Fj are expansions of a2 and aj, the numbers of co-occurrent words of w2 and wj, respectively, and F2j is an expansion of c2j, the number of co-occurrent words that both w2 and wj have in common.",
        "The expansion are obtained as follows:",
        "where f (2) is the co-occurrence frequency of word w2 and its co-occurrent word ax ( 2 x ), andf (2j) is the co-occurrence frequency of words w2 and wj and their co-occurrent word a(2) (x = 1, a2).",
        "As a result, we can define a correlative matrix D with the distance d2j as its element.",
        "Each word w2 is thus coded with the elements in the i-throw of the correlative matrix D as",
        "where N is the total number of words appearing in the translation pair of sentences (i.e., N = m + n), and V(w2) E RN is the input to the SOM."
      ]
    },
    {
      "heading": "4 Experimental Results",
      "text": []
    },
    {
      "heading": "4.1 Data",
      "text": [
        "Word alignment experiments were performed for ten translation pairs of sentences.",
        "The learning data was obtained in the way described in Sec. 3.2.",
        "Considering the translation pair of sentences given in Sec. 3.1 as an example, the number of words was N = m + n=16+15=31, the total number of co-occurrent words was 62,627, and the number of different co-occurrent words was 22,077.",
        "Among the 31 words, the period symbol (\"o \")4 had the largest number of co-occurrent words (4,180), while the word \"7/j' /Jib\" in the Japanese sentence and the comma \", \" in the translated Chinese sentence had the smallest numbers of co-occurrent words (5 each)."
      ]
    },
    {
      "heading": "4.2 SOM",
      "text": [
        "We used an SOM consisting of a 13x13 two-dimensional array.",
        "The number of input dimensions, N, was 31, the same as the number of words to be mapped.",
        "In the ordering phase, the number of learning steps, T, was set to 10,000, the initial value of the learning rate, a(0), was set to 0.1, and the initial radius of the neighborhood, a(0), was set to 13, equal to the diameter of the SOM.",
        "In the fine adjustment phase, T was set to 100,000, a(0) was set to 0.01, and a(0) was set to 7.",
        "The initial reference vectors m2(0) consisted of random values between 0 and 1.0.",
        "4 Although there is actually no need to align period symbols between sentences, this step was not omitted because the sentences were processed mechanically.",
        "ment of the translation pair given in Sec. 3.1 as an example.",
        "Here, the words tagged with \"J\" are Japanese words from the Japanese sentence and the words with \"C\" are Chinese words from the translated Chinese sentences .",
        "From the map, we could obtain the word alignment results listed in Table 1 by focusing on each Japanese word and choosing the closest Chinese word to it' .",
        "The correct answers are also given in the table.",
        "From this table, we can see that [J : 4LE, C : 4LE A],[J : *N, C : *N], [J :, C MTS],[J : 7 /j' /jib , C : ,Ww,],[J : t}' k , C: p71-�], [J:o , C:o ] were aligned correctly.",
        "Among these pairs, in the case of [J: 7 /j' /jib , C:,WW,] and [J:t}'k , C: p7�], the Japanese word and the Japanese translation candidates for the Chinese words have different surface representations.",
        "The other alignment results are incorrect in the strict sense of the word.",
        "Among these apparent mistakes, however, there are some interesting results.",
        "For example, for the Japanese word \"J: M-A\", although \"C: q%fi\" was aligned as the closest Chinese word, the semantic map shows that the second closest Chinese word is actually \"C:ON-A\".",
        "That is, if we had included the second closest candidate, we would have obtained the correct answer.",
        "Simi",
        "larly, for \"J: l _;f\" , its second candidates is \"C: A\", a correct answer.",
        "Also, the incorrect alignment results, [J:` L, C:,WM] and [J:�_,, C:o ] were due to the fact that there are no Chinese words (or at least none appearing in the sentence) that correspond to these Japanese words.",
        "Another problem was incorrect alignment caused by the inconsistency of word segmentation between the Japanese and Chinese sentence, as in the case of [J:fft'-g:, C:fft'-gt].",
        "None of these problems can be resolved by only applying the word alignment technique.",
        "Table 2 lists the baseline word alignment results, which were obtained by focusing on each Japanese word and choosing the Chinese word with the smallest semantic distance dzj which was calculated by Eq.",
        "(8).",
        "From this table we can see that [J : 7 b, C : MTS] was incorrect, while \"J : 7/j'/jib\" was correctly aligned by using the semantic map.",
        "Also, although incorrect results were obtained both for the semantic map, such as [J:M-A, C: q%fi] or [J:rIM , C: ON-A] and for the baseline such as, [J:M-A, C:*N] or [J: q%fi, C:MTS], the results for the semantic map were somewhat correct in meaning, whereas those for the baseline were totally wrong.",
        "If we see the second candidates, we can know that the second candidates of \"JA-A\" and \"J: l Y _;f\" are \"C:MTS\" and \"C:* N\" which are incorrect.",
        "We can thus say that the method using the semantic map performed better than the baseline method.",
        "Figure 3 shows the word-alignment semantic map obtained by principle component analysis (PCA).",
        "By comparing it with Figure 2, we can see that the results obtained by PCA would be worse than those obtained by self-organization.",
        "For example, the pair [J: 7 /J' �b , C:,W�I, which has different surface representations, could not be obtained by PCA.",
        "\"J: MR\" also could not be correctly aligned even if the second closest candidate were included.",
        "In addition, words tend to cluster together in certain areas and the total disposition of the words is thus imbalanced, which detracts from the semantic map's features of visibility and continuity.",
        "We also tried to use hierarchical clustering for word alignment.",
        "The results obtained were slightly worse than those obtained with the self-organizing semantic map.",
        "For example, [J: 7 /J'�Jib, C:,WMI also could not be correctly obtained with the clustering method.",
        "Moreover, because we could not know the semantic distance between words within a group, we could not easily obtain second closest candidates as we could with the semantic map."
      ]
    },
    {
      "heading": "5 Conclusion",
      "text": [
        "This paper has proposed a novel word alignment method designed to provide a meaning-based approach.",
        "The effectiveness of the proposed method was confirmed through small-scale experiments.",
        "In our future work, we are going to conduct numerical evalution through large scale experimental comparison with existing methods.",
        "We also plan to develop a word alignment technique for practical use by integrating the proposed method into existing systems."
      ]
    }
  ]
}
