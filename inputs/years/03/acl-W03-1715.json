{
  "info": {
    "authors": [
      "Oliver Streiter"
    ],
    "book": "SIGHAN Workshop on Chinese Language Processing",
    "id": "acl-W03-1715",
    "title": "Abductive Explanation-Based Learning Improves Parsing Accuracy and Efficiency",
    "url": "https://aclweb.org/anthology/W03-1715",
    "year": 2003
  },
  "references": [
    "acl-C92-4194",
    "acl-C92-4211",
    "acl-J99-2004",
    "acl-P95-1036",
    "acl-P98-1022",
    "acl-W00-1205"
  ],
  "sections": [
    {
      "heading": "Abstract",
      "text": [
        "Natural language parsing has to be accurate and quick.",
        "Explanation-based Learning (EBL) is a technique to speed-up parsing.",
        "The accuracy however often declines with EBL.",
        "The paper shows that this accuracy loss is not due to the EBL framework as such, but to deductive parsing.",
        "Abductive EBL allows extending the deductive closure of the parser.",
        "We present a Chinese parser based on abduction.",
        "Experiments show improvements in accuracy and efficiency.1"
      ]
    },
    {
      "heading": "1 Introduction",
      "text": [
        "The difficulties of natural language parsing, in general, and of parsing Chinese, in particular, are due to local ambiguities of words and phrases.",
        "Extensive linguistic and non-linguistic knowledge is required for their resolution (Chang, 1994; Chen, 1996).",
        "Different parsing approaches provide different types of knowledge.",
        "Example-based parsing approaches offer rich syntagmatic contexts for disambiguation, richer than rule-based approaches do (Yuang et al., 1992).",
        "Statistical approaches to parsing acquire mainly paradigmatic knowledge and require larger corpora, c.f.",
        "(Carl and Langlais, 2003).",
        "Statistical approaches handle unseen events via smoothing.",
        "Rule-based approaches use abstract category labels.",
        "Example-based parsing generalizes examples during compilation time, e.g. (Bod and Kaplan, 1998), or performs a similarity-based fuzzy match during runtime (Zavrel and Daelemans, 1997).",
        "Both techniques may be computationally demanding, their effect on parsing however is quite different, c.f.",
        "(Streiter, 2002a).",
        "Explanation-based learning (EBL) is a method to speed-up rule-based parsing via the caching of examples.",
        "EBL however trades speed for accuracy.",
        "For many systems, a small loss in accuracy is acceptable if an order of magnitude less computing time is required.",
        "Apart from speed, one generally recognizes that EBL acquires some kind of knowledge from texts.",
        "However, what is this knowledge like if it does not help with parsing?",
        "Couldn’t a system improve by learning its own output?",
        "Can a system learn to parse Chinese by parsing Chinese?",
        "The paper sets out to tackle these questions in theory and practice."
      ]
    },
    {
      "heading": "1.1 Explanation-based Learning (EBL)",
      "text": [
        "Explanation-based learning techniques transform a general problem solver (PS) into a specific and operational PS (Mitchel et al., 1986).",
        "The caching of the general PS’s output accounts for this transformation.",
        "The PS generates, besides the output, a documentation of the reasoning steps involved (the explanation).",
        "This determines which output the system will cache.",
        "The utility problem questions the claim of speeding-up applications (Minton, 1990): Retrieving cached solutions in addition to regular processing requires extra time.",
        "If retrieval is slow and cached solutions are rarely re-used, the cost-benefit ratio is negative.",
        "The accuracy of the derived PS is generally below that of the general PS.",
        "This may be due to the EBL framework as such or the deductive base of the PS.",
        "Research in abductive EBL (A-EBL) seems to suggest the latter: A-EBL has the potential to acquire new knowledge (Dimopoulos and Kakas, 1996).",
        "The relation between knowledge and accuracy however is not a direct and logical one.",
        "The U-shaped language learning curves in children exemplifies the indirect relation (Marcus et al., 1992).",
        "Wrong regular word forms supplant correct irregular forms when rules are learned.",
        "We therefore cannot simply equate automatic knowledge acquisition and accuracy improvement, in particular for complex language tasks."
      ]
    },
    {
      "heading": "1.2 EBL and Natural Language Parsing",
      "text": [
        "Previous research has applied EBL for the speed-up of large and slow grammars.",
        "Sentences are parsed.",
        "Then the parse trees are filtered and cached.",
        "Subsequent parsing uses the cached trees.",
        "A complex HPSG-grammar transforms into tree-structures with instantiated values (Neumann, 1994).",
        "One hash table lookup of POS-sequences replaces typed-feature unification.",
        "Experiments conducted in EBL-augmented parsing consistently report a speed-up of the parser and a drop in accuracy (Rayner and Samuelsson, 1994; Srinivas and Joshi, 1995).",
        "A loss of information may explain the drop of accuracy.",
        "Contextual information, taken into account by the original parser, may be unavailable in the new operational format (Sima’an, 1997), especially if partial, context-dependent solutions are retrieved.",
        "In addition, the set of cached parse trees, judged to be ”sure to cache”, is necessarily biased (Streiter, 2002b).",
        "Most cached tree structures are short noun phrases.",
        "Parsing from biased examples will bias the parsing.",
        "A further reason for the loss in accuracy are incorrect parses which leak into the cache.",
        "A stricter filter does not solve the problem.",
        "It increases the bias in the cache, reduces the size of the cache, and evokes the utility problem.",
        "EBL actually can improve parsing accuracy (Streiter, 2002b) if the grammar does not derive the parses to be cached via deduction but via abduction.",
        "The deductive closure2 which cannot increase with EBL from deductive parsing may increase with abductive parsing."
      ]
    },
    {
      "heading": "2 A Formal View on Parsing and Learning",
      "text": [
        "We use the following notation throughout the paper: (function applied to yields x), (relation applied to yields x).",
        "and represent tuples and sets respectively.",
        "The prefix denotes the cardinality of a collection, e.g. .",
        "Uppercase variables stand for collections and lowercase variables for elements.",
        "Collections may contain the anonymous variable (the variable _ in PROLOG).",
        "Over-braces or under-braces should facilitate reading: .",
        "A theory is where is a set of rules .",
        "and are two disjoint sets of attributes",
        "and (e.g. ).",
        "A rule is written as or .",
        "A rule specifies the rela",
        "tion between an observable fact and an attribute assigned to it.",
        "is the set of observable data with each being a tuple .3 is the set of data classified according to , with .",
        ", and may have an internal structure in the form of ordered or unordered collections of more elementary , and respectively.",
        "Transferring this notation to the description of parsing, is a syntactic formalism and a grammar.",
        "is the union of syntax trees and morphosyntactic tags.",
        "is a corpus tagged with .",
        "corresponds to a list of words, phrases or sentences (the surface strings).",
        "is a treebank, a cache of parse trees, or a history of explanations."
      ]
    },
    {
      "heading": "2.1 Parsing:",
      "text": [
        "A parser defines a relation between and (c.f.",
        "2).",
        "Parsing is a relation between and a subset of (c.f.",
        "3).",
        "Simplifying, we can assume that is defined as the set of rules, i.e. .",
        "A specific parser is derived by the application of to the training material (e.g. ): .",
        "The set of possible relations is .",
        "Elements of are caching (no generalization), induction (hypothesis after data inspection) and abduction (hypothesis during classification).",
        "Equation (5) describes the cycle of grammar learning and grammar application.",
        "is based on memory if .in (6) is the trivial formalization of caching.",
        "Parsing proceeds via recalling defined in (7).",
        "The cycle of grammar learning and parsing is defined in (8): The training material yields the parsing output .4 parsing learning from",
        "Let be a function which replaces one or more elements of a collection by a named variable or .",
        "is a deductive inference if is obtained from an induction (a reduction of with the help of ).",
        "The following expressions define induction (9), deduction (10) and the inductive-deductive cycle (11): 4We use subscripts to indicate the identity of variables.",
        "The same subscript of two variables implies the identity of both variables.",
        "Different subscripts imply nothing.",
        "The variables may be identical or not identical.",
        "In memory-based parsing, learning material and parsing output are identical.",
        "parsing",
        "Abduction, defined as is a runtime generalization which is triggered by a concrete to be classified.",
        "We separate and for presentation purpose only.",
        "The relation may express a similarity, a temporal or causal relation.",
        "(12) and the cycle of (13) define abduction.",
        "parsing learning from",
        "Abduction subsumes reasoning by analogy.",
        "Abduction is an analogy, if describes a similarity.",
        "Reasoning from rain to snow is a typical analogy.",
        "Reasoning from wet street to rain is an abductive reasoning.",
        "For a parsing approach based on analogy c.f.",
        "(Lepage, 1999).",
        "5Abduction is a process of hypothesis generation.",
        "Deduction and abduction may work conjointly whenever deductive inferences encounter gaps.",
        "A deductive inference stops in front of a gap between the premises and a possible conclusion.",
        "Abduction creates a new hypothesis, which allows to bridge the gap and to continue the inference.",
        "(8)"
      ]
    },
    {
      "heading": "2.2 Learning:",
      "text": [
        "In this section, we formalize EBL.",
        "We mechanically substitute in the definition of EBL by to show their learning potentials.",
        "A learning system changes internal states, which influence the performance.",
        "The internal states of are determined by and .",
        "We assume that, for a given , remains identical before and after learning.",
        "Therefore, the comparison of (before learning) with (after learning) reveals the acquired knowledge.",
        "We define EBL in (14).",
        "is the parser before learning.",
        "This parser applies to and yields , formalized as .",
        "The new parser is the application of to the union of and",
        "From two otherwise identical parsers, the parser with not present in the other has a greater deductive closure.",
        "The cardinality of reflects an empirical knowledge.",
        "The empirical knowledge does not allow to conclude something new, but to resolve ambiguities in accordance with observed data, e.g. for a sub-language as shown in (Rayner and Samuelsson, 1994).",
        "Both learning techniques have the potential of improving the accuracy."
      ]
    },
    {
      "heading": "2.2.1 Learning through Parsing",
      "text": [
        "A substitution of with reveals the transformation of to .",
        "We start with caching and recalling (Equation 15).",
        "Parsing with the cache of yields .",
        "The deductive closure is not enlarged.",
        "Quantitative relations with respect to change in .",
        "If is not cached twice, memory-based EBL is idempotent .6",
        "EBL with induction and deduction is shown in (16).",
        "Here the subscripts merit special attention: is parsed from .",
        "This yields .",
        "Integrating into C changes the empirical knowledge with respect to and .",
        "If the empirical knowledge does not influence , D-EBL is idempotent.",
        "The deductive closure does not increase as",
        "Abductive EBL (A-EBL) is shown in (17).",
        "A-EBL acquires empirical knowledge similarly to D-EBL.",
        "In addition, a new is acquired.",
        "This may differ from with respect to and/or .",
        "In the experiments in A-EBL we reported below, and holds.",
        "learning"
      ]
    },
    {
      "heading": "2.2.2 Recursive Rule Application",
      "text": [
        "Parsing is a classification task in which is assigned to .",
        "Differently from typical classification tasks in machine learning, natural language parsing requires an open set .",
        "This is obtained via the recursive application of , which unlike non-recursive styles of analysis (Srinivas and Joshi, 1999) yields (syntax trees) of any complexity.",
        "Then is applied to so that can be matched by further rules (c.f.",
        "18).",
        "Without this reduction, recursive parsing could not go beyond memory-based parsing.",
        "tutions.",
        "Abductive term identification bridges gaps in the deduction (X Y).",
        "The marker ’?’ is a graphical shortcut for the set of lexemes in .",
        "The function defines an induction and recursive parsing is thus a deduction.",
        "Combinations of memory-based and deduction-based parsing are deductions, combinations of abduction-based parsing with any another parsing are abductions.",
        "Macro Learning is the common term for the combination of EBL with recursive deduction (Tadepalli, 1991).",
        "A macro is a rule which yields the same result as a set of rules with and does.",
        "In terms of a grammar, such macros correspond to redundant phrases, i.e. phrases that are obtained by composing smaller phrases of .",
        "Macros represent shortcuts for the parser and, possibly, improved likelihood estimate of the composed structure compared to the estimates under independency assumption (Abney, 1996).",
        "When the usage of macros excludes certain types of analysis, e.g. by trying to find longest/best matches we can speak of pruning.",
        "This is the contribution of D-EBL for parsing."
      ]
    },
    {
      "heading": "3 Experiments in EBL",
      "text": []
    },
    {
      "heading": "3.1 Experimental purpose and setup",
      "text": [
        "The aim of the experiments is to verify whether new knowledge is acquired in A-EBL and D-EBL.",
        "Secondly, we want to test the influence of new knowledge on parsing accuracy and speed.",
        "The general setup of the experiment is the following.",
        "We use a section of a treebank as seed-corpus ( ).",
        "We train the seed-corpus to a corpus-based parser.",
        "Using a test-corpus we establish the parsing",
        "are obtained by parsing step 4a or 5 where only one POS-labels may be different in the last characters (e.g. ).",
        "The resulting corpora are and",
        "accuracy and speed of the parser ( (recall,precision,f-score,time)).",
        "Then, we parse a large corpus ( ).",
        "A filter criterion that works on the explanation applies.",
        "We train those trees which pass the filter to the parser ( ).",
        "Then the parsing accuracy and speed is tested against the same training corpus ( (recall,precision,f-score,time)).",
        "Sections of the Chinese Sinica Treebank (Huang et al., 2000) are used as seed-treebank and gold standard for parsing evaluation.",
        "Seed-corpora range between 1.000 and 20.000 trees.",
        "We train them to the parser OCTOPUS (Streiter, 2002a).",
        "This parser integrates memory deduction and abduction-based parsing in a hierarchy of preferences, starting from 1 memory-based parsing, 2 non-recursive deductive parsing, 3 recursive deductive parsing and 5 finally abductive parsing (Fig.",
        "2).",
        "Learning the seed corpora ( ) results in 1992).",
        "For every the parser produces one parse-tree and an explanation.",
        "The explanation has the form of a derivation tree in TAGs, c.f (Joshi, 2003).",
        "The deduction and abduction steps are visible in the explanation.",
        "Filters apply on the explanation and create sub-corpora that belong to one inference type.",
        "The first filter requires the explanation to contain only one non-recursive deduction, i.e. only parsing step 2.",
        "As deductive parsing is attempted after memory-based parsing (1), holds.",
        "A second filter extracts those structures, which"
      ]
    },
    {
      "heading": "3.2 The Acquired Knowledge",
      "text": [
        "We want to know whether or not new knowledge has been acquired and what the nature of this acquired knowledge is.",
        "As parsing was not recursive, we can approach the closure by the types of POS-sequences from all trees and their subtrees in a corpus.",
        "We contrast this with to the types of lexeme-sequences.",
        "The data show that only A-EBL increases the closure.",
        "But even when looking at lexemes, i.e. empirical knowledge, the A-EBL acquires richer information than D-EBL does."
      ]
    },
    {
      "heading": "size of seed corpus",
      "text": [
        "The representatives of the cached parses is gauged by the percentage of top NPs and VPs (including Ss) as top-nodes.",
        "Fig 5 shows the bias of cached parses which is more pronounced with D-EBL than with A-EBL.",
        "is parsed, producing the corpora .",
        "The corpus used is a subset of the 5 Million word Sinica Corpus (Huang and Chen,"
      ]
    },
    {
      "heading": "3.3 Evaluating Parsing",
      "text": [
        "The experiments consist in evaluating the parsing accuracy and speed for each .",
        "We test the parsing accuracy on 300 untrained and randomly selected sentences using the f-score on unlabeled dependency relations.",
        "Fig.",
        "6 shows parsing accuracy depending on the size of the seed-corpus.",
        "The graphs show side branches where we introduce the EBL-derived training material.",
        "This allows comparing the effect of A-EBL, D-EBL and hand-coded trees (the baseline).",
        "Fig.",
        "7 shows the parsing speed in words per second (Processor: 1000 MHz, Memory:128 MB) for the same experiments.",
        "Rising lines indicate a speed-up in parsing.",
        "We have interpolated and smoothed the curves.",
        "0 5000 10000 15000 20000 25000 size of seed corpus The experimental results confirm the drop in parsing accuracy with D-EBL.",
        "This fact is consistent across all experiments.",
        "With A-EBL, the parsing accuracy increases beyond the level of departure.",
        "The data also show a speed-up in parsing.",
        "This speed-up is more pronounced and less data-hungry with A-EBL.",
        "Improving accuracy and efficiency are thus not mutually exclusive, at least for A-EBL."
      ]
    },
    {
      "heading": "4 Conclusions",
      "text": [
        "Explanation-based Learning has been used to speedup natural language parsing.",
        "We show that the loss in accuracy results from the deductive basis of parsers, not the EBL framework.",
        "D-EBL does not extend the deductive closure and acquires only empirical (disambiguation) knowledge.",
        "The accuracy declines due to cached errors, the statistical bias the filters introduce and the usage of shortcuts with limited contextual information.",
        "Alternatively, if the parser uses abduction, the deductive closure of the parser enlarges.",
        "This makes accuracy improvements possible - not a logical consequence.",
        "In practice, the extended deductive closure compensates for negative factors such as wrong parses or unbalanced distributions in the cache.",
        "On a more abstract level, the paper treats the problem of automatic knowledge acquisition for Chinese NLP.",
        "Theory and practice show that abduction-based NLP applications acquire new knowledge and increase accuracy and speed.",
        "Future research will maximize the gains.",
        "parsing accuracy with C_seed parsing accuracy with C_seed+C_A parsing accuracy with C_seed + C_D"
      ]
    }
  ]
}
