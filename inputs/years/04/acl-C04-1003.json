{
  "info": {
    "authors": [
      "Wojciech Skut"
    ],
    "book": "International Conference on Computational Linguistics",
    "id": "acl-C04-1003",
    "title": "Incremental Construction of Minimal Acyclic Sequential Transducers from Unsorted Data",
    "url": "https://aclweb.org/anthology/C04-1003",
    "year": 2004
  },
  "references": [
    "acl-J00-1002",
    "acl-J97-2003",
    "acl-N03-1009"
  ],
  "sections": [
    {
      "heading": "Abstract",
      "text": [
        "This paper presents an efficient algorithm for the incremental construction of a minimal acyclic sequential transducer (ST) for a dictionary consisting of a list of input and output strings.",
        "The algorithm generalises a known method of constructing minimal finite-state automata (Daciuk et al., 2000).",
        "Unlike the algorithm published by Mihov and Maurel (2001), it does not require the input strings to be sorted.",
        "The new method is illustrated by an application to pronunciation dictionaries."
      ]
    },
    {
      "heading": "1 Introduction",
      "text": [
        "Sequential transducers constitute a powerful formalism for storing and processing large dictionaries.",
        "Each word in the dictionary is associated with an annotation, e.g., phonetic transcription or a collection of syntactic features.",
        "Since STs are deterministic, lexical lookup can be performed in linear time.",
        "Space efficiency can be achieved by means of minimisation algorithms (Mohri, 1994; Eisner, 2003).",
        "In the present paper, we consider the following problem.",
        "Given a list of strings w(') ... w('\"`) associated with annotations o(') ... o(''), we want to construct a minimal ST T implementing the mapping f (w W) = o(j), j = 1 ... m. The naive way of doing that would be first to create a (non-minimal) ST implementing f and then to minimise it.",
        "As pointed out by Daciuk et al.",
        "(2000), this can be inefficient, especially for large m. Instead, the same task can be performed more efficiently in an incremental way, i.e., by constructing a sequence of transducers Tl ... T,,,, such that each Tj is the minimal ST implementing the restriction of the original mapping f to the first j words (f I {w(l) ... w(j)1)• Since the insertion of a new word wj+' typically affects only few states of the transducer, Tj+1 can be constructed from Tj by changing only a small part of its structure.",
        "Daciuk et al.",
        "(2000) show how to incrementally construct a minimal finite-state automaton for a list of words wl ... w,,,,,.",
        "Their algorithm can also be applied to transducers, but fails to produce a minimal ST in the general case.",
        "Mihov and Maurel (2001) describe an algorithm that handles the ST case correctly, but requires the words to be sorted in advance.",
        "In some applications, this requirement is unrealistic as lexical entries may be added dynamically to an already constructed dictionary.'",
        "The present paper presents an algorithm that does not make assumptions about the order of the list WM ... w('\"`).",
        "The paper is structured as follows.",
        "Section 2 introduces definitions and notation.",
        "The original algorithm for finite automata is described in section 3.",
        "Section 4 explains why the algorithm does not work for transducers.",
        "The required generalisation is introduced in section 5; an algorithm based on this generalisation is the topic of section 6.",
        "Section 7 illustrates the new method with a practical application."
      ]
    },
    {
      "heading": "2 Definitions",
      "text": [
        "Definition 1.",
        "(Deterministic FSA) A deterministic finite-state automaton (DFSA) over an alphabet E is a quintuple A = (E, Q, qo, 6, F) such that Q is a finite set of states, qo E Q is the initial state, F C Q the set of final states, and 6: Q x E – � Q is a (partial) transition function.",
        "6 can be extended to the domain",
        "A accepts a string w E E* if q= P (qo, w) is defined and q E F. The set of all strings accepted by A is called the language of A and 'Many systems employ a built-in lexicon that is constructed off-line, but may be extended with user dictionaries merged in at any time in any order.",
        "The only way to use the sorted-data algorithm would be to unfold the already minimised lexicon, add the new entries, sort the data and reapply the construction method.",
        "written L(A).",
        "An FSA is called trim if every state belongs to a path from qo to a final state.",
        "sions from A* (Dom (a) = Dom (6)).",
        "Function a can be extended to Q x E* according to the following recursive definition: �(q, e) = e, a* (q, wa) = a* (q, w)a(P (q, w), a).",
        "Unless indicated otherwise, the definitions formulated above for DFSAs also apply to STs"
      ]
    },
    {
      "heading": "2.1 String Notation",
      "text": [
        "For u, v E E*, uv and u • v denote the concatenation of u and v. u n v is the longest common prefix of u and v. If u is a prefix of v (written u <p v), u-1v denotes the remainder of v:",
        "string uj ... uk of u (u[i ... k] = e if i > k).",
        "If T is an ST, w n T stands for the longest prefix u <p w such that P (qo, u) is defined."
      ]
    },
    {
      "heading": "3 Minimisation of FSAs",
      "text": [
        "The algorithm decribed by Daciuk et al.",
        "(2000) is iterative.",
        "In each iteration, given a minimal acyclic trim FSA A = (E, Q, qo, b, F) and a word w E E*, the algorithm creates a DFSA A' _ (E, Q', qo, Y, F') such that A' is the minimal automaton for the language L(A) U {w}.",
        "A' then serves as input to the next iteration.",
        "The key notion here is the equivalence of states.",
        "Two states q1, q2 E Q are considered equivalent (written ql - q2) ifF L (ql) =L (q2)• A well-known result states that a trim FSA is minimal ifE' it does not contain a pair ql, q2 of distinct but equivalent states:",
        "Each iteration consists of two steps, which can be called insertion and local minimisation.2"
      ]
    },
    {
      "heading": "3.1 Insertion",
      "text": [
        "The insertion operation identifies the longest prefix wl ... wl of w in A and the corresponding states qo ... ql.",
        "Some of them may be confluence states, i.e., states q2 such that in – degree (g2) >",
        "1.",
        "In order to prevent overgeneration, the algorithm identifies the first confluence state qk and clones the path qk ... ql.",
        "The cloned states qk ... ql are copies of the original ones,",
        "In the next step, a chain of states 41+1 ... qt, qt E F, consuming the remainder of w (i.e., w1+1 ... wt) is appended to ql (if it has been created) or to ql.",
        "If l = t, the remainder is the empty string, and we make sure that �"
      ]
    },
    {
      "heading": "g1141 E F.",
      "text": [
        "Formally, this step creates an automaton �A =",
        "This completes the insertion step.",
        "The new automaton A obviously accepts the language L(A) U {w} and preserves the right languages of all states except qo ... qk-1•"
      ]
    },
    {
      "heading": "3.2 Local Minimisation",
      "text": [
        "The situation after insertion is that A contains",
        "• a path qo ... qk-1 of states whose right languages may have changed, 2 The following description refers to a simpler variant",
        "of the algorithm rather than to the optimised version described in the pseudocode in the original publication.",
        "Optimisation is discussed separately in section 6.5.",
        "3We set k := 1 + 1 if there are no confluence states.",
        "b(q, a) _ • a path qk ... qt of newly created (partly cloned) states, and • the remaining states of A, whose right languages have not changed (i.e., (1) still holds",
        "for Q\\{qo ... qk-1f )• In order to make the new FSA minimal, the algorithm must enforce condition (1) for the states qo ... qk-14k ... qt by replacing them, if possible, by their equivalents in a set Q%, which is initially set to Q\\{qp ... qk-11.",
        "The sequence is traversed in reverse order, starting from qt.",
        "In the j-th iteration (j = 1... t – 2), the algorithm checks if there is already a state q' E Q% equivalent to the current state q.",
        "If such a q' exists, q is replaced by q' (i.e., q is deleted and all transitions reaching q are redirected to q').",
        "Otherwise, q is added to Q5t.",
        "In this way, the algorithm gets rid of duplicates w.r.t.",
        "the equivalence relation -.",
        "The automaton left after the last iteration satisfies condition (1), i.e., it is minimal."
      ]
    },
    {
      "heading": "3.3 The State Register",
      "text": [
        "The efficiency of the algorithm depends on its ability to quickly check the equivalence of states.",
        "This check is fast because P (q, u) E Q% for all q E Q% (at any stage of the local minimisation step).",
        "In effect, q1 - q2 < > Out(gl) =",
        "transitions leaving q.",
        "Thus, for each q E Q%, the pair (Out(q), q) is put on a register, i.e., an associative container that maps sets of pairs (input, state) (uniquely identifying a right language) to the corresponding states in Q5t.",
        "4 Application to Transducers The problem for sequential transducers can be stated as follows: given a minimal ST T implementing a sequential function f, we want to insert into T a string w associated with an emission o, creating a minimal ST for f U { (w, o) }.",
        "Daciuk et al.",
        "(2000) state on this topic: This new algorithm can also be used to construct transducers.",
        "The alphabet of the (transducing) automaton would be E1 x E2, where E1 and E2 are the alphabets of the levels.",
        "Alternatively, as previously described, elements of E2 can be associated with the final states of the dictionary and only output once a valid word from E*1 is recognised.",
        "Unfortunately, both suggested solutions are problematic.",
        "They require that we commit ourselves to a particular alignment of input and output symbols in the transitions in advance, before running the algorithm.",
        "For instance, consider the fragment of a pronunciation dictionary shown below.",
        "but b uh t bite b ai t cut k uh t cite s ai t Obviously, there are several string-to-string transducers that implement this dictionary.",
        "One possibility would be to encode the mapping in a phonologically motivated way, i.e., associating each phonetic symbol with the grapheme(s) it corresponds to.",
        "Unfortunately, the result of applying an FSA minimisation algorithm is non-deterministic (figure 1).",
        "The second suggestion made by Daciuk et al.",
        "(2000), the use of final emissions, can be emulated using a special end-of-string symbol $.",
        "The result of FSA minimisation, shown at the top of figure 2, is an ST, but not minimal, since it has more states than the ST shown below."
      ]
    },
    {
      "heading": "5 ST Minimality Criteria",
      "text": [
        "In order to adapt the original algorithm to transducers, we need to find an ST counterpart of the - relation defined for finite-state automata.",
        "The following proposition constitutes a good point of departure.",
        "-t--: follows immediately with u' = a* (qo, u),",
        "adapt the original algorithm, we must define an equivalence relation on Q, analogous to -.",
        "It turns out that this is possible for transducers that are prefix-normalised, as stated in the following definition."
      ]
    },
    {
      "heading": "6 The Algorithm",
      "text": [
        "The following proposition allows us to define an equivalence relation on Q analogous to R f.",
        "According to proposition 2, a modification of the original algorithm (by Daciuk et al.",
        "(2000)) shall produce a minimal ST if - is replaced by -ST, and the transducer being constructed is prefix-normalised in each iteration.",
        "As in the original approach, each iteration is a two-step operation: first, a new word-output pair (w, o) is inserted into a minimal, trim and prefix-normalised transducer T, creating a prefix-normalised, \"almost minimal\" transducer �7'.",
        "In the second step, the \"redundant\" states on the path of w are merged with equivalent states in �7', resulting in a minimal, trim and prefix-normalised ST implementing fT U { (w, o) }.",
        "The modifications to the FSA algorithm required in order to adapt it to sequential transducers are discussed in sections 6.1 and 6.2.",
        "The pseudocode is presented in section 6.3. q ST q' < >"
      ]
    },
    {
      "heading": "6.1 Insertion",
      "text": [
        "Like the original algorithm, the modified one identifies wAT = qo ... ql and creates new states 41+1 ... qt• It also clones the path qk ... ql from the first confluence state (if there is one).",
        "The main complication is due to the insertion of the output sequence o.",
        "In order for the ST to be well-formed, the output &* (qo, w n T) generated by the prefix w n T must be a prefix of o.",
        "However, the original output a* (qo, w n T) in T might not meet this requirement.",
        "The solution is to \"push\" some of the outputs away from the path of the prefix wAT = w[l ... 1].",
        "However, one must be careful not to change the right languages (and their translations) of the states that are not on the path of w. Furthermore, proposition 2 requires the resulting ST to be prefix-normalised.",
        "All this can be achieved by the following recursive definition of &.4",
        "As for the suffix w[l+l t], we associate the output remainder &*(go,w[l ... l]) – lo with the first transition.",
        "The remaining ones emit e. This insertion mechanism ensures that T implements the mapping fT U { (w, o) } without changing the equivalence of states not on the path qo ... qk-1•"
      ]
    },
    {
      "heading": "6.2 Local Minimisation",
      "text": [
        "As in the FSA algorithm, the path qo • • • qk-14k • • • qt is traversed in reverse",
        "order.",
        "Each state q for which there exists an equivalent state q' E Q% is replaced by q'.",
        "What changes is the way the equivalence of two states q1, q2, q2 E QZ is determined.",
        "Obviously, now it is no longer sufficient to compare the target states and input labels of all transitions leaving ql and q2.",
        "However, since T is prefix-normalised, the only extra bit to check is the output, i.e., we keep the original",
        "dures INSERT() and REMOVE_DUPLICATES(), responsible respectively for the insertion and the local minimisation step.",
        "The former traverses the word from left to right, clones the path from the first confluence state down (if there is any), and ends up in the state P (qo, w n T), or its copy.",
        "From there, INSERT_SUFFIX() is called, creating a chain of states corresponding to the remainder of Word (The pseudocode of INSERT_SUFFIX() is omitted for space reasons, but its functionality is very simple: the remainder of Output is emitted in the first transition of this new chain of states).5 In each iteration of the for-loop, the variable Output holds the remainder of the original output that has not been emitted so far.",
        "PUSH_OUTPUTS(State, Residual) takes care of making the path outputs in �T compatible with o = fT(o).",
        "After i iterations of the loop, the argument Residual holds the value of (ono-*(go,w[l ... i-1])) 1a*(g0,w[l...i]), i.e., the remainder of a* (qo, w[l ... i-1]) after subtracting the longest common prefix with o.",
        "This prefix is prepended to the output labels of all transitions starting in State.",
        "The procedure REMOVE_DUPLICATES() traverses the path of w in T (in reverse order) and removes those states for which there is an equivalent state in the register.",
        "The remaining states are added to the register (note that the procedure INSERT_SUFFIX() de-registers all states from the root down to the first confluence state – if such a state exists – or to the end of w n T).",
        "else Register +- Register U { Child} rof procedure PUSH OUTPUTS (State, Residual) for each a E E if S(State, a) is defined a(State, a) +- Residual - a(State, a)"
      ]
    },
    {
      "heading": "6.4 Extensions",
      "text": [
        "The algorithm can be extended to the more general case of subsequential transducers (SST).",
        "An SST is an ST that emits final outputs when halting in a final state (Mohri, 1997).",
        "It can be emulated in the ST framework by appending a special end-of-string character $ to each string, making each final state q in the transducer non-final and adding a transition from q via $ to a new final state q f. The output associated with this transition is the ST equivalent of a final output.",
        "In this encoding, the new algorithm can be used to construct minimal subsequential transducers.",
        "Alternatively, the algorithm can be directly modified to cope with final outputs.",
        "In this case, the equivalence relation ST needs to be refined by requiring that two equivalent final states must also have identical final outputs.",
        "In some cases, the mapping f : w -� o is not a function.",
        "For example, a word in a pronunciation dictionary may have two or more transcriptions.",
        "Such cases of bounded ambiguity can be handled by another extension of the ST framework, namely p-subsequential transducers, in which each final state is associated with up to p final outputs (Mohri, 1997).",
        "The present algorithm can be extended to this case by employing p different end-of-string symbols $1 ... $p, as in the case of SSTs.",
        "This technique was used in the application described in section 7."
      ]
    },
    {
      "heading": "6.5 Complexity and Optimisation",
      "text": [
        "For a dictionary of m words, the main loop of the algorithm executes m times.",
        "The loops in procedures INSERTO (including the call to INSERT -SUFFIX()) and REMOVE_DUPLICATES() are each executed jwj times for each word w. Putting a state on a register may be done in constant time when using a hash map.",
        "Compared to the FSA algorithm, the ST generalisation has one more complexity component, namely the procedure PUSH_OUTPUTSO, which is executed in each iteration of the loop in function INSERTO).",
        "Each call to PUSH-OUTPUTS(q) involves OutDegree (q) operations.",
        "In practical implementation, there is also some overhead stemming from the use of more complex data structures (because of the need to store transition outputs).",
        "This mainly affects the efficiency of the register lookup and the INSERTO) procedure.",
        "The algorithm can be optimised by reducing the number of times states are registered/deregistered during the processing of the prefix of w in T (main loop of INSERT()).",
        "More precisely, the idea is to deregister a state only if there is any residual output pushed down the trie (i.e., the previous value of OutputSuffcx was other than e).",
        "As a result, some states ql ... qs, s < k, may stay registered after the call to INSERTO.",
        "The loop in REMOVE_DUPLICATES() must then check whether or not 6(g27 wi+1) = qi+1• If not, q2+1 must have been replaced by an equivalent state.",
        "In such a case, we must de-register q2 and check if there are equivalent states in the register.",
        "As soon as one of the q2's is not replaced, there is no need to perform this check for the remaining states q2-1 ... ql• This optimisation idea is used in the original algorithm.",
        "As for STs, the speed-up achieved is moderate because PUSH – OUTPUTS( typically changes most of the outputs on the path of w. 7 Applications and Evaluation The new algorithm has been employed to construct pronunciation lexica in the rVoice text-to-speech system.?",
        "In languages such as English, where the relation between orthography and pronunciation is not straightforward, it is often advantageous to store all known words in the dictionary, rather than rely on letter-to-sound rules (Fackrell and Skut, 2004).",
        "The algorithm makes it possible to store large amounts of data in such dictionaries without affecting the efficiency and flexibility of the system: the resulting representations are very compact, words can be looked up deterministically in linear time, and user-defined entries can be inserted into the dictionary at any time in any order (unlike in Maurel and Mihov's approach).",
        "This last feature in particularly important as rVoice users can control the behaviour of the system by dynamically inserting their own entries into the dictionary at runtime.",
        "The performance of the algorithm has been evaluated by constructing a minimal ST for a pronunciation dictionary comprising the 50,000 most frequent British surnames.",
        "The size and the construction time for the ST were compared to the equivalent parameters for the sorted-data ST algorithm (Mihov and Maurel, 2001) and the unsorted-data FSA algorithm (Daciuk et al., 2000).",
        "The dictionary was not sorted, so there was an extra sorting step in the case of Maurel and Mihov's algorithm (sorting took less than 1 sec.",
        "and is not included in the reported execution time).",
        "In the FSA, the phonetic transcriptions were encoded as final emissions (i.e., the FSA encoded the language {w(1)o(1) � �w(m)o(m)j, each phonetic symbol serving as an additional symbol of the input alphabet).",
        "The ST encoding used a special end-of-string symbol $ appended to each word in order to make sure the resulting mapping was rational.$ The results are shown in table 1.",
        "The comparison demonstrates that STs are",
        "methods (unsorted-data ST, sorted-data ST and unsorted-data FSA) applied to a pronunciation lexicon on a Pentium 4 1.7 GHz processor.",
        "superior to FSAs as an encoding method for lex-ica annotated with rich respresentations.",
        "FSA minimisation is obviously of little help if every (or almost every) input is associated with a different annotation; almost no states are merged in the part of the FSA encoding the w(2)'s.9 Since the FSA is much larger, construction takes longer than in the ST case although the FSA algorithm is faster on structures of equal size.",
        "Not surprisingly, the sorted-data algorithm is faster than the unsorted-data version, even including the actual sorting time.",
        "However, its limited flexibility restricts its applicability, leaving the new unsorted-data algorithm as the preferable option in a range of applications."
      ]
    }
  ]
}
