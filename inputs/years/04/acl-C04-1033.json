{
  "info": {
    "authors": [
      "Xiaofeng Yang",
      "Jian Su",
      "Guodong Zhou",
      "Chew Lim Tan"
    ],
    "book": "International Conference on Computational Linguistics",
    "id": "acl-C04-1033",
    "title": "An NP-Cluster Based Approach to Coreference Resolution",
    "url": "https://aclweb.org/anthology/C04-1033",
    "year": 2004
  },
  "references": [
    "acl-J01-4004",
    "acl-J94-4002",
    "acl-M95-1005",
    "acl-N01-1008",
    "acl-N04-1002",
    "acl-P02-1014",
    "acl-P02-1060",
    "acl-P95-1017",
    "acl-P98-1012",
    "acl-W02-1008",
    "acl-W02-1040",
    "acl-W03-1307",
    "acl-W99-0611"
  ],
  "sections": [
    {
      "heading": "Abstract",
      "text": [
        "Traditionally, coreference resolution is done by mining the reference relationships between NP pairs.",
        "However, an individual NP usually lacks adequate description information of its referred entity.",
        "In this paper, we propose a supervised learning-based approach which does coreference resolution by exploring the relationships between NPs and coreferential clusters.",
        "Compared with individual NPs, coreferential clusters could provide richer information of the entities for better rules learning and reference determination.",
        "The evaluation done on MEDLINE data set shows that our approach outperforms the baseline NP-NP based approach in both recall and precision."
      ]
    },
    {
      "heading": "1 Introduction",
      "text": [
        "Coreference resolution is the process of linking as a clusters multiple expressions which refer to the same entities in a document.",
        "In recent years, supervised machine learning approaches have been applied to this problem and achieved considerable success (e.g. Aone and Bennett (1995); McCarthy and Lehnert (1995); Soon et al.",
        "(2001); Ng and Cardie (2002b)).",
        "The main idea of most supervised learning approaches is to recast this task as a binary classification problem.",
        "Specifically, a classifier is learned and then used to determine whether or not two NPs in a document are co-referring.",
        "Clusters are formed by linking coreferential NP pairs according to a certain selection strategy.",
        "In this way, the identification of coreferential clusters in text is reduced to the identification of coreferential NP pairs.",
        "One problem of such reduction, however, is that the individual NP usually lacks adequate descriptive information of its referred entity.",
        "Consequently, it is often difficult to judge whether or not two NPs are talking about the 'In this paper the term “cluster” can be interchangeably used as “chain”, while the former better emphasizes the equivalence property of coreference relationship.",
        "same entity simply from the properties of the pair alone.",
        "As an example, consider the pair of a non-pronoun and its pronominal antecedent candidate.",
        "The pronoun itself gives few clues for the reference determination.",
        "Using such NP pairs would have a negative influence for rules learning and subsequent resolution.",
        "So far, several efforts (Harabagiu et al., 2001; Ng and Cardie, 2002a; Ng and Cardie, 2002b) have attempted to address this problem by discarding the “hard” pairs and select only those confident ones from the NP-pair pool.",
        "Nevertheless, this eliminating strategy still can not guarantee that the NPs in “confident” pairs bear necessary description information of their referents.",
        "In this paper, we present a supervised learning-based approach to coreference resolution.",
        "Rather than attempting to mine the reference relationships between NP pairs, our approach does resolution by determining the links of NPs to the existing coreferential clusters.",
        "In our approach, a classifier is trained on the instances formed by an NP and one of its possible antecedent clusters, and then applied during resolution to select the proper cluster for an encountered NP to be linked.",
        "As a coreferential cluster offers richer information to describe an entity than a single NP in the cluster, we could expect that such an NP-Cluster framework would enhance the resolution capability of the system.",
        "Our experiments were done on the the MEDLINE data set.",
        "Compared with the baseline approach based on NP-NP framework, our approach yields a recall improvement by 4.6%, with still a precision gain by 1.3%.",
        "These results indicate that the NP-Cluster based approach is effective for the coreference resolution task.",
        "The remainder of this paper is organized as follows.",
        "Section 2 introduces as the baseline the NP-NP based approach, while Section 3 presents in details our NP-Cluster based approach.",
        "Section 4 reports and discusses the experimental results.",
        "Section 5 describes related research work.",
        "Finally, conclusion is given in Section 6. and Cardie, 2002b) selects the candidate with the maximal CF. 2 Baseline: the NP-NP based approach"
      ]
    },
    {
      "heading": "2.1 Framework description",
      "text": [
        "We built a baseline coreference resolution system, which adopts the common NP-NP based learning framework as employed in (Soon et al., 2001).",
        "Each instance in this approach takes the form of i{NPj, NPi}, which is associated with a feature vector consisting of 18 features (f1 ∼ f18) as described in Table 2.",
        "Most of the features come from Soon et al.",
        "(2001)’s system.",
        "Inspired by the work of (Strube et al., 2002) and (Yang et al., 2004), we use two features, StrSim1 (f17) and StrSim2 (f18), to measure the string-matching degree of NPj and NPi.",
        "Given the following similarity function:",
        "StrSim1 and StrSim2 are computed using StrSimilarity(SNPj, SNPi) and StrSimilarity(SNPi, SNPj ), respectively.",
        "Here SNP is the token list of NP, which is obtained by applying word stemming, stopword removal and acronym expansion to the original string as described in Yang et al.",
        "(2004)’s work.",
        "During training, for each anaphor NPj in a given text, a positive instance is generated by pairing NPj with its closest antecedent.",
        "A set of negative instances is also formed by NPj and each NP occurring between NPj and NPi.",
        "When the training instances are ready, a classifier is learned by C5.0 algorithm (Quinlan, 1993).",
        "During resolution, each encountered noun phrase, NPj, is paired in turn with each preceding noun phrase, NPi.",
        "For each pair, a testing instance is created as during training, and then presented to the decision tree, which returns a confidence value (CF)2 indicating the likelihood that NPi is coreferential to NPj.",
        "In our study, two antecedent selection strategies, Most Recent First (MRF) and Best First (BF), are tried to link NPj to its a proper antecedent with CF above a threshold (0.5).",
        "MRF (Soon et al., 2001) selects the candidate closest to the anaphor, while BF (Aone and Bennett, 1995; Ng 2 The confidence value is obtained by using the smoothed ratio t+2 , where p is the number of positive instances and t is the total number of instances contained in the corresponding leaf node."
      ]
    },
    {
      "heading": "2.2 Limitation of the approach",
      "text": [
        "Nevertheless, the problem of the NP-NP based approach is that the individual NP usually lacks adequate description information about its referred entity.",
        "Consequently, it is often difficult to determine whether or not two NPs refer to the same entity simply from the properties of the pair.",
        "See the the text segment in Table 1, for example,",
        "In the above text, [1 A mutant of KBF1/p50], [4 This protein] and [7 This mutant] are annotated in the same coreferential cluster.",
        "According to the above framework, NP7 and its closest antecedent, NP4, will form a positive instance.",
        "Nevertheless, such an instance is not informative in that NP4 bears little information related to the entity and thus provides few clues to explain its coreference relationship with NP7.",
        "In fact, this relationship would be clear if [1 A mutant of KBF1/p50], the antecedent of NP4, is taken into consideration.",
        "NP1 gives a detailed description of the entity.",
        "By comparing the string of NP7 with this description, it is apparent that NP7 belongs to the cluster of NP1, and thus should be coreferential to NP4.",
        "This suggests that we use the coreferential cluster, instead of its single element, to resolve an NP correctly.",
        "In our study, we propose an approach which adopts an NP-Cluster based framework to do resolution.",
        "The details of the approach are given in the next section."
      ]
    },
    {
      "heading": "3 The NP-Cluster based approach",
      "text": [
        "Similar to the baseline approach, our approach also recasts coreference resolution as a binary classification problem.",
        "The difference, however, is that our approach aims to learn a classifier which would select the most preferred cluster, instead of the most preferred antecedent, for an encountered NP in text.",
        "We will give the framework of the approach, including the instance rep-Features describing the relationships between NPj and NPi",
        "1.",
        "DefNp1 1 if NPj is a definite NP; else 0 2.",
        "DemoNP1 1 if NPj starts with a demonstrative; else 0 3.",
        "IndefNP1 1 if NPj is an indefinite NP; else 0 4.",
        "Pron1 1 if NPj is a pronoun; else 0 5.",
        "ProperNP1 1 if NPj is a proper NP; else 0 6.",
        "DefNP2 1 if NPi is a definite NP; else 0 7.",
        "DemoNP2 1 if NPi starts with a demonstrative; else 0 8.",
        "IndefNP2 1 if NPi is an indefinite NP; else 0 9.",
        "Pron2 1 if NPi is a pronoun; else 0 10.",
        "ProperNP2 1 if NPi is a proper NP; else 0 11.",
        "Appositive 1 if NPi and NPj are in an appositive structure; else 0 12.",
        "NameAlias 1 if NPi and NPj are in an alias of the other; else 0 13.",
        "GenderAgree 1 if NPi and NPj agree in gender; else 0 14.",
        "NumAgree 1 if NPi and NPj agree in number; else 0 15.",
        "SemanticAgree 1 if NPi and NPj agree in semantic class; else 0 16.",
        "HeadStrMatch 1 if NPi and NPj contain the same head string; else 0 17.",
        "StrSim1 The string similarity of NPj against NPi 18.",
        "StrSim2 The string similarity of NPi against NPj Features describing the relationships between NPj and cluster Ck 19.",
        "ClusterNumAgree 1 if Ck and NPj agree in number; else 0 20.",
        "ClusterGenAgree 1 if Ck and NPj agree in gender; else 0 21.",
        "ClusterSemAgree 1 if Ck and NPj agree in semantic class; else 0 22.",
        "ClusterLength The number of elements contained in Ck 23.",
        "ClusterStrSim The string similarity of NPj against Ck 24.",
        "ClusterStrLNPSim The string similarity of NPj against the longest NP in Ck",
        "Table 2: The features in our coreference resolution system (Features 1 ∼ 18 are also used in the baseline system using NP-NP based approach) resentation, the training and the resolution procedures, in the following subsections."
      ]
    },
    {
      "heading": "3.1 Instance representation",
      "text": [
        "An instance in our approach is composed of three elements like below: i{NPj, Ck, NPi} where NPj, like the definition in the baseline, is the noun phrase under consideration, while Ck is an existing coreferential cluster.",
        "Each cluster could be referred by a reference noun phrase NPi, a certain element of the cluster.",
        "A cluster would probably contain more than one reference NPs and thus may have multiple associated instances.",
        "For a training instance, the label is positive if NPj is annotated as belonging to Ck, or negative if otherwise.",
        "In our system, each instance is represented as a set of 24 features as shown in Table 2.",
        "The features are supposed to capture the properties of NPj and Ck as well as their relationships.",
        "In the table we divide the features into two groups, one describing NPj and NPi and the other describing NPj and Ck.",
        "For the former group, we just use the same features set as in the baseline system, while for the latter, we introduce 6 more features: ClusterNumAgree, ClusterGenAgree and ClusterSemAgree: These three features mark the compatibility of NPj and Ck in number, gender and semantic agreement, respectively.",
        "If NPj mismatches the agreement with any element in Ck, the corresponding feature is set to 0.",
        "ClusterLength: The number of NPs in the cluster Ck.",
        "This feature reflects the global salience of an entity in the sense that the more frequently an entity is mentioned, the more important it would probably be in text.",
        "ClusterStrSim: This feature marks the string similarity between NPj and Ck.",
        "Suppose SNPj is the token set of NPj, we compute the feature value using the similarity function StrSimilarity(SNPj, SCk), where",
        "ClusterStrLNPSim: It marks the string matching degree of NPj and the noun phrase in Ck with the most number of tokens.",
        "The intuition here is that the NP with the longest string would probably bear richer description information of the referent than other elements in the cluster.",
        "The feature is calculated using the similarity function StrSimilarity(SNPj, SNPk), where"
      ]
    },
    {
      "heading": "3.2 Training procedure",
      "text": [
        "Given an annotated training document, we process the noun phrases from beginning to end.",
        "For each anaphoric noun phrase NPj, we consider its preceding coreferential clusters from right to left3.",
        "For each cluster, we create only one instance by taking the last NP in the cluster as the reference NP.",
        "The process will not terminate until the cluster to which NPj belongs is found.",
        "To make it clear, consider the example in Table 1 again.",
        "For the noun phrase [7 This mutant], the annotated preceding coreferential clusters are:",
        "Among them, the first two instances are labelled as negative while the last one is positive.",
        "After the training instances are ready, we use C5.0 learning algorithm to learn a decision tree classifier as in the baseline approach."
      ]
    },
    {
      "heading": "3.3 Resolution procedure",
      "text": [
        "The resolution procedure is the counterpart of the training procedure.",
        "Given a testing document, for each encountered noun phrase, NPj, we create a set of instances by pairing NPj with each cluster found previously.",
        "The instances are presented to the learned decision tree to judge the likelihood that NPj is linked to a cluster.",
        "The resolution algorithm is given in Figure 1.",
        "As described in the algorithm, for each cluster under consideration, we create multiple instances by using every NP in the cluster as the reference NP.",
        "The confidence value of the cluster",
        "is the maximal confidence value of its instances.",
        "Similar to the baseline system, two cluster selection strategies, i.e. MRF and BF, could be applied to link NPj to a proper cluster.",
        "For MRF strategy, NPj is linked to the closest cluster with confidence value above 0.5, while for BF, it is linked to the cluster with the maximal confidence value (above 0.5)."
      ]
    },
    {
      "heading": "3.4 Comparison of NP-NP and NP-Cluster based approaches",
      "text": [
        "As noted above, the idea of the NP-Cluster based approach is different from the NP-NP based approach.",
        "However, due to the fact that in our approach a cluster is processed based on its reference NPs, the framework of our approach could be reduced to the NP-NP based framework if the cluster-related features were removed.",
        "From this point of view, this approach could be considered as an extension of the baseline approach by applying additional cluster features as the properties of NPi.",
        "These features provide richer description information of the entity, and thus make the coreference relationship between two NPs more apparent.",
        "In this way, both rules learning and coreference determination capabilities of the original approach could be enhanced."
      ]
    },
    {
      "heading": "4 Evaluation",
      "text": []
    },
    {
      "heading": "4.1 Data collection",
      "text": [
        "Our coreference resolution system is a component of our information extraction system in biomedical domain.",
        "For this purpose, an annotated coreference corpus have been built 4, which",
        "consists of totally 228 MEDLINE abstracts selected from the GENIA data set.",
        "The average length of the documents in collection is 244 words.",
        "One characteristic of the bio-literature is that pronouns only occupy about 3% among all the NPs.",
        "This ratio is quite low compared to that in newswire domain (e.g. above 10% for MUC data set).",
        "A pipeline of NLP components is applied to pre-process an input raw text.",
        "Among them, NE recognition, part-of-speech tagging and text chunking adopt the same HMM based engine with error-driven learning capability (Zhou and Su, 2002).",
        "The NE recognition component trained on GENIA (Shen et al., 2003) can recognize up to 23 common biomedical entity types with an overall performance of 66.1 F-measure (P=66.5% R=65.7%).",
        "In addition, to remove the apparent non-anaphors (e.g., embedded proper nouns) in advance, a heuristic-based non-anaphoricity identification module is applied, which successfully removes 50.0% non-anaphors with a precision of 83.5% for our data set.",
        "4.2 Experiments and discussions Our experiments were done on first 100 documents from the annotated corpus, among them 70 for training and the other 30 for testing.",
        "Throughout these experiments, default learning parameters were applied in the C5.0 algorithm.",
        "The recall and precision were calculated automatically according to the scoring scheme proposed by Vilain et al.",
        "(1995).",
        "In Table 3 we compared the performance of different coreference resolution systems.",
        "The first line summarizes the results of the baseline system using traditional NP-NP based approach as described in Section 2.",
        "Using BF strategy, Baseline obtains 80.3% recall and 77.5% precision.",
        "These results are better than the work by Castano et al.",
        "(2002) and Yang et al.",
        "(2004), which were also tested on the MEDLINE data set and reported a F-measure of about 74% and 69%, respectively.",
        "In the experiments, we evaluated another NP-NP based system, AllAnte.",
        "It adopts a similar learning framework as Baseline except that during training it generates the positive instances by paring an NP with all its antecedents instead of only the closest one.",
        "The system attempts to use such an instance selection strategy to incorporate the information from coreferential clusters.",
        "But the results are nevertheless disappointing: although this strategy boosts the recall by 5.4%, the precision drops considerably by above 6% at the same time.",
        "The overall F-measure is even lower than the baseline systems.",
        "The last line of Table 3 demonstrates the results of our NP-Cluster based approach.",
        "For BF strategy, the system achieves 84.9% recall and 78.8% precision.",
        "As opposed to the baseline system, the recall rises by 4.6% while the precision still gains slightly by 1.3%.",
        "Overall, we observe the increase of F-measure by 2.8%.",
        "The results in Table 3 also indicate that the BF strategy is superior to the MRF strategy.",
        "A similar finding was also reported by Ng and Cardie (2002b) in the MUC data set.",
        "To gain insight into the difference in the performance between our NP-Cluster based system and the NP-NP based system, we compared the decision trees generated in the two systems in Figure 2.",
        "In both trees, the string-similarity features occur on the top portion, which supports the arguments by (Strube et al., 2002) and (Yang et al., 2004) that string-matching is a crucial factor for NP coreference resolution.",
        "As shown in the figure, the feature StrSim1 in left tree is completely replaced by the ClusterStrSim and ClusterStrLNPSim in the right tree, which means that matching the tokens with a cluster is more reliable than with a single NP.",
        "Moreover, the cluster length will also be checked when the NP under consideration has low similarity against a cluster.",
        "These evidences prove that the information from clusters is quite important for the coreference resolution on the data set.",
        "The decision tree visualizes the importance of the features for a data set.",
        "However, the tree is learned from the documents where coreferential clusters are correctly annotated.",
        "During resolution, unfortunately, the found clusters are usually not completely correct, and as a result the features important in training data may not be also helpful for testing data.",
        "Therefore, in the experiments we were concerned about which features really matter for the real coreference resolution.",
        "For this purpose, we tested our system using different features and evaluated their performance in Table 4.",
        "Here we just considered feature ClusterLength (f22), ClusterStrSim (f23) and ClusterStrLNPSim (f24), as Figure 2 has indicated that among the cluster-related features only these three are possibly effective for resolution.",
        "Throughout the experiment, the Best-First strategy was applied.",
        "As illustrated in the table, we could observe that:",
        "1.",
        "Without the three features, the system is equivalent to the baseline system in terms of the same recall and precision.",
        "2.",
        "ClusterStrSim (f23) is the most effective as it contributes most to the system performance.",
        "Simply using this feature boosts the F-measure by 2.7%.",
        "3.",
        "ClusterStrLNPSim (f24) is also effective by improving the F-measure by 2.1% alone.",
        "When combined with f23, it leads to the best F-measure.",
        "4.",
        "ClusterLength (f22) only brings 0.1% F",
        "measure improvement.",
        "It could barely increase, or even worse, reduces the F-measure when used together with the the other two features."
      ]
    },
    {
      "heading": "5 Related work",
      "text": [
        "To our knowledge, our work is the first supervised-learning based attempt to do coreference resolution by exploring the relationship between an NP and coreferential clusters.",
        "In the heuristic salience-based algorithm for pronoun resolution, Lappin and Leass (1994) introduce a procedure for identifying anaphorically linked NP as a cluster for which a global salience value is computed as the sum of the salience values of its elements.",
        "Cardie and Wagstaff (1999) have proposed an unsupervised approach which also incorporates cluster information into consideration.",
        "Their approach uses hard constraints to preclude the link of an NP to a cluster mismatching the number, gender or semantic agreements, while our approach takes these agreements together with other features (e.g. cluster-length, string-matching degree,etc) as preference factors for cluster selection.",
        "Besides, the idea of clustering can be seen in the research of cross-document coreference, where NPs with high context similarity would be chained together based on certain clustering methods (Bagga and Biermann, 1998;"
      ]
    },
    {
      "heading": "6 Conclusion",
      "text": [
        "In this paper we have proposed a supervised learning-based approach to coreference resolution.",
        "Rather than mining the coreferential relationship between NP pairs as in conventional approaches, our approach does resolution by exploring the relationships between an NP and the coreferential clusters.",
        "Compared to individual NPs, coreferential clusters provide more information for rules learning and reference determination.",
        "In the paper, we first introduced the conventional NP-NP based approach and analyzed its limitation.",
        "Then we described in details the framework of our NP-Cluster based approach, including the instance representation, training and resolution procedures.",
        "We evaluated our approach in the biomedical domain, and the experimental results showed that our approach outperforms the NP-NP based approach in both recall (4.6%) and precision (1.3%).",
        "While our approach achieves better performance, there is still room for further improvement.",
        "For example, the approach just resolves an NP using the cluster information available so far.",
        "Nevertheless, the text after the NP would probably give important supplementary information of the clusters.",
        "The ignorance of such information may affect the correct resolution of the NP.",
        "In the future work, we plan to work out more robust clustering algorithm to link an NP to a globally best cluster."
      ]
    }
  ]
}
