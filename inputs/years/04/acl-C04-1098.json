{
  "info": {
    "authors": [
      "Junlin Zhang",
      "Le Sun",
      "Weimin Qu",
      "Yufang Sun"
    ],
    "book": "International Conference on Computational Linguistics",
    "id": "acl-C04-1098",
    "title": "A Trigger Language Model-Based IR System",
    "url": "https://aclweb.org/anthology/C04-1098",
    "year": 2004
  },
  "references": [],
  "sections": [
    {
      "heading": "Abstract",
      "text": [
        "Language model based IR system proposed in recent 5 years has introduced the language model approach in the speech recognition area into the IR community and improves the performance of the IR system effectively.",
        "However, the assumption that all the indexed words are irrelative behind the method is not the truth.",
        "Though statistical MT approach alleviates the situation by taking the synonymy factor into account, it never helps to judge the different meanings of the same word in varied context.",
        "In this paper we propose the trigger language model based IR system to resolve the problem.",
        "Firstly we compute the mutual information of the words from training corpus and then design the algorithm to get the triggered words of the query in order to fix down the topic of query more clearly.",
        "We introduce the relative parameters into the document language model to form the trigger language model based IR system.",
        "Experiments show that the performance of trigger language model based IR system has been improved greatly.",
        "The precision of trigger language model increased 12% and recall increased nearly 10.8% compared with Ponte language model method."
      ]
    },
    {
      "heading": "1 Introduction",
      "text": [
        "Using language models for information retrieval has been studied extensively recently(Jin et al. 2002 Lafferty and Zhai 2001 Srikanth and Srihari 2002 Lavrenko and Croft 2001 Liu and Croft 2002).",
        "The basic idea is to compute the conditional probability P(Q|D), i.e. the probability of generating a query Q given the observation of a document D. Several different methods have been applied to compute this conditional probability.",
        "In most approaches, the computation is conceptually decomposed into two distinct steps: (1) Estimating a document language model; (2) Computing the query likelihood using the estimated document model based on some query model.",
        "For example, Ponte and Croft emphasized the first step, and used several heuristics to smooth the Maximum Likelihood of the document language model, and assumed that the query is generated under a multivariate Bernoulli model (Ponte and Croft 1998).",
        "The BBN method (Miller et al. 1999) emphasized the second step and used a two-state hidden Markov model as the basis for generating queries, which, in effect, is to smooth the MLE with linear interpolation, a strategy also adopted in Hiemstra and Kraaij (Hiemstra and Kraaij 1999).",
        "In Zhai and Lafferty (Zhai and Lafferty 2001), it has been found that the retrieval performance is affected by both the estimation accuracy of document language models and the appropriate modeling of the query, and a two stage smoothing method was suggested to explicitly address these two distinct steps.",
        "It’s not hard to see that the unigram language model IR method contains the following assumption: Each word appearing in the document set and query has nothing to do with any other word.",
        "Obviously this assumption is not true in reality.",
        "Though statistical MT approach (Berger and Lafferty 1999 ) alleviates the situation by taking the synonymy factor into account, it never helps to judge the different meanings of the same word in varied context.",
        "In this paper we propose the trigger language model based IR system to resolve the problem.",
        "Though the basic idea of using the triggered words to improve the performance of language model was proposed by Raymond almost 10 years ago (Raymond et al. 1993), Our method adopts a different approach for other objectivity in the IR field.",
        "Firstly we compute the mutual information of the words from training corpus and then design the algorithm to get the triggered words of the query in order to fix down the topic of query more clearly.",
        "We introduce the relative parameters into the document language model to form the trigger language model based IR system.",
        "Experiments show that the performance of trigger language model based IR system has been improved greatly.",
        "In what follows, Section 2 describes trigger language model based IR system in detail.",
        "Section 3 is our evaluation about the model.",
        "Finally, Section 4 summarizes the work in this paper."
      ]
    },
    {
      "heading": "2 Trigger Language Model based IR System",
      "text": []
    },
    {
      "heading": "2.1 Interrelationship of Indexing Words",
      "text": [
        "In order to find out the interrelationship of words in some specific context, we consider the co-occurring times of different words within fixed sized text window of the document.",
        "When the co-occurring time is large enough, we think that relationship is meaningful.",
        "Mutual Information is a common tool to be applied under this situation.",
        "So we compute the mutual information as following:",
        "where Nw denotes the size of the vocabulary, N(wa, wb, Lw) is the co-occurring times of word wa and wb within Lw sized window in training set.",
        "N(wa) is the count of the word wa appearing in the training set and N(wb) is the count of word wb appearing in the training set.",
        "We use the corpus provided by IR task of NTCIR2 (NTCIR 2002) as the training set to compute the mutual information of words.",
        "This corpus contains nearly 100 thousands news articles encoding in BIG5 charset.",
        "We think the mutual information which is larger than 25 is meaningful.",
        "Considering the stop words in document or query are useless to represent the content, we remove 200 highest frequent words from the document before computation.",
        "Table 1 shows some examples with higher mutual information."
      ]
    },
    {
      "heading": "2.2 Algorithm of Triggered Words by Query",
      "text": [
        "Generally speaking, a word always represents many different meanings and its exact meaning adopted in specific topic can be determined by the co-occurring words in its context.",
        "Different meaning of a word often lead to the different vocabulary set of related word.",
        "In order to find out the exact meaning of the words contained by the query in IR system, we design the algorithm to compute the triggered vocabularies of query.",
        "It is just these triggered words that show the exact meaning of the words in query in some specific context and help fix down the topic of query more clearly.",
        "The basic idea behind the algorithm is as following: By computing the mutual information, we can derive the relative words of a query word.",
        "All these words mean the semantically related vocabularies of the query word under different contexts.",
        "We propose that if the intersection of the derived related words of different words in query is not null, the words in the intersection is useful to judge the exact meaning of the words in query.",
        "At the same time, the more times an intersection word appears in related vocabulary set of different query word, the higher the weight of this word to fix down the topic of the query is.",
        "So we design the following algorithm to compute the triggered vocabulary set of query: Algorithm 1:Triggered vocabularies by query Input: Vocabulary set I of query word and its co-occurring words after removing the stop words in the query."
      ]
    },
    {
      "heading": "2.1 get the different",
      "text": [
        "combination L ={<qj 1,S 1 >,<qj,2,S,2 > <%j,S; >} which contains i elements from set I;"
      ]
    },
    {
      "heading": "2.2 if any vocabulary set Sj ,k (1 < k <= i)",
      "text": [
        "in Lj contains no element, then we turn to 2.4 , otherwise we turn to 2.3;"
      ]
    },
    {
      "heading": "2.3 Compute the intersection T,. j of all",
      "text": [
        "vocabulary set Sj k (1 < k <= i) in Lj Here Ti ,j ={<w1,α1 >,<w2,α2 >, <wm,αi >} , where α = log i , (1=< w <= i ).",
        "αw is the",
        "word weight decided by the length of Lj ; 2.4 T = T ∪ Ti j , adopting the higher word weightαw during the merging process; } } Step 3.",
        "Output the triggered vocabulary set T;"
      ]
    },
    {
      "heading": "2.3 Similarity Computation of Query and Document",
      "text": [
        "We use the similar strategy with Ponte language model method (Ponte and Croft 1998) to compute the similarity between the query and the document.",
        "That is, we firstly construct the simple language model according to the statistical information of vocabulary and then compute the generative probability of the query.",
        "The difference is that the trigger language model method takes the context information of a word into account.",
        "So we compute the triggered words set of query q according to algorithm 1.This way we get the triggered vocabulary set",
        "This set contains the words triggered by query and it is these triggered words that determine the exact meaning of the vocabularies in query among the several optional choices.",
        "This helps fix down the topic of query more clearly.",
        "Introducing the triggered words factor into the document language model, we can form the trigger language model based information retrieval system.",
        "The similarity of query and document can be computed as following:",
        "(1) Q = {q1,q2, qi ,.... ql(Q)} denotes query and l (Q) is the length of the query; (2) Md denotes the trigger language model of document d;",
        "document in document set and 1(d) is the length of the document;",
        "words di in a document.",
        "Here f (dj) means the account of the words dj appearing in the document.",
        "(5) p(q; I dj) denotes the probability of q;",
        "being triggered by the document word di .When 2 words are same, the probability equals 1.",
        "If they are different and the word di belongs to the triggered vocabulary set of query, the probability equals the according parameter in the T9,otherwise the probability is 0。",
        "tf (q;) denotes times of query word q; appearing in document set and cs denotes the total length of documents which contains the word q,."
      ]
    },
    {
      "heading": "3 Experiment Results",
      "text": []
    },
    {
      "heading": "3.1 Corpus",
      "text": [
        "The corpus we used to evaluate the performance of our proposed trigger language model IR system is the document set offered by the traditional Chinese Document set of NTCIR3 for the IR task.",
        "The corpus consists of 381681 news articles from Hong Kong and Taiwan with varied topics.",
        "After the word segmentation, the document set contains 150700953 words.",
        "Among them,127519 different words are the entries of the vocabulary.",
        "The average length of each document is 394.",
        "The 50 queries offered by NTCIR3 IR task are contained in a XML file and each query consists of following elements: Topic Number(NUM),Topic Title(TITLE),Topic question(DESC),Topic Narrative(NARR) and Topic Concepts(CONC).",
        "In order to make it easer to compare the performance of the different IR methods, we adopt the Topic Question field as the query and regard the top 1000 retrieval documents as the standard result of the experiment."
      ]
    },
    {
      "heading": "3.2 Analysis of Experiment Results",
      "text": [
        "We design 3 relative experiments to evaluate the trigger language model IR method: vector space model, Ponte language model based method and the trigger language model approach.",
        "Precision and recall are two main evaluation parameters.",
        "As for the trigger model IR method, the optimal size of the text window is 20 content words and the mutual information over 25 is regarded as the meaningful information.",
        "Experiment results can be seen in table 2.",
        "The data of column % Al in table 2 shows the performance improvement of Ponte language model compared with vector space model.",
        "The data tells us that the precision of language model based method increased 10% and recall increased nearly 13.7%.",
        "The data of column % ∆2 in table 2 shows the performance improvement of trigger language model compared with Ponte language model method.",
        "From the data we can see that the precision of trigger language model increased 12% and recall increased nearly 10.8%.",
        "We can draw the conclusion that the trigger language model has improved the performance greatly.",
        "The performance comparison can be showed more clearly in figure 1."
      ]
    },
    {
      "heading": "Acknowledgement 4 Conclusion",
      "text": [
        "Language model based IR system proposed in recent 5 years has introduced the language model approach in the speech recognition area into the IR community and improves the performance of the IR system effectively.",
        "However, the assumption that all the indexed words are irrelative behind the method is not the truth.",
        "Though statistical MT approach alleviates the situation by taking the synonymy factor into account, it never helps to judge the different meanings of the same word in varied context.",
        "In this paper we propose the trigger language model based IR system to resolve the problem.",
        ".",
        "Firstly we compute the mutual information of the words from training corpus and then design the algorithm to get the triggered words of the query in order to fix down the topic of query more clearly.",
        "We introduce the relative parameters into the document language model to form the trigger language model based IR system.",
        "Experiments show that the performance of trigger language model based IR system has been improved greatly.",
        "This work is supported by Beijing New Star Plan of Technology & Science(NO.H020820790130) and the National Science Fund of China under contact 60203007."
      ]
    }
  ]
}
