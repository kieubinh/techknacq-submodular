{
  "info": {
    "authors": [
      "Hiroyuki Sakai",
      "Shigeru Masuyama"
    ],
    "book": "International Conference on Computational Linguistics",
    "id": "acl-C04-1144",
    "title": "A Multiple-Document Summarization System With User Interaction",
    "url": "https://aclweb.org/anthology/C04-1144",
    "year": 2004
  },
  "references": [
    "acl-J02-4005",
    "acl-P02-1058",
    "acl-P99-1071",
    "acl-W00-0405",
    "acl-W00-0409",
    "acl-W02-1907"
  ],
  "sections": [
    {
      "heading": "Abstract",
      "text": [
        "We propose a multiple-document summarization system with user interaction.",
        "Our system extracts keywords from sets of documents to be summarized and shows the keywords to a user on the screen.",
        "Among them, the user selects some keywords reflecting his/her needs.",
        "Our system controls the produced summary by using these selected keywords.",
        "For evaluation of our method, we participated in TSC3 of NTCIR4 workshop by letting our system select 12 best keywords regarding scoring by the system.",
        "Our participated system attained the best performance in content evaluation among systems not using sets of questions.",
        "Moreover, we evaluated effectiveness of user interaction in our system.",
        "With user interaction, our system attained both higher coverage and precision than that without user interaction."
      ]
    },
    {
      "heading": "1 Introduction",
      "text": [
        "Recent rapid progress of computer and communication technologies enabled us to access enormous amount of machine-readable information easily.",
        "However, this has caused the information overload problem.",
        "In order to solve this problem, automatic summarization methods have been studied (Mani and T.Maybury, 1999).",
        "In particular, the necessity for a multiple-document summarization has been increasing and the multiple-document summarization technology has been intensively studied recently (Mani, 2001).",
        "In this paper, we define multiple-document summarization as a process for producing a summary from a relevant document set.",
        "Such a document set may be very large and may contain a number of topics.",
        "It is preferable that a summary produced by a multiple-document summarization system from the document set covers all topics contained in the document set.",
        "However, it is difficult to produce a summary that covers all the topics in the document set with a small number of characters.",
        "For example, a document set relevant to “releasing AIBO” contains some topics, e.g., what is AIBO?, how to sell AIBO?, etc.",
        "Moreover, sentences recognized as important sentences considerably differ person to person (Nomoto and Matsumoto, 2001).",
        "This is because “summarization need”, i.e., topics a different person wants to read, may differ.",
        "Hence, we propose a multiple-document summarization system with user interaction for coping appropriately with user’s summarization need.",
        "Our system extracts keywords from a document set to be summarized and shows the keywords to a user.",
        "Among them, the user selects keywords reflecting user’s summarization need.",
        "Our system controls a produced summary by using the keywords selected by the user.",
        "For realizing our purpose, we have devised a scoring method for keywords extraction specialized to our purpose.",
        "We would like to emphasize here the fact that scoring of words for extracting keywords shown to a user is crucial for the system performance as well as different from those used in usual automatic indexing.",
        "We participated in TSC3 (Text Summarization Challenge - 3) of NTCIR4 workshop 1 and attained the best performance in content evaluation among systems not using sets of questions.",
        "Note that our system participated in TSC3 is an automatic summarization system without user interaction by letting our system with user interaction select 12 best keywords regarding scoring by the system.",
        "Moreover, we evaluated effectiveness of user interaction and that with user interaction attained both higher coverage and precision than that without user interaction.",
        "ously proposed multiple-document summarization methods (see, e.g.,(Barzilay et al., 1999), (Mani and Bloedorn, 1999), (Goldstein et al., 2000), (Ando et al., 2000), (Lin and Hovy, 2002), (Nobata and Sekine, 2002), (Hirao et al., 2003)) in that: (1) Our system can produce a summary coping appropriately with each user’s summarization need by letting a user select keywords reflecting user’s summarization need.",
        "(2) The keywords are extracted automatically from a document set to be summarized by calculating a score to each noun contained in the document set.",
        "The formula to calculate scores consists of not only frequency of nouns and document frequency used in t f • idf but also distribution of nouns in the document set and location of nouns in documents or the document set.",
        "The reason why such factors are used will be explained in the next section.",
        "(3) Our system deletes redundant adnominal verb phrases in sentences to reduce the number of characters in a sentence.",
        "The deletable adnominal verb phrases are decided statistically by using entropy based on a probability that verbs modify noun, etc.",
        "Our previous method (Sakai and Masuyama, 2002) adjusted to multiple-document summarization so that more deletable adnominal verb phrases are recognized, is used in this system.",
        "The interactive summarization system has been introduced for the first time by (Saggion and Lapalme, 2002).",
        "The system proposed in (Saggion and Lapalme, 2002) is based on shallow syntactic and semantic analysis, conceptual identification and text re-generation, while, our system is based on a statistical method."
      ]
    },
    {
      "heading": "3 The method to extract relevant keywords",
      "text": [
        "A relevant document set S to be summarized may be regarded as a document set obtained by a hypothetical query from the entire document set Δ to be considered.",
        "In TSC3, the entire document set consists of newspaper articles, Mainichi newspaper and Yomiuri newspaper, Japanese daily newspapers, from January 1 to December 31, 1998, 1999.",
        "We explain a method to extract keywords relevant to such a hypothetical query from document set S. Here, we define such keywords as relevant keywords ti, i = 1, 2, ... , k. We assign scores to nouns contained in document set S and nouns assigned a large score are extracted as relevant keywords.",
        "A large score is assigned if a noun fulfills the following four conditions.",
        "1.",
        "The noun that appears frequently in the document set S to be summarized.",
        "2.",
        "The noun that appears uniformly in each document d E S. 3.",
        "The noun that appears in the beginning",
        "of a document (i.e., the 1st sentence) and in the beginning of the document set in chronological order (i.e., the 1st document).",
        "4.",
        "The noun that does not appear frequently in entire document set Δ.",
        "Our method for extracting relevant keywords consists of the following two steps.",
        "rt(ti, d): the document number of document d containing noun ti for the first time in document set S in chronological order.",
        "idf (ti, Δ): idf (Baeza-Yates and Ribeiro-Neto, 1999) value assigned to noun ti in entire document set Δ.",
        "En(ti, S) is an entropy based on a probability that noun ti appears in document d E S. For example, En(ti, S) assigned to noun ti contained only in one document d E S is 0.",
        "Though such noun ti may be an important noun for document d, it may be an irrelevant noun for document set S. Hence, noun ti that is assigned small entropy value should not be extracted as a relevant keyword.",
        "However, a noun that appears uniformly in each document contained in document set S has a large entropy value.",
        "En(ti, S) is calculated by formula 3.",
        "The 3rd term in formula 1 is to assign a large value to a noun appearing in the beginning of a document.",
        "The 4th term in formula 1 is to assign a large value to a noun appearing in the beginning of a document set in chronological order.",
        "The reason why these members are included is that the 1st sentence in the 1st document frequently contains important information (see, e.g.,(Nobata and Sekine, 2002))."
      ]
    },
    {
      "heading": "4 The method to extract important sentences",
      "text": [
        "The method to extract important sentences measures similarity between a sentence and the set of relevant keywords selected by a user, and extracts sentences assigned large similarity as important sentences.",
        "The similarity is calculated as cosine metric between a vector of a sentence and a vector of the set of relevant keywords.",
        "If the same noun as relevant keywords is contained frequently in a sentence, the cosine metric assigned to the sentence has a large value.",
        "The method to extract important sentences is summarized as follows: Here, we define relevant keywords shown to a user as keyword set K and define relevant keywords selected by a user as keyword set U.",
        "Step 1: Recalculate score of relevant keywords ti’s by the following formula.",
        "Here, we define the number of keywords shown to a user to be k.",
        "Step 2: Generate relevant keyword vector VK consisting of W'(ti, S) (i = 1, ... , k) assigned to each relevant keyword (ti E K).",
        "Step 3: Generate sentence vector Vs consisting of W'(tj, S) (j = 1, ... , m) assigned to each noun contained in sentence s (tj E s).",
        "Step 4: Calculate a cosine metric between vector VK and vector Vs as similarity sim(s, K) by formula 6.",
        "Step 5: Extract the sentences with m largest similarity sim(s, K) as important sentences and output these m sentences in chronological order.",
        "Step 2: If d(s1, s2) has a value smaller than a characters in a sentence.",
        "We define adnomi-threshold value, delete sentence si having anal verb phrases as phrases that modify a noun smaller cosine metric sim(si, K).",
        "and include a verb modifying the noun.",
        "For example, in the case of “SONY ga kaihatsu shita aibo(: the AIBO devel",
        "Step 3: Calculate a cosine metric between vector Vsdl and vector Vsda as similarity sim(sd1, sd2).",
        "Step 4: If sim(sd1, sd2) has a value larger than a threshold value, delete document di (i = 1 or 2) having a smaller score W(sdi) (sdi is in di).",
        "Score W(sdi) is calculated by the following formula 8.",
        "Here, documents d1 and d2 are newspaper articles issued on the same day.",
        "We determined the threshold value to be 0.85 in Step 4 by trial and error using sample data provided by the organizer of TSC3.",
        "Note that this sample data has not used in the formal run as a document set to be summarized.",
        "Note that if di is deleted, sentences contained in document di are not extracted and the important sentences extracted by our system are changed.",
        "Hence, our system executes this algorithm to delete documents and the algorithm to extract important sentences iteratively until no document is deleted by this algorithm.",
        "6 The method to reduce the number of characters in a sentence Our system deletes redundant adnominal verb phrases in sentences to reduce the number of We determined the threshold value to be 0.0001 in Step 2.",
        "This is a sufficiently small value to regard contents of s1 identical to contents of s2.",
        "Next, redundant information contained in the document set is deleted as follows.",
        "Here, we define a set of important sentences contained in document di as sdi.",
        "The method is as follows.",
        "Step 1: Generate vector Vsdl, consisting of W'(ti, S) (i = 1, ... , n) assigned to nouns contained in sd1.",
        "where, V (n): set of verbs contained in adnominal verb phrases modifying noun n in entire document set Δ, f (v, n): frequency of verb v modifying noun n in entire document set Δ.",
        "IM(VP(n), s): a factor to reflect rating of context in adnominal verb phrase VP(n) contained in sentence s. CV(n, s): the number of occurrences of noun n modified by adnominal verb phrases from the 1st sentence in the 1st document to sentence s in document d E S in document set S in chronological order.",
        "J(n): the number of common nouns contained in noun n if noun n is a compound noun.",
        "The IM(VP(n), s) is calculated by formula 14.",
        "IM(VP(n), s) = 0.5 + R E I(c, s) (14)",
        "where, R: the number of segments composing adnominal verb phrase VP(n), W'(c, S): the score calculated by formula 5 to noun c contained in adnominal verb phrase VP(n).",
        "CT(c, s): the number of occurrences of noun c contained in adnominal verb phrases from the 1st sentence in the 1st document to sentence s in document d E S in document set S in chronological order.",
        "We introduced CV (n, s) in formula 12 and CT (c, s) in formula 15 in order to recognize more deletable adnominal verb phrases than our previous method applied directly to multiple-document summarization."
      ]
    },
    {
      "heading": "7 Implementation",
      "text": [
        "We implemented our method and developed a multiple-document summarization system.",
        "We employed JUMAN 3 as a morphological analyzer, and KNP4 as a parser.",
        "We show a summary produced by our system in Figure 1.",
        "The document set to be summarized contains 9 documents relevant to “releasing AIBO” and the summary consists of less than 236 characters.",
        "Moreover, we show a summary in Figure 2 when a user selects keywords relevant to the movement and performance of AIBO (e.g., “",
        "1999.)",
        "Our system participated in TSC3 is not a system with user interaction for realizing automatic multiple documents summarization.",
        "Hence, we define the following execution of our system to be “Auto” for realizing an automatic multiple-document summarization system without user interaction.",
        "Auto: The execution of our system where 12 best keywords regarding scoring by the system are selected.",
        "The number of keywords selected by the system is determined by trial and error using sample data provided by the organizer of TSC3.",
        "The main evaluation method of TSC3 is : Content evaluation: Human judges match summaries they produced with system results at sentence level, and evaluate the results based on the degree of the matching (how well they match).",
        "The sentences in the human-produced summaries have values that show the degree of importance, and these values are taken into account at the final evaluation 5."
      ]
    },
    {
      "heading": "8.1 Evaluation results of TSC3",
      "text": [
        "The result of content evaluation is shown in Figure 3 6.",
        "Here, “AUTO” shows our system that participated in TSC3.",
        "“Lead” is the lead method, a baseline method.",
        "In TSC3, we are given the sets of questions about important information of the document sets by the organizer of TSC3.",
        "Note that these sets of questions are produced from summaries made by human as correct data.",
        "(For example: when will AIBO",
        "be released ?",
        "etc.)",
        "Here, we exclude evaluation results of a system that uses the sets of questions for producing summaries of multiple documents 7.",
        "The reason is as follows.",
        "As mentioned above, the sets of questions are produced from summaries made by human as correct data.",
        "Hence, we consider that using the sets of questions as machine-readable information for producing summaries is not realistic.",
        "Moreover, we consider that comparing systems using the sets of questions with systems not using them by ranking is unfair.",
        "By the result shown in figure 3, our system that implemented “AUTO” has attained the best performance among the systems not using the sets of questions.",
        "8.2 Evaluation of user interaction Our system is essentially a multiple-document summarization system with user interaction.",
        "Hence, we evaluate effectiveness of user interaction of our system in this subsection.",
        "For evaluating it, we consider the following execution of our system: Interaction: Execution of our system where relevant keywords contained in the set of questions are selected, and relevant keywords not contained in the set of questions are deleted.",
        "The “Interaction” simulates user interaction on our system.",
        "(i.e., we regard the set of questions mentioned at the beginning of Sec.8.1 as user’s summarization need.",
        "Since the set of questions produced from summaries by human (i.e., user), will be able to regard the questions as user's we summarization need.)",
        "The coverage and precision of “Interaction” is shown in Figure 4.",
        "Moreover, the coverage and precision of “Auto” and “Lead” are shown for comparison.",
        "Here, the coverage and precisions which take redundancy into account are obtained by using the scoring tool provided for the subtask in TSC3."
      ]
    },
    {
      "heading": "9 Discussion",
      "text": [
        "From the result shown in figure 3, our system participating in TSC3 as “Auto” attained the best performance among the systems not using the sets of questions.",
        "We think the reason why the good performance was attained is that the first 12 keywords extracted from a document set to be summarized by scoring by our method",
        "were appropriate.",
        "Sentences extracted by using keywords irrelevant to the document set may not probably be important.",
        "From the result shown in figure 4, we conclude that the “Interaction” is more effective than the “AUTO”.",
        "Moreover, the effectiveness of user interaction in the case of “long” is more remarkable than that of “short”.",
        "The reason why the effectiveness of user interaction in the case of “long” is more remarkable is as follows.",
        "In the case of “short”, our system has to extract sentences fewer than that of “long”.",
        "Even if a user had changed relevant keywords to use for sentence extraction, the sentences extracted by our system are not necessarily changed in the case of “short”.",
        "However, the extracted sentences are greatly changed in the case of “long” when a user had changed relevant keywords.",
        "Hence, we consider that sentences are extracted well by changing relevant keywords in the case of “long”."
      ]
    },
    {
      "heading": "Acknowledgment",
      "text": [
        "This work was supported in part by The 21st Century COE Program “Intelligent Human Sensing”, from the ministry of Education, Culture, Sports, Science and Technology of Japan and The Grant-in-Aid from the Japan Society for the Promotion of Science."
      ]
    }
  ]
}
