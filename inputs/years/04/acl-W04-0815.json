{
  "info": {
    "authors": [
      "Stephen Anthony",
      "Jon David Patrick"
    ],
    "book": "SENSEVAL International Workshop on the Evaluation of Systems for the Semantic Analysis of Text",
    "id": "acl-W04-0815",
    "title": "Dependency Based Logical Form Transformations",
    "url": "https://aclweb.org/anthology/W04-0815",
    "year": 2004
  },
  "references": [
    "acl-A97-1011",
    "acl-J02-3001",
    "acl-W02-0815",
    "acl-W99-0501"
  ],
  "sections": [
    {
      "heading": "Abstract",
      "text": [
        "This paper describes a system developed for the transformation of English sentences into a first order logical form representation.",
        "The methodology is centered on the use of a dependency grammar based parser.",
        "We demonstrate the suitability of applying a dependency parser based solution to the given task and in turn explain some of the limitations and challenges involved when using such an approach.",
        "The efficiencies and deficiencies of our approach are discussed as well as considerations for further enhancements."
      ]
    },
    {
      "heading": "1 Introduction",
      "text": [
        "In addition to the well-known all words and lexical sample tasks deployed in previous Senseval workshops a number of new tasks have been included in this sense evaluation.",
        "These new tasks include identification of semantic roles as in FrameNet (Gildea and Jurafsky 2002), disambiguation of WordNet glosses (Miller 1990; Fellbaum 1998; Harabagiu, Miller et al.",
        "1999), automatic acquisition of subcategorisation frames (Korhonen 2002; Preiss and Korhonen 2002), and Logical Form Identification (LFI) (Rus 2002; Rus and Moldovan 2002).",
        "This paper discusses a solution developed for the LFI task.",
        "The approach used here employs a functional dependency parser (Järvinen and Tapanainen 1997; Tapanainen and Järvinen 1997) and uses a limited number of additional resources.",
        "This contribution is intended to demonstrate the suitability of a dependency parser to the given task and also explain some of the limitations and challenges involved when using such an approach."
      ]
    },
    {
      "heading": "1.1 Motivation",
      "text": [
        "Part of the initial step towards the interpretation of a sentence as postulated by Hobbs et al.",
        "(1993) involves the proof of the logical form of a sentence.",
        "This statement entails the transformation of a sentence into a logical form as a fundamental building block towards sentence interpretation.",
        "Advantages specifically related to the utilisation of logical forms in language processing include a simplified interface between syntax and semantics, a natural and easily exploitable representation of syntactic arguments, and the potential for formation of conceptual predicates (Rus 2002) if predicates are disambiguated with respect to a general ontology such as WordNet."
      ]
    },
    {
      "heading": "1.2 Task Description",
      "text": [
        "The Logical Form (LF) employed in this task is a flat, scope-free first order logic representation that embeds lexical and syntactic information.",
        "A predicate is generated for every nominal, verbal, adjectival, and adverbial content word.",
        "The name of the predicate is a concatenation of the lemmatised word form and part-of-speech category.",
        "The sentence below is followed by its corresponding target logical form representation.",
        "Some students like to study in the mornings.",
        "Relationships between predicates are shared through their arguments.",
        "The two types of arguments used are events (e) and entities (x).",
        "Using the transformation shown above as an example, the event predicate ‘like’ is labeled as e4 and has subject argument x3 which corresponds to ‘student’ and grammatical object argument e6 which corresponds to the ‘study’ event predicate.",
        "The remainder of the argument slots are reserved for indirect and prepositional objects.",
        "Determiners, plurals, negation, auxiliaries, verb tenses, and punctuation are excluded from the final representation."
      ]
    },
    {
      "heading": "2 Methodology",
      "text": [
        "The system is built using a highly modular design and is intended to be as generic and reusable as possible.",
        "The basic data structure is a flat list-like representation with generic property slots attached to each element.",
        "This structure maximises compatibility with the final representation and allows for greater flexibility in the types of information that may be associated with each predicate.",
        "Figure 1 illustrates the major processing modules available and the work flow.",
        "A syntactic parse including functional dependencies is produced on a per sentence basis.",
        "Definitions of the properties associated with each token are presented in Table 1.",
        "token The resultant parse is transformed into a linear data structure indexed by word position.",
        "This is illustrated in Table 2 using the example sentence ‘Some students like to study in the mornings’.",
        "The original token text is stored, as is the lemmatised form.",
        "Head and dependency type are the most important class of information used by the system.",
        "The dependency type and head of the token is often directly, if not indirectly, translatable into a predicate argument.",
        "Examples of the types of dependency functions employed include subject, object, prepositional complement, agent, subject and object complements, indirect object, goal, and coordinating conjunctions.",
        "Determiner and negator functions are also of interest because they are excluded from the final representation.",
        "The filter module moderates the presence or absence of tokens using stop lists or pass lists or a combination of both.",
        "Stop lists are used to specify content to be excluded from the token stream and pass lists specify elements that should remain.",
        "Tokens may be filtered from the stream based on any attribute type and value listed in Table 1.",
        "This information is provided in the filter set.",
        "The principal types of information filtered in this system are determiners based on morphological tags and auxiliaries based on syntactic tag information.",
        "For example ‘some’ and ‘the’ are filtered as a consequence of a morpho property equals ‘DET’ stop list rule.",
        "When the token stream has been annotated with the necessary information and has passed through the filter, the tokens that remain are passed through the logical form processor (LFP).",
        "The main function of the LFP is to build an inverted index identifying all dependent tokens.",
        "Once grammatical dependencies are assigned and the inverted index is built the logical form representation may be constructed.",
        "Each predicate is constructed from the token stream in turn based on the part-of--speech category of the token.",
        "The base form of the token is concatenated with the part-of-speech tag.",
        "A mapping table is used to transform the part-of-speech information pro",
        "duced by the parse into the coarser grained WordNet tags.",
        "Entities are the simplest type of predicate to construct as they contain only a single argument, for which the word identifier attribute value is used.",
        "Noun tokens ‘student’ and ‘morning’ from the example are transformed into the predicates student:n_(x3) and morning:n_(x9).",
        "Pronouns, prepositional complements, and coordinating conjunctions are dealt with individually using their respective dependency function values.",
        "Adjectives are constructed using the head dependency value as the argument unless the dependent is marked with a subject.",
        "In this case the argument becomes the head of the subject.",
        "Adverbs are created primarily using the dependency function alone.",
        "Verbal predicates are constructed using SUBJ, OBJ, GOAL, OC, I-OBJ, COMP, and PCOMP dependencies in the specified order.",
        "A special case exists for verbs that have object complement dependencies.",
        "In these cases attributive nominals are identified and assigned as arguments independently.",
        "The main verb ‘like’ in our example is transformed into the predicate like:v_(e4, x3, e6) as a result of subject (SUBJ) and object (OBJ) dependencies found in ‘student’ and ‘study’ respectively.",
        "Given the fact that we are dealing with the main verb, the LFP inverts the subject and object dependencies, inserts them into the head verb token property slot and assigns their respective word identifier values.",
        "The inverted properties augment the token slot for ‘like’ which has word identifier four in Table 2.",
        "The additional elements of the inverted index used to build the predicate are listed in Table 3.",
        "identifier three matches the grammatical subject token ‘students’ aid word identifier nine matches the head of the prepositional phrase ‘in the mornings’."
      ]
    },
    {
      "heading": "3 Evaluation",
      "text": []
    },
    {
      "heading": "Argument,predicate,andsentencelevelprecisionandrecallmeasuresareusedtoevaluateperform-anceofthesystemascomparedtoagold-standard.",
      "text": [
        "The system was trained on a set of 50 sentences with corresponding logical forms.",
        "Final testing was performed on aset of 300 LF-sentence pairs."
      ]
    },
    {
      "heading": "3.2 Predicate Level 3.3 Sentence Level",
      "text": [
        "The major source of error in terms of arguments originated from the parser’s inappropriate handling of coordinating conjunctions.",
        "Another common source of error arose from poor handling of nominal group complexes.",
        "With regard to predicate performance, the decision to forfeit the use of the available multi-word item list proved costly."
      ]
    },
    {
      "heading": "5 Future Work",
      "text": [
        "Harabagiu et al.",
        "(1999) proposed a scheme for attaching sense tags to predicates within the framework of transforming WordNet glosses into a logical form.",
        "In this way conceptual predicates may be formed to manipulate a meaning representation in more significant ways.",
        "Naturally the sense inventory must be sensitive enough to allow for a meaningful and representative mutation to be applied to the meaning representation."
      ]
    },
    {
      "heading": "6 Conclusions",
      "text": [
        "Dependency grammars provide a natural and intuitive solution to the task of logical form identific a-tion.",
        "We have managed to demonstrate relatively good overall performance on the given task with minimal additional processing and a very small amount of training data.",
        "It is argued that a dependency grammar based parse provides a rich source of knowledge that is suitable for the transformation of English sentences into a logical form.",
        "It would appear that there is to a large extent enough information embedded within the parser’s output to achieve the desired outcome.",
        "It is however apparent that other types of information could further improve the solution.",
        "These types of information include named entity recognition and multi-word phrase detection."
      ]
    }
  ]
}
