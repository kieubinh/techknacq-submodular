{
  "info": {
    "authors": [
      "Mauro Castillo",
      "Francis Real",
      "Jordi Atserias",
      "German Rigau"
    ],
    "book": "SENSEVAL International Workshop on the Evaluation of Systems for the Semantic Analysis of Text",
    "id": "acl-W04-0823",
    "title": "The TALP Systems for Disambiguating WordNet Glosses",
    "url": "https://aclweb.org/anthology/W04-0823",
    "year": 2004
  },
  "references": [
    "acl-H93-1052",
    "acl-J92-1001",
    "acl-J95-4004",
    "acl-P97-1007",
    "acl-W99-0501"
  ],
  "sections": [
    {
      "text": [
        "the current content of the MEANING Multilingual Central Repository (McR) (Atserias et al., 2004) (i.e. SUMO, WordNet Domains, etc.).",
        "Given a word from a gloss, each heuristic votes for different synsets.",
        "The program simply adds up the votes for each word sense, selecting the most voted sense.",
        "We have presented two different systems using two different preprocess.",
        "• PRE-XWN (XWN preprocess) uses the gloss segmentation and PoS tagging provided by the XWN.",
        "• In PRE-TALP (TALP preprocess) first, the sentences are tokenized and then passed on to a multiword identification module.",
        "Then, the output containing the multi-words is POS tagged using Eric Brill's tagger (Brill, 1995).",
        "Tagged words and multiword expressions are lemmatized using `YN.",
        "PRE-XWN 00256298n the restoration,#n(s) of run-down,#a(g) urban,#a(n) areas,#n(n) by the mid-dle,#a class,#n(n) ( resulting,#v(n) in the displace-ment,#n of lower,#a(n) - income,#n(s) people,#n(n) PRE-TALP 00256298n the restoration,#n of run-down,#v urban-areas,#n by the middle-class,#n resulting,#v in the displacement,#n of lower,#a - income,#n people,#n )",
        "haviours of both preprocessing systems.",
        "PRE-TALP recognizes the Multi Word Expression urban-area and middle-class, while XWN split them in several words.",
        "On the other hand, the tagger did not recognize run-down as an adjective.",
        "Obviously, different segmentation and tagging preprocessing causes different word counts and scoring."
      ]
    },
    {
      "heading": "2.1 Heuristics",
      "text": [
        "The main heuristics used in the disambiguation process are:",
        "1.",
        "Monosemous: Applying a closed – world assumption, this heuristic identifies monosemous words.",
        "2.",
        "Most Frequent: Based on `YN2.0 sense frequencies, this heuristic only selects those",
        "synsets having frequencies higher than the 85% of the most frequent senses.",
        "3.",
        "Hypernym: This method follows the hy-pernym chain looking for words appearing in the gloss (e.g. the genus term).",
        "4.",
        "WordNet Relations: This heuristic follows any synset relation looking for words appearing in its gloss.",
        "The method does not only use direct relations, but also performs a chaining search following all relations and stopping at distance five.",
        "5.",
        "MultiWordNet Domains (Magnini and Cavagli, 2000): Having a synset with a particular `YN Domain label, this method selects those synsets from the words of the gloss having the same Domain label.",
        "6.",
        "Patterns: This method uses the \"One sense per collocation\" heuristic (Yarowsky, 1993), implementing those patterns appearing in (Novischi, 2002).",
        "7.",
        "Lexical Parallelism: This heuristic identifies the words with the same PoS separated by comas or conjunctions and marks",
        "them, when possible, with senses that belong to the same hierarchy.",
        "a. SUMO (Niles and Pease, 2001): Having a synset with a particular SUMO label, this method selects those synsets from the words of the gloss having the same SUMO label.",
        "9.",
        "Category: Having a synset being connected to a particular `YN CATEGORY,",
        "this method selects those synsets from the words of the gloss connected the same CATEGORY.",
        "10.",
        "Bigram: This heuristic uses high frequency word sense pairs occurring in SemCor.",
        "11.",
        "Sense One: Finally, this heuristic always assigns the first `YN sense.",
        "3 Test Data",
        "The test set consists of 15,179 gold assigments from 9,257 glosses taked directly from XWN2.01.1 (see table 2).",
        "However, this version is not free of errors and inconsistencies.",
        "For instance, XWN has 724 word tagged senses not belonging to `YN.",
        "Three of them labelled as gold.",
        "Furthermore, as we can see in table 3 the synset distributions of the test data and WN2.0 are very different.",
        "In particular for adjective and adverbs.",
        "Being the test data not representative of WN2.0, this test set misleads the global results and the final goal of the task.",
        "PRE-TALP The final results of both TALP systems are presented in table 4.",
        "Obviously, the performance of PRE-TALP is lower than PRE-XWN because it uses a different preprocess.",
        "The difference in the amount of words is due to the preprocess (different tokenization, PoS tagging).",
        "From the ten systems presented at the task,"
      ]
    },
    {
      "heading": "5 Conclusions and Future Work",
      "text": [
        "It is our belief, following (McRoy, 1992) and (Rigau et al., 1997), that full-fledged lexical ambiguity resolution should integrate several information sources and techniques.",
        "Our heuristics used most of the information content coherently integrated within the Multilingual Central Repository (MCx) of MEANING (Atserias et al., 2004), one of the richest and largest multilingual lexical knowledge base in existence.",
        "In order to improve the current systems, we plan to enrich the current set of heuristics using other knowledge uploaded into the MCx with a more robust preprocessing schema."
      ]
    },
    {
      "heading": "Acknowledgments",
      "text": [
        "This research has been partially funded by the European Commission (Meaning Project, IST-2001-34460), and by the Spanish Research Ministry (Hermes Project: TIC2000-0335-C03-02) , Generalitat de Catalunya (2002FI 00648) and Universidad Tecnoloègica Metropolitana (Chile).",
        "References E. Agirre, O. Ansa, X. Arregi, J.M.",
        "Arriola, A. Diaz de Ilarraza, E. Pociello, and L. Uria.",
        "2002.",
        "Methodological issues in the building of the basque wordnet: quantitative and qualitative analysis.",
        "In Proceedings of the first International WordNet Conference in Mysore, India, 21-25 January.",
        "J. Atserias, S. Climent, X. Farreres, G. Rigau, and H. Rodriguez.",
        "1997.",
        "Combining multiple methods for the automatic construction of multilingual wordnets.",
        "In Proceedings of RANLP'97, pages 143-149, Bulgaria.",
        "Jordi Atserias, Luis Villarejo, German Rigau, Eneko Agirre, John Carroll, Bernardo Magnini, and Piek Vossen.",
        "2004.",
        "The meaning multilingual central repository.",
        "In Proceedings of the Second International Global WordNet Conference (GWC'04), Brno, Czech Republic, January.",
        "ISBN 80-210-3302-9.",
        "E. Brill.",
        "1995.",
        "Transformation-based error-driven learning and natural language processing: A case study in part of speech tagging.",
        "Computational Linguistics, 21(4) ."
      ]
    }
  ]
}
