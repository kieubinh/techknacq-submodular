{
  "info": {
    "authors": [
      "Andras Csomai"
    ],
    "book": "SENSEVAL International Workshop on the Evaluation of Systems for the Semantic Analysis of Text",
    "id": "acl-W04-0826",
    "title": "UBBNBC WSD System Description",
    "url": "https://aclweb.org/anthology/W04-0826",
    "year": 2004
  },
  "references": [],
  "sections": [
    {
      "heading": "2 Stemming",
      "text": [
        "The Naïve Bayes classification proves to be a good performing tool in word sense disambiguation, although it has not yet been applied to the Romanian language.",
        "The aim of this paper is to present our WSD system, based on the NBC algorithm, that performed quite well in Senseval 3."
      ]
    },
    {
      "heading": "1 Introduction",
      "text": [
        "According to the literature, the NBC algorithm is very efficient, in many cases it outperforms more sophisticated methods (Pedersen 1998).",
        "Therefore, this is the approach we used in our research.",
        "The word sense disambiguating process has three major steps, therefore, the application has three main components as follows: Stemming – removal of suffixes, and the filtering out of the irrelevant information from the corpora.",
        "A simple dictionary based approach.",
        "Learning – the training of the classifier, based on the sense tagged corpora.",
        "A database containing the number of co-occurrences is built.",
        "Disambiguating –on the basis of the database, the correct sense of a word in a given context is estimated.",
        "In the followings the previously mentioned three steps are described in detail.",
        "The preprocessing of the corpora is one of the most result-influential steps.",
        "The preprocessing consists of the removal of suffixes and the elimination of the irrelevant data.",
        "The removal of suffixes is performed trough a simple dictionary based method.",
        "For every wi word the possible wj candidates are selected from the dictionary containing the word stems.",
        "Then a similarity score is calculated between the word to be stemmed and the candidates, as follows:",
        "The result is the candidate with the highest score if its score is above a certain threshold, otherwise the word is leaved untouched.",
        "In the preprocessing phase we also erase the pronouns and prepositions from the examined context.",
        "This exclusion was made upon a list of stop words."
      ]
    },
    {
      "heading": "3 Learning",
      "text": [
        "The training is conducted according to the NBC algorithm.",
        "First a database is built, with the following tables: words – contains all the words found in the corpora.",
        "Its role is to assign a sense id to every word.",
        "wordsenses – contains all the tagged words in the corpora linked with their possible senses.",
        "One entry for a given sense and word.",
        "scorei= nosenses - number of tagged contexts, with a given sense nocontexts - number of tagged contexts of a given word occurrences – number of co-occurrences of a given word with a given sense Figure1: The tables of the database The training of the system is nothing but filling up the tables of the database.",
        "fill NoSenses fill NoContexts fill Wordsenses scan corpora cakt=actual entry in corpora (a context) w=actual word in entry (the ambiguous word) sk=actual sense of entry scan cakt vj= actual word in entry if vj<>w then if vj in words then vi=wordid from words where w=vj else add words vj endif if (exists entry in occurrences where wordid=vi and senseid=sk) then increment C(wordid,senseid) in occurrences, where wordid=vi and senseid=sk else add occurrences(wordid, senseid, 1) endif step to next word endscan step to next entry endscan corpora As it is obvious, the database is filled up (so the system is trained) only upon the training corpus provided for the Senseval3 Romanian Lexical Sample task."
      ]
    },
    {
      "heading": "4 Disambiguation",
      "text": [
        "The basic assumption of the Naïve Bayes method is that the contextual features are not dependent on each other.",
        "In this particular case, we assume that the probability of co-occurrence of a word vi with the ambiguous word w of sense s is not dependent on other co-occurrences.",
        "The goal is to find the correct sense s′, of the word w, for a given context.",
        "This s′ sense maximizes the following equation.",
        "s′= arg maxsk P (sk |c) = arg maxsk = arg maxsk At this point we make the simplifying “naïve” assumption:",
        "The algorithm (Tatar, 2003) for estimating the correct sense of word w according to its c context is the following: for every sk sense of w do score(sk) =P(sk) for every vj from context c do",
        "where s’ is the estimated sense, vj is the j-th word of the context, skis the k-th possible sense for word w.",
        "where C(w) is the number of contexts for word w, C(vj , sk) is the number of occurrences of word vj in",
        "contexts tagged with sense sk , and C(sk) is the number of contexts tagged with sense sk The values are obtained from the database, as follows: C(w)- from nocontexts, C(vj , sk) - from occurrences, C(sk)- from nosenses.",
        "wordsenses is being used to determine the possible senses of a given word."
      ]
    },
    {
      "heading": "5 Evaluation",
      "text": [
        "The described system was evaluated at Senseval 3.",
        "The output was not weighted, therefore for every ambiguous word, at most 1 solution (estimated sense) was provided.",
        "The results achieved, are the followings:"
      ]
    },
    {
      "heading": "Figure2: Coarse-grained score",
      "text": [
        "A simple test was made, before the Senseval 3 evaluation.",
        "The system was trained on 90% of the Romanian Lexical Sample training corpus, and tested on the remaining 10%.",
        "The selection was random, with a uniform distribution.",
        "A coarse grained score was computed and compared to the baseline score.",
        "A baseline method consists of determining the most frequent sense for every word (based upon the training corpus) and in the evaluation phase always this sense is assigned.",
        "UBBNBC Baseline recall 0.66 0.56 precision 0.69 0.56"
      ]
    },
    {
      "heading": "Figure3: baseline UBBNBC comparison References",
      "text": []
    }
  ]
}
