{
  "info": {
    "authors": [
      "Yoong Keok Lee",
      "Hwee Tou Ng",
      "Tee Kiah Chia"
    ],
    "book": "SENSEVAL International Workshop on the Evaluation of Systems for the Semantic Analysis of Text",
    "id": "acl-W04-0834",
    "title": "Supervised Word Sense Disambiguation With Support Vector Machines and Multiple Knowledge Sources",
    "url": "https://aclweb.org/anthology/W04-0834",
    "year": 2004
  },
  "references": [
    "acl-A00-2018",
    "acl-A97-1004",
    "acl-J01-3001",
    "acl-P96-1006",
    "acl-W00-0726",
    "acl-W02-1006",
    "acl-W96-0213",
    "acl-W97-0323"
  ],
  "sections": [
    {
      "heading": "Abstract",
      "text": [
        "We participated in the SENSEVAL-3 English lexical sample task and multilingual lexical sample task.",
        "We adopted a supervised learning approach with Support Vector Machines, using only the official training data provided.",
        "No other external resources were used.",
        "The knowledge sources used were part-of-speech of neighboring words, single words in the surrounding context, local collocations, and syntactic relations.",
        "For the translation and sense subtask of the multilingual lexical sample task, the English sense given for the target word was also used as an additional knowledge source.",
        "For the English lexical sample task, we obtained fine-grained and coarse-grained score (for both recall and precision) of 0.724 and 0.788 respectively.",
        "For the multilingual lexical sample task, we obtained recall (and precision) of 0.634 for the translation subtask, and 0.673 for the translation and sense subtask."
      ]
    },
    {
      "heading": "1 Introduction",
      "text": [
        "This paper describes the approach adopted by our systems which participated in the English lexical sample task and the multilingual lexical sample task of SENSEVAL-3.",
        "The goal of the English lexical sample task is to predict the correct sense of an ambiguous English word , while that of the multilingual lexical sample task is to predict the correct Hindi (target language) translation of an ambiguous English (source language) word .",
        "The multilingual lexical sample task is further subdivided into two subtasks: the translation subtask, as well as the translation and sense subtask.",
        "The distinction is that for the translation and sense subtask, the English sense of the target ambiguous word is also provided (for both training and test data).",
        "In all, we submitted 3 systems: system nusels for the English lexical sample task, system nusmlst for the translation subtask, and system nusmlsts for the translation and sense subtask.",
        "All systems were based on the supervised word sense disambiguation (WSD) system of Lee and Ng (2002), and used Support Vector Machines (SVM) learning.",
        "Only the training examples provided in the official training corpus were used to train the systems, and no other external resources were used.",
        "In particular, we did not use any external dictionary or the sample sentences in the provided dictionary.",
        "The knowledge sources used included part-of-speech (POS) of neighboring words, single words in the surrounding context, local collocations, and syntactic relations, as described in Lee and Ng (2002).",
        "For the translation and sense subtask of the multilingual lexical sample task, the English sense given for the target word was also used as an additional knowledge source.",
        "All features encoding these knowledge sources were used, without any feature selection.",
        "We next describe SVM learning and the combined knowledge sources adopted.",
        "Much of the description follows that of Lee and Ng (2002)."
      ]
    },
    {
      "heading": "2 Support Vector Machines (SVM)",
      "text": [
        "The SVM (Vapnik, 1995) performs optimization to find a hyperplane with the largest margin that separates training examples into two classes.",
        "A test example is classified depending on the side of the hyperplane it lies in.",
        "Input features can be mapped into high dimensional space before performing the optimization and classification.",
        "A kernel function can be used to reduce the computational cost of training and testing in high dimensional space.",
        "If the training examples are nonseparable, a regularization parameter ( by default) can be used to control the trade-off between achieving a large margin and a low training error.",
        "We used the implementation of SVM in WEKA (Witten and Frank, 2000), where each nominal feature with possible values is converted into binary (0 or 1) features.",
        "If a nominal feature takes the th value, then the th binary feature is set to 1 and all the other binary features are set to 0.",
        "The default linear kernel is used.",
        "Since SVM only handles binary (2-class) classification, we built one binary classifier for each sense class.",
        "Note that our supervised learning approach made use of a single learning algorithm, without combining multiple learning algorithms as adopted in other research (such as (Florian et al., 2002))."
      ]
    },
    {
      "heading": "3 Multiple Knowledge Sources",
      "text": [
        "To disambiguate a word occurrence , systems nusels and nusmlst used the first four knowledge sources listed below.",
        "System nusmlsts used the English sense given for the target ambiguous word as an additional knowledge source.",
        "Previous research (Ng and Lee, 1996; Stevenson and Wilks, 2001; Florian et al., 2002; Lee and Ng, 2002) has shown that a combination of knowledge sources improves WSD accuracy.",
        "Our experiments on the provided training data of the SENSEVAL-3 translation and sense subtask also indicated that the additional knowledge source of the English sense of the target word further improved accuracy (See Section 4.3 for details).",
        "We did not attempt feature selection since our previous research (Lee and Ng, 2002) indicated that SVM performs better without feature selection."
      ]
    },
    {
      "heading": "3.1 Part-of-Speech (POS) of Neighboring Words",
      "text": [
        "We use 7 features to encode this knowledge source: , where ( ) is the POS of the th token to the left (right) of , and is the POS of .",
        "A token can be a word or a punctuation symbol, and each of these neighboring tokens must be in the same sentence as .",
        "We use a sentence segmentation program (Reynar and Ratna-parkhi,1997) and a POS tagger (Ratnaparkhi,1996) to segment the tokens surrounding into sentences and assign POS tags to these tokens.",
        "For example, to disambiguate the word bars in the POS-tagged sentence “Reid/NNP saw/VBD me/PRP looking/VBG at/IN the/DT iron/NN bars/NNS ./.”, the POS feature vector is where denotes the POS tag of a null token."
      ]
    },
    {
      "heading": "3.2 Single Words in the Surrounding Context",
      "text": [
        "For this knowledge source, we consider all single words (unigrams) in the surrounding context of , and these words can be in a different sentence from .",
        "For each training or test example, the SENSEVAL-3 official data set provides a few sentences as the surrounding context.",
        "In the results reported here, we consider all words in the provided context.",
        "Specifically, all tokens in the surrounding context of are converted to lower case and replaced by their morphological root forms.",
        "Tokens present in a list of stop words or tokens that do not contain at least an alphabet character (such as numbers and punctuation symbols) are removed.",
        "All remaining tokens from all training contexts provided for are gathered.",
        "Each remaining token contributes one feature.",
        "In a training (or test) example, the feature corresponding to is set to 1 iff the context of in that training (or test) example contains .",
        "For example, if is the word bars and the set of selected unigrams is chocolate, iron, beer , the feature vector for the sentence “Reid saw me looking at the iron bars.” is 0, 1, 0 ."
      ]
    },
    {
      "heading": "3.3 Local Collocations",
      "text": [
        "A local collocation refers to the ordered sequence of tokens in the local, narrow context of .",
        "Offsets and denote the starting and ending position (relative to ) of the sequence, where a negative (positive) offset refers to a token to its left (right).",
        "For example, let be the word bars in the sentence “Reid saw me looking at the iron bars .”Then is the iron and is iron.",
        ", where denotes a null token.",
        "Like POS, a collocation does not cross sentence boundary.",
        "To represent this knowledge source of local collocations, we extracted 11 features corresponding to the following collocations: , , , , , , , , , ,and .",
        "This set of 11 features is the union of the collocation features used in Ng and Lee (1996) and Ng (1997).",
        "Note that each collocation is represented by one feature that can have many possible feature values (the local collocation strings), whereas each distinct surrounding word is represented by one feature that takes binary values (indicating presence or absence of that word).",
        "For example, if is the word bars and suppose the set of collocations for is a chocolate, the wine, the iron , then the feature value for collocation in the sentence “Reid saw me looking at the iron bars.” is the iron."
      ]
    },
    {
      "heading": "3.4 Syntactic Relations",
      "text": [
        "We first parse the sentence containing with a statistical parser (Charniak, 2000).",
        "The constituent tree structure generated by Charniak's parser is then converted into a dependency tree in which every word points to a parent headword.",
        "For example, in the sentence “Reid saw me looking at the iron bars.",
        "”, the word Reid points to the parent headword saw.",
        "Similarly, the word me also points to the parent headword saw.",
        "We use different types of syntactic relations, depending on the POS of .",
        "If is a noun, we use four features: its parent headword , the POS of , the voice of (active, passive, or if is not a verb),",
        "and the relative position of from (whether is to the left or right of ).",
        "If is a verb, we use six features: the nearest word to the left of such that is the parent headword of , the nearest word to the right of such that is the parent headword of , the POS of , the POS of , the POS of , and the voice of .",
        "If is an adjective, we use two features: its parent headword and the POS of .",
        "Headwords are obtained from a parse tree with the script used for the CoNLL-2000 shared task (Tjong Kim Sang and Buchholz, 2000).1 Some examples are shown in Table 1.",
        "Each POS noun, verb, or adjective is illustrated by one example.",
        "For each example, (a) shows and its POS; (b) shows the sentence where occurs; and (c) shows the feature vector corresponding to syntactic relations."
      ]
    },
    {
      "heading": "3.5 Source Language (English) Sense",
      "text": [
        "For the translation and sense subtask of the multilingual lexical sample task, the sense of an ambiguous word in the source language (English) is provided for most of the training and test examples.",
        "An example with unknown English sense is denoted with question mark (“?”) in the corpus.",
        "We treat “?” as another “sense” of (just like any other valid sense of ).",
        "We compile the set of English senses of a word encountered in the whole training corpus.",
        "For each sense in this set, a binary feature is generated for each training and test example.",
        "If an example has as the English sense of , this binary feature (corresponding to ) is set to 1, otherwise it is set to 0."
      ]
    },
    {
      "heading": "4 Evaluation",
      "text": [
        "Since our WSD system always outputs exactly one prediction for each test example, its recall is always the same as precision.",
        "We report below the micro-averaged recall over all test words."
      ]
    },
    {
      "heading": "4.1 Evaluation on SENSEVAL-2 and SENSEVAL-1 Data",
      "text": [
        "Before participating in SENSEVAL-3, we evaluated our WSD system on the English lexical sample task of SENSEVAL-2 and SENSEVAL-1.",
        "The micro-averaged, fine-grained recall over all SENSEVAL2 test words and all SENSEVAL-1 test words are given in Table 2.",
        "In SENSEVAL-1, some example sentences are provided with the dictionary entries of the words used in the evaluation.",
        "We provide the recall on SENSEVAL-1 test data with and without the use of such additional dictionary examples in training.",
        "On both SENSEVAL-2 and SENSEVAL-1 test data, the accuracy figures we obtained, as reported in Table 2, are higher than the best official test scores reported on both evaluation data sets."
      ]
    },
    {
      "heading": "4.2 Official SENSEVAL-3 Scores",
      "text": [
        "We participated in the SENSEVAL-3 English lexical sample task, and both subtasks of the multilingual lexical sample task.",
        "The official SENSEVAL3 scores are shown in Table 3.",
        "Each score is the micro-averaged recall (which is the same as precision) over all test words.",
        "According to the task organizers, the fine-grained (coarse-grained) recall of the best participating system in the English lexical sample task is 0.729 (0.795).",
        "As such, the performance of our system nusels compares favorably with the best participating system.",
        "We are not able to fully assess the performance of our multilingual lexical sample task systems nusmlst and nusmlsts at the time of writing this paper, since performance figures of the best participating system in this task have not been released by"
      ]
    },
    {
      "heading": "4.3 Utility of English Sense as an Additional Knowledge Source",
      "text": [
        "To determine if using the English sense as an additional knowledge source improved the accuracy of the translation and sense subtask, we conducted a fivefold cross validation experiment.",
        "We randomly divided the training data of the translation and sense subtask for each word into 5 portions, using 4 portions for training and 1 portion for test.",
        "We then repeated the process by selecting a different portion as the test data each time and training on the remaining portions.",
        "Our investigation revealed that adding the English sense to the four existing knowledge sources improved the micro-averaged recall from 0.628 to 0.638 on the training data.",
        "As such, we decided to use the English sense as an additional knowledge source for our system nusmlsts.",
        "After the official SENSEVAL-3 evaluation ended, we evaluated a variant of our system nusmlsts without using the English sense as an additional knowledge source.",
        "Based on the official test keys released, the micro-averaged recall drops to 0.643, which seems to suggest that the English sense is a helpful knowledge source for the translation and sense subtask."
      ]
    },
    {
      "heading": "5 Conclusion",
      "text": [
        "In this paper, we described our participating systems in the SENSEVAL-3 English lexical sample task and multilingual lexical sample task.",
        "Our WSD systems used SVM learning and multiple knowledge sources.",
        "Evaluation results on the English lexical sample task indicate that our method achieves good accuracy on this task."
      ]
    },
    {
      "heading": "6 Acknowledgements",
      "text": [
        "This research is partially supported by a research grant R252-000-125-112 from National University of Singapore Academic Research Fund."
      ]
    }
  ]
}
