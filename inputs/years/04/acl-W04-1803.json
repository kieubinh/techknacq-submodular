{
  "info": {
    "authors": [
      "Keita Tsuji",
      "Kyo Kageura"
    ],
    "book": "CompuTerm International Workshop on Computational Terminology",
    "id": "acl-W04-1803",
    "title": "Extracting Low-Frequency Translation Pairs from Japanese-English Bilingual Corpora",
    "url": "https://aclweb.org/anthology/W04-1803",
    "year": 2004
  },
  "references": [
    "acl-H91-1026",
    "acl-J00-2004",
    "acl-J96-1001",
    "acl-P93-1003",
    "acl-P97-1017",
    "acl-P98-1004",
    "acl-W96-0107"
  ],
  "sections": [
    {
      "heading": "Abstract",
      "text": [
        "We propose a method for extracting low-frequency translation pairs from Japanese-English bilingual corpora.",
        "Many methods have been proposed for extracting translation pairs fr om biling ual corpora, but most arc based on word frequency a nd are, therefore, not effecti ve in extracting lowfrequency pairs.",
        "In J apaneseEnglish co rpora, many low-frequ ency translation pairs a r e loanword pairs that can be e xtract ed based on transliteration patterns.",
        "Our combined method, which relies on both transliteration and word frequency, performed significantly b etter than methods utilizing word frequency a lone.",
        "Our method achieved 80% precis io n at 84% recall against t he give n corpus, v .. · hile the word-frequency model achieved just 803 precision a t 8% recall."
      ]
    },
    {
      "heading": "1 Introduction",
      "text": [
        "In NLP application areas such as machine translation and cross-language informat ion retrieval, a range of translation word pairs a re needed.",
        "·while popular and well-known translation pairs a re included in existing bilingual dictionaries, n ew ly coine d and minor translation pairs ar e not yet covered in any resource.",
        "Therefore, it would be very useful if we could extract these pairs from proper bilingual corpora.",
        "Because newly coined translation pairs have just b egun to appear in text and because of t he nature of minor translation pairs, the frequencies of both are n ecessarily low.",
        "From this point of view, we aim to develop a method for extr acting low-fr equency translation pairs from Japanese-English bilingual corpora.",
        "So far, there have been many methods prop osed for extracting t ranslation pairs from bilingual corpora.",
        "The most typical and inte n sively studied are word-frequency-based m ethods that extract word vV1 and H' Ro as translation if W; and W Eo co-occur in numerous bilingu al sentence pairs .",
        "Although frequency-based m ethods have a stron g theoretical b asis and are often sufficien t ly effective, they have on e weak p o int, i .e., t hey are not good a t extracting low-freque n cy pairs.",
        "For instance, if WJ a nd T¥Eo occ ur a nd co-occur in just one biling ual sentence pair, and a nother word, W E x, occurs in one and the same sentence, the frequency-based method cannot determine which TtVe o or W ex is the co rrect translation of iv J.",
        "It is therefore desirable to develop a method for extracting low-frequency translation pairs, filling the gaps in, as well as making good use of, the frequency-based method.",
        "Language-pairindependent m e thods such as t h e fr equencybased method are adequately refined , and we believe that incorporating languagc-pairdcpendcnt knowledge, which is often ignored, is a step in t he right directio n .",
        "In this, among the first studies base d on t his framework, we focus on the Japanese and English language pair, although we take specia l care to keep t h e method as open to generalization as possible.",
        "In .Japanese-English bilingual corpora, many lmv-frequency tran slation p airs are loan -word pairs .",
        "Although these pairs can be extracted based on some transliteration patterns (without relying on ·word frequency) and there has b een some research related t o trans literations (Knight and Graehl, 1997) (Fujii and Ishikawa, 2001 ), few studies have been conducted for extracting these pairs from bilingua l corpora based on transliteration.",
        "Two tasks arise: ( 1) To develop an effective method for extracting transli terated word pairs t h at include many of the low-frequency .Japanese-English translation pairs; and (2) To make good u se of the frequency-based met hod to extract l owfreque ncy and es pecially non-translite rat ional tra ns lation pairs.",
        "Solving t h ese tasks, we propose a combined m e thod that u tili zes both transliteration and 'vord fr e quency.",
        "In the following sections, we will first give the results of an invest igation into low -frequency CompuTerm 2004 3rd International Workshop on Computational Terminology 23 translation pairs, next describe our method: and then show that significant improvement was observed by our proposed method."
      ]
    },
    {
      "heading": "2 Preliminary Investigation",
      "text": [
        "We used one bilingual dictionary and four bilingual corpora for our investigation and experiment.",
        "The bilingual dictionary we used was EDICT, which contained 102,380 pairs of Japanese-English translation pairs.",
        "We regard EDICT as one example of existing bilingual dictionaries.",
        "The bilingual corpora we used consist of 9,000 pairs of abstracts of academic papers in the fields of (1) information processing field and (2) architecture collected by the National Institute of Informatics of Japan.",
        "Each Japanese-English abstract was written by the respective authors of each paper, and there is no strict correspondence between them.",
        "We assume that corpora which are strictly correspondent at each sentence level are still hard to obtain, while loosely correspondent ones become more readily available.",
        "1 We chose these abstract corpora to keep our method realistic and applicable to many fields.",
        "Also, consequently, 'tve do not try to align sentences in each abstract.",
        "Instead, we defined each whole abstract as a segment from which we extracted translation pairs.",
        "We also used 9,000 bilingual titles in the above fields for compari: mn.",
        "The bask quantities are shown in Table 1.",
        "2 'lnf-Abst' and 'Arc-Abst' represent the abstract corpus of information processing and architecture: respectively.",
        "'Inf-Titl' and 'Arc-Titl' represent the title corpus in the same manner.",
        "We define 'min(WJ, WK)' of the word pair WJ and w-i;: as the smaller of the number of segments in which the word H'1 occurred and in which HlE occurred.",
        "For instance: if fV1 and vV E occurred in four and six segments, respectively, 'min(WJ, WEr of that pair is four.",
        "In addition, we represent the translation pairs whose min(W1 , TiVE) is N a.s 'min(WJ: TYE) = N translation pairs'.",
        "We randomly selected 1,000 segments of each corpus and manually identified the translation pairs which should be extracted in each segment.",
        "In our estraction experiment, we evalu-1For instance, (Omae et al., 2003) obtained loosely correspondent bilingual texts from the \\\\Teb by submitting bilingual equivalent keywords to Google and extracting translation pairs from the resultant texts.",
        "2The plural forms of English words were converted into singular forms.",
        "ChaSen 2.0b and Brill tagger were used for the Japanese and English texts, respectively.",
        "Chasen Words English Words Token Type Token Type Inf-Abst 1,389,473 23,072 957,467 34,908 Arc-Abt;t 1,263,833 23,758 695 ,542 40,244 Inf-Tit!",
        "101,421 7,312 83,357 12,843 Arc-Tit.I 181,744 9,125 156,479 18,625 Table 1: Ila.",
        "'lic Quantities of Four Corpora ated the result based on these pairs.",
        "The number of these pairs are shown in the column 'Pair' in Table 5.",
        "Fbr instance, we can see in Table 5 that there are 548 min(H~1, WE) = 1 translation pairs in the information processing abstract corpus.",
        "Note that their frequencies were counted based on 9,000 segments, not on 1:000 segments.",
        "2.1 Existing Dictionary and Low-frequency Pairs in the Corpora \\!Ve investigated what percentages of the single word noun translation pairs in the corpora arc listed in EDICT.",
        "The results are shown in the column 'R_Dict' in Table 5.",
        "Generally speaking, the low-frequency translation pairs (i.e., those whose min(WJ, WE) are small) are not fo;ted in EDICT.",
        "For instance, only 11.78% of min(W1 , WE) = 1 translation pairs in the architecture abstract corpus are listed in EDICT.",
        "With this fact, v~'e \\vould like to say that the existing bilingual dictionaries do not contain lov•,rfrequency translation pairs.",
        "2.2 Problems With the Frequency-based Method for Extracting Low-frequency Pairs We define 'full co-occurrence' of a word A with a translation pair (X, Y) as a situation in which the word A and X always co-occur in the same segment.",
        "There are two types of full co-occurrence: (a) A and X belong to the same language; and (b) A and X belong to differnnt languages.",
        "When type-(a) full co-occurrence as in Table 2 occurs (i.e., A=' / -F', (X, Y)=('~ li*':'path')), the frequency-based method estimates that '~Ji!1l' and '.J F ' are equally likely to be the translation of 'path'.",
        "vVhen type( b) full co-occurrence as in Table 3 occurs (i.e., A='node', (X , Y)=('~~': ' path')), the frequency-based method estimates that 'node' is more likclv to be the translation of '**-.ii*' than 'path'.",
        "Ii~ situations of type-(a), the method 24 CompuTerm 2004 3rd International Workshop on Computational Terminology cannot determine which is the correct translation, and in situations of type-(b), the method chooses the wrong word as the translation.",
        "Full co-occurrence is related to 'indirect association' (Melamed, 2000).",
        "But this only refers to situations in which word A 'often' as opposed to 'fulli co-occurs with X.",
        "Table 5 shows how full co-occurrence can pose a difficult obstacle for the frequency-based method when extracting low-frequency translation pairs.",
        "In Table 5, 'R_FulLCooc' is the ratio (%) of translation pairs that are fully co-occurred by other words against the total translation pairs.",
        "Ft>r instance, among 314 rnin(H'J, l'VR) = 1 tmnslation pairs in the architecture abstract corpus, 90.13% arc fully cooccurrcd by other ·words.",
        "Japanese Part English Part path path path path path Table 2: Full Co-occurrence of Type-( a) Japanese Part English Part path path, node path, node path, node path Table 3: Full Co-occurrence of Type-(b) 2.3 Loanword Pairs Among Low-frequency Pairs The character types of translation pairs are also shown in Table 5.",
        "'Katak', 'Roman', 'Kanji' and 'Other' represents the ratio (%) of the translation pairs whose Japanese words are represented using katakana characters, Roman alphabets, kanji characters and other characters, respectively.",
        "In the .J aparn~se language, most of the transliterated loan words are written in katakana or the Roman alphabet, and vice versa.",
        "Table 5 shows that the smaller the rnin(H'J, Tt'R) becomes, the larger the ratio of the loanword pairs becomes.",
        "The loanword pairs can be extracted based on some transliteration patterns ·without relying on word frequency.",
        "3 The Extraction Method Our preliminary investigations revealed: ( 1) that most of the low-frequency translation pairs are in the situation of full co-occurrence (as mentioned in Section 2.2) and cannot he extracted based on word frequency alone; and (2) that many of them are transliterated word pairs.",
        "Our method is based on these observations; it is as follows: 1) From each segment, extract the translation pairs based on transliteration.",
        "For instance, if there are candidate words '~~ (path)' and'}-F (node)' in the Japanese part of the segment and there are 'path' and 'node' in the English part of the segment, '} - F' and 'node' are extracted based on transliteration patterns such as 'J '='no' and 'F '='de'.",
        "2) Remove the extracted pairs from the candidate words.",
        "As a result, '~lm' and 'path' arc left in the segment.",
        "3) Based on word frequency, extract translation pairs from the candidate words left in the segment.",
        "Figure 1 sho>vs the flmv of our method.",
        "Extraction methods like Steps 1 and 3 used to be studied independently.",
        "For instance, (Gale and Church, 1991) (Kupiec, 1993)(Smadja et al. , 1996) (Hiemstra, 1997)(Kitamura and Matsumoto, 1996) (Ahrenberg et al., 1998) (Melamed, 2000) focused on word frequency and (Collier et al., 1997)(Jeong et al., 1999) extracted loanword pairs based on transliteration patterns.",
        "The unique point of our method in a technical sense is that we incorporated Steps 1 and 2 before applying the frequency-based method.",
        "These steps are the key to resolving the issue of full co-occurrence.",
        "vVe expect that Step 1 identifies the correct translation of A~ in Section 2.2 and Step 2 removes A with that correct translation.",
        "After these steps, the full co-occurrence by A is resolved and the frequency-based method regains its power to extract translation pairs (X , Y) that remain in the segment.",
        "While many effective frequency-based methods have been proposed, there were only a few transliteration-based methods especially for the .Japanese-English language pa ir.",
        "Against this CompuTerm 2004 3rd International Workshop on Computational Terminology 25 26 CompuTerm 2004 3rd International Workshop on Computational Terminology Identify the Candidate Words based on Morphological Analysis Extract Translation Pairs based on Transliteration Patterns Remove the Extracted Word Pairs from the Candidates Extract Translation Pairs based on Word Frequencies Final Translation Pairs L(W;, .)",
        "is the sum of the number of link's b~tween W; and all the other words.",
        "L(., vv E) is defined as the same.",
        "3 4 Extraction Experiment Tv>'o kinds of extraction experiments were performed.",
        "The targets of extraction were rnin(W;, WE) = 1 translation pairs, which we think are difficult to extract but believe to be valuable pairs in the sense that they include the most newlv coined translation pairs.",
        "As we ~reviously-mentioned, we evaluated the result based on the randomly-selected 1,000 segments in the corpus.",
        "From the extracted pairs, we eliminated the pairs that could not be extracted from these 1,000 segments and calculated the precision and recall.",
        "We calculated them every time we extracted one pair whose P was highest at Step 3.",
        "(A) Basic Extraction Experiment: We extracted min(WJ, vVi!,·) = 1 translation pairs and evaluated the result.",
        "The threshold D at Steps 1 and 2 were 0.9 or 0.8.",
        "This experiment was performed to show the overall effectiveness.",
        "of our method to extract low-frequency translation pairs.",
        "(I3) .",
        ":\"{ on-transliterational Pairs Extraction Experiment: We evaluated the result of extracting rnin(vV,, vVE) = 1 translation pairs that were not loanword pairs.",
        "This experiment ;vas performed to show the effectiveness of incorporating Steps 1 and 2 before Step 3.",
        "If our method extracted theRe non-transliterational pairR with higher predRion and recall than the frequency-based method alone, it is very likely that part of the issue of full co-occurrence was resolved through Steps 1 and 2.",
        "The threshold D at Steps 1 and 2 Were 0.9, 0.8 or 0.7.",
        "4.1 Result of the Basic Experiment The results of the basic experiment against the information processing abstract corpus and the architecture abstract corpus are shown in Figures 2 and 3, respectively.",
        "In Figures 2 and 3, 'TLS(D=X)+lVIelarned' represents the precision and recall curve of the met.hod whose threshold at Step 2 was X and whose frequency-based method used at Step 3 was that of (Melamed, 2000).",
        "Just 'l\\folamed' represents the result of using the method of (Melamed, 2000) alone.",
        "3·we adopted the method 'B' of (Melamed, 2000).",
        "We tried his 'score.B ' as the final criteria, too, but the above score P produced better results.",
        "The notation of Hiemstra is the same.",
        "From Figures 2 and 3, we can say the following: (1) The results gained through the frequencybascd methods alone arc not good.",
        "One of the reasons for this should be the issue of full cooccurrence.",
        "(2) The results of the combined method are by far better than those of the frequencyb~< ied method only.",
        "For instance, the combined method (TLS(D=0.8)+Melamed) achieved 80% precision at 843 recall against the information processing abstract corpus while the method of (l\\/Iclarncd, 2000) achieved 80% prccisi~n at ~ust 83 recall.",
        "Incorporating the transhtcrat1onbased method to extract Japanese-English seems to have been effective, as we hypothesized in our preliminary investigation.",
        "(3) Generally speaking, the recall against the information processing abstract corpus was better than that against the architecture corpus.",
        "Table 5 show:> that the amount of loanword pairs in the information processing corpus is larger than that in the architecture corpus.",
        "The ext~-action result indicates that our method will function more effectively in fields or language pairs where word loans are common.",
        "( 4) The maximum of the recall when we set D = 0.8 was larger than that when we set D = 0.9.",
        "It meam; that, to achieve overall good recall.",
        "we should rely on transliteration-based meth~d and greedily extract loanword pairn.",
        "These tendencies were also observed in the results against two title corpora, though the precision and recall ;vere higher.",
        "4.2 Result of Extracting N on-transliterational Pairs The results of the experiment (B) against the information processing abstract corpus and the architecture abstract corpus are shown in Figures 4 and 5, respectively.",
        "We can see in Figure 4 that the performance of the combined method for extracting non-transliterational pairs is better than that of (Melamed, 2000) alone.",
        "For instance, the combined method (TLS(D=0.8)+1'Ielamed) achieved 643 precision at 23 recall, while the method of (l\\/Ielarned, 2000) achieved 19% precision at.",
        "2% recall.",
        "Similar results were obtained in other corpora and when we used the method of (Hiemstra, 1997).",
        "This indicates that Steps 1 and 2 resolved a number of cases of full co-occurrence among non-transliterational rnin(iv,, VVE) = 1 translation pairs and enabled the frequency-CompuTerm 2004 3rd International Workshop on Computational Terminology 27 based method to extract them.",
        "We can see in Figures 5 that the prec1s10n when we set D = 0.9 was lower than those when we set D = 0.8 and D = 0.7.",
        "It means that if we extract and remove only the highly-matched loanword pairl'i, the full co-occurrence is not resolved.",
        "We observed that the best value for D was around 0.8.",
        "5 Conclusions",
        "From the standpoint that the low-frequency translation pairs in bilingual corpora include many useful pairs, we developed a method for extracting them from corpora.",
        "The investigation and experiment clarified the following four points: (1) The frequency-based method is not effective in extracting lo>v-frequency translation pairs because of full co-occurrence; (2) In Japanese-English bilingual corpora, lowfrequency translation pairs are often loanword pairs and they can be extracted using the transliteration-based method; (3) The performance of the combined method for extracting low-frequency translation pairs is higher than that of the frequency-based method alone; (4) Extracting and removing the loanword pairs using the transliteration-based method leads to the resolution or amelioration of full co-occurrence and enables the frequency-based method to extract non-transliterational lowfrequency pairs.",
        "What is special about our research is that it focused on word pairs that have often been ignored and that it proposed a method addressing the circumstances of the JapaneseEnglish language pair quite well.",
        "We feel more attention should be paid to language-pairdependent know ledge and we developed an optimized method for Japanese and English based on this framework.",
        "We would like to add that, by modifying the transliteration patterns, similar methods should work fairly well against other language pairs where word loans are common.",
        "References",
        "L. Ahrcnberg et al. 1998.",
        "\"A Simple Hybrid Aligner for Generating Lexical Correspondences in Parallel Texts\".",
        "In Proceedings of the COLING-ACL'98, pages 29-35.",
        "J.",
        "13reen.",
        "EDICT.",
        "http://>vww.csse.monash.edu.au;-jwb/.",
        "I\\.",
        "Collier et al. 1997.",
        "\"Acquisition of EnglishJapancsc Proper Nouns from I\\oisy-Parallcl Newswire Articles Using KATAKA::\"{A Matching\".",
        "In Proceedings of the Natural Language Processing Pacific Rim Symposium 1997, pages 309-314.",
        "A. Fujii and T. Ishikawa.",
        "2001.",
        "\"Japanese/English Cross-Language Information Retrieval: Exploration of Query Translation and Transliteration\".",
        "Computers and the Human·ities, 35( 4) :389-420.",
        "W. A. Gale and K. W.",
        "Church.",
        "1991.",
        "\"Identifying ·word Correspondences in Parallel Texts\".",
        "In Proceedings of the DARPA Speech and Natural Language Workshop, pages 152-157.",
        "D. Hiemstra.",
        "1997.",
        "\"Deriving a Bilingual Lexicon for Cross-Language Information Retrieval\".",
        "In Proceedings of the Fourth Groningen International Information Technology Conference for Students, pages 21-26.",
        "K. S. Jeong et al. 1999.",
        "'(Automatic Iclcnt.ification and Back-transliteration of Foreign Words for Information Retrieval\".",
        "fojormation Prncessing and ManrLgernent, 35(4):523 540.",
        "M. Kitamura and Y. Matsumoto.",
        "1996.",
        "'(Automatic Extraction of Word Sequence Correspondences in Parallel Corpora''.",
        "In Proceedings of the 4th Workshop on Ver:q LaT:qe Corpora, pages 79-87.",
        "K. Knight and J. Graehl.",
        "1997.",
        "\"1/Iachine Transliteration\".",
        "In Proceedings of the 35th Annual Conference of the AGL, pages 128135.",
        "J. Kupiec.",
        "1993.",
        "\"An Algorithm for Finding Noun Phrase Correspondences in Bilingual Corpora\".",
        "In Proceedings of the Sixth Conference of the EA CL, pages 17-22.",
        "I. D. Melamed.",
        "2000.",
        "\"Models of Translational Equivalence among vVords\" .",
        "Computational Linguistics, 26 (2):221-249.",
        "H. Omac et al. 2003.",
        "\"Extraction of Compound Word Translations from Non-parallel Japanese-French Text in World Wide Web\".",
        "In Proceedings of the Workshop PAPILLON-200S on M·ultiling·ual Lexical Databases.",
        "(Ko Pagenation).",
        "F. Smadja et al. 1996.",
        "\"Translating Collocations for Bilingual Lexicons: A Statistical Approach\".",
        "Computational Lingnistics, 22(1):1 38.",
        "K. Tsuji.",
        "2002.",
        "\"Automatic Extract.ion of Translational Japanese-KATAKANA and English Word Pairs from Bilingual Corpora\".",
        "International Journal of Computer Processing of Oriental Languages, 15 (:3) :261-279."
      ]
    }
  ]
}
