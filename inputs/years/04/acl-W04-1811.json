{
  "info": {
    "authors": [
      "Teruo Koyama",
      "Kyo Kageura"
    ],
    "book": "CompuTerm International Workshop on Computational Terminology",
    "id": "acl-W04-1811",
    "title": "Term Extraction Using Verb Co-Occurrence",
    "url": "https://aclweb.org/anthology/W04-1811",
    "year": 2004
  },
  "references": [
    "acl-C94-1084",
    "acl-P93-1024",
    "acl-P98-1112",
    "acl-P98-2214"
  ],
  "sections": [
    {
      "heading": "Abstract",
      "text": [
        "This paper proposes a method of automatic term extraction in 'Which documents are gTouped on the basis of discourse/ domains by means of characteristic verbs and nominal terms.",
        "The method aims to (a) extract terms in accordance with their general positions in the discourse, (b) enhance the precision of extraction and ( c) cover relatively low-frequency terms in extraction.",
        "Experiments show that it performs well in terms of these objectives."
      ]
    },
    {
      "heading": "1 Introduction",
      "text": [
        "Term extraction is important in natural language processing, especially in addressing the lexical bottleneck.",
        "To date, various statistical methods, such as TF-IDF, have been applied 1.o !.his 1.ask, and have attained great success (Aizawa, 2003; Bourigault ct al., 1998; Daillc ct al., 1994; Kagcura & Koyama, 2000; l'viima & Ananiadou, 2000; l\\foens, 2000; Nakagawa, 2000).",
        "Hmvever, some problems still remain: (a) the concept of \"domain\" or \"field\" is determined mostly in advance; (b) the positions of extracted terms in the domain are not very clear; ( c) generally, in statistical approaclwB, the rC'Bnlt.s are sensitive to frequency, and it is difficult to deal with low-frequency terms.",
        "This paper proposes a way of dealing with these problems.",
        "The basic idea is that there are some characteristic verbs used in scientific discourse, which can be used (a) to define the domains/ sub-domains in the corpora of the broad domain and (b) lo csLimatc the positions1 of terms that co-occur with them using clustering analysis.",
        "Some studies have analy:r,ed the role of verbs in documents (Eumcridou ct. al., 2002; Kia.vans there, by \"position\", we mean to which discoursal class, sub-domain or conceptual group a term belongs.",
        "See Sowa (199:3) for some related discussion 11.hont the position of concepts represented in tenns.",
        "& Kan, 1998).",
        "Most of them focus on the microstructure of discourse, such as verb-argument relations.",
        "Our approach a.irm; a!.",
        "elucidating the positions of verbs as a deciding factor in the macro discoursal structure2 of documents in corpora.",
        "The application of clustering in extracting various generic characteristics in language has been intensively carried out (Pereira ct al., Hl93; Utsuro et al., 1998).",
        "In contrast to these works, the present study is specifically concerned with macro-discourse and lexical clues that rcficct it.",
        "In the following, section 2 outlines the method we propose.",
        "Section 3 will discuss how the combination of major verbs can be used 1.o classify terms and documents; section 4 will discuss the effect of using the proposed method in term extraction.",
        "2 Outline of the proposed method Our basic hypothesis is: For a coherent domain, sub-domain or set of documents, there are a few major \"verbal\" concepts and \"nominal\" concepts that determine the macrostructure of discourse, which are respectively represented by characteristic verbs and nouns.",
        "Uased on this hypothesis, we define the procedure of identifying macro-discourse and extracting terms as follows: 1.",
        "Extract verbs 3 and term eandidat.cs (noun related sequences) which are expected to represent macro-discourse.",
        "2.",
        "Cluster the term candidates based on the co-occurring verbs cxLracLcd in step 1.",
        "2By \"macro\" we mean the generali.,,ed discoursal structure that characterizes a domain, a sub-domain or a group of documents.",
        "3IIere, we include verb sterns 11.s well according to .Japanese ;vord cla.~sification.",
        "80 CompuTerm 2004 Poster Session 3rd International Workshop on Computational Terminology 3.",
        "Manually identify groups of term candidates that correspond to macro-discourse groups, and identify representative vectors consisting of verbs LhaL correspond Lo discoursal groups on the basis of step 2.",
        "4.",
        "Cluster documents on the basis of verb vectors defined in step 3.",
        "5.",
        "For each clustered document, apply a basic term extraction method.",
        "By identifying discourse groups within given corpora, it is possible Lo macro-str11cturi11c terms.",
        "Also, quantitative information is expected to become relatively more sensitive to low-frequeney term candidates.",
        "In the following experiments, we use a corpus extracted from I.he database edited by Nll (:'fational Institute of Informatics), consisting of rcscareh reports in various seicntific fields supported by grant-in-aid from the Japan Society for the Promotion of Science for 1998.",
        "\\Ve use two sub-eorpora, i.e. in the field of engineering and in natural science.",
        "The number of reports is 7753 for engineering and 5171 for natural science.",
        "Each report consists of about 750 (Japanese) characters.",
        "We applie<l the \"Juman\" morphological analy11er and extract.ed sequencPB of nouns or word stems as (noun) term candidates.",
        "3 Defining contextual information Herc, we elaborate on steps 1 to 3 described in section 2.",
        "Step#l.",
        "First, ·we order candidate terms and verbs by TF-IDF, in order to select important terms and verbs in the domain.",
        "\\Ve scleeL the 15 verbs and 50 candidate terms with the highest TFlDF values.",
        "Step#2.",
        "In relation to a verb v, we ean select a document set Du ·which includes the verb.",
        "For this set, a parameter that indicates the strength of the co-occurrence tcndcney between a term t and v can be defined as \\\\There, 4 4This parameter can be regarded to be proportional to the likelihood ratio of the appearance of t within Dv and Dh, rnim1H one.",
        "• fv: term frequency in Dv • fh: term frequency in all documents (JJ,,) • di.",
        ": document number of D v • d1i: whole document number of 1J1i Step#3.",
        "Using multiple verbs, we can obtain a vector =+ Rt = { Rtv} for the term t. Along ·we select 15 verbs, the 50 terms distribute themselves in a Hi-dimensional vector spaee.",
        "On these vceLors, we apply clustering: analysis using the Euclidean distance and compact clustering method.",
        "Figure 1 shows the result of the analysis for the engineering corpus.",
        "Cutting the tree at level 3, in Fig.1, we obtain 8 term gToups.",
        "Each group can be presumed to be chemistry-1 (groupl), material engiueeriug (group2), civil engineering (group3), semiconductors (group1), chemisLry-2 (group5), imaging (groupo), system engineering/ control (group7), arnl condensed matter physics (group8) rc'Bpect.ively.",
        "This grouping seems to correspond to real engineering subdomains.",
        "Applying the same method to the natural science corpus, we obtain 6 term groups, namely, chcmisLry-1, astronomy /geology, biology, mathematics, physies, and chcmistry-2.",
        "4 Term extraction experiment Once the grouping of terms has been done, we can obtain mean (term) vectors for each group.",
        "These vectors can be used to evaluate Lhc sLrcngLh of Lhc relation between a document and each term group.",
        "Suppose a vector ~ = {Vik} is the mean vector of the 'i-th term group, and Vik is the eomponent corresponding to the k-th verb.",
        "The strength of the relation between a document DJ and Lhc i-th term gToup is given by where, n ~j = II Aiijk 1 k=l T( lJJ) denotes the set of words in the document D.i.",
        "Using this measure, 'vc can apply steps 4 and 5 in section 2.",
        "Step#4.",
        "0 2 4 6 8 CompuTerm 2004 Poster Session 3rd International Workshop on Computational Terminology 81 82 CompuTerm 2004 Poster Session 3rd International Workshop on Computational Terminology Table 1: l\\ umber of non-terms among HJ() eandidates (in engineering) documents freq.",
        "less-freq.",
        "Croupl 1818 g 11 Group2 2596 1 12 Group3 2078 7 8 Group4 2485 8 3 Group5 1616 10 g Group6 1393 ..., I 1 Group7 1326 8 8 Group8 1363 8 11 TF-lDF 27 First 3800 3800 31 duded in the top 100 results for frequent terms, and in randomly sampled 100 results for less frequent terms.",
        "\\Ve also prepare data on the top 100 TF-IDF value am] the result of the propose<l metho<l applied to the first.",
        "3800 documents in the corpus.",
        "Table 1 shows the result.",
        "H shows Lhat the precision of Lenn extraction based on document.",
        "division is better than using the TF-IDF score and random grouping of documents.",
        "\\Ve applied the same method to 6 groups in the natural science field, and observed a similar improvcmcnL.",
        "5 Conclusion and discussion We have proposed a method of improving simple automatic term extraction ba.<.",
        ";ed on grouping documents by discourse/ domains using cooccurrences of characteristic verbs and nominal terms.",
        "The un<lerlying hypothesis was: lf we focus on a few major \"verbal\" concepts and \"nominal\" concepts that are expected to determine the macro-structure of discourse, which are respectively represented by characteristic verbs and nouns, we could structurize or group the documents in the corpus according to the macro-structure of discourse or topic, which in turn will contribute to enhancing term extraction.",
        "The experimental results based on the corpora, of engineering and of natural science have shown that the method is highly promising.",
        "We are currently applying the method to the corpus of human science.",
        "Though a detailed evaluation has not yet been carried out, the results so far are highly promising.",
        "The current method still relies on some intuition and manual evaluation in the intermediate stages.",
        "\\Ve are examining ways of automatizing these phases as well as improving the methods of the term extraction phase using different weighting measures.",
        "References Akiko N. Aizawa.",
        "2003.",
        "\"An informationtheoretic perspective of tf-idf measures,\" lnforwation Proeess·ing and Management, 39(1): 45-65. l3ourigault, D., Jacquemin, C., and L'Homme, IVI.",
        "C. 1998.",
        "Proceedings oj' lhe lsl International Workshop on Computational Terminology (Comp'lderm 1998).",
        "COLL\\IG-ACL, Montreal.",
        "Daille, 13., Gaussier, E. and Lange, 1\\11.",
        "1994.",
        "\"Towards automatic extraction of monolingual and bilint,'lial terminology,'' COLING-94: 515 521.",
        "Eumcridou, E., Nkwcnti-A~ch, I3.",
        "and :\\kNaught, .J.",
        "2002.",
        "\"The contribution of verbal semantic content towards recognition,'' International Journal of Corpus Linguistics, 7(1): 87-106.",
        "Kageura, K. and Koyama, T. eds.",
        "2000.",
        "Special l.9s1w on Japanese Term Exlmclion: Terrninology, 6(2).",
        "Klavans, J. and Kan, l\\if.",
        "Y.",
        "1998.",
        "\"Role of verbs in document analysis,\" COLINGA CL '98: 680 686.",
        "Mima, 11. and Ananiadou, S. 2000.",
        "\"An application and evaluation of the C/NC-value approach for the automatic term recognition of multi-word units in .JapanPBe,'' Terminology, 6(2): 175194. l\\focns, JvI.",
        "F. 2000.",
        "Ji ulornalic Inrlc:r,ing and Abstracting of Document Texts.",
        "Dordrccht: Kluwer.",
        "Nakagawa.",
        "H. 2000.",
        "\"Automatic term recognition on statistics of compound nouns,\" Terminology, 6(2): 175-194.",
        "Pereira, F., Tishby, N., and Lee, L. 1993.",
        "\"Distributional clustering of English words,\" ACL-92: 128-135.",
        "Sowa, J. F. 1993.",
        "\"Lexical structures and conceptual structures.\"",
        "In Pustejovsky, J. ed.",
        "Semantics and Lexicon.",
        "Dordrecht: Kluwer.",
        "223 262.",
        "Utsuro, T., .Miyata, T., and l\\fatsumoto, Y.",
        "1998.",
        "\"General-to-specific model selection for subcategori,.",
        ";ation preference,\" COLJNGA CL '98: 13141320 ."
      ]
    }
  ]
}
