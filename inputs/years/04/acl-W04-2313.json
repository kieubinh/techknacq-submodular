{
  "info": {
    "authors": [
      "Sandrine Zufferey",
      "Andrei Popescu-Belis"
    ],
    "book": "SIGdial Workshop on Discourse and Dialogue",
    "id": "acl-W04-2313",
    "title": "Towards Automatic Identification of Discourse Markers in Dialogs: The Case of Like",
    "url": "https://aclweb.org/anthology/W04-2313",
    "year": 2004
  },
  "references": [],
  "sections": [
    {
      "heading": "Abstract",
      "text": [
        "This article discusses the detection of discourse markers (DM) in dialog transcriptions, by human annotators and by automated means.",
        "After a theoretical discussion of the definition of DMs and their relevance to natural language processing, we focus on the role of like as a DM.",
        "Results from experiments with human annotators show that detection of DMs is a difficult but reliable task, which requires prosodic information from soundtracks.",
        "Then, several types of features are defined for automatic disambiguation of like: collocations, part-of-speech tags and duration-based features.",
        "Decision-tree learning shows that for like, nearly 70% precision can be reached, with near 100% recall, mainly using collocation filters.",
        "Similar results hold for well, with about 91 % precision at 100% recall."
      ]
    },
    {
      "heading": "1 Introduction",
      "text": [
        "The identification of discourse markers (DMs) is an essential step in dialog understanding, since there is often a prosodic, syntactic and functional distinction between DMs and the rest of an utterance.",
        "For instance, the identification of DMs is relevant to lower-level analysis processes such as POS tagging or parsing.",
        "After a brief theoretical definition in relation to natural language processing, this article will focus on the highly ambiguous discourse marker like – which besides a DM can also be a verb, a preposition, etc.",
        "As a DM, like mainly fulfills one function (to introduce an approximation with a variable scope), so the main problem in NLP is to disambiguate occurrences of like as a DM from other occurrences.",
        "We describe in section 5 two experiments that assess the performance of humans on this task in terms of inter-annotator agreement, then proceed to automate the identification of like as a DM, using collocation filters (section 6), a POS tagger (section 7), and decision-tree classification (section 8), which is also extended to the identification of well.",
        "The automated methods appear to be useful aids to manual annotators, since they reach 70% precision for like with near 100% recall.",
        "This article is related to a dialog processing and retrieval application, developed within the IM2 project1.",
        "We make use of the ICSI Meeting Recording corpus of transcribed and annotated dialog, which contains 75 one-hour recordings of staff meetings, each involving up to eight speakers2.",
        "Each channel is manually transcribed and timed.",
        "We use here an initial release of 50 dialogs, annotated with dialog acts, segmented into about 65,000 prosodic utterances."
      ]
    },
    {
      "heading": "2 Role of Discourse Markers in Dialog",
      "text": []
    },
    {
      "heading": "2.1 Definition",
      "text": [
        "Despite the wide research interest raised by discourse markers for many years, there is no generally agreed upon definition of this term.",
        "The first difficulty arises from the fuzzy terminology used to designate these elements.",
        "Even though in English they are most often referred to as discourse markers, a variety of other names are also used, such as discourse particles, discourse connectives, pragmatic markers, etc.",
        "But the main problem for the study of DMs is that there seems to be no agreement regarding which elements should be included",
        "in this class.",
        "For instance, in English, Fraser(1990) has ❑ proposedalistof32 DMs, butSchiffrin(1987)hasonly 23.",
        "Moreover, these two lists have onlyfive common ❑ elements.",
        "The lackofagreementon whatcounts as a DM reflects the great diversity of approaches used to ❑ investigatethem, resultingfrom divergentresearch interests, methods andgoals.",
        "❑ At a verygeneral level, it is nevertheless possible to ❑ formulate a rather consensual definition of DMs.",
        "Following Andersen (2001, p. 39), discourse markers are “a ❑ class ofshort, recurrent linguistic items that generally ❑ have little lexical importbut serve significant pragmatic ❑ functions in conversation.”Items typicallyfeaturedin ❑ this class include (in English): actually, and, but, I mean, like, so, you know, and Nwell.",
        "OurstudyofDMs andits application to natural language processing is related to a wider-scope investigation ofDMs which is groundedin relevance theory ❑ (Sperber & Wilson1 986/1995).",
        "In this framework, DMs ❑ encode a procedure whose role is to constrain the inferential partofcommunication, byrestraining the number of hypotheses the hearer has to consider in order to understand the speaker’s meaning3."
      ]
    },
    {
      "heading": "2.2 Importance ofDiscourseMarkers for NLP",
      "text": [
        "The analysis of DMs for language processing is often inspired bydiscourse analysis theories such as Rhetorical Structure Theory(Mann & Thompson 1 988).",
        "In this context, DMs are used to detect coherence relations automatically(Marcu2000).",
        "Forexample, so, therefore andthenaresupposedtoindicatearelationofconclu-sion between two segments.",
        "However, this analysis of DMs is notfine-grainedenough: for instance, ifthe three markers above imply the same type ofrelation, whycan theynot be interchangedin everycontext?",
        "Morerecently, DMs have also been usedasuseful cues to detect dialog acts andconversational moves.",
        "For example, oh implies aresponse to a newpiece ofinfor-mation andwellimplies a correction (Heeman, Byron & Allen 1 998).",
        "However, DMs are then onlypartial cues, since thereis no one-to-one mappingbetween theuse of a marker andthe presence of a given relation (see for instance Taboada 2003).",
        "❑ In order to provide a more precise and comprehensive frameworkfor the use ofDMs in natural language processing, we derived elsewhere a three-step resolution procedure from arelevance-theoretic analysis (Zufferey 2004).",
        "These steps can be summarizedas follows: ❑",
        "1. detect the occurrencesofDMs 2.",
        "❑ attach an inferential procedure to everymarker ❑ 3. determine thescopeof eachprocedure",
        "In the remainder ofthis paper, we will focus onlyon the firststep, i.e. thedetectionofDMs.",
        "Thedifficultyof this taskcomes fromthefact thatDMs are veryam-biguous items.",
        "Typically, words like well, nowor like can fulfillmultiplefunctions.",
        "Thefirststeptowards a correct use ofDMs for language processing is therefore to disambiguate them, i.e. to extractonlytheoccur-rences of the respective lexical item functioning as a DM –in otherwords the pragmatic occurrences (see their definition for like in section 3 below).",
        "Sections 6,7 and 8 below will describe various automatic methods to accomplish this task.",
        "Note that ❑ even ifwe have groundedour approach in relevance theory, this Efirst taskisof paramountimportancetoanytheoryofdis-course.",
        "Forinstance, in an RST framework, DMs can be used to infer coherence relations onlyiftheir pragmatic occurrences have previouslybeen identified.",
        "❑"
      ]
    },
    {
      "heading": "2.3 ❑ Overview of DM Frequencies ❑",
      "text": [
        "The manualannotationofDMsin asubpartof theICSI meeting corpus (ca.",
        "6 hours and 60,000 words) shows a big difference in the frequencyofoccurrence for various DMs.Themostfrequentonesare but(543times),like (89), andwell (287).",
        "Others are moderatelyfrequent, e.g., actually (43), basically (21) ornow(19), while otherare veryrare: furthermore(2), however(1), more-over(0).Thefrequencyof eachDM is relativelystable across the meetings.",
        "❑ The frequencyofDMsdependsalot onthetypeof discourse.",
        "Forexample, the DMhoweveris foundmuch more frequentlyin written than in spoken language.",
        "There are about 50 occurrences ofhoweverin the Lon-don-LundCorpus (500,000 words, transcription ofspoken ❑ language) ❑ and ❑ about ❑ 550 ❑ occurrences ❑ in ❑ the Lancaster-Oslo/Bergen (LOB) corpus (1 million words, written texts).",
        "However–like most otherDMs –is also much more frequentin dialogs as opposedto monologs.",
        "Another bias comes from the type of activity recorded: however is more frequent in formal settings, such as interviews vs. telephone conversations.",
        "Andlast, the regional variation ofEnglish, e. g. American vs. British, can influence the results.",
        "EAccordingto Lenk(1998), “howeverisnot usedinspokenAmerican English”.",
        "The conclusion is thatthe frequencies above cannot be taken to be universal.",
        "But in the type of data we are interestedin–dialogs –thereisahighproportionof DM like.Besides,in agreaterpart of theICSI-MRcorpus (ca.",
        "50 hours),37%ofthe 2,116 occurrences of like correspondtoitsuse as aDM. Hencethenecessityto disambiguateitcorrectlybecomes quiteobvious, not onlyto have abetterpragmaticanalysis ofoccurrences but also toimprove parsingandPOStagging4."
      ]
    },
    {
      "heading": "3 ❑ The Case ofLike",
      "text": [
        "The discoursemarkerlikeis probablyoneofthemost difficult to detect automatically because of the large number offunctionsofthewordlike.",
        "ApartfromaDM, like can be used as a preposition, as in example ( 1) below, an adjective (2), a conjunction (3), an adverb (4), a noun (5) anda verb (6)5: ❑",
        "1.",
        "F1 Hewas likeason to me.",
        "❑ 2.",
        "Cooking, ironingandlikechores.",
        "3.",
        "Nobodycansingthat songlikehedid.",
        "4.",
        "F1 It’s nothinglikeasniceastheirprevious house!",
        "❑ 5.",
        "F1 Scenes of unrestthelike(s)ofwhichhadnever been seen before in the city.",
        "❑ 6.",
        "F1 Ilike chocolateverymuch.",
        "The DM like is sometimes analyzed simplyas a “filler”, a hesitation word like rkhmm that has no contri-butionto the meaningofanutterance6.However,other studies have shown thatlikehas a much more complex role in dialogue.",
        "FAtagenerallevel, likecanbede-scribedasa“loosetalk”marker(Andersen2001).",
        "The function oflike is to make explicit to the hearer that whatfollows themarker (forinstance anoun phrase) is in fact a loose interpretation of the speaker’s belief.",
        "Consider the following examples from the ICSI corpus:",
        "1.",
        "Ittookliketwentyminutes.",
        "2.",
        "❑ Theyhadlittle carvings oflike deadpeople on the walls or something.",
        "Inthe first example,byusinglike, [thespeakerintendsto communicate that the duration mentionedis an approximation.",
        "In the secondexample, theapproximation concerns theexpression thatwas used(“deadpeople”).",
        "Byusing like, the speaker informs the audience that this term doesn’t exactlymatch what she has in mind.",
        "But like as a DMhas also otherfunctions, for example introducing a quotation (reported speech) and serving as a discourse link introducing a correction or a reformulation7.",
        "We will notelaborateon thesefunctions, sincethe remainderofthispaperwillbededicatedtotheidentifi-cation of DM like, regardless ofits precise functions.",
        "❑"
      ]
    },
    {
      "heading": "4 Disambiguation ofLikebyHumans",
      "text": [
        "Before trying to extract automatically the pragmatic occurrences oflike,wehavedesignedtwoexperiments involving human judges.",
        "These preliminaryexperiments are useful indicators ofthedifficultyofthis task, and the human scores will be used to assess more accurately the scores obtained by automatic methods systems."
      ]
    },
    {
      "heading": "4.1 Description oftheExperiments ❑",
      "text": [
        "In thefirst experiment, human judges usedonlythe written transcription ofutterances containing like.",
        "Inthe secondexperiment, weexploredthepossibilitytoim-prove the level ofinter-annotatoragreementbyusing prosodic information: the human judges were also able to listen to the meeting recordings."
      ]
    },
    {
      "heading": "4.2 First Experiment:AnnotationBasedonWritten Transcription Only ❑",
      "text": [
        "The firstexperimentinvolved6 human judges, 3 men and3 women whoseagerangedfrom25 to40.",
        "They were dividedin two groups ofequal size:one ofnative English speakers, andone ofFrench speakers with a verygoodknowledgeofEnglish.",
        "❑ Everyjudgewasaskedtoannotateanumberofut-terances ❑ containing ❑ like, taken ❑ from two ❑ different sources: 26 occurrences came from the transcription of movie dialogs (from Pretty Woman) and 49 occurrences corresponded to one ICSI-MRmeeting.",
        "The participants were askedto decide for everyoc-currence oflikewhetheritrepresentedaDMornot.",
        "Theywere also asked to specifytheir degree of certainty on a three-point scale (1 N certain, 2 N reasonablysure, 3 N hesitating).",
        "Answers were simplywritten on paper.",
        "At the beginning, participants receivedwritten indications concerning the role oflike as a DM as well as examples ofpragmatic andnon-pragmatic uses.",
        "❑"
      ]
    },
    {
      "heading": "4.3 ❑ Second Experiment: Use ofProsodic Cues ❑",
      "text": [
        "Inthesecondexperiment,agroupof3 judges (2French speakersand1 English speaker)wereaskedtoperform the same type oftask, butin addition to thewritten transcription, theywere also allowed to listen to the re-cordingofthemeetingwhenneeded.",
        "Thissecond experimentdidnotincludedialogsfromamoviebut onlyfrom a one-hour ICSI-MRmeeting, containing 5 5 occurrences oflike8.",
        "Theparticipantsreceivedthesame set ofinstructions as in the firstexperiment, and in addition some explanation about the prosodyoflike as a DM.",
        "No time constraints were imposed, so the subjects could listen to the recording as manytimes as needed.",
        "Onaverage,theycompletedthetaskinahalfanhour.",
        "Access to the recording was provided through a hypertext transcript synchronized to the sound file at the 1utterance level (a multimedia 1 solution developed for the IM2 project)."
      ]
    },
    {
      "heading": "4.4 ResultsandDiscussion",
      "text": [
        "Results showthat annotatingDMs is a difficult task even for human judges.",
        "In the firstexperiment, the level 8Two oftheparticipantshadalreadyparticipatedinthefirst experiment, but the meetingwas not the one usedinthe previous experiment.",
        "11 of inter-annotator agreement measured by the Kappa coefficientis quite low(r=0.40) forthe natural dialogs ofthe ICSI-MRcorpus, andaveragefor themovie tran-scription(r= 0.65)9.In thesecondexperiment,withthe help ofprosodic cues, inter-annotator agreement increases, andtheannotation becomes much more reliable (r=0.74).",
        "Therefore, theidentification ofDM likeis an empiricallyvalidtask, which can be accomplishedat a reasonable performance level byuntrained annotators.",
        "However, access to the prosodic information (from recordings) appears to be required.",
        "Theinter-annotator agreement scores also set an initial boundaryon auto-maticperformances, which shouldnotbeexpectedto reach much higher levels.",
        "These results shouldbe con-firmedbyexperiments on longertranscripts, involving also annotators with specific training for DMs.",
        "❑ The results obtainedin these experiments shedan interesting empirical light on a number of predictions that were made before the experiments.",
        "❑ First, it appears thatDMs areeasierto annotatein pre-planneddialogs, because such dialogs are less ambiguous than the natural ones.",
        "Indeed, the level of agreement reached for the movie transcription is l much higher than for the IC SI-MR meeting in the same conditions (0.65 vs. 0.42).",
        "This resultconfirms thateven if movie dialogs are made to reproduce the naturalness of naturallyoccurring dialogs, theyare never as ambiguous, mainlybecause theyonlyreflect the global communicative intention of one person (the author).",
        "The secondhypothesiswetestedconcernedthedif-ference between native andnon-native speakers’ ability to annotate DMs.",
        "We believedthatthe group ofnative English speakers would have a better level ofagree-ment.",
        "This prediction has not been confirmed: the group ofnon-native English speakers obtainednearlythesame level ofagreementas thenative English speakers, for both types of corpora: r = 0.67 vs. r= 0.63 for the movie transcription and r= 0.4 vs. r= 0.43 for the meeting corpus.",
        "So it seems that non-native English speakers with a verygood command ofEnglish are just as reliable as native English speakers to annotate DMs.",
        "M The thirdprediction we have testedis the possible correlation between the degree ofcertaintyof annotators andthelevel ofagreement.",
        "Wehaven’tbeen ableto findanysignificant correlation on both types ofcorpora and l in both experiments.",
        "Thus, the capacityofhuman judges to evaluate their own intuition doesn’t seem to be veryhigh for this task.",
        "However, it should be mentioned that in general, the subjects have been much more confident in the second experiment, when theywere able to useprosodiccues.",
        "The percentageofanswers given 9 We use Krippendorff’ s scale to assess intercoder agreement.",
        "This scale discounts anyresult with r<0.67, allows tentative conclusions when0.67 < r<0.8 anddefinite conclusions when r2 0.8.",
        "11 with maximal certaintybythe two annotators who took partin both experiments grewfrom 45%to 60%and from 65%to 87% respectively.",
        "❑ When lookingmorecloselyat theutterances upon which annotators do notagree, we can see thatsome types ofoccurrencesoflikeseemto be muchmoredif-ficulttoannotateinboth experiments.",
        "In mostofthese cases, like hadthe function ofa preposition.",
        "For example, one subject was mistaken in annotating all occurrences ofthetype: sounds like, seemslike, feelslike, as DMs.",
        "This observationisnotsosurprisingifwebearin mindthatthepragmatic uses oflikeseem to have emerged(historically) in agrammaticalization process.",
        "According to Andersen (2001, p. 294): “the fundamental assumption here is that the pragmatic marker like originates in alexical item, thatis, apreposition with the inherent meaning ‘similar to’”.",
        "This suggests that more detailed explanations regarding the role of the DM like as well as some more training would probably l i m-prove the reliabilityof annotation.",
        "To sum up, these two experiments have enabledus toquantifythelevel of agreementbetweenhumananno-tators andto confirm the usefulness ofprosodic cues in order to efficientlydetect the DM like.",
        "❑"
      ]
    },
    {
      "heading": "5 Automatic Detection ofLikeasaDM",
      "text": []
    },
    {
      "heading": "5.1 ❑ A Priori Cues",
      "text": [
        "We have defined three linguistic criteria to be used for the disambiguation ofDMs in general, which we will applyto the disambiguation oflike in section 6 below.",
        "The first criterion is the presence of collocations.",
        "For instance, when well is used to markachange of topic, it is nearlyalways usedin acluster ofmarkers such as: well you know, well now, well Ithinkoroh well.",
        "Onthecontrary, when usedtocloseatopic, well can very often be found in clusters like OKwell or well anyway/anyhow.",
        "The criterion ofcollocations can also be applied the other wayround, to establish cases where a given element cannotbe a DM.",
        "Forinstance, when like ❑ is ❑ used ❑ in ❑ collocations ❑ such ❑ as: ❑ I/you ❑ like, seems/feels like, justlike; or when well is used in constructions like: very well, as Fwell, quite well, etc.",
        "The second criterion isthe position in the utterance.",
        "Again, depending on the word, this criterion can be used to ascertain that an element is a DM or, on the contrary, to rule out this possibility.",
        "For instance, well as a DM is nearlyalways placedatthebeginningofan utterance or at least, atthe beginning ofa prosodic unit.",
        "In other cases, the use ofthis criterion implies that to be a DM, an elementmustnotcommencetheutterance.",
        "According F to Aijmer (2002, p. 30):“Some of the discourse particles [... ] (actually, sortof) can, for instance, be in-sertedparentheticallyor finally, often with little difference in meaning, after a sentence, clause, turn, tone unit as apost-endfieldconstituent.” ❑ The third criterion is prosody.",
        "According to Schif-frin(1987, p. 328)“[adiscourseparticle] hastohavea range ofprosodiccontourse.g.tonicstressandfollowed bya pause, phonological reduction”.",
        "However, even though these three criteria can help a human annotatorto extractDMs successfullymost of the time, some rare occurrences remain ambiguous.",
        "Some occurrencesareat the boundarybetweenaprag-maticandanon-pragmatic use.",
        "In these rare cases, both interpretations remain equallypossible.",
        "❑"
      ]
    },
    {
      "heading": "5.2 ApplicationofA PrioriCuestoNLP",
      "text": [
        "Some of the criteria we propose seem relatively easy to automate.",
        "For instance, it is rather easyto extract a seta collocationsoncealistismade.",
        "Although somecolloca-tions implythepresenceofaDM, andsomeotherits absence, in some cases this criterion is in fact much more efficient in its second form, to rule out the pres-enceof aDM.Itisalsorathereasytoautomatethecriterion involving a certain position in the utterance, especiallywhenthe position isstronglyconstrained(for instance, at the beginning or endoftheutterance).",
        "As far as prosody is concerned, the detection of pitch variations (for instance amounting to a correct transcription ofcommas) seems feasible for goodqualityrecordings.",
        "C However, used independently from the others, none of these criteria can suffice to completely automate the extraction ofDMs,eventhoughin some cases asingle criterion can be enough to get good results.",
        "For example, in the caseofwell, the position in the utterancecan often be sufficient to correctly extract a significant proportion ofall occurrences.",
        "Nevertheless, it will not solve all occurrences, since wellis not always used at the beginning of an utterance but also at the beginning ofa prosodic phrase, as in: “AndIsaid, well Ihavetothink about it”.",
        "In these cases, the use ofprosodyto detect prosodic phrases becomes [ necessary.",
        "Similarly, the ex-clusionofsomecollocationslikeverywell,aswell,etc.",
        "is necessaryto solve the last problematic cases.",
        "❑ In sum, these criteriaseem to be sufficientto par-tiallyautomate the disambiguation of DMs, which could serve to reduce the burden of human annotators."
      ]
    },
    {
      "heading": "5.3 Evaluation ofNLP Performance",
      "text": [
        "The evaluationofDMdetectionrequiresa“goldstandard”(correctannotation)andtheimplementationof comparison metrics.",
        "The correct annotation ofDMs was discussedin theexperiments above, in the caseoflike, a highlyversatilemarker.",
        "In ordertohave enoughdatafor our NLP experiment, oneoftheauthors annotated manuallyall occurrences oflike in 50 one-hour dialogs from the ICSI-MRcorpus, generating 2,116 occurrences oflike, ofwhich 792 are DMs.",
        "About 20 occurrences of like could not be reliably disambiguated and were re-movedfrom the reference annotation.",
        "❑ Wehave alreadycomparedtheannotationsproduced byhuman judges using the kappa metric.",
        "This metric can be usedaswellto scorethe performancesofasys-tem at distinguishing pragmatic from non pragmatic uses.",
        "Notethatkappacompensatesthescoresbytaking into account the probabilityofagreement bychance.",
        "A simpler but useful metric is the percentage of occurrences correctlyidentified, oraccuracy.",
        "Unlike kappa, accuracydoes notfactoroutagreementbychance, but provides a more interpretable score.",
        "10 ❑ Furthermore, ifthetasktobeevaluatedisthere-trieval ofpragmatic uses among all uses ofthe lexical item (which are trivial to detect), then recall and precision are also relevant.",
        "For instance, to evaluate techniques thatfilter out non-DMs, we will require them to reach [ nearly1 00% recall, anda reasonable precision – say, more than 0.6 or 0.7 for like, i.e. twice the baseline precision, which is thefrequencyofthe DMuse."
      ]
    },
    {
      "heading": "6 ❑ Filters for the Disambiguation ofLike",
      "text": [
        "We first explore the possibilityto use a list of colloca-tionsinorderto identifyoccurrences oflikeasaDMin two differentcorpora, ICSI-MRandatranscription of Switchboardtelephoneconversations.",
        "Thebestuseof this criterion is to maximize precision while keeping recall as closeas possibleto1 00%, i.e. toruleouta maximal numberofoccurrences thatare notpragmatic while keepingallthepragmaticones.",
        "Suchapartial identification can be usedas a filter to reduce the numberofoccurrences thatmustbeprocessedmanually.",
        "The list of collocations that exclude the presence of a DM contains for example collocations such as: something like that, Ilike, looks like, etc.",
        "The full list contains 26 collocations andwas testedon two different corpora: first, on a subpartofthe ICSI-MRcorpus, with 6 hours of recording, andapproximately60,000 words; then on theSwitchboarddata, transcribedandannotated with DMs (Meteer 1 995), with ca.",
        "2,500 conversations andabout 3 million words.",
        "❑ Ourmethodreaches 0.75 precision with 1 00%recall on the ICSI-MRcorpus, and 0.44 precision with 0.99 recall on Switchboard.",
        "The main goal ofthe filter is thus achieved: recall remains veryhigh on both corpora.",
        "A precision of0.75forICSI-MRmeansthatasignificant numberofoccurrences arecorrectlyruledout–theinitial proportion ofpragmatic uses is about 1 /3, while af",
        "for 20% and 0.52 for 40%.",
        "11 ter the application of the filter it reaches 3/4, and none ❑ ofthepragmaticuseswas missedintheprocess.",
        "❑ The ❑ efficiency ofthe ❑ filter is ❑ smaller ❑ on the Switchboarddata(0.44precisionvs.",
        "0.75 forICSI).In the ICSI-MRcorpus, theprecision obtainedis probably the highest possible one with this filter, since the corpus ❑ was usedas adevelopmentcorpus, from which we have ❑ extractedourset ofcollocations.",
        "Ontheotherhand,in ❑ the Switchboardcorpus, the lower precision might also ❑ bedue to theincoherentannotation.",
        "Weusedindeedthe annotation of DMs that was F1 already present in F1 Switchboard, andthis annotation is not entirelyreliable.",
        "❑ In fact, no real theoretical assumptions seem to underlie ❑ this annotation IandaccordingtoMeteer(1995)thecriteriontodecideifanambiguouscasewasaDMwas “[... ] ifthe speaker is aheavydiscourse like user, count ambiguous cases as discourse markers, if not, assume ❑ theyare not.” In such circumstances, we can expect that the low precision of our system on Switchboard can at ❑ least be partlyattributed to this lackof reliability.",
        "❑ Finally, our system has performedthe same taskas ❑ human judges in the first experiment(see section 4) on ❑ 49 occurrences of like in one ICSI-MRmeeting.",
        "Interestingly, ifwecomparethe average kappa obtainedbetween humans andthekappa obtained between the system andall human judges, we get the same value (κ = 0.42).",
        "Even though the results obtained bythis pre-liminarysystem are quite tentative, this comparison ❑ with human judges seems to indicatethatthe performance is quite acceptable.",
        "❑"
      ]
    },
    {
      "heading": "7 ❑ Use ofa Part-of-speech Tagger",
      "text": [
        "The use ofa POS tagger for disambiguating pragmatic vs. non-pragmaticuses oflikeisastraightforwardidea.",
        "Indeed,iftheaccuracyofthetaggers on colloquial speech transcripts was veryhigh, this would help filter-ingout many(ifnotall) ofthenon-pragmaticuses, such as cases when like is simplya verb.",
        "❑ WeexperimentedusingQTag, afreelyavailable probabilisticPOS taggerforEnglish(Mason2000)11.",
        "The taggerassigns one ofthe following tags to occurrences oflike: preposition(IN, 1,412occurrences), verb (VB, 509), subordinative conjunction (CS,134), general adjective (JJ, 52), and general adverb (RB,9).",
        "These tags mustthen be interpreted in terms ofDM uses.",
        "Asimpleattemptistousethetaggerasafilter,to remove verbal occurrences.",
        "Hence, aVB tagis interpreted as non-DM, andall the other tags as (possible) DMs.",
        "Unfortunately, the evaluation shows that such a filterisunreliable: recallis0.77, precision is 0.3 8, accuracy44%, andkappa is only0.02, i.e. near random cor",
        "relation.",
        "As expected, other interpretations ofthe tags donotleadtobetteroverallresults.Themostsignificant figures are obtained when selecting only adjectival uses oflike(taggedJJ) as potential DMs: the recall is of course verylow, but precision is 0.74, which means that the JJ tag could be used as a cue for the presence of a DM use.",
        "❑ The main reason that explains the failure of the tagger to detect DM uses oflike is thatit was not trainedon speech transcription, where like is quite frequent.",
        "A tagger trainedon speech (supposing annotateddatais available) could use some punctuation from the transcription to improve its accuracy, such as marks for in-terruptionsandpauses thatsometimesappeararound DMuses oflike.",
        "This couldhelpit to avoidmarking some ofthoseoccurrencesas VB.AstudybyHeeman, Byron andAllen (1997) has shown that when specific tags are assigned to DMs andthe tagging is done in the process of speechrecognition,boththequalityoftagging andthe correct identification ofDMs are significantlyimproved.",
        "❑"
      ]
    },
    {
      "heading": "8 ❑ Statistical Training ofDM Classifiers ❑",
      "text": [
        "The relevance ofmachinelearningtechniques todetect DMs andto improve manually-derived classification models has alreadybeen emphasizedbyLitman (1996).",
        "We have conductedmachine learning experiments with the 2,116-occurrence dataset, andconfirmedthe relevance ofthe filters defined in section 6 above, andthe role ofseveral additional features.",
        "The results obtained with likearealso compared, attheendofthissection, with an analysis on well as aDM. ❑"
      ]
    },
    {
      "heading": "8.1 Features for the Classification ofLike",
      "text": [
        "For eachoccurrenceoflike, weextractedthefollowing features thatwe thoughtrelevant to the DM/non-DM classification problem: ❑",
        "• presence of acollocationthatrulesouttheoccur-rence as aDM;since like can be either the first wordorthesecondwordinthecollocation,we separated thisintotwo features; ❑ • duration ofthespokenwordlikecomputedfrom",
        "the timing providedwith theICSI-MRtranscriptions, which was generatedautomatically; ❑",
        "• duration ofthe pause before like:0ormore,or −1 iftheutterancebegins with like (thesegmen-tationinto prosodic utteranceswasalsoprovided with the transcription); ❑ • duration ofthepause afterlike:0ormore,or−1",
        "ifthe utterance ends with like.",
        "❑ In ordertoclassifyeachoftheoccurrencesoflikeas eitheraDM oranon-DM, we useddecision trees as providedwith the machine learningtoolkit WEKA (Witten andFrank2000)12.",
        "Since not all thefeatures are discrete, we used the C4.5 decision tree learner (Quinlan 1993), or J48 in WEKA.For testing, we experimented both with separate trainingandtestsets derivedfrom thedata(e.g.1,500 vs. 616instances), andbyusing1 0 fold ❑ cross-validation ❑ of ❑ classifiers ❑ as ❑ provided ❑ by WEKA.",
        "Results beingsimilar, we reportbelowthelat-terscores.",
        "❑"
      ]
    },
    {
      "heading": "8.2 ❑ Results for the Classification ofLike",
      "text": [
        "The best performance obtained bya C4.5 classifier is 0.95 recall and0.68 precision fortheDMoccurrences, corresponding to 81 %correctlyclassified instances and a kappa of0.63.This isasignificantperformance,but it appears to be in the same range as the filter-based method(testedonlyon asmallerdataset).",
        "Andindeed, the classifiertree(seeFigure1 intheAppendix)exhibits as the firstnodes the two classes ofcollocation filters defined apriori in section 6.",
        "This is a strong empirical proofoftherelevanceofthesefilters.",
        "Notethatthiscri-terion has not been used byLitman (1996) who focuses on a much more detailedanalysis of the prosodyalong with some textual features.",
        "❑ Moreover, the next feature in the tree is theduration ofthepausebeforelike(‘pause_avant’):itappearsthat a relatively long pause before like(greater than 240 ms) characterizes a DM in most remainingcases (70 outof 78).",
        "This matches our intuitions about the prosodic be-haviouroflike as aDM.",
        "The nextfeatures in thetree have quite a low precision, andmaynot generalize to othercorpora.",
        "Tentatively, it appears thataveryshort like (shorter than 120 ms) is not aDM. ❑ The best classifier tends to show that apartfrom the collocation filters, the other features do not playan important role.",
        "A classifier based onlyon the collocation filters achieves 0.96 recall and0.67 precision for DM identification (80% correctlyclassifiedinstances and κ=0.62), which is onlyslightlybelow the best classi-fier.Is it thatthetime-basedfeaturesare totallyirrelevant?",
        "An experiment withoutthetwo collocation filters shows that temporal features are relevant: the best classifier achieves 67% correct classification, with κ= 0.23, that is, somewhatabove chance.",
        "Again, among thefirst nodes ofthe tree are the interval before likeand its dura-tion(Figure2in Appendix).",
        "Also, apauseafter like seems tosignalaDM.",
        "Temporalfeatures aretherefore relevant to DM detection, but theyare in realitycorre-lated with collocation-based features, which supersede them when theycan be detected.",
        "❑ The conclusions of this experiment with like are that the simplefeatures designeduntil now, though particu",
        "larlyefficient given theirsimplicity, do not allowfor more than 70%precision ( at100%recall)forthedetection oflikeas aDM. Time-basedfeatures do not outperform collocation-based filters – though the former could generalize better to other DMs.",
        "This result is also par-ticularlyinterestingconsideringthefact thathuman annotators performedsignificantlybetter when allowed to usesoundfiles.",
        "Theresultssuggestthatprosodicfea-tures other than duration are relevant for the disambiguation oflike.Furtherworkon theprosodyoflike (e.g. pitch) shouldenable us to refine this criterion."
      ]
    },
    {
      "heading": "8.3 The ClassificationofWell",
      "text": [
        "Using a similar procedure, we have appliedC4.5 classification to the detection ofwell as a DM.",
        "On the same dialogs as above, weannotatedtheoccurrences ofwell as a DM (579) among all occurrences of well (873).",
        "About 66%ofall occurrences areDMs, which gives a baseline classification score (all occurrences considered to be DMs).",
        "❑ The features defined for well are similar to those usedfor like: collocation-basedfilters (with adifferent content)andtime-basedfeatures.",
        "Inaddition, wede-finedacollocation-basedfeature thatis supposedto as-certainthepresenceofaDM, namelycollocationssuch asoh well orOKwell.",
        "Wealsoconsidertheoccurrence ofwell atthe endofan interruptedorabandonedutter-ance (ending on transcriptions by‘= =’), a feature we hypothesizeto indicate aDM.",
        "The highest accuracy,91%andκ= 0.8,isobtained bya classifier combining the collocation filters andthe duration ofthepause afterwell(cf.Figure3intheAppendix).",
        "This corresponds to 91 %precision and97% recall forthedetectionofDMs.",
        "❑ The use of the collocation-based filter alone – the one that rules out DM occurrences based on the previ-ousword,e.g.aswell–-Cyieldsonlyslightlylowerper- formance (90%with κ= 0.79).",
        "Again, this does not mean that all the otherfeatures are irrelevant.",
        "Rather, the time-based filter based on the duration of the pause after well, which includes the detection of well at the endofcompletedorinterruptedutterances, produces a classification accuracyof75%(andalowkappa,0.45), with 77% precision and96%recall on the identification ofDMs only.",
        "❑ These results suggest that time-based features could generalize to a whole class ofDMs, but for individual DMs, such features are outperformedbycollocations filters based onpatternsofoccurrences.",
        "The definition of collocation filters for a set of DMs seems feasible, albeit somehowtedious.",
        "❑"
      ]
    },
    {
      "heading": "9 ❑ Conclusion",
      "text": [
        "This paper has presentedseveral computational ap-proachestothedisambiguationofdiscoursemarkers, with afocus on thehighlyambiguous wordlike.",
        "Experiments regarding the humancapacity to annotate reliably the discourse marker like show that relatively untrainedannotators reach akappa agreement ofabout 0.74, producing reliable, though notperfect, annotations –provided theyhave access to the soundfiles.",
        "Automatic performance of the identification task, using a set of collocationfilters,canhelpannotatorsbydiscarding some ofthenon-pragmaticoccurrences.",
        "However, POS taggers seem unable to disambiguate the occurrences of likeinspeechtranscripts.",
        "Finally, thetrainingofdeci-sion trees on about 2, 100 occurrences oflike confirms the relevance ofcollocation filters as the main features, followedbytime-basedfeatures, whilecorrectlyclassi-fying more than 80%ofthe occurrences oflike, and more than 90%ofthose of well.",
        "❑ Future work should explore the relevance of other potential features.",
        "However, given the strongpragmatic function ofDMs, it is unlikelythat low-level features combined with machine learning will entirely solve the problem.",
        "As wehaveseen, POS taggingis quiteunreli-able on DMs, butPOS tags from the surroundingwords couldserve as features for statistical training.",
        "More data and more reliable annotations will also help.",
        "Another promisingapproach is the generalization ofclassification features across several DMs, which will allowthe detection of an entire class ofdiscourse markers.",
        "❑"
      ]
    },
    {
      "heading": "References ❑",
      "text": []
    },
    {
      "heading": "Appendix",
      "text": [
        "Theclassifiers(C4.5 decision trees)built forlike [andfor well that are reproduced here must be interpreted using thefollowingrules.",
        "Startingwiththeroot ofthetree, occurrences of the respective DM (like or well) are classified according to the features appearing at the nodes (roundshapes).",
        "Depending on the values ofthe features (branches ofthe tree), theoccurrences areclassifiedas a DM ( 1) or not (0).",
        "The rectangular boxes contain the class (0/1) and the number of instances correctly/incorrectlyclassified.",
        "❑ Figure m. Best classifierfor like as a DM.",
        "In Figure 1, for like, the features can be glossed as follows: ‘collokexclavant’ –collocation filter ruling out the presenceofaDM, dependingon thewordbefore like; ‘collokexclapres’ –collocation filter, wordafter like; ‘pauseavant’–durationofthesilentgapbefore like; ‘dureelike’ –durationoflike.",
        "Themostrelevant feature, after the collocation filters, is the gap before like: apausesignalsaDMin91%ofthecases.",
        "In Figure 2, for like, when collocation filters are not used, a pause before (‘pauseavant’) anda pause after (‘pauseapres’)arethe mostreliableindicators of aDM (occurrences classifiedas ‘1’).",
        "❑",
        "The best classifierwithout the collocationfeatures C(not representedhere) corresponds to the following rules: (a) ifwell ends an interruptedutterance, then itis aDM (100%accurate); (b) ifit ends a completedutterance, then itis not a DM(88%acc.",
        "); (c) otherwise, itis aDM (81 %acc.).",
        "❑"
      ]
    }
  ]
}
