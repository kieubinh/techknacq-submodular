{
  "info": {
    "authors": [
      "Hu Zhang",
      "Jiaheng Zheng",
      "Ying Zhao"
    ],
    "book": "Second International Joint Conference on Natural Language Processing: Companion Volume including Posters/Demos and tutorial abstracts",
    "id": "acl-I05-2001",
    "title": "A Classification-based Algorithm for Consistency Check of Part-of-Speech Tagging for Chinese Corpora",
    "url": "https://aclweb.org/anthology/I05-2001",
    "year": 2005
  },
  "references": [],
  "sections": [
    {
      "heading": "Abstract",
      "text": [
        "Ensuring consistency of Part-of-Speech (POS) tagging plays an important role in constructing high-quality Chinese corpora.",
        "After analyzing the POS tagging of multi-category words in large-scale corpora, we propose a novel consistency check method of POS tagging in this paper.",
        "Our method builds a vector model of the context of multi-category words, and uses the k-NN algorithm to classify context vectors constructed from POS tagging sequences and judge their consistency.",
        "The experimental results indicate that the proposed method is feasible and effective."
      ]
    },
    {
      "heading": "1 Introduction",
      "text": [
        "Constructing high-quality and large-scale corpora has always been a fundamental research area in the field of Chinese natural language processing.",
        "In recent years, the rapid development in the fields of machine translation (MT), phonetic recognition (PR), information retrieval (IR), web text mining, and etc., is demanding more Chinese corpora of higher quality and larger scale.",
        "Ensuring consistency of Part-of-Speech (POS) tagging plays an important role in constructing high-quality Chinese corpora.",
        "In particular, we focus on consistency check of the POS tagging of multi-tagging words, which consist of same Chinese characters and are near-synonymous, but To whom correspondence should be addressed.",
        "have different grammatical functions.",
        "No matter how many different POS tags a multi-category words may be tagged, ensuring consistency of POS tagging means to assign the multi-category word with the same POS tag when it appears in similar context.",
        "Novel approaches and techniques have been proposed for automatic rule-based and statistics-based POS tagging, and the state-of-the-art approaches achieve a tagging precision of 89% and 96%, respectively.",
        "A great portion of the words appearing in Chinese corpora are multi-category words.",
        "We have studied the text data from the 2M-word Chinese corpus published by Peking University, and statistics show that multi-category words cover 11% of the words, while the percentage of the occurrence of multi-category words is as high as 47%.",
        "When checking the POS tags, human experts may have disagreements or make mistakes in some cases.",
        "After analyzing 1,042 sentences containing the word \" , which are extracted from the 2M-word Chinese corpus of Peking University, the number of incorrect tags for the word \" is 15, which accounts for around 1.3%.",
        "So far in the field of POS tagging, most of the works have focused on novel algorithms or techniques for POS tagging.",
        "There are only a limited number of studies has focused on consistency check of POS tagging.",
        "Xing (Xing, 1999) analyzed the inconsistency phenomena of word segmentation (WS) and POS tagging.",
        "Qu and Chen (Qu and Chen, 2003) improved the corpus quality by obtaining POS tagging knowledge from processed corpora, preprocessing, and checking con1 sistency with methods based on rules and statistics.",
        "Qian and Zheng (Qian and Zheng, 2003; Qian and Zheng, 2004) introduced a rule-based consistency check method that obtained POS tagging knowledge automatically from processed corpora by machine learning (ML) and rough set (RS) methods.",
        "For real corpora, Du and Zheng (Du and Zheng, 2001) proposed a rule-based consistency check method and strategy to identify the inconsistency phenomena of POS tagging.",
        "However, the algorithms and techniques for automatic consistency check of POS tagging proposed in (Qu and Chen, 2003; Qian and Zheng, 2003; Qian and Zheng, 2004; Du and Zheng, 2001) still have some insufficiencies.",
        "For example, the assignment of POS tags of the inconsistent POS tagging that are not included in the instance set needs to be conducted manually.",
        "In this paper, we propose a novel classification-based method to check the consistency of POS tagging.",
        "Compared to Zhang et al.",
        "(Zhang et al., 2004), the proposed method fully considers the mutual relation of the POS in POS tagging sequence, and adopts transition probability and emission probability to describe the mutual dependencies and h-NN algorithm to weigh the similarity.",
        "We evaluated our proposed algorithm on our 1.5M-word corpus.",
        "In open test, our method achieved a precision of 85.24% and a recall of 85.84%.",
        "The rest of the paper is organized as follows.",
        "Section 2 introduces the context vector model of POS tagging sequences.",
        "Section 3 describes the proposed classification-based consistency check algorithm.",
        "Section 4 discusses the experimental results.",
        "Finally, the concluding remarks are given in Section 5."
      ]
    },
    {
      "heading": "2 Describing the Context of Multi-category Words",
      "text": [
        "The basic idea of our approach is to use the context information of multi-category words to judge whether they are tagged consistently or not.",
        "In other words, if a multi-category word appears in two locations and the surrounding words in those two locations are tagged similarly, the multi-category word should be assigned with the same POS tag in those two locations as well.",
        "Hence, our approach is based on the context of multi-category words and we model the context by looking at a window around a multi-category word and the tagging sequence of this window.",
        "In the rest of this section, we describe our vector representation of the context of multi-category words and how to determine various parameters in our vector representations."
      ]
    },
    {
      "heading": "2.1 Vector Representation of the Context of Multi-category Words",
      "text": [
        "Our vector representation of context consists of three key components: the POS tags of each word in a context window (POS attribute), the importance of each word to the center multi-category word based on distance (position attribute), and the dependency of POS tags of the center multi-category word and its surrounding words (Dependency Attribute).",
        "Given a multi-category word and its context window of size 1, we represent the words in sequential order as (wl, w2i ..., wl) and the POS tags of each word as (tl, t2, ..., tl).",
        "We also refer to the latter vector as POS tagging sequence.",
        "In practise, we choose a proper value of 1 so that the context window contains sufficient number of words and the complexity of our algorithm remains relatively low.",
        "We will discuss this matter in detail later.",
        "In this study, we set the value of 1tobe7.",
        "The POS tagging sequence contains information of the POS of each preceding (following) word in a POS tagging sequence as well as the position of each POS tag.",
        "The POS of surrounding words may have different effect on determining the POS of the multi-category word, which we refer to as POS attribute and represent it using a matrix as follows.",
        "Suppose we have a tag set of size m (cl, c2, ..., c,,,,), given a multi-category word with a context window of size 1 (wi, w2i ..., wi) and its POS tagging sequence, the POS attribute matrix Y is an 1 by m matrix, where the rows indicate the POS tags of the preceding words, multi-category word, and the following words in the context window, while the columns present tags in the tag set.",
        "Yij= 1iff the POS tag of wi is cj .",
        "For example, consider the the POS attribute matrix of in the following sentence: ^^/v ^/a ^^/n^/u^/a^/n ^/d^/v ^^/n ,/w",
        "As we let l = 7, we look at the word and its 3 preceding and following words.",
        "Hence, the POS tagging sequence is ( a, n, u, a, n, d, v ).",
        "In our study, we used a standard tag set that consists of 25 tags.",
        "Suppose the tag set is ( n, v, a, d, u, p, r,m,q,c,w,I,f,s,t,b,z,e,o,l,j,h,k,g,y),then the POS attribute matrix of in this example is:",
        "Due to the different distances from the multi-category word, the POS of the word before (after) the multi-category word may in a POS tagging sequence have a different influence on the POS tagging of the multi-category word, which we refer to as position attribute.",
        "Given a multi-category word with a context window of size 1, suppose the number of preceding (following) words is n (i.e., l = 2n + 1), the position attribute vector VX of the multi-category word is given by VX = (dl, ..., dn, do+l, do+2, ..., dl), where do+l is the value of the position attribute of the multi-category word and do+li (dn+l+i) is the value of the position attribute of the ith preceding (following) word.",
        "We further require that Vi",
        "We choose a proper position attribute vector so that the multi-category word itself has the highest weight, and the closer the surrounding word , the higher its weight is.",
        "If we consider a context window of size 7, based on our preliminary experiments, we chose the following position attribute values: dl = d7 = 1/22; d2 = d6 = 1/11;",
        "position attribute vector used in our study can be written as follows:",
        "Note that if the POS tag in the POS tagging sequence is incorrect, the position attribute value of the corresponding position should be turned into a negative value, so that when the incorrect POS tag appears in a POS tagging sequence, this attribute can correctly show that the incorrect POS tag has negative effect on generating the final context vector.",
        "The last attribute we focus on is dependency attribute, which corresponds to the fact that there are mutual dependencies on the appearance of every POS in POS tagging sequences.",
        "In particular, we use transition probability and emission probability in Hidden Markov Model (HMM) (Leek, 1997) to capture this dependency.",
        "Given a tag set of size m (cl, c21 ..., c,,,,), the transition probability table T is an m by m matrix and given by:",
        "where f (ci, cj) is the frequency of the POS tag cj appears after the POS tag ci in the entire corpus; f (ci) is the frequency of the POS tag ci appears in the entire corpus; and PT is the transition probability.",
        "Given a tag set of size m (cl, c21 ..., c,,,), the emission probability table E is an m by m matrix and given by:",
        "where f (ci, cj) is the frequency of the POS tag ci appears before the POS tag cj in the entire corpus; f (cj) is the frequency of the POS tag cj appears in the entire corpus; and PE is the emission probability.",
        "Note that both T and E are constructed from the entire corpus and we can look up these two tables easily when we consider the POS tags appear in POS tagging sequences.",
        "Now, when we look at a context window of size 7 (wl, w2i ..., w7) and its POS tagging sequence (tl, t2, ..., t7), there are three types of probabilities we need to take into account.",
        "The first one is the probability of the appearance of the POS tag t4 of the multi-category word, which we can write as follows:",
        "where f(W4) is the frequency of the appearance of the multi-category word w4 in the entire corpus and f (w4istaggedast4) is the frequency of the appearance where the word w4 is tagged as t4 in the entire corpus.",
        "The second one is transition probability, which is the probability of the appearance of the POS tag ti+l in the i + 1 position after the POS tag ti in the i position and shown in Eqn.",
        "2:",
        "(2) The last last is emission probability, which is the probability of the appearance of the POS tag ti-1 in the i 1 position before the POS tag ti in the i position and shown in Eqn.",
        "3:",
        "According to the above three probability formulas we can build a seven dimensional vector, where each dimension corresponds to one POS tag, respectively.",
        "Given a multi-category word with a context window of size 7 and its POS tagging sequence, the dependency attribute vector VP of the multi-category word is defined as follows:"
      ]
    },
    {
      "heading": "2.1.4 Context Vector of Multi-category Words",
      "text": [
        "Now we are ready to define the context vector of multi-category words.",
        "Given a multi-category word with a context window of size l and its POS attribute matrix Y, position attribute vector VX, and dependency attribute vector VP, the context vector VS of the multi-category word is defined as follows:",
        "where a and 13 are the weights of the position attribute and the dependency attribute, respectively.",
        "Note that we require a + 13 = 1, and their optimal values are determined by experiments in our study."
      ]
    },
    {
      "heading": "2.2 Experiment on the Size of the Context Window",
      "text": [
        "Context vectors can be extended by using 4 to 7 preceding (following) words to substitute 3 preceding (following) words in context windows and POS tagging sequences.",
        "We conducted experiments with a context window of size 3 to 7 on our sampled 1M-word training corpus and performed closed test.",
        "The experimental results are evaluated in terms of both the precision of consistency check and algorithm complexity simultaneously.",
        "We plot the effect on precision in Figure 1.",
        "preceding (following) words.",
        "As shown in Figure 1, the precision of consistency check increases as we include more preceding (following) words.",
        "In particular, the precision is improved by 1% when we use 7 preceding (following) words.",
        "However, the increase of complexity is much higher than that of precision, because the dimensionality of the position attribute vector, POS attribute vector, and dependency attribute vector doubles.",
        "Hence, we chose 3 as the number of preceding (following) words to form context windows and calculate context vectors."
      ]
    },
    {
      "heading": "2.3 Effect on consistency check precision of",
      "text": [
        "a and 13 When using our sampled 1M-word training corpus to conduct closed test, we found that consistency check precision changes significantly with the different values of a and 13.",
        "Figure 2 shows the trend when a varies from 0.1 to 0.9.",
        "We used a = 0.4 and 13 = 0.6 in our experiments."
      ]
    },
    {
      "heading": "3 Consistency Check of POS Tagging",
      "text": [
        "Our consistency check algorithm is based on classification of context vectors of multi-category words.",
        "In particular, we first classify context vectors of each multi-category word in the training corpus, and then we conduct the consistency check of POS tagging based on classification results."
      ]
    },
    {
      "heading": "3.1 Similarity between Context Cectors of Multi-category Words",
      "text": [
        "After constructing context vectors for all multi-category words from their context windows and POS tagging sequences, the similarity of two context vectors is defined as the Euclidean Distance between the two vectors.",
        "where x and y are two arbitrary context vectors of n dimensions."
      ]
    },
    {
      "heading": "3.2 h-NN Classification Algorithm",
      "text": [
        "Classification is a process to assign objects that need to be classified to a certain class.",
        "In this paper, we used a popular classification method: the k-NN algorithm.",
        "Suppose we have c classes and a class (wi(i = 1, 2, ..., c)) has Ni samples (X~i)~(j = 1, 2, ..., Ni)).",
        "The idea of the h-NN algorithm is that for each unlabeled object x, compute the distances between x and all samples whose class is known, and select h samples (h nearest neighbors) with the smallest distance.",
        "This object x will be assigned to the class that contains the most samples in the k nearest neighbors.",
        "We now formally define the discriminant function and discriminant rule.",
        "Suppose h1, k2,..., h are the numbers of samples in the h nearest neighbors of the object x that belong to the classes wl, w2, ..., w, respectively.",
        "Define the discriminant function of the class wi as di (x) = hi, i = 1, 2, ..., c. Then, the discriminant rule of determining the class of the object x can be defined as follows: d,,,,x = max di (x) ==> x E w,,,, ~~~~~~~~~~"
      ]
    },
    {
      "heading": "3.3 Consistency Check Algorithm",
      "text": [
        "In this section, we describe the steps of our classification-based consistency check algorithm in detail.",
        "Step1: Randomly sampling sentences containing multi-category words and checking their POS tagging manually.",
        "For each multi-category word, classifying the context vectors of the sampled POS tagging sequences, so that the context vectors that have the same POS for the multi-category word belong to the same class.",
        "Step2: Given a context vector x of a multi-category word c, calculating the distances between x and all the context vectors that contains the multi-category word c in the training corpus, and selecting k context vectors with smallest distances.",
        "Step3: According to the k-NN algorithm, checking the classes of the k nearest context vectors and classifying the vector x. Step4: Comparing the POS of the multi-category word c in the class that the k-NN algorithm assigns x to and the POS tag of c. If they are the same, the POS tagging of the multi-category word c is considered to be consistent, otherwise it is inconsistent.",
        "The major disadvantage of this algorithm is the difficulty in selecting the value of k. If k is too small, the classification result is unstable.",
        "On the other hand, if k is too big, the classification deviation increases."
      ]
    },
    {
      "heading": "3.4 Selecting h in Classification Algorithm",
      "text": [
        "Figure 3 shows the consistency check precision values obtained with various k values in the k-NN algorithm.",
        "The precision values are closed",
        "test results on our 1M-word training corpus, and tagging.",
        "were obtained by using a = 0.4 and 13 = 0.6 in the context vector model.",
        "algorithm.",
        "As shown in Figure 3, when h continues to increase from 6, the precision remains the same.",
        "When when k reaches to 9, the precision starts declining.",
        "Our experiment with other a and /3 values also show similar trends.",
        "Hence, we chose h = 6 in this paper."
      ]
    },
    {
      "heading": "4 Experimental Results",
      "text": [
        "We evaluated our consistency check algorithm on our 1.5M-word corpus (including 1M-word training corpus) and conducted open and closed tests.",
        "The results are showed in Table 1.",
        "The experimental results show two interesting trends.",
        "First, the precision and recall of our consistency check algorithm are 87.20% and 92.67% in closed test, respectively, and 85.24% and 85.84% in open test, respectively.",
        "Compared to Zhang et al.",
        "(Zhang et al., 2004), the precision of consistency check is improved by 2-3%, and the recall is improved by 10%.",
        "The experimental results indicate that the context vector model has great improvements over the one used in Zhang et al.",
        "(Zhang et al., 2004).",
        "Second, thanks to the great improvement of the recall, to some extent, our consistency check algorithm prevents the happening of events with small probabilities in POS"
      ]
    },
    {
      "heading": "5 Conclusion and Future Research",
      "text": [
        "In this paper, we propose a new classification-based method to check consistency of POS tagging, and evaluated our method on our 1.5M-word corpus (including 1M-word training corpus) with both open and closed tests.",
        "In the future, we plan to investigate more types of word attributes and incorporate linguistic and mathematical knowledge to develop better consistency check models, which ultimately provide a better means of building high-quality Chinese corpora."
      ]
    },
    {
      "heading": "Acknowledgements",
      "text": []
    }
  ]
}
