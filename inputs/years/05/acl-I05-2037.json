{
  "info": {
    "authors": [
      "Soojong Lim",
      "Changki Lee",
      "Myung-Gil Jang"
    ],
    "book": "Second International Joint Conference on Natural Language Processing: Companion Volume including Posters/Demos and tutorial abstracts",
    "id": "acl-I05-2037",
    "title": "Restoring an Elided Entry Word in a Sentence for Encyclopedia QA System",
    "url": "https://aclweb.org/anthology/I05-2037",
    "year": 2005
  },
  "references": [
    "acl-J97-4002"
  ],
  "sections": [
    {
      "heading": "Speech/Language Information Research Department ETRI, Korea",
      "text": [
        "leeck@etri .",
        "re .",
        "kr"
      ]
    },
    {
      "heading": "Myoung-Gil Jang Speech/Language Information Research Department ETRI, Korea",
      "text": []
    },
    {
      "heading": "Abstract",
      "text": [
        "This paper presents a hybrid model for restoring an elided entry word for encyclopedia QA system.",
        "In Korean encyclopedia, an entry word is frequently omitted in a sentence.",
        "If the QA system uses a sentence without an entry word, it cannot provide a right answer.",
        "For resolving this problem, we combine a rule-based approach with Maximum Entropy model to use the merit of each approach.",
        "A rule-based approach uses caseframes and sense classes.",
        "The result shows that combined approach gives a 20% increase over our baseline."
      ]
    },
    {
      "heading": "1 Introduction",
      "text": [
        "Ellipsis is a linguistic phenomenon that people omit a word or phrase not to repeat a same word or phrase in a sentence or a document.",
        "Usually, ellipsis involves the use of clauses that are not syntactically complete sentences (Allen, 1995) but the fact does not apply to all cases.",
        "An ellipsis occurring in encyclopedia documents in Korean is an example.",
        "Korean: classes which are not restored using sense classes.",
        "If there is no caseframes, we use a statistical method, ME model, for determining whether the entry word is restored or not.",
        "Because each approach has both strength and weakness, we combine three approaches to achieve a better performance."
      ]
    },
    {
      "heading": "2 Related Work",
      "text": [
        "Ellipsis is a pervasive phenomenon in natural languages.",
        "While previous work provides important insight into the abstract syntactic and semantic representations that underlie ellipsis phenomena, there has been little empirically oriented work on ellipsis.",
        "There are only two similar empirical experiments done for this task.",
        "First is Hardt's algorithm(Hardt, 1997) for detecting VPE in the Penn Treebank.",
        "It achieves precision levels of 44% and recall of 53%, giving an F-Measure of 48% using a simple search technique, which relies on the annotation having identified empty expressions correctly.",
        "Second is Nielsen's machine learning techniques(Nielsen, 2003).",
        "They only try to detect of elliptical verbs using four different machine learning techniques, Transformation-based learning, Maximum entropy modeling, Decision Tree Learning, Memory Based Learning.",
        "It achieves precision levels of 85.14% and recall of 69.63%, giving an F-Measure of 76.61%.",
        "There are 4 steps: detection, identification of antecedents, difficult antecedents, resolving antecedents.",
        "Because this study only concentrates on the detection, a comparison with our study is inadequate.",
        "We combine rule-based techniques with machine learning technique for using the merit of each technique."
      ]
    },
    {
      "heading": "3 Restoring an Elided Entry Word",
      "text": [
        "We use three kinds of algorithms: A caseframe algorithm, an acceptable sense class algorithm, and Maximum Entropy (ME) algorithm.",
        "For knowing a strength and weakness points of each algorithm, we do experiments on each algorithm.",
        "Then we combine algorithms for higher performance.",
        "Our system answers in three ways: restoring an entry word as a subject, restoring an entry word as an object, and does not restore an entry word.",
        "We evaluate an algorithm in two ways.",
        "First, we evaluate all answers with precision.",
        "Second, we evaluate just two answers, restoring an entry word as a subject and object, with F-measure."
      ]
    },
    {
      "heading": "3.1 Using Caseframes",
      "text": [
        "We use modified caseframes constructed for Korean-Chinese machine translation.",
        "The format of Korean-Chinese machine translation case frame is as the following: A=Sense_code!case_particle verb > Chinese > Korean Sentence",
        "The result of caseframe algorithm is in table 2.",
        "The result of caseframe algorithm shows that it has a high precision but a relatively low recall because it is impossible to construct caseframes for all sentences."
      ]
    },
    {
      "heading": "3.2 Acceptable Sense Class",
      "text": [
        "All entry words in the encyclopedia belong to at least one sense class.",
        "We verify all 444 sense classes to see whether they could be restored in a sentence.",
        "We set a precision threshold 50% and we fix 36 sense classes to \"acceptable sense class\".",
        "An acceptable sense class is a sense class that if an entry word is included in an acceptable sense class, we unconditionally restore an entry word in a sentence.",
        "Our verification tells that there is only acceptable sense classes for subjects.",
        "Table 3 shows acceptable sense classes.",
        "The result of acceptable sense class algorithm is presented in table 4.",
        "Because we cannot get acceptable sense classes for objects, F-measure of object is 0."
      ]
    },
    {
      "heading": "3.3 Maximum Entropy Modeling",
      "text": [
        "Maximum entropy modeling uses features, which can be complex, to provide a statistical model of the observed data which has the highest possible entropy, such that no assumptions about the data are made.",
        "where p is the most uniform distribution, C is a set of probability distributions under the constraints and H(p) is entropy of p. o Ratnaparkhi(Ratnaparkhi 98) makes a strong argument for the use of maximum entropy modes, and demonstrates their use in a variety of NLP tasks.",
        "The Maximum Entropy Toolkit was used for the experiments.' Because maximum entropy allows for a wide range of features, we can use various features, such as lexical feature, POS feature, sense feature, and syntactic feature.",
        "Each feature consists of subfeatures: Lexical feature; Verb lex : lexeme of a target verb Verb e lex : lexeme of a suffix attatched to a target verb POS feature; Verb_pos : pos of a target verb Verb e_pos : pos of a suffix attatch to a target verb Sense feature;",
        "Ti res code: where sense of an entry word is included in acceptable sense class Verb cf subj, obj: whether a sense of entry word is included in caseframe of a targe verb Ti sense : sense class of entry word Syntactic feature; Tree_posi: position of parse tree Rel type: relation type between verbs in a sentence Sen subj, sen obj : existence of subject or object Hybrid feature; Pair =(sense class of entry word, verb) Table 5 shows an example of features that we use for finding an elided entry word.",
        "Previous work using ME model adopted distance-based context for training.",
        "Because we use syntactic features, we can use not only distance-based context but also predicate-argument based context.",
        "The training data for ME algorithm consist of verbs in the encyclopedia document and their syntactic arguments.",
        "Each verb-arguments set is augmented with the information that signifies whether a subject, an object or neither of them should be restored.",
        "For training, we use a dependency parser[Lim, 2004].",
        "A precision of this parser is about 75%.",
        "The results of ME model algorithm is shown in table 6.",
        "The results of ME model shows that its score is the lowest of all.",
        "We guess the reason is that there is not enough training data for covering all sense classes.",
        "Our proposed approach (ASC CF ME) gives the best results among all experiments, with an F-measure of 68.1%, followed closely by ASC_ME.",
        "This gives a 20% increase over our baseline.",
        "For testing a portability of our approach, we experiment the noun phrase ellipsis (NPE) detection.",
        "The performance of NPE is alike an elided entry word.",
        "Recall is 69.31, Precision is 65.05, and F-measure is 67.12.",
        "So we expect the performance of our approach not to drop when applied to NPE or other ellipsis problem.",
        "The results so far are encouraging, and show that the approach taken is capable of producing a robust and accurate system.",
        "In this paper, we suggested the approach that restores an elided entry word for Encyclopedia QA systems combining an acceptable sense class algorithm, a caseframe algorithm, and ME model.",
        "For future work, we plan to pursue the following research.",
        "First, we will use various machine learning methods and compare them with the ME model.",
        "Second, because we plan to apply this approach in the encyclopedia document, we need to design the more general approach to use other ellipsis phenomenon.",
        "Third, we try to find a method for enhancing performance of restoring elided entry words as the object."
      ]
    }
  ]
}
