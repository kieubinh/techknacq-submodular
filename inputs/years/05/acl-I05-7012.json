{
  "info": {
    "authors": [
      "Eduard Barbu",
      "Verginica Barbu Mititelu"
    ],
    "book": "Proceedings of OntoLex 2005 – Ontologies and Lexical Resources",
    "id": "acl-I05-7012",
    "title": "A Case Study in Automatic Building of Wordnets",
    "url": "https://aclweb.org/anthology/I05-7012",
    "year": 2005
  },
  "references": [
    "acl-W00-1318"
  ],
  "sections": [
    {
      "heading": "Abstract",
      "text": [
        "In this paper we present a two-phase methodology for automatically building a wordnet (that we call target wordnet) strictly aligned with an already available wordnet (source wordnet).",
        "In the first phase the synsets for the target language are automatically generated and mapped onto the source language synsets using a series of heuristics.",
        "In the second phase the salient relations that can be automatically imported are identified and the procedure for their import is explained.",
        "The assumptions behind such methodology will be stated, the heuristics employed will be presented and their success evaluated against a case study (automatically building a Romanian wordnet using Princeton WordNet)."
      ]
    },
    {
      "heading": "1 Introduction",
      "text": [
        "The importance of a wordnet for NLP applications can hardly be overestimated.",
        "The Princeton WordNet (PWN) (Fellbaum, 1998) is now a mature lexical ontology which has demonstrated its efficiency in a variety of tasks (word sense disambiguation, machine translation, information retrieval, etc.).",
        "Inspired by the success of PWN many languages started to develop their own wordnets taking PWN as a model (cf. http://www.",
        "globalwordnet.org/gwa/wordnet table.",
        "htm).",
        "In what follows we present a methodology that can be used for automatically building wordnets strictly aligned (that is, using only the EQSYNONYM relation) with an already available wordnet.",
        "We have started our experiment with the study of nouns, so the data presented here are valid only for this grammatical category.",
        "The methodology we present has two phases.",
        "In the first one the synsets for the target language are automatically generated and mapped onto the source language synsets using a series of heuristics.",
        "In the second phase the salient relations that can be automatically imported are identified and the procedure for their import is explained.",
        "The paper has the following organization.",
        "Firstly we state the implicit assumptions in building a wordnet strictly aligned with other wordnets.",
        "Then we shortly describe the resources that one needs in order to apply the heuristics, and also the criteria we used in selecting the Source language test synsets to be implemented.",
        "Finally, we state the problem to be solved in a more formal way, the heuristics employed will be presented and their success evaluated against a case study (automatically building a Romanian wordnet using PWN 2.0)."
      ]
    },
    {
      "heading": "2 Assumptions",
      "text": [
        "The assumptions that we considered necessary for automatically building a target wordnet using a Source wordnet are the following:",
        "1.",
        "There are word senses that can be clearly identified.",
        "This assumption is implicit when one builds a wordnet aligned or not with other wordnets.",
        "This premise was extensively questioned among others by (Kilgarriff, 1997) who thinks that word senses have not a real ontological status, but they exist only relative to a task.",
        "We will not discuss this issue here.",
        "2.",
        "A rejection of the strong reading of Sapir-Whorf (Carroll, 1964) hypothesis (the principle of linguistic relativity).",
        "3.",
        "The acceptance of the conceptualization made by the Source wordnet.",
        "By conceptualization we understand the way in which the Source Wordnet \"sees\" the reality by identifying the main concepts to be expressed and their relationships.",
        "For specifying how different languages can differ with respect with to conceptual space they reflect we will follow (Sowa, 1992) who consider three distinct dimensions: • accidental.",
        "The two languages have different notations for the same concepts.",
        "For example the Romanian word mär and the English word apple lexicalize the same concept.",
        "• systematic.",
        "The systematic dimension defines the relation between the grammar of a language and its conceptual structures.",
        "It deals with the fact that some languages are SVO or VSO, etc., some are analytic and other agglutinative.",
        "Even if it is an important difference between languages, the systematic dimension has little import for our problem • cultural.",
        "The conceptual space expressed by a language is determined by environmental, cultural factors, etc.",
        "It could be the case for example, that concepts that define the legal systems of different countries are not mutually compatible.",
        "So when someone builds a wordnet starting from a source wordnet he/she should ask himself/herself what are the parts (if any) that could be safely transferred in the target language.",
        "The assumption that we make use of is that the differences between the two languages (source and target) are merely accidental: they have different lexicalizations for the same concepts.",
        "As the conceptual space is already expressed by the Source wordnet structure using a language notation, our task is to find the concepts notations in the target language.",
        "When the Source wordnet is not perfect (the real situation), then a drawback of the automatic mapping approach is that all the mistakes existent in the source wordnet are transferred in the target wordnet."
      ]
    },
    {
      "heading": "3 Selection of concepts and resources used",
      "text": [
        "When we selected the set of synsets to be implemented in Romanian we followed two criteria.",
        "The first criterion states that the selected set should be structured in the source wordnet.",
        "This is dictated by the methodology we have adopted (automatic mapping and automatic relation import).",
        "The second criterion is related to the evaluation stage.",
        "To properly evaluate the built wordnet, it should be compared with a \"golden standard\".",
        "The golden standard that we use will be the Romanian Word-net (RoWN) developed in the BalkaNet project.",
        "For fulfilling both criteria we chose a subset of noun concepts from the Romanian Wordnet that has the property that its projection on PWN 2.0 is closed under the hyperonym and the meronym relations.",
        "Moreover, this subset includes the upper level part of PWN lexical ontology.",
        "The projection of this subset on PWN 2.0 comprises 9716 synsets that contain 19624 literals.",
        "For the purpose of automatic mapping of this subset we used an in-house dictionary built from many sources.",
        "The dictionary has two main components:",
        "• The first component consists of the above-mentioned 19624 literals and their Romanian translations.",
        "We must make sure that this part of the dictionary is as complete as possible.",
        "Ideally, all senses of the English words should be translated.",
        "For that we used the (Levitchi and Bantaç, 1992) dictionary and other dictionaries available on web.",
        "• The second component is (Levitchi and Bantaç, 1992) dictionary.",
        "The other resource used is the Romanian Explanatory Dictionary (EXPD 1996) whose entries are numbered to reflect the dependencies between different senses of the same word.",
        "4 Notation introduction In this section we introduce the notations used in the paper and we outline the guiding idea of all heuristics we used: 1.",
        "By TL we denote the target lexicon.",
        "In our experiment TL will contain Romanian words (nouns).",
        "TL= { rwl, rw2, ... rwm } where rwi, withi=l..m, denotes a target word.",
        "2.",
        "By SL we denote the source lexicon.",
        "In our case SL will contain English words (nouns).",
        "SL={ ew1, ew2, ... ewn} where ew}, withj=l..n, denotes a source word.",
        "3.",
        "WT and Ws are the wordnets for the target language and the source language, respectively.",
        "4. wkj denotes the k\" sense of the word Wj.",
        "5.",
        "BD is a bilingual dictionary which acts as a bridge between SL and TL.",
        "BD=(SL, TL, M) is a 3-tuple, where M is a function that associates to each word in SL a set of words in TL.",
        "For an arbitrary word eWj eSL, M(ewj) ={ rwx, rw2, ... rwk }.",
        "A bilingual dictionary formally maps words and not word senses.",
        "If word senses had been mapped, then building WT from a Ws would have been trivial.",
        "Our heuristics is that by increasing the number of interconnections between words in both languages we can uniquely characterize the meaning of a word (synset) as the set of its relations with other synsets or other words.",
        "In the source wordnet a set of relations already exist.",
        "Other useful relations can be derived in the source wordnet or can be imposed by an external resource with which the wordnet is linked (ontology, domains).",
        "In the target language the useful relations can be derived using resources like corpuses, monolingual dictionaries, already classified sets of documents.",
        "We have developed so far a set of four heuristics and we plan to supplement them in the future."
      ]
    },
    {
      "heading": "5 The first heuristic rule",
      "text": [
        "The first heuristic exploits the fact that synonymy imposes an equivalence class on word senses.",
        "ewM , ew■ are the words in synset and superscripts denote their sense numbers) be a SL synset and length(EnSyn)>l. We impose the length of a synset to be greater than one when at least one component word is not a variant of the other words.",
        "So we disregard synsets such as {artefact, artifact}.",
        "The BD translations of the words in the synset will be: We build the corresponding TL synset as M(ew. )",
        "if 3 ew.",
        "e EnSyn such that NoSenses v Jik ' Jik J M(e\\Vj ) fl M (e\\Vj )... fl M(ewÄ )otherwise.",
        "Words belonging to the same synset in SL should have a common translation in TL.",
        "Above we distinguished two cases:",
        "1.",
        "At least one of the words in a synset is monose-mous.",
        "2.",
        "All words in the synset are polysemous.",
        "In the first case we build the TL synset as the set of translations of the monosemous word.",
        "In the second case the corresponding TL synset will be constructed by the intersection of all TL translations of the SL words in the synset.",
        "Taking the actual RoWN as a gold standard we can evaluate the results of our heuristics by comparing the obtained synsets with those in the RoWN.",
        "We distinguish five possible cases: The synsets are equal (this case will be labeled as Identical, ID).",
        "The generated synset has all literals of the correct synset and at least one more (Over-generation, OG).",
        "The generated synset and the golden one have some literals in common and some different (Over-lap,OP).",
        "The generated synset literals form a proper subset of the golden synset (Under-generation,UG).",
        "The generated synset has no literals in common with the correct one (Disjoint,DJ).",
        "The cases Over-Generation, Overlap and Disjoint will be counted as errors.",
        "The other two cases, namely Identical and Under-generation, will be counted as successes.",
        "The evaluation of the first heuristics is given in Table 1.",
        "The NMS column represents the number of synsets mapped by the heuristic, the Percents mapped (PM) column contains the percents of the synsets mapped by the heuristics from the total number of the synsets (9716).",
        "The Percent errors (PE) column represents the percent of synsets from the number of mapped synsets wrongly assigned by the heuristics.",
        "The high number of mapped synsets proves the quality of the first component of the dictionary we used.",
        "The only type of error we encountered is Over-generation."
      ]
    },
    {
      "heading": "6 The second heuristic rule",
      "text": [
        "The second heuristic draws from the fact that the hyperonymy relation can be interpreted as an IS-A relation.",
        "It is also based on two related observations:",
        "1.",
        "A hyperonym and his hyponyms carry some common information.",
        "2.",
        "The information common to the hyperonym and the hyponym will increase as you go down in the hierarchy.",
        "such that EnSym HYP EnSyn2, meaning that En-Sym is a hyperonym of EnSyn2.",
        "Then we generate the translation lists of the words in the synsets.",
        "The intersection is computed as before: The generated synset in the target language will be computed as TL Synset = TL EnSym fl TL EnSyn2Given the above consideration, it is possible that a hyponym and its hyperonym have the same translation in other language and this is more probable as you descend in the hierarchy.",
        "The procedure formally described above is applied for each synset in the source list.",
        "It generates the list of translations for all words in the hyperonym and hyponym synsets and then constructs the TL synsets by intersecting their translations.",
        "In case the intersection is not empty the created synset will be assigned to both SL language synsets.",
        "Because the procedure generates autohyponym synsets this could be an indication that the TL created synsets could be clustered in the TL.",
        "The results of the second heuristic are presented in Table 2.",
        "The low number of mapped synsets (10%) is due to the fact that we did not find many common translations between hyperonyms and their hyponyms."
      ]
    },
    {
      "heading": "7 The third heuristic",
      "text": [
        "The third heuristics takes profit of an external relation imposed over the wordnet.",
        "At IRST PWN 1.6 was augmented with a set of Domain Labels, the resulting resource being called Wordnet Domains (Magnini and Cavaglia, 2000).",
        "The idea of using domains is helpful for distinguishing word senses (different word senses of a word are assigned to different domains).",
        "The best case is when each sense of a word has been assigned to a distinct domain.",
        "But even if the same domain labels are assigned to two or more senses of a word, in most cases we can assume that this is a strong indication of a fine-grained distinction.",
        "It is very probable that the distinction is preserved in the target language by the same word.",
        "For our task we label every word in the BD dictionary with its domain label.",
        "For English words the domain is automatically generated from the English synset labels.",
        "For labeling Romanian words we downloaded a collection of documents from web directories such that the categories of the downloaded documents match the categories used in the Wordnet Domain.",
        "After POS tagging and lemmatizing the documents we selected as features the most relevant nouns.",
        "For this we used the well known x statistic.",
        "The selected nouns were labeled with the corresponding document categories.",
        "The following entry is a BD dictionary entry augmented with domain information: M(ew1Pi,...])= rwx [D,,D2...], rw2 [Di,D3...], rwi [D2,D4...] In the square brackets the domains that pertain to each word are listed.",
        "SL synset and Y)l the associated domain.",
        "Then the TL synset will be constructed as follows:",
        "rwt e M( ewm ) has the property that its domain matches the domain of EnSyn!.",
        "For each synset in the SL we generated all the translations of its literals in the TL.",
        "Then the TLsynset is built using only those TL literals whose domain matches the SL synset domain.",
        "The results of this heuristic are given in Table 3."
      ]
    },
    {
      "heading": "11 Conclusions and future work",
      "text": [
        "Other experiments of automatically building word-nets that we are aware off are (Atserias et al., 1997) and (Lee et al., 2000).",
        "They combine several methods, using monolingual and bilingual dictionaries for obtaining a Spanish Wordnet and, respectively, a Korean one starting from PWN 1.5.",
        "However, our approach is characterized by the fact that it gives an accurate evaluation of the results by automatically comparing them with a manually built wordnet.",
        "We also explicitly state the assumptions of this automatic approach.",
        "Our approach is the first to use an external resource (Wordnet Domains) in the process of automatically building a wordnet.",
        "We obtained a version of Romanian Wordnet that contains 9610 synsets and 11969 relations with 91% accuracy.",
        "The results obtained encourage us to develop other heuristics for automatically building a target Wordnet from a source Wordnet.",
        "The success of our procedure was facilitated by the quality of the bilingual dictionary we used.",
        "Some heuristics developed here may be applied for the automatic construction of synsets of other parts of speech.",
        "That is why we also plan to extend our experiment to adjectives and verbs.",
        "Their evaluation would be of great interest in our opinion.",
        "Finally we would like to thank two anonymous reviewers for helping us in improving the final version of the paper."
      ]
    }
  ]
}
