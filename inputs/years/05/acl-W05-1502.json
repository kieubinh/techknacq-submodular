{
  "info": {
    "authors": [
      "Hakan Burden",
      "Peter Ljunglöf"
    ],
    "book": "International Workshop on Parsing Technology",
    "id": "acl-W05-1502",
    "title": "Parsing Linear Context-Free Rewriting Systems",
    "url": "https://aclweb.org/anthology/W05-1502",
    "year": 2005
  },
  "references": [
    "acl-P87-1015"
  ],
  "sections": [
    {
      "heading": "Abstract",
      "text": [
        "We describe four different parsing algorithms for Linear Context-Free Rewriting Systems (Vijay-Shanker et al., 1987).",
        "The algorithms are described as deduction systems, and possible optimizations are discussed.",
        "The only parsing algorithms presented for linear context-free rewriting systems (LCFRS; Vijay-Shanker et al., 1987) and the equivalent formalism multiple context free grammar (MCFG; Seki et al., 1991) are extensions of the CKY algorithm (Younger, 1967), more designed for their theoretical interest, and not for practical purposes.",
        "The reason for this could be that there are not many implementations of these grammar formalisms.",
        "However, since a very important subclass of the Grammatical Framework (Ranta, 2004) is equivalent to LCFRS/MCFG (Ljunglöf, 2004a; Ljunglöf, 2004b), there is a need for practical parsing algorithms.",
        "In this paper we describe four different parsing algorithms for Linear Context-Free Rewriting Systems.",
        "The algorithms are described as deduction systems, and possible optimizations are discussed."
      ]
    },
    {
      "heading": "1 Introductory definitions",
      "text": [
        "A record is a structure r = {r1 = a1; ... ; rte, = ate,}, where all ri are distinct.",
        "That this can be seen as a set of feature-value pairs.",
        "This means that we can define a simple version of record unification r1 t r2 as the union r1 Ur2, provided that there is no r such that r1.r =� r2.r.",
        "We sometimes denote a sequence X1,..., Xte, by the more compact �X.",
        "To update the ith record in a list of records, we write �r[i := r].",
        "To substitute a variable Bk for a record rk in any data structure r, we write r[Bk/rk]."
      ]
    },
    {
      "heading": "1.1 Decorated Context-Free Grammars",
      "text": [
        "The context-free approximation described in section 4 uses a form of CFG with decorated rules of the form",
        "f : A – > a, where f is the name of the rule, and a is a sequence of terminals and categories subscripted with information needed for post-processing of the context-free parse result.",
        "In all other respects a decorated CFG can be seen as a straightforward CFG."
      ]
    },
    {
      "heading": "1.2 Linear Context-Free Rewriting Systems",
      "text": [
        "A linear context free rewriting system (LCFRS; Vijay-Shanker et al., 1987) is a linear, non-erasing multiple context free grammar (MCFG; Seki et al., 1991).",
        "An MCFG rule is written1 A – > f [B1 ... Bb]:= { r1 =�1; ... ; rte, =�te, } where A and Bi are categories, f is the name of the rule, ri are record labels and ai are sequences of terminals and argument projections of the form Bi.r.",
        "The language G(A) of a category A is a set of string records, and is defined recursively as",
        "It is the possibility of discontinuous constituents that makes LCFRS/MCFG more expressive than context-free grammars.",
        "If the grammar only consists of single-label records, it generates a context-free language.",
        "Example A small example grammar is shown in figure 1, and generates the language",
        "where sh� is the homomorphic mapping such that each a in s is translated to c, and each b is translated to d. Examples of generated strings are ac, abcd and bbaddc.",
        "However, neither abc nor abcdabcd will be",
        "generated.",
        "The language is not context-free since it contains a combination of multiple and crossed agreement with duplication.",
        "If there is at most one occurrence of each possible projection Ai.r in a linearization record, the MCFG rule is linear.",
        "If all rules are linear the grammar is linear.",
        "A rule is erasing if there are argument projections that have no realization in the linearization.",
        "A grammar is erasing if it contains an erasing rule.",
        "It is possible to transform an erasing grammar to non-erasing form (Seki et al., 1991).",
        "Example The example grammar is both linear and non-erasing.",
        "However, given that grammar, the rule",
        "is both non-linear (since A.p occurs more than once) and erasing (since it does not mention A.q)."
      ]
    },
    {
      "heading": "1.3 Ranges",
      "text": [
        "Given an input string w, a range p is a pair of indices, (i, j) where 0 < i < j < I w I (Boullier, 2000).",
        "The entire string w = w1 ... wn spans the range (0, n).",
        "The word wi spans the range (i – 1, i) and the substring wi+1, ... , wj spans the range (i, j).",
        "A range with identical indices, (i, i), is called an empty range and spans the empty string.",
        "A record containing label-range pairs,",
        "is called a range record.",
        "Given a range p = (i, j), the ceiling of p returns an empty range for the right index, rp] = (j, j); and the floor of p does the same for the left index A = (i, i).",
        "Concatenation of two ranges is non-deterministic, (i, j) .",
        "(j/, k) = { (i, k) Ij = j/ } ."
      ]
    },
    {
      "heading": "1.3.1 Range restriction",
      "text": [
        "In order to retrieve the ranges of any substring s in a sentence w = w1 ... wn we define range restriction of s with respect to w as (s)' = { (i, j) I s = wi+1 ... wj }, i.e. the set of all occurrences of s in w. If w is understood from the context we simply write (s).",
        "Range restriction of a linearization record 4) is written (4)), which is a set of records, where every terminal token s is replaced by a range from (s).",
        "The range restriction of two terminals next to each other fails if range concatenation fails for the resulting ranges.",
        "Any unbound variables in 4) are unaffected by range restriction.",
        "Example Given the string w = abba, range restricting the terminal a yields",
        "The other possible solutions fail since they cannot be range concatenated."
      ]
    },
    {
      "heading": "2 Parsing as deduction",
      "text": [
        "The idea with parsing as deduction (Shieber et al., 1995) is to deduce parse items by inference rules.",
        "A parse item is a representation of a piece of information that the parsing algorithm has acquired.",
        "An inference rule is written",
        "where y is the consequence of the antecedents y1 ... yn, given that the side conditions in C hold."
      ]
    },
    {
      "heading": "2.1 Parsing decorated CFG",
      "text": [
        "Decorated CFG can be parsed in a similar way as standard CFG.",
        "For our purposes it suffices to say that the algorithm returns items of the form, [f :A/� – > B1/�1 ... Bn/�n • ] saying that A spans the range p, and each daughter Bi spans pi.",
        "The standard inference rule combine might look like this for decorated CFG: Combine",
        "Note that the subscript x in Bx is the decoration that will only be used in post-processing."
      ]
    },
    {
      "heading": "3 The Naïve algorithm",
      "text": [
        "Seki et al.",
        "(1991) give an algorithm for MCFG, which can be seen as an extension of the CKY algorithm (Younger, 1967).",
        "The problem with that algorithm is that it has to find items for all daughters at the same time.",
        "We modify this basic algorithm to be able to find one daughter at the time.",
        "There are two kinds of items.",
        "A passive item [A; r] has the meaning that the category A has been found spanning the range record r. An active item for the rule A – > f [B� �B'] := IF has the form [A – > f[B�• �B']; 4); �r] in which the categories to the left of the dot, �B, have been found with the linearizations in the list of range records �r.",
        "4) is the result of substituting theyrojections in IF with ranges for the categories found in B."
      ]
    },
    {
      "heading": "3.1 Inference rules",
      "text": [
        "There are three inference rules, Predict, Combine and Convert.",
        "Prediction gives an item for every rule in the grammar, where the range restriction 4) is what has been found from the beginning.",
        "The list of daughters is empty since none of the daughters in B� have been found yet.",
        "Combine",
        "An active item looking for Bk and a passive item that has found Bk can be combined into a new active item.",
        "In the new item we substitute Bk for rk in the linearization record.",
        "We also add rk to the new item’s list of daughters.",
        "Convert",
        "Every fully instantiated active item is converted into a passive item.",
        "Since the linearization record 4) is fully instantiated, it is equivalent to the range record r.",
        "The subscripted numbers are for distinguishing the two categories from each other, since they are equivalent.",
        "Here A.q is a context-free category of its own, not a record projection."
      ]
    },
    {
      "heading": "4 The Approximative algorithm",
      "text": [
        "Parsing is performed in two steps in the approximative algorithm.",
        "First we parse the sentence using a context-free approximation.",
        "Then the resulting context-free chart is recovered to a LCFRS chart.",
        "The LCFRS is converted by creating a decorated context-free rule for every row in a linearization record.",
        "Thus, the rule",
        "will give n context-free rules f : A.ri – > ai.",
        "The example grammar from figure 1 is converted to a decorated CFG in figure 2.",
        "Parsing is now initiated by a context-free parsing algorithm returning decorated items as in section 2.1.",
        "Since the categories of the decorated grammar are projections of LCFRS categories, the final items will be of the form",
        "Since the decorated CFG is over-generating, the returned parse chart is unsound.",
        "We therefore need to retrieve the items from the decorated CFG parse chart and check them against the LCFRS to get the discontinuous constituents and mark them for validity.",
        "The initial parse items are of the form, [A – > f [�B]; r = P; �r] where r� is extracted from a corresponding decorated item such that ri = { r = p I (B.r)i/ � E 0 }.",
        "In other words, [ f : (A.r)/ � – > 0], by partitioning the daughters in 0 ri will consist of all r = p such that B.r is subscripted by i in the decorated item.",
        "Apart from the initial items, we use three kinds of parse items.",
        "From the initial parse items we first build LCFRS items, of the form",
        "where ri ... rte, is a list of labels, r� is a list of l�Bl range records, and r is a range record for the labels r1 ... ri_ 1.",
        "In order to recover the chart we use mark items [A – > f[B�• �B']; r; r�•�r'] The idea is that r� has been verified as range records spanning the daughters �B.",
        "When all daughters have been verified, a mark item is converted to a passive item [A; r]."
      ]
    },
    {
      "heading": "4.1 Inference rules",
      "text": [
        "There are five inference rules, Pre-Predict, Pre-Combine, Mark-Predict, Mark-Combine and Convert.",
        "Every rule A – > f [ �B] is predicted as an LCFRS item.",
        "Since the context-free items contain information about a1 ... ate,, we only need to use the labels r1, ... , rte,.",
        "�rb is a list of l�Bl empty range records.",
        "If there is an initial parse item for the rule R with label r, we can combine it with an LCFRS item looking for r, provided the daughters’ range records can be unified.",
        "When all record labels have been found, we can start to check if the items have been derived in a valid way by marking the daughters’ range records for correctness.",
        "An item that has marked all daughters as correct is converted to a passive item."
      ]
    },
    {
      "heading": "5 The Active algorithm",
      "text": [
        "The active algorithm parses without using any context-free approximation.",
        "Compared to the Naïve algorithm the dot is used to traverse the linearization record of a rule instead of the categories in the right-hand side.",
        "For this algorithm we use a special kind of range, pE, which denotes simultaneously all empty ranges (i, i).",
        "Range restricting the empty string gives (e) = pE.",
        "Concatenation is defined as p� pE = pE � p = p. Both the ceiling and the floor of pE are identities, rpE� = LpEJ = pE.",
        "There are two kinds of items.",
        "Passive items [A; r] say that we have found category A inside the range record r. An active item for the rule A – > f [�B]:= {4); r = ao; IF} is of the form",
        "where r is a range record corresponding to the linearization rows in 4) and a has been recognized spanning p. We are still looking for the rest of the row, 0, and the remaining linearization rows IF.",
        "r� is a list of range records containing information about the daughters �B."
      ]
    },
    {
      "heading": "5.1 Inference rules",
      "text": [
        "There are five inference rules, Predict, Complete, Scan, Combine and Convert.",
        "For every rule in the grammar, predict a corresponding item that has found the empty range.",
        "�rb is a list of l�Bl empty range records since nothing has been found yet.",
        "When an item has found an entire linearization row we continue with the next row by starting it off with the empty range.",
        "An active item that has fully recognized all its linearization rows is converted to a passive item."
      ]
    },
    {
      "heading": "6 The Incremental algorithm",
      "text": [
        "An incremental algorithm reads one token at the time and calculates all possible consequences of the token before the next token is read2.",
        "The Active algorithm as described above is not incremental, since we do not know in which order the linearization rows of a rule are recognized.",
        "To be able to parse incrementally, we have to treat the linearization records as sets of feature-value pairs, instead of a sequence.",
        "The items for a rule A – > f [\"B] := 4) have the same form as in the Active algorithm:",
        "However, the order between the linearization rows does not have to be the same as in 4).",
        "Note that in this algorithm we do not use passive items.",
        "Also note that since we always know where in the input we are, we cannot make use of a distinguished E-range.",
        "Another consequence of knowing the current input position is that there are fewer possible matches for the Combine rule.",
        "If the next symbol in the linearization row is a terminal, its range restriction is concatenated to the range for the partially recognized row.",
        "Combine",
        "If the next item is a record projection Bi.r', and there is an item for Bi which has found r', then move the dot forward.",
        "The information in ri must be consistent with the information found for the Bi item, {r'; r' = p'}."
      ]
    },
    {
      "heading": "7 Discussion",
      "text": [
        "We have presented four different parsing algorithms for LCFRS/MCFG.",
        "The algorithms are described as deduction systems, and in this final section we discuss some possible optimizations, and complexity issues."
      ]
    },
    {
      "heading": "7.1 Different prediction strategies",
      "text": [
        "The Predict rule in the above described algorithms is very crude, predicting an item for each rule in the grammar (for the Incremental algorithm even for each input position).",
        "A similar context-free prediction rule is called bottom-up Earley by Sikkel and Nijholt (1997).",
        "Such crude predictions are only intended for educational purposes, since they lead to lots of uninteresting items, and waste of computing power.",
        "For practical purposes there are two standard context-free prediction strategies, top-down and bottom-up (see e.g. Wirén (1992)) and they can be adapted to the algorithms presented in this paper.",
        "The main idea is that an item for the rule A – > f [B] with the linearization row r = a is only predicted if.. .",
        "(Top-down prediction) ... there is another item looking for A. r. (Bottom-up prediction) ... there is an passive item that has found the first symbol in a.",
        "For a more detailed description of these prediction strategies, see Ljunglöf (2004a)."
      ]
    },
    {
      "heading": "7.2 Efficiency and complexity of the algorithms",
      "text": [
        "The theoretical time complexity for these algorithms is not better than what has been presented earlier.",
        "The complexity arguments are similar and the reader is referred to Seki et al.",
        "(1991).",
        "However, theoretical time complexity does not say much about practical performance, as is already clear from context-free parsing, where the theoretical time complexity has remained the same ever since the first publications (Kasami, 1965; Younger, 1967).",
        "There are two main ways of improving the efficiency of existing algorithms, which can be called refinement and filtering (Sikkel and Nijholt, 1997).",
        "First, one wants to be able to locate existing parse items efficiently, e.g. by indexing some properties in a hash table.",
        "This is often done by refining the parse items or inference rules, increasing the number of items or deduction steps.",
        "Second, it is desirable to reduce the number of parse items, which can be done by filtering out redundant parts of an algorithm.",
        "The algorithms presented in this paper can all be seen as refinements and filterings of the basic algorithm of Seki et al.",
        "(1991): The naïve algorithm is a refinement of the basic algorithm, since single items and deduction steps are decomposed into several different items and smaller deduction steps.",
        "The approximative algorithm is both a refinement and a filtering of the naïve algorithm; a refinement since the inference rules Pre-Predict and Pre-Combine are added, and a filtering since there will hopefully be less items for Mark-Predict and Mark-Combine to take care of.",
        "The active algorithm is a refinement of the naïve algorithm, since the Combine rule is divided into the rules Complete, Scan and Combine.",
        "The incremental algorithm is finally a refinement of the active algorithm, since Predict and Complete can select from any possible remaining linearization row, and not just the following.",
        "Furthermore, the different prediction strategies (top-down and bottom-up), become filterings of the algorithms, since they reduce the number of parse items."
      ]
    },
    {
      "heading": "7.3 Implementing and testing the algorithms",
      "text": [
        "The algorithms presented in this paper have been implemented in the programming language Haskell, for inclusion in the Grammatical Framework system (Ranta, 2004).",
        "These implementations are described by Burden (2005).",
        "We have also started to implement a selection of the algorithms in the programming language Prolog.",
        "Preliminary results suggest that the Active algorithm with bottom-up prediction is a good candidate for parsing grammars written in the Grammatical Framework.",
        "For a normal sentence in the English resource grammar the speedup is about 20 times when compared to context-free parsing and filtering of the parse trees.",
        "In the future we plan to test the different algorithms more extensively."
      ]
    },
    {
      "heading": "Acknowledgments",
      "text": [
        "The authors are supported by the EU project TALK (Talk and Look, Tools for Ambient Linguistic Knowledge), IST-507802."
      ]
    }
  ]
}
