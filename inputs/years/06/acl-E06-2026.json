{
  "info": {
    "authors": [
      "Manfred Klenner"
    ],
    "book": "Conference of the European Association for Computational Linguistics – Demonstrations",
    "id": "acl-E06-2026",
    "title": "Grammatical Role Labeling With Integer Linear Programming",
    "url": "https://aclweb.org/anthology/E06-2026",
    "year": 2006
  },
  "references": [
    "acl-C04-1197",
    "acl-P04-1051",
    "acl-W99-0629"
  ],
  "sections": [
    {
      "heading": "Abstract",
      "text": [
        "In this paper, we present a formalization of grammatical role labeling within the framework of Integer Linear Programming (ILP).",
        "We focus on the integration of sub-categorization information into the decision making process.",
        "We present a first empirical evaluation that achieves competitive precision and recall rates."
      ]
    },
    {
      "heading": "1 Introduction",
      "text": [
        "An often stressed point is that the most widely used classifiers such as Naive Bayes, HMM, and Memory-based Learners are restricted to local decisions only.",
        "With grammatical role labeling, for example, there is no way to explicitly express global constraints that, say, the verb “to give” must have 3 arguments of a particular grammatical role.",
        "Among the approaches to overcome this restriction, i.e. that allow for global, theory based constraints, Integer Linear Programming (ILP) has been applied to NLP (Punyakanok et al., 2004) .",
        "We apply ILP to the problem of grammatical relation labeling, i.e. given two chunks.1 (e.g. a verb and a np), what is the grammatical relation between them (if there is any).",
        "We have trained a maximum entropy classifier on vectors with morphological, syntactic and positional information.",
        "Its output is utilized as weights to the ILP component which generates equations to solve the following problem: Given subcategorization frames (expressed in functional roles, e.g. subject), and given a sentence with verbs, V (auxiliary, modal, finite, non-finite, ..), and chunks, C (np, pp), label all pairs (V UC) x (V UC) with a grammatical role2.",
        "In this paper, we are pursuing two empirical scenarios.",
        "The first is to collapse all subcategorization",
        "frames of a verb into a single one, comprising all subcategorized roles of the verb but not necessarily forming a valid subcategorization frame of that verb at all.",
        "For example, the verb “to believe” subcategorizes for a subject and a prepositional complement (“He believes in magic”) or for a subject and a clausal complement (“She believes that he is dreaming”), but there is no frame that combines a subject, a prepositional object and a clausal object.",
        "Nevertheless, the set of valid grammatical roles of a verb can serve as a filter operating upon the output of a statistical classifier.",
        "The typical errors being made by classifiers with only local decisions are: a constituent is assigned to a grammatical role more than once and a grammatical role (e.g. of a verb) is instantiated more than once.",
        "The worst example in our tests was a verb that receives from the maxent classifier two subjects and three clausal objects.",
        "Here, such a role filter will help to improve the results.",
        "The second setting is to provide ILP with the correct subcategorization frame of the verb.",
        "The results of such an oracle setting define the upper bound of the performance our ILP approach can achieve.",
        "Future work will be to let ILP find the optimal subcategorization frame given all frames of a verb."
      ]
    },
    {
      "heading": "2 The ILP Specification",
      "text": [
        "Integer Linear Programming (ILP) is the name of a class of constraint satisfaction algorithms which are restricted to a numerical representation of the problem to be solved.",
        "The objective is to optimize (minimize or maximize) the numerical solution of linear equations (see the objective function in Fig. 1).",
        "The general form of an ILP specification is given in Fig. 1 (here: maximization).",
        "The goal is to maximize a nary function f, which is defined as the sum of the variables yiXi.",
        "Assignment decisions (e.g. grammatical role labeling) can be modeled in the following way: X,,",
        ",J represents the weighted sum of all adjunct attachments.",
        "T is the weighted sum of all attributive PP (“the book in her hand ..”) and genitive NP attachments (“die Frau desge,, Professorsge,,” [the wife of the professor]).",
        "U represents the weighted sum of all unassigned objects.3 V is the weighted sum of the case frame instantiations of all verbs in the sentence.",
        "It is defined as follows:",
        "are binary class variables that indicate the (non-) assignment of a constituent ci to the grammatical function Gj (e.g. subject) of a verb vk.",
        "To represent this, three indices are needed.",
        "Thus, X is a complex variable name, e.g. Gijk.",
        "For the sake of readability, we add some mnemotechnical sugar and use Givjck instead or Svjck for a constituent ck being (or not) the subject S of verb vj (S thus is an instantiation of Gi) .",
        "If the value of such a class variable Givjck is set to 1 in the course of the maximization task, the attachment was successful, otherwise ( Givjck = 0) it failed.",
        "yi from Fig. 1 are weights that represent the impact of an assignment (or a constraint); they provide an empirically based numerical justification of the assignment (we don”t need the aij).",
        "For example, we represent the impact of Givjck=1 by wGiv,ck.",
        "These weights are derived from a maximum entropy model trained on a treebank (see section 5).",
        "b is used to set up numerical constraints.",
        "For example that a constituent can only be the filler of one grammatical role.",
        "The decision, which of the class variables are to be “on” or “off” is based on the weights and the constraints an overall solution must obey to.",
        "ILP seeks to optimize the solution."
      ]
    },
    {
      "heading": "3 Formalization",
      "text": [
        "We restrict our formalization to the following set of grammatical functions: subject (S), direct (i.e. accusative) object (D), indirect (i.e. dative) object (Z), clausal complement (C), prepositional complement (P), attributive (np or pp) attachment (T) and adjunct (,J).",
        "The set of grammatical relations of a verb (verb complements) is denoted with G, it comprises S, D, Z, C and P. The objective function is:",
        "This sums up over all verbs.",
        "For each verb, each grammatical role (Rvi is the set of such roles) is instantiated from the stock of all constituents (consts*, which includes all np and pp constituents but also the verbs as potential heads of clausal objects).",
        "Gvicj is a variable that indicates the assignment of a constituent cj to the grammatical function G of verb vi.",
        "wGvicj is the weight of such an assignment.",
        "The (binary) value of each Gvicj is to be determined in the course of the constraint satisfaction process, the weight is taken from the maximum entropy model.",
        "T is the function for weighted attributive attachments:",
        "where wTcicj is the weight of an assignment of constituent cj to constituent ci and Tcicj is a binary variable indicating the classification decision whether cj actually modifies ci.",
        "In contrast to consts*, consts does not include verbs.",
        "The function for weighted adjunct attachments,",
        "where consts – is the set of PP constituents of the sentence.",
        "w,7vic, is the weight given to a classification of a PP as an adjunct of a clause with vi as verbal head.",
        "The function for the weighted assignment to the null class, U, is:",
        "This represents the impact of assigning a constituent neither to a verb (as a complement) nor",
        "to another constituent (as an attributive modifier).",
        "Uci = 1 means that the constituent ci has got no head (e.g. a finite verb as part of a sentential coordination), although it might be the head of other ci .",
        "The equations from 1 to 5 are devoted to the maximization task, i.e. which constituent is attached to which grammatical function and with which impact.",
        "Of course, without any further restrictions, every constituent would get assigned to every grammatical role - because there are no co-occurrence restrictions.",
        "Exactly this would lead to a maximal sum.",
        "In order to assure a valid distribution, restrictions have to be formulated, e.g. that a grammatical role can have at most one filler object and that a constituent can be at most the filler of one grammatical role."
      ]
    },
    {
      "heading": "4 Constraints",
      "text": [
        "A constituent cj must either be bound as an attribute, an adjunct, a verb complement or by the null class.",
        "This is to say that all class variables with cj sum up to exactly 1; cj then is consumed.",
        "one of the grammatical roles of verb vi (G c Rvi).",
        "No two constituents can be attached to each other symmetrically (being head and modifier of each other at the same time), i.e. T (among others) is defined to be asymmetric.",
        "Tcicj + Tcj ci < 1, V j, i (7) Finally, we must restrict the number of filler objects a grammatical role can have.",
        "Here, we have to distinguish among our two settings.",
        "In setting one (all case roles of all frames of a verb are collapsed into a single set of case roles), we can’t require all grammatical roles to be instantiated (since we have an artificial case frame, not necessarily a proper one).",
        "This is expressed as < 1 in equation 8. coasts\" Gvicj < 1, Vi, G E Rvi (8) In setting two (the actual case frame is given), we require that every grammatical role G of the verb vi (G E Rv) must be instantiated exactly"
      ]
    },
    {
      "heading": "5 The Weighting Scheme",
      "text": [
        "A maximum entropy model was used to fix a probability model that serves as the basis for the ILP weights.",
        "The model was trained on the Tiger treebank (Brants et al., 2002) with feature vectors stemming from the following set of features: the part of speech tags of the two candidate chunks, the distance between them in phrases, the number of verbs between them, the number of punctuation marks between them, the person, case and number of the candidates, their heads, the direction of the attachment (left or right) and a passive/active voice flag.",
        "The output of the maxent model is for each pair of chunks (represented by their feature vectors) a probability vector.",
        "Each entry in this probability vector represents the probability (used as a weight) that the two chunks are in a particular grammatical relation (including the “non-grammatical relation”, NGR) .",
        "For example, the weight for an adjunct assignment, WJV1c3, of two chunks v1 (a verb) and c3 (a np or a pp) is given by the corresponding entry in the probability vector of the maximum entropy model.",
        "The vector also provides values for a subject assignment of these two chunks etc."
      ]
    },
    {
      "heading": "6 Empirical Results",
      "text": [
        "The overall precision of the maximum entropy classifier is 87.46%.",
        "Since candidate pairs are generated almost without restrictions, most pairs do not realize a proper grammatical relation.",
        "In the training set these examples are labeled with the non-grammatical relation label NGR (which is the basis of ILPs null class U).",
        "Since maximum entropy modeling seeks to sharpen the classifier with respect to the most prominent class, NGR gets a strong bias.",
        "So things are getting worse, if we focus on the proper grammatical relations.",
        "The precision then is low, namely 62.73%, the recall is 85.76%, the f-measure is 72.46 %.",
        "ILP improves the precision by almost 20% (in the “all frames in one setting” the precision is 81.31%).",
        "We trained on 40,000 sentences, which gives about 700,000 vectors (90% training, 10% test, including negative and positive pairings).",
        "Our first experiment was devoted to fix an upper bound for the ILP approach: we selected from the set of subcategorization frames of a verb the correct one (according to the gold standard).",
        "The set of licenced grammatical relations then is reduced to the cor",
        "rect subcategorized GR and the non-governable GR J (adjunct) and T (attribute).",
        "The results are given in Fig. 2 under F.... (cf. section 3 for GR shortcuts, e.g. S for subject).",
        "The results of the governable GR (S down to C) are quite good, only the results for prepositional complements (P) are low (the f-measure is 76.4%).",
        "From the 36509 grammatical relations, 37173 were found and 31680 were correct.",
        "Overall precision is 85.23%, recall is 86.77% and the f-measure is 85.99%.",
        "The most dominant error being made here is the coherent but wrong assignment of constituents to grammatical roles (e.g. the subject is taken to be object).",
        "This is not a problem with ILP or the subcategorization frames, but one of the statistical model (and the feature vectors).",
        "It does not discriminate well among alternatives.",
        "Any improvement of the statistical model will push the precision of ILP.",
        "The results of the second setting, i.e. to collapse all grammatical roles of the verb frames to a single role set (cf.",
        "Fig.",
        "2, F,oii), are astonishingly good.",
        "The f-measures comes close to the results of (Buchholz, 1999).",
        "Overall precision is 79.99%, recall 82.67% and f-measure is 81.31%.",
        "As expected, the values of the governable GR decrease (e.g. recall for prepositional objects by 30.1%).",
        "The third setting will be to let ILP choose among all subcategorization frames of a verb (there are up to 20 frames per verb).",
        "First experiments have shown that the results are between the F,o,, and F,oii results.",
        "The question then is, how close can we come to the Fro,, upper bound."
      ]
    },
    {
      "heading": "7 Related Work",
      "text": [
        "ILP has been applied to various NLP problems, including semantic role labeling (Punyakanok et al., 2004), extraction of predicates from parse trees (Klenner, 2005) and discourse ordering in generation (Althaus et al., 2004).",
        "(Roth and Yih, 2005) discuss how to utilize ILP with Conditional Random Fields.",
        "Grammatical relation labeling has been coped with in a couple of articles, e.g. (Buchholz, 1999).",
        "There, a cascaded model (of classifiers) has been proposed (using various tools around TIMBL).",
        "The f-measure (perfect test data) was 83.5%.",
        "However, the set of grammatical relations differs from the one we use, which makes it difficult to compare the results."
      ]
    },
    {
      "heading": "8 Conclusion and Future Work",
      "text": [
        "In this paper, we argue for the integration of top down (theory based) information into NLP.",
        "One kind of information that is well known but have been used only in a data driven manner within statistical approaches (e.g. the Collins parser) is subcategorization information (or case frames).",
        "If subcategorization information turns out to be useful at all, it might become so only under the strict control of a global constraint mechanism.",
        "We are currently testing an ILP formalization where all subcategorization frames of a verb are competing with each other.",
        "The benefits will be to have the instantiation not only of licensed grammatical roles of a verb, but of a consistent and coherent instantiation of a single case frame.",
        "Acknowledgment.",
        "I would like to thank Markus Dreyer for fruitful (“long distance”) discussions and a number of (steadily improved) maximum entropy models.",
        "Also, the detailed comments of the reviewers have been very helpful."
      ]
    }
  ]
}
