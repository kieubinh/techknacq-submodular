{
  "info": {
    "authors": [
      "Chi-Shing Wang",
      "Grace Ngai"
    ],
    "book": "SIGHAN Workshop on Chinese Language Processing",
    "id": "acl-W06-0106",
    "title": "A Clustering Approach for Unsupervised Chinese Coreference Resolution",
    "url": "https://aclweb.org/anthology/W06-0106",
    "year": 2006
  },
  "references": [
    "acl-C04-1033",
    "acl-I05-2040",
    "acl-J01-4004",
    "acl-M95-1005",
    "acl-M98-1029",
    "acl-N01-1008",
    "acl-N04-1001",
    "acl-N04-1038",
    "acl-P02-1014",
    "acl-P05-1020",
    "acl-W03-1015",
    "acl-W04-3224",
    "acl-W99-0611"
  ],
  "sections": [
    {
      "heading": "Abstract",
      "text": [
        "Coreference resolution is the process of identifying expressions that refer to the same entity.",
        "This paper presents a clustering algorithm for unsupervised Chinese coreference resolution.",
        "We investigate why Chinese coreference is hard and demonstrate that techniques used in coreference resolution for English can be extended to Chinese.",
        "The proposed system exploits clustering as it has advantages over traditional classification methods, such as the fact that no training data is required and it is easily extended to accommodate additional features.",
        "We conduct a set of experiments to investigate how noun phrase identification and feature selection can contribute to coreference resolution performance.",
        "Our system is evaluated on an annotated version of the TDT3 corpus using the MUC-7 scorer, and obtains comparable performance.",
        "We believe that this is the first attempt at an unsupervised approach to Chinese noun phrase coreference resol ution."
      ]
    },
    {
      "heading": "1 INTRODUCTION",
      "text": [
        "Noun phrase coreference resolution is the process of detecting noun phrases (NPs) in a document and determining whether the NPs refer to the same entity, where an entity is defined as “a construct that represents an abstract identity”.",
        "The NPs that refer to the entity are known as mentions.",
        "Mentions can be antecedents or ana-phors.",
        "An anaphor is an expression that refers back to a previous expression in a discourse.",
        "In Figure 1, %#11�� (President Clinton) refers to %#11 (Clinton) and is described as an anaphoric reference to%#11 (Clinton).",
        "%#11� �(President Clinton) is described as the antecedent of 0, (he).",
        "%#11 (Clinton), %#11�� (President Clinton) and the second 0, (he) are all mentions of the same entity that refers to former U.S. president Bill Clinton.",
        "NP coreference resolution is an important subtask in natural language processing (NLP) applications such as text summarization, information extraction, data mining and question answering.",
        "This task has attracted much attention in recent years (Cardie and Wa gstaff, 1999; Harabagiu et al., 2001; Soon et al., 2001; Ng and Cardie, 2002; Yang et al., 2004; Florian et al., 2004; Zhou et al., 2005), and has been included as a subtask in the MUC (Message Understanding Conferences) and ACE (Automatic Content Extraction) competitions.",
        "Coreference resolution is a difficult task for various reasons.",
        "Firstly, a list of features can play a role to support coreference resolution such as",
        "[Clinton1] said that Washington would progressively follow through on economic aid to [Korea2].",
        "[Kim Dae-Jung3] applauded [Clinton1]’s speech.",
        "[He1] said, “[President Clinton 1] reiterated in the talks that [he1] would provide solid support for [Korea2] to shake off the economic crisis.",
        "Sydney, July 2006. c�2006 Association for Computational Linguistics gender agreement, number agreement, head noun matches, semantic class, positional information, contextual information, appositive, abbreviation etc.",
        "Ng and Cardie (2002) found 53 features which are useful for this problem.",
        "However, no single feature is completely reliable since there are always exceptions: e.g. the number agreement test returns false when",
        "segmentation system (Lancashire, 2005) to segment the Chinese characters into words.",
        "The segmented words are then labeled with POS tags by a statistical POS tagging system (Fung et al., 2004)."
      ]
    },
    {
      "heading": "3 Mention Detection",
      "text": [
        "After the corpus has been preprocessed, mention detection involves the identification of NPs in the corpus that refer to some entity.",
        "Most of these NPs correspond to non-recursive NPs, which makes this task simpler as most syntactic parsers identify NPs as part of the parsing process.",
        "This approach, however, suffers from two problems: firstly, the parser itself is unlikely to be 100% accurate; and secondly, the boundaries of the NPs identified by the parser may not correspond exactly with those of the entities identified by the human annotator.",
        "Another approach is simply to use heuristics based on the POS tag sequence to identify potential NPs of interest.",
        "The advantage of this method is that the NPs thus extracted should be closer to the human-annotated entities since the heuristics will be constructed specifically for this task.",
        "To investigate the effect of different approaches on the result of the coreference resolution, we applied both methods separately to our corpus.",
        "The corpus was parsed with a state-of-the-art multilingual statistical parser (Bikel 2004), which is trained on the Chinese Penn Treebank.",
        "After parsing, we extracted all non-recursive NP chunks tagged by the parser as possible mentions.",
        "For the heuristic-based approach, we applied a few simple heuristics, which had been previously developed during unrelated work for English named-entity resolution (i.e. they were not written with foreknowledge of the gold standard entities) and which are based on the part-of-speech tags of the words.",
        "Some examples of our heuristics were to look for pronouns, or to extract all noun sequences, or sequences of determiners followed by adjectives and nouns.",
        "Table 1 shows the performance of the parsing-based approach versus the heuristic-based approach.",
        "The parser-based approach suffers mainly because the NPs that it extracts tend to be on the long side, resulting in recall errors when the boundaries of the parser-identified NPs mismatch with the human-annotated entities.",
        "In addition, the parser also tends to extract more NPs than needed, which results in a hit to precision."
      ]
    },
    {
      "heading": "4 Coreference Resolution",
      "text": [
        "The final step after the mention detection phase is to determine which of the extracted phrases refer to the same entity, or are coreferent.",
        "The small size of our corpus made it quite obvious that we would not be able to perform supervised learning, as there would not be enough data for generalization purposes.",
        "Therefore we chose to use an unsupervised clustering approach for this step.",
        "Clustering is a natural choice as it partitions the data into groups; used on coreference resolution, we expect to gather coreferrent NPs into the same cluster.",
        "Furthermore, most clustering methods can easily incorporate both context-dependent and independent constraints into their features."
      ]
    },
    {
      "heading": "4.1 Features",
      "text": [
        "Our features use both lexical and syntactic information designed to capture both the content of the phrase and its role within the sentence.",
        "With the exception of the last three features, which are defined with respect to a noun phrase pair, all our features describe various aspects of a single noun phrase: Lexical String – This is just simply the string of words in the phrase.",
        "Head Noun – The head noun in a phrase is the noun that is not a modifier for another noun.",
        "Sentence Position – This measures the position of the phrase within the document.",
        "Gender – For each phrase, we use a gazetteer to assign it a gender.",
        "The possible values are male (e.g. AI, mister), female (e.g. 4%",
        "Semantic Class – To give the system more information on each phrase, we generated our own gazetteer from a combination of gazetteers compiled from web sources and heuristics.",
        "Our gazetteer consists of 4700 entries, each of which is labeled with one of the following semantic classes: person, organization, location, facility, GPE, date, money, vehicle and weapon.",
        "Phrases in the corpus that are found in the gazetteer are given the same semantic class label; phrases not in the gazetteer are marked as UNKNOWN.",
        "Proper Name – The part-of-speech tag “NR” and a list of common proper names were used to label each noun phrase as to whether it is a proper name (values: true/false).",
        "Pronoun – Determined by the part-of-speech “PN”.",
        "Values: true/false.",
        "Demonstrative Noun Phrase – A demonstrative noun phrase is a phrase that consists of a noun phrases preceded by one of the characters [",
        "are very commonly used in Chinese and even though the previous feature will work on most of them, there are some common exceptions.",
        "To make sure that we catch those as well, we introduced a Chinese-specific feature as a further test.",
        "Since abbreviations and nicknames are not usually substrings of the original strings, but will still share some common characters, we measure the Levenshtein distance, defined as the number of character insertions, deletions and substitutions, between every potential antecedent-anaphor pair."
      ]
    },
    {
      "heading": "4.2 Distance Metric",
      "text": [
        "In order for the clustering algorithm to be able to group instances together by similarity, we need to determine a distance metric between two instances – in our case, two noun phrases.",
        "For our system, we borrowed a simple distance metric from Cardie and Wagstaff (1999) that sums up the results of a series of functions over the two phrases:",
        "Table 2 presents the features and the corresponding functions that were used in our system.",
        "Each function calculates a distance between the two phrases that is an indicator of the degree of incompatibility between the two phrases with respect to a particular feature.",
        "The NOUN PHRASE, HEAD NOUN, DEMONSTRATIVE, APPOSITIVE and ABBREVIATIVE functions test for compatibility and return a negative value when the two phrases are compatible for that term’s feature.",
        "The reason for the negative value returned is that if the two phrases match on this particular feature, then it is a strong indicator of coreference.",
        "Therefore, we reduce the distance between two phrases, making it more likely that they will be clustered together into the same entity.",
        "When there is a mismatch, however, it does not necessarily indicate that the two NPs are non-coreferential, so we leave the distance between the NPs unchanged.",
        "Conversely, there are some features where a mismatch would indicate that the two NPs are absolutely non-compatible and will definitely not refer to the same entity.",
        "The DISTANCE, GENDER, NUMBER, SEMANTIC, PROPER NAME, PRONOUN and EDIT _DISTANCE functions return a positive value when the two phrases mismatch on that particular feature.",
        "A positive value results in a greater distance between two phrases, which makes it less likely for them to be clustered together."
      ]
    },
    {
      "heading": "4.3 Clustering Algorithm",
      "text": [
        "Most of the previous work in clustering-based noun phrase coreference resolution has centered around the use of bottom-up clustering methods, where each noun phrase is initially assigned to a singleton cluster by itself, and clusters which are “close enough” to each other are merged (Cardie & Wagstaff, 1999; Angheluta et al., 2004).",
        "In our system, we use a method called modified k-means clustering (Wilpon & Rabiner 1985), which takes the opposite approach and uses a top-down approach to split clusters, interleaved with a k-means iterative phase.",
        "Modified k-means clustering has been successfully applied to speech recognition and it has the advantage of always being able to come to the optimal clustering (i.e. it is not dependent upon the starting state or merging order).",
        "Modified k-means starts off with all the instances in one big cluster.",
        "The system then iteratively performs the following steps:",
        "1.",
        "For each cluster, find its centroid, defined as the instance which is the closest to all other instances in the same cluster.",
        "2.",
        "For each instance: a.",
        "Calculate its distance to all the centroids.",
        "b.",
        "Find the centroid with the minimum distance, and join its cluster.",
        "3.",
        "Iterate 1-2 until instances stop moving between clusters.",
        "4.",
        "Find the cluster with the largest intra-cluster distance.",
        "(Call this Clustermax and its centroid, Centroidmax.)",
        "If this distance is smaller than some threshold r, stop.",
        "5.",
        "From the instances inside Clustermax, find the pair that are the furthest apart from each other.",
        "a.",
        "Add the pair of instances to the list of centroids and remove Centroidmax from the list.",
        "b. Repeat from Step 2.",
        "The algorithm thus alternates traditional k-means clustering with a step that adds new clusters to the pool of existing ones.",
        "Used for coreference resolution, it splits up the instances into clusters in which the instances are more similar to each other than to instances in other clusters.",
        "The only thing left to do is to determine a suitable threshold.",
        "As functions that check for compatibility return negative values while positive distances indicate incompatibility, a threshold of 0 would separate compatible and incompatible",
        "elements.",
        "However, since the feature extraction will not be totally accurate, (especially for the GENDER and NUMBER features which test for incompatibility) we chose to be more lenient with deciding whether two phrases should be clustered together, and used a threshold of r = 1 to allow for possible errors."
      ]
    },
    {
      "heading": "5 Evaluation",
      "text": [
        "Evaluation of coreference resolution systems has traditionally been performed with precision and recall.",
        "The MUC competition defines recall as follows (Vilain et al., 1995):",
        "phrases which we know refer to the same entity), and p(C;) is the partitioning of C; by the automatically-generated clusters.",
        "For precision, the role of the automatic and gold standard clusters are reversed.",
        "Our results were evaluated using the MUC scoring program which reports recall, precision and F-measure, where the F-measure is defined as the harmonic mean of precision and recall:",
        "Table 3 presents the results of our coreference resolution system on the outputs of both the parsing-based and heuristic-based entity detection systems, as measured by the MUC-7 scoring program.",
        "For the purposes of comparison, we also present results of our clustering algorithm on the gold standard entities.",
        "This gives us a sense of the upper bound that we could potentially achieve if we got 100% accuracy on our mention detection phase.",
        "An additional baseline is generated by implementing a system that assumes that all phrases refer to the same entity – i.e. it takes all the heuristically-generated phrases and puts them into one big cluster.",
        "This gives us an upper bound on the recall of the system.",
        "Yet another baseline, to see how easy the task is, is to merge mentions together if the “Noun Phrase Match” function tests true.",
        "From the results, it can be seen that our system achieves a performance gain of over 10 F-Measure points over the simplest baseline, and over 8 F-Measure points over the more sophisticated baseline.",
        "Unfortunately, due to corpus differences, we cannot conduct a comparison with results found in previous work.",
        "An interesting observation is the fact that the heuristic-based entity recognizer achieves better performance than the one based on statistical parsing.",
        "The parser is trained on the Chinese Penn Treebank, which tends to have relatively longer noun phrases, and as result, the phrases generated by the parser also tend to be on the long side.",
        "This causes errors at the entity recognition phase, which results in a performance hit for the overall system."
      ]
    },
    {
      "heading": "6 Analysis",
      "text": [
        "One interesting question to ask about the results is the contribution of any given individual feature to the result of the overall system.",
        "We have already investigated the effect of entity recognition, and in this section, we take a look at the features for the clustering algorithm.",
        "Error!",
        "Reference source not found.",
        "presents the results of a series of experiments in which one feature at a time was removed from the clustering algorithm.",
        "The last entry in the table shows the results of the full system; the drop in performance when a feature is removed is indicative of its contribution.",
        "Judging from the results, the 3 features that contribute the most to performance are the NOUN PHRASE MATCH, SEMANTIC AGREEMENT and EDIT DISTANCE fe atures.",
        "Two out of the three, NOUN PHRASE and EDIT DISTANCE, operate on lexical information.",
        "The importance of string matching to coreference resolution is consistent with findings in previous work (Yang et al.",
        "2004), which arrived at the same conclusion for English.",
        "In addition, we note that the two Chinese-specific features that were introduced, ABBREVIATION and EDIT DISTANCE, both contribute significantly (as measured by a student’s t-test) to the performance of the final system.",
        "Of our features, those that contribute the least to the overall performance are the GENDER, NUMBER and DEMONSTRATIVE NOUN PHRASE features.",
        "For DEMONSTRATIVE NOUN PHRASE, the reason is because of data sparsity – there are just simply not enough examples that it would make any significant impact.",
        "For the GENDER and NUMBER features, we find that the problem is mostly with errors in feature generation.",
        "To our knowledge, this is the first published result on unsupervised Chinese coreference resolution.",
        "Due to differences in data, it is not possible to conduct a comparison of our work with previous results."
      ]
    },
    {
      "heading": "7 Related Work",
      "text": [
        "Coreference resolution has attracted much attention in recent years, especially as a result of the MUC and ACE competitions.",
        "The approaches taken have exhibited a shift from knowledge-based approaches to learning-based approaches.",
        "Many of the learning-based approaches recast coreference resolution as a binary classification task, which, given a pair of NPs, uses a trained classifier to determine whether they are coreferent.",
        "Soon et al.",
        "(2001) used this approach with a 12-feature decision tree based classifier and Ng and Cardie (2002) extended this approach with extra machine learning frameworks and a larger set of features.",
        "Yang et al.",
        "(2004) extended this approach into an NP-cluster based approach, which considers the relationships between phrases and coreferential clusters.",
        "In addition, several unsupervised approaches have been proposed.",
        "Cardie and Wagstaff (1999) recast the problem as a clustering task which applied a set of incompatibility functions and weights in the distance metric.",
        "Bean and Riloff (2004) used information extraction patterns to identify contextual clues that would determine the compatibility between NPs.",
        "All of the previously mentioned work has been for English.",
        "There has been relatively little work in Chinese: Florian et al.",
        "(2004) provides results using a language-independent framework on the Entity Detection and Tracking task (EDT).",
        "They formulate the detection subtask as a classification problem using a Robust Risk Minimization classifier combined with a Maximum Entropy classifier.",
        "Their system performs significantly well on English, Chinese and Arabic, however, the system suffers from small amount of training data (90K characters for Chinese, in contrast with 340K words for English).",
        "Their system obtained an ACE value of 58.8 on the ACE evaluation data on Chinese.",
        "Finally, Zhou et al.",
        "(2005) proposed a unified Transformation-Based Learning framework on Chinese EDT.",
        "The TBL tracking model looks at pairs of NPs at a time and classifies them as being coreferent or not based on the values of six features.",
        "They report an ACE score of 63.3 on their dataset."
      ]
    },
    {
      "heading": "8 Conclusions and Future Work",
      "text": [
        "In this paper, we have presented an unsupervised approach to Chinese coreference resolution.",
        "Our approach performs resolution by clustering, with the advantage that no annotated training data is needed.",
        "We evaluated our approach using a corpus which we developed using standard annotation schemes, and find that our system achieves an error reduction rate of almost 30% over the baseline.",
        "We also analyze the performance of our system by investigating the contribution of individual features to our system.",
        "The analysis illus",
        "trates the contribution of the new language-specific features.",
        "While the results produced by our system are impressive, it should be noted that all our features consider only the mention phrase itself.",
        "We consider this to be a rather simplistic and incomplete.",
        "In future work, we plan to investigate the use of more sophisticated features, including contextual features, to improve the performance of our system."
      ]
    }
  ]
}
