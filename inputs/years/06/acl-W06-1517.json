{
  "info": {
    "authors": [
      "Marco Kuhlmann",
      "Mathias Mohl"
    ],
    "book": "International Workshop on Tree Adjoining Grammar and Related Formalisms",
    "id": "acl-W06-1517",
    "title": "Extended Cross-Serial Dependencies in Tree Adjoining Grammars",
    "url": "https://aclweb.org/anthology/W06-1517",
    "year": 2006
  },
  "references": [
    "acl-C88-1001",
    "acl-P01-1018",
    "acl-P06-2066",
    "acl-P92-1012"
  ],
  "sections": [
    {
      "heading": "Abstract",
      "text": [
        "The ability to represent cross-serial dependencies is one of the central features of Tree Adjoining Grammar (TAG).",
        "The class of dependency structures representable by lexicalized TAG derivations can be captured by two graph-theoretic properties: a bound on the gap degree of the structures, and a constraint called well-nestedness.",
        "In this paper, we compare formalisms from two strands of extensions to TAG in the context of the question, how they behave with respect to these constraints.",
        "In particular, we show that multicomponent TAG does not necessarily retain the well-nestedness constraint, while this constraint is inherent to Coupled Context-Free Grammar (Hotz and Pitsch, 1996)."
      ]
    },
    {
      "heading": "1 Introduction",
      "text": [
        "The ability to assign ‘limited cross-serial dependencies’ to the words in a sentence is a hallmark of mildly context-sensitive grammar formalisms (Joshi, 1985).",
        "In the case of TAG, an exact definition of this ability can be given in terms of two graph-theoretic properties of the dependency structures induced by TAG derivations: the gap degree restriction and the well-nestedness constraint (Bodirsky et al., 2005).",
        "Gap degree and well-nestedness can be seen as the formal correspondents of what Joshi (1985) refers to as ‘a limited amount of cross-serial dependencies’ and ‘the nesting properties as in the case of context-free grammars.’ More specifically, the gap degree of a dependency structure counts the number of discontinuities in a dependency subtree, while well-nestedness constrains the positions of disjoint subtrees relative to one another.",
        "The dependency structures that correspond to the derivations in a lexicalized TAG are well-nested, and their gap degree is at most 1.",
        "In the present paper, we compare formalisms from two strands of extensions to TAG in the context of the question, what classes of dependency structures they are able to induce.",
        "We are particularly interested in formalisms that induce only well-nested dependency structures.",
        "This interest is motivated by two observations: First, well-nestedness is interesting as a generalization of projectivity (Marcus, 1967) – while more than 23% of the 73 088 dependency structures in the Prague Dependency Treebank of Czech (Ha-ji�c et al., 2001) are non-projective, only 0.11% are not well-nested (Kuhlmann and Nivre, 2006).",
        "Second, well-nestedness is interesting for processing.",
        "Specifically, parsers for well-nested grammar formalisms are not confronted with the ‘crossing configurations’ that make the universal recognition problem of Linear Context-Free Rewriting Systems NP-complete (Satta, 1992).",
        "In summary, it appears that well-nestedness can strike a successful balance between empirical coverage and computational tractability.",
        "If this is true, then a formalism that has the well-nestedness constraint hardwired is preferable over one that has not.",
        "The results of this paper can be summarized as follows: Derivations in lexicalized multicomponent TAGs (Weir, 1988; Kallmeyer, 2005), in which a single adjunction adds a set of elementary trees, either induce exactly the same dependency structures as TAG, or induce all structures of bounded gap degree, even non-well-nested ones.",
        "This depends on the decision whether one takes ‘lexicalized’ to mean ‘one lexical anchor per tree’, or ‘one lexical anchor per tree set’.",
        "In contrast, multi-foot extensions of TAG (Abe, 1988; Hotz and Pitsch, 1996), where a single elementary tree may have more than one foot node, only induce well-nested dependency structures of bounded gap degree.",
        "Thus, from the dependency point of view, they constitute the structurally more conservative extension of TAG.",
        "Proceedings of the 8th International Workshop on Tree Adjoining Grammar and Related Formalisms, pages 121–126, Sydney, July 2006. c�2006 Association for Computational Linguistics",
        "We start with a presentation of the dependency view on TAG that constitutes the basis for our work, and introduce the relevant terminology.",
        "The main objective of this section is to provide intuitions; for the formal details, see Bodirsky et al.",
        "(2005)."
      ]
    },
    {
      "heading": "2.1 The dependency view on TAG",
      "text": [
        "Lets _ w1 • • • wn be a sentence (a sequence of tokens).",
        "By a dependency structure for s, we mean a tuple (W, -->, -<), where W _ { w 1, ... , wn }, and -->_ { (wi, wj) E W x W jI wj depends on wi } -<_ {(wi,wj)EWxWji<j} To interpret a grammar formalism as a specification for a set of dependency structures, we need to assign meaning to the relation ‘depends’ in terms of this formalism.",
        "For TAG, this can be done based on the Fundamental Hypothesis that ‘every syntactic dependency is expressed locally within a single elementary tree’ (Frank, 2002).",
        "More specifically, a derivation in a (strongly) lexicalized TAG can be viewed as a dependency structure as follows: The set W contains the (occurences of) lexical anchors involved in the derivation.",
        "For two anchors wi, wj E W, wi --> wj if the elementary tree anchored at wj was substituted or adjoined into the tree anchored at wi.",
        "We then have wi -< wj if wi precedes wj in the yield of the derived tree corresponding to the derivation.",
        "Notice that the relation --> in such a dependency structure is almost exactly the derivation tree of the underlying TAG derivation; the only difference is that elementary trees have been replaced by their lexical anchors.",
        "Figure 1 shows a TAG grammar together with a dependency structure induced by a derivation of this grammar.",
        "Tokens in the derived string are represented by labelled nodes; the solid arcs between the nodes represent the dependencies.",
        "2.2 Gap degree and well-nestedness An interesting feature of the dependency structure shown in Figure 1 is that it violates a standard constraint on dependency structures known as pro-jectivity (Marcus, 1967).",
        "We introduce some terminology for non-projective dependency structures: A set T C W is convex, if for no two tokens w1, w2 E T, there exists a token w from W – T such that w1 -< w -< w2.",
        "The cover of T, C(T), is the smallest convex set that contains T. For w E W, we write a w for the set of tokens in the b c d subtree rooted at w (including w itself).",
        "A gap in a w is a largest convex set in C (a w) – a w. The gap degree of w, gd(w), is the number of gaps in a w. The gaps in a w partition a w into gd(w) – 1 largest convex blocks; we write ai w to refer to the i -th of these blocks, counted from left to right (with respect to -<).",
        "The gap degree of a dependency structure is the maximum over the gap degrees of its subtrees; we write Dg for the set of all dependency structures with a gap degree of at most g. The gap degree provides a quantitative measure for the non-projectivity of dependency structures.",
        "Well-nestedness is a qualitative property: it constrains the relative positions of disjoint subtrees.",
        "Let w1, w2 E W such that aw1 and aw2 are disjoint.",
        "Four tokens w i , w21 E a w 1, w12, w2 2 E a w2 interleave, if w i -< w12 -< w i -< w22.A dependency structure is well-nested, if it does not contain interleaving tokens.",
        "We write Dwn for the set of all well-nested dependency structures.",
        "For illustration, consider again the dependency structure shown in Figure 1.",
        "It has gap degree 1: a2 is the only token w for which a w is not convex; the set {b1, c1} forms a gap in aa2.",
        "The structure is also well-nested.",
        "In contrast, the structure shown in the right half of Figure 2 is not well-nested; the tokens b, c, d, e interleave.",
        "Bodirsky et al.",
        "(2005) show that TAG induces precisely the set Dwn n D1 ."
      ]
    },
    {
      "heading": "3 Multicomponent extensions",
      "text": [
        "Multicomponent TAG (MCTAG) extends TAG with the ability to adjoin a whole set of elementary trees (components) simultaneously.",
        "To answer the question, whether this extension also leads to an extended class of dependency structures, we first need to decide how we want to transfer the Fundamental Hypothesis (Frank, 2002) to MCTAGs."
      ]
    },
    {
      "heading": "3.1 One anchor per component",
      "text": [
        "If we commit to the view that each component of a tree set introduces a separate lexical anchor and its syntactic dependencies, the dependency structures induced by MCTAG are exactly the structures induced by TAG.",
        "In particular, each node in the derivation tree, and therefore each token in the dependency tree, corresponds to a single elementary tree.",
        "As Kallmeyer (2005) puts it, one can then consider an MCTAG as a TAG G ‘where certain derivation trees in G are disallowed since they do not satisfy certain constraints.’ The ability of MCTAG to perform multiple adjunctions simultaneously allows one to induce more complex sets of dependency structures – each individual structure is limited as in the case of standard TAG."
      ]
    },
    {
      "heading": "3.2 One anchor per tree set",
      "text": [
        "If, on the other hand, we take a complete tree set as the level on which syntactic dependencies are specified, MCTAGs can induce a larger class of dependency structures.",
        "Under this perspective, tokens in the dependency structure correspond not to individual components, but to tree sets (Weir, 1988).",
        "For each token w, � w then contains the lexical anchors of all the subderivations starting in the tree set corresponding to w. As there can be a gap between each two of these subderivations, the gap degree of the induced dependency structures is bounded only by the maximal number of components per tree set.",
        "At the same time, even non-well-nested structures can be induced; an example is shown in Figure 2.",
        "Here, �b is distributed over the components rooted at B1 and B2, and �c is distributed over C1 and C2.",
        "The elementary tree rooted at A arranges the substitution sites such that b, c, d, e interleave.",
        "Note that the MCTAG used in this example is heavily restricted: it is tree-local and does not even use adjunction.",
        "This restricted form suffices to induce non-well-nested dependency structures."
      ]
    },
    {
      "heading": "4 Multi-foot extensions",
      "text": [
        "A second way to extend TAG, orthogonal to the multicomponent approach, is to allow a single elementary tree to have more than one foot node.",
        "For this kind of extension, the Fundamental Hypothesis does not need to be reinterpreted.",
        "Probably the most prominent multi-foot extension of TAG is Ranked Node Rewriting Grammar (RNRG) (Abe, 1988); however, the properties that we are interested in here can be easier investigated in a notational variant of RNRG, Coupled Context-Free Grammar (Hotz and Pitsch, 1996).",
        "Terminology Multi-foot formalisms require a means to specify which foot node gets what material in an adjunction.",
        "To do so, they use ranked symbols.",
        "A ranked alphabet is a pair 17 = (E, p), where E is an alphabet, and p E E--> N is a total function that assigns every symbol Q E E a (positive) rank.",
        "Define 17Œr� := { � E E I p(a) = r }.",
        "The components of a, comp(a), are the elements of the set { (a, i) I 1 < i < p(a) }.",
        "We write ai instead of (a, i).",
        "Let comp(17) := S�2Hcomp(�)."
      ]
    },
    {
      "heading": "4.1 Coupled Context-Free Grammar",
      "text": [
        "Coupled Context-Free Grammar (CCFG) is a generalization of context-free grammar in which non-terminals come from a ranked alphabet, and components of a non-terminal can only be substituted simultaneously.",
        "The ‘TAG-ness’ of CCFG is reflected in the requirement, that the RHS of productions must be words from a bracket-like language, and thus have the same hierarchical structure as elementary trees in a TAG.",
        "As an example, the second elementary tree from Figure 1 can be linearized as",
        "where each pair (T1, T2) of matching components corresponds to an inner node in the tree, and the boundary between the first and the second part of the tuple marks the position of the foot node.",
        "The required structure of the RHS can be formalized as follows: Definition 1 Let 17 be a ranked alphabet, and let E be an unranked alphabet.",
        "The extended semi-Dyck set over 17 and E, ESD(17, E), is the smallest set that satisfies the following properties:",
        "Definition 2 Let N be a ranked alphabet of nonterminals, and let T be an (unranked) alphabet of terminals.",
        "A ranked rewriting system over ESD(N, T) is a finite, non-empty set of productions of the form X --> (a1, ... , ar), where X E N[r], and a := a1 .",
        ".",
        ".",
        "ar E ESD(N, T).",
        "We write p(p) to refer to the rank of the non-terminal on the LHS of a production p. RNRG and CCFG are notational variants because each RNRG elementary tree with r – 1 foot nodes can be linearized into the RHS of a production X --> (a 1, ... , ar) in a ranked rewriting system, as indicated by the example above.",
        "Definition 3 A coupled context free grammar is a tuple G = (N, T, P, S) where: N is a ranked alphabet of non-terminal symbols; T is an unranked alphabet of terminal symbols; P is a ranked rewriting system over ESD(N, T); S E N[1] is a start symbol.",
        "We say that a CCFG G is an r-CCFG, if the maximal rank among all non-terminals in G is r.",
        "such that u2,.",
        ".",
        ".",
        ", ur E ESD(N, T), and X E N[r].",
        "We say that can be derived from q5 in one step, and write � G , if G contains a production X --> (a 1, ... , ar) .",
        "The string language of G is the set L(G) := {s E T* I S �*G s }.",
        "Based on this definition, the notions of derivation tree and derived tree are defined in the usual way.",
        "In particular, the nodes of the derivation tree are labelled with productions, while the nodes of the corresponding derived tree are labelled with components from comp(17) (inner nodes) and terminal symbols (leaves).",
        "We write (TO, Tb) to refer to a derivation in CCFG: TO stands for the derivation tree, Tb for the corresponding derived tree.",
        "4.2 The dependency view on CCFG A CCFG G is strongly lexicalized, if each production p contains exactly one terminal symbol, written as anchor(p).",
        "Just as in the case of TAG, a strongly lexicalized CCFG G can be interpreted as a dependency grammar: Let (TO, Tb) be a derivation in G. Since G is strongly lexicalized, there is a one-to-one mapping between the nodes of the derivation tree TO (labelled with productions) and the leaves of the derived tree Tb (labelled with terminals); we refer to this mapping by the name fL.",
        "Definition 5 A dependency structure D is induced by a derivation (TO, Tb), written (TO, Tb) �- D, if (a) anchor(p1) --> anchor(p2) in D if and only if p1 --> p2 in TO; (b) anchor(p1) -< anchor(p2) in D if and only if fL(p1) -< fL(p2) in Tb.",
        "We write D(G) for the set of all dependency structures induced by derivations in G. Figure 3 shows a sample CCFG G, a derivation in G, and the dependency structure induced by this derivation."
      ]
    },
    {
      "heading": "4.3 Projections",
      "text": [
        "To reason about the structural properties of the dependency languages induced by CCFGs, we need some additional definitions.",
        "In the following, we use the notation (u : a) to refer to a node u with label a in some given labelled tree.",
        "Let D E D(G) be a dependency structure such that (TO, Tb) �- D, and let (u: p) E TO be a node.",
        "Somewhere in the course of the derivation represented by TO, the p(p) components of the non-terminal on the LHS of the production p are simultaneously rewritten.",
        "Let fI (u) be the p(p)-tuple of nodes in Tb that correspond to these components.",
        "Note that, while fL maps nodes in the derivation tree TO to leaves in the derived tree T b, fI takes nodes in TO to tuples of inner nodes in T b.",
        "Define",
        "The set down(u) contains the lexical anchors in the sub-derivation starting at u.",
        "The set proj(u, i) identifies that part of this sub-derivation that is derived from the i -th component of the non-terminal at the LHS of the production corresponding to u.",
        "For the derivation shown in Figure 3, we have"
      ]
    },
    {
      "heading": "4.4 Results",
      "text": [
        "In this section, we prove the main technical results of this paper: that all dependency structures",
        "Proof Let (T#, Tb) �- D, and let (u: p) E T#.",
        "By definition of proj, for each 1 < i < p(p), the set proj(u, i) forms a contiguous region of the sentence derived by T#.",
        "Using Lemma 6, we then see that down(u) is distributed over at most p(u) contiguous regions of that sentence.",
        "This means that the dependency subtree rooted at anchor(p) has at most p(p) – 1 gaps.",
        "Lemma 8 JO(G) C JOwn Proof Choose a D E JO(G), and assume that D is not well-nested.",
        "Then there is a governor u E D with two distinct dependents v, w such that � v contains tokens v 1, v2, and w contains tokens w1, w2 such that v 1 -< w 1 -< v2 -< w2.",
        "For the derivation (T#, Tb) that induces D, this means that there is a node (u : p) with children (v : p„) and (w : p,,) in T# such that",
        "Since down(v) and down(w) are disjoint; v1 and v2 must come from distinct convex blocks in down(v), and w1 and w2 must come from distinct convex blocks in down(w).",
        "Therefore,",
        "Proof Let D = (W, -->, -<) be a dependency structure from JOwn n JOr_1.",
        "We construct an r-CCFG G = (N, T, P, S) that induces D. For the ranked alphabet N of non-terminals, put N = {N,, I w E W }, �(N,,) = gd(w) + 1.",
        "The set S of start symbols is {NT}, where T is the root of D. For the terminal alphabet, put T = W. The set P consists of I W I productions of the form N,, --> �˛, where w E W, and ˛� is a tuple with arity gd(w) + 1 that contains the terminal w and non-terminal components for all children of w as follows.",
        "Consider the following family of sets: C,, = {{w}}U{ �i v I w --> v, 1 < i < gd(v)+1}.",
        "All sets in C,, are disjoint, and their union equals the set � w. We define a function [•] that interprets the elements of C,, as elements from N U T as follows: [{w}] := w, and [�iv] := Ni„.",
        "Now the RHS of a rule N,, --> ˛� is fully specified by the following equivalences, where C E C,,: [C] occurs in ˛i iff C C �i w [C1] precedes [C2] in ˛� iff C1 x C2 C -< Applied to the dependency structure of Figure 3c, this constructs the given grammar G*.",
        "Note that, due to the well-nestedness of D, the RHS of each rule forms a valid extended semi-Dyck word."
      ]
    },
    {
      "heading": "5 Summary",
      "text": [
        "Starting from the fact that TAG is able to derive well-nested dependency structures with a gap degree of at most 1, we have investigated how multicomponent and multi-foot extensions of TAG alter this expressivity.",
        "Our results are as follows: • For multicomponent TAG, the notion of ‘induced dependency structures’ depends on the assumed notion of lexicalization.",
        "Therefore, either the same structures as in TAG, or arbitrary gap-bounded dependency structures are derivable.",
        "In the former case, MCTAG has the same structural limits as standard TAG; in the latter case, even non-well-nested dependency structures are induced.",
        "• The multi-foot extension CCFG (and its equivalent RNRG) is restricted to well-nested dependency structures, but in contrast to TAG, it can induce structures with any bounded gap degree.",
        "The rank of a grammar is an upper bound on the gap degree of the dependency structures it induces.",
        "Since the extensions inherent to MCTAG and CCFG are orthogonal, it is possible to combine them: Multi-Component Multi-Foot TAG (MMTAG) as described by Chiang (2001) allows to simultaneously adjoin sets of trees, where each tree may have multiple foot nodes.",
        "The structural limitations of the dependency structures inducible by MCTAG and CCFG generalize to MMTAG as one would expect.",
        "As in the case of MCTAG, there are two different understandings of how a dependency structure is induced by an MMTAG.",
        "Under the ‘one anchor per component’ perspective, MMTAG, just like CCFG, derives well-nested structures of bounded gap-degree.",
        "Under the ‘one anchor per tree set’ perspective, just like MCTAG, it also derives non-well-nested gap-bounded structures.",
        "Acknowledgements We thank Jan Schwingham-mer, Guido Tack, and Stefan Thater for fruitful discussions during the preparation of this paper, and three anonymous reviewers for their detailed comments on an earlier version.",
        "The work of Marco Kuhlmann is funded by the Collaborative Research Centre ‘Resource-Adaptive Cognitive Processes’ of the Deutsche Forschungsgemeinschaft."
      ]
    }
  ]
}
