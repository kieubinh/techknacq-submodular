{
  "info": {
    "authors": [
      "Xavier Carreras",
      "Mihai Surdeanu",
      "Lluís Màrquez"
    ],
    "book": "Conference on Computational Natural Language Learning CoNLL",
    "id": "acl-W06-2925",
    "title": "Projective Dependency Parsing With Perceptron",
    "url": "https://aclweb.org/anthology/W06-2925",
    "year": 2006
  },
  "references": [
    "acl-C96-1058",
    "acl-P05-1012",
    "acl-W02-1001",
    "acl-W06-2920"
  ],
  "sections": [
    {
      "heading": "Abstract",
      "text": [
        "We describe an online learning dependency parser for the CoNLL-X Shared Task, based on the bottom-up projective algorithm of Eisner (2000).",
        "We experiment with a large feature set that models: the tokens involved in dependencies and their immediate context, the surface-text distance between tokens, and the syntactic context dominated by each dependency.",
        "In experiments, the treatment of multilingual information was totally blind."
      ]
    },
    {
      "heading": "1 Introduction",
      "text": [
        "We describe a learning system for the CoNLL-X Shared Task on multilingual dependency parsing (Buchholz et al., 2006), for 13 different languages.",
        "Our system is a bottom-up projective dependency parser, based on the cubic-time algorithm by Eisner (1996; 2000).",
        "The parser uses a learning function that scores all possible labeled dependencies.",
        "This function is trained globally with online Perceptron, by parsing training sentences and correcting its parameters based on the parsing mistakes.",
        "The features used to score, while based on the previous work in dependency parsing (McDonald et al., 2005), introduce some novel concepts such as better codification of context and surface distances, and runtime information from dependencies previously parsed.",
        "Regarding experimentation, the treatment of multilingual data has been totally blind, with no special processing or features that depend on the language.",
        "Considering its simplicity, our system achieves moderate but encouraging results, with an overall labeled attachment accuracy of 74.72% on the CoNLL-X test set."
      ]
    },
    {
      "heading": "2 Parsing and Learning Algorithms",
      "text": [
        "This section describes the three main components of the dependency parsing: the parsing model, the parsing algorithm, and the learning algorithm."
      ]
    },
    {
      "heading": "2.1 Model",
      "text": [
        "Let 1, ... , L be the dependency labels, defined beforehand.",
        "Let x be a sentence of n words, x1 ... xn.",
        "Finally, let Y(x) be the space of well-formed dependency trees for x.",
        "A dependency tree y E Y(x) is a set of n dependencies of the form [h, m, l], where h is the index of the head word (0 < h < n, where 0 means root), m is the index of the modifier word (1 < m < n), and l is the dependency label (1 < l < L).",
        "Each word of x participates as a modifier in exactly one dependency of y.",
        "Our dependency parser, dp, returns the maximum scored dependency tree for a sentence x:",
        "In the formula, w is the weight vector of the parser, that is, the set of parameters used to score dependencies during the parsing process.",
        "It is formed by a concatenation of L weight vectors, one for each dependency label, w = assume a feature extraction function, 0, that represents an unlabeled dependency [h, m] in a vector of D features.",
        "Each of the wl has D parameters or dimensions, one for each feature.",
        "Thus, the global",
        "Proceedings of the 10th Conference on Computational Natural Language Learning (CoNLL -X), pages 181–185, New York City, June 2006. c�2006 Association for Computational Linguistics weight vector w maintains L x D parameters.",
        "The scoring function is defined as follows: sco([h, m, l], x, y, w) _ O(h, m, x, y) • wl Note that the scoring of a dependency makes use of y, the tree that contains the dependency.",
        "As described next, at scoring time y just contains the dependencies found between h and m."
      ]
    },
    {
      "heading": "2.2 Parsing Algorithm",
      "text": [
        "We use the cubic-time algorithm for dependency parsing proposed by Eisner (1996; 2000).",
        "This parsing algorithm assumes that trees are projective, that is, dependencies never cross in a tree.",
        "While this assumption clearly does not hold in the CoNLL-X data (only Chinese trees are actually 100% projective), we chose this algorithm for simplicity.",
        "As it will be shown, the percentage of non-projective dependencies is not very high, and clearly the error rates we obtain are caused by other major factors.",
        "The parser is a bottom-up dynamic programming algorithm that visits sentence spans of increasing length.",
        "In a given span, from word s to word e, it completes two partial dependency trees that cover all words within the span: one rooted at s and the other rooted at e. This is done in two steps.",
        "First, the optimal dependency structure internal to the span is chosen, by combining partial solutions from internal spans.",
        "This structure is completed with a dependency covering the whole span, in two ways: from s to e, and from e to s. In each case, the scoring function is used to select the dependency label that maximizes the score.",
        "We take advantage of this two-step processing to introduce features for the scoring function that represent some of the internal dependencies of the span (see Section 3 for details).",
        "It has to be noted that the parsing algorithm we use does not score dependencies on top of every possible internal structure.",
        "Thus, by conditioning on features extracted from y we are making the search approximative."
      ]
    },
    {
      "heading": "2.3 Perceptron Learning",
      "text": [
        "As learning algorithm, we use Perceptron tailored for structured scenarios, proposed by Collins (2002).",
        "In recent years, Perceptron has been used in a number of Natural Language Learning works, such as in",
        "partial parsing (Carreras et al., 2005) or even dependency parsing (McDonald et al., 2005).",
        "Perceptron is an online learning algorithm that learns by correcting mistakes made by the parser when visiting training sentences.",
        "The algorithm is extremely simple, and its cost in time and memory is independent from the size of the training corpora.",
        "In terms of efficiency, though, the parsing algorithm must be run at every training sentence.",
        "Our system uses the regular Perceptron working in primal form.",
        "Figure 1 sketches the code.",
        "Given the number of languages and dependency types in the CoNLL-X exercise, we found prohibitive to work with a dual version of Perceptron, that would allow the use of a kernel function to expand features."
      ]
    },
    {
      "heading": "3 Features",
      "text": [
        "The feature extraction function, O(h, m, x, y), represents in a feature vector a dependency from word positions m to h, in the context of a sentence x and a dependency tree y.",
        "As usual in discriminative learning, we work with binary indicator features: if a certain feature is observed in an instance, the value of that feature is 1; otherwise, the value is 0.",
        "For convenience, we describe O as a composition of several base feature extraction functions.",
        "Each extracts a number of disjoint features.",
        "The feature extraction function O(h, m, x, y) is calculated as:",
        "where Otoken extracts context-independent token features, Otctx computes context-based token features, Odep computes context-independent depen",
        "T,,//able 2: Dependency features, both context-independent (Ode,) and context-based (�d�tx), between two points i and j, i < j. dir - dependency direction: left to right or right to left.",
        "dency features, Od�tx extracts contextual dependency features, Odist calculates surface-distance features between the two tokens, and finally, Oruntime computes dynamic features at runtime based on the dependencies previously built for the given interval during the bottom-up parsing.",
        "mmdh m is a shorthand for a triple of numbers: min (h, m), max(h, m) and dh m (a sign indicating the direction, i.e., +1 if m < h, and – 1 otherwise).",
        "We detail the token features in Table 1, the dependency features in Table 2, and the surface-distance features in Table 3.",
        "Most of these features are inspired by previous work in dependency parsing (McDonald et al., 2005; Collins, 1999).",
        "What is impor�dist (x, i, j, dir) foreach(k E (i, j)): dir • cp(xi) • cp(xk) • cp(xj) number of tokens between i and j number of verbs between i and j number of coordinations between i and j number of punctuations signs between i and j",
        "tant for the work presented here is that we construct explicit feature combinations (see above tables) because we configured our linear predictors in primal form, in order to keep training times reasonable.",
        "While the features presented in Tables 1, 2, and 3 are straightforward exploitations of the training data, the runtime features (Oruntime) take a different, and to our knowledge novel in the proposed framework, approach: for a dependency from m to h, they represent the dependencies found between m and h that attach also to h. They are described in detail in Table 4.",
        "As we have noted above, these features are possible because of the parsing scheme, which scores a dependency only after all dependencies spanned by it are scored."
      ]
    },
    {
      "heading": "4 Experiments and Results",
      "text": [
        "We experimented on the 13 languages proposed in the CoNLL-X Shared Task (Hajiˇc et al., 2004; Simov et al., 2005; Simov and Osenova, 2003; Chen et al., 2003; B¨ohmov´a et al., 2003; Kromann, 2003; van der Beek et al., 2002; Brants et al., 2002; Kawata and Bartels, 2000; Afonso et al., 2002; Dˇzeroski et al., 2006; Civit and Marti, 2002; Nilsson et al., 2005; Oflazer et al., 2003; Atalay et al., 2003).",
        "Our approach to deal with many different languages was totally blind: we did not inspect the data to motivate language-specific features or processes.",
        "We did feature filtering based on frequency counts.",
        "Our feature extraction patterns, that exploit both lexicalization and combination, generate millions of feature dimensions, even with small datasets.",
        "Our criterion was to use at most 500,000 different dimensions in each label weight vector.",
        "For each language, we generated all possible features, and then filtered out most of them according to the counts.",
        "Depending on the number of training sentences, our counts cut-offs vary from 3 to 15.",
        "For each language, we held out from training data a portion of sentences (300, 500 or 1000 depending on the total number of sentences) and trained a model for up to 20 epochs in the rest of the data.",
        "We evaluated each model on the held out data for different number of training epochs, and selected the optimum point.",
        "Then, we retrained each model on the whole training set for the selected number of epochs.",
        "Table 5 shows the attachment scores obtained by our system, both unlabeled (UAS) and labeled (LAS).",
        "The first column (GOLD) presents the LAS obtained with a perfect scoring function: the loss in accuracy is related to the projectivity assumption of our parsing algorithm.",
        "Dutch turns out to be the most non-projective language, with a loss in accuracy of 5.44%.",
        "In our opinion, the loss in other languages is relatively small, and is not a major limitation to achieve a high performance in the task.",
        "Our system achieves an overall LAS of 74.72%, with substantial variation from one language to another.",
        "Turkish, Arabic, Dutch, Slovene and Czech turn out to be the most difficult languages for our system, with accuracies below 70%.",
        "The easiest language is clearly Japanese, with a LAS of 88.13%, followed by Chinese, Portuguese, Bulgarian and German, all with LAS above 80%.",
        "Table 6 shows the contribution of base feature extraction functions.",
        "For four languages, we trained models that increasingly incorporate base functions.",
        "It can be shown that all functions contribute to a better score.",
        "Contextual features (03) bring the system to the final order of performance, while distance (04) and runtime (0) features still yield substantial improvements."
      ]
    },
    {
      "heading": "5 Analysis and Conclusions",
      "text": [
        "It is difficult to explain the difference in performance across languages.",
        "Nevertheless, we have identified",
        "04 with 0runt�me.",
        "four generic factors that we believe caused the most errors across all languages: Size of training sets: the relation between the amount of training data and performance is strongly supported in learning theory.",
        "We saw the same relation in this evaluation: for Turkish, Arabic, and Slovene, languages with limited number of training sentences, our system obtains accuracies below 70%.",
        "However, one can not argue that the training size is the only cause of errors: Czech has the largest training set, and our accuracy is also below 70%.",
        "Modeling large distance dependencies: even though we include features to model the distance between two dependency words (Odi,t), our analysis indicates that these features fail to capture all the intricacies that exist in large-distance dependencies.",
        "Table 7 shows that, for the two languages analyzed, the system performance decreases sharply as the distance between dependency tokens increases.",
        "Modeling context: many attachment decisions, e.g. prepositional attachment, depend on additional context outside of the two dependency tokens.",
        "To address this issue, we have included in our model features to capture context, both static (�d�t� and �t�t�) and dynamic (�runtime).",
        "Nevertheless, our error analysis indicates that our model is not rich enough to capture the context required to address complex dependencies.",
        "All the top 5 focus words with the majority of errors for Spanish and Portuguese – “y”, “de”, “a”, “en”, and “que” for Spanish, and “em”, “de”, “a”, “e”, and “para” for Portuguese – indicate complex dependencies such as prepositional attachments or coordinations.",
        "Projectivity assumption: Dutch is the language with most crossing dependencies in this evaluation, and the accuracy we obtain is below 70%.",
        "On the Degree of Lexicalization We conclude the error analysis of our model with a look at the degree of lexicalization in our model.",
        "A quick analysis of our model on the test data indicates that only 34.80% of the dependencies for Spanish and 42.94% of the dependencies for Portuguese are fully lexical-ized, i.e. both the head and modifier words appear in the model feature set (see Table 8).",
        "There are two reasons that cause our model to be largely un-lexicalized: (a) in order to keep training times reasonable we performed heavy filtering of all features based on their frequency, which eliminates many lexicalized features from the final model, and (b) due to the small size of most of the training corpora, most lexicalized features simply do not appear in the testing section.",
        "Considering these results, a reasonable question to ask is: how much are we losing because of this lack of lexical information?",
        "We give an approximate answer by analyzing the percentage of fully-lexicalized dependencies that are correctly parsed by our model.",
        "Assuming that our model scales well, the accuracy on fully-lexicalized dependencies is an indication for the gain (or loss) to be had from lexicalization.",
        "Our model parses fully-lexicalized dependencies with an",
        "accuracy of 74.81% LAS for Spanish (2.35% lower than the overall score) and of 83.77% LAS for Portuguese (0.40% higher than the overall score).",
        "This analysis indicates that our model has limited gains (if any) from lexicalization.",
        "In order to improve the quality of our dependency parser we will focus on previously reported issues that can be addressed by a parsing model: large-distance dependencies, better modeling of context, and non-projective parsing algorithms."
      ]
    },
    {
      "heading": "Acknowledgements",
      "text": [
        "This work was partially funded by the European Union Commission (PASCAL - IST-2002-506778) and Spanish Ministry of Science and Technology (TRANGRAM - TIN2004-07925C03-02).",
        "Mihai Surdeanu was supported by a Ramon y Cajal fellowship of the latter institution."
      ]
    }
  ]
}
