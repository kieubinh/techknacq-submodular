{
  "info": {
    "authors": [
      "Guangwei Wang",
      "Kenji Araki"
    ],
    "book": "Human Language Technologies 2007: the Conference of the North American Chapter of the Association for Computational Linguistics; Companion Volume, Short Papers",
    "id": "acl-N07-2048",
    "title": "Modifying SO-PMI for Japanese Weblog Opinion Mining by Using a Balancing Factor and Detecting Neutral Expressions",
    "url": "https://aclweb.org/anthology/N07-2048",
    "year": 2007
  },
  "references": [
    "acl-H05-1043",
    "acl-P02-1053"
  ],
  "sections": [
    {
      "text": [
        "Graduate School of Information Science and Technology",
        "We propose a variation of the SO-PMI algorithm for Japanese, for use in Weblog Opinion Mining.",
        "SO-PMI is an unsupervised approach proposed by Turney that has been shown to work well for English.",
        "We first used the SO-PMI algorithm on Japanese in a way very similar to Turney's original idea.",
        "The result of this trial leaned heavily toward positive opinions.",
        "We then expanded the reference words to be sets of words, tried to introduce a balancing factor and to detect neutral expressions.",
        "After these modifications, we achieved a well-balanced result: both positive and negative accuracy exceeded 70%.",
        "This shows that our proposed approach not only adapted the SO-PMI for Japanese, but also modified it to analyze Japanese opinions more effectively."
      ]
    },
    {
      "heading": "1. Introduction",
      "text": [
        "Recently, more and more websites add information in the form of personal opinions to the Web, e.g. customer reviews of products, forums, discussion groups, and blogs.",
        "Here, we use the term Weblog for these sites.",
        "This type of information is often useful.",
        "However, we have to deal with an enormous amount of unstructured and/or semi-structured data.",
        "These data are subjective, in free format and mostly textual, thus using them is difficult and time consuming.",
        "Therefore, how to mine the Weblog opinions automatically more effectively has attracted more and more attention (Gamon, 2005; Popescu, 2005; Chaovalit, 2005).",
        "Turney (2002) has presented an unsupervised opinion classification algorithm called SO-PMI (Semantic Orientation Using Pointwise Mutual Information).",
        "The main use of SO-PMI is to estimate the semantic orientation (i.e. positive or negative) of a phrase by measuring the hits returned from a search engine of pairs of words or phrases, based on the mutual information theory.",
        "This approach has previously been successfully used on English.",
        "The average accuracy was 74% when evaluated on 410 reviews from Epinions.",
        "However, according to our preliminary experiment, directly translating Turney's original idea into Japanese gave a very slanted result, with a positive accuracy of 95% and a negative accuracy of only 8%.",
        "We found that the balance between the positive and negative sides is influenced greatly by the page hits of reference words/sets, since a search engine is used.",
        "Therefore, we introduced a balancing factor according for the difference in occurrence between positive and negative words.",
        "And then we added several threshold rules to detect neutral expressions.",
        "The proposed approach is evaluated on 200 positive and 200 negative Japanese opinion sentences and yielded a well-balanced result.",
        "In the remainder of this paper, we review the SO-PMI Algorithm in Section 2, then adapt the SO-PMI for Japanese and present the modifications in Section 3.",
        "In section 4, we evaluate and discuss the experimental results.",
        "Section 5 gives concluding remarks."
      ]
    },
    {
      "heading": "2. Details of the SO-PMI Algorithm",
      "text": [
        "The SO-PMI algorithm (Turney, 2002) is used to estimate the semantic orientation (SO) of a phrase by measuring the similarity of pairs of words or phrases using the following formula:",
        "PMI(wordi,word2)=log2 SO(phrase)",
        "The reference words \"excellent\" and \"poor\" are used, thus SO is positive when a phrase is more strongly associated with \"excellent\" and negative when a phrase is more strongly associated with \"poor\".",
        "Let hits(query) be the number of hits returned when using a search engine, the following estimate of SO can be derived from Formula (2) and (1) with some minor algebraic manipulation.",
        "A _ hits(phrase NEAR\"excellent\")*hits(\"poor\") (3)",
        "Turney used AltaVista search engine because it has a NEAR operator.",
        "This operator constrains the search to documents that contain the words within ten words of one another, in either order.",
        "Turney's previous work has shown that NEAR performs better than AND when measuring the strength of semantic association between words."
      ]
    },
    {
      "heading": "3. Our Proposed Approach",
      "text": [
        "The first step of our approach is to extract opinion phrases using word POS (part of speech) templates based on our analysis of opinions in Japanese Weblog and the results of related work (Kobayashi, 2003; Taku, 2002; Wang, 2006).",
        "The second step is to estimate the semantic orientation of the extracted phrases, using the SO-PMI algorithm.",
        "Following Turney's original idea, we first translated the SO formula to the one shown in Formula (4) for Japanese.",
        "We used the Google search engine to get the hits(query) even though Google does not have a NEAR operator.",
        "The AltaVista NEAR operator does not work well for Japanese and Google indexes more",
        "http://www.altavista.com/sites/search/adv http://www.google.co.jp/",
        "pages than AltaVista, thus we used Google and replaced the NEAR operator with the AND operator in the SO formula.",
        "\"t^BL^\" and \"^S\" were selected because they correspond to the English words \"excellent\" and \"poor\".",
        "For testing the performance of this trial, we used 200 positive and 200 negative Japanese opinion sentences which have been labeled by hand.",
        "The results were very slanted.",
        "Many phrases, whether positive or negative in meaning, still received a positive SO.",
        "Some possible causes could be that \"^S (poor)\" has more hits than \"tll; B Lll (excellent)\", as shown in Table 1, and that the AND operator is less useful than the NEAR operator.",
        "In Japanese, there are many expressions when people evaluate something.",
        "For example, \"H (good)\", \"Sl (good)\", (satisfaction)\" , \"t",
        "^BLl (excellent)\" are usually used when someone wants to convey a positive opinion.",
        "Hence we tried to replace the reference words \"excellent\" and \"poor\" with two reference sets: \"p – basic\" and \"n – basic\":",
        "C _ hits(phrase ANDp – basic)*hits(n – basic)",
        "hits(phrase AND n – basic) *hits(p – basic)",
        "\"p-basic\" is a set of common strong positive words in Japanese.",
        "\"n-basic\" is a set of common weak negative words.",
        "The hit counts of these words from Google is shown in Table 1 (All data from 2007/01/12).",
        "The hits(query) was calculated by hits(phrase AND ('VV^ (good)\" OR (like)\") OR \"HV (good)\" OR...).",
        "Table 1: Frequency of p-basic/n-basic words on the Web",
        "We evaluated this modification using the same",
        "(phrase, \"excellent\")",
        "p basic words",
        "Hits (K)",
        "R(%)",
        "n basic words",
        "Hits (li)",
        "R(%)",
        "LUXgood)",
        "372,000",
        "36.83",
        "^ S(poor)",
        "119,000",
        "11.78",
        "»S(Iike)",
        "242,000",
        "23.96",
        "SlXtMd)",
        "110,000",
        "10.89",
        "SlXgood)",
        "211,000",
        "20.89",
        "^SXworry)",
        "83,000",
        "8.22",
        "MA(charm)",
        "150,000",
        "14.85",
        "Ä,#(faull)",
        "77,900",
        "7.71",
        "*»S(favorile)",
        "115,000",
        "11.39",
        "SStUXhord)",
        "77,600",
        "7.68",
        "SSjLlXwant)",
        "115,000",
        "11.39",
        "$l(dislike)",
        "65,000",
        "6.44",
        "SlUHdelighlfu!)",
        "107,000",
        "10.59",
        "M(not good)",
        "37,900",
        "3.75",
        "103,000",
        "1020",
        "ttlHdisIike)",
        "37,100",
        "3.67",
        "fl<(good)",
        "96,900",
        "9.59",
        "7i»(useless)",
        "26,500",
        "2.62",
        "HS(satisfäction)",
        "80,600",
        "7.98",
        "ilXpiiinfu!)",
        "26,500",
        "2.62",
        "iSSlHintere sting)",
        "79,700",
        "7.89",
        "^^(dissatisfaction)",
        "26,100",
        "2.58",
        "^ILlXhappy)",
        "75,500",
        "7.48",
        "^^(dissatisfaction)",
        "22,200",
        "2.20",
        "JttS(Iovely)",
        "74,700",
        "7.40",
        "&3§(worst)",
        "20,700",
        "2.05",
        "O^h-LlXhappy)",
        "59,500",
        "5.89",
        "T«S (fault)",
        "16,600",
        "1.64",
        "fa 4jL-5lXintere sting)",
        "28,400",
        "2.81",
        "&>S M(not good)",
        "15,600",
        "1.54",
        "THbUXexcellenl)",
        "26,000",
        "2.57",
        "Sf LXbad)",
        "10,300",
        "1.02",
        "data as in Section 3.1.",
        "We obtained a slightly better result.",
        "However the SO values were still slanted.",
        "This time many phrases, whether positive or negative in meaning, still received a negative SO.",
        "All of these test results are shown in detail in Section .2.",
        "In the experiments above, we obtained heavily slanted results.",
        "We consider that the large difference in page hits between the positive and negative reference words/sets are the main cause for this phenomenon.",
        "To mitigate this problem, we decided to introduce a balancing factor to adjust the balance between the positive and negative sides.",
        "The SO formula was modified from (5) to (6).",
        "The balancing factor f (a) was calculated by Formula (7).",
        "hits(n – basic) _ The log2 of \"p – basic\" and \"n – basic\" is a factor that adjusts the balance of the similarity of \"p – basic\"/\"n – basic\" and phrases automatically by the hits of'\"p – basic\"/\"n – basic\" itself.",
        "a is a weight value.",
        "We evaluated different values of a from \"0.0\" to \"1.0\" on the benchmark dataset, which is shown in detail in Section .2.",
        "From these preliminary trials, we also found that many neutral phrases often receive positive or negative SO.",
        "Therefore we added detection of neutral expressions.",
        "The idea is that if the phrase is strongly or faintly associated with both \"p – basic\" and \"n – basic\", it is considered a neutral phrase.",
        "Because this means that this phrase has an ambiguous connection with both \"p – basic\" and\"n – basic\".",
        "We use the following rules (Figure 1) to separate neutral phrases from positive/negative phrases.",
        "The threshold values ta, tb and tc are obtained from a small, hand-labeled corpus.",
        "1. hits(phrase ANDp basic) > (a .......... f,____.....",
        "th AND hits(phrase AND n basic) < th",
        "4 Experimental Performance Evaluation 4.1 Gold Standard and Evaluation Metrics",
        "As a gold standard, we collected a benchmark dataset which has 200 positive opinion sentences and 200 negative opinion sentences from the reviews about Electronic Dictionary and MP3 Player products that have been labeled as either positive or negative reviews in \"Kakaku.com\"4.",
        "\"Kakaku.com\" is the largest Japanese Weblog specializing in product comparison of consumer goods, including price and user opinions, etc.",
        "Lots of people exchange miscellaneous product information and reviews.",
        "These reviews are classified as questions, positive reviews, negative reviews, rumors, sale information or \"other\" category.",
        "To classify a sentence as positive (P) or negative (N), the average SO of the phrases in the sentence is used.",
        "If the average SO is P, the sentence is a positive sentence; otherwise it is a negative sentence.",
        "As evaluation metrics, we measured our proposed approach's performance by accuracy.",
        "accuracy was measured as the number of sentences correctly classified as P/N sentences to the total number of P/N sentences in the benchmark dataset (200).",
        "PA means positive accuracy, NA means negative accuracy, i.e. the accuracy on only positive or negative sentences respectively.",
        "First we did the balancing factor experiment to determine the value of \"a\", using the benchmark dataset.",
        "The results are shown in Figure 2.",
        "(a) and (b) show the dashed line indicates average accuracy (74%) on English Data from Turney's Study (2002).",
        "Turney didn't evaluate positive and negative accuracy respectively.",
        "The full drawn line indicates the result after translating the original SO-PMI to Japanese (PA:95%, NA: 8%).",
        "PA series (the line with triangle mark)/NA series (the line with circle mark) when values of \"a\" from \"0.0\" to \"1.0\" were used.",
        "Changing the a tends to be a tradeoff, lowering PA when NA is improved and vice versa.",
        "Therefore, we used Harmonic – Mean by the following formula to find a proper value of \"a\".",
        "Harmonic Mean _",
        "Figure 2, (c) shows PA, NA and Harmonic-Mean curves for different values",
        "j hits( phrase AND p basic) – h",
        "AND n basic) j < tc",
        "(a) Positive Accuracy (PA) (b) Negative Accuracy (NA) (c) Harmonic-Mean ofPA/NA Figure 2: Experiment for a in Balance Factor of \"a\".",
        "We selected the \"a=0.9\" giving the highest Harmonic-Mean value, thus giving a good balance between PA (75%) and NA (70%).",
        "The comparative experiment results between the SO-PMI for Japanese (Test 1), and our modifications (Test 2, 3, 4) are shown in Table 2.",
        "PA: Positive Accuracy NA: Negative Accuracy",
        "In Test 1 and 2, we obtained extreme results, leaning to the positive or negative end, whether using the Turney's original approach or expanding the reference word as \"p – basic\" and \"n – basic\".",
        "In Test 3, we added a balancing factor as described in section 3.2, and obtained a comparatively well-balanced result.",
        "Finally, after adding the neutral expressions detection, we achieved a PA of 78% and NA of 72% (Test 4).",
        "The balance between positive and negative sides was quite improved by contrast with Test 1 and 2."
      ]
    },
    {
      "heading": "5. Conclusions",
      "text": [
        "This study first proposed a modified unsupervised approach (SO-PMI) for Japanese Weblog Opinion Mining.",
        "Some parts of Turney's approach, such as the NEAR operator, does not work for Japanese, thus some modifications must be done.",
        "In a preliminary experiment, the negative accuracy (8%) was very poor while the positive accuracy (95%) was high.",
        "To deal with this phenomenon, we presented three modifications based on the characteristics of",
        "Japanese and the results of related work.",
        "The experiment results (positive accuracy: 78%, negative accuracy: 72%) show that our proposal achieved a considerably improved performance, comparing with directly translating the SO-PMI.",
        "Hence it would be expected that the balancing factor and neutral expressions detection would work effectively also for other reference words or languages.",
        "In the future, we will evaluate different choices of words for the sets ofpositive and negative reference words.",
        "We also plan to appraise our proposal on other languages.",
        "Test Content",
        "PA(%)",
        "NA(%)",
        "Test 1",
        "Naive translation of Tumey's Approach for Japanese",
        "95",
        "8",
        "Test 2",
        "Modification 1 : Two Reference Sets",
        "12",
        "99",
        "Test 3",
        "Test 2 4 Modification 2: Balancing Factor I Œ = 0.9J",
        "75",
        "70",
        "Test 4",
        "Test 3 4 Modification 3: Neutral Phrase Detection",
        "78",
        "72"
      ]
    }
  ]
}
