{
  "info": {
    "authors": [
      "Jing Jiang",
      "ChengXiang Zhai"
    ],
    "book": "45th Annual Meeting of the Association of Computational Linguistics",
    "id": "acl-P07-1034",
    "title": "Instance Weighting for Domain Adaptation in NLP",
    "url": "https://aclweb.org/anthology/P07-1034",
    "year": 2007
  },
  "references": [
    "acl-N03-1027",
    "acl-N04-1001",
    "acl-W04-3237",
    "acl-W04-3238",
    "acl-W06-1615"
  ],
  "sections": [
    {
      "text": [
        "Jing Jiang and ChengXiang Zhai",
        "Domain adaptation is an important problem in natural language processing (NLP) due to the lack of labeled data in novel domains.",
        "In this paper, we study the domain adaptation problem from the instance weighting perspective.",
        "We formally analyze and characterize the domain adaptation problem from a distributional view, and show that there are two distinct needs for adaptation, corresponding to the different distributions of instances and classification functions in the source and the target domains.",
        "We then propose a general instance weighting framework for domain adaptation.",
        "Our empirical results on three NLP tasks show that incorporating and exploiting more information from the target domain through instance weighting is effective."
      ]
    },
    {
      "heading": "1. Introduction",
      "text": [
        "Many natural language processing (NLP) problems such as part-of-speech (POS) tagging, named entity (NE) recognition, relation extraction, and semantic role labeling, are currently solved by supervised learning from manually labeled data.",
        "A bottleneck problem with this supervised learning approach is the lack of annotated data.",
        "As a special case, we often face the situation where we have a sufficient amount of labeled data in one domain, but have little or no labeled data in another related domain which we are interested in.",
        "We thus face the domain adaptation problem.",
        "Following (Blitzer et al., 2006), we call the first the source domain, and the second the target domain.",
        "The domain adaptation problem is commonly encountered in NLP.",
        "For example, in POS tagging, the source domain may be tagged WSJ articles, and the target domain may be scientiic literature that contains scientific terminology.",
        "In NE recognition, the source domain may be annotated news articles, and the target domain may be personal blogs.",
        "Another example is personalized spam filtering, where we may have many labeled spam and ham emails from publicly available sources, but we need to adapt the learned spam filter to an individual user's inbox because the user has her own, and presumably very different, distribution of emails and notion of spams.",
        "Despite the importance of domain adaptation in NLP, currently there are no standard methods for solving this problem.",
        "An immediate possible solution is semi-supervised learning, where we simply treat the target instances as unlabeled data but do not distinguish the two domains.",
        "However, given that the source data and the target data are from different distributions, we should expect to do better by exploiting the domain difference.",
        "Recently there have been some studies addressing domain adaptation from different perspectives (Roark and Bacchi-ani, 2003; Chelba and Acero, 2004; Florian et al., 2004; Daumé III and Marcu, 2006; Blitzer et al., 2006).",
        "However, there have not been many studies that focus on the difference between the instance distributions in the two domains.",
        "A detailed discussion on related work is given in Section 5.",
        "In this paper, we study the domain adaptation problem from the instance weighting perspective.",
        "In general, the domain adaptation problem arises when the source instances and the target instances are from two different, but related distributions.",
        "We formally analyze and characterize the domain adaptation problem from this distributional view.",
        "Such an analysis reveals that there are two distinct needs for adaptation, corresponding to the different distributions of instances and the different classification functions in the source and the target domains.",
        "Based on this analysis, we propose a general instance weighting method for domain adaptation, which can be regarded as a generalization of an existing approach to semi-supervised learning.",
        "The proposed method implements several adaptation heuristics with a unified objective function: (1) removing misleading training instances in the source domain; (2) assigning more weights to labeled target instances than labeled source instances; (3) augmenting training instances with target instances with predicted labels.",
        "We evaluated the proposed method with three adaptation problems in NLP, including POS tagging, NE type classification, and spam filtering.",
        "The results show that regular semi-supervised and supervised learning methods do not perform as well as our new method, which explicitly captures domain difference.",
        "Our results also show that incorporating and exploiting more information from the target domain is much more useful for improving performance than excluding misleading training examples from the source domain.",
        "The rest of the paper is organized as follows.",
        "In Section 2, we formally analyze the domain adaptation problem and distinguish two types of adaptation.",
        "In Section 3, we then propose a general instance weighting framework for domain adaptation.",
        "In Section 4, we present the experiment results.",
        "Finally, we compare our framework with related work in Section 5 before we conclude in Section 6."
      ]
    },
    {
      "heading": "2. Domain Adaptation",
      "text": [
        "In this section, we define and analyze domain adaptation from a theoretical point of view.",
        "We show that the need for domain adaptation arises from two factors, and the solutions are different for each factor.",
        "We restrict our attention to those NLP tasks that can be cast into multiclass classification problems, and we only consider discriminative models for classification.",
        "Since both are common practice in NLP, our analysis is applicable to many NLP tasks.",
        "Let X be a feature space we choose to represent the observed instances, and let Y be the set of class labels.",
        "In the standard supervised learning setting, we are given a set of labeled instances {(xi ,yi)}f=i, where xi £ X, yi £ Y, and (xi,yi) are drawn from an unknown joint distribution p(x, y).",
        "Our goal is to recover this unknown distribution so that we can predict unlabeled instances drawn from the same distribution.",
        "In discriminative models, we are only concerned with p(y\\x).",
        "Following the maximum likelihood estimation framework, we start with a parameterized model family p(y\\x; 0), and then find the best model parameter 0* that maximizes the expected log likelihood of the data:",
        "9* = argmaW p(x,y) logp(y\\x; ff)dx.",
        "Since we do not know the distribution p(x, y), we maximize the empirical log likelihood instead:",
        "= argmax – V\"logp(yt\\xt; 9).",
        "Note that since we use the empirical distribution p(x,y) to approximate p(x,y), the estimated 0* is dependent on p(x, y).",
        "In general, as long as we have sufficient labeled data, this approximation is fine because the unlabeled instances we want to classify are from the same p(x, y).",
        "Let us now turn to the case of domain adaptation where the unlabeled instances we want to classify are from a different distribution than the labeled instances.",
        "Let ps(x,y) and pt(x,y) be the true underlying distributions for the source and the target domains, respectively.",
        "Our general idea is to use ps(x, y) to approximate pt(x, y) so that we can exploit the labeled examples in the source domain.",
        "If we factor p(x,y) into p(x,y) = p(y\\x)p(x), we can see that pt(x, y) can deviate from ps(x, y) in two different ways, corresponding to two different kinds of domain adaptation:",
        "Case 1 (Labeling Adaptation): pt(y\\x) deviates from ps(y\\x) to a certain extent.",
        "In this case, it is clear that our estimation of ps(y\\x) from the labeled source domain instances will not be a good estimation of pt(y\\x), and therefore domain adaptation is needed.",
        "We refer to this kind of adaptation as function/labeling adaptation.",
        "Case 2 (Instance Adaptation): pt(y\\x) is mostly similar to ps(y\\x), butpt(x) deviates from ps(x).",
        "In this case, it may appear that our estimated ps(y\\x) can still be used in the target domain.",
        "However, as we have pointed out, the estimation of ps(y\\x) depends on the empirical distribution ps(x, y), which deviates from pt(x, y) due to the deviation of ps(x) from pt(x).",
        "In general, the estimation of ps(y\\x) would be more influenced by the instances with high ps(x,y) (i.e., high ps(x)).",
        "If pt(x) is very different from ps(x), then we should expect pt(x, y) to be very different from ps(x, y), and therefore different from ps(x, y).",
        "We thus cannot expect the estimated ps(y\\x) to work well on the regions where pt(x, y) is high, but ps(x, y) is low.",
        "Therefore, in this case, we still need domain adaptation, which we refer to as instance adaptation.",
        "Because the need for domain adaptation arises from two different factors, we need different solutions for each factor.",
        "If pt(y\\x) deviates from ps(y\\x) to some extent, we have one of the following choices:",
        "Change of representation:",
        "It may be the case that if we change the representation of the instances, i.e., if we choose a feature space X different from X, we can bridge the gap between the two distributions ps(y\\ x) and pt(y\\x).",
        "For example, consider domain adaptive NE recognition where the source domain contains clean newswire data, while the target domain contains broadcast news data that has been transcribed by automatic speech recognition and lacks capitalization.",
        "Suppose we use a naive NE tagger that only looks at the word itself.",
        "If we consider capitalization, then the instance Bush is represented differently from the instance bush.",
        "In the source domain, ps(y = Person\\x = Bush) is high while ps(y = Person\\x = bush) is low, but in the target domain, pt(y = Person\\x = bush) is high.",
        "If we ignore the capitalization information, then in both domains p( y = Person\\ x = bush) will be high provided that the source domain contains much fewer instances of bush than Bush.",
        "Adaptation through prior:",
        "When we use a parameterized model p(y\\x; 0) to approximate p(y\\x) and estimate 0 based on the source domain data, we can place some prior on the model parameter 0 so that the estimated distribution p(y\\x; 0) will be closer to pt(y\\x).",
        "Consider again the NE tagging example.",
        "If we use capitalization as a feature, in the source domain where capitalization information is available, this feature will be given a large weight in the learned model because it is very useful.",
        "If we place a prior on the weight for this feature so that a large weight will be penalized, then we can prevent the learned model from relying too much on this domain specific feature.",
        "Instance pruning:",
        "If we know the instances x for which pt(y\\x) is different from ps (y \\ x), we can actively remove these instances from the training data because they are \"misleading\".",
        "For all the three solutions given above, we need either some prior knowledge about the target domain, or some labeled target domain instances; from only the unlabeled target domain instances, we would not know where and why pt(y\\x) differs from",
        "ps(y\\x).",
        "In the case where pt(y\\x) is similar to ps(y\\x), but pt(x) deviates from ps(x), we may use the (unla-beled) target domain instances to bias the estimate of ps (x) toward a better approximation of pt(x), and thus achieve domain adaptation.",
        "We explain the idea below.",
        "Our goal is to obtain a good estimate of 0$ that is optimized according to the target domain distribution pt(x, y).",
        "The exact objective function is thus",
        "= argmax/ pt{x) £ P(y \\ x) log p(y | X;0)dx.",
        "Our idea of domain adaptation is to exploit the labeled instances in the source domain to help obtain",
        "Let Ds = {(xs, ys)}i=1 denote the set of labeled instances we have from the source domain.",
        "Assume that we have a (small) set of labeled and a (large) set of unlabeled instances from the target domain, denoted by Dt,i = {(xj\\yf and D>t,u = {x^}^\", respectively.",
        "We now show three ways to approximate the objective function above, corresponding to using three different sets of instances to approximate the instance space X.",
        "Using Ds:",
        "Using ps(y\\x) to approximate pt(y\\x), we obtain",
        "Here we use only the labeled instances in Ds but we adjust the weight of each instance by p4xy.",
        "The major difficulty is how to accurately estimate pPtjX) ■ Using Vt,i:",
        "Note that this is the standard supervised learning method using only the small amount of labeled target instances.",
        "The major weakness of this approximation is that when Ntil is very small, the estimation is not accurate.",
        "Using Vt,u:",
        "The challenge here is that pt(y\\xtllu; 9) is unknown to us, thus we need to estimate it.",
        "One possibility is to approximate it with a model 9 learned from Ds and Vtil.",
        "For example, we can set pt(y\\x,9) = p(y\\x; 9).",
        "Alternatively, we can also set pt(y\\x, 9) to 1 if y = arg maxy, p(y'\\x; 9) and 0 otherwise."
      ]
    },
    {
      "heading": "3. A Framework of Instance Weighting for Domain Adaptation",
      "text": [
        "The theoretical analysis we give in Section 2 suggests that one way to solve the domain adaptation problem is through instance weighting.",
        "We propose a framework that incorporates instance pruning in Section 2.2 and the three approximations in Section 2.3.",
        "Before we show the formal framework, we first introduce some weighting parameters and explain the intuitions behind these parameters.",
        "First, for each (xs, ys) £ Ds, we introduce a parameter ai to indicate how likely pt(y's\\xs) is close to ps(ys\\xs).",
        "Large ai means the two probabilities are close, and therefore we can trust the labeled instance (xs,ys) for the purpose of learning a classifier for the target domain.",
        "Small ai means these two probabilities are very different, and therefore we should probably discard the instance (xs, ys) in the learning process.",
        "Second, again for each (xs,ys) £ Ds, we introduce another parameter [3i that ideally is equal to PS^1)).",
        "From the approximation in Section 2.3 that uses only Ds, it is clear that such a parameter is useful.",
        "Next, for each xtu £ Vt>u, and for each possible label y £ Y, we introduce a parameter Yi(y) that indicates how likely we would like to assign y as a tentative label to xti'u and include (xti'u, y) as a training example.",
        "Finally, we introduce three global parameters As, \\til and \\tu that are not instance-specific but are associated with Ds, Vt l and Dt u, respectively.",
        "These three parameters allow us to control the contribution of each of the three approximation methods in Section 2.3 when we linearly combine them together.",
        "We now formally define our instance weighting framework.",
        "Given Ds, Dt; l and Dtuu, to learn a classifier for the target domain, we find a parameter 9 that optimizes the following objective function:",
        "Eyey 7k(y), and As + At , i + Xt,u = 1.",
        "The last term, log p(9), is the log of a Gaussian prior distribution of 9, commonly used to regularize the complexity of the model.",
        "In general, we do not know the optimal values of these parameters for the target domain.",
        "Nevertheless, the intuitions behind these parameters serve as guidelines for us to design heuristics to set these parameters.",
        "In the rest of this section, we introduce several heuristics that we used in our experiments to set these parameters.",
        "Following the intuition that if pt(y\\x) differs much from ps(y\\x), then (x, y) should be discarded from the training set, we use the following heuristic to set as.",
        "First, with standard supervised learning, we train a model 9ttl from Dtt l. We consider p(y\\x; 9ttl) to be a crude approximation of pt(y\\x).",
        "Then, we classify {x^^ using 9t11.",
        "The top k instances that are incorrectly predicted by 9t,l (ranked by their prediction confidence) are discarded.",
        "In another word, as of the top k instances for which ys = &rgm&xy p(y\\xs; 9t11) are set to 0, and ai of all the other source instances are set to 1.",
        "Accurately setting fi involves accurately estimating ps(x) and pt(x) from the empirical distributions.",
        "For many NLP classification tasks, we do not have a good parametric model for p(x).",
        "We thus need to resort to non-parametric density estimation methods.",
        "However, for many NLP tasks, x resides in a high dimensional space, which makes it hard to apply standard non-parametric density estimation methods.",
        "We have not explored this direction, and in our experiments, we set fi to 1 for all source instances.",
        "Setting 7 is closely related to some semi-supervised learning methods.",
        "One option is to set 7k (y) = p(y\\x\\u; 9).",
        "In this case, 7 is no longer a constant but is a function of 9.",
        "This way of setting 7 corresponds to the entropy minimization semi-supervised learning method (Grandvalet and Bengio, 2005).",
        "Another way to set 7 corresponds to bootstrapping semi-supervised learning.",
        "First, let 9(n\" be a model learned from the previous round of training.",
        "We then select the top k instances from Dt u that have the highest prediction confidence.",
        "For these instances, we set 7k(y) = 1 for y = argmaxy,p(y'\\x\\u; 9(n)), and 7k (y) = 0 for all other y.",
        "In another word, we select the top k confidently predicted instances, and include these instances together with their predicted labels in the training set.",
        "All other instances in Dt; uare not considered.",
        "In our experiments, we only considered this bootstrapping way of setting 7.",
        "As, At,l and Atuu control the balance among the three sets of instances.",
        "Using standard supervised learning, As and At,l are set proportionally to Cs and Ct,l, that is, each instance is weighted the same whether it is in Ds or in Dt; l, and Atuu is set to 0.",
        "Similarly, using standard bootstrapping, At u is set proportionally to Ct u, that is, each target instance added to the training set is also weighted the same as a source instance.",
        "In neither case are the target instances emphasize more than source instances.",
        "However, for domain adaptation, we want to focus more on the target domain instances.",
        "So intuitively, we want to make At l and At u somehow larger relative to As.",
        "As we will show in Section 4, this is indeed beneficial.",
        "In general, the framework provides great flexibility for implementing different adaptation strategies through these instance weighting parameters."
      ]
    },
    {
      "heading": "4. Experiments",
      "text": [
        "We chose three different NLP tasks to evaluate our instance weighting method for domain adaptation.",
        "The first task is POS tagging, for which we used 6166 WSJ sentences from Sections 00 and 01 of Penn Treebank as the source domain data, and 2730 PubMed sentences from the Oncology section of the PennBioIE corpus as the target domain data.",
        "The second task is entity type classification.",
        "The setup is very similar to Daumé III and Marcu (2006).",
        "We assume that the entity boundaries have been correctly identified, and we want to classify the types of the entities.",
        "We used ACE 2005 training data for this task.",
        "For the source domain, we used the newswire collection, which contains 11256 examples, and for the target domains, we used the weblog (WL) collection (5164 examples) and the conversational telephone speech (CTS) collection (4868 examples).",
        "The third task is personalized spam filtering.",
        "We used the ECML/PKDD 2006 discovery challenge data set.",
        "The source domain contains 4000 spam and ham emails from publicly available sources, and the target domains are three individual users' inboxes, each containing 2500 emails.",
        "For each task, we consider two experiment settings.",
        "In the first setting, we assume there are a small number of labeled target instances available.",
        "For POS tagging, we used an additional 300 Oncology sentences as labeled target instances.",
        "For NE typing, we used 500 labeled target instances and 2000 unlabeled target instances for each target domain.",
        "For spam filtering, we used 200 labeled target instances and 1800 unlabeled target instances.",
        "In the second setting, we assume there is no labeled target instance.",
        "We thus used all available target instances for testing in all three tasks.",
        "We used logistic regression as our model of p(y\\x; 9) because it is a robust learning algorithm and widely used.",
        "We now describe three sets of experiments, corresponding to three heuristic ways of setting a, At,l and At u.",
        "In the first set of experiments, we gradually remove \"misleading\" labeled instances from the source domain, using the small number of labeled target instances we have.",
        "We follow the heuristic we described in Section 3.1, which sets the a for the top k misclassified source instances to 0, and the a for all the other source instances to 1.",
        "We also set At l and At l to 0 in order to focus only on the effect of removing \"misleading\" instances.",
        "We compare with a baseline method which uses all source instances with equal weight but no target instances.",
        "The results are shown in Table 1.",
        "From the table, we can see that in most experiments, removing these predicted \"misleading\" examples improved the performance over the baseline.",
        "In some experiments (Oncology, CTS, u00, u01), the largest improvement was achieved when all misclassified source instances were removed.",
        "In the case of weblog NE type classification, however, removing the source instances hurt the performance.",
        "A possible reason for this is that the set of labeled target instances we use is a biased sample from the target domain, and therefore the model trained on these instances is not always a good predictor of \"misleading\" source instances.",
        "The second set of experiments is to add the labeled target domain instances into the training set.",
        "This corresponds to setting At l to some non-zero value, but still keeping At u as 0.",
        "If we ignore the domain difference, then each labeled target instance is weighted the same as a labeled source instance (= ~ij,L), which is what happens in regular supervised learning.",
        "However, based on our theoretical analysis, we can expect the labeled target instances to be more representative of the target domain than the source instances.",
        "We can therefore assign higher weights for the target instances, by adjusting the ratio between At l and As.",
        "In our experiments, we set ji- = a ij^ , where a ranges from 2 to 20.",
        "The results are shown in Table 2.",
        "As shown from the table, adding some labeled target instances can greatly improve the performance for all tasks.",
        "And in almost all cases, weighting the target instances more than the source instances performed better than weighting them equally.",
        "We also tested another setting where we first removed the \"misleading\" source examples as we showed in Section 4.2, and then added the labeled target instances.",
        "The results are shown in the last row of Table 2.",
        "However, although both removing \"misleading\" source instances and adding labeled target instances work well individually, when combined, the performance in most cases is not as good as when no source instances are removed.",
        "We hypothesize that this is because after we added some labeled target instances with large weights, we already gained a good balance between the source data and the target data.",
        "Further removing source instances would push the emphasis more on the set of labeled target instances, which is only a biased sample of the whole target domain.",
        "The POS data set and the CTS data set have previously been used for testing other adaptation methods (Daumé III and Marcu, 2006; Blitzer et al., 2006), though the setup there is different from ours.",
        "Our performance using instance weighting is comparable to their best performance (slightly worse for",
        "POS and better for CTS).",
        "In the third set of experiments, we assume that we do not have any labeled target instances.",
        "We tried two bootstrapping methods.",
        "The first is a standard bootstrapping method, in which we gradually added the most confidently predicted unlabeled target instances with their predicted labels to the training set.",
        "Since we believe that the target instances should in general be given more weight because they better represent the target domain than the source instances, in the second method, we gave the added target instances more weight in the objective function.",
        "In particular, we set \\tu = \\s such that the total contribution of the added target instances is equal to that of all the labeled source instances.",
        "We call this second method the balanced bootstrapping method.",
        "Table 3 shows the results.",
        "As we can see, while bootstrapping can generally improve the performance over the baseline where no unlabeled data is used, the balanced bootstrapping method performed slightly better than the standard bootstrapping method.",
        "This again shows that weighting the target instances more is a right direction to go for domain adaptation."
      ]
    },
    {
      "heading": "5. Related Work",
      "text": [
        "There have been several studies in NLP that address domain adaptation, and most of them need labeled data from both the source domain and the target domain.",
        "Here we highlight a few representative ones.",
        "For generative syntactic parsing, Roark and Bac-chiani (2003) have used the source domain data to construct a Dirichlet prior for MAP estimation of the PCFG for the target domain.",
        "Chelba and Acero (2004) use the parameters of the maximum entropy model learned from the source domain as the means of a Gaussian prior when training a new model on the target data.",
        "Florian et al.",
        "(2004) first train a NE tagger on the source domain, and then use the tagger's predictions as features for training and testing on the target domain.",
        "The only work we are aware of that directly mod-",
        "1 POS",
        "NE Type",
        "Spam 1",
        "k",
        "Oncology",
        "k",
        "CTS",
        "k",
        "WL",
        "k",
        "u00",
        "u01",
        "u02",
        "0",
        "0.8630",
        "0",
        "0.7815",
        "0",
        "0.7045",
        "0",
        "0.6306",
        "0.6950",
        "0.7644",
        "4000",
        "0.8675",
        "800",
        "0.8245",
        "600",
        "0.7070",
        "150",
        "0.6417",
        "0.7078",
        "0.7950",
        "8000",
        "0.8709",
        "1600",
        "0.8640",
        "1200",
        "0.6975",
        "300",
        "0.6611",
        "0.7228",
        "0.8222",
        "12000",
        "0.8713",
        "2400",
        "0.8825",
        "1800",
        "0.6830",
        "450",
        "0.7106",
        "0.7806",
        "0.8239",
        "16000",
        "0.8714",
        "3000",
        "0.8825",
        "2400",
        "0.6795",
        "600",
        "0.7911",
        "0.8322",
        "0.8328",
        "all",
        "0.8720",
        "all",
        "0.8830",
        "all",
        "0.6600",
        "all",
        "0.8106",
        "0.8517",
        "0.8067",
        "| POS",
        "NE Type",
        "Spam 1",
        "method",
        "Oncology",
        "method",
        "CTS",
        "WL",
        "method",
        "u00",
        "u01",
        "u02",
        "Ds only",
        "0.8630",
        "Ds only",
        "0.7815",
        "0.7045",
        "Ds only",
        "0.6306",
        "0.6950",
        "0.7644",
        "Vs + Vt,i Vs + 5Vt,i Vs + 10DMVs + 20Dt,i",
        "0.9349 0.9411 0.9429 0.9443",
        "Vs + Vt,i Vs + 2Vt,i Vs + 5Vt,i Vs + 10DM",
        "0.9340 0.9355 0.9360 0.9355",
        "0.7735 0.7810 0.7820 0.7840",
        "Vs + Vt,i Vs + 2Vt,i Vs + 5Dt,i Vs + 10DM",
        "0.9572 0.9606 0.9628 0.9639",
        "0.9572 0.9600 09611 0.9628",
        "0.9461 0.9533 0.9601 0.9633",
        "V's + 20Dt,i",
        "0.9422",
        "V's + 10DM",
        "0.8950",
        "0.6670",
        "V's + 10Dt , i",
        "0.9717",
        "0.9478",
        "0.9494",
        "Table 3: Accuracy on the target domain without using labeled target instances.",
        "In balanced bootstrapping, more weights are put on the target instances in the objective function than in standard bootstrapping.",
        "els the different distributions in the source and the target domains is by Daumé III and Marcu (2006).",
        "They assume a \"truly source domain\" distribution, a \"truly target domain\" distribution, and a \"general domain\" distribution.",
        "The source (target) domain data is generated from a mixture of the \"truly source (target) domain\" distribution and the \"general domain\" distribution.",
        "In contrast, we do not assume such a mixture model.",
        "None of the above methods would work if there were no labeled target instances.",
        "Indeed, all the above methods do not make use of the unlabeled instances in the target domain.",
        "In contrast, our instance weighting framework allows unlabeled target instances to contribute to the model estimation.",
        "Blitzer et al.",
        "(2006) propose a domain adaptation method that uses the unlabeled target instances to infer a good feature representation, which can be regarded as weighting the features.",
        "In contrast, we weight the instances.",
        "The idea of using to weight instances has been studied in statistics (Shi-modaira, 2000), but has not been applied to NLP tasks."
      ]
    },
    {
      "heading": "6. Conclusions and Future Work",
      "text": [
        "Domain adaptation is a very important problem with applications to many NLP tasks.",
        "In this paper, we formally analyze the domain adaptation problem and propose a general instance weighting framework for domain adaptation.",
        "The framework is flexible to support many different strategies for adaptation.",
        "In particular, it can support adaptation with some target domain labeled instances as well as that without any labeled target instances.",
        "Experiment results on three NLP tasks show that while regular semi-supervised learning methods and supervised learning methods can be applied to domain adaptation without considering domain difference, they do not perform as well as our new method, which explicitly captures domain difference.",
        "Our results also show that incorporating and exploiting more information from the target domain is much more useful than excluding misleading training examples from the source domain.",
        "The framework opens up many interesting future research directions, especially those related to how to more accurately set/estimate those weighting parameters."
      ]
    },
    {
      "heading": "Acknowledgments",
      "text": [
        "This work was in part supported by the National Science Foundation under award numbers 0425852 and 0428472.",
        "We thank the anonymous reviewers for their valuable comments.",
        "POS",
        "NE Type",
        "Spam 1",
        "method",
        "Oncology",
        "CTS",
        "WL",
        "u00",
        "u01",
        "u02",
        "supervised",
        "0.8630",
        "0.7781",
        "0.7351",
        "0.6476",
        "0.6976",
        "0.8068",
        "standard bootstrap",
        "0.8728",
        "0.8917",
        "0.7498",
        "0.8720",
        "0.9212",
        "0.9760",
        "balanced bootstrap",
        "0.8750",
        "0.8923",
        "0.7523",
        "0.8816",
        "0.9256",
        "0.9772"
      ]
    }
  ]
}
