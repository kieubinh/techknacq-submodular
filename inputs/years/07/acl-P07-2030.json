{
  "info": {
    "authors": [
      "Ryuichiro Higashinaka",
      "Kohji Dohsaka",
      "Hideki Isozaki"
    ],
    "book": "45th Annual Meeting of the Association for Computational Linguistics Companion Volume Proceedings of the Demo and Poster Sessions",
    "id": "acl-P07-2030",
    "title": "Learning to Rank Definitions to Generate Quizzes for Interactive Information Presentation",
    "url": "https://aclweb.org/anthology/P07-2030",
    "year": 2007
  },
  "references": [
    "acl-C02-1053",
    "acl-P03-1069"
  ],
  "sections": [
    {
      "text": [
        "Learning to Rank Deinitions to Generate Quizzes for Interactive",
        "Information Presentation",
        "Ryuichiro Higashinaka and Kohji Dohsaka and Hideki Isozaki",
        "NTT Communication Science Laboratories, NTT Corporation",
        "This paper proposes the idea of ranking definitions of a person (a set of biographical facts) to automatically generate \"Who is this?\"",
        "quizzes.",
        "The definitions are ordered according to how difficult they make it to name the person.",
        "Such ranking would enable users to interactively learn about a person through dialogue with a system with improved understanding and lasting motivation, which is useful for educational systems.",
        "In our approach, we train a ranker that learns from data the appropriate ranking of definitions based on features that encode the importance of keywords in a definition as well as its content.",
        "Experimental results show that our approach is significantly better in ranking definitions than baselines that use conventional information retrieval measures such as tf*idf and pointwise mutual information (PMI)."
      ]
    },
    {
      "heading": "1. Introduction",
      "text": [
        "Appropriate ranking of sentences is important, as noted in sentence ordering tasks (Lapata, 2003), in effectively delivering content.",
        "Whether the task is to convey news texts or definitions, the objective is to make it easier for users to understand the content.",
        "However, just conveying it in an encyclopedia-like or temporal order may not be the best solution, considering that interaction between a system and a user improves understanding (Sugiyama et al., 1999) and that the cognitive load in receiving information is believed to correlate with memory fixation (Craik and Lockhart, 1972).",
        "In this paper, we discuss the idea of ranking definitions as a way to present people's biographical information to users, and propose ranking definitions to automatically generate a \"Who is this?\"",
        "quiz.",
        "Here, we use the term 'definitions of a person' to mean a short series of biographical facts (See Fig. 1).",
        "The definitions are ordered according to how difficult they make it to name the person.",
        "The ranking also enables users to easily come up with answer candidates.",
        "The definitions are presented to users one by one as hints until users give the correct name (See Fig. 2).",
        "Although the interaction would take time, we could expect improved understanding of people's biographical information by users through their deliberation and the long lasting motivation afforded by the entertaining nature of quizzes, which is important in tutorial tasks (Baylor and Ryu, 2003).",
        "Previous work on definition ranking has used measures such as tf*idf (Xu et al., 2004) or ranking models trained to encode the likelihood of a definition being good (Xu et al., 2005).",
        "However, such measures/models may not be suitable for quiz-style ranking.",
        "For example, a definition having a strong co-occurrence with a person may not be an easy hint when it is about a very minor detail.",
        "Certain descriptions, such as a person's birthplace, would have to come early so that users can easily start guessing who the person is.",
        "In our approach, we train a ranker that learns from data the appropriate ranking of definitions.",
        "Note that we only focus on the ranking of definitions and not on the interaction with users in this paper.",
        "We also assume that the definitions to be ranked are given.",
        "Section 2 describes the task of ranking definitions, and Section 3 describes our approach.",
        "Section 4 describes our collection of ranking data and the ranking model training using the ranking support vector machine (SVM), and Section 5 presents the evaluation results.",
        "Section 6 summarizes and mentions future work."
      ]
    },
    {
      "heading": "2. Ranking Definitions for Quizzes",
      "text": [
        "Figure 1 shows a list of definitions of Natsume Soseki, a famous Japanese novelist, in their original ranking at the encyclopedic website goo (http://dic-tionary.goo.ne.jp/) and in the quiz-style ranking we aim to achieve.",
        "Such a ranking would realize a dialogue like that in Fig. 2.",
        "At the end of the dialogue, the user would be able to associate the person and the definitions better, and it is expected that some new facts could be learned about that person.",
        "Figure 1: List of definitions of Natsume Soseki, a famous Japanese novelist, in their original ranking in the encyclopedia and in the quiz-style ranking.",
        "The definitions were translated by the authors.",
        "Ranking definitions is closely related to definitional question answering and sentence ordering in multi-document summarization.",
        "In deinitional question answering, measures related to information retrieval (IR), such as tf*idf or pointwise mutual information (PMI), have been used to rank sentences or information nuggets (Xu et al., 2004; Sun et al., 2005).",
        "Such measures are used under the assumption that outstanding/co-occurring keywords about a deiniendum characterize that deiniendum.",
        "However, this assumption may not be appropriate in quizstyle ranking; most content words in the deinitions are already important in the IR sense, and strong cooccurrence may not guarantee high ranks for hints to be presented later because the hint can be too spe-ciic.",
        "An approach to creating a ranking model of deinitions in a supervised manner using machine learning techniques has been reported (Xu et al., 2005).",
        "However, the model is only used to distinguish deinitions from non-deinitions on the basis of features related mainly to linguistic styles.",
        "In multi-document summarization, the focus has been mainly on creating cohesive texts.",
        "(Lapata, 2003) uses the probability of words in adjacent sentences as constraints to maximize the coherence of all sentence-pairs in texts.",
        "Although we acknowledge that having cohesive deinitions is important, since we are not creating a single text and the dialogue that we aim to achieve would involve frequent user/system interaction (Fig.",
        "2), we do not deal with the coherence of deinitions in this paper.",
        "51 Who is this?",
        "First hint: Graduated from the University of Tokyo.",
        "Ul Yoshida Shigeru?",
        "52 No, not even close!",
        "Second hint: Born in Ushigome, Edo.",
        "U2 I don't know.",
        "53 OK. Third hint: Novelist and scholar of British literature.",
        "U3 Murakami Haruki?",
        "54 Close!",
        "Fourth hint: Familiar with Haiku, Chinese poetry, and calligraphy.",
        "55 Very close!",
        "Fifth hint: Published masterpieces in Asahi Shimbun.",
        "Figure 2: Example dialogue based on the quiz-style ranking of deinitions.",
        "S stands for a system utterance and U for a user utterance."
      ]
    },
    {
      "heading": "3. Approach",
      "text": [
        "Since it is dificult to know in advance what characteristics are important for quiz-style ranking, we learn the appropriate ranking of deinitions from data.",
        "The approach is the same as that of (Xu et al., 2005) in that we adopt a machine learning approach for deinition ranking, but is different in that what is learned is a quiz-style ranking of sentences that are already known to be good deinitions.",
        "First, we collect ranking data.",
        "For this purpose, we turn to existing encyclopedias for concise biographies.",
        "Then, we annotate the ranking.",
        "Secondly, we devise a set of features for a deinition.",
        "Since the existence of keywords that have high scores in IR-related measures may suggest easy hints, we incorporate the scores of IR-related measures as features (IR-related features).",
        "Certain words tend to appear before or after others in a biographical document to convey particular information about people (e.g., words describing occupations at the beginning; those describing works at the end, etc.)",
        "Therefore, we use word positions within the biography of the person in question as features (positional features).",
        "Biographies can be found in online resources, such as biography.com (http://www.biography.com/) and Wikipedia.",
        "In addition, to focus on the particular content of the definition, we use bag-of-words (BOW) features, together with semantic features (e.g., semantic categories in Nihongo Goi-Taikei (Ikehara et al., 1997) or word senses in WordNet) to complement the sparseness of BOW features.",
        "We describe the features we created in Section 4.2.",
        "Finally, we create a ranking model using a preference learning algorithm, such as the ranking SVM (Joachims, 2002), which learns ranking by reducing the pairwise ranking error.",
        "Original Ranking:",
        "1.",
        "Novelist and scholar of British literature.",
        "2.",
        "Real name: Kinnosuke.",
        "3.",
        "Born in Ushigome, Edo.",
        "4.",
        "Graduated from the University of Tokyo.",
        "5.",
        "Master of early-modern literature along with Mori Ogai.",
        "6.",
        "After the success of \"I Am a Cat\", quit all teaching jobs and joined",
        "Asahi Shimbun.",
        "7.",
        "Published masterpieces in Asahi Shimbun.",
        "8.",
        "Familiar with Haiku, Chinese poetry, and calligraphy.",
        "9.",
        "Works include \"Botchan\", \"Sanshiro\", etc.",
        "Quiz-style Ranking:",
        "1.",
        "Graduated from the University of Tokyo.",
        "2.",
        "Born in Ushigome, Edo.",
        "3.",
        "Novelist and scholar of British literature.",
        "4.",
        "Familiar with Haiku, Chinese poetry, and calligraphy.",
        "5.",
        "Published masterpieces in Asahi Shimbun.",
        "6.",
        "Real name: Kinnosuke.",
        "7.",
        "Master of early-modern literature along with Mori Ogai.",
        "8.",
        "After the success of \"I Am a Cat\", quit all teaching jobs and joined",
        "Asahi Shimbun.",
        "9.",
        "Works include \"Botchan\", \"Sanshiro\", etc."
      ]
    },
    {
      "heading": "4. Experiment",
      "text": [
        "We collected biographies (in Japanese) from the goo encyclopedia.",
        "We irst mined Wikipedia to calculate the PageRankTMof people using the hyper-link structure.",
        "After sorting them in descending order by the PageRank score, we extracted the top-150 people for whom we could ind an entry in the goo encyclopedia.",
        "Then, 11 annotators annotated rankings for each of the 150 people individually.",
        "The annotators were instructed to rank the deinitions assuming that they were creating a \"who is this?\"",
        "quiz; i.e., to place the deinition that is the most characteristic of the person in question at the end.",
        "The mean of the Kendall's coefficients of concordance for the 150 people was sufficiently high at 0.76 with a standard deviation of 0.13.",
        "Finally, taking the means of ranks given to each deinition, we merged the individual rankings to create the reference rankings.",
        "An example of a reference ranking is the bottom one in Fig. 1.",
        "There are 958 definition sentences in all, with each person having approximately 6-7 definitions.",
        "We derived our IR-related features based on Mainichi newspaper articles (1991-2004) and Wikipedia articles.",
        "We used these two different sources to take into account the difference in the importance of terms depending on the text.",
        "We also used sentences, sections (for Wikipedia articles only) and documents as units to calculate document frequency, which resulted in the creation of five frequency tables: (i) Mainichi-Document, (ii) Mainichi-Sentence, (iii) Wikipedia-Document, (iv) Wikipedia-Section, and (v) Wikipedia-Sentence.",
        "Using the five frequency tables, we calculated, for each content word (nouns, verbs, adjectives, and unknown words) in the deinition, (1) frequency (the number of documents where the word is found), (2) relative frequency (frequency divided by the maximum number of documents), (3) co-occurrence frequency (the number of documents where both the word and the person's name are found), (4) relative co-occurrence frequency, and (5) PMI.",
        "Then, we took the minimum, maximum, and mean values of (1)-(5) for all content words in the deinition as features, deriving 75 (5 x 5 x 3) features.",
        "Then, using the Wikipedia article (called an entry)for theperson in question, we calculated (1)-(4) within the entry, and calculated tf*idf scores of words in the definition using the term frequency in the entry.",
        "Again, by taking the minimum, maximum, and mean values of (1)-(4) and tf*idf, we yielded 15 (5 x 3) features, for a total of 90 (75 + 15) IR-related features.",
        "Positional features were derived also using the Wikipedia entry.",
        "For each word in the deinition, we calculated (a) the number of times the word appears in the entry, (b) the minimum position of the word in the entry, (c) its maximum position, (d) its mean position, and (e) the standard deviation of the positions.",
        "Note that positions are either ordinal or relative; i.e., the relative position is calculated by dividing the ordinal position by the total number of words in the entry.",
        "Then, we took the minimum, maximum, and mean values of (a)-(e) for all content words in the deinition as features, deriving 30 (5 x 2 (ordinal or relative positions) x 3) features.",
        "For the BOW features, we first parsed all our definitions with CaboCha (a Japanese morphological/dependency parser, http://chasen.org/~taku/soft-ware/cabocha/) and extracted all content words to make binary features representing the existence of each content word.",
        "There are 2,156 BOW features in our data.",
        "As for the semantic features, we used the semantic categories in Nihongo Goi-Taikei.",
        "Since there are 2,715 semantic categories, we created 2,715 features representing the existence of each semantic category in the deinition.",
        "Semantic categories were assigned to words in the deinition by a morphological analyzer that comes with ALT/J-E, a Japanese-English machine translation system (Ikehara et al., 1991).",
        "In total, we have 4,991 features to represent each deinition.",
        "We calculated all feature values for all deinitions in our data to be used for the learning.",
        "Using the reference ranking data, we trained a ranking model using the ranking SVM (Joachims, 2002) (with a linear kernel) that minimizes the pairwise ranking error among the deinitions of each person."
      ]
    },
    {
      "heading": "5. Evaluation",
      "text": [
        "To evaluate the performance of the ranking model, compared it with baselines that use only the scores of IR-related and positional features for ranking, i.e., sorting.",
        "Table 1 shows the performance of the ranking model (by the leave-one-out method, predicting the ranking of deinitions of a person by other people's rankings) and that of the 10 best-performing baselines.",
        "The ranking error is pairwise ranking error; i.e., the rate of misordered pairs.",
        "A descriptive name is given for each baseline.",
        "For example, Wikipedia-Sentence-PMI-max means that we used the maximum PMI values of content words in the deinition calculated from Wikipedia, with sentence as the unit for obtaining frequencies.",
        "Our ranking model outperforms all of the baselines.",
        "McNemar's test showed that the difference between the proposed model and the best-performing baseline is significant (p<0.00001).",
        "The results also show that PMI is more effective in quiz-style ranking than any other measure.",
        "The fact that maxis important probably means that the mere existence of a word that has a high PMI score is enough to raise the ranking of a hint.",
        "It is also interesting that Wikipedia gives better ranking, which is probably because people's names and related keywords are close to each other in such descriptive texts.",
        "Analyzing the ranking model trained by the ranking SVM allows us to calculate the weights given to the features (Hirao et al., 2002).",
        "Table 2 shows the top-10 features in weights in absolute igures when all samples were used for training.",
        "It can be seen that high PMI values and words/semantic categories related to government or creation lead to easy hints, whereas semantic categories, such as birth and others (corresponding to the person in 'a person from Tokyo'), lead to early hints.",
        "This supports our intuitive notion that birthplaces should be presented early for users to start thinking about a person."
      ]
    },
    {
      "heading": "6. Summary and Future Work",
      "text": [
        "This paper proposed ranking deinitions of a person to automatically generate a \"Who is this?\"",
        "quiz.",
        "Using reference ranking data that we created manually, we trained a ranking model using a ranking SVM based on features that encode the importance of keywords in a deinition as well as its content.",
        "Feature Name",
        "Wikipedia-Sentence-PMI-max SemCat:33 (others/someone) SemCat:186 (creator) BOW:bakufu (feudal government) SemCat: 163 (sovereign/ruler/monarch) Wikipedia-Document-PMI-max",
        "Wikipedia-Section-PMI-max SemCat:2595 (unit; e.g., numeral classifier) SemCat:2606 (plural; e.g., plural form)",
        "Table 2: Weights of features learned for ranking definitions by the ranking SVM.",
        "SemCat denotes it is a semantic-category feature with its semantic category ID followed by the description of the category in parentheses.",
        "BOW denotes a BOW feature.",
        "Experimental results show that our ranking model signiicantly outperforms baselines that use single IR-related and positional measures for ranking.",
        "We are currently in the process of building a dialogue system that uses the quiz-style ranking for deinition presentation.",
        "We are planning to examine how the different rankings affect the understanding and motivation of users.",
        "Rank",
        "Description",
        "Ranking Error",
        "1",
        "Proposed ranking model",
        "0.185",
        "2",
        "Wikipedia-Sentence-PMI-max",
        "0.299",
        "3",
        "Wikipedia-Section-PMI-max",
        "0.309",
        "4",
        "Wikipedia-Document-PMI-max",
        "0.312",
        "5",
        "Mainichi-Sentence-PMI-max",
        "0.318",
        "6",
        "Mainichi-Document-PMI-max",
        "0.325",
        "7",
        "Mainichi-Sentence-relative-co-occurrence-max 0.338",
        "8",
        "Wikipedia-Entry-ordinal-Min-max",
        "0.338",
        "9",
        "Wikipedia-Sentence-relative-co-occurrence-max 0.339",
        "10",
        "Wikipedia-Entry-relative-Min-max",
        "0.340",
        "11",
        "Wikipedia-Entry-ordinal-Mean-mean",
        "0.342"
      ]
    }
  ]
}
