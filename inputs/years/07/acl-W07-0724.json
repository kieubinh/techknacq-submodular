{
  "info": {
    "authors": [
      "Nicola Ueffing",
      "Michel Simard",
      "Samuel Larkin",
      "Howard Johnson"
    ],
    "book": "Workshop on Statistical Machine Translation",
    "id": "acl-W07-0724",
    "title": "NRC's PORTAGE System for WMT 2007",
    "url": "https://aclweb.org/anthology/W07-0724",
    "year": 2007
  },
  "references": [
    "acl-D07-1103",
    "acl-J93-2003",
    "acl-N03-1017",
    "acl-P03-1021",
    "acl-W06-1607",
    "acl-W06-3110",
    "acl-W06-3118",
    "acl-W07-0728"
  ],
  "sections": [
    {
      "text": [
        "NRC's PORTAGE system for WMT 2007",
        "Nicola Ueffing, Michel Simard, Samuel Larkin Howard Johnson",
        "Interactive Language Technologies Group Interactive Information Group",
        "National Research Council Canada",
        "Gatineau, Quebec, Canada firstname.lastname@nrc.gc.ca",
        "National Research Council Canada Ottawa, Ontario, Canada Howard.Johnson@nrc.gc.ca",
        "We present the PORTAGE statistical machine translation system which participated in the shared task of the ACL 2007 Second Workshop on Statistical Machine Translation.",
        "The focus of this description is on improvements which were incorporated into the system over the last year.",
        "These include adapted language models, phrase table pruning, an IBMl-based decoder feature, and rescor-ing with posterior probabilities."
      ]
    },
    {
      "heading": "1. Introduction",
      "text": [
        "The statistical machine translation (SMT) system PORTAGE was developed at the National Research Council Canada and has recently been made available to Canadian universities and research institutions.",
        "It is a state-of-the-art phrase-based SMT system.",
        "We will shortly describe its basics in this paper and then highlight the new methods which we incorporated since our participation in the WMT 2006 shared task.",
        "These include new scoring methods for phrase pairs, pruning of phrase tables based on significance, a higher-order language model, adapted language models, and several new decoder and rescoring models.",
        "PORTAGE was also used in a joint system developed in cooperation with Systran.",
        "The interested reader is referred to (Simard et al., 2007).",
        "Throughout this paper, let sJ := 8\\ ... sJ denote a source sentence of length J, t[ := t\\... tja target sentence of length I, and s and t phrases in source and target language, respectively."
      ]
    },
    {
      "heading": "2. Baseline",
      "text": [
        "As baseline for our experiments, we used a version of PORTAGE corresponding to its state at the time of the WMT 2006 shared task.",
        "We provide a basic description of this system here; for more details see (Johnson et al., 2006).",
        "PORTAGE implements a two-stage translation process: First, the decoder generates N-best lists, using a basic set of models which are then rescored with additional models in a second step.",
        "In the baseline system, the decoder uses the following models (or feature functions):",
        "• one or several phrase table(s), which model the translation direction p(s 11).",
        "They are generated from the training corpus via the \"diag-and\" method (Koehn et al., 2003) and smoothed using Kneser-Ney smoothing (Foster et al., 2006),",
        "• one or several n-gram language model(s) trained with the SRILM toolkit (Stolcke, 2002); in the baseline experiments reported here, we used a trigram model,",
        "• a distortion model which assigns a penalty based on the number of source words which are skipped when generating a new target phrase,",
        "• a word penalty.",
        "These different models are combined log-linearly.",
        "Their weights are optimized w.r.t.",
        "BLEU score using the algorithm described in (Och, 2003).",
        "This is done on the provided development corpus.",
        "The search algorithm implemented in the decoder is a dynamic-programming beam-search algorithm.",
        "After the decoding step, rescoring with additional models is performed.",
        "The baseline system generates a l,000-best list of alternative translations for each source sentence.",
        "These lists are rescored with the different models described above, a character penalty, and three different features based on IBM Models l and 2 (Brown et al., 1993) calculated in both translation directions.",
        "The weights of these additional models and of the decoder models are again optimized to maximize BLEU score.",
        "Note that we did not use the decision-tree-based distortion models described in (Johnson et al., 2006) here because they did not improve translation quality.",
        "In the following subsections, we will describe the new models added to the system for our",
        "WMT 2007 submissions."
      ]
    },
    {
      "heading": "3. Improvements in PORTAGE",
      "text": [
        "Whereas the phrase tables used in the baseline system contain only one score for each phrase pair, namely conditional probabilities calculated using Kneser-Ney smoothing, our current system combines seven different phrase scores.",
        "First, we used several types of phrase table smoothing in the WMT 2007 system because this proved helpful on other translation tasks: relative frequency estimates, Kneser-Ney- and Zens-Ney-smoothed probabilities (Foster et al., 2006).",
        "Furthermore, we added normalized joint probability estimates to the phrase translation model.",
        "The other three scores will be explained at the end of this subsection.",
        "We pruned the generated phrase tables following the method introduced in (Johnson et al., 2007).",
        "This approach considers all phrase pairs (s, t) in the phrase table.",
        "The count C(s, t) of all sentence pairs containing (s, t) is determined, as well as the count of all source/target sentences containing s/t .",
        "Using these counts, Fisher's exact test is carried out to calculate the significance of the phrase pair.",
        "The phrase tables are then pruned based on the p-value.",
        "Phrase pairs with low significance, i.e. which are only weakly supported by the training data, are pruned.",
        "This reduces the size of the phrase tables to 8-16% on the different language pairs.",
        "See (Johnson et al., 2007) for details.",
        "Three additional phrase scores were derived from information on which this pruning is based:",
        "• the significance level (or p-value),",
        "• the number C(s , t ) of sentence pairs containing the phrase pair, normalized by the number of source sentences containing s ,",
        "• C(s , t ), normalized by the number of target sentences containing t .",
        "For our submissions, we used the last three phrase scores only when translating the Eu-roParl data.",
        "Initial experiments showed that they do not improve translation quality on the News Commentary data.",
        "Apart from this, the systems for both domains are identical.",
        "Concerning the language models, we made two changes to our system since WMT 2006.",
        "First, we replaced the trigram language model by a 4-gram model trained on the WMT 2007 data.",
        "We also investigated the use of a 5-gram, but that did not improve translation quality.",
        "Second, we included adapted language models which are specific to the development and test corpora.",
        "For each development or test corpus, we built this language model using information retrieval to find relevant sentences in the training data.",
        "To this end, we merged the training corpora for EuroParl and News Commentary.",
        "The source sentences from the development or test corpus served as individual queries to find relevant training sentence pairs.",
        "For each source sentence, we retrieved 10 sentence pairs from the training data and used their target sides as language model training data.",
        "On this small corpus, we trained a trigram language model, again using the SRILM toolkit.",
        "The feature function weights in the decoder and the rescoring model were optimized using the adapted language model for the development corpus.",
        "When translating the test corpus, we kept these weights, but replaced the adapted language model by that specific to the test corpus.",
        "We integrated several new decoder and rescoring features into PORTAGE.",
        "During decoding, the system now makes use of a feature based on IBM Model 1.",
        "This feature calculates the probability of the (partial) translation over the source sentence, using an IBM1 translation model in the direction p(t{ | sJ).",
        "In the rescoring process, we additionally included several types of posterior probabilities.",
        "One is the posterior probability of the sentence length over the N-best list for this source sentence.",
        "The others are determined on the level of words, phrases, and n-grams, and then combined into a value for the whole sentence.",
        "All posterior probabilities are calculated over the N-best list, using the sentence probabilities which the baseline system assigns to the translation hypotheses.",
        "For details on the posterior probabilities, see (Ueffing and Ney, 2007; Zens and Ney, 2006).",
        "This year, we increased the length of the N-best lists from 1,000 to 5,000.",
        "For truecasing the translation output, we used the model described in (Agbago et al., 2005).",
        "This model uses a combination of statistical components, including an n-gram language model, a case mapping model, and a specialized language model for unknown words.",
        "The language model is a 5-gram model trained on the WMT 2007 data.",
        "The detokenizer which we used is the one provided for WMT 2007."
      ]
    },
    {
      "heading": "4. Experimental results",
      "text": [
        "We submitted results for six of the translation directions of the shared task: French English, German English, and Spanish English.",
        "Table 1 shows the improvements resulting from incorporating new techniques into PORTAGE on the Spanish – English EuroParl task.",
        "The baseline system is the one described in section 2.",
        "Trained on the 2007 training corpora, this yields a BLEU score of 30.48.",
        "Adding the new phrase scores introduced in section 3.1 yields a slight improvement in translation quality.",
        "This improvement by itself is not significant, but we observed it consistently across all evaluation metrics and across the different development and test corpora.",
        "Increasing the order of the language model and adding an adapted language model specific to the translation input (see section 3.2) improves the BLEU score by 0.6 points.",
        "This is the biggest gain we observe from introducing a new method.",
        "The incorporation of the IBM1-based decoder feature causes a slight drop in translation quality.",
        "This surprised us because we found this feature to be very helpful on the NIST Chinese - English translation task.",
        "Adding the posterior probabilities presented in section 3.3 in rescoring and increasing the length of the N-best lists yielded a small, but consistent gain in translation quality.",
        "The overall improvement compared to last year's system is around 1 BLEU point.",
        "The gain achieved from introducing the new methods by themselves are relatively small, but they add up.",
        "Table 2 shows results on all six language pairs we translated for the shared task.",
        "The translation quality achieved on the 2007 test set is similar to that on the 2006 test set.",
        "The system clearly performs better on the EuroParl domain than on News Commentary.",
        "Table 2: Translation quality in terms of BLEU[%] and NIST score on all tasks.",
        "True-cased and detokenized translation output.",
        "25.27",
        "6.82",
        "26.02",
        "6.91",
        "19.36",
        "5.86",
        "18.94",
        "5.71",
        "31.54",
        "7.55",
        "32.09",
        "7.67",
        "30.94",
        "7.39",
        "30.92",
        "7.41",
        "30.90",
        "7.51",
        "31.90",
        "7.68",
        "30.08",
        "7.26",
        "30.06",
        "7.26",
        "20.23",
        "6.19",
        "23.17",
        "7.10",
        "13.84",
        "5.38",
        "16.30",
        "5.95",
        "31.07",
        "7.68",
        "31.08",
        "8.11",
        "30.79",
        "7.73",
        "32.56",
        "8.25",
        "24.97",
        "6.78",
        "26.84",
        "7.47",
        "24.91",
        "6.79",
        "26.60",
        "7.24",
        "Table 1: Effect of integrating new models and methods into the PORTAGE system.",
        "Translation quality in terms of BLEU and NIST score, WER and PER on the EuroParl Spanish-English 2006 test set.",
        "True-cased and detokenized translation output.",
        "Best results printed in boldface."
      ]
    },
    {
      "heading": "5. Conclusion",
      "text": [
        "We presented the PORTAGE system with which we translated six language pairs in the WMT 2007 shared task.",
        "Starting from the state of the system during the WMT 2006 evaluation, we analyzed the contribution of new methods which were incorporated over the last year in detail.",
        "Our experiments showed that most of these changes result in (small) improvements in translation quality.",
        "In total, we gain about 1 BLEU point compared to last year's system."
      ]
    },
    {
      "heading": "6. Acknowledgments",
      "text": [
        "Our thanks go to the PORTAGE team at NRC for their contributions and valuable feedback.",
        "system",
        "BLEU[%]",
        "NIST",
        "WER[%]",
        "PER[%]",
        "baseline",
        "30.48",
        "7.44",
        "58.62",
        "42.74",
        "+ new phrase table features",
        "30.66",
        "7.48",
        "58.25",
        "42.46",
        "+ 4-gram LM + adapted LM",
        "31.26",
        "7.53",
        "57.93",
        "42.26",
        "+ IBM1-based decoder feature",
        "31.18",
        "7.51",
        "58.13",
        "42.53",
        "+ refined rescoring",
        "31.54",
        "7.55",
        "57.81",
        "42.24"
      ]
    }
  ]
}
