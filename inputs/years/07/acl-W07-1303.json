{
  "info": {
    "authors": [
      "T. Mark Ellison"
    ],
    "book": "Ninth Meeting of the ACL Special Interest Group in Computational Morphology and Phonology",
    "id": "acl-W07-1303",
    "title": "Bayesian Identification of Cognates and Correspondences",
    "url": "https://aclweb.org/anthology/W07-1303",
    "year": 2007
  },
  "references": [
    "acl-J00-2004",
    "acl-P06-1035",
    "acl-P84-1091"
  ],
  "sections": [
    {
      "text": [
        "Linguistics, University of Western Australia, and Analith Ltd mark@marke His on.net"
      ]
    },
    {
      "heading": null,
      "text": [
        "This paper presents a Bayesian approach to comparing languages: identifying cognates and the regular correspondences that compose them.",
        "A simple model of language is extended to include these notions in an account of parent languages.",
        "An expression is developed for the posterior probability of child language forms given a parent language.",
        "Bayes' Theorem offers a schema for evaluating choices of cognates and correspondences to explain semantically matched data.",
        "An implementation optimising this value with gradient descent is shown to distinguish cognates from non-cognates in data from Polish and Russian.",
        "Modern historical linguistics addresses questions like the following.",
        "How did language originate?",
        "What were historically-recorded languages like?",
        "How related are languages?",
        "What were the ancestors of modern languages like?",
        "Recently, computation has become a key tool in addressing such questions.",
        "Kirby (2002) gives an overview of current current work on how language evolved, much of it based on computational models and simulations.",
        "Ellison (1992) presents a linguistically motivated method for classifying consonants as consonants or vowels.",
        "An unexpected result for the dead language Gothic provides added weight to one of two competing phonological interpretations of the orthography of this dead language.",
        "Other recent work has applied computational methods for phylogenetics to measuring linguistic distances, and/or constructing taxonomic trees from distances between languages and dialects (Dyen et al., 1992; Ringe et al., 2002; Gray and Atkinson, 2003; McMahon and McMahon, 2003; Nakleh et al., 2005; Ellison and Kirby, 2006).",
        "A central focus of historical linguistics is the reconstruction of parent languages from the evidence of their descendents.",
        "In historical linguistics proper, this is done by the comparative method (Jeffers and Lehiste, 1989; Hock, 1991) in which shared arbitrary structure is assumed to reflect common origin.",
        "At the phonological level, reconstruction identifies cognates and correspondences, and then constructs sound changes which explain them.",
        "This paper presents a Bayesian approach to assessing cognates and correspondences.",
        "Best sets of cognates and correspondences can then be identified by gradient ascent on this evaluation measure.",
        "WThile the work is motivated by the eventual goal of offering software solutions to historical linguistics, it also hopes to show that Bayes' theorem applied to an explicit, simple model of language can lead to a principled and tractable method for identifying cognates.",
        "The structure of the paper is as follows.",
        "The next section details the notions of historical linguistics needed for this paper.",
        "Section 2 formally defines a model of language and parent language.",
        "The subsequent section situates the work amongst similar work in the literature, making use of concepts described in the earlier sections.",
        "Section 4 describes the calculation of the probability of wordlist data given a hypothesised parent language.",
        "This is combined with Bayes' theorem and gradient search in an algorithm to find the best parent language for the data.",
        "Section 5 describes the results of applying an implementation of the algorithm to data from Polish and Russian.",
        "The final section summarises the paper and suggests further work."
      ]
    },
    {
      "heading": "1. Cognates, Correspondences and Reconstruction",
      "text": [
        "In the neo-Grammarian model of language change, a population speaking a uniform language divides, and then the two populations undergo separate language changes.",
        "Word forms with continuous histories in respective daughter languages descending which from a common word-form ancestor are called cognate, no matter what has happened to their semantics.",
        "Cognate word forms may have undergone deformations to make them less similar to each other, these deformations resulting from regular, phonological changes.",
        "Note that in the fields of applied linguistics, second language acquisition, and machine translation, the term cognate is used to mean any words that are phonologically similar to each other.",
        "This is not the sense meant here.",
        "Phonological change produces modifications to the segmental inventory, replacing one segment by another in all or only some contexts.",
        "This sometimes has the effect of collapsing segment types together.",
        "Other changes may divide one segment type into two, depending on a contextual condition.",
        "The relation of parent-language segments to daughter-language segments is, usually, a many-to-many relation.",
        "Parent-child segmental relations are reflected in the correspondences between segment inventories in the daughter languages.",
        "Correspondences are pairings of segments from daughter languages which have derived from a common parent segment.",
        "For example, p in Latin frequently corresponds to f in English, as in words like pater and father.",
        "Both segments have developed from a (postulated) Proto-IndoEuropean *p. Because correspondences only occur between cognates, identifying the two is often a bootstrap process: cor-raling cognates helps find more correspondences, and forms sharing a number correspondences are probably cognate."
      ]
    },
    {
      "heading": "2. Formal Structures",
      "text": [
        "The method presented in this paper is based on a formal model of language.",
        "This is described in section 2.1.",
        "The subsequent section extends the model to define a parent language, whose segmental inventory is correspondences and whose lexicon is cognates linking two descendent languages.",
        "The language model is based on three assumptions.",
        "Assumption 1 There is a universal, discrete set M of meanings.",
        "Assumption 2 A language L has its own set of segments X(L).",
        "Assumption 3 The lexicon \\ of a language L is a partial map of meanings to strings of segments X : M – E(L)*.",
        "On the basis of these assumptions, we can define a language L to be a tripie (M, £(L), X(L)) of meanings, segments and mappings from meanings onto strings of segments.",
        "For example, consider written Polish.",
        "The set of meanings contains concepts as TO TAKE-perfect-infinitive, TREE-nominative-singular, and so on.",
        "The segmental inventory contains the 32 segments a^bccdee_fghijkl Imnnooprsstuwyzzz, ignoring capitalisation.",
        "The lexicon matches meanings to strings of segments, TO TAKE-perfect-infinitive to wziac, TREE-nominative-singular to drzewo.",
        "Definition 1 A degree-(u,v) correspondence",
        "As an example of a correspondence, consider the pair of small strings from Polish and Russian, (c,ti>).",
        "This is a degree-(1, 2) correspondence because its members have lengths as low as one correspondence for any u < 1 and v > 2.",
        "Any correspondence can be mapped onto its components by projection functions.",
        "Definition 2 The projections n1 and n2 map",
        "a correspondence (s,t) onto its first ni(s,t) = s or second n2(s,t) = t component string respectively.",
        "The first projection function will map (c,ti>) onto c, while the second maps (c,ti>) onto ti>.",
        "Correspondences can be formed into strings.",
        "These strings also have projections.",
        "Definition 3 The projections n1 and n2 map",
        "a string of correspondences c1 ..Ck onto the concatenation of the projections of each correspondence.",
        "Suppose we sequence four correspondences into the string (w,b)(z,3)(ia_,»)(c,Tb).",
        "This string has first and second projections, wziac and b3»ti>, formed by concatenating the respective projections of each correspondence.",
        "We can now define a parent language.",
        "Definition 4 A degree-(u, v) parent L0 of two languages Li,L2 is a triple (M, T1(L0),X(L0)) where S(L0) is a set of degree-(u, v) correspon-Li L2 X(Lo)",
        "M onto S(L0) which obeys",
        "The circle stands for function composition.",
        "Continuing our past example, we will focus on the two meanings TO TAKE-perfect-infinitive and TREE-nominative-singular.",
        "The segment inventory for the parent language contains degree-(0,2) correspondences: (,e), (c,ti>), (d,,a,), (e,e), (i%«), (o,o), (rz,p), (w,b), (z,3).",
        "The lexical function maps TO TAKE-perfect-infinitive onto the string of correspondences (w,b) (z,3) (i%») (c,tb) while TREE-nominative-singular maps to (d,fl) (,e) (rz,p) (e,e) (w,b) (o,o).",
        "The parent language condition is verified by checking the projections of the two correspondence strings.",
        "The first string has projections wziac and b3htb, which are forms for the meaning TO TAKE-perfect-infinitive in Polish and Russian respectively.",
        "The second string has projections drzewo and flepeso, which are forms for the meaning TREE-nominative-singular in Polish and Russian respectively.",
        "So the projection condition is satisfied.",
        "If the lexical function is only defined on these two meanings, then this is a valid parent language.",
        "It is worth emphasising that the projection condition for qualifying as a parent language applies only for those meanings for which the parent lexical mapping is defined.",
        "The corresponding forms in the child languages are said to be cognate in this model.",
        "WThere no parent form is reconstructed, the forms are not cognate, and are to be accounted for in some way other than the parent language."
      ]
    },
    {
      "heading": "3. Related Work",
      "text": [
        "The current work is, of course, far from the first to seek to identify cognates and/or correspondences.",
        "Here is an abbreviated overview of previous work in the field.",
        "More detailed surveys can be found in chapter 3 of Kondrak's (2002) PhD thesis or Lowe's online survey of prior art in this field.",
        "In perhaps the first computational work on historical linguistics, Kay (1964) described an algorithm for determining correspondences given a list of cognate pairs across two daughter languages.",
        "His method seeks to find the smallest set of correspondences which allows a degree-(l, oo) alignment for each cognate pair.",
        "Unfortunately, the complexity of the problem has precluded its application to significant daa sets.",
        "Frantz (1970) developed a PL/1 programming which returned numerical evaluations of correspondences and cognacy, given a list of possible cognate word-pairs.",
        "Each word pair must be supplied as a degree-(0, l) reconstruction, that is, aligning single segments with each other or with gaps.",
        "Guy (1984; 1994) presented a program called COGNATE which finds regular correspondences and identifies cognates using statistical techniques.",
        "For his Master's, Broza (1998) developed MDL-based software called candid which identifies correspondences from cognates and expresses these as contextual phonological transformation rules.",
        "Kondrak's (2002) doctoral dissertation combines phonological and semantic similarity methods with correspondance-learning.",
        "The algorithms for learning correspondences are taken from Melamed's (2000) probabilistic methods for identifying word-word translation equivalence.",
        "These methods, like the current work, are Bayesian.",
        "Because Melamed's problem seeks partial rather than complete explanation of the inputs in terms of correspondences, the matching problem is somewhat more difficult theoretically.",
        "As a result, he does not arrive at the decomposition of the sum of the probability of two inputs given the set of possible correspondences, approximating this with a high probability alignment."
      ]
    },
    {
      "heading": "4. Conditional Probability of the Data",
      "text": [
        "The core of any Bayesian model is the conditional probability of the data given the hypothesis.",
        "This section details how probabilities assigned to data, and the assumptions on which this assignment is based.",
        "The data is the mapping of meanings onto forms in two daughter languages.",
        "If those two languages are Li and L2, we want to determine",
        "P(A(Li), A(L2)|h).",
        "The nature of h will be discussed in section 4.6.",
        "For brevity, we will write Aj for A(L»).",
        "The first step in defining the conditional probability of the data is to decompose it into meaning-by-meaning probabilities.",
        "This can be achieved by adopting the following two assumptions.",
        "Assumption 4 In a given language, the forms for different meanings are selected independently.",
        "This assumption states that within a single language choosing, for example, a form wziac for meaning to take-perfect-infinitive is no help in predicting the form which expresses tree-nominative-singular.",
        "Assumption 5 Across different languages, the forms corresponding to different meanings are independent.",
        "According to this assumption, the Polish word wziac and the Russian word b3»ti> can be structurally dependent because they express the same meaning.",
        "In contrast, we can only expect a chance relationship between the Russian word b3»ti> meaning to take-perfect-infinitive, and the Polish word drzewo expressing tree-nominative-singular.",
        "Together, these two assumptions imply that the only dependencies possible between any four forms expressing the two meanings mi and m2 in two languages L^d L2 are between A(mi) and A (mi) on the one hand and A(m2) and A(m2) on the other.",
        "Consequently the probability of generating the word forms in two languages can be decomposed into the product of generating the two language-particular forms for each meaning.",
        "The next assumption holds that structural correlation between corresponding forms should be explained as resulting from cognacy.",
        "Assumption 6 Across different languages, forms corresponding to the same meaning are dependent only if the forms are cognate.",
        "If the words for a particular meaning do not derive from a common ancestral form, then they are uncorrelated.",
        "To return to our Polish and Russian examples, we can expect dependencies in structure between the cognate words drzewo and flepeso.",
        "But we should expect no such correlation in the non-cognate pair pomarancza and anejifaCHH meaning ORANGE-nominativesingular.",
        "Let us write Mj for the domain of the lexical function in language Lj.",
        "This is the set of meanings for which this language has defined a word form.",
        "The set of cognates is the domain of the lexical function of the parent language, Mo.",
        "We can decompose the evidential words into three sets: M0 of cognates, Mi \\ M0 of meanings only expressed in language Li5 and M2 \\M0 of meansecond and third categories are non-cognate, and so probabilistically independent of each other.",
        "The conditional probability of the data can thus be expressed as follows.",
        "meMi\\Mo meM2\\Mo",
        "We now turn to the probability of generating a string in a language.",
        "The first assumption defines the distribution over word-length.",
        "Assumption 7 The probability of a word having a particular length is negative exponential in that length.",
        "The second assumption allows segment probability to depend only on the segment identity, and not on its neighbourhood.",
        "Assumption 8 Segment choice is context-independent.",
        "These two assumptions together imply that the probability of strings is determined by a fixed distribution over E(Lj) U {#}, where # is an end-of-word marker.",
        "For the descendent languages, this distribution can be taken as the relative frequencies of the segments and end-of-word marker.",
        "Denote this distribution for language Lj",
        "The probability of generating a word in a language, given relative frequencies /j, is the product of the relative frequencies for each lettern in the word, multiplied by the relative frequency of the end-of-word marker.",
        "Note that this expression only holds for words that are independent of all others, such as components of non-cognate pairs.",
        "The probability of generating a cognate pair of words is similar to the above, because descendent forms are deterministically derivable from the parent forms.",
        "If (Ai(m), A2(m)) are a pair of cognates derived from an ancestral form A0(m), then there is unit probability that the descendent forms are what they are given the parent: P (Ai (m),A2(m)|A0(m)) = l.",
        "Since a cognate pair is derivable from a parent form, the probability of a cognate pair is the sum of the probabilities of all parent forms which will generate the two descendents.",
        "Write W(m) = W(Ai(m),A2(m)) for the set of possible correspondence strings in the parent which project onto wordforms Ai(m) and A2(m).",
        "Then the probability of the word pair is given by:",
        "The summation poses a slight problem, however.",
        "How do we sum over all possible strings with given projections?",
        "Fortunately, we can decompose the summation.",
        "Start by recognising that the parent language is also a language, and so the probability of forms in the language is determined by a distribution over segments – in this case correspondences – and the end-of-word marker.",
        "For consistency, we call this distribution",
        "The only parent form which projects onto two empty strings is the empty string, consisting only of the end-of-word marker.",
        "For brevity, we will drop the lambdas, writing P(x,y|h) for P(Ai(m) = x, A2(m) = y|h)",
        "We assume, without loss of generality, that the segmental inventory of the parent language consists of all degree-(u, v) correspondences between Li and L2.",
        "Parent segments which are never used can be excluded by giving them zero /0",
        "The function Pre(s; u, v) returns the set of binary divisions (a, b) of the string s, such that the length of the first part a is at least u and at most v",
        "WTith this function, we can recursively define a function W(s,t; u, v) on pairs of strings (s,t) which returns the set of all degree-(u, v) parent language strings which project onto t. For plicit.",
        "By definition, the only parent language string which can map onto the empty string in both descendents is the empty string.",
        "The recursive step breaks the strings s and t into all possible prefixes a and c respectively.",
        "The correspondence (a, c) is then preposed on all W joint unions and concatenation can be transformed into a recursive definition for the probability P0(s,t|h) of constructing a member of the set.",
        "Disjoint union is replaced by summation, concatenation by product.",
        "The probability of an individual correspondence (a, c) is its (unknown) relative frequency /0(a, c) in the parent parameters.",
        "We now have the pieces to specify the probability of finding any particular form as the form-pair for the descendent languages.",
        "The probability of the pair in the case of cognacy is P0(Ai(m), A2(m)|h).",
        "If the pair are not cognate, then they are independent, and their probability is Pi(Ai(m))P2(A2(m)|h).",
        "Ifwe write c(m|h) for the likelihood that the pair is cognate, we can combine these two values to given a total probability of the two forms.",
        "Because the word-pairs are independent (assumption 4), the product of the above probabil-m the data given the hypothesis.",
        "One burning question remains, however.",
        "WThat is the hypothesis?",
        "The simple answer is that it is exactly those free variables in the specification of the probability of the data",
        "There were two groups of unknowns in the probability of the data.",
        "The first is the rela-/0",
        "parent-language forms.",
        "The second is the like-c zero and one indexed by meanings.",
        "A hypothesis is therefore any setting of values for the pair of vectors (/, c).",
        "not fixed in the above derivation, they will be held constant for any particular search, and thus do not define a dimension in the hypothesis space.",
        "In this section, we have derived P(D|h), the likelihood of our data given a hypothesis.",
        "For simplicity, we choose a flat prior over hypotheses, rendering the MAP Bayesian approach an instance of maximum likelihood determination.",
        "The value for the likelihood is differentiable in each of the parameters.",
        "Consequently, gradient descent can be used to find the hypothesis which maximises the probability of the data."
      ]
    },
    {
      "heading": "5. Results",
      "text": [
        "In constructing the method, we made a number of assumptions about independence of forms.",
        "It is sensible that for testing, the method is applied to data that conforms reasonably well to these assumptions.",
        "The alternative is to apply it to data which contradicts its fundamental assumptions, consequently hampering its effectiveness.",
        "Polish and Russian were chosen to provide the data because they approximately obey assumption 6: words have dependent structures if and only if they are cognate.",
        "For our two languages, this means that borrowings from common sources are uncommon (numbering 45 in our data set), at least in comparison with the number of cognates (numbering 156).",
        "The data was harvested from two online dictionaries (Wordgumbo, 2007a; Wordgumbo, 2007b), one English-Polish, the other English-Russian.",
        "Multiple translations were simplified, with the shortest translation retained.",
        "The English glosses were used as the meanings for the words.",
        "Where the gloss contained a capital letter, indicating a proper noun, this was eliminated from the data.",
        "The data should also conform to assumption 4, that words for different meanings with a language are independent.",
        "So where two meanings in the data sets were realised with the same form, these meanings were deemed to be structurally dependent, and so only the first was retained in the wordlist.",
        "The remaining data contains 407 aligned Polish-Russian word pairs.",
        "Polish and Russian both use a great deal of derivational and inflectional morphology.",
        "The simple language model used here does not take this into account, so this will be a disturbing influence on the results.",
        "The aligned wordlists were hand-tagged as cognate, common borrowing or non-cognate.",
        "A permissive rule of cognacy was used: if the roots of words in the two languages were cognate, they were cognate, even if represented with non-cognate derivational and/or inflectional morphology.",
        "Borrowings as: cognates non-cognates",
        "Figure 1: Evaluation of program performance on 407 meaning-matched pairs of Polish-Russian words.",
        "Common borrowings are scored as cognates in the first column, non-cognates in the second.",
        "The scores show that the method works well in identifying cognates, particularly if common borrowings are accepted as cognates, or excluded manually.",
        "If common borrowings are scored as non-cognates, then the accuracy falls.",
        "Of the correspondences found between Polish and Russian, 67 have a phonological basis.",
        "The remaining 27 result from mismatch morphology in cognates or differences in common borrowings."
      ]
    },
    {
      "heading": "6. Conclusion",
      "text": [
        "This paper has presented a model of language which allows the calculation of the posterior probability of forms arising in the cases where",
        "they are cognate, and where they are not.",
        "Bayes' theorem relates these probabilities to the posterior likelihood of particular correspondences and cognacy relationships.",
        "Gradient descent can be used to search this space for the best distribution over correspondences, and best cognacy evaluations for meaning-paired words.",
        "The application to data from Polish and Russian shows remarkable success identifying both cognates and non-cognates.",
        "Future work will proceed by relaxing constraints on the parent language.",
        "The parent inventory will be widened to include multisegment correspondences.",
        "Multiple parent languages will be permitted, to the end of separating borrowings from cognates.",
        "Finally, richer models of language, incorporating syllable structure, will allow more information to identify cognates."
      ]
    }
  ]
}
