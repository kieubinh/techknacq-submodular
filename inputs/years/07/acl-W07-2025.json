{
  "info": {
    "authors": [
      "Steven Bethard",
      "James H. Martin"
    ],
    "book": "Fourth International Workshop on Semantic Evaluations (SemEval-2007)",
    "id": "acl-W07-2025",
    "title": "CU-TMP: Temporal Relation Classification Using Syntactic and Semantic Features",
    "url": "https://aclweb.org/anthology/W07-2025",
    "year": 2007
  },
  "references": [
    "acl-N01-1025",
    "acl-P06-1095",
    "acl-W07-2014"
  ],
  "sections": [
    {
      "text": [
        "Proceedings of the 4th International Workshop on Semantic Evaluations (SemEval-2007), pages 129?132, Prague, June 2007. c?2007 Association for Computational Linguistics CU-TMP:"
      ]
    },
    {
      "heading": "Abstract",
      "text": [
        "We approached the temporal relation identification tasks of TempEval 2007 as pairwise classification tasks.",
        "We introduced a variety of syntactically and semantically motivated features, including temporal-logic-based features derived from running our Task B system on the Task A and C data.",
        "We trained support vector machine models and achieved the second highest accuracies on the tasks: 61% on Task A, 75% on Task B and 54% on Task C."
      ]
    },
    {
      "heading": "1 Introduction",
      "text": [
        "In recent years, the temporal structure of text has become a popular area of natural language processing research.",
        "Consider a sentence like: (1) The top commander of a Cambodian resistance force said Thursday he has sent a team to recover the remains of a British mine removal expert kidnapped and presumed killed by Khmer Rouge guerrillas almost two years ago.",
        "English speakers immediately recognize that kidnapping came first, then sending, and finally saying, even though before and after never appeared in the text.",
        "How can machines learn to do the same?",
        "The 2007 TempEval competition tries to address this question by establishing a common corpus on which research systems can compete to find temporal relations (Verhagen et al., 2007).",
        "TempEval considers the following types of event-time temporal relations: Task A Events1and times within the same sentence Task B Events1 and document times Task C Matrix verb events in adjacent sentences In each of these tasks, systems attempt to annotate pairs with one of the following relations: BEFORE,"
      ]
    },
    {
      "heading": "BEFORE-OR-OVERLAP, OVERLAP, OVERLAP-OF",
      "text": [
        "AFTER, AFTER or VAGUE.",
        "Competing systems are instructed to find all temporal relations of these types in a corpus of newswire documents.",
        "We approach these tasks as pairwise classification problems, where each event/time pair is assigned one of the TempEval relation classes (BEFORE, AFTER, etc.).",
        "Event/time pairs are encoded using syntactically and semantically motivated features, and then used to train support vector machine (SVM) classifiers.",
        "The remainder of this paper is structured as follows.",
        "Section 2 describes the features used to characterize event/time relations.",
        "Section 3 explains how we used these features to train SVM models for each task.",
        "Section 4 discusses the performance of our models on the TempEval data, and Section 5 summarizes the lessons learned and future directions."
      ]
    },
    {
      "heading": "2 Features",
      "text": [
        "We used a variety of lexical, syntactic and semantic features to characterize the different types of temporal relations.",
        "In each task, the events and times were characterized using the features:",
        "pos The parts of speech2of the words, e.g. this crucial moment has the parts of speech DT-JJ-NN.",
        "gov-prep Any prepositions governing the event or time, e.g. in during the Iran-Iraq war, the preposition during governs the event war, and in after ten years, the preposition after governs the time ten years.",
        "gov-verb The verb that governs the event or time, e.g. in rejected in peace talks, the verb rejected governs the event talks, and in withdrawing on Friday, the verb withdrawing governs the time Friday.",
        "For events that are verbs, this feature is just the event itself.",
        "gov-verb-pos The part of speech2 of the governing verb, e.g. withdrawing has the part of speech VBG.",
        "aux Any auxiliary verbs and adverbs modifying the governing verb, e.g. in could not come, the words could and not are considered auxiliaries for the event come, and in will begin withdrawing on Friday, the words will and begin are considered auxiliaries for the time Friday.",
        "Events were further characterized using the features (the last six use gold-standard TempEval markup): modal Whether or not the event has one of the auxiliaries, can, will, shall, may, or any of their variants (could, would, etc.).",
        "gold-stem The stem, e.g. the stem of fallen is fall.",
        "gold-pos The part-of-speech, e.g. NOUN or VERB.",
        "gold-class The semantic class, e.g.",
        "REPORTING.",
        "gold-tense The tense, e.g. PAST or PRESENT.",
        "gold-aspect The aspect, e.g. PERFECTIVE.",
        "gold-polarity The polarity, e.g. POS or NEG.",
        "Times were further characterized using the following gold-standard TempEval features:"
      ]
    },
    {
      "heading": "2From MXPOST (ftp.cis.upenn.edu/pub/adwait/jmx/)",
      "text": [
        "gold-type The type, e.g.",
        "DATE or TIME.",
        "gold-value The value, e.g. PAST REF or 1990-09. gold-func The temporal function, e.g.",
        "TRUE.",
        "These gold-standard event and time features are similar to those used by Mani and colleagues (2006).",
        "The features above don't capture much of the differences between the tasks, so we introduced some task-specific features.",
        "Task A included the features: inter-time The count of time expressions between the event and time, e.g. in Figure 1, there is one time expression, Sept 30, between the event posted and the time the quarter.",
        "inter-path The syntactic path between the event and the time, e.g. in Figure 1 the path between posted and the quarter is VBD>VP>S<PP<NP<NP.",
        "inter-path-parts The path, broken into three parts: the tags from the event to the lowest common ancestor (LCA), the LCA, and the tags from the LCA to the time, e.g. in Figure 1 the parts are VBD>VP, S and PP<NP<NP.",
        "inter-clause The number of clause nodes along the syntactic path, e.g. in Figure 1 there is one clause node along the path, the top S node.",
        "Our syntactic features were derived from a syntactic tree, though Boguraev and Ando (2005) suggest that some could be derived from finite state grammars.",
        "For Task C we included the following feature: tense-rules The relation predicted by a set of tense rules, where past tense events come BEFORE present tense events, present tense events come BEFORE future tense events, etc.",
        "In the text: (2) Finally today, we [EVENT learned] that the space agency has taken a giant leap forward.",
        "Collins will be [EVENT named] commander of Space Shuttle Columbia.",
        "Since learned is in past tense and named is in future, the relation is (learned BEFORE named).",
        "In preliminary experiments, the Task B system had the best performance, so we ran this system on the data for Tasks A and C, and used the output to add the following feature for both tasks: task-b-rel The relation predicted by combining the output of the Task B system with temporal logic.",
        "For example, consider the text:",
        "(3) [TIME 08-15-90 (=1990-08-15)]",
        "[TIME today (=1990-08-15)] sought peace on another front by promising to release soldiers captured during the Iran-Iraq [EVENT war].",
        "If Task B said (war BEFORE 08?15?90) then since 08?15?90=1990?08?15=today, the relation (war BEFORE today) must hold."
      ]
    },
    {
      "heading": "3 Models",
      "text": [
        "Using the features described in the previous section, each temporal relation ?",
        "an event paired with a time or another event ?",
        "was translated into a set of feature values.",
        "Pairing those feature values with the TempEval labels (BEFORE, AFTER, etc.)",
        "we trained a statistical classifier for each task.",
        "We chose support vector machines3(SVMs) for our classifiers as they have shown good performance on a variety of natural language processing tasks (Kudo and Matsumoto, 2001; Pradhan et al., 2005).",
        "Using cross-validations on the training data, we performed a simple feature selection where any feature whose removal improved the cross-validation F-score was discarded.",
        "The resulting features for each task are listed in Table 1.",
        "After feature selection, we set the SVM free parameters, e.g. the kernel degree and cost of misclassification, by performing additional cross-validations on the training data, and selecting the model parameters which yielded the highest F-score for each task4.",
        "that the feature was used for that task.",
        "For Task C, 1 indicates that the feature was used only for the first event and not the second, and 2 indicates the reverse."
      ]
    },
    {
      "heading": "4 Results",
      "text": [
        "We evaluated our classifers on the TempEval test data.",
        "Because the Task A and C models derived features from the Task B temporal relations, we first ran the Task B classifer over all the data, and then ran the Task A and Task C classifiers over their individual data.",
        "The resulting temporal relation classifications were evalutated using the standard TempEval scoring script.",
        "Table 2 summarizes these results.",
        "Our models achieved an accuracy of 61% on Task A, 75% on Task B and 54% on Task C, the second highest scores on all these tasks.",
        "The Temp",
        "accuracy of the model with all features.",
        "Eval scoring script also reported a relaxed measure where for example, systems could get partial credit for matching a gold standard label like OVERLAP-OR-AFTER with OVERLAP or AFTER.",
        "Under this measure, our models achieved an accuracy of 63% on Task A, 76% on Task B and 60% on Task C, again the second highest scores in the competition.",
        "We performed a basic feature analysis where, for each feature in a task, a model was trained with that feature removed and all other features retained.",
        "We evaluated the performance of the resulting models using cross-validations on the training data5.",
        "Features whose removal resulted in the largest drops in model performance are listed in Table 3.",
        "For Task A, the most important features were the preposition governing the time and the time's normalized value.",
        "For Task B, the most important features were the auxiliaries governing the event, and the event's stem.",
        "For Task C, the most important features were the verb and auxiliaries governing the second event.",
        "For both Tasks A and C, the features based on the Task B relations were one of the top six features.",
        "In general however, no single feature dominated any one task ?",
        "the greatest drop in performance from removing a feature was only 2.9%."
      ]
    },
    {
      "heading": "5 Conclusions",
      "text": [
        "TempEval 2007 introduced a common dataset for work on identifying temporal relations.",
        "We framed 5We used cross-validations on the training data to preserve the validity of the TempEval test data for future research the TempEval tasks as pairwise classification problems where pairs of events and times were assigned a temporal relation class.",
        "We introduced a variety of syntactic and semantic features, including paths between constituents in a syntactic tree, and temporal relations deduced by running our Task B system on the Task A and C data.",
        "Our models achieved an accuracy of 61% on Task A, 75% on Task B and 54% on Task C. Analysis of these models indicated that no single feature dominated any given task, and suggested that future work should focus on new features to better characterize temporal relations."
      ]
    },
    {
      "heading": "6 Acknowledgments",
      "text": [
        "This research was performed under an appointment of the first author to the DHS Scholarship and Fellowship Program, administered by the ORISE through an interagency agreement between DOE and DHS.",
        "ORISE is managed by ORAU under DOE contract number DE-AC05-06OR23100.",
        "All opinions expressed in this paper are the author's and do not necessarily reflect the policies and views of DHS, DOE, or ORAU/ORISE."
      ]
    }
  ]
}
