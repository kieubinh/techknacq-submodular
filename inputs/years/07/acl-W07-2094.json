{
  "info": {
    "authors": [
      "Francois-Regis Chaumartin"
    ],
    "book": "Fourth International Workshop on Semantic Evaluations (SemEval-2007)",
    "id": "acl-W07-2094",
    "title": "UPAR7: A knowledge-based system for headline sentiment tagging",
    "url": "https://aclweb.org/anthology/W07-2094",
    "year": 2007
  },
  "references": [
    "acl-H05-1059"
  ],
  "sections": [
    {
      "heading": "Abstract",
      "text": [
        "For the Affective Text task at SemEval2007, University Paris 7's system first evaluates emotion and valence on all words of a news headline (using enriched versions of SentiWordNet and a subset of WordNet-Affect).",
        "We use a parser to find the head word, considering that it has a major importance.",
        "We also detect contrasts (between positive and negative words) that shift valence.",
        "Our knowledge-based system achieves high accuracy on emotion and valence annotation.",
        "These results show that working with linguistic techniques and a broad-coverage lexicon is a viable approach to sentiment analysis of headlines."
      ]
    },
    {
      "heading": "1 Introduction",
      "text": []
    },
    {
      "heading": "1.1 Objectives",
      "text": [
        "The detection of emotional connotations in texts is a recent task in computational linguistics.",
        "Its economic stakes are promising; for example, a company could detect, by analyzing the blo-gosphere, people's opinion on its products.",
        "The goal of the SemEval task is to annotate news headlines for emotions (using a predefined list: anger, disgust, fear, joy, sadness & surprise), and for valence (positive or negative).",
        "A specific difficulty here is related to the small number of words available for the analysis."
      ]
    },
    {
      "heading": "1.2 Overall architecture",
      "text": [
        "Our system is mainly rule-based and uses a linguistic approach.",
        "From a macroscopic point of view, we follow the hypothesis that, in a news title, all the words potentially carry emotions.",
        "If linguistic resources make it possible to detect these emotions individually, how can we deal with headlines where bad and good emotions appear at once?",
        "Our objective is to identify the expression which carries the main topic of the title.",
        "One can consider that this expression has a primary importance.",
        "We also seek to lay down rules for detecting specific emotions.",
        "For instance, surprise sometimes comes from the contrast between good and bad news.",
        "And sometimes, simple lexical elements are characteristic of an emotion; a negation or a modal auxiliary in a title may be a relevant indicator of surprise.",
        "We describe here the techniques we implemented to address all these points."
      ]
    },
    {
      "heading": "2 Components & resources used",
      "text": [
        "The system we employed for the Affective Text evaluation consists of the following components1:",
        "?",
        "The SS-Tagger (a Part-of-Speech tagger)2, ?",
        "The Stanford Parser.",
        "We also used several lexical resources: ?",
        "WordNet version 2.1, ?",
        "A subset of WordNet-Affect, ?",
        "SentiWordNet.",
        "As the SS-Tagger is straightforward, we will not say more about it here.",
        "We will, however, discuss the remaining components and resources below."
      ]
    },
    {
      "heading": "2.1 Choice of the Stanford Parser",
      "text": [
        "We wished to use a syntactic parser for this task.",
        "We hesitated between two parsers producing a dependency graph, the Link Grammar Parser (Sleator, Temperley, 1991) and the Stanford Parser (Manning, Klein, 2002).",
        "As a news title is sometimes reduced to a nominal group, without a verb, our experiments showed that we should modify the title to make it ?grammatically correct?.",
        "Such a step is essential to obtain accurate results with a rule-based analyzer such as the Link Grammar Parser.",
        "On the other hand, a statistical analyzer like the Stanford Parser is more tolerant with constructions which are not grammatically correct.",
        "That is why we chose it."
      ]
    },
    {
      "heading": "2.2 WordNet",
      "text": [
        "We used WordNet (Miller, 1995) as a semantic lexicon.",
        "This well-known project, started in 1985 at Princeton, offers a broad-coverage semantic network of the English language, and is probably one of the most popular NLP resources.",
        "In WordNet, words are grouped into sets of synonyms.",
        "Various semantic relations exist between these synsets (for example, hypernymy and hyponymy, antonymy, derivation?",
        ")."
      ]
    },
    {
      "heading": "2.3 WordNet-Affect",
      "text": [
        "WordNet-Affect (Strapparava, Valitutti, 2004) is a hierarchy of ?affective domain labels?, with which the synsets representing affective concepts are further annotated.",
        "We used the subset of WordNet-Affect provided as emotions lists by the SemEval organizers.",
        "To improve it, we manually added to the emotion lists new words that we found important on the task trial data.",
        "The synsets of emotions lists were considered as seeds; our system recursively propagated their emotions to their neighbor synsets3.",
        "SentiWordNet SentiWordNet (Esuli, Sebastiani, 2006) describes itself as a lexical resource for opinion mining.",
        "SentiWordNet assigns to each synset of WordNet three sentiment scores 4 : positivity, negativity, objectivity, the sum of which always equals 1.0.",
        "This resource has been created with a mix of linguistics and statistics (using classifiers).",
        "The advantage of this approach is to allow the automatic generation of emotion values for all the synsets of WordNet.",
        "The disadvantage is that, as all the results are not manually validated, some resulting classifications can appear incorrect5.",
        "We recursively propagate the positivity and"
      ]
    },
    {
      "heading": "3.1 ?De-capitalization? of common words",
      "text": [
        "A preliminary problem that we had to solve was related to the Anglo-Saxon habit of putting initial capital letters in all the words of a title.",
        "The first pass of our system thus detected news titles that were ?improperly?",
        "capitalized, and ?de-capitalizes?",
        "their common words.",
        "For that, we used the SS-Tagger on the title; according to the part of speech of each word, information found in WordNet, and some hand-crafted rules7, the system chooses or not to keep the initial.",
        "The impact of this processing step is far from negligible, from the point of view of the Stanford Parser.",
        "Indeed, let us have a look at the difference between the parsing of the title, before (figure 1) and after (figure 2) this processing."
      ]
    },
    {
      "heading": "3 Following relations such as Hyponym, Derivation, Adjective",
      "text": [
        "verb), Antonym and Derivation.",
        "For antonyms, positivity and negativity values are exchanged.",
        "7 For instance, a word that cannot be any form of a WordNet lemma is probably a proper noun, and then we keep its initial.",
        "(Words are tagged with the right part-of-speech, and dependencies are now correct.)"
      ]
    },
    {
      "heading": "3.2 Individual words rating",
      "text": [
        "For the moment, we consider the output of the Stanford Parser as an array of PoS-tagged words.",
        "We use WordNet's morphology functions to find the possible base form of each word.",
        "At this stage, an important question arose: was lexical disambiguation possible?",
        "We thought not, because with short sentences, few relevant heuristics apply.",
        "We chose another solution, by considering that the emotion and valence values of a word were the linear combination of that of all its possible meanings, balanced by the frequency of each lemma.",
        "We detected emotion and valence values for each word, by using our enriched version of WordNet-Affect and SentiWordNet.",
        "In fact, we also detected some extra information: ?",
        "An additional 7th emotion, that looks like ?compassion for people needing protection?.",
        "Our assumption is that certain words express a subjacent need for protection.",
        "For example, there is ?student?",
        "behind ?school?, and ?child?",
        "behind ?adoption?.",
        "So, we built a list of words designating something that needs protection; we also include in this list words such as ?troops?, ?shoppers??",
        "?",
        "We tried to detect acronyms relating to technology; for this, we defined a list of high-tech companies and a very basic regular expression rule saying that a word (not in WordNet) containing numbers, or capitals not in first position, should be something high-tech.",
        "(This very basic rule seems to work nicely on PS3, iPod, NASA?).",
        "We use these high-tech indications to increase the ?joy?",
        "emotion.",
        "?",
        "We counted lexical elements that we think are good indicators of surprise: negations, modal auxiliaries, question marks.",
        "At this stage, we begin some post-processing on individual words.",
        "Which factors cause anger rather that sadness?",
        "We believe that human intention (to harm) causes the former emotion, while natural factors such as disease or climatic catastrophes cause the latter.",
        "So, we used a few rules related to the WordNet noun hierarchy, based on the fact that when a noun is a hyponym of a given synset, we boost some emotions:",
        "Then, the emotions found serve to update the valence, by increasing positivity or negativity:"
      ]
    },
    {
      "heading": "3.3 Global sentence rating",
      "text": [
        "At this stage, our system tries to find the main subject of the news title.",
        "Again, we use the output of the Stanford Parser, but this time, we make use of the dependency graph.",
        "We consider that the main word is the root of the dependency graph, i.e. the word that is never a dependant word.",
        "(For instance, in figure 2, the main word is ?predicts?.)",
        "We think that the contribution of this main word is much more important than that of the other words of the title8.",
        "So, we multiply its individual valence and emotion by 6.",
        "The last important part of linguistic processing is the detection of contrasts and accentuations between ?good?",
        "or ?bad?",
        "things.",
        "We search patterns like [noun?subject?verb] or [verb?direct object?noun] in the dependency graph, with verbs that increase or decrease a quantity9 .",
        "Using the valence of the given noun, this gives our system the ability to detect very good news (?boosts (brain) power?)",
        "or good news where something bad gets less important (?reduces risk?, ?slows decline?, ?hurricane weakens??",
        ")."
      ]
    },
    {
      "heading": "4 Results",
      "text": [
        "Our rule-based system detects the six emotions in news headlines with an average accuracy reaching 89.43% (coarse-grained evaluation).",
        "However, recall is low.",
        "8 In sentences like ?study says?",
        "?, ?scientists say?",
        "?, ?police affirm?",
        "?, the main head word is the verb of the relative.",
        "9 We ?rediscovered?",
        "valence shifters (words that modify the sentiment expressed by a sentiment-bearing word, see (Po-lanyi and Zaenen, 2006)).",
        "The valence detection accuracy (55% in coarse-grained evaluation) is lower than in emotion annotation.",
        "We attribute this difference to the fact that it is easier to detect emotions (that are given by individual words) rather than valence, which needs a global understanding of the sentence."
      ]
    },
    {
      "heading": "5 Conclusion",
      "text": [
        "Emotion and valence tagging is a complex and interesting task.",
        "For our first attempt, we designed and developed a linguistic rule-based system, using WordNet, SentiWordNet and WordNet-Affect lexical resources, that delivers high accuracy results.",
        "In our future work, we will explore the potential of simultaneously using a statistical approach, in order to improve recall of sentiment annotation."
      ]
    }
  ]
}
