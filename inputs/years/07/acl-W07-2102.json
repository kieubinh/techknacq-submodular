{
  "info": {
    "authors": [
      "Cosmin Adrian Bejan",
      "Chris Hathaway"
    ],
    "book": "Fourth International Workshop on Semantic Evaluations (SemEval-2007)",
    "id": "acl-W07-2102",
    "title": "UTD-SRL: A Pipeline Architecture for Extracting Frame Semantic Structures",
    "url": "https://aclweb.org/anthology/W07-2102",
    "year": 2007
  },
  "references": [
    "acl-J02-3001",
    "acl-P03-1002",
    "acl-P98-1013",
    "acl-W04-0819",
    "acl-W04-3212",
    "acl-W04-3213"
  ],
  "sections": [
    {
      "text": [
        "Proceedings of the 4th International Workshop on Semantic Evaluations (SemEval-2007), pages 460?463, Prague, June 2007. c?2007 Association for Computational Linguistics"
      ]
    },
    {
      "heading": "Abstract",
      "text": [
        "This paper describes our system for the task of extracting frame semantic structures in SemEval?2007.",
        "The system architecture uses two types of learning models in each part of the task: Support Vector Machines (SVM) and Maximum Entropy (ME).",
        "Designed as a pipeline of classifiers, the semantic parsing system obtained competitive precision scores on the test data."
      ]
    },
    {
      "heading": "1 Introduction",
      "text": [
        "The SemEval?2007 task for extracting frame semantic structures relies on the human annotated data available in the FrameNet (FN) database.",
        "The Berkeley FrameNet project (Baker et al., 1998) is an ongoing effort of building a semantic lexicon for English based on the theory of frame semantics.",
        "In frame semantics, the meaning of words or word expressions, also called target words (TW), comprises aspects of conceptual structures, or frames, that describe specific situations.",
        "The semantic roles, or frame elements (FE), associated with a target word are locally defined in the frame evoked by the target word.",
        "Currently, the FN lexicon includes more than 135,000 sentences extracted from the British National Corpus containing more than 6,100 target words that evoke more than 825 semantic frames.",
        "For this task, we extended our previous work at Senseval-3 (Bejan et al., 2004) by (1) experimenting with additional features, (2) adding new classification subtasks to accomplish all the requirements, and (3) integrating these subtasks into a pipeline architecture."
      ]
    },
    {
      "heading": "2 System Description",
      "text": [
        "Given a sentence, the frame semantic structure extraction task consists of recognizing the word expressions that evoke semantic frames, assigning the correct frame to them and, for each target word, detecting and labeling the corresponding frame elements properly.",
        "The task also requires the determination of syntactic realizations associated to a frame element, such as grammatical function (GF) and phrase type (PT).",
        "The following illustrates a sentence example annotated with frame elements together with their corresponding grammatical functions and phrase types for the target word ?tie?",
        ":",
        "AEOI's activities and facilities have been tied to several universities .",
        "Frame = Make_Cognitive_Connection evokes To extract semantic structures similar to those illustrated in the example we divide the SemEval?",
        "2007 task into four sub-tasks: (1) target word frame disambiguation (TWFD); (2) FE boundary detection (FEBD); (3) GF label classification (GFLC) and (4) FE label classification (FELC).",
        "The subtasks TWFD and GFLC are natural extensions of the approach described in (Bejan et al., 2004) for the task of semantic role labeling at Senseval-03.",
        "We design machine learning classifiers specific for each of the four subtasks and arrange them in a pipeline architecture such that a classifier can use information predicted by its previous classifiers.",
        "The system architecture is illustrated in Figure 1.",
        "In the data processing step, we parse each sentence into a syntactic tree using the Collins parser and extract named entities using an in",
        "house implementation of a named entity recognizer.",
        "We also extract from the FN lexicon mappings of target words and the semantic frames they evoke.",
        "Various features corresponding to constituents were extracted and passed to SVM and ME classifiers.",
        "For example, in Figure 2, the frame dis",
        "ambiguation subtask extracts features corresponding to the constituent tied in order to predict the right frame between the semantic frames that can be evoked by this target word.",
        "In this figure, the correct categories for each subtask are shown in boldface.",
        "The complete set of features extracted for all the classification subtasks is illustrated in Figure 3.",
        "These represent a subset of features used in previous works (Gildea and Jurafsky, 2002; Florian et al., 2002; Surdeanu et al., 2003; Xue and Palmer, 2004; Bejan et al., 2004; Pradhan et al., 2005) for automatic semantic role labeling and word sense disambiguation.",
        "Figure 3 also indicates whether or not a feature is selected for a specific classification task.",
        "In the remaining part of this section we describe in detail each classification subtask and the features that have the most salient effect on improving the corresponding classifiers."
      ]
    },
    {
      "heading": "2.1 Frame Disambiguation",
      "text": [
        "In FrameNet, some target words can evoke multiple semantic frames.",
        "In order to extract the semantic structure of an ambiguous target word, the first step is to assign the correct frame to the target word in a given context.",
        "This task is similar with the word sense disambiguation task.",
        "We select from the FN lexicon 556 target words that evoke at least two semantic frames and have at least five sentences annotated for each frame, and assemble a multi-class classifier for each ambiguous target word.",
        "As described in Figure 3, for this task we extract features used in word sense disambiguation (Florian et al., 2002), lexical features of the target word, and NAMED ENTITY FLAGS associated with the root node in a syntactic parse tree.",
        "For the rest of the ambiguous target words that have less than five sentences annotated we randomly choose a frame as being the correct frame in a given context."
      ]
    },
    {
      "heading": "2.2 Frame Element Identification",
      "text": [
        "The idea of splitting the automatic semantic role labeling task into FE boundary detection and FE label classification was first proposed in (Gildea and Ju-rafsky, 2002) and then adopted by other works in this task.",
        "The problem of detecting the FE boundaries is cast as the problem of deciding whether or not a constituent is a valid candidate for a FE.",
        "CW POS: The POS corresponding to the content word;v21 CW STEM: Stemmed content word;v22 GOVERNING CATEGORY: Test whether the noun phrase constituents arevv23 dominated by verbal phrases or sentence phrases; SYNTACTIC DISTANCE: The length of the syntactic path;v24 PP FIRST WORD: If the constituent is a prepositional phrase, return the first word in the phrase; v25 HUMAN: Test whether the constituent phrase is either a personal pronoun or a hyponym of first sense of PERSON synset in WordNet; v26 CONSTITUENTS NUMBER: The number of candidate FEs;v27 CONSTITUENTS LIST: Constituents labels list of the candidate FEs;v28 SAME CLAUSE: Test whether the constituent is in the same clause withv29 the target word; GF: The grammatical function of a candidate frame element;v30 GF LIST: The list of grammatical functions associated to the candidate FEs;v31 FRAME: The name of the semantic frame that is evoked by the target word;vvv32 NP SISTER: Determine whether the constituent has a noun phrase sister;v33 FIRST/LAST WORD: Return the first/last word of the constituent phrase;v34 FIRST/LAST POS: Return the first/last POS in the constituent;vv35",
        "VOICE & POSITION: Join of VOICE and POSITION.v42 TW UNIGRAMS: The words, stem words and part of speech (POS) unigramsv01 that are adjacent to target word expressions; TW BIGRAMS: The words, stem words and POS bigrams that are adjacent to02 target word expressions; TW WORD: The target word expression;03 TW STEM: The stem word(s) of the target word expression;v v04 v TW POS: The POS of the target word;v TW CLASS: The lexical class of the target word, e.g. verb, noun, adjective;vv06 05 NAMED ENTITY FLAGS: Set of binary features indicating whether a consti?vv07 tuent contains, is contained or exactly identifies a named entity; VERB WSD: If the target word is a verb, extract the head noun of the direct object and the prepositional object included in the verbal phrase; v08 v NOUN WSD: If the target word is a noun, extract the head word of the verbal phrase that is in a verb?subject or verb?object relation with the noun; 09 v ADJECTIVE WSD: If the target word is an adjective, extract the head noun that is modified by the adjective; 10 v PHRASE TYPE: The syntactic category of the constituent;vv11 DIRECTED PATH: Path in the syntactic parse tree between the constituent and the target word preserving the movement direction; vvv12 UNDIRECTED PATH: Same syntactic path as DIRECTED PATH without13 v preserving the movement direction; PARTIAL PATH: Path from the constituent to the earlier common ancestor of the target word and the constituent; v14 POSITION: Test whether the constituent contains the target word, or appears before or after the target word; vv v15 VOICE: Test if the verbal target word has active or passive construction;vv16 HW: The head word of the constituent;v vv17",
        "We consider a binary classifier over the entire FN data and extract features for each constituent from a syntactic parse tree.",
        "Because this experimental setup allows training the binary classifier on a large set of examples, the best feature combination consists of a restrained number of features.",
        "Most of these features are from the set proposed by (Gildea and Jurafsky, 2002).",
        "Another feature that improved the prediction of FE boundaries in every feature selection experiment is the FRAME feature.",
        "Since the frame disambiguation is executed before the FE boundary detection in the pipeline architecture, we can use the FRAME feature at this step.",
        "This feature helps the binary classifier distinguish between frame element structures from different semantic frames."
      ]
    },
    {
      "heading": "2.3 Grammatical Function Classification",
      "text": [
        "Once we identify the candidate boundaries for frame elements, the next step is to assign the grammatical functions to these boundaries.",
        "In FrameNet, the grammatical functions represent the manner in which the frame elements satisfy grammatical constraints with respect to the target word.",
        "For this task we train a multi-class classifier over the entire lexicon to predict seven categories of GFs that exist in FN.",
        "In addition, we assign the NULL category for those FEs that double as target words.",
        "The features are extracted only for the constituents that are identified as FEs in the previous FE boundary identification sub-task.",
        "The best feature set in this phase includes the features proposed by (Gildea and Jurafsky, 2002) and the FRAME feature."
      ]
    },
    {
      "heading": "2.4 Frame Element Classification",
      "text": [
        "The task of FE classification is to assign FE labels to every constituent identified as FE.",
        "In order to predict the frame elements, which are locally defined for each semantic frame, we built 489 multi-class classifiers, where each classifier corresponds to a frame in FrameNet.",
        "This partitioning of the FN lexicon has the advantage of increasing the overall classification performance and efficiently learning the frame elements labels.",
        "On the other hand, this approach suffers from the lack of annotated data in some frames and hence it requires using a large set of features.",
        "The advantage of designing the classifiers in a pipeline architecture is best illustrated in this subtask.",
        "Some of the most effective features for FE classification are extracted using information from previous sub-tasks: FRAME feature is made available by the TWFD sub-task, CONSTITUENTS NUMBER and CONSTITUENTS LIST are made available by the FEBD sub-task, and GF and GF LIST are made available by the GFLC sub-task."
      ]
    },
    {
      "heading": "3 Experimental Results",
      "text": [
        "We report experimental results on all four classification sub-tasks.",
        "In our experiments we trained two types of classification models for each sub-task: SVM and ME.",
        "In order to optimize the performance measure of each subtask and to find the best configuration of classification models we used 20% of the subtasks training data as validation data.",
        "Table 1 lists the best configuration of classification models as well as the best subtask results when running the experiments on the validation data.",
        "For frame disambiguation, we obtained 76.71% accuracy compared to a baseline of 60.72% accuracy that always predicts the most annotated frame for each of the 556 target words.",
        "The results for GFLC and FELC subtasks listed in Table 1 were achieved by using gold FE boundaries.",
        "The SemEval?2007 organizers provided fully annotated training files, a scorer to evaluate these training files, and testing files containing flat sentences.",
        "In the evaluation process, a semantic dependency graph corresponding to a fully system annotated sentence is created and then matched with its gold dependency graph.",
        "The matching process not only evaluates every semantic structure of a target word, but also considers frame-to-frame and FE-toFE graph relations between the semantic structures.",
        "In addition, various scoring options were considered: exact or partial frame matching, partial credit for evaluating the named entities, evaluation of the flat frame elements labels, and an option for matching only the frames in evaluation.",
        "The evaluation for flat frame elements labels is similar with the evaluation performed at Senseval-3.",
        "The only difference is that for this scorer the FE boundaries must match exactly.",
        "In Table 2, we present the averaged precision, recall and F1 measures for evaluating the semantic dependency graphs and detecting the semantic frames on the testing files.",
        "The ?Options?",
        "column represents the configuration parameters of the scorer: (E)xact/(P)artial frame matching, seman",
        "Although the system achieved good precision scores on the test data, the recall values caused the system to obtain unsatisfactory F1-measure values.",
        "We expect that the recall will increase by considering various heuristics for a better mapping of the frame elements to constituents in parse trees."
      ]
    },
    {
      "heading": "4 Conclusions",
      "text": [
        "We described a system that participated in SemEval?",
        "2007 for the task of extracting frame semantic structures.",
        "We showed that a pipeline architecture of the SVM and ME classifiers as well as an adequate selection of the classification models can improve the performance measures of each sub-task."
      ]
    }
  ]
}
