{
  "info": {
    "authors": [
      "Kapil Thadani",
      "Kathleen R. McKeown"
    ],
    "book": "International Conference on Computational Linguistics",
    "id": "acl-C08-1110",
    "title": "A Framework for Identifying Textual Redundancy",
    "url": "https://aclweb.org/anthology/C08-1110",
    "year": 2008
  },
  "references": [
    "acl-C04-1057",
    "acl-D07-1043",
    "acl-J05-3002",
    "acl-N03-1003",
    "acl-N03-1024",
    "acl-P02-1058"
  ],
  "sections": [
    {
      "text": [
        "The task of identifying redundant information in documents that are generated from multiple sources provides a significant challenge for summarization and QA systems.",
        "Traditional clustering techniques detect redundancy at the sentential level and do not guarantee the preservation of all information within the document.",
        "We discuss an algorithm that generates a novel graph-based representation for a document and then utilizes a set cover approximation algorithm to remove redundant text from it.",
        "Our experiments show that this approach offers a significant performance advantage over clustering when evaluated over an annotated dataset."
      ]
    },
    {
      "heading": "1. Introduction",
      "text": [
        "This paper approaches the problem of identifying and reducing redundant information in documents that are generated from multiple sources.",
        "This task is closely related to many well-studied problems in the field of natural language processing such as summarization and paraphrase recognition.",
        "Systems that utilize data from multiple sources, such as question-answering and extractive summarization systems that operate on news data, usually include a component to remove redundant information from appearing in their generated output.",
        "However, practical attempts at reducing redundancy in the output of these types of systems usually involve clustering the sentences of the generated output, picking a representative sentence from each cluster and discarding the rest.",
        "Although this strategy would remove some redundant information, clustering approaches tuned for coarse matches could also remove non-redundant information whereas clustering approaches tuned for near-exact matches could end up removing very little repeated information.",
        "This is simply a consequence of the fact that information can, and usually does, exist at the sub-sentential level and that clusters of sentences don't necessarily correspond to clusters of information.",
        "In this paper, we discuss a framework for building a novel graph-based representation to detect redundancy within documents.",
        "We identify redundancy at the sub-sentential level through pairwise alignment between the sentences of a document and use this to build a bipartite graph which enables us to keep track of redundant information across all sentences.",
        "Common information between pairs of sentences, detected with the alignment algorithm, can be extrapolated to document-wide units of information using the graph structure.",
        "Individual sentences that are encompassed by the information in the rest of the document can then be identified and removed efficiently by using a well-known greedy algorithm adapted for this representation."
      ]
    },
    {
      "heading": "2. Related Work",
      "text": [
        "The challenge of minimizing redundant information is commonly faced by IR engines and extractive summarization systems when generating their responses.",
        "A well-known diversity-based rerank-ing technique for these types of systems is MMR (Carbonell and Goldstein, 1998), which attempts to reduce redundancy by preferring sentences that differ from the sentences already selected for the summary.",
        "However, this approach does not attempt to identify sub-sentential redundancy.",
        "Alternative approaches to identifying redundancy use clustering at the sentence level (Lin and Hovy, 2001) to remove sentences that are largely repetitive; however, as noted earlier, this is not well-suited to the redundancy task.",
        "The use of sentence simplification in conjunction with clustering (Siddharthan et al., 2004) could help alleviate this problem by effectively clustering smaller units, but this issue cannot be avoided unless sentences are simplified to atomic elements of information.",
        "Other research has introduced the notion of identifying concepts in the input text (Filatova and Hatzivassiloglou, 2004), using a set cover algorithm to attempt to include as many concepts as possible.",
        "However, this approach uses tf-idf to approximate concepts and thus doesn't explicitly identify redundant text.",
        "Our work draws on this approach but extends it to identify all detectable redundancies within a document set.",
        "Another approach does identify small sub-sentential units of information within text called \"Basic Elements\" and uses these for evaluating summarizations (Hovy et al., 2006).",
        "Our approach, in contrast, does not make assumptions about the size or structure of redundant information since this is uncovered through alignments.",
        "We thus require the use of an alignment algorithm to extract the common information between two pieces of text.",
        "This is related to the well-studied problem of identifying paraphrases (Barzi-lay and Lee, 2003; Pang et al., 2003) and the more general variant of recognizing textual entailment, which explores whether information expressed in a hypothesis can be inferred from a given premise.",
        "Entailment problems have also been approached with a wide variety of techniques, one of which is dependency tree alignment (Marsi et al., 2006), which we utilize as well to align segments of text while respecting syntax.",
        "However, our definition of redundancy does not extend to include unidirectional entailment, and the alignment process is simply required to identify equivalent information."
      ]
    },
    {
      "heading": "3. Levels of Information",
      "text": [
        "In describing the redundancy task, we deal with multiple levels of semantic abstraction from the basic lexical form.",
        "This section describes the terminology used in this paper and the graph-based representation that is central to our approach.",
        "The following terms are used throughout this paper to refer to different aspects of a document.",
        "Snippet: This is any span of text in the document and is a lexical realization of information.",
        "While a snippet generally refers to a single sentence within a document, it can apply to multiple sentences or phrases within sentences.",
        "Since redundancy will be reduced by removing whole snippets, a snippet can be defined as the smallest unit of text that can be dropped from a document for the purpose of reducing redundancy.",
        "To illustrate the levels of information that we consider, consider the following set of short sentences as snippets.",
        "Although this is a synthesized example to simplify presentation, sentences with this type of overlapping information occur frequently in the question-answering scenario over news in which our approach has been used.",
        "Xi: Whittington is an attorney.",
        "X2: Cheney shot Whittington, a lawyer.",
        "X3: Whittington, an attorney, was shot in Texas.",
        "X4: Whittington was shot by Cheney while hunting quail.",
        "X5: This happened during a quail hunt in Texas.",
        "We can see that all the information in xi is contained in both X2 and X3.",
        "While no other snippet is completely subsumed by any single snippet, they can be made redundant given combinations of other snippets; for example, X4 is redundant given X2, X3 and X5.",
        "In order to identify these combinations, we need to identify the elements of information within each snippet.",
        "Concept: This refers to a basic unit of information within a document.",
        "Concepts may be facts, opinions or details.",
        "These are not necessarily sememes, which are atomic units of meaning, but simply units of information that are seen as atomic within the document.",
        "We further restrict the definition of a concept to a unit of information seen in more than one snippet, since we are only interested in concepts which help in identifying redundancy.",
        "Formally, a document can be defined as a set of S snippets X = {xi,..., x^}, which is a literal representation of the document.",
        "However, it can also be defined in terms of its information content.",
        "We use Z = {z,..., zc} to represent the set of C concepts that cover all information appearing more than once in the document.",
        "In the example above, we can identify five non-overlapping concepts:",
        "zA: Whittington was shot z : Whittington is an attorney z : The shooting occurred in Texas zD: It happened during a hunt for quail z : Cheney was the shooter",
        "We use subscripts for snippet indices and superscripts for concept indices throughout this paper.",
        "Nugget: This is a textual representation of a concept in a snippet and therefore expresses some information which is also expressed elsewhere in the document.",
        "Different nuggets for a given concept may have unique lexico-syntactic realizations, as long as they all embody the same semantics.",
        "With regard to the notation used above, nuggets can be represented by an S x C matrix Y where each denotes the fragment of text (if any) from the snippet xs that represents concept zc.",
        "Since a concept itself has no unique textual realization, it can be simply represented by the combination of all its nuggets.",
        "For instance, in the example shown above, concept zD is seen in both X4 and X5 in the form of two nuggets (\"... while hunting quail\") and yg (\"... during a quail hunt\"), which are paraphrases.",
        "The degree to which we can consider this and other types of lexical or syntactic differences between nuggets that have the same semantic identity depends on the alignment algorithm used.",
        "Intersection: This is the common information between two snippets that can be obtained through their alignment.",
        "For example, the intersection from the alignment between X2 and X4 consists of two fragments of text that express that Cheney shot Whittington (an active-voiced fragment from X2 and a passive-voiced fragment from X4).",
        "In general, aligning Xj and Xj produces an intersection Vjj which is simply a pair of aligned text fragments covering the set of concepts that Xj and Xj have in common.",
        "However, these undivided segments of text may actually contain multiple nuggets from a document-wide perspective.",
        "We assume that intersections can be decomposed into smaller intersections through further alignments with snippets or other intersections; this process is explained in Subsection 4.3.",
        "Figure 1 illustrates the example introduced in Subsection 3.1 as a network with intersections represented as edges between snippets.",
        "This is the type of graph that would be built using pairwise alignments between all snippets.",
        "Note that although some intersections such as V12 (between xi and X2) and V3;5 express concepts directly, other intersections such as V2,3 and V2,4 are undivided combinations of concepts.",
        "Since we cannot directly identify concepts and their nuggets, this graph is not immediately useful for reducing redundancy.",
        "Figure 1: Graph representing pairwise alignments between the example snippets from Section 3.",
        "For clarity, alphabetic labels like A represent concepts zA.",
        "Node labels show concepts within snippets and edge labels indicate concepts seen in intersections.",
        "Figure 2: Structure of the equivalent concept graph for the example document illustrated in Figure 1.",
        "Circular nodes xs represent snippets, large squares zc represent concepts and small squares y^ depict nuggets for each concept within a snippet.",
        "Now, since the matrix Y describes the interaction of concepts with snippets, it can be viewed as an incidence matrix that defines a bipartite graph between snippets and concepts with nuggets representing the edges.",
        "In this concept graph representation, each snippet can connect to any number of other snippets via a shared concept.",
        "Since concepts serve to connect multiple snippets together, the concept graph can also be seen as a hypergraph, which is a generalization of a graph in which each edge may connect together multiple vertices.",
        "Figure 2 illustrates the structure of the equivalent concept graph for the previous example.",
        "This is simply the bipartite graph with the two types of nodes, namely snippets and concepts, represented using different symbols.",
        "For clarity, nuggets are also depicted as nodes in the graph, thereby reducing edges to simple links indicating membership.",
        "This representation identifies the redundancy between snippets in terms of non-overlapping concepts and is therefore more useful than the graph from Figure 1 for reducing redundancy."
      ]
    },
    {
      "heading": "4. Constructing the Concept Graph",
      "text": [
        "We now describe how a concept graph can be constructed from a document by using dependency tree alignment and leveraging the existing structure of the graph during construction.",
        "In order to obtain the concept graph representation, the common information between each pair of snippets in the document must first be discovered by aligning all pairs of snippets with each other.",
        "We make use of dependency parsing and alignment of dependency parse trees to obtain intersections between each pair of snippets, where each intersection may be a discontiguous span of text corresponding to an aligned subtree within each snippet.",
        "In our experiments, dependency parsing is accomplished with Minipar (Lin, 1998) and alignment is done using a bottom-up tree alignment algorithm (Barzilay and McKeown, 2005) modified to account for the shallow semantic role labels produced by the parser.",
        "The alignment implementation is not the focus of this work, however, and the framework described here could by applied using any alignment technique between segments of text in potentially any language.",
        "As seen in Figure 1, the intersections that can be extracted solely by pairwise comparisons are not unique and may contain multiple concepts.",
        "A truly information-preserving approach requires the explicit identification of concepts as in the concept graph from Figure 2, but efficiently converting the former into the latter poses a non-trivial challenge.",
        "Our approach attempts to obtain a set of irreducible concepts such that each concept in this set cannot wholly or partially contain any other concept in the set (thereby conforming to the definition of a concept in Subsection 3.1).",
        "We attempt to build the concept graph and maintain irreducible concepts alongside each of the S(S – l)/2 pairwise alignment steps.",
        "Every intersection found by aligning a pair of snippets is assumed to represent some concept that these snippets share; it is then compared with existing concepts and is decomposed into smaller intersections if it overlaps partially with any one of them.",
        "This implies a worst-case of C comparisons at each pairwise alignment step (2C if both fragments of an intersection are compared separately).",
        "However, this can be made more efficient by exploiting the structure of the graph.",
        "A new intersection only has to be compared with concepts which might be affected by it and only affects the other snippets containing these concepts.",
        "We can show that this leads to an algorithm that requires fewer than C comparisons, and additionally, that these comparisons can be performed efficiently.",
        "Consider the definition of alignment along the lines of a mathematical relation.",
        "We require snippet alignment to be an equivalence relation and it therefore must have the following properties.",
        "Symmetry: If an intersection Vjj contains a concept z', then will also contain z'.",
        "This property allows only S(S – l)/2 alignments to suffice instead of the full S(S – 1).",
        "Therefore, without loss of generality, we can specify that all alignments between x» and Xj should have i < j.",
        "Transitivity: If intersections Vjj and Vj^ both contain some concept z', then v^fc will also contain z'.",
        "This property leads to an interesting consequence.",
        "Assuming we perform alignments in order (initially aligning xi and X2 and iterating for j within each i), we observe that x» has been aligned with snippets {xi,..., Xj_i} and, for any i > 1, snippets {xi,..., Xj_i} were aligned with all snippets {xi,..., x^}.",
        "Since i < j, this implies that Xi was directly aligned with snippets {xi,..., Xj_i} which in turn were each aligned with all S snippets.",
        "Therefore, due to the property of transitivity, all concepts contained in a new intersection Vj j that also exist in the partly-constructed graph would already be directly associated with Xj.",
        "Note that this does not hold for Xj as well, since Xj has not been aligned with {xj+i,..., Xj_i}; therefore, it may not have encountered all relevant concepts.",
        "This implies that for any i and j, all concepts that might be affected by a new intersection Vjj have already been uncovered in Xj and thus Vij only needs to be compared to these concepts.",
        "For every new intersection Vjj produced by an alignment between x» and x.,-, the algorithm compares it (specifically, the fragment from Xj) with each existing nugget yf for each concept zfc already seen in Xj.",
        "Checking for the following cases ensures that the graph structure contains only irreducible concepts for all the alignments seen:",
        "1.",
        "If Vj j doesn't overlap with any current nugget from Xj, it becomes a new concept that links to Xj and Xj.",
        "In our example, the first intersection V12 contains \"Whittington... an attorney\" from xi and \"...Whittington, a lawyer\" from X2; this becomes a new concept zB since xi has no other nuggets.",
        "2.",
        "If Vj j overlaps completely with a nugget yf, then Xj must also be linked to concept zfc.",
        "For example, xi's fragment in the second intersection V13 is also \"Whittington... an attorney\", so X3 must also link to zB.",
        "3.",
        "If Vj j subsumes , it is split up and the non-overlapping portion is rechecked against existing nuggets recursively.",
        "For example, X2's fragment in the intersection V2,3 is \"...shot Whittington, a lawyer\", part of which overlaps with yB, so this intersection is divided up and the part representing \"...shot Whittington ...\" becomes a new concept zA.",
        "4.",
        "If, on the other hand, yf subsumes Vjj, the concept zfc is itself split up along with all nuggets that it links to, utilizing the present structure of the graph.",
        "When comparing intersections, we can restrict the decomposition of nuggets to prevent the creation of overly-granular concepts.",
        "For instance, we can filter out intersections containing only isolated named-entities or syntactic artifacts like determiners since they contain no information by themselves.",
        "We can also prevent verbs and their arguments from being split apart using information from a snippet's dependency parse, if available.",
        "Instead of C additional comparisons in the worst case after each pairwise snippet alignment, we need no more comparisons in the worst case than the maximum number of concepts that can exist in a single snippet.",
        "Since this value grows no faster than C as S increases, this is a significant improvement.",
        "Other factors, such as the overhead required to split up concepts, remain unchanged.",
        "Furthermore, since all the additional comparisons are carried out between nuggets of the same snippet, we don't need to perform any further alignment among nuggets or concepts.",
        "Alignments are expensive; each is 0{n\\n2) where n\\ and «2 are the number of words in the two segments of text being aligned (if dependency tree alignment is used) along with an overhead for checking word similarity.",
        "However, since we now only need to compare text from the same snippet, the comparison can be performed in linear time by simply comparing spans of word indices, thereby also eliminating the overhead for comparing words."
      ]
    },
    {
      "heading": "5. Decreasing redundancy",
      "text": [
        "The concept graph can now be applied to the task of reducing redundancy in the document by dropping snippets which contain no information that is not already present in the rest of the document.",
        "Every snippet xs in a document can be represented as a set of concepts {zc : G Y).",
        "Since concepts are defined as information that is seen in more than one snippet as per the definition in Subsection 3.1, representing snippets as sets of concepts will overlook any unique information present in a snippet.",
        "Without loss of generality, we can add any such unique information in the form of an artificial concept for each snippet to Z so that snippets can be completely represented as sets of concepts from Z.",
        "Note that the union of snippets Uf=i x« equals Z.",
        "Reducing redundancy in the document while preserving all information requires us to identify the most snippets whose entire informational content is covered by the rest of the snippets in the document, thereby targeting them for removal.",
        "Since we express informational content in concepts, this problem reduces to the task of finding the smallest group of snippets that together cover all the concepts in the document, i.e. we need to find the smallest subset X' C X such that, if X' contains R snippets x'r, the union of these snippets U^Li x'r- also equals Z.",
        "Therefore, every concept in a snippet from X – X' also exists in at least one snippet from X' and no concept from Z is lost.",
        "This formulation of the problem is the classic",
        "X2: Cheney shot Whittington, a lawyer.",
        "X3: Whittington, an attorney, was shot in Texas.",
        "X4: Whittington was shot by Cheney while hunting quail.",
        "X5: This happened during a quail hunt in Texas.",
        "set cover problem, which seeks to find the smallest possible group of subsets of a universe that covers all the other subsets.",
        "A more general variant of this problem is weighted set cover in which the subsets have weights to be maximized or costs to be minimized.",
        "While this problem is known to be NP-hard, there exists a straightforward local maximization approach (Hochbaum, 1997) which runs in polynomial time and is proven to give solutions within a known bound of the optimal solution.",
        "This greedy approximation algorithm can be adapted to our representation.",
        "The algorithm selects a snippet xr to the subset X' such that information content of X U xr is maximized.",
        "In general, this implies that the snippet with the highest degree over uncovered concepts must be selected at each iteration.",
        "Other measures such as snippet length, fluency, or rank in an ordered list can be included in a weight measure in order to break ties and introduce a preference for shorter, more fluent, or higher-ranked snippets.",
        "Consider the example from Section 3.",
        "The candidates for selection are X2, X3 and X4 since they contain the most uncovered concepts.",
        "If X2 is selected, its concepts zA, zB and zE are covered.",
        "At this stage, X5 contains two uncovered concepts while X3 and X4 contain just one each.",
        "Thus, X5 is selected next and its concepts zc and zD are covered.",
        "Since no uncovered concepts remain, all snippets which haven't been selected are redundant.",
        "This solution, which is shown in Figure 3, selects the following text to cover all the snippets:",
        "Other solutions are also possible depending on the factors involved in choosing the snippet to be selected at each iteration.",
        "For example, the algorithm might choose to select X3 first instead of X2, thereby yielding the following solution:"
      ]
    },
    {
      "heading": "6. Experiments",
      "text": [
        "To evaluate the effectiveness of this framework empirically, we ran experiments over documents containing annotations corresponding to concepts within the document.",
        "We also defined a metric",
        "Figure 3: Pruned version of the concept graph example shown in Figure 2, illustrating the outcome of removing redundant snippets.",
        "for comparing any concept graph over a document to a gold-standard concept graph.",
        "This was used to compare the concept graphs created by our approach to perturbed versions of the gold-standard graphs and graphs created by clustering.",
        "Due to the scarcity of available annotated datasets suitable for evaluating redundancy, we utilized the pyramid dataset from DUC 2005 (Nenkova et al., 2007) which was created from 20 articles for the purpose of summarization evaluation.",
        "Each pyramid document is a hierarchical representation of 7 summaries of the orginal news article.",
        "These summaries have been annotated to identify the individual semantic content units or SCUs where each SCU represents a certain fact, observation or piece of information in the summary.",
        "A sentence fragment representing an occurrence of an SCU in a summary is a contributor to the SCU.",
        "The pyramid construction for a group of summaries of the same article mirrors the concept graph representation described in Subsection 3.2.",
        "SCUs with more than two contributors are similar in definition to concepts while their contributors fill the role of nuggets.",
        "Using this analogy, each dataset consists of a combination of the seven summaries in a single pyramid document; the 20 pyramid documents therefore yield 20 datasets.",
        "The evaluation task requires us to compare the concept graph generated by our algorithm to the ideal",
        "(surfis:",
        "Figure 4: The bipartite graph on the left shows snippets xs linked to concepts produced automatically; the one on the right shows the same snippets linked to SCUs from annotated data.",
        "Dashed lines indicate mappings between concepts and SCUs.",
        "concept graph extracted from the pyramid document annotations.",
        "Standard metrics do not apply easily to the problem of comparing bipartite graphs, so we define a novel metric modeled on the well-known IR measures of precision, recall and F-measure.",
        "Figure 4 illustrates the elements involved in the evaluation task.",
        "guish between the sets of links generated by the algorithm and retrieved from the annotations respectively.",
        "Precision and recall are defined as follows while F-measure retains its traditional definition as their harmonic mean.",
        "Precision Recall",
        "Sum of weights in Laig n L",
        "Sum of weights in LaigSum of weights in Laig n Lmr",
        "Sum of weights in L",
        "To determine a mapping between concepts and SCUs, we identify every concept and SCU pair, say zc and zs, which has one or more snippets in common and, for each snippet x» that they have in common, we find the longest common subsequence between their nuggets y\\ and yf to obtain the following score which ranges from 0 to 1.",
        "LCS score = length(UCS) min (length(y1), length(yf))",
        "Table 1 : Summary of the evaluation metrics averaged over all 20 pyramid documents when m = 0.5",
        "This score is compared with a user-defined mapping threshold m to determine if the concept and SCU are sufficiently similar.",
        "In order to avoid biasing the metric by permitting multiple mappings per concept, we adjust for merges or 1 : N mappings by cloning the concept and creating N 1:1 mappings in its place.",
        "We then adjust for splits or N : 1 mappings by dividing the weight of each of the links connected to a participating concept by N. Due to this normalization, the metrics are observed to be stable over variations in m.",
        "We compare the performance of the algorithm against two baselines.",
        "The first approach involves a random concept assignment scheme to build artificial concept graphs using the distributional properties of the gold-standard concept graphs.",
        "The number of concepts C and the number of snippets that each concept links to is determined by sampling from distributions over these properties derived from the statistics of the actual SCU graph for that document.",
        "For evaluation, these artificial concepts are randomly mapped to SCUs using m to control the likelihood of mapping.",
        "The best scores from 100 evaluation runs were considered.",
        "The second baseline used for comparison is a clustering algorithm, since clustering is the most common approach to dealing with redundancy.",
        "For this purpose, we use a recursive spectral partitioning algorithm, a variant of spectral clustering (Shi and Malik, 2000) which obtains an average V-measure (Rosenberg and Hirschberg, 2007) of 0.93 when clustering just pyramid contributors labeled by their SCUs.",
        "The algorithm requires a parameter that controls the homogeneity of each cluster; we run it over the entire range of settings of this parameter.",
        "We consider the clustering that maximizes F-measure in order to avoid any uncertainty regarding optimal parameter selection and to implicitly compare our algorithm against an entire hierarchy of possible clusterings.",
        "We define the metrics of precision, recall and F-measure over the links between snippets and concepts.",
        "Assuming we have a mapping between generated concepts and gold-standard SCUs, we can judge whether each link is correct.",
        "Let each single link between a snippet and a concept have an associated weight of 1 by default and let L indicate a set of such links.",
        "We use La\\g and L to distin-",
        "Measure",
        "Random",
        "Clustering",
        "Concepts",
        "Precision Recall",
        "0.0510 0.0515",
        "0.2961 0.1162",
        "0.4496 0.3266",
        "Fi score",
        "0.0512",
        "0.1669",
        "0.3783",
        "Table 1 shows the Fi scores over evaluation runs using the random concept assignment, clustering and concept graph techniques.",
        "These results are obtained at a mapping threshold of m = 0.5, which implies that we consider a mapping between a concept and an SCU if their nuggets over common sentences share more than 50% of their words on average.",
        "The results do not vary significantly at different settings of m.",
        "We observe that the concepts extracted by our graph-based approach perform significantly better than the best-performing clustering configuration.",
        "Despite a fairly limited alignment approach that doesn't use synonyms or semantic analysis, the concept graph outperforms the baselines by nearly an order of magnitude on each document.",
        "This validates our initial hypothesis that clustering approaches are not suitable for tackling the redundancy problem at the sub-sentential level."
      ]
    },
    {
      "heading": "7. Conclusions and Future Work",
      "text": [
        "We have described a graph-based algorithm for identifying redundancy at the sub-snippet level and shown that it outperforms clustering methods that are traditionally applied to the redundancy task.",
        "Though the algorithm identifies redundancy at the sub-snippet level, redundancy can be decreased by dropping only entirely redundant snippets.",
        "We hope to be able to overcome this limitation by extending this information-preserving approach to the synthesis of new non-redundant snippets which minimize redundant content in the document.",
        "In addition, this work currently assumes that redundancy is bidirectional; however, we intend to also address the case of unidirectional redundancy by considering entailment recognition approaches."
      ]
    },
    {
      "heading": "Acknowledgements",
      "text": [
        "We are grateful to Andrew Rosenberg, David El-son, Mayank Lahiri and the anonymous reviewers for their useful feedback.",
        "This material is based upon work supported by the Defense Advanced Research Projects Agency under Contract No.",
        "HR0011-06-C-0023."
      ]
    }
  ]
}
