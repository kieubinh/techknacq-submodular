{
  "info": {
    "authors": [
      "Kun Yu",
      "Daisuke Kawahara",
      "Sadao Kurohashi"
    ],
    "book": "International Conference on Computational Linguistics",
    "id": "acl-C08-1132",
    "title": "Chinese Dependency Parsing with Large Scale Automatically Constructed Case Structures",
    "url": "https://aclweb.org/anthology/C08-1132",
    "year": 2008
  },
  "references": [
    "acl-C02-1145",
    "acl-C04-1104",
    "acl-D07-1013",
    "acl-D07-1097",
    "acl-D07-1111",
    "acl-E06-1011",
    "acl-J04-4004",
    "acl-N06-1023",
    "acl-P06-1105",
    "acl-P07-1052",
    "acl-P07-2055",
    "acl-P96-1025",
    "acl-W00-1201",
    "acl-W02-2016",
    "acl-W03-1707",
    "acl-W03-1717",
    "acl-W05-1516",
    "acl-W06-1604",
    "acl-W06-2920",
    "acl-W06-2927"
  ],
  "sections": [
    {
      "text": [
        "This paper proposes an approach using large scale case structures, which are automatically constructed from both a small tagged corpus and a large raw corpus, to improve Chinese dependency parsing.",
        "The case structure proposed in this paper has two characteristics: (1) it relaxes the predicate of a case structure to be all types of words which behaves as a head; (2) it is not categorized by semantic roles but marked by the neighboring modifiers attached to a head.",
        "Experimental results based on Penn Chinese Treebank show the proposed approach achieved 87.26% on unlabeled attachment score, which significantly outperformed the baseline parser without using case structures."
      ]
    },
    {
      "heading": "1. Introduction",
      "text": [
        "Case structures (i.e. predicate-argument structures) represent what arguments can be attached to a predicate, which are very useful to recognize the meaning of natural language text.",
        "Researchers have applied case structures to Japanese syntactic analysis and improved parsing accuracy successfully (Kawahara and Kurohashi, 2006(a); Abekawa and Okumura, 2006).",
        "However, few works focused on using case structures in Chinese parsing.",
        "Wu (2003) proposed an approach to learn the relations between verbs and nouns and applied these relations to a Chinese parser.",
        "Han et al. (2004) presented a method to acquire the sub-categorization of Chinese verbs and used them in a PCFG parser.",
        "Normally, case structures are categorized by semantic roles for verbs.",
        "For example, Kawahara and Kurohashi (2006(b)) constructed Japanese case structures which were marked by post positions.",
        "Wu (2003) classified the Chinese verb-noun relations as 'verb-object' and 'modifier-head'.",
        "In this paper, we propose a new type of Chinese case structure, which is different from those presented in previous work (Wu, 2003; Han et al., 2004; Kawahara and Kurohashi, 2006(a); Abekawa and Okumura, 2006) in two aspects:",
        "(1) It relaxes the predicate of a case structure to be all types of words which behaves as a head;",
        "(2) It is not categorized by semantic roles but marked by the neighboring modifiers attached to a head.",
        "The sibling modification information remembers the parsing history of a head node, which is useful to correct the parsing error such as a verb |f (see) is modified by two nouns %jf£ (film) and fi\\3t (introduction) as objects (see Figure 1).",
        "S/NR g-/VV ft.fé/NN frï/f/NN (a) an incorrect dependency tree",
        "fft/NR a/VV m.a^/NN fbjtfVNN (b) a correct dependency tree",
        "We automatically construct large scale case structures from both a small tagged corpus and a large raw corpus.",
        "Then, we apply the large scale case structures to a Chinese dependency parser to improve parsing accuracy.",
        "The Chinese dependency parser using case structures is evaluated by Penn Chinese Treebank 5.1 (Xue et al., 2002).",
        "Results show that the automatically constructed case structures helped increase parsing accuracy by 2.13% significantly.",
        "The rest of this paper is organized as follows: Section 2 describes the proposed Chinese case structure and the construction method in detail; Section 3 describes a Chinese dependency parser using constructed case structures; Section 4 lists the experimental results with a discussion in section 5; Related work is introduced in Section 6; Finally, Section 7 gives a brief conclusion and the direction of future work."
      ]
    },
    {
      "heading": "2. Chinese Case Structure and its Construction",
      "text": [
        "We propose a new type of Chinese case structure in this paper, which is represented as the combination of a case pattern and a case element (see Figure 2).",
        "Case element remembers the bi-lexical dependency relation between all types of head-modifier pairs, which is also recognized in previous work (Wu, 2003; Han et al., 2004; Kawahara and Kurohashi, 2006(a); Abekawa and Okumura, 2006).",
        "Case pattern keeps the pos-tag sequence of all the modifiers attached to a head to remember the parsing history of a head node.",
        "(b) a case structure compiled from (a)",
        "We use 9,684 sentences from Penn Chinese Treebank 5.1 as the tagged corpus, and 7,338,028 sentences written in simplified Chinese from Chinese Gigaword (Graff et al., 2005) as the raw corpus for Chinese case structure construction.",
        "Before constructing case structures from the raw corpus, we need to get the syntactic analysis of it.",
        "First, we do word segmentation and pos-tagging for the sentences in Chinese Gigaword by a Chinese morphological analyzer (Nakagawa and Uchimoto, 2007).",
        "Then a Chinese deterministic syntactic analyzer (Yu et al., 2007) is used to parse the whole corpus.",
        "To guarantee the accuracy of constructed case structures, we only use the sentences with less than k words from Chinese Gigaword.",
        "It is based on the assumption that parsing short sentences is more accurate than parsing long sentences.",
        "The performance of the deterministic parser used for analyzing Chinese Gigaword (see Figure 3) shows smaller k ensures better parsing quality but suffers from lower sentence coverage.",
        "Referring to Figure 2, we set k as 30.",
        "A case pattern consists of a sequence of pos-tags indicating the order of all the modifiers attached to a head (see Figure 1), which can be represented as following.",
        "Here, [posm,posm-1,...,pos1]l means the pos-tag sequence of the modifiers attached to a head from the left side, and [pos1,..., posn-1, posn ]r means the pos-tag sequence of the modifiers attached to a head from the right side.",
        "We use the 33 pos-tags defined in Penn Chinese Treebank (Xue et al., 2002) to describe a case pattern, and make following modifications:",
        "• group common noun, proper noun and pronoun together and mark them as 'noun';",
        "• group predicative adjective and all the other verbs together and mark them as 'verb';",
        "• only regard comma, pause, colon and semicolon as punctuations and mark them as 'punc\\ and neglect other punctuations.",
        "• group cardinal number and ordinal number together and mark them as 'num';",
        "• keep the original definition for other postags but label them by new tags, such as labeling 'P' as 'prep' and labeling 'AD' as 'adv'.",
        "The task of case pattern construction is to extract cpi for each head from both the tagged corpus and the raw corpus.",
        "As we will introduce later, the Chinese dependency parser using case structures applies CKY algorithm for decoding.",
        "Thus the following substrings of cpi are also extracted for each head as horizontal Markovization during case pattern construction.",
        "As introduced in Section 2.1, a case element keeps the lexical preference between a head and its modifier.",
        "Therefore, the task of case element construction is to extract head-modifier pairs from both the tagged corpus and the raw corpus.",
        "Although only the sentences with less than k (k=30) words from Chinese Gigaword are used as raw corpus to guarantee the accuracy, there still exist some dependency relations with low accuracy in these short sentences because of the non-perfect parsing quality.",
        "Therefore, we apply a head-modifier (HM) classifier to the parsed sentences from Chinese Gigaword to further extract head-modifier pairs with high quality.",
        "This HM classifier is based on SVM classification.",
        "Table 1 lists the features used in this classifier.",
        "The HM classifier is trained on 3500 sentences from Penn Chinese Treebank with gold-standard word segmentation and pos-tag.",
        "All the sentences are parsed by the same Chinese deterministic parser used for Chinese Gigaword analysis.",
        "The correct dependency relations created by the parser are looked as positive examples and the left dependency relations are used as negative examples.",
        "TinySVM is selected as the SVM toolkit.",
        "A polynomial kernel is used and degree is set as 2.",
        "Tested on 346 sentences, which are from Penn Chinese Treebank and parsed by the same deterministic parser with gold standard word segmentation and pos-tag, this HM classifier achieved 96.77% on precision and 46.35% on recall."
      ]
    },
    {
      "heading": "3. A Chinese Dependency Parser Using Case Structures",
      "text": [
        "We develop a lexicalized Chinese dependency parser to use constructed case structures.",
        "This parser gives a probability P(T\\S) to each possible dependency tree T of an input sentence S=w1,w2,...,w„ (w, is a node representing a word with its pos-tag), and outputs the dependency tree T that maximizes P(T\\S) (see equation 1).",
        "CKY algorithm is used to decode the dependency tree from bottom to up.",
        "To use case structures, P(T\\S) is divided into two parts (see equation 2): the probability of a sentence S generating a root node wROoT, and the product of the probabilities of a node w, generating a case structure CS,.",
        "As introduced in Section 2, a case structure CSi is composed of a case pattern cpi and a case element cmi.",
        "Thus",
        "P(CSi I wi) = P(cpi, cmi I wi)",
        "A case element cmi consists of a set of dependencies {Dj}, in which each Dj is a tuple <wj, diSj, commaj>.",
        "Here Wj means a modifier node, diSj means the distance between Wj and its head, and commaj means the number of commas between Wj and its head.",
        "Assuming any Dj and Dk are independent of each other when they belong to the same case element, P(cmiIWi,cpi) can be written as",
        "Feature",
        "Description",
        "P0Shead/ Posmod",
        "Pos-tag pair of head and modifier",
        "Distance",
        "Distance between head and modifier",
        "HasComma",
        "If there exists comma between head and modifier, set as 1; otherwise as 0",
        "HasColon",
        "If there exists colon between head and modifier, set as 1; otherwise as 0",
        "HasSemi",
        "If there exists semicolon between head and modifier, set as 1; otherwise as 0",
        "Finally, P(wj,disj,commaj \\ wi,cpi) is divided as P (wj, disj, commaj \\ wt, cpt ) : P(wj \\ wt, cpt) X P(disj, commaj \\ wi, wj, cpi)",
        "Maximum likelihood estimation is used to estimate P(wrootIS) on training data set with the smoothing method used in (Collins, 1996).",
        "The estimation of P(cpiIWi), P(WjIWi,cpi), and P(disj, commaj IWi,Wj,cpi) will be introduced in the following subsections.",
        "Three steps are used to estimate P(cpiIWi) by maximum likelihood estimation using the constructed case patterns:",
        "• Estimate P(cpi|wi) only by the case patterns from the raw corpus and represent it as",
        "Ptagged (cpi W,) ;",
        "• Estimate P(cpi|wi) by equation 6, in which ^pattern is calculated by equation 7 to set proper ratio for the probabilities estimated by the case patterns from different corpora.",
        "In equation 7, Stagged and Sraw mean the occurrence of a lexicalized node wi=<lexi, posi> generating cpi in the tagged or raw corpus, rjtagged and nraw mean the occurrence of a back-off node wi=<posi> generating cpi in the tagged or raw corpus.",
        "To overcome the data sparseness problem, we not only apply the smoothing method used in (Collins, 1996) for a lexicalized head to back off it to its part-of-speech, but also assign a very small value to P(cpi|wi) when there is no cpimodifying wi in the constructed case patterns.",
        "3.3 Estimating P(wj\\wi,cpi) and P(disj, commaj \\wi,Wj,cpi) by Case Elements",
        "To estimate P(wj\\wi,cpi) and P(diSj, commaj |wi,Wj,cpi) by maximum likelihood estimation, we also use three steps:",
        "• Estimate the two probabilities only by the case elements from the tagged corpus and represent them as Ptagged (Wj | Wt, cpt) and",
        "P,agg„d (diSj, commaj | wt, Wj, cpt) ;",
        "• Estimate the two probabilities only by the case elements from the raw corpus, and represent",
        "them as (Wj | W,, cp,) and",
        "Praw (diSj, commaj | Wi, Wj, cpi) ;",
        "• Estimate P(wjjwi,cpi) and P(diSj, commaj |wi,Wj,cpi) by equation 8 and equation 9.",
        "= klement * P,agged (Wj | Wi , cpi ) +",
        "= Keemen, * lagged (diS j , commaj | Wi, Wj , cpi) +",
        "The smoothing method used in (Collins, 1996) is applied during estimation.",
        "In order to set proper ratio for the probabilities estimated by the case elements from different corpora, we use a parameter Äelement in equation 8 and 9.",
        "The appropriate setting (Äelement =0.4) is learned by a development data set (see Figure 4)."
      ]
    },
    {
      "heading": "4. Evaluation Results 4.1 Experimental Setting",
      "text": [
        "We use Penn Chinese Treebank 5.1 as data set to evaluate the proposed approach.",
        "9,684 sentences from Section 001-270 and 400-931, which are also used for constructing case structures, are used as training data.",
        "346 sentences from Section 271-300 are used as testing data.",
        "334 sentences from Section 301-325 are used as development data.",
        "Penn2Malt is used to transfer the phrase structure of Penn Chinese Treebank to dependency structure.",
        "Gold-standard word segmentation and pos-tag are applied in all the experiments.",
        "S^ged + TJagged +8raw +lraw",
        "Unlabeled attachment score (UAS) (Buchholz and Marsi, 2006) is used as evaluation metric.",
        "Because of the difficulty of assigning correct head to Chinese punctuation, we calculate UAS only on the dependency relations in which the modifier is not punctuation.",
        "Three parsers were evaluated in this experiment:",
        "• 'baseline': a parser not using case structures, where P(T|S) is calculated by equation 11 and P(Wj|wi) and P(diSj, commaj |wi,wj) are estimated by training data set only.",
        "= P(wroot | S) * n P(Wj, disj, comma j | wi)",
        "• 'w/ case elem': a parser only using case element, which also calculates P(T|S) by equation 11 but estimates P(wj|wi) and P(disj, commaj \\wi,wj) by constructed case elements.",
        "• ' proposed': the parser introduced in Section 3, which uses both case elements and case patterns.",
        "The evaluation results on testing data set (see Table 2) shows the proposed parser achieved 87.26% on UAS, which was 2.13% higher than that of the baseline parser.",
        "This improvement is regarded as statistically significant (McNemar's test: p<0.0005).",
        "Besides, Table 2 shows only using case elements increased parsing accuracy by 1.30%.",
        "It means both case elements and case patterns gave help to parsing accuracy, and case elements contributed more in the proposed approach.",
        "Figure 5 and Figure 6 show the dependency trees of two example sentences created by both the baseline parser and the proposed parser.",
        "In Figure 5, the baseline parser incorrectly assigned ^iT/NN (signing) as the head of £f£/NN (cooperation).",
        "However, after using the case element Igg/NN (project) -¥ 1=H+VNN, the correct head of -pH+VNN was found by the proposed parser.",
        "Figure 6 shows the baseline parser recognized JFJJ/VV (opening) as the head of |g /P (as) incorrectly.",
        "But in the proposed parser, the probability of JFJJ/VV generating the case pattern '[prep, punc, prep]l' was much lower than that of JFJJ/VV generating the case pattern '[prep]/.",
        "Therefore, the proposed parser rejected the incorrect dependency that |§/P modified H£/VV and got the correct head of |§/P as /VV (show) successfully."
      ]
    },
    {
      "heading": "5. Discussion",
      "text": [
        "5.1 Influence of the Number of Case Structures on Parsing Accuracy",
        "During case structure construction, we only used the sentences with less than k (k=30) words from Chinese Gigaword as the raw corpus.",
        "Enlarging k will introduce more sentences from Chinese Gi-gaword and increase the number of case structures.",
        "Table 4 lists the number of case structures and parsing accuracy of the proposed parser on testing data set with different k. It shows enlarging the number of case structures is a possible way to increase parsing accuracy.",
        "But simply setting larger k did not help parsing, because it decreased the parsing accuracy of Chinese Gi-gaword and consequently decreased the accuracy of constructed case structures.",
        "Using good parse selection (Reichart and Rappoport, 2007; Yates et al., 2006) on the syntactic analysis of Chinese Gigaword is a probable way to construct more case structures without decreasing their accuracy.",
        "We will consider about it in the future.",
        "5.2 Influence of the Case Structure Construction Corpus on Parsing Accuracy",
        "We also evaluated the proposed parser on testing data set using case structures constructed from different corpora.",
        "Results (see Table 5) show that parsing accuracy was improved greatly only when using case structures constructed from both the two corpora.",
        "The case structures constructed from either of a single corpus only gave a little help to parsing.",
        "It is because among all the case structures used during testing (see Table 6), 19.57% case elements were constructed from the tagged corpus only and 54.18% case patterns were constructed from the raw corpus only.",
        "The incorrect head-modifier pairs extracted from Chinese Gigaword is a possible reason for the fact that some case elements only existing in the tagged corpus.",
        "Enhancing good parse selection on Chinese Giga-word could improve the quality of extracted head-modifier pairs and solve this problem.",
        "In addition, the strict definition of case pattern is a probable reason that makes more than half of the case patterns only exist in the raw corpus and 18.18% case patterns exist in neither of the two corpora.",
        "We will modify the representation of case pattern to make it more flexible to the number of modifiers to resolve this issue in the future.",
        "k",
        "10",
        "20",
        "30",
        "40",
        "# of Case Element (M)",
        "0.66",
        "1.14",
        "1.81",
        "2.75",
        "# of Case Pattern (M)",
        "0.57",
        "1.55",
        "3.91",
        "8.48",
        "UAS (%)",
        "85.16",
        "86.42",
        "87.26",
        "87.07",
        "Parsing model",
        "baseline",
        "w/ case elem",
        "proposed",
        "UAS (%)",
        "85.13",
        "86.43 (+1.30)",
        "87.26 (+2.13)",
        "+/NR 3S/NR -A-fE/NN rBb/JJ ftfi/NN Jf B/NN ft/DEG SiJ'/NN ... (b) dependency tree created by the proposed parser",
        "project ...).",
        "3Ë/P irffi/NN , /PU ft/P frWtf/NN ff^/VV ft/DEC Sïà#/NN #/AD S^/VV ... (a) dependency tree created by the baseline parser",
        "S/P irffi/NN , /PU ft/P frWtf/NN ff^/VV ft/DEC BJi#/NN #/AD B^/VV ... (b) dependency tree created by the proposed parser",
        "stadium will show.",
        ").",
        "Gold standard word segmentation and pos-tag are applied in previous experiments.",
        "However, parsing accuracy will be affected by the incorrect word segmentation and pos-tag in the real applications.",
        "Currently, the best performance of Chinese word segmentation has achieved 99.20% on F-score, but the best accuracy of Chinese pos-tagging was 96.89% (Jin and Chen, 2008).",
        "Therefore, we think pos-tagging is more crucial for applying parser in real task compared with word segmentation.",
        "Considering about this, we evaluated the parsing models introduced in Section 4 with real pos-tag in this experiment.",
        "Parsing model baseline__proposed",
        "An HMM-based pos-tagger is used to get postag for testing sentences with gold word segmentation.",
        "The pos-tagger was trained on the same training data set described in Section 4.1 and achieved 93.70% F-score on testing data set.",
        "Results (see Table 7) show that even if with real pos-tags, the proposed parser still outperformed the baseline parser significantly.",
        "However, the results in Table 7 indicate that incorrect pos-tag affected the parsing accuracy of the proposed parser greatly.",
        "Some researchers integrated postagging into parsing and kept n-best pos-tags to reduce the effect of pos-tagging errors on parsing accuracy (Cao et al., 2007).",
        "We will also consider about this in our future work.",
        "Corpus",
        "Tagged",
        "Raw",
        "Tagged+Raw",
        "UAS (%)",
        "85.25",
        "85.90",
        "87.26",
        "Corpus",
        "Tagged",
        "Raw",
        "Tagged+Raw",
        "None",
        "% of case element",
        "19.57",
        "8.95",
        "68.07",
        "3.41",
        "% of case pattern",
        "0.03",
        "54.18",
        "27.61",
        "18.18"
      ]
    },
    {
      "heading": "6. Related Work",
      "text": [
        "To our current knowledge, there were few works about using case structures in Chinese parsing, except for the work of Wu (2003) and Han et al.",
        "(2004) .",
        "Compared with them, our proposed approach presents a new type of case structures for all kinds of head-modifier pairs, which not only recognizes bi-lexical dependency but also remembers the parsing history of a head node.",
        "Parsing history has been used to improve parsing accuracy by many researchers (Yamada and",
        "Matsumoto, 2003; McDonald and Pereira, 2006).",
        "Yamada and Matsumoto (2003) showed that keeping a small amount of parsing history was useful to improve parsing performance in a shift-reduce parser.",
        "McDonald and Pereira (2006) expanded their first-order spanning tree model to be second-order by factoring the score of the tree into the sum of adjacent edge pair scores.",
        "In our proposed approach, the case patterns remember the neighboring modifiers for a head node like McDonald and Pereira's work.",
        "But it keeps all the parsing histories of a head, which is different from only keeping adjacent two modifiers in (McDonald and Pereira, 2006).",
        "Besides, to use the parsing histories in CKY decoding, our approach applies horizontal Markovization during case pattern construction.",
        "In general, the success of using case patterns in Chinese parsing in his paper proves again that keeping parsing history is crucial to improve parsing performance, no matter in which way and to which parsing model it is applied.",
        "There were also some works that handled lexical preference for Chinese parsing in other ways.",
        "For example, Cheng et al.",
        "(2006) and Hall et al.",
        "(2007) applied shift-reduce deterministic parsing to Chinese.",
        "Sagae and Tsujii (2007) generalized the standard deterministic framework to probabilistic parsing by using a best-first search strategy.",
        "In these works, lexical preferences were introduced as features for predicting parsing action.",
        "Besides, Bikel and Chiang (2000) applied two lexicalized parsing models developed for English to Penn Chinese Treebank.",
        "Wang et al.",
        "(2005) proposed a completely lexicalized bottom-up generative parsing model to parse Chinese, in which a word-similarity-based smoothing was introduced to replace part-of-speech smoothing."
      ]
    },
    {
      "heading": "7. Conclusion and Future Work",
      "text": [
        "This paper proposes an approach to use large scale case structures, which are automatically constructed from both a small tagged corpus and the syntactic analysis of a large raw corpus, to improve Chinese dependency parsing.",
        "The proposed case structures not only recognize the lexical preference between all types of head-modifier pairs, but also keep the parsing history of a head word.",
        "Experimental results show the proposed approach improved parsing accuracy significantly.",
        "Besides, although we only apply the proposed approach to Chinese dependency parsing currently, the same idea could be adapted to other languages easily because it doesn't use any language specific knowledge.",
        "There are several future works under consideration, such as modifying the representation of case patterns to make it more robust, enhancing good parse selection on the analysis of raw corpus, and integrating pos-tagging into parsing model."
      ]
    }
  ]
}
