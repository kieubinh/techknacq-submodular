{
  "info": {
    "authors": [
      "Hirotoshi Taira",
      "Sanae Fujita",
      "Masaaki Nagata"
    ],
    "book": "Conference on Empirical Methods in Natural Language Processing",
    "id": "acl-D08-1055",
    "title": "A Japanese Predicate Argument Structure Analysis using Decision Lists",
    "url": "https://aclweb.org/anthology/D08-1055",
    "year": 2008
  },
  "references": [
    "acl-C04-1100",
    "acl-D07-1002",
    "acl-J05-1004",
    "acl-J94-2003",
    "acl-N04-1030",
    "acl-N06-1055",
    "acl-P06-1079",
    "acl-P07-1027",
    "acl-W02-1003",
    "acl-W04-2705",
    "acl-W06-1617",
    "acl-W07-1522",
    "acl-W97-0114"
  ],
  "sections": [
    {
      "text": [
        "Hirotoshi Taira, Sanae Fujita, Masaaki Nagata",
        "NTT Communication Science Laboratories 2-4, Hikaridai, Seika-cho, Keihanna Science City, Kyoto 619-0237, Japan",
        "This paper describes a new automatic method for Japanese predicate argument structure analysis.",
        "The method learns relevant features to assign case roles to the argument of the target predicate using the features of the words located closest to the target predicate under various constraints such as dependency types, words, semantic categories, parts of speech, functional words and predicate voices.",
        "We constructed decision lists in which these features were sorted by their learned weights.",
        "Using our method, we integrated the tasks of semantic role labeling and zero-pronoun identification, and achieved a 17% improvement compared with a baseline method in a sentence level performance analysis."
      ]
    },
    {
      "heading": "1. Introduction",
      "text": [
        "Recently, predicate argument structure analysis has attracted the attention of researchers because this information can increase the precision of text processing tasks, such as machine translation, information extraction (Hirschman et al., 1999), question answering (Narayanan and Harabagiu, 2004) (Shen and Lapata, 2007), and summarization (Melli et al., 2005).",
        "In English predicate argument structure analysis, large corpora such as FrameNet (Fillmore et al., 2001), PropBank (Palmer et al., 2005) and NomBank (Meyers et al., 2004) have been created and utilized.",
        "Recently, the GDA Corpus (Hashida, 2005), Kyoto Text Corpus Ver.4.0 (Kawahara et al., were constructed in Japanese, and these corpora have become the target of an automatic Japanese predicate argument structure analysis system.",
        "We conducted Japanese predicate argument structure (PAS) analysis for the NAIST Text Corpus, which is the largest of these three corpora, and, as far as we know, this is the first time PAS analysis has been conducted for whole articles of the corpus.",
        "The NAIST Text Corpus has the following characteristics, i) semantic roles for both predicates and event nouns are annotated in the corpus, ii) three major case roles, namely the ga, wo and ni-cases in Japanese are annotated for the base form of predicates and event nouns, iii) both the case roles in sentences containing the target predicates and those outside the sentences (zero-pronouns) are annotated, and iv) coreference relations are also annotated.",
        "As regards i), recently there has been an increase in the number of papers dealing with nominalized predicates (Pradhan et al., 2004) (Jiang and Ng, 2006) (Xue, 2006) (Liu and Ng, 2007).",
        "For example, 'trip' in the sentence \"During my trip to Italy, I met him.\"",
        "refers not only to the event \"I met him\" but also to the event \"I traveled to Italy.\"",
        "As in this example, nouns sometimes have argument structures referring to an event.",
        "Such nouns are called event nouns (Komachi et al., 2007) in the NAIST Text Corpus.",
        "At the same time, the problems related to compound nouns are also important.",
        "In Japanese, a compound noun sometimes simultaneously contains both an event noun and its arguments.",
        "For example, the compound noun, 'kkHMR (corporate buyout)' contains an event noun 'MR (buyout)' and its accusative, 'kkM (corporate).'",
        "However, compound",
        "Proceedings of the 2008 Conference on Empirical Methods in Natural Language Processing, pages 523-532, Honolulu, October 2008.",
        "©2008 Association for Computational Linguistics",
        "nouns provide no information about syntactic dependency or about case markers, so it is difficult to specify the predicate-argument structure.",
        "Komachi et al.",
        "investigated the argument structure of event nouns using the co-occurrence of target nouns and their case roles in the same sentence (Komachi et al., 2007).",
        "In these approaches, predicates and event nouns are dealt with separately.",
        "Here, we try to unify these different argument structures using decision lists.",
        "As regards ii), for example, in the causative sentence, '^7V-ttfAfc^t5#^*5 (Mary makes Tom fix dinner),' the basic form of the causative verb, (make fix)' is (fix),' and its nominative is ' (Tom)' and the accusative case role (wo-case) is '^:f% (dinner),' although the surface case particle is ni (dative).",
        "We must deal with syntactic transformations in passive, causative, and benefactive constructions when analyzing the corpus.",
        "As regards iii) and iv), in Japanese, zero pronouns often occur, especially when the argument has already been mentioned in previous sentences.",
        "There have been many studies of zero-pronoun identification (Walker et al., 1994) (Nakaiwa, 1997) (Iida et al., 2006).",
        "In this paper, we present a general procedure for handling both the case role assignment of predicates and event nouns, and zero-pronoun identification.",
        "We use the decision list learning of rules to find the closest words with various constraints, because with decision lists the readability of learned lists is high and the learning is fast.",
        "The rest of this paper is organized as follows.",
        "We describe the NAIST Text Corpus, which is our target corpus in Section 2.",
        "We describe our proposed method in Section 3.",
        "The result of experiments using the NAIST Text Corpus and our method are reported in Section 4 and our conclusions are provided in Section 5."
      ]
    },
    {
      "heading": "2. NAIST Text Corpus",
      "text": [
        "In the NAIST Text Corpus, three major obligatory Japanese case roles are annotated, namely the ga-case (nominative or subjective case), the wo-case (accusative or direct object) and the ni-case (dative or indirect object).",
        "The NAIST Text Corpus is based on the Kyoto Text Corpus Ver.",
        "3.0, which contains 38,384 sentences in 2,929 texts taken from news articles and editorials in a Japanese newspaper, the Mainichi Shinbun'.",
        "We divided these case roles into four types by location in the article as in (Iida et al., 2006), i) the case role depends on the predicate or the predicate depends on the case role in the intra-sentence ( dependency relations'), ii) the case role does not depend on the predicate and the predicate does not depend on the case role in the intra-sentence ( zero-anaphoric (intra-sentential)'), iii) the case role is not in the sentence containing the predicate ( zero-anaphoric (inter-sentential)'), and iv) the case role and the predicate are in the same phrase ( in same phrase').",
        "Here, we do not deal with exophora.",
        "We show the distribution of the above four types in test samples in our split of the NAIST Text Corpus in Tables 1 and 2.",
        "In predicates, the dependency relations' type in the wo-case and the ni-case occur frequently.",
        "In event nouns, the zero-anaphoric (intra-sentential)' and zero-anaphoric (inter-sentential)' types in the ga-case occur frequently.",
        "With respect to the in same phrase' type, the wo-case occurs frequently.",
        "3 Predicate Argument Structure Analysis using Features of Closest Words",
        "In this section, we describe our algorithm.",
        "In the algorithm, we used various constraints when searching for the words located closest to the target predicate.",
        "We described these constraints as features with the direct products of dependency types (ic, oc, ga_c, wo_c, ni_c, sc, nc, fw and bw), generalization levels (words, semantic categories, parts of speech), functional words and voices.",
        "In Japanese, the functional words in a phrase (Bun-setsu in Japanese) and the interdependency of bun-setsu phrases are important for determining the predicate argument structure.",
        "In accordance with the character of the dependency between the case roles and the predicates or event nouns, we divided Japanese word dependency into the following seven types that cover all dependency types in Japanese.",
        "Additionally, we use two optional dependency types.",
        "a) Incoming connection type (ic) depends on functional word",
        "phrasej I word target predicate",
        "predicate or event noun \"The negotiations between Japan and U.S. had been making progress and\" negotiation \"The negotiations progress\" b) Outgoing connection type (oc) phrasej I word I shou-dou impulse",
        "shita did new published book acc \"for the newly published book I bought impulsively\"",
        "With this type, the target case role is the headword of a bunsetsu phrase and the case role phrase depends on the target predicate phrase (Figure 1).",
        "ga-case (Nominative)",
        "predicate argument structure target case",
        "wo-case (Accusative) n I-case (Dative) \"buy the books\" predicate verb or event noun",
        "With this type, the target case role is the headword ofaphrase and aphrase containing a targetpredicate or event noun depends on the case role phrase (Figure 2).",
        "predicate",
        "ga (Nominative)",
        "wo (Accusative)",
        "ni (Dative)",
        "all",
        "15,996 (100.00%)",
        "8,348 (100.00%)",
        "4,871 (100.00%)",
        "dependency relations zero-anaphoric (intra-sentential) zero-anaphoric (inter-sentential) in same phrase",
        "9,591 (59.96%) 3,856 (24.11%) 2,496 ( 15.60%) 53 ( 0.33%)",
        "7,184 (86.06%) 870 ( 10.42%) 225 ( 2.70%) 69 ( 0.83%)",
        "4,276 ( 87.78%) 360 ( 7.39%) 132 ( 2.71%) 103 ( 2.11%)",
        "Table 2: Distribution of case roles for event nouns (Test Data)",
        "event noun",
        "ga (Nominative)",
        "wo (Accusative)",
        "ni (Dative)",
        "all",
        "4,099 (100.00%)",
        "2,314 (100.00%)",
        "423 (100.00%)",
        "dependency relations zero-anaphoric (intra-sentential) zero-anaphoric (inter-sentential) in same phrase",
        "977 (23.84%) 1,672 (40.79%) 1,040 (25.37%)",
        "410 (10.00%)",
        "648 (28.00%) 348 (15.04%) 165 (7.13%) 1,153 (49.83%)",
        "105 (24.82%) 135 (31.91%) 44 (10.40%) 139 (32.86%)",
        "phrase_",
        "-' target case",
        "word",
        "head word",
        "functional word",
        "S",
        "nichi",
        "bei",
        "koushou",
        "ga",
        "Japan U.S. negotiation top",
        "target case",
        "predicate argument structure",
        "ga-case",
        "wo-case",
        "ni-case",
        "predicate",
        "(Nominative)",
        "(Accusative)",
        "(Dative)",
        "or event noun",
        "phrasej",
        "target predicate",
        "word -",
        "- word PREDorEN FW",
        "target case",
        "word HW [",
        "FW",
        "TU *",
        "kan hon",
        "wo",
        "target predicate c) Within the same phrase type (sc) compound noun phrasej-\"The negotiations between Japan and U.S. is\" \"Japan negotiates\" koushou-suru negotiate g) non-connection type (nc) target case nicnj koushou ga hajimatta",
        "Japan U.S. negotiation top began \"The negotiations between Japan and U.S. began\" word PRED or EN FW konkaino jidousha koushou dewa this time car negotiation in \"This time, in the negotiations about cars\" \"Japan negotiates about cars\"",
        "Connection into other case element types d) gac e) woe f) ni_c depends on settoku-suru \"Tom's friend persuades Tom\" persuade",
        "With this type, the target case role and the target predicate or event noun are in the same phrase (Figure 3).",
        "With these types, a phrase containing the target case role depends on a phrase containing another predetermined case role (Figure 4).",
        "We use the terms 'ga_c', 'wo_c' and 'ni_c' when the predetermined case roles are the ga-case, wo-case and ni-case, respectively.",
        "With this type, a phrase containing the target case role and a phrase containing the target predicate or event noun are in the same article, but these phrases do not depend on each other (Figure 5).",
        "Type fw and bw stand for 'forward' and 'backward' types, respectively.",
        "Type fw means the word located closest to the target predicate or event noun without considering functional words or voices.",
        "With fw, the word is located between the top of the article containing the target predicate and the target predicate or event noun.",
        "Similarly, type bw means the word located closest to the target predicate or noun, which is located between the targeted predicate or event noun, and the tail of the article containing the predicate.",
        "We used three levels of generalization for every case role candidate, that is, word, semantic category, and part of speech.",
        "Every word is annotated with a part of speech in the Kyoto Text Corpus, and we used these annotations.",
        "With regard to semantic categories, we annotated every word with a semantic category based on a Japanese thesaurus, Nihongo Goi Taikei.",
        "The thesaurus consists of a hierarchy of 2,710 semantic classes, defined for over 264,312 nouns, with a maximum depth of twelve (Ikehara et al., 1997).",
        "We mainly used the semantic classes of",
        "target case",
        "target predicate",
        "word",
        " – word – ",
        "word PRED or EN f",
        "FW",
        "H",
        "nichi",
        "bei koushou",
        "&",
        "ga",
        "Japan",
        "U.S. negotiation",
        "top",
        "target case",
        "predicate argument structure",
        "target predicate",
        "ga-case",
        "wo-case",
        "ni-case",
        "predicate",
        "(Nominative)",
        "(Accusative)",
        "(Dative)",
        "or event noun",
        "target case",
        "predicate a",
        "rgument structure",
        "target predicate",
        "ga-case",
        "wo-case",
        "ni-case",
        "predicate",
        "(Nominative)",
        "(Accusative)",
        "(Dative)",
        "or event noun",
        "B",
        "mm",
        "nichi",
        "jidousha",
        "koushou-suru",
        "Japan",
        "car",
        "negotiate",
        "phrase_",
        "phrasej",
        "phrasek",
        "target case",
        "target predicate",
        "word",
        " – HW f",
        "FW",
        "word – case word",
        "FW",
        "PRED or EN",
        "CD",
        "tomu",
        "no",
        "yuujin",
        "niyoru",
        "settoku",
        "Tom",
        "of",
        "friend",
        "of",
        "persuasion",
        "'persuasion of Tom's friend\"",
        "ga c",
        "predicate argument structure target case",
        "target predicate",
        "ga-case (Nominative)",
        "wo-case (Accusative)",
        "ni-case (Dative)",
        "predicate or event noun",
        "t human I* Organization 1/f facility a9entV, region place natural place",
        "< animate",
        "abstract thing abstract ( relation I inanimate mental state action human activity phenomenon natural phenomenon existence relationship property location",
        "the third level, and partly the fourth level, which are similar to semantic roles.",
        "We show the top three levels of the Nihongo Goi Taikei common noun thesaurus in Figure 6.",
        "We annotated the words with their semantic category by hand.",
        "We used a functional word in the phrase containing the target case role and active and passive voices for the predicate as base features.",
        "The training algorithm used for our method is shown in Figure 7.",
        "First, the algorithm constructs features that search for the words located closest to the target predicate under various constraints.",
        "Next, the algorithm learns by using linear Support Vector Machines (SVMs) (Vapnik, 1995).",
        "SVMs learn effective features by the one vs. rest method for every case role.",
        "We used TinySVM as an SVM implementation.",
        "Moreover, we construct decision lists sorted by weight from linear SVMs.",
        "Finally, the algorithm calculates the existing probabilities of case roles for every predicate or event noun.",
        "This step produces the criterion that decides whether or not we will determine the case roles when there is no interdependency between the case role candidate and the predicate.",
        "Our split of the NAIST Text Corpus has only 62,264 training samples for 2,874 predicates, and we predict that there will be a shortage of training samples when adopting traditional learning algorithms, such as learning algorithms using entropy.",
        "So, we used SVMs with a high generalization capability to learn the decision lists.",
        "The test algorithm of our method is shown in Figure 8.",
        "In the test phase, we analyzed test samples using decision lists and the existing probabilities of case roles learned in the training phase.",
        "In step 1, we determined case roles using a decision list consisting of features exhibiting case role and predicate inter-dependency, that is, ic, oc, ga_c, wo_c, and ni_c.",
        "This is because there are many cases in Japanese where the syntactic constraint is stronger than the semantic constraint when we determine the case roles.",
        "In step 2, we determined case roles using a decision list of sc ('in same phrase') for the case roles that were not determined in step 1.",
        "This step was mainly for event nouns.",
        "Japanese event nouns frequently form compound nouns that contain case roles.",
        "In step 3, we decided whether or not to proceed to the next step by using the existing probabilities of case roles.",
        "If the probability was less than a certain threshold (50%), then the algorithm stopped.",
        "In step 4, we determined case roles using a decision list of the features that have no interdependency, that is, nc, fw and bw.",
        "This step will be executed when the target case role is syntactically necessary and determined by the co-occurrence of the case roles and predicate or event noun without syntactic clues, such as dependency, functional words and voices."
      ]
    },
    {
      "heading": "4. Experimental Results",
      "text": [
        "We performed our experiments using the NAIST Text Corpus 1.4ß (Iida et al., 2007).",
        "We used 49,527 predicates and 12,737 event nouns from articles published from January 1st to January 11th and the editorials from January to August as training exfor each predicate pi in all predicates appeared in the training corpus do",
        "for each instance pij of p4, in the training corpus do Clear order() for all features aij – the article including pij Wjj – the number of words in aijpred-index – the word index of pij in aij depJtype = ge^dependenc^type(wm,pij ) else if depJtype == 'sc' then inc_order(n, depJtype, '', '') if wm is the ga-case role then yn,ga – 1 else yn,ga – 0 if wm is the wo-case role then ynwo – 1 else yn,wo – 0 if wm is the ni-case role then ynni – 1 else yn,ni – 0 end for depJtype = ge^dependenc^type(wm,pij- ) if wm is the ga-case role then yn,ga – 1 else yn,ga – 0 if wm is the wo-case role then y„jWO – 1 else yn,wo – 0 if wm is the ni-case role then yn<ni – 1 else yn,ni – 0 end for end for",
        "Learn linear SVMs using (xi, yi,ga),(x„, yn,ga) Learn linear SVMs using (xi, yi,wo),(x„, y„,wo) Learn linear SVMs using (xi, yi,„i),(x„, yn,„i) Make the decision list for pi, sorting features by weight.",
        "Calculate the existing probabilities of case roles for pi.",
        "end for procedure get.dependency_type(wm, pij ) if phrase(wm) depends on phrase(pij) then return 'ic' else if phrase(pij) depends on phrase(wm) then return 'oc' else if phrase(wm) depends onphrase(pga) then return 'ga_c' else if phrase(wm) depends on phrase(pwo) then return 'wo_c' else if phrase(wm) depends on phrase(pni) then return 'ni_c' else if phrase(wm) equals phrase(pij) then return 'sc' else return 'nc end procedure procedure inc_order(n, depJtype, func, voice)",
        "Set a feature fw = (wm, depJtype, func, voice) ; order(fw )++ ; if order(fw) == 1 then xnjw – 1 Setafeature fs = (sem(wm), depJtype, func, voice) ; order(fs)++ ; if order(fs) == 1 then xnjs – 1 Set a feature fp = (pos(wm), depJype, func, voice) ; order(fp)++ ; if order(fp) == 1 then xnjv – 1 feature Jist(pi) – feature Jist(pi)[j {fw ,fs,fp} end procedure",
        "Step 1.",
        "Determine case roles using a decision list concerning ic, oc, ga_c, wo_c and ni_c.",
        "Step 2.",
        "Determine case roles using a decision list concerning sc for undetermined case roles in",
        "Step.1.",
        "Step 3.",
        "If the existing probability of case roles < 50 % then the program ends.",
        "Step 4.",
        "Determine case roles using a decision list concerning nc, fw and bw types.",
        "amples.",
        "We used 11,023 predicates and 3,161 event nouns from articles published on January 12th and 13th and the September editorials as development examples.",
        "And we used 19,501 predicate and 5,276 event nouns from articles dated January 14th to 17th and editorials dated October to December as test examples.",
        "This is a typical way to split the data.",
        "We used the annotations in the Kyoto Text Corpus as the interdependency of bunsetsu phrases.",
        "We used both individual and multiple words as case roles.",
        "We used the phrase boundaries annotated in the NAIST Text Corpus in the training phase, and used those annotated automatically by our system using POSs and simple rules in the test phase.",
        "The accuracy of the automatic annotation is about 90%.",
        "To evaluate our algorithm, we conducted experiments using a baseline method.",
        "With the method, we used only nouns that depended on predicates or event nouns as case role candidates.",
        "If the functional word (post-positional case) in the phrase is 'ga','wo' and 'ni , we determined the ga-case, wo-case, or ni-case for the candidates.",
        "Next, as regards event nouns in compound nouns, if there was another word in a compound noun containing an event noun and it co-occurred with the event noun as a case role with a higher probability in the training samples, then the word was selected for the case role.",
        "The conventional approach for making decision lists utilizes the entropy of samples selected by the rules (Yarowsky, 1994) (Goodman, 2002).",
        "We performed comparative experiments using Yarowsky's entropy algorithm (Yarowsky, 1994).",
        "The overall results are shown in Table 7.",
        "Here, 'entropy indicates Yarowsky s algorithm, which uses entropy (Yarowsky, 1994).",
        "Throughout the test data, the F-measure (%) of our method exceeded that of the baseline system and the 'entropy system.",
        "With the ga-case (nominative) in particular, the F-measure increased 9 points.",
        "Table 3 shows some examples of the existing probabilities of case roles for predicates or event nouns.",
        "When the probabilities are extreme values such as the ni-case (dative) of (negotiation), the wo-case (accusative) of #JD (participation), and the wo-case and ni-base of (based on), we can decide to fill the targeted case role or not with high precision.",
        "However, it is difficult to decide to fill the targeted case role or not when the probability is close to 50 percent as in the ga-case of (use).",
        "We show the learned decision list of the ic type (the case role depends on the predicate or event noun), sc type (in the same phrase) and the other types for event noun (negotiation) in Tables 4,5 and 6, respectively.",
        "Here, 'word in the 'level column means 'base form of predicate and 'sem means semantic category of predicate.",
        "In the ic and sc type decision lists, features with semantic categories, such as 'REGION', 'LOCATION' and 'EVENT , occupy a higher order.",
        "In contrast, in the list of the other types, the features that occupy the higher order are the features of the word base form.",
        "This means local knowledge of relations between case roles and predicates or event nouns in the word level is more important than semantic level knowledge.",
        "Predicate",
        "Existing Probability",
        "or Event Noun",
        "ga (NOM)",
        "wo (ACC)",
        "ni (DAT)",
        "(use)",
        "44.72%",
        "82.92%",
        "5.33%",
        "(negotiation)",
        "77.41%",
        "30.70%",
        "0.00%",
        "#in (participation)",
        "87.09%",
        "0.00%",
        "72.46%",
        "3S^< (based on)",
        "81.89%",
        "0.00%",
        "100.00%",
        "order",
        "case",
        "depJype",
        "level",
        "head word",
        "functional word",
        "voice",
        "weight",
        "1",
        "ga",
        "ic",
        "word",
        "^^»AKÄftS (North Korea)",
        "© (of)",
        "active",
        "0.9820",
        "2",
        "ga",
        "ic",
        "sem",
        "Mià (REGION)",
        "© (of)",
        "active",
        "0.6381",
        "3",
        "ga",
        "ic",
        "word",
        "BMMH (both Japan and U.S.)",
        "© (of)",
        "active",
        "0.5502",
        "4",
        "wo",
        "ic",
        "word",
        "-fâ^HrttlxÂ (establishment of joint ventures)",
        "© (of)",
        "active",
        "0.5288",
        "5",
        "wo",
        "ic",
        "word",
        "SMMfadfrS?",
        "(telecommunications)",
        "© (of)",
        "active",
        "0.4142",
        "6",
        "wo",
        "ic",
        "word",
        "Mfi^AKÄffllH (North Korea)",
        "b© (for)",
        "active",
        "0.3168",
        "7",
        "wo",
        "ic",
        "word",
        "fïâ (ACTION)",
        "© (of)",
        "active",
        "0.3083",
        "8",
        "ga",
        "ic",
        "sem",
        "TfefrSiri (OOV NOUN)",
        "© (of)",
        "active",
        "0.2939",
        "9",
        "wo",
        "ic",
        "word",
        "SifW*l^pßmva*5J (car and auto parts sector)",
        "© (of)",
        "active",
        "0.2775",
        "10",
        "wo",
        "ic",
        "sem",
        "S (LOCATION)",
        "© (of)",
        "active",
        "0.2471",
        "order",
        "case",
        "dep.type",
        "level",
        "head word",
        "weight",
        "1",
        "wo",
        "sc",
        "sem",
        "MM (EVENT)",
        "1.1738",
        "2",
        "wo",
        "sc",
        "word",
        "WtM (arrangement)",
        "1.0000",
        "3",
        "ga",
        "sc",
        "word",
        "B^MzS (airline of Japan and China)",
        "0.9392",
        "4",
        "wo",
        "sc",
        "sem",
        "Jgi# (MENTAL STATE)",
        "0.8958",
        "5",
        "ga",
        "sc",
        "word",
        "BM^B^ – tiX^rlf (financial services of Japan and U.S.)",
        "0.8371",
        "6",
        "wo",
        "sc",
        "word",
        "SS^HBjl (contract extension)",
        "0.7870",
        "7",
        "wo",
        "sc",
        "word",
        "(joint venture)",
        "0.7865",
        "8",
        "wo",
        "sc",
        "word",
        "Äfföß'f^fi (intellectual property rights)",
        "0.7224",
        "9",
        "wo",
        "sc",
        "word",
        "êtt^-H^m (car and auto parts)",
        "0.7196",
        "10",
        "sc",
        "word",
        "(Japan and North Korea)",
        "0.6771",
        "order",
        "case",
        "depJtype",
        "level",
        "head word",
        "functional word",
        "voice",
        "weight",
        "1",
        "ga",
        "fw",
        "word",
        "BM (Japan and U.S.)",
        "1.9954",
        "2",
        "ga",
        "fw",
        "word",
        "(Taiwan)",
        "1.9952",
        "3",
        "ga",
        "fw",
        "word",
        "(U.S. and North Korea)",
        "1.4979",
        "4",
        "ga",
        "fw",
        "word",
        "(U.K. and China)",
        "1.1773",
        "5",
        "ga",
        "nc",
        "word",
        "MS (both nations)",
        "fi (TOP)",
        "active",
        "1.1379",
        "6",
        "wo",
        "fw",
        "word",
        "HKlE^'fti (diplomatic normalization)",
        "1.0000",
        "7",
        "bw",
        "word",
        "(U.S. and North Korea)",
        "1.0000",
        "8",
        "fw",
        "word",
        "(capital and labor)",
        "1.0000",
        "9",
        "wo",
        "fw",
        "word",
        "êlW^rSf (automotive area)",
        "1.0000",
        "10",
        "nc",
        "word",
        "MU (both sides)",
        "fi (TOP)",
        "active",
        "1.0000",
        "training data",
        "test data",
        "sentence",
        "ga (NOM)",
        "wo (ACC)",
        "ni (DAT)",
        "sentence",
        "ga (NOM)",
        "wo (ACC)",
        "ni (DAT)",
        "baseline",
        "25.32",
        "32.58",
        "74.51",
        "82.70",
        "21.34",
        "30.08",
        "69.48",
        "76.62",
        "entropy",
        "73.46",
        "89.53",
        "92.72",
        "91.09",
        "33.10",
        "45.67",
        "73.28",
        "77.77",
        "our method",
        "64.81",
        "86.76",
        "92.52",
        "92.20",
        "38.06",
        "55.07",
        "75.82",
        "80.45",
        "We show the results we obtained for predicates in Table 8.",
        "The results reveal that our method is superior to the baseline system.",
        "Our algorithm is particularly effective in the ga-case.",
        "We show the results we obtained for event nouns in Table 9.",
        "This also shows that our method is superior to the baseline system.",
        "The precision with sc type is high and our method is effective as regards event nouns."
      ]
    },
    {
      "heading": "5. Conclusion",
      "text": [
        "We presented a new method for Japanese automatic predicate argument structure analysis using decision lists based on the features of the words located closest to the target predicate under various constraints.",
        "The method learns the relative weights of these different features for case roles and ranks them using decision lists.",
        "Using our method, we integrated the knowledge of case role determination and zero-pronoun identification, and generally achieved a high precision in Japanese PAS analysis.",
        "In particular, we can extract knowledge at various levels from the corpus for event nouns.",
        "In future, we will use richer constraints and research better ways of distinguishing whether or not cases are obligatory."
      ]
    },
    {
      "heading": "Acknowledgments",
      "text": [
        "We thank Ryu Iida and Yuji Matsumoto of NAIST for the definitions of the case roles in the NAIST Text Corpus and functional words, and Franklin Chang for valuable comments.",
        "baseline / our method",
        "ga (Nominative)",
        "wo (Accusative)",
        "ni (Dative)",
        "all",
        "34.44 / 57.40",
        "77.00 / 79.50",
        "79.83 / 83.15",
        "dependency relations zero-anaphoric (intra-sentential) zero-anaphoric (inter-sentential) in same phrase",
        "51.96 / 75.53 0.00 / 30.15 1.85 / 23.45 0.00 / 75.00",
        "85.42 / 88.20 0.00 / 11.41 3.00 / 9.32 0.00 / 51.78",
        "81.83 / 89.51 0.00 / 3.66 0.00 / 11.76 0.00 / 84.65",
        "baseline / our method",
        "ga (Nominative)",
        "wo (Accusative)",
        "ni (Dative)",
        "all",
        "11.05 / 45.64",
        "32.30 / 61.80",
        "20.85 / 38.88",
        "dependency relations zero-anaphoric (intra-sentential) zero-anaphoric (inter-sentential) in same phrase",
        "12.98 / 68.01 0.00 / 36.19 1.40 / 23.25",
        "58.76 / 78.93",
        "25.00 / 62.46 0.00 / 20.46 1.06 / 10.37",
        "47.44 / 77.96",
        "40.00 / 56.05 0.00 / 6.62 0.00 / 3.51",
        "28.91 / 58.13"
      ]
    }
  ]
}
