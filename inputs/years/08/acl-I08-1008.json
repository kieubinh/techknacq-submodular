{
  "info": {
    "authors": [
      "Min Zhang",
      "Chengjie Sun",
      "Haizhou Li",
      "Aiti Aw",
      "Chew Lim Tan",
      "Wang XiaoLong"
    ],
    "book": "Proceedings of the Third International Joint Conference on Natural Language Processing",
    "id": "acl-I08-1008",
    "title": "Name Origin Recognition Using Maximum Entropy Model and Diverse Features",
    "url": "https://aclweb.org/anthology/I08-1008",
    "year": 2008
  },
  "references": [
    "acl-J96-1002",
    "acl-J98-4003",
    "acl-P04-1024",
    "acl-P07-1016"
  ],
  "sections": [
    {
      "text": [
        "Name Origin Recognition Using Maximum Entropy Model",
        "and Diverse Features",
        "1 2 11 3 2",
        "Min Zhang , Chengjie Sun , Haizhou Li , Aiti Aw , Chew Lim Tan , Xiaolong Wang",
        "institute for Infocomm Harbin Institute of National University of",
        "Research, Singapore Technology, China Singapore, Singapore",
        "{mzhang,hli,aaiti} {cjsun,wangxl} tancl@comp.",
        "@i2r.a-star.edu.sg @insun.hit.edu.cn nus.edu.sg",
        "Name origin recognition is to identify the source language of a personal or location name.",
        "Some early work used either rule-based or statistical methods with single knowledge source.",
        "In this paper, we cast the name origin recognition as a multi-class classification problem and approach the problem using Maximum Entropy method.",
        "In doing so, we investigate the use of different features, including phonetic rules, n-gram statistics and character position information for name origin recognition.",
        "Experiments on a publicly available personal name database show that the proposed approach achieves an overall accuracy of 98.44% for names written in English and 98.10% for names written in Chinese, which are significantly and consistently better than those in reported work."
      ]
    },
    {
      "heading": "1. Introduction",
      "text": [
        "Many technical terms and proper names, such as personal, location and organization names, are translated from one language into another with approximate phonetic equivalents.",
        "The phonetic translation practice is referred to as transliteration; conversely, the process of recovering a word in its native language from a transliteration is called as back-transliteration (Zhang et al., 2004; Knight and Graehl, 1998).",
        "For example, English name \"Smith\" and \"i*#t (Pinyin: Shi-Mi-Si)\" in",
        "Chinese form a pair of transliteration and backtransliteration.",
        "In many natural language processing tasks, such as machine translation and cross-lingual information retrieval, automatic name transliteration has become an indispensable component.",
        "Name origin refers to the source language of a name where it originates from.",
        "For example, the origin of the English name \"Smith\" and its Chinese transliteration \"JÂ£l?!",
        "?St (Shi-Mi-Si)\" is English, while both \"Tokyo\" and \"%tt (Dong-Jing)\" are of Japanese origin.",
        "Following are examples of different origins of a collection of English-Chinese transliterations.",
        "Taejon-^ffl(Da-Tian) Vietnamese: Phan Van Khai-#^^(Pan-",
        "Wen-Kai)",
        "Hanoi-Mrt(He-Nei)",
        "In the case of machine transliteration, the name origins dictate the way we rewrite a foreign word.",
        "For example, given a name written in English or Chinese for which we do not have a translation in",
        "Chinese characters in round brackets for ease of reading.",
        "a English-Chinese dictionary, we first have to decide whether the name is of Chinese, Japanese, Korean or some European/English origins.",
        "Then we follow the transliteration rules implied by the origin of the source name.",
        "Although all English personal names are rendered in 26 letters, they may come from different romanization systems.",
        "Each romanization system has its own rewriting rules.",
        "English name \"Smith\" could be directly transliterated into Chinese as \"^^^(Shi-Mi-Si)\" since it follows the English phonetic rules, while the Chinese translation of Japanese name \"Koizumi\" becomes \"^^(Xiao-Quan)\" following the Japanese phonetic rules.",
        "The name origins are equally important in back-transliteration practice.",
        "Li et al.",
        "(2007) incorporated name origin recognition to improve the performance of personal name transliteration.",
        "Besides multilingual processing, the name origin also provides useful semantic information (regional and language information) for common NLP tasks, such as co-reference resolution and name entity recognition.",
        "Unfortunately, little attention has been given to name origin recognition (NOR) so far in the literature.",
        "In this paper, we are interested in two kinds of name origin recognition: the origin of names written in English (ENOR) and the origin of names written in Chinese (CNOR).",
        "For ENOR, the origins include English (Eng), Japanese (Jap), Chinese Mandarin Pinyin (Man) and Chinese Cantonese Jyutping (Can).",
        "For CNOR, they include three origins: Chinese (Chi, for both Mandarin and Cantonese), Japanese and English (refer to Latin-scripted language).",
        "Unlike previous work (Qu and Grefenstette, 2004; Li et al., 2006; Li et al., 2007) where NOR was formulated with a generative model, we regard the NOR task as a classification problem.",
        "We further propose using a discriminative learning algorithm (Maximum Entropy model: MaxEnt) to solve the problem.",
        "To draw direct comparison, we conduct experiments on the same personal name corpora as that in the previous work by Li et al.",
        "(2006).",
        "We show that the MaxEnt method effectively incorporates diverse features and outperforms previous methods consistently across all test cases.",
        "The rest of the paper is organized as follows: in section 2, we review the previous work.",
        "Section 3 elaborates our proposed approach and the features.",
        "Section 4 presents our experimental setup and reports our experimental results.",
        "Finally, we conclude the work in section 5."
      ]
    },
    {
      "heading": "2. Related Work",
      "text": [
        "Most of previous work focuses mainly on ENOR although same methods can be extended to CNOR.",
        "We notice that there are two informative clues that used in previous work in ENOR.",
        "One is the lexical structure of a romanization system, for example, Hanyu Pinyin, Mandarin Wade-Giles, Japanese Hepbrun or Korean Yale, each has a finite set of syllable inventory (Li et al., 2006).",
        "Another is the phonetic and phonotactic structure of a language, such as phonetic composition, syllable structure.",
        "For example, English has unique consonant clusters such as /str/ and /ks/ which Chinese, Japanese and Korean (CJK) do not have.",
        "Considering the NOR solutions by the use of these two clues, we can roughly group them into two categories: rule-based methods (for solutions based on lexical structures) and statistical methods (for solutions based on phonotactic structures).",
        "Rule-based Method",
        "Kuo and Yang (2004) proposed using a rule-based method to recognize different romanization system for Chinese only.",
        "The left-to-right longest match-based lexical segmentation was used to parse a test word.",
        "The romanization system is confirmed if it gives rise to a successful parse of the test word.",
        "This kind of approach (Qu and Grefen-stette, 2004) is suitable for romanization systems that have a finite set of discriminative syllable inventory, such as Pinyin for Chinese Mandarin.",
        "For the general tasks of identifying the language origin and romanization system, rule based approach sounds less attractive because not all languages have a finite set of discriminative syllable inventory.",
        "Statistical Method",
        "1) N-gram Sum Method (SUM): Qu and Gre-fenstette (2004) proposed a NOR identifier using a trigram language model (Cavnar and Trenkle, 1994) to distinguish personal names of three language origins, namely Chinese, Japanese and English.",
        "In their work, the training set includes 11,416 Chinese name entries, 83,295 Japanese name entries and 88,000 English name entries.",
        "However, the trigram is defined as the joint probabil-",
        "ity p(cpi_1ci_2) for 3-character cici_1ci_2 rather than the commonly used conditional probability p(ci | c__1ci_2) .",
        "Therefore, the so-called trigram in Qu and Grefenstette (2004) is basically a substring unigram probability, which we refer to as the n-gram (n-character) sum model (SUM) in this paper.",
        "Suppose that we have the unigram count C(cjcj_lcj_2) for character substring cjcj_1ci_2 , the unigram is then computed as:",
        "which is the count of character substring cici_1ci_2 normalized by the sum of all 3-character string counts in the name list for the language of interest.",
        "For origin recognition of Japanese names, this method works well with an accuracy of 92%.",
        "However, for English and Chinese, the results are far behind with a reported accuracy of 87% and 70% respectively.",
        "2) N-gram Perplexity Method (PP): Li et al.",
        "(2006) proposed using n-gram character perplexity PPc to identify the origin of a Latin-scripted name.",
        "Using bigram, the PPc is defined as:",
        "where Nc is the total number of characters in the test name, c is the th character in the test name.",
        "p(ci | c_1) is the bigram probability which is learned from each name list respectively.",
        "As a function of model, PPc measures how good the model matches the test data.",
        "Therefore, PPc can be used to measure how good a test name matches a training set.",
        "A test name is identified to belong to a language if the language model gives rise to the minimum perplexity.",
        "Li et al.",
        "(2006) shown that the PP method gives much better performance than the SUM method.",
        "This may be due to the fact that the PP measures the normalized conditional probability rather than the sum of joint probability.",
        "Thus, the PP method has a clearer mathematical interpretation than the SUM method.",
        "The statistical methods attempt to overcome the shortcoming of rule-based method, but they suffer from data sparseness, especially when dealing with a large character set, such as in Chinese (our experiments will demonstrate this point empirically).",
        "In this paper, we propose using Maximum Entropy (MaxEnt) model as a general framework for both ENOR and CNOR.",
        "We explore and integrate multiple features into the discriminative classifier and use a common dataset for benchmarking.",
        "Experimental results show that the MaxEnt model effectively incorporates diverse features to demonstrate competitive performance."
      ]
    },
    {
      "heading": "3. MaxEnt Model and Features",
      "text": [
        "The principle of maximum entropy (MaxEnt) model is that given a collection of facts, choose a model consistent with all the facts, but otherwise as uniform as possible (Berger et al., 1996).",
        "Max-Ent model is known to easily combine diverse features.",
        "For this reason, it has been widely adopted in many natural language processing tasks.",
        "The MaxEnt model is defined as:",
        "where ci is the outcome label, x is the given observation, also referred to as an instance.",
        "Z is a normalization factor.",
        "N is the number of outcome labels, the number of language origins in our case.",
        "f1, f2,l, fK are feature functions and",
        "a1, a2, l , aK are the model parameters.",
        "Each parameter corresponds to exactly one feature and can be viewed as a \"weight\" for the corresponding feature.",
        "In the NOR task, c is the name origin label; x is a personal name, fi is a feature function.",
        "All features used in the MaxEnt model in this paper are binary.",
        "For example:",
        "In our implementation, we used Zhang's maximum entropy package.",
        "Let us use English name \"Smith\" to illustrate the features that we define.",
        "All characters in a name are first converted into upper case for ENOR before feature extraction.",
        "N-gram Features: N-gram features are designed to capture both phonetic and orthographic structure information for ENOR and orthographic information only for CNOR.",
        "This is motivated by the facts that: 1) names written in English but from non-English origins follow different phonetic rules from the English one; they also manifest different character usage in orthographic form; 2) names written in Chinese follows the same pronunciation rules (Pinyin), but the usage of Chinese characters is distinguishable between different language origins as reported in Table 2 of (Li et al., 2007).",
        "The N-gram related features include:",
        "3) FTri: character trigram <SMI, MIT, ITH >",
        "Position Specific n-gram Features: We include position information into the n-gram features.",
        "This is mainly to differentiate surname from given name in recognizing the origin of CJK personal names written in Chinese.",
        "For example, the position specific n-gram features of a Chinese name \"M^S(Wen-Jia-Bao)\" are as follows:",
        "3) FPTri: position specific trigram <0 ^Jt^(Wen-Jia-Bao)>",
        "Phonetic Rule-based Features: These features are inspired by the rule-based methods (Kuo and Yang, 2004; Qu and Grefenstette, 2004) that check whether an English name is a sequence of syllables of CJK languages in ENOR task.",
        "We use the following two features in ENOR task as well.",
        "1) FMan: a Boolean feature to indicate whether a name is a sequence of Chinese Mandarin Pinyin.",
        "2) FCan: a Boolean feature to indicate whether a name is a sequence of Cantonese Jyutping.",
        "Other Features:",
        "1) FLen: the number of Chinese characters in a given name.",
        "This feature is for CNOR only.",
        "The numbers of Chinese characters in personal names vary with their origins.",
        "For example, Chinese and Korean names usually",
        "consist of 2 to 3 Chinese characters while Japanese names can have up to 4 or 5 Chinese characters 2) FFre: the frequency of n-gram in a given name.",
        "This feature is for ENOR only.",
        "In CJK names, some consonants or vowels usually repeat in a name as the result of the regular syllable structure.",
        "For example, in the Chinese name \"Zhang Wanxiang\", the bigram \"an\" appears three times Please note that the trigram and position specific trigram features are not used in CNOR due to anticipated data sparseness in CNOR."
      ]
    },
    {
      "heading": "4. Experiments",
      "text": [
        "We conduct the experiments to validate the effectiveness of the proposed method for both ENOR and CNOR tasks.",
        "Origin # entries Romanization System",
        "Table 1: DE: Latin-scripted personal name corpus for ENOR Origin # entries",
        "Table 2: DC: Personal name corpus written in Chinese characters for CNOR Datasets: We prepare two data sets which are collected from publicly accessible sources: DE and DCfor the ENOR and CNOR experiment respectively.",
        "DE is the one used in (Li et al., 2006), consisting of personal names of Japanese (Jap), Chinese (Man), Cantonese (Can) and English (Eng) origins.",
        "DC consists of personal names of Japanese (Jap), Chinese (Chi, including both Mandarin and Cantonese) and English (Eng) origins.",
        "Table 1 and Table 2 list their details.",
        "In the experiments, 90% of entries in Table 1 (DE) and Table 2 (DC) are randomly selected for training and the remaining 10% are kept for testing for each language origin.",
        "Columns 2 and 3 in Tables 7 and 8 list the numbers of entries in the training and test sets.",
        "Evaluation Methods: Accuracy is usually used to evaluate the recognition performance (Qu and Gregory, 2004; Li et al., 2006; Li et al., 2007).",
        "However, as we know, the individual accuracy used before only reflects the performance of recall and does not give a whole picture about a multi-class classification task.",
        "Instead, we use precision (P), recall (R) and F-measure (F) to evaluate the performance of each origin.",
        "In addition, an overall accuracy (Acc) is also given to describe the whole performance.",
        "The P, R, F and Acc are calculated as following:",
        "P = # correctly recognized entries of the given origin # entries recognized as the given origin by the system",
        "# correctly recognized entries of the given origin R =- # entries of the given origin",
        "F = 2PR a = # all correctly recognized entries P + R # all entries",
        "Table 3 reports the experimental results of ENOR.",
        "It shows that the MaxEnt approach achieves the best result of 98.44% in overall accuracy when combining all the diverse features as listed in Subsection 3.2.",
        "Table 3 also measures the contributions of different features for ENOR by gradually incorporating the feature set.",
        "It shows that:",
        "1) All individual features are useful since the performance increases consistently when more features are being introduced.",
        "2) Bigram feature presents the most informative feature that gives rise to the highest",
        "performance gain, while the trigram feature further boosts performance too.",
        "3) MaxEnt method can integrate the advantages of previous rule-based and statistical methods and easily integrate other features.",
        "Features",
        "Origin",
        "P(%)",
        "R(%)",
        "Acc(%)",
        "FUni",
        "Eng 91.40 80.76 85.75 Man 83.05 81.90 82.47 Can 81.13 82.76 81.94 .Jap 87.31 94.11 90.58",
        "+FBi",
        "Eng 97.54 91.10 94.21",
        "Man 97.51 98.10 97.81 96.72Can 97.68 98.05 97.86 96.72",
        "Jap 94.62 98.24 96.39",
        "+FTri",
        "Eng 97.71 93.79 95.71 Man 98.94 99.37 99.16 Can 99.12 99.19 99.15 .Jap 96.19 98.52 97.34",
        "+FPUni",
        "Eng 97.53 94.64 96.06",
        "Man 99.21 99.43 99.32 98.16Can 99.41 99.24 99.33 98.16",
        "Jap 96.48 98.49 97.47",
        "+FPBi",
        "Eng 97.68 94.98 96.31 Man 99.32 99.50 99.41 98 28Can 99.53 99.34 99.44 .Jap 96.59 98.52 97.55",
        "+FPTri",
        "Eng 97.62 94.97 96.27",
        "Man 99.34 99.58 99.46 98.30Can 99.63 99.37 99.50 98.30",
        "Jap 96.61 98.45 97.52",
        "+FFre",
        "Eng 97.74 95.06 96.38 Man 99.37 99.59 99.48 Can 99.61 99.41 99.51 .Jap 96.66 98.56 97.60",
        "+ FMan + FCan",
        "Eng 97.82 95.11 96.45",
        "Man 99.52 99.68 99.60 98.44Can 99.71 99.59 99.65 98.44",
        "Jap 96.69 98.59 97.63",
        "Table 4 reports the feature weights of two features \"FMan\" and \"FCan\" with regard to different origins in ENOR task.",
        "It shows that \"FCan\" has positive weight only for origin \"Can\" while \"FMan\" has positive weights for both origins \"Man\" and \"Jap\", although the weight for \"Man\" is higher.",
        "This agrees with our observation that the two features favor origins \"Man\" or \"Can\".",
        "The feature weights also reflect the fact that some Japanese names can be successfully parsed by the Chinese Mandarin Pinyin system due to their similar syllable structure.",
        "For example, the Japanese name \"Tanaka Miho\" is also a sequence of Chinese Pinyin: \"Ta-na-ka Mi-ho\".",
        "Table 5 reports the contributions of different features in CNOR task by gradually incorporating the feature set.",
        "It shows that:",
        "1) Unigram features are the most informative",
        "2) Bigram features degrade performance.",
        "This is largely due to the data sparseness problem as discussed in Section 3.2.",
        "3) FLen is also useful that confirms our intuition about name length.",
        "Finally the combination of the above three useful features achieves the best performance of 98.10% in overall accuracy for CNOR as in the last row of Table 5.",
        "In Tables 3 and 5, the effectiveness of each feature may be affected by the order in which the features are incorporated, i.e., the features that are added at a later stage may be underestimated.",
        "Thus, we conduct another experiment using \"all-but-one\" strategy to further examine the effectiveness of each kind of features.",
        "Each time, one type of the n-gram (n=1, 2, 3) features (including orthographic n-gram, position-specific and n-gram frequency features) is removed from the whole feature set.",
        "The results are shown in Table 6.",
        "Table 6 reveals that removing trigram features affects the performance most.",
        "This suggests that trigram features are much more effective for ENOR than other two types of features.",
        "It also shows that trigram features in ENOR does not suffer from the data sparseness issue.",
        "Feature",
        "12 2 k t Or P R Ac",
        "FUni",
        "Eng 97.89 98.43 98.16",
        "Chi 95.8G 95.G3 95.42 96.97",
        "Jap 96.96 97.G5 97.GG",
        "+FBi",
        "Eng 96.99 98.27 97.63",
        "Chi 96.86 92.11 94.43 96.28",
        "Jap 95.G4 97.73 96.36",
        "+FLen",
        "Eng 97.35 98.38 97.86",
        "Chi 97.29 95.GG 96.13 97.14",
        "Jap 96.78 97.64 97.21",
        "+FPUni",
        "Eng 97.74 98.65 98.19",
        "Chi 97.65 96.34 96.99 97.77",
        "Jap 97.91 98.G5 97.98",
        "+FPBi",
        "Eng 97.5G 98.43 97.96",
        "Chi 97.61 96.G4 96.82 97.56",
        "Jap 97.59 97.94 97.76",
        "FUni",
        "+FLen",
        "+",
        "FPUni",
        "Eng 98.G8 99.G4 98.56",
        "Chi 97.57 96.88 97.22 98 1G",
        "Jap 98.58 98.11 98.34",
        "Features",
        "Origin",
        "P(%)",
        "R(%)",
        "fen",
        "Acc(%)",
        "w/o",
        "Unigram",
        "Eng",
        "97.81",
        "95.G1",
        "96.39",
        "Man Can Jap",
        "99.41 99.53",
        "96.63",
        "99.58 99.48 98.52",
        "99.49 99.5G 97.57",
        "98.34",
        "Eng",
        "97.34",
        "95.17",
        "96.24",
        "w/o Bigram",
        "Man Can",
        "99.3G 99.54",
        "99.48 99.33",
        "99.39 99.43",
        "98.26",
        "Jap",
        "96.73",
        "98.32",
        "97.52",
        "w/o",
        "Tri-",
        "gram",
        "Eng",
        "97.57",
        "94.1G",
        "95.8G",
        "Man Can Jap",
        "98.98 99.2G",
        "96.G6",
        "99.23 99.G8",
        "98.42",
        "99.1G 99.14",
        "97.23",
        "97.94",
        "accuracy is obtained when removing unigram features, which is much lower than 98.10% when bigram features are removed.",
        "This suggests that unigram features are very useful in CNOR, which is mainly due to the data sparseness problem that bigram features may have encountered.",
        "Table 7 (ENOR) and Table 8 (CNOR) compare our MaxEnt model with the SUM model (Qu and Gregory, 2004) and the PP model (Li et al., 2006).",
        "All the experiments are conducted on the same data sets as described in section 4.1.",
        "Tables 7 and 8 show that the proposed MaxEnt model outperforms other models.",
        "The results are statistically significant ( x test with p<0.01) and consistent across all tests.",
        "Model Complexity:",
        "We look into the complexity of the models and their effects.",
        "Tables 7 and 8 summarize the overall accuracy of three models.",
        "Table 9 reports the numbers of parameters in each of the models.",
        "We are especially interested in a comparison between the MaxEnt and PP models because their performance is close.",
        "We observe that, using trigram features, the MaxEnt model has many more parameters than the PP model does.",
        "Therefore, it is not surprising if the MaxEnt model outperforms when more training data are available.",
        "However, the experiment results also show that the MaxEnt model consistently outperforms the PP model even with the same size of training data.",
        "This is largely attributed to the fact that MaxEnt incorporates more robust features than the PP model does, such as rule-based, length of names features.",
        "One also notices that PP clearly outperforms SUM by using the same number of parameters in ENOR and shows comparable performance in",
        "CNOR tasks.",
        "Note that SUM and PP are different in two areas: one is the PP model employs word length normalization while SUM doesn't; another that the PP model uses n-gram conditional probability while SUM uses n-character joint probability.",
        "We believe that the improved performance of PP model can be attributed to the effect of usage of conditional probability, rather than length normalization since length normalization does not change the order of probabilities.",
        "Data Sparesness:",
        "We understand that we can only assess the effectiveness of a feature when sufficient statistics is available.",
        "In CNOR (see Table 8), we note that the Chinese transliterations of English origin use only 377 Chinese characters, so data sparseness is not a big issue.",
        "Therefore, bigram SUM and bigram PP methods easily achieve good performance for English origin.",
        "However, for Japanese origin (represented by 1413 Chinese characters) and Chinese origin (represented by 2319 Chinese characters), the data sparseness becomes acute and causes performance degradation in SUM and PP models.",
        "We are glad to find that MaxEnt still maintains a good performance benefiting from other robust features.",
        "Table 10 compares the overall accuracy of the three methods using unigram and bigram features in CNOR task, respectively.",
        "It shows that the MaxEnt method achieves best performance.",
        "Another interesting finding is that unigram features perform better than bigram features for PP and MaxEnt models, which shows that data sparseness remains an issue even for MaxEnt model."
      ]
    },
    {
      "heading": "5. Conclusion",
      "text": [
        "We propose using MaxEnt model to explore diverse features for name origin recognition.",
        "Experiment results show that our method is more effective than previously reported methods.",
        "Our contributions include:",
        "1) Cast the name origin recognition problem as a multi-class classification task and propose a MaxEnt solution to it;",
        "2) Explore and integrate diverse features for name origin recognition and propose the most effective feature sets for ENOR and",
        "for CNOR",
        "In the future, we hope to integrate our name origin recognition method with a machine transliteration engine to further improve transliteration performance.",
        "We also hope to study the issue of name origin recognition in context of sentence and use contextual words as additional features.",
        "Origin # training # test entries entries",
        "Trigram SUM P (%) R(%) F",
        "Trigram PP P(%) R(%) F",
        "MaxEnt P(%) R(%) F",
        "Eng 79,920 8,879",
        "Man 104,291 11,588 Can 104,165 11,574",
        "Jap 110,951 12,324",
        "94.66 72.5G 82.11 86.79 94.87 9G.65 9G.G3 93.87 91.91 89.17 92.84 9G.96",
        "95.84 94.72 95.28 98.99 98.33 98.66 96.17 99.67 97.89 98.2G 96.29 97.24",
        "97.82 95.11 96.45",
        "99.52 99.68 99.60 99.71 99.59 99.65",
        "96.69 98.59 97.63",
        "Overall Acc (%)",
        "89.57",
        "97.39",
        "98.44",
        "Origin # training entries",
        "# test",
        "entries",
        "Bigram SUM P(%) R(%) F",
        "Bigram PP P(%) R(%) F",
        "P(%)",
        "MaxEnt",
        "R(%)",
        "F",
        "Eng 37,644 Chi 29,795 Jap 33,897",
        "3,765 2,98G 3,39G",
        "95.94 98.65 97.28 96.26 87.35 91.59 93.G1 97.67 95.28",
        "97.58 97.61 97.6G 95.1G 87.35 91.G6 9G.94 97.43 94.G7",
        "98.G8 97.57 98.58",
        "99.G4 96.88 98.11",
        "98.56 97.22 98.34",
        "Overall Acc (%)",
        "95.GG",
        "94.53",
        "98.10",
        "Methods",
        "# of parameters for ENOR",
        "# of parameters for CNOR",
        "Trigram",
        "Unigram",
        "Bigram",
        "MaxEnt",
        "124,692",
        "13,496",
        "182,116",
        "PP",
        "16,851",
        "4,G45",
        "86,49G",
        "SUM",
        "16,851",
        "4,G45",
        "86,49G"
      ]
    }
  ]
}
