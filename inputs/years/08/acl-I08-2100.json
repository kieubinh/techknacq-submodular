{
  "info": {
    "authors": [
      "Masaki Murata",
      "Sachiyo Tsukawaki",
      "Toshiyuki Kanamaru",
      "Qing Ma",
      "Hitoshi Isahara"
    ],
    "book": "Proceedings of the Third International Joint Conference on Natural Language Processing",
    "id": "acl-I08-2100",
    "title": "Non-Factoid Japanese Question Answering through Passage Retrieval that Is Weighted Based on Types of Answers",
    "url": "https://aclweb.org/anthology/I08-2100",
    "year": 2008
  },
  "references": [
    "acl-N04-1008",
    "acl-P02-1054"
  ],
  "sections": [
    {
      "text": [
        "Masaki Murata and Sachiyo Tsukawaki Toshiyuki Kanamaru",
        "National Institute of Information and Kyoto University",
        "Communications Technology Yoshida-Nihonmatsu-Cho, Sakyo",
        "3-5 Hikaridai, Seika-cho, Soraku-gun, Kyoto, 606-8501 Japan",
        "Kyoto 619-0289, Japan kanamaru@hi.h.kyoto-u.ac.jp {murata,tsuka}@nict.go.jp",
        "We constructed a system for answering non-factoid Japanese questions.",
        "We used various methods of passage retrieval for the system.",
        "We extracted paragraphs based on terms from an input question and output them as the preferred answers.",
        "We classified the non-factoid questions into six categories.",
        "We used a particular method for each category.",
        "For example, we increased the scores of paragraphs including the word \"reason\" for questions including the word \"why.\"",
        "We participated at NTCIR-6 QAC-4, where our system obtained the most correct answers out of all the eight participating teams.",
        "The rate of accuracy was 0.77, which indicates that our methods were effective."
      ]
    },
    {
      "heading": "1. Introduction",
      "text": [
        "A question-answering system is an application designed to produce the correct answer to a question given as input.",
        "For example, when \"What is the capital of Japan?\"",
        "is given as input, a question-answering system may retrieve text containing sentences like \"Tokyo is Japan's capital and the country's largest and most important city\", and \"Tokyo is also one of Japan's 47 prefectures\", from Websites, newspaper articles, or encyclopedias.",
        "The system then outputs \"Tokyo\" as the correct answer.",
        "We believe question-answering systems will become",
        "Hitoshi Isahara",
        "National Institute oflnformation and",
        "Communications Technology 3-5 Hikaridai, Seika-cho, Soraku-gun, Kyoto 619-0289, Japan isahara@nict.go.jp",
        "a more convenient alternative to other systems designed for information retrieval and a basic component of future artificial intelligence systems.",
        "Numerous researchers have recently been attracted to this important topic.",
        "These researchers have produced many interesting studies on question-answering systems (Kupiec, 1993; Ittycheriah et al., 2001; Clarke et al., 2001; Dumis et al., 2002; Magnini et al., 2002; Moldovan et al., 2003).",
        "Evaluation conferences and contests on question-answering systems have also been held.",
        "In particular, the U.S.A. has held the Text REtrieval Conferences (TREC) (TREC-10 committee, 2001), and Japan has hosted the Question-Answering Challenges (QAC) (National Institute of",
        "Informatics, 2002) at NTCIR (NII Test Collection for IR Systems ) 3.",
        "These conferences and contests have aimed at improving question-answering systems.",
        "The researchers who participate in these create question-answering systems that they then use to answer the same questions, and each system's performance is then evaluated to yield possible improvements.",
        "We addressed non-factoid question answering in NTCIR-6 QAC-4.",
        "For example, when the question was \"Why are people opposed to the Private Information Protection Law?\"",
        "the system retrieved sentences based on terms appearing in the question and output an answer using the retrieved sentences.",
        "Numerous studies have addressed issues that are involved in the answering of non-factoid questions (Berger et al., 2000; Blair-Goldensohn et al., 2003; al., 2006; Asada, 2006).",
        "We constructed a system for answering non-factoid Japanese questions for QAC-4.",
        "We used methods of passage retrieval for the system.",
        "We extracted paragraphs based on terms from an input question and output them as the preferred answers.",
        "We classified the non-factoid questions into six categories.",
        "We used a particular method for each category.",
        "For example, we increased the scores of paragraphs including the word \"reason\" for questions including the word \"why.\"",
        "We performed experiments using the NTCIR-6 QAC-4 data collection and tested the effectiveness of our methods."
      ]
    },
    {
      "heading": "2. Categories of Non-Factoid Questions",
      "text": [
        "We used six categories of non-factoid questions in this study.",
        "We constructed the categories by consulting the dry run data in QAC-4.",
        "1.",
        "Definition-oriented questions (Questions that require a definition to be given in response.)",
        "2.",
        "Reason-oriented questions (Questions that require a reason to be given in response.)",
        "e.g., kojin jouhou hokogou ni hantai shiteiru hito wa doushite hantai shiteiru no desuka?",
        "(Why are people opposed to the Private Information Protection Law?)",
        "3.",
        "Method-oriented questions (Questions that require an explanation of a method to be given in response.)",
        "e.g., sekai isan wa donoyouni shite kimeru no desuka?\"",
        "(How is a World Heritage Site determined?)",
        "4.",
        "Degree-oriented questions (Questions that require an explanation ofthe degree ofsomething to be given in response.)",
        "5.",
        "Change-oriented questions (Questions that require a description of things that change to be given in response.)",
        "e.g., shounen hou wa dou kawari mashitaka?",
        "(How was the juvenile law changed?)",
        "6.",
        "Detail-oriented questions (Questions that require a description of the particulars or details surrounding a sequence of events to be given in response.)",
        "e.g., donoyouna keii de ryuukyuu oukoku wa ni-hon no ichibu ni natta no desuka?",
        "(How did Ryukyu come to belong to Japan?)"
      ]
    },
    {
      "heading": "3. Question-answering Systems in this",
      "text": [
        "The system has three basic components:"
      ]
    },
    {
      "heading": "1.. Prediction of type of answer",
      "text": [
        "The system predicts the answer to be a particular type of expression based on whether the input question is indicated by an interrogative pronoun, an adjective, or an adverb.",
        "For example, if the input question is \"Why are people opposed to the Private Information Protection Law?",
        "\", the word \"why\" suggests that the answer will be an expression that describes a reason."
      ]
    },
    {
      "heading": "2.. Document retrieval",
      "text": [
        "The system extracts terms from the input question and retrieves documents by using these terms.",
        "Documents that are likely to contain the correct answer are thus gathered during the retrieval process.",
        "For example, for the input question \"Why are people opposed to the Private Information Protection Law?",
        "\", the system extracts \"people,\" \"opposed,\" \"Private,\" \"Information,\" \"Protection,\" and \"Law\" as terms and retrieves the appropriate documents based on these."
      ]
    },
    {
      "heading": "3.. Answer detection",
      "text": [
        "The system separates the retrieved documents into paragraphs and retrieves those that contain terms from the input question and a clue expression (e.g., \"to wa\" (copula sentence) for the definition sentence).",
        "The system outputs the retrieved paragraphs as the preferred answer.",
        "We used the following rules for predicting the type of answer.",
        "We constructed the rules by consulting the dry run data in QAC-4.",
        "1.",
        "Definition-oriented questions Questions including expressions such as \"to wa nani,\" \"donna,\" \"douiu,\" \"douitta,\" \"nanimono,\" \"donoyouna mono,\" \"donna mono,\" and \"douiu koto\" (which all mean \"what is\") are recognized by the system as being definition-oriented questions.",
        "2.",
        "Reason-oriented questions Questions including expressions such as \"naze\" (why), \"naniyue\" (why), \"doushite\" (why), \"nani ga riyuu de\" (what is the reason), and \"donna riyuu de\" (what reason), are recognized by the system as being reason-oriented questions.",
        "3.",
        "Method-oriented questions Questions including expressions such as \"dou,\" \"dousureba,\" \"douyatte,\" \"dono youni shite,\" \"ikani shite,\" \"ikani,\" and \"donnna houhou de\" (which all mean \"how\") are recognized by the system as being method-oriented questions.",
        "4.",
        "Degree-oriented questions Questions including expressions such as \"dorekurai\" (how much), \"dorekurai no\" (to what extent), and \"dono teido\" (to what extent), are recognized by the system as being degree-oriented questions.",
        "5.",
        "Change-oriented questions Questions including expressions such as \"naniga chigau\" (What is different), \"donoyuni kawaru\" (How is ... changed), and \"dokoga kotonaru\" (What is different), are recognized by the system as being change-oriented questions.",
        "6.",
        "Detail-oriented questions Questions including expressions such as \"dono you na keii,\" \"dono you na ikisatsu,\" and \"dono you na nariyuki\" (which all mean \"how was\") are recognized by the system as being detail-oriented questions.",
        "Our system extracts terms from a question by using the morphological analyzer, ChaSen (Matsumoto et al., 1999).",
        "The analyzer first eliminates prepositions, articles, and similar parts of speech.",
        "It then retrieves documents by using the extracted terms.",
        "The documents are retrieved as follows: We first retrieve the top kdri documents with the highest scores calculated using the equation",
        "Score(d)",
        "where d is a document, t is a term extracted from a question, and tf (d, t) is the frequency of t occurring in d. Here, df (t) is the number of documents in which t appears, N is the total number of documents, length(d) is the length of d, and A is the average length of all documents.",
        "Constants kt and k+ are defined based on experimental results.",
        "We based this equation on Robertson's equation (Robertson and Walker, 1994; Robertson et al., 1994).",
        "This approach is very effective, and we have used it extensively for information retrieval (Murata et al., 2000; Murata et al., 2001; Murata et al., 2002).",
        "The question-answering system uses a large number for kt.",
        "We extracted the top 300 documents and used them in the next procedure.",
        "In detecting answers, our system first generates candidate expressions for them from the extracted documents.",
        "We use two methods for extracting candidate expressions.",
        "Method 1 uses a paragraph as a candidate expression.",
        "Method 2 uses a paragraph, two continuous paragraphs, or three continuous paragraphs as candidate expressions.",
        "We award each candidate expression the following score.",
        "Score(d) – mint1eT log",
        "where d is a candidate expression, T is the set of terms in the question, dist(tl,t2) is the distance between tl and t2 (defined as the number of characters between them with dist(t1,t2) = 0.5 when t1= t2), and length(d) is the number of characters in a candidate expression.",
        "The numerical term, 0.00000001 x length(d), is used for increasing the scores oflong paragraphs.",
        "For reason-oriented questions, our system uses some reason terms such as \"riyuu\" (reason), \"gen'in\" (cause), and \"nazenara\" (because) as terms for Eq.",
        "2 in addition to terms from the input question.",
        "This is because we would like to increase the score of a document that includes reason terms for reason-oriented questions.",
        "For method-oriented questions, our system uses some method terms such as \"houhou\" (method), \"tejun\" (procedure), and \"kotoniyori\" (by doing) as terms for second document retrieval (re-ranking) in addition to terms from the input question.",
        "For detail-oriented questions, our system uses some method terms such as \"keii\" (a detail, or a sequence of events), \"haikei\" (background), and \"rek-ishi\" (history) as terms for second document retrieval (re-ranking) in addition to terms from the input question.",
        "For degree-oriented questions, when candidate paragraphs include numerical expressions, the score (Score(d)) is multiplied by 1.1.",
        "For definition-oriented questions, the system first extracts focus expressions.",
        "When the question includes expressions such as \"X-wa\", \"X-towa\", \"X-toiunowa\", and \"X-tte\", X is extracted as a focus expression.",
        "The system multiplies the score, (Score(d)), of the candidate paragraph having \"X-wa\", \"X-towa or something by 1.1.",
        "When the candidate expression includes focus expressions having modifiers (including modifier clauses and modifier phrases), the modifiers are used as candidate expressions, and the scores ofthe candidate expressions are multiplied by 1.1.",
        "Below is an example of a candidate expression that is a modifier clause in a sentence.",
        "(There were a total oflOO questions.)",
        "Question sentence: sekai isan jouyaku to wa dono youna jouyaku desu ka?",
        "(What is the Convention concerning the Protection of the World Cultural and Natural Heritage?)",
        "Sentence including answers:",
        "1972 nen no dai 17 kai yunesuko soukai de saitaku sareta sekai isan jouyaku ....",
        "(Convention concerning the Protection of the World Cultural and Natural Heritage, which was adopted in 1972 in the 17th general assembly meeting of the UN Educational, Scientific and Cultural Organization.)",
        "Finally, our system extracts candidate expressions having high scores, (Score(d)s), as the preferred output.",
        "Our system extracts candidate expressions having scores that are no less than the highest score multiplied by 0.9 as the preferred output.",
        "We constructed the methods for answer detection by consulting the dry run data in QAC-4."
      ]
    },
    {
      "heading": "4. Experiments",
      "text": [
        "The experimental results are listed in Table 1.",
        "One hundred non-factoid questions were used in the experiment.",
        "The questions, which were generated by the QAC-4 organizers, were natural and not generated by using target documents.",
        "The QAC-4 organizers checked four or fewer outputs for each question.",
        "Methods 1 and 2 were used to determine what we used as answer candidate expressions (Method 1 uses one paragraph as a candidate answer.",
        "Method 2 uses one paragraph, two paragraphs, or three paragraphs as candidate answers.",
        ").",
        "\"A,\" \"B,\" \"C,\" and \"D\" are the evaluation criteria.",
        "\"A\" indicates output that describes the same content as that in the answer.",
        "Even if there is a supplementary expression in the output, which does not change the content, the output is judged to be \"A.\"",
        "\"B\" indicates output that contains some content similar to that in the answer but contains different overall content.",
        "\"C\" indicates output that contains part of the same content as that in the answer.",
        "\"D\" indicates output does not contain any of the same content as and \"D\" in Table 1 indicate the number of questions where an output belongs to \"A,\" \"B,\" \"C,\" and \"D\".",
        "Method",
        "Correct",
        "A",
        "B",
        "C",
        "D",
        "Method 1",
        "57",
        "18",
        "42",
        "10",
        "89",
        "Method 2",
        "77",
        "5",
        "67",
        "19",
        "90",
        "\"Correct\" indicates the number of questions where an output belongs to \"A,\" \"B,\" or \"C\".",
        "The evaluation criteria \"Correct\" was also used officially at NTCIR-6 QAC-4.",
        "We found the following.",
        "• Method 1 obtained higher scores in evaluation A than Method 2.",
        "This indicates that Method 1 can extract a completely relevant answer more accurately than Method 2.",
        "• Method 2 obtained higher scores in evaluation \"Correct\" than Method 1.",
        "The rate of accuracy for Method 2 was 0.77 according to evaluation \"Correct\".",
        "This indicates that Method 2 can extract more partly relevant answers than Method 1.",
        "When we want to extract completely relevant answers, we should use Method 1.",
        "When we want to extract more answers, including partly relevant answers, we should use Method 2.",
        "• Method 2 was the most accurate (0.77) of those used by all eight participating teams.",
        "We could detect paragraphs as answers including input terms and the key terms related to answer types based the methods discussed in Section 3.3.",
        "Our system obtained the best results because our method of detecting answers was the most effective.",
        "Below is an example of the output of Method 1, which was judged to be \"A.\"",
        "Question sentence:",
        "jusei ran shindan wa douiu baai ni okon-awareru noka?",
        "(When is amniocentesis performed on a pregnant woman?)",
        "System output:",
        "omoi idenbyou no kodono ga umareru no wo fusegu.",
        "(To prevent the birth of children with serious genetic disorders.)",
        "Examples of answers given by organizers:",
        "omoi idenbyou (A serious genetic disorder) omoi idenbyou no kodomo ga umareru kanousei ga takai baai"
      ]
    },
    {
      "heading": "5. Conclusion",
      "text": [
        "We constructed a system for answering non-factoid Japanese questions.",
        "An example of a non-factoid question is \"Why are people opposed to the Private Information Protection Law?\"",
        "We used various methods of passage retrieval for the system.",
        "We extracted paragraphs based on terms from an input question and output them as the preferred answers.",
        "We classified the non-factoid questions into six categories.",
        "We used a particular method for each category.",
        "For example, we increased the scores of paragraphs including the word \"reason\" for questions including the word \"why.\"",
        "We participated at NTCIR6 QAC-4, where our system obtained the most correct answers out of all the eight participating teams.",
        "The rate of accuracy was 0.77, which indicates that our methods were effective.",
        "We would like to apply our method and system to Web data in the future.",
        "We would like to construct a sophisticated system that can answer many kinds of complicated queries such as non-factoid questions based on a large amount ofWeb data."
      ]
    },
    {
      "heading": "Acknowledgements",
      "text": [
        "We are grateful to all the organizers of NTCIR-6 who gave us the chance to participate in their contest to evaluate and improve our question-answering system.",
        "We greatly appreciate the kindness of all those who helped us."
      ]
    }
  ]
}
