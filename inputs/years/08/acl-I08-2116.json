{
  "info": {
    "authors": [
      "Akinori Fujino",
      "Hideki Isozaki",
      "Jun Suzuki"
    ],
    "book": "Proceedings of the Third International Joint Conference on Natural Language Processing",
    "id": "acl-I08-2116",
    "title": "Multi-label Text Categorization with Model Combination based on F1-score Maximization",
    "url": "https://aclweb.org/anthology/I08-2116",
    "year": 2008
  },
  "references": [
    "acl-H05-1087"
  ],
  "sections": [
    {
      "text": [
        "Multi-label Text Categorization with Model Combination based on F\\-score Maximization",
        "Akinori Fujino, Hideki Isozaki, and Jun Suzuki",
        "Text categorization is a fundamental task in natural language processing, and is generally defined as a multi-label categorization problem, where each text document is assigned to one or more categories.",
        "We focus on providing good statistical classifiers with a generalization ability for multi-label categorization and present a classifier design method based on model combination and F1-score maximization.",
        "In our formulation, we first design multiple models for binary classification per category.",
        "Then, we combine these models to maximize the Fi-score of a training dataset.",
        "Our experimental results confirmed that our proposed method was useful especially for datasets where there were many combinations of category labels."
      ]
    },
    {
      "heading": "1. Introduction",
      "text": [
        "Text categorization is a fundamental task in such aspects of natural language processing as information retrieval, information extraction, and text mining.",
        "Since a text document often belongs to multiple categories in real tasks such as web pages and international patent categorization, text categorization is generally defined as assigning one or more predefined category labels to each data sample.",
        "Therefore, developing better classifiers with a generalization ability for such multi-label categorization tasks is an important issue in the field of machine learning.",
        "A major and conventional machine learning approach to multi-label categorization is based on binary classification.",
        "With this approach, we assume the independence of categories and design a binary classifier for each category that determines whether or not to assign a category label to data samples.",
        "Statistical classifiers such as the logistic regression model (LRM), the support vector machine (SVM), and naive Bayes are employed as binary classifiers (Joachims, 1998).",
        "In text categorization, the Fi score is often used to evaluate classifier performance.",
        "Recently, methods for training binary classifiers to maximize the Fi score have been proposed for SVM (Joachims, 2005) and LRM (Jansche, 2005).",
        "It was confirmed experimentally that these training methods were more effective for obtaining binary classifiers with better Fi score performance than the minimum error rate and maximum likelihood used for training conventional classifiers, especially when there was a large imbalance between positive and negative samples.",
        "In multi-label categorization, macro-and micro-averaged Fi scores are often used to evaluate classification performance.",
        "Therefore, we can expect to improve multi-label classification performance by using binary classifiers trained to maximize the Fi -score.",
        "On the other hand, classification frameworks based on classifier combination have also been studied in many previous works such as (Wolpert, 1992; Larkey and Croft, 1996; Ting and Witten, 1999; Ghahramani and Kim, 2003; Bell et al., 2005; Fumera and Roli, 2005), to provide better classifier systems.",
        "In the classifier combination research field, it is known that weighted linear combinations of multiple classifiers often provide better classification performance than individual classifiers.",
        "We present a classifier design method based on the combination of multiple binary classifiers to improve multi-label classification performance.",
        "In our framework, we first train multiple binary classifiers for each category.",
        "Then, we combine these binary classifiers with weights estimated to maximize micro-or macro-averaged Fi -scores, which are often used for evaluating multi-label classifiers.",
        "To estimate combination weights, we extend the Fi score maximization training algorithm for LRM described in (Jansche, 2005).",
        "Using three real text datasets, we show experimentally that our classifier design method is more effective than the conventional binary classification approaches to multi-label categorization.",
        "Our method is based on a binary classification approach.",
        "However, Kazawa et al.",
        "(2005) proposed a method for modeling a map directly from data samples to the combination of assigned category labels, and confirmed experimentally that the method outperformed conventional binary classification approaches.",
        "Therefore, we also compare our method with the direct mapping method experimentally."
      ]
    },
    {
      "heading": "2. F 1 score Maximization Training of LRM",
      "text": [
        "We first review the F1-score maximization training method for linear models using a logistic function described in (Jansche, 2005).",
        "The method was proposed in binary classification settings, where classifiers determine a class label assignment y 0} for a data sample represented by a feature vector x.",
        "Here, y(n) = 1 (=0) indicates that the class label is assigned (unassigned) to the nth feature vector .",
        "The discriminative function of a binary classifier based on a linear model is often defined as where 0 = (00,01)* is a model parameter vector, and 0lx implies the inner product of 01 and x.A binary classifier using f (x; 0) outputs a predicted class label assignment y for x as y(n) = 1 (=0) when f (x(n); 0) > 0(< 0).",
        "An LRM is a binary classifier that uses the discriminative function f(x; 0).",
        "In this model, the class posterior probability distribution is defined by using a logistic function:",
        "In this paper, the classifier design approach that employs this training method is called LRM-L.",
        "By contrast, in the training method proposed by (Jansche, 2005), the discriminative function f (x; w) is estimated to maximize the F1 score of training dataset D. This training method employs an approximate form of the F1 score obtained by using a logistic function.",
        "The F1-score is defined as F1 = 2(l/PR + l/REwhere PR and RE represent precision and recall defined as PR = C/A and RE = C/B, respectively.",
        "Here, C represents the number of data samples whose true and predicted class label assignments, y(n) and y(n), respectively, correspond to l. A represents the number of data samples for which y(n) = l. B represents the number of data samples for which y(n) = l. C, A, and B are computed for training dataset D as C = EM=1 y(m)y(m), A = EM=1 y(m),and B = y(m).",
        "In (Jansche, 2005), y(m) was approximated by using the discriminative and logistic functions shown in Eqs.",
        "(1) and (2) as because lim^oo g(7f (x(m); 0)) = y(m).",
        "Then, an approximate distribution of the F1 score for training dataset D was provided as g(z) = {l + exp-z)}\".",
        "The 0 estimate for the discriminative function f (x; 0) can be computed to maximize Jf (0) = log F1(0) + log p(0) around the initial 0 value by using a gradient method.",
        "In this paper, the classifier design approach that uses this training method is called LRM-F."
      ]
    },
    {
      "heading": "3. Proposed Method",
      "text": [
        "We propose a framework for designing a multi-label classifier based on the combination of multiple models.",
        "In our formulation, multiple models are combined with weights estimated to maximize the F1 scores of the training dataset.",
        "In this section, we show our formulation for model combination and training methods for combination weights.",
        "3.1 Combination of Multiple Models for Multi-label Categorization",
        "Multi-label categorization is the task of selecting multiple category labels from K predefined category labels for each data sample.",
        "Multi-label classifiers provide a map from a feature vector x to a category label assignment vector y = (y1,...,yk,...,yK)*, where y^n) = l (=0) indicates that the kth category label is assigned (unas-signed) to x(n).",
        "In our formulation, we first design multiple models for binary classification per category and obtain J x K discriminative functions, where J is the number of models.",
        "The discriminative function of the jth model for the kth category is denoted by fjk(x; 0jk), where 0jk represents the model parameter vector.",
        "Let 6 = {0jk}j,k be a model parameter set.",
        "We train model parameter vectors individually with each model training algorithm and obtain the estimate 6 = {0jk}jk.",
        "Then, we define the discriminative function of our multi-label classifier by combining multiple models such as where w = (w0,w1,...,Wj,...,wJ)* is a weight parameter vector and is independent of k. Wj provides the combination weight of the jth model, and wo is the bias factor for adjusting the threshold of the category label assignment.",
        "We estimate the w value to maximize the micro-averaged F1-score (FM), which is often used for evaluating multi-label categorization performance.",
        "The score of training dataset D = {x(m), y(m) }M=1 is calculated as",
        ">fc=ll/fc Vk",
        "We provide an approximate form of the Fß-score of the training dataset, Fß (6, w), by using the approximation:",
        "as shown in Eq.",
        "(4).",
        "In our proposed method, w is estimated to maximize F^ ( 6, w).",
        "However, training dataset D is also used to estimate .",
        "Using the same training data samples for both and w may lead to a bias estimation of w. Thus, we used an n-fold cross-validation of the training data samples to estimate w as in (Wolpert, 1992).",
        "Let 6(-m) be the model parameter set estimated by using n - l training data subsets not containing {x(m), y(m)}.",
        "Then, using we provide the objective function of w such that where p(w) is a prior probability density of w. We use a Gaussian prior (Chen and Rosenfeld, 1999) with the form as p(w) oc FJJ=0 exp{ – (wj ~ pj)/2<jj }, where <jj, and pj are hyperparameters in the Gaussian prior.",
        "We compute an estimate of w to maximize Jß(w) around the initial w value by using a quasi-Newton method.",
        "In this paper, this formulation is called model combination by micro-averaged F1-score maximization (MC-F,).",
        "In multi-label categorization problems, the macro-averaged F1-score (FM) is also used to evaluate classifiers.",
        "Moreover, the average labeling F1-score (Fl) has been used to evaluate the average labeling performance of classifiers for data samples (Kazawa et al., 2005).",
        "These F1-scores are computed for training dataset D as z l^k=\\ Vk Vk",
        "Using Eq.",
        "(8), we can also obtain the approximate forms, FM(6, w) and FL(6, w), of the FMand FL-scores, and then present similar objective functions to that for the FM-score.",
        "Therefore, in the next section, we examine experimentally the performance of classifiers obtained by estimating w to maximize FM( 6, w) and FL( 6, w).",
        "In this paper, these model combination methods based on FM-and FL-scores are called MC-FM and MC-FL, respectively."
      ]
    },
    {
      "heading": "4. Experiments",
      "text": [
        "To evaluate our proposed method empirically, we used three test collections: Reuters-21578 (Reuters), WIPO-alpha (WIPO), and Japanese Patent (JPAT) datasets.",
        "Reuters and WIPO are English document datasets and have often been employed for benchmark tests of multi-label classifiers.",
        "The Reuters dataset contains news articles from the Reuters newswire and consists of 135 topic categories.",
        "Following the setup in (Yang and Liu, 1999), we extracted 7770 and 3019 articles as training and test samples, respectively.",
        "A subset consisting of the training and test samples contained 90 topic categories.",
        "We removed vocabulary words included either in the stoplist or in only one article.",
        "There were 16365 vocabulary words in the dataset.",
        "The WIPO dataset consists of patent documents categorized using the International Patent Classification (IPC) taxonomy (Fall et al., 2003).",
        "The IPC taxonomy has four hierarchical layers: Section, Class, Subclass, and Group.",
        "Using patent documents belonging to Section D (textiles; paper), we evaluated classifiers in a task that consisted of selecting assigned category labels from 160 groups for each patent document.",
        "Following the setting provided in the dataset, we extracted 1352 and 358 patent documents as training and test samples, respectively.",
        "We removed vocabulary words in the same way as for Reuters.",
        "There were 45895 vocabulary words in the dataset.",
        "The JPAT dataset (Iwayama et al., 2007) consists of Japanese patent documents published between 1993 and 1999 by the Japanese Patent Office.",
        "These documents are categorized using a taxonomy consisting of Themes and F-terms.",
        "The themes are top-label categories, and the patent documents belonging to each theme are categorized by using F-",
        "Table 1: Statistical information of three datasets: Nav and Nmax are the average and maximum number of assigned category labels per data sample, respectively.",
        "K and Nds are the number of category labels and data samples, respectively.",
        "NLC is the number of category label combinations appearing in each dataset.",
        "terms.",
        "Using patent documents belonging to Theme 5J104, we evaluated classifiers in a task that consisted of selecting assigned category labels from 268 F-terms for each patent document.",
        "1920 patent documents published between 1993 and 1997 were used as training samples, and 544 patent documents published between 1998 and 1999 were used test samples.",
        "We extracted Japanese nouns, verbs, and adjectives from patent documents by using a morphological analyzer named MeCab , and removed vocabulary words included in only one patent document.",
        "There were 21135 vocabulary words in the dataset.",
        "Table 1 shows statistical information about the category label assignment of the data samples for the three datasets.",
        "The average numbers of assigned category labels per data sample, Nav, for Reuters and WIPO were close to 1 and much smaller than that for JPAT.",
        "The number of category label combinations, NLC, included in JPAT was larger than those for Reuters and WIPO.",
        "These statistical information results show that JPAT is a more complex multi-label dataset than Reuters or WIPO.",
        "For text categorization tasks, we employed word-frequency vectors of documents as feature vectors input into classifiers, using the independent word-based representation, known as the Bag-of-Words (BOW) representation.",
        "We normalized the L1-norms of the word-frequency vectors to 1, to mitigate the effect of vector size on computation.",
        "We did not employ any word weighting methods such as inverse document frequency (IDF).",
        "Reuters",
        "WIPO",
        "JPAT",
        "Nav",
        "1.17",
        "1.28",
        "10.5",
        "Nmax",
        "15",
        "6",
        "40",
        "K",
        "90",
        "160",
        "268",
        "Nds",
        "10789",
        "1710",
        "2464",
        "NLC",
        "468",
        "378",
        "2430",
        "Nds/NLC",
        "23.1",
        "4.52",
        "1.01",
        "We constructed three multi-label text classifiers based on our proposed model combination methods, MC-Fu, MC-Fm, and MC-FL, where LRM and SVM (J = 2) were employed as binary classification models combined with each method.",
        "We trained the LRM by using LRM-L described in Section 2, where a Gaussian prior was used as the prior probability density of the parameter vectors.",
        "We provided the SVM by using SVMlight (SVM-L), where we employed a linear kernel function and tuned the C (penalty cost) parameter as a hyperparameter.",
        "To evaluate our proposed method, we examined the micro-and macro-averaged, and average labeling F1-scores (Fu, FM, and FL), of test samples obtained with the three classifiers based on MC-Fu, MC-FM, and MC-FL.",
        "We compared the performance of the three classifiers with that of two binary classification approaches, where LRM-L or SVM-L was used for binary classification.",
        "We also examined two binary classification approaches using LRM-F and SVM-F. For LRM-F, we used a Gaussian prior and provided the initial parameter vector with a parameter estimate obtained with LRM-L. SVM-F is a binary classifier design approach that employs SVMPerf .",
        "For SVM-F, we used a linear kernel function, set the L (loss parameter) parameter to maximize the F1 -score, and tuned the C (penalty cost) parameter as a hyperparameter.",
        "Moreover, we examined the performance of the Maximal Margin Labeling (MML) method (Kazawa et al., 2005), which models the map from feature vectors to category label assignment vectors, because it was reported that MML provides better performance than binary classification approaches.",
        "We tuned the hyperparameter of SVM-F for JPAT to provide good performance for test samples, because the computational cost for training was high.",
        "We tuned the other hyperparameters by using a 10fold cross-validation of training samples.",
        "In Table 2, we show the classification performance obtained for three datasets with our proposed and other methods described in Section 4.2.",
        "We examined nine evaluation scores: the micro-averaged F1-score (Fu), precision (Pu), and recall (Ru), the",
        "Table 2: Micro-and macro-averaged, and average labeling F1-scores (%) with our proposed and conventional methods.",
        "macro-averaged F1 score (FM), precision (PM), and recall (RM), and the average labeling F1-score (FL), precision (PL), and recall (RL) of the test samples.",
        "FM and PM were calculated by regarding both the F1 score and precision as zero for the categories where there were no data samples predicted as positive samples.",
        "LRM-F and SVM-F outperformed LRM-L and",
        "SVM-L in terms of FM-score for the three datasets, respectively.",
        "The training methods of LRM-F and SVM-F were useful to improve the FM-scores of LRM and SVM, as reported in (Jansche, 2005; Joachims, 2005).",
        "The FM-and FL-scores of LRM-F were similar or better than those of LRM-L. LRM-F was effective in improving not only the FM-score but also the Fu- and FL-scores obtained with LRM.",
        "Let us evaluate our model combination methods.",
        "Method",
        "FM (FM/fiM) FM (Pm/Rm) Fl (Pl/Rm)",
        "MC-FMMC-Fm MC-FL",
        "87.0(87.4/86.7) 51.3 (60.0/48.4) 90.0 (90.1/92.3) 85.0(80.8/89.5) 53.9(54.9/58.4) 89.7 (88.5/94.1) 86.3 (84.3/88.3) 53.4 (59.6/52.6) 90.0 (89.3/93.6)",
        "LRM-L LRM-F",
        "85.2(87.3/83.2) 46.1 (55.0/43.1) 86.9 (87.6/88.6) 85.2 (87.2/83.2) 47.4 (58.5/42.7) 87.0 (87.6/88.7)",
        "SVM-L SVM-F",
        "87.1 (92.9/82.0) 48.9(58.9/45.8) 88.1 (89.3/88.8) 82.4(78.9/86.2) 51.4(49.4/60.1) 87.4 (86.9/91.4)",
        "MML",
        "87.8 (92.6/83.4) 59.3(62.6/60.0) 91.2(91.7/93.2)",
        "(a) Reuters",
        "Method",
        "FM (FM/fiM) FM (Pm/Rm) Fl (Pl/Rm)",
        "MC-FMMC-Fm MC-FL",
        "51.4(57.3/46.6) 30.4(35.8/30.3) 46.9 (48.3/51.5) 48.1 (46.1/50.4) 32.2(33.8/36.0) 46.8 (46.3/56.0) 48.6(45.8/51.9) 32.5(33.4/36.5) 47.1 (46.4/56.8)",
        "LRM-L LRM-F",
        "40.5 (68.0/28.9) 22.1 (33.7/17.9) 32.7 (36.5/32.0) 41.0(68.6/29.2) 22.3 (34.0/18.1) 33.2 (37.0/32.4)",
        "SVM-L SVM-F",
        "41.8(61.9/31.5) 24.4(34.2/21.0) 35.1 (38.8/35.3) 48.3 (53.8/43.8) 32.3 (37.4/31.8) 45.6 (47.9/49.6)",
        "MML",
        "48.6 (54.9/43.6) 30.8 (36.5/29.7) 49.4 (56.2/48.4)",
        "(b) WIPO",
        "Method",
        "FM (FM/fiM) FM (Pm/Rm) Fl (Pl/Rm)",
        "MC-FMMC-Fm MC-Fl",
        "41.8(42.6/41.1) 17.5 (21.4/17.4) 40.2 (43.5/44.4) 40.6(35.8/46.7) 20.2(20.4/23.1) 39.4(37.7/50.6) 42.1 (42.3/41.9) 17.6(21.1/17.8) 40.5(43.2/45.2)",
        "LRM-L LRM-F",
        "33.9 (44.4/27.4) 15.8 (20.9/14.0) 32.2 (46.5/29.9) 36.9(44.6/31.5) 16.9(22.9/14.7) 35.1 (47.3/34.1)",
        "SVM-L SVM-F",
        "33.3 (39.6/28.7) 16.3 (20.9/14.6) 31.9 (42.4/31.6) 32.2(28.6/36.8) 19.7(15.0/38.4) 31.0 (30.7/40.0)",
        "MML",
        "32.7 (42.1/26.8) 14.7(19.4/12.9) 32.2(51.8/30.5)",
        "MC-Fu provided better Fu-scores than LRM-F and SVM-F.",
        "The FM-scores of MC-FM were similar or better than those of LRM-F and SVM-F.",
        "Moreover, MC-FL outperformed LRM-F and SVM-F in terms of FL-scores.",
        "The binary classifiers designed by using LRM-F and SVM-F were trained to maximize the F1 score for each category.",
        "On the other hand, MC-Fu, MC-FM, and MC-FL classifiers were constructed by combining LRM and SVM with weights estimated to maximize the Fu-, FM-, and FL-scores, respectively.",
        "The experimental results show that our training methods for combination weights were useful for obtaining better multi-label classifiers.",
        "MC-Fu, MC-Fm, and MC-FL outperformed MML as regards the three F1 scores for JPAT.",
        "However, MML performed better for Reuters than MC-Fu, MC-FM, and MC-FL, and provided a better FL-score for WIPO.",
        "As shown in Table 1, there were more category label combinations for JPAT than for Reuters or WIPO.",
        "As a result, there were fewer data samples for the same category label assignment for JPAT.",
        "Therefore, MML, which learns the map directly from the feature vectors to the category label assignment vectors, would have been overfitted to the training dataset for JPAT.",
        "By contrast, our model combination methods employ binary classifiers for each category, which mitigates such an overfitting problem.",
        "Our model combination methods will be useful for complex datasets where there are many category label combinations."
      ]
    },
    {
      "heading": "5. Conclusion",
      "text": [
        "We proposed a multi-label classifier design method based on model combination.",
        "The main idea behind our proposed method is to combine multiple models with weights estimated to maximize evaluation scores such as the micro-and macro-averaged, and average labeling F1 -scores.",
        "Using three real text datasets, we confirmed experimentally that our proposed method provided similar or better performance than conventional binary classification approaches to multi-label categorization.",
        "We also confirmed that our proposed method was useful for datasets where there were many combinations of category labels.",
        "Future work will involve training our multi-label classifier by using labeled and un-labeled samples, which are data samples with and without category label assignment."
      ]
    }
  ]
}
