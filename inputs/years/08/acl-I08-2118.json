{
  "info": {
    "authors": [
      "Venkatesan T. Chakaravarthy",
      "Sachindra Joshi",
      "Ganesh Ramakrishnan",
      "Shantanu Godbole",
      "Sreeram Balakrishnan"
    ],
    "book": "Proceedings of the Third International Joint Conference on Natural Language Processing",
    "id": "acl-I08-2118",
    "title": "Learning Decision Lists with Known Rules for Text Mining",
    "url": "https://aclweb.org/anthology/I08-2118",
    "year": 2008
  },
  "references": [
    "acl-A92-1021",
    "acl-W00-0603"
  ],
  "sections": [
    {
      "text": [
        "Venkatesan Chakravarthy Sachindra Joshi Ganesh Ramakrishnan",
        "IBM India Research Lab IBM India Research Lab IBM India Research Lab",
        "Shantanu Godbole Sreeram Balakrishnan",
        "IBM India Research Lab IBM Silicon Valley Lab",
        "Many real-world systems for handling unstructured text data are rule-based.",
        "Examples of such systems are named entity annotators, information extraction systems, and text classifiers.",
        "In each of these applications, ordering rules into a decision list is an important issue.",
        "In this paper, we assume that a set of rules is given and study the problem (MaxDL) of ordering them into an optimal decision list with respect to a given training set.",
        "We formalize this problem and show that it is NP-Hard and cannot be approximated within any reasonable factors.",
        "We then propose some heuristic algorithms and conduct exhaustive experiments to evaluate their performance.",
        "In our experiments we also observe performance improvement over an existing decision list learning algorithm, by merely reordering the rules output by it."
      ]
    },
    {
      "heading": "1. Introduction",
      "text": [
        "Rule-based systems have been extensively used for several problems in text mining.",
        "Some problems in text mining where rule-based systems have been successfully used are part of speech tagging (Brill, 1992), named entity annotation (Grishman, 1997; Appelt et al., 1995), information extraction (May-nard et al., 2001), question answering (Riloff and Thelen, 2000) and classification (Han et al., 2003; Li and Yamanishi, 1999; Sasaki and Kita, 1998).",
        "Several studies have been conducted that compare the performance of rule-based systems and other machine learning techniques with mixed results.",
        "While there is no clear winner between the two approaches in terms of performance, the rule-based approach is clearly preferred in operational settings (Borth-wick, 1999; Varadarajan et al., 2002).",
        "Rule-based systems are human comprehensible and can be improved over time.",
        "Therefore, it is imperative to develop methods that assist in building rule-based systems.",
        "A rule-based system consists of a set of rules.",
        "These rules can either be manually designed or could be learnt from a training set using rule-induction techniques (J. and G, 1994; Cohen, 1995).",
        "Each rule consists of an antecedent or pattern and a consequent or predicted annotation.",
        "In this paper, we will restrict our attention to a broad class of rules in which the antecedent describes a series of conditions on the input item and the consequent specifies the label that applies to instances covered by the antecedent.",
        "The conditions could also be expressed as patterns in regular or more powerful grammars.",
        "In general, rules could be ambiguous, i.e., multiple rules could cover an instance.",
        "A common approach for resolving this ambiguity is to define an ordering on the rules (Maynard et al., 2001; Borth-wick, 1999).",
        "A decision list is one such mechanism (Rivest, 1987).",
        "A set of rules that are intended to be interpreted in a sequence is called a decision list.",
        "In other words, a decision list is an ordering of the given set of rules.",
        "Given an instance t, the rules are applied in the specified order until a pattern of a rule R covers t. The instance t is assigned the predicted annotation associated with R.",
        "In this paper, we study the problem of arranging a given set of rules into the \"best\" decision list.",
        "Learning decision lists using training data has been studied in the past (Rivest, 1987; J. and G, 1994; Cohen, 1995; Li and Yamanishi, 1999).",
        "These methods attempt to simultaneously learn rules and their ordering.",
        "Typically they use separate and conquer (Witten and Frank, 2005) strategy and order generated rules as they are discovered.",
        "The generation and ordering of rules are not considered as two separate tasks.",
        "In contrast, we assume that the rules are given to us and study the problem of arranging them into an optimal decision list, where optimality is determined over a training data set.",
        "Our approach is motivated by the observation that in many operational settings, it is easier and preferred to get a set of rules designed by domain experts (Lewis et al., 2003).",
        "Alternatively, the set of rules can be determined using existing techniques for rule learning (J. and G, 1994; Cohen, 1995; Califf and Mooney, 1998).",
        "The separation of rule ordering from rule generation allows us to analyze the problem of ordering in detail and to develop effective methods for rule ordering.",
        "We demonstrate the usefulness of the proposed methods for ordering manually designed rules in the task of named entity annotation and machine learnt rules in the task of classification.",
        "We determine the ordering of the given set of rules based on a training set.",
        "A training set consists of a set of pairs (tj,aj) where tj is an instance and ajis its actual annotation.",
        "Given a set of rules and a training data set, we define the problem as follows: Arrange the rules into a decision list such that maximum number of instances are assigned the correct annotation.",
        "We refer to this problem as the M axDL problem.",
        "We show that this problem is NP hard and cannot approximated within a factor of n1-e, for any e > 0.",
        "We then propose some heuristics and present an experimental study of these heuristics.",
        "Our experimental results show performance improvement over an existing decision list learning algorithm, by merely reordering the rules output by that algorithm.",
        "We also illustrate the performance improvements obtained by applying our algorithms for ordering named entity annotation rules and classification rules.",
        "In the rest of the paper we formalize the MaxDL problem (§2), show it is NP-hard and can't be approximated within reasonable factors (§3), and propose heuristics in a greedy framework (§4).",
        "We present experiments (§5) and conclude with Section§6."
      ]
    },
    {
      "heading": "2. MaxDL Problem Definition and Notations",
      "text": [
        "The input consists of a set of instances T = (t1; t2,..., tm}, a set of annotations A and a set of rules R = (R1; R2,..., Rn}.",
        "Each rule Rj = (p, a) is a pair, where p is called the pattern and a e A is called the predicted annotation.",
        "The patten p will be given as a set p C I; we say that the instances in p are covered by R. The input also includes a mapping A : T – A, that provides for each instance t an annotation A(t), called the actual annotation of t. The pair ( T, A) is the training data.",
        "Given the above input, a decision list L is an ordering (i.e. permutation) of the input rules.",
        "The list L assigns an annotation to each instance t as defined below.",
        "We consider each rule according to the ordering given by L until we find a rule Rj = (p, a) that covers t and assign the annotation a to t. We denote by L(t) the annotation assigned by L to t. Thus, L defines a function L : I – A.",
        "We say that the list L correctly annotates an instance t, if the annotation assigned by L matches the actual annotation of t, i.e., L(t) = A(t).",
        "Given the above input, the MaxDL problem is to to construct a decision list L such that the number of instances correctly annotated by L, is maximized i.e., we want to maximize |{t|A(t) = L(t)}| .",
        "Notations:",
        "Let R = ( p, a) be a rule and t be an instance covered by R. We say that a rule R correctly covers t, if a = A(t).",
        "Similarly, R said to incorrectly cover t, if a = A(t).",
        "Let L be a decision list.",
        "We say that an instance t is happy under L, if L correctly annotates t, i.e., L(t) = A(t).",
        "Let Happy(L) denote the set of instances that are happy under L. Notice that the M axDL problem asks for a decision list L such that |Happy(L)| is maximized."
      ]
    },
    {
      "heading": "3. NP Hardness and Inapproximability",
      "text": [
        "In this section, we prove that the MaxDL problem is NP-Hard and also show that the problem cannot even be approximated with any constant factor.",
        "Theorem 1 The MaxDL problem is NP-Hard.",
        "Proof: We give a reduction from the maximum independent set problem (MaxIS ), a well-known NP-Hard problem (Garey and Johnson, 1979).",
        "Recall that an independent set in a graph refers to any subset of vertices such that no two vertices from the set share an edge.",
        "The MaxIS problem is to find the largest independent set in a given undirected graph.",
        "Let G = (V, E) be the input graph having vertex set V = v2,..., vn}.",
        "We create an instance of the MaxDL problem as follows.",
        "For each vertex vj, we add an annotation aj to A, an instance tj to T and a rule Rj to R. We declare aj to be the actual annotation of tj.",
        "The predicted annotation of Rj is set to aj.",
        "We define Rj to cover only the instance tj and the instances corresponding to the neighbors of vj.",
        "Meaning, Rj covers the instances in the set {tj} U {tj Vj) e E}.",
        "This completes the reduction.",
        "We claim that given a decision list L having k happy instances, we can construct an independent set of size k and vice versa.",
        "The NP-Hardness of MaxDL follows from the claim.",
        "We now proceed to prove the claim.",
        "Consider a decision list L. Notice that for any instance tj, Rj is the only rule that correctly covers tj.",
        "Take any two different instances tj and tj that are happy under L. Without loss of generality, assume that Rj appears before Rj in L. Now, if Rj covers tj, tj would be unhappy under L. So, Rj does not cover tj, which implies that Vj is not a neighbor of vj (i.e., Vj) e E).",
        "Hence, the set / = {vj|tj e Happy(L)} is an independent set of G. We note that |11 = |Happy(L)|.",
        "Conversely, consider an independent set / of G. Let R(I) = {Rj|vj e /}.",
        "Form a decision list L by first arranging the rules from R(I) in any arbitrary order followed by arranging the rest of rules in any arbitray order.",
        "Notice that for any vertex vj e I, Rj correctly covers tj and no other rule appearing before Rj covers tj.",
        "Thus, tj is happy under L. It follows that |Happy(L)| > |11.",
        "We have proved that the MaxDL problem is NP-Hard.",
        "□",
        "In our NP-Hardness reduction, we had shown that given a decision list L, we can construct an independent set / such that |Happy(L)| = |11, and vice versa.",
        "This means that any approximation algorithm for the MaxDL problem can be translated (by combining it with our NP-Hardness reduction) into an equally good approximation algorithm for the MaxIS problem.",
        "Corollary 1 follows from (Zuck-erman, 2006).",
        "Corollary 1 If NP = P then for any e > 0, the MaxDL problem cannot approximated within a factor of n1-e.",
        "In particular, the problem is not approximable within any constant factor."
      ]
    },
    {
      "heading": "4. Heuristic Algorithms for the MaxDL Problem",
      "text": [
        "As the MaxDL problem is hard to approximate, we turn to heuristic approaches.",
        "All our heuristics fall into a natural greedy framework, described below.",
        "Our greedy framework for finding a decision list is as follows.",
        "In each iteration we greedily choose a rule and output it.",
        "For this purpose, we use some scoring function for assigning scores to the rules and choose the rule having the maximum score.",
        "Then the chosen rule is deleted.",
        "The process is continued until all the rules are output.",
        "The above procedure gives us a decision list.",
        "We present this general framework in the Figure 1.",
        "The only unspecified part in the above framework is the scoring function.",
        "Intuitively, the scoring function tries to measure the goodness of a rule.",
        "For a rule R and an instance t, we define following notations for further use:",
        "We now present our first candidate scoring function, which we call simple precision scoring.",
        "A natural score for a rule R is its precision: the fraction of instances covered correctly by R among the instances covered by it.",
        "Under Scoresp, the score of a rule R is determined only by the number of instances covered correctly",
        "(|lnst+|) and incorrectly (|lnst-|).",
        "The nature of",
        "instances are not taken into account.",
        "The variants of Scoresp proposed here assigns weights to instances, based on which the scores are computed.",
        "We assign weights to the instances based on how easy it is to make them happy.",
        "For an instance t, define the happiness quotient h(t) to be the fraction of rules that correctly cover t among all the rules that cover t:",
        "The value h( t) is a measure of how easy it is to make t happy; the larger the value of h( t) , it is easier to make t happy.",
        "For instance, if h(t) w 1, then |Rules+| w |Rulest|, meaning that almost any rule that covers t will annotate it correctly.",
        "Thus, it is easy to make t happy.",
        "On the other extreme, if h(t) w 0, then only a small fraction of the rules that cover t annotate it correctly.",
        "Thus it is harder to make t happy.",
        "When we schedule a rule R, the instances in Inst+ become happy and those in Inst-become unhappy.",
        "Our new scoring functions give credit to R for each instance in Inst+ and award a penalty R for each instance in Inst-.",
        "The credit and the penalty depend on the happiness quotient of the instance.",
        "Informally, we want to give more credit R for making hard instances happy; similarly, we want to penalize R for making easy instances unhappy.",
        "A natural way of accomplishing the above is to award a credit of (1 – h(t)) for each instance t e Inst+ and a penalty of h(t) for each instance t e Inst-.",
        "Below, we formally define the above quantities as gain and loss associated with R. For each rule R, define",
        "Based on the above quantities, we define a natural scoring function, called Weighted Precision:",
        "Our third scoring function is a refinement of the weighted precision scoring.",
        "In ScoreWP, we compute the happiness quotient of a token by taking in account the number of rules that cover the token and among those the ones that cover it correctly.",
        "The refinement is obtained by also considering the nature of these rules.",
        "We define",
        "E „,„ , + precision(R)ER£Rulest precision(R)",
        "Gain, loss and the scoring function are defined similar to that of ScoreWP:"
      ]
    },
    {
      "heading": "5. Experiments",
      "text": [
        "In this section, we describe rule-ordering experiments on two real-world tasks.",
        "1) named-entity (NE) annotation that relied on hand-crafted rules for MUC-7 dataset.",
        "2) The second application we consider is rule-based multi-class text classification.",
        "We order rules learnt on benchmark text classification datasets and observe consistent improvements by merely reordering rules learnt by other rule learners.",
        "Rule-based named entity annotation is a natural instance of a decision list problem.",
        "Typically, rule-based NE annotation systems (Cunningham et al., 2002) require rules to be manually written as well as ordered manually.",
        "In this section, we show that our proposed rule-ordering algorithms perform better than the natural heuristic.",
        "Note that we do not intend to build a rule-based decision list which performs better than existing methods.",
        "Setup: In our problem formulation of MAXDL , the set of instances T and mapping A from instances to actual annotations, together form a training set.",
        "We have access to a set of documents D = d2,..., that have all its named entities annotated.",
        "To generate pairs (T, A) using the set of documents D, let Tdi represent the set of token sequences that are annotated in a document dj e D. Let A(t) be the actual annotation for an instance t e Tdi.",
        "Given a set of rules R and a document collection D, each rule R e R is applied to each document dj e D. The set of token sequences (instances here) which R covers (InstR), is included in the set of instances T. For all instances t e Tdi, we add a mapping t – A(t) in A.",
        "For all other instances t e {InstR – Tdi}, we have a mapping t – null included in A.",
        "We perform these additions for each document and rule pair.",
        "Finally, we add a rule R* = (*, null) to the rule set R. The pattern * matches every instance t e [J InstR and associates a null annotation with the instance.",
        "We only consider \"person name\", \"organization\" and \"place name\" annotations.",
        "We use two different rule sets containing about 30 rules each.",
        "Table 1 presents accuracy achieved by our proposed algorithms for the two chosen rule sets.",
        "In all the cases our proposed methods perform better than ScoresP.",
        "The result also shows that our proposed methods generalize better than simple ScoresP.",
        "In this section, we show another application of our algorithms in ordering classification rules.",
        "The antecedent of a classification rule is a series of tests on the input and the consequent gives the class label.",
        "Since different rules can assign conflicting classes, rule-ordering becomes important in choosing a correct class.",
        "These rules come from a variety of sources and could be hand-crafted or machine-learnt.",
        "Machine learnt rules could be generated using association mining (Agrawal and Srikant, 1994), inductive logic programming (Lavrac and Dzeroski, 1994), or Ripper (Cohen, 1995).",
        "Even classifiers can be seen as rules, e.g., linear discriminants are rules that assign one of two classes to exclusive partitions of input space.",
        "Due to domain specificity and unavailability of hand-tuned rules we illustrate rule-ordering on: (1) rules induced heterogeneous set of rules obtained from naive Bayes and decision trees (BinRules).",
        "Setup: We used benchmark text classification datasets (Forman, 2003) available from the Weka site.",
        "These multi-class datasets represent 229 binary text classification problems, with positive class size avg.",
        "149, and class skews avg.",
        "1 : 31.",
        "These are subsets of various benchmark tasks like Reuters, TREC, and Ohsumed (oh).",
        "We present only a subset of the results (with only ScoreWP and ScoreWP) here for lack of space.",
        "We report experiments over 10 random 50 : 50 train-test splits.",
        "The training split is used to learn rules and their ordering.",
        "The orderings are evaluated on the test split and average train and test accuracies reported.",
        "Results:",
        "The RipRules setting: We induce rules (from the train split) using the JRip implementation in Weka (Witten and Frank, 2005).",
        "We apply our various algorithms to merely reorder the rules output by JRip.",
        "In Table 2 we present results comparing JRip output with their reordered versions obtained from ScoreSP, ScoreWP and ScoreWP.",
        "Along with the name of each data set, the average number of rules induced from the training splits are also mentioned in parentheses.",
        "The best accuracies are marked in bold.",
        "We observe that the reordered rule-sets using ScoreWP and ScoreWP perform better than both baselines ScoreSP and JRip with lower deviations.",
        "The BinRules setting: For an n-class problem we obtain classification rules by training a heterogeneous collection of one-vs-rest binary classifiers.",
        "Each classifier is either a naive Bayes or a decision tree classifier trained to discriminate one class from the rest (2n classifiers).",
        "We treat each binary classifier as a classification rule that covers an instance if the binary classifier assigns its associated class to that instance.",
        "In addition, corresponding to every class, we introduce a default classification rule that assigns the associated class to any instance it encounters.",
        "This gives us 3n rules.",
        "We used the naive Bayes and J48 implementations in Weka to obtain binary rules, ordered using ScoreWP and ScoreWP, and compared with ScoreSP baseline in Table 3.",
        "We also show individual classifier accuracy, and the best are marked bold.",
        "It is encouraging to note that all our rule-ordering techniques always outperform their multi-class counterparts on the test data set.",
        "We outperform the baseline ScoreSP method on all data sets with lower deviations.",
        "Rule-sets",
        "Accuracy",
        "Scoresp",
        "Scorewp",
        "ScoreWP",
        "Rule-set 1",
        "Trng",
        "76.4",
        "76.7",
        "78.9",
        "Test",
        "50.0",
        "52.7",
        "54.5",
        "Rule-set 2",
        "Training",
        "70.1",
        "71.6",
        "73.3",
        "Test",
        "49.1",
        "51.4",
        "52.0",
        "Dataset (avg.",
        "# rules)",
        "Acc--uracy",
        "JRip",
        "Scoresp",
        "Scorewp",
        "ScoreWP",
        "la2s (37)",
        "Trng Test",
        "86.16±0.39 76.93±0.43",
        "86.02±0.16 77.88±0.16",
        "86.68±0.16 78.05±0.17",
        "87.04±0.17 78.1±0.15",
        "oh5 (28)",
        "Trng Test",
        "86.95±0.41 76.43±0.58",
        "88.26±0.21 79.08±0.37",
        "88.8±0.16 79.37±0.38",
        "89.06±0.17 79.24±0.35",
        "tr45 (17)",
        "Trng Test",
        "91.88±0.38 78.9±0.47",
        "92.61±0.18 80.99±0.29",
        "92.84±0.23 81.19±0.28",
        "93.3±0.21 81.3±0.3",
        "Data set",
        "Accu--racy",
        "Multi",
        "J48",
        "-class NaiveBayes",
        "Scoresp",
        "Scorewp",
        "ScoreWp",
        "la2s(18)",
        "Trng Test",
        "94.75±0.39 73.43±0.64",
        "85.78±0.29 73.68±0.37",
        "94.64±0.14 78.0±0.21",
        "95.9±0.03 78.46±0.23",
        "95.99±0.01 78.64±0.29",
        "oh5 (30)",
        "Trng Test",
        "95.08±0.21 78.08±0.76",
        "99.56±0.09",
        "74.16±0.77",
        "96.27±0.14 82.72±0.25",
        "98.43±0.09 83.16±0.24",
        "98.45±0.09 83.98±0.26",
        "tr45 (30)",
        "Trng Test",
        "97.91 ±0.11 85.25±1.02",
        "87.16±1.18 69.91±1.33",
        "97.71±0.14 84.06±0.44",
        "98.93±0.06 86.1±0.39",
        "98.98±0.05 86.42±0.41"
      ]
    },
    {
      "heading": "6. Conclusions",
      "text": [
        "In this paper, we formulated and studied the MaxDL problem.",
        "We proved the hardness of the problem.",
        "We then proposed some heuristic approaches and established the usefulness of our methods experimentally.",
        "We observed improved performance in classification task by merely reordering the rules obtained by an existing decision list learning algorithm.",
        "In future work, we would like to explore how rule-ordering formulation can be applied to ordering heterogeneous classifiers in the ensemble learning setting."
      ]
    }
  ]
}
