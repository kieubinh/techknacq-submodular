{
  "info": {
    "authors": [
      "Kenji Tateishi",
      "Dai Kusui"
    ],
    "book": "Proceedings of the Third International Joint Conference on Natural Language Processing",
    "id": "acl-I08-2121",
    "title": "Fast Duplicated Documents Detection using Multilevel Prefix-filter",
    "url": "https://aclweb.org/anthology/I08-2121",
    "year": 2008
  },
  "references": [],
  "sections": [
    {
      "text": [
        "Fast Duplicate Document Detection using Multilevel Preix-ilter",
        "Kenji Tateishi and Dai Kusui",
        "Duplicate document detection is the problem of finding all document-pairs rapidly whose similarities are equal to or greater than a given threshold.",
        "There is a method proposed recently called prefix-filter that finds document-pairs whose similarities never reach the threshold based on the number of uncommon terms (words/characters) in a document-pair and removes them before similarity calculation.",
        "However, prefix-filter cannot decrease the number of similarity calculations sufficiently because it leaves many document-pairs whose similarities are less than the threshold.",
        "In this paper, we propose multilevel prefix-filter, which reduces the number of similarity calculations more efficiently and maintains the advantage of prefix-filter (no detection loss, no extra parameter) by applying multiple different prefix-filters."
      ]
    },
    {
      "heading": "1. Introduction",
      "text": [
        "Duplicate Document Detection (DDD) is the problem of finding all document-pairs rapidly whose similarities are equal to or greater than a given threshold.",
        "DDD is often used for data cleaning of customer databases, trend analysis of failure case databases in contact centers, and can be applied for spam filtering by detecting duplicate blog documents.",
        "After receiving target documents and the similarity threshold (ST), the Duplicate Document Detection System (DDDS) shows users all document pairs whose similarities are equal or greater than ST, or document groups these document pairs unify.",
        "In the case of data cleaning, DDDS additionally requires users to confirm whether each document pair result is truly duplicated.",
        "The naive implementation of DDD requires similarity calculations of all document pairs, but it demands huge time according to the number of target documents.",
        "The current techniques apply the two-stage approach: (i) Reduce document pairs using shallow filtering methods, and then (ii) calculate similarities between the remaining document pairs.",
        "Among them, prefix-filter(Sarawagi and Kir-pal, 2004)(Chaudhuri et al., 2006)(Bayardo et al., 2007) is a filtering method that finds document-pairs whose similarities never reach the threshold based on the number of uncommon terms (words/characters) in a document-pair, and that removes them before similarity calculation.",
        "For example, suppose that a document pair is composed of 10 terms, and 80% similarity means 8 terms are in common in the document pair.",
        "In this case, if the similarity of a document pair is equal to or greater than 80% and 3 terms are selected from one document, the other document must contain at least one of the 3 terms.",
        "Therefore, prefix-filter can remove document pairs where one document does not contain any of the 3 terms selected from the other.",
        "It can be implemented rapidly by index files.",
        "Prefix-filter has two advantages compared with other filtering methods: (i) All document pairs equal to or greater than the similarity threshold (ST) are obtained without any detection loss, and (ii) no extra parameter for filtering is required other than ST.",
        "The problem with prefix-filter is that it cannot reduce similarity calculations sufficiently because it leaves many document-pairs whose similarities are less than ST. Document-pairs that prefix-filter can remove depend on terms selected from each document (in the above example, which 3 terms are selected).",
        "At worst, document pairs where only one term is in common might remain.",
        "The processing time of DDD can be approximated by the product of the number of similarity calculations and the processing time of each similarity calculation.",
        "In order to identify the same document pairs correctly, a deep similarity function considering synonyms and variants is essential.",
        "Therefore, the number of similarity calculations should decrease as mush as possible.",
        "In this paper, we propose multilevel prefix-filter, which reduces the number of similarity calculations more efficiently and maintains the advantages of prefix-filter (no detection loss, no extra parameter) by applying multiple different prefix-filters.",
        "Each prefix-filter chooses terms from each document based on a different priority decision criterion, and removes different document-pairs.",
        "It finally calculates the similarities of the document-pairs left by all of the prefix-filters.",
        "We conducted an experiment with a customer database composed of address and company name fields, and used edit-similarity for the similarity calculation.",
        "The result showed that multilevel prefix-filter could reduce the number of similarity calculations to 1/4 compared with the current prefix-filter."
      ]
    },
    {
      "heading": "2. Prefix-filter",
      "text": [
        "Prefix-filter finds document-pairs whose similarities never reach the similarity threshold (ST) based on the number of uncommon terms in a document-pair, and that removes them before the similarity calculation.",
        "A DDDS with prefix-filter processes the following four steps.",
        "Step 1: Define x: the minimum proportion of common terms in a document pair whose similarity is equal to or greater than ST(0 < ST < 1).",
        "Step 2: Decide priorities of all terms on target documents.",
        "Step 3: Select terms from each document according to the priorities in Step 2 until the proportion of selected terms exceeds 1 – x.",
        "Step 4: Remove document pairs that share no terms selected in Step 3, and calculate the similarities of the remaining document pairs.",
        "Let us illustrate how prefix-filter works briefly.",
        "For example, a user inputs 6 documents as in Fig.1 and sets the similarity threshold at ST = 0.6 and chooses edit-similarity as the similarity function.",
        "Note that edit-similarity between document d1 and document d2, denoted as editsim(d1,d2), is defined as follows.",
        "Here, \\d1\\ and \\d2\\ denotes the length of dl and d2 respectively, and edit-distance(d1,d2) represents the minimum number of edit operations (insertion, deletion, and substitution) that convert dl to d2.",
        "For example, edit-distance(d1, d5) in Fig.1 is 4: delete E, H, and I, and insert M. Then, max(\\d1\\, \\d5\\) is 9, derived from \\d1\\ = 9 and \\d5\\ = 7.",
        "Therefore, edit_sim(d1,d5) = 1 - (4/9) = 0.45.",
        "In the first step, when the similarity function is edit-similarity, the minimum proportion of common terms (characters) in a document pair whose similarity is equal or greater than ST = 0.6 is x = 0.6.",
        "This means the similarity of a document pair in which the proportion of common terms is less than 0.6 never reaches 0.6. x can be derived from the similarity function (see Appendix A).",
        "In step 2, DDDS decides the priorities ofall terms on target documents.",
        "Fig.",
        "1 (a) gives all terms contained in the 6 documents priorities from the lowest document frequency (if the same frequency, alphabetical order).",
        "Regardless of the priority decision criteria, the similarities of document pairs removed are always less than ST, but document pairs removed differ.",
        "Empirically, it is known that giving high priority from the term of the lowest frequency is effective because the lower the frequency of a term, the lower the probability of a document pair containing that term(Chaudhuri et al., 2006).",
        "In step 3, DDDS chooses terms from each document according to the priority decision criterion of step 2 in Fig.1 (a) until the proportion of selected terms exceeds 1 – x = 0.4.",
        "For example, the proportion is over 0.4 when DDDS selects 4 terms from d1, composed of 9 terms.",
        "DDDS selects 4 terms according to (a): {A, B, C, I}.",
        "Fig.1 (b) shows selected terms using boldface and background color.",
        "Finally, DDDS removes document pairs thatshare no terms selected in step 3, and calculates similarities of the remaining document pairs.",
        "The similarities of document pairs with no common terms never reach 0.6 because the proportion of common terms is less than 0.6.",
        "Prefix-filter can be implemented easily using an index file, storing the relation of each selected term and the list of document IDs including the term.",
        "As a result, document dl targets d3 and d5 on similarity calculation.",
        "Finally, the number of similarity calculations can be reduced by 5 times while naive solution requires (6*5)/2=15 times."
      ]
    },
    {
      "heading": "3. Multilevel prefix-filter",
      "text": [
        "The problem with prefix-filter is that it cannot reduce similarity calculations suficiently because it leaves many document-pairs whose similarities are less than ST. Document-pairs that prefix-filter can remove depend on terms selected from each document.",
        "At worst, document pairs where only one term is in common might remain.",
        "In the case of selecting terms according to priority decision criterion (a) in Fig.l, for example, a document pair {d4,d6} on (b) remains although only K is in common.",
        "In order to identify the same document pairs correctly, a deep similarity function such as edit-similarity is essential.",
        "Therefore, the number of similarity calculations should be decreased as much as possible.",
        "We propose multilevel prefix-filter, which reduces the number of similarity calculations more ef-iciently by applying multiple different preix-ilters.",
        "Each prefix-filter chooses terms from each document based on different priority decision criteria, and removes different document-pairs.",
        "It inally calculates the similarities of document-pairs left by all of the preix-ilters.",
        "That is why multilevel preixfilter can reduce the number of document pairs more comprehensively than the current preix-ilter (without any detection loss).",
        "Fig.2 illustrates an example of multilevel preix-ilter, applying preix-ilter twice.",
        "After DDDS changes priority decision criterion between the irst and second preix-ilter, terms selected from each document vary.",
        "As a result, document pairs iltered by each preix-ilter change as well.",
        "The product of document pairs each preix-ilter leaves leads to the reduction of similarity calculations by 3 times.",
        "Let us explain two kinds of priority decision criteria of terms in the following sections.",
        "We define Score(n,w), the score of a term w on nth preix-ilter, as follows, and give a higher priority to a smaller value of Score(n,w).",
        "where df(w) is the document frequency of w over the target documents, and sdf (i, w) denotes the number of documents in which w was selected on ith preix-ilter.",
        "The basic concept is to give a higher priority to a term of smaller frequency.",
        "As mentioned before, this is effective because the lower the frequency of a term, the lower the probability of a document pair containing that term.",
        "On the other hand, it is expected that a multilevel preix-ilter becomes more effective if each preix-ilter can ilter different document pairs.",
        "Therefore, after the second preix-ilter (n > 2), we give a higher priority to a term whose frequency is small (irst term) and which was not selected by previous preix-ilters (second term).",
        "Fig.3 illustrates the process of multilevel prefix-ilter based on this creterion.",
        "This multilevel preix-ilter can be implimented using two kinds of index files (WJNDEX, DJNDEX) rapidly.",
        "If PC with multiple processers, it is easy to parallelize filtering process.",
        "We define Score(d, n, w), the score of a term w contained in document d on nth preix-ilter, as fol-",
        "d1",
        "ABCDEF HIJ",
        "d2",
        "E G H J L",
        "d3",
        "B C D E F HI",
        "d4",
        "E G H J K L",
        "d5",
        "A B C D F J M",
        "d6",
        "K M",
        "First prefix-filter A>G>l>K>L>M>B>C>D>F>E>lW",
        "lows, and give a higher priority to a smaller value of Score(d, n, w).",
        "where DSd_1 is target documents of similarity calculation of d left after the n – 1-th prefix-filter, and DSSw is documents containing a term w. The basic concept is to give a higher priority to a term that can ilter many document pairs.",
        "It decides the priorities of terms on nth preix-ilter after waiting for the result of n – 1-th prefix-filter."
      ]
    },
    {
      "heading": "4. Experiments",
      "text": [
        "We compared multilevel preix-ilter with the current preix-ilter in order to clarify how much the proposed method could reduce the number of similarity calculations.",
        "We used a customer database in Japanese, composed of 200,000 records, and had been used for data cleaning.",
        "Each record has two fields, company name and address, averaging 11 terms and 18 terms, respectively.",
        "We selected edit-similarity as the similarity function, and set 80% as ST.",
        "The database contains 86031 (43%) duplicated documents (records) in the company name, and 123068 (60%) in the address ield when we assumed document pairs whose similarity was equal to or greater than 80%.",
        "A DDDS with multilevel prefix-filter ran on an NEC Express 5800 with Windows 2000, 2.6GHz Pentium Xeon and 3.4 GByte of memory.",
        "N- Number of applying prefix-filter, D-Target documents, ST-Similarity Threshold Index creation process^"
      ]
    },
    {
      "heading": "1.. for(wGD)",
      "text": []
    },
    {
      "heading": "3.. end for",
      "text": []
    },
    {
      "heading": "6.. W~ terms chosen from w edi of the smallest Scorefi.w)",
      "text": [
        "until the proportion of selected terms exceeds i-x."
      ]
    },
    {
      "heading": "9.. pushfWJNDEXfl.w), d,)",
      "text": []
    },
    {
      "heading": "10.. end for",
      "text": []
    },
    {
      "heading": "11.. end for",
      "text": []
    },
    {
      "heading": "14.. end for",
      "text": []
    },
    {
      "heading": "15.. end for Matching process:",
      "text": [
        "Filtering process:"
      ]
    },
    {
      "heading": "19.. for(wSWJNDEX(j,d,))",
      "text": []
    },
    {
      "heading": "22.. end for",
      "text": []
    },
    {
      "heading": "24.. end for",
      "text": [
        "Similarity calculation process:"
      ]
    },
    {
      "heading": "25.. for(dsSDS)",
      "text": []
    },
    {
      "heading": "27.. end for",
      "text": []
    },
    {
      "heading": "28.. end for",
      "text": [
        "Fig.4 (a) shows the comparison between multilevel prefix-filter using Score(d, n, w) and Score(n, w) under the condition that the number of preix-ilters is one or two.",
        "The company name ield was used for target documents.",
        "Although multilevel preix-ilter using Score(n,w) succeeded in the reduction of processing time, Score(d,n,w) failed because of too many score calculations.",
        "Therefore, we used Score(n, w) in the following experiments.",
        "Fig.4 (b) shows the number of similarity calculations when the number of applied preix-ilters varies.",
        "In this figure, n = 1 means the current preix-ilter.",
        "The number of similarity calculations decreased most sharply in the case of applying preix-ilters twice on both the company name and address ields, and converged in 10 times.",
        "Multilevel preix-ilter reduced the number of similarity calculations by 10 times, about to 1/4 (77% reduction) in the company name ield, and about to 1/3 (69% reduction) in the address field.",
        "Fig.4 (c) shows total processing time when the number of applied preix-ilters varies.",
        "It represents the sum of index creation/iltering time and similarity calculation time.",
        "When the number of applied preix-ilters increased, the latter decreased because the number of similarity calculations also decreased, but the former increased instead.",
        "Note that we did not parallelize the iltering process here.",
        "Total processing time decreased most sharply in the case of applying preix-ilters 4 times on both the company name (to be 43%) and address ields (to be 49%).",
        "d1",
        "ABCDEF H I J",
        "d2",
        "E GH J |",
        "d3",
        "BCDEF H 1",
        "d4",
        "E GH JKL",
        "d5",
        "ABCD F J M",
        "d6",
        "K M",
        "d1",
        "ABCDEF H I J",
        "d2",
        "E GH J L",
        "d3",
        "BCDEF H I",
        "d4",
        "E GH JKL",
        "d5",
        "ABCD F J M",
        "d6",
        "K M",
        "Fig.4 (d) shows the reduction rate of the number of similarity calculations and processing time when preix-ilter was applied 4 times and the size of target document sets varied.",
        "Here, the reduction rate denotes the proportion of the number of similarity calculations or processing time ofmulti-level preix-ilter, applying preix-ilter 4 times, to those of the current preix-ilter, applying preix-ilter once.",
        "This result reveals the effectiveness of multilevel prefix-ilter does not change for the size of the target document set.",
        "The experimental results indicated that multilevel preix-ilter could reduce the number of similarity calculations up to 1/4, and that this effectiveness was not lost by changing the size of the target database.",
        "In addition, it showed that the optimal number ofap-plied preix-ilters did not depend on the target ield or the size of the target database.",
        "Therefore, multilevel preix-ilter proved to be more effective than the current preix-ilter without losing the advantages of the current preix-ilter (no detection loss, no extra parameter).",
        "The experimental results also indicated that the company name ield was more effective than the address ield.",
        "As mentioned, the address ield was longer than that of the company name ield on average, and it contained more duplicated documents.",
        "Therefore, we expect that the proposed method is effective in the following situation: (i) the length of each document (record) is short, (ii) the number of duplicate documents has been reduced beforehand by simple iltering methods such as deleting exact match documents or documents different only in space, and (iii) detecting the remaining duplicate documents by using a deep similarity function such as edit-similarity."
      ]
    },
    {
      "heading": "5. Related work",
      "text": [
        "Duplicate Document Detection for databases has been researched for a long time(Elmagarmid et al., 2007).",
        "The current techniques apply the two-stage approach: (i) Reduce document pairs using shallow iltering methods, and then (ii) calculate similarity between the remaining document pairs.",
        "Multi-level preix-ilter belongs to the irst step (i).",
        "Current filtering methods were independent of the similarity function.",
        "Jaro(Jaro, 1989) proposed Standard Blocking, which created many record blocks in which each record shared the same irst n terms, and calculated the similarity of document-pairs included in the same record block.",
        "Hernandez(Hernandez and Stolfo, 1995) proposed the Sorted Neighborhood Method (SNM), which irst sorted records by a given key function, and then grouped adjacent records within the given window size as a block.",
        "McCallum(McCallum et al., 2000) improved them by allowing a record to locate in plural blocks in order to avoid detection loss.",
        "However, the problems of these iltering methods using blocking are that the user needs trial and error parameters such as irst n terms for Standard Blocking, and that these incur detection loss in spite of improvements being attempted, caused by two documents of a correct document pair existing in different blocks.",
        "Preix-ilter solved these problems: (i) all document pairs equal or more than similarity threshold (ST) are obtained without any detection loss, and (ii) any extra parameter for iltering is not required other than ST. As we clariied in Section 4, multilevel preix-ilter proved to be more effective than the current preix-ilter without losing these advantages.",
        "Another iltering method without any detection loss, called PARTENUM, has been proposed re-cently(Arasu et al., 2006).",
        "However, it needs to adjust two kinds of parameters (nl, n2) for obtaining optimal processing time according to the size of target document set or the similarity threshold."
      ]
    },
    {
      "heading": "6. Conclusion",
      "text": [
        "In this paper, we proposed multilevel preix-ilter, which reduces the number of similarity calculations more eficiently and maintains the advantage of the current preix-ilter by applying multiple different prefix-filters.",
        "Experiments with a customer database composed of 200,000 documents and edit-distance for similarity calculation showed that it could reduce the number of similarity calculations to 1/4 compared with the current prefix-filter."
      ]
    }
  ]
}
