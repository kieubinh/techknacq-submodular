{
  "info": {
    "authors": [
      "Jia-Lin Tsai"
    ],
    "book": "Proceedings of the Sixth SIGHAN Workshop on Chinese Language Processing",
    "id": "acl-I08-4027",
    "title": "Word Boundary Token Model for the SIGHAN Bakeoff 2007",
    "url": "https://aclweb.org/anthology/I08-4027",
    "year": 2008
  },
  "references": [
    "acl-I05-3017",
    "acl-I05-3020",
    "acl-P06-2108",
    "acl-W06-0115"
  ],
  "sections": [
    {
      "text": [
        "Word Boundary Token Model for the SIGHAN Bakeoff 2GG7",
        "Tsai Jia-Lin",
        "This paper describes a Chinese word segmentation system based on word boundary token model and triple template matching model for extracting unknown words; and word support model for resolving segmentation ambiguity."
      ]
    },
    {
      "heading": "1. Introduction",
      "text": [
        "In the SIGHAN bakeoff 2007, we participated in the CKIP and the CityU closed tasks.",
        "Our Chinese word segmentation system is based on three models: (a) word boundary token (WBT) model and (b) triple context matching model for unknown word extraction, and (c) word support model for segmentation disambiguation.",
        "Since the word support model and triple context matching model have been proposed in our previous work (Tsai, 2005, 2006a and 2006b) at the SIGHAN bakeoff 2005 (Thomas, 2005) and 2006 (Levow, 2006), the major descriptions of this paper is on the WBT model.",
        "The remainder of this paper is arranged as follows.",
        "In Section 2, we present the WBT model for extracting words from each Chinese sentence.",
        "Scored results and analyses of our CWS system are presented in Section 3.",
        "Finally, in Section 4, we present our conclusion and discuss the direction of future research."
      ]
    },
    {
      "heading": "2. Word Boundary Token Model",
      "text": [
        "To develop the WBT model, first, we define word boundary token.",
        "Second, we give definition and computation of the WBT probability and the WBT frequency for a given corpus.",
        "Finally, algorithm of our WBT model for word extraction is given.",
        "We classify WBT into three types: left, right and bi-direction.",
        "The left and right word boundary (WB) tokens are the immediately preceding word and the following word of a word in a Chinese sentence, respectively.",
        "Suppose WiW2W3 is a Chinese sentence comprised of three Chinese words Wi, W2 and W3.",
        "To this case, Wi and W3 are the left and the right WB tokens of W2, respectively.",
        "On the other hand, those words that can simultaneously be left and right WB tokens of a word in corpus are defined as bi-direction WB tokens.",
        "Suppose W4W2Wi is a Chinese sentence comprised of three Chinese words W4, W2 and Wi.",
        "Following the above cases, Wi can be a bi-direction WB token for W2.",
        "Table i is the Top 5 left, right and bi-direction WB tokens derived by the Academia Sinica (AS) corpus (CKIP, 1995 and 1996).",
        "From Table 1, the Top 1 left , right and bi-direction WB tokens is \"^J(of).\"",
        "Left",
        "Right",
        "Bi-Direction",
        "Top1",
        "fö(of)",
        "fö(of)",
        "Top2",
        "JÉ(is)",
        "JÉ(is)",
        "JÉ(is)",
        "Top3",
        "Ä(at)",
        "T (already)",
        "Ä(at)",
        "Top4",
        "«(a)",
        "Ä(at)",
        "T (already)",
        "Top5",
        "W(has)",
        " – (one)",
        "#ä(and)",
        "We first give the computation of WBT frequency, then, the computation of WBT probability.",
        "(1) WBT frequency: we use WBT_F(string, WBT, L/R) as the function of WBT frequency, where string is a n-char string containing n Chinese characters, WBT is a word boundary token, and L/R indicates to compute left or right WBT frequency.",
        "Now, take WBT_F(\" ^ffl(we)\", \"&5(of)\", L) as example.",
        "First, we submit the query \"fi^ficff\"!\"",
        "to system corpus.",
        "Second, set the number of sentences including this query is the WBT_F(\"OT(we)\", \"ft(of), L).",
        "(2) WBT Probability: we use WBT_P(string1, string2, WBT, L/R) as the function of WBT probability, where string1 and string2 are two n-char strings, WBT is a word boundary token, and L/R indicates to compute left or right WBT probability.",
        "The equations of left and the right WBT probability are:",
        "We use WBTM(n, WBT, threshold^, thresholdf) as the function of the WBT model, where n is the window size, threshold_p is the threshold value of WBT probability and thresholdf is the threshold value of WBT frequency.",
        "The algorithm of our WBT model applied to extract words from a given Chinese sentence is as follows: Step 1.",
        "INPUT:",
        "n, WBT, threshold_p and thresholdf; Step 2.",
        "IF sentence length is less or equal to n THEN GOTO Step 4; Step 3.",
        "SET loopCount to one REPEAT",
        "COMBINE the characters of sentence between loopCountth and (loopCount + n - 1)th to be a stringa",
        "COMBINE the characters of sentence between (loopCount+1)th and (loopCount + n)th to be a string_b",
        "IF WBT_P(string_a, stringb, WBT, L) > threshold_p AND",
        "WBT_P(string_a, string_b, WBT, R) > threshold_p AND",
        "WBT_F(string_a, WBT, L) > threshold_f AND",
        "WBT_F(string_a, WBT, R) > threshold_f",
        "THEN SET string a is as word",
        "IF WBT_P(string_b, string_a, WBT, L) > threshold_p AND",
        "WBT_P(string_b, string_a, WBT, R) > threshold_p AND",
        "WBT_F(string_b, WBT, L) > threshold_f AND",
        "WBT_F(string_b, WBT, R) > threshold_f",
        "THEN SET string_b to a word",
        "INCREMENT loopCount UNTIL loopCount > sentence length - n Step 4.",
        "END.",
        "loopCount is 1 loopCount is 21) to extract word \"Jjfti\" from the Chinese sentence",
        "\"SfitiMT",
        "Table 2 is an example of applying WBTM(2, \"ft\", 0.95, 1) to extract words from the Chinese sentence \"Mi^l&M\" by the AS corpus"
      ]
    },
    {
      "heading": "3. Evaluation",
      "text": [
        "In the SIGHAN Bakeoff 2007, there are five training corpus for word segmentation (WS) task: AS (Academia Sinica), CityU (City University of Hong Kong) are traditional Chinese corpus; CTB (University of Colorado, United States), NCC (State Language Commission of P.R.C., Beijing) and SXU (Shanxi University, Taiyuan) are simplified Chinese corpus.",
        "For each corpus, there are closed and open tasks.",
        "In this Bakeoff, we attend the AS (Academia Sinica) and CityU (City University of Hong Kong) closed WS tasks.",
        "Tables 3 and 4 show the details of CKIP and CityU tasks.",
        "From Table 3, it indicates that the CKIP should be a 10-folds design.",
        "From Table 4, it indicates that the CityU should be a 5-folds design.",
        "The major steps of our CWS system with word boundary token model, triple context matching model and word support model are as below: Step 0.",
        "Combine training corpus and testing corpus",
        "as system corpus; Step 1.",
        "Generate the BMM segmentation for the given Chinese sentence by system dictionary; Step 2.",
        "Use WBT model with system corpus to extract 2-char, 3-char and 4-char words from the given Chinese sentence, where WBT is set to \"ft,\" \"i,\" \"ft,\" \"7,\" thresholds is set to 0.95 and thresholdf is set to 1; Step 3.",
        "Use TCT (triple context template) matching model to extract 2-char, 3-char and 4-char words from the segmented Chinese sentence of Step 1.",
        "The details of TCT matching model",
        "Step 4.",
        "Add the found words of Steps 2 and 3 into system dictionary;",
        "Step 5.",
        "Generate the BMM segmentation for the given Chinese sentence by system dictionary;",
        "Step 6.",
        "Use word support model to resolve Overlap Ambiguity (OA) and Combination Ambiguity (CA) problems for the BMM segmentation of Step 5.",
        "baseline system for the CKIP closed WS task by the SIGHAN Bakeoff 2007.",
        "Table 6 is the comparison between our CWS and the SIGHAN Bakeoff 2007 baseline system for the CityU closed WS task by the SIGHAN Bakeoff 2007.",
        "our CWS system and the SIGHAN Bakeoff 2007 baseline system for the CKIP closed WS task baseline system for the CityU closed WS task",
        "From Tables 5 and 6, it shows the major improvement of our CWS for the baseline system is on the precision of word segmentation.",
        "That is to say, the major target system for improving our CWS system is the unknown word extraction system, i.e. the word boundary model and the triple context template matching model.",
        "Table 7 is the coverage of 2-char, 3-char, 4-char and great than 4-char error words extracting by our",
        "CWS for the CKIP and the CityU closed WS tasks.",
        "Baseline",
        "Our CWS",
        "Increase",
        "R",
        "0.8978",
        "0.915",
        "0.0172",
        "P",
        "0.8232",
        "0.9001",
        "0.0769",
        "F",
        "0.8589",
        "0.9075",
        "0.0486",
        "Baseline",
        "Our CWS",
        "Increase",
        "R",
        "0.9006",
        "0.9191",
        "0.0185",
        "P",
        "0.8225",
        "0.9014",
        "0.0789",
        "F",
        "0.8598",
        "0.9102",
        "0.0504",
        "content and illustration of Sinica corpus of Academia Sinica.",
        "Institute of Information Science, Academia Sinica.",
        "CKIP (Chinese Knowledge Information Processing Group).",
        "1996.",
        "A study of Chinese Word Boundaries and Segmentation Standard for Information processing (in Chinese).",
        "Technical Report, Taiwan, Taipei, Academia Sinica.",
        "Levow, Gina-Anne.",
        "2006.",
        "The Third International Chinese Language Processing Bakeoff: Word Segmentation and Named Entity Recognition, In Proceedings of SIGHAN5 the 3rd International Chinese Language Processing Bakeoff at Col ing/ACL 2006, July, Sydney, Australia, 108-117.",
        "Thomas, Emerson.",
        "2005.",
        "The Second International Chinese Word Segmentation Bakeoff, In Proceedings of The 2nd International Chinese Word Segmentation Bakeoff at SIGHAN-4, October, Jeju Island, Korea, 123-133.",
        "Tsai, Jia-Lin.",
        "2005.",
        "Report to BMM-based Chinese Word Segmentor with Context-based Unknown Word Identifier for the Second International Chinese Word Segmentation Bakeoff, In Proceedings of The 2nd International Chinese Word Segmentation Bakeoff at SIGHAN-4, October, Jeju Island, Korea, 142-145.",
        "Tsai, Jia-Lin.",
        "2006.",
        "Using Word Support Model to Improve Chinese Input System, In Proceedings of Coling/ACL 2006, July, Sydney, Australia, 842849.",
        "Tsai, Jia-Lin.",
        "2006.",
        "BMM-based Chinese Word Segmentor with Word Support Model for the",
        "SIGHAN Bakeoff 2006, In Proceedings of SIGHAN5 the 3rd International Chinese Language Processing Bakeoff at Coling/ACL 2006, July, Sydney, Australia, 130-133.",
        "CWS for the CKIP and the CityU closed WS tasks",
        "From Table 7, it shows the major n-char unknown word extraction for improving our CWS system is on 2-char unknown word extraction.",
        "It is because that the total coverage of 2-char word errors extraction of our CWS system for the CKIP and the CityU WS tasks is 75%."
      ]
    },
    {
      "heading": "4. Conclusions",
      "text": [
        "In this paper, we describes a Chinese word segmentation system based on word boundary token model and triple context matching model (Tsai, 2005) for extracting unknown words; and word support model (Tsai, 2006a and 2006b) for resolving segmentation ambiguity.",
        "To develop the word boundary model, we define WBT and classify WBT into three types of left, right and bi-direction.",
        "As per three types of WBT, we define WBT probability and WBT frequency.",
        "In the SIGHAN Bakeoff 2007, we take part in the CKIP and the CityU closed word segmentation tasks.",
        "The scored results show that our CWS can increase the Bakeoff baseline system with 4.86% and 5.04% F-measures for the CKIP and the CityU word segmentation tasks, respectively.",
        "On the other hand, we show that the major room for improving our CWS system is the 2-char unknown word extraction of the word boundary model and triple context matching model.",
        "The performance of word support model is great and supports our previous work (Tsai, 2006a and 2006b).",
        "We believe one major advantage of the WBT model is to use it with web as live corpus to minimum the corpus sparseness effect.",
        "Therefore, in the future, we shall investigate the WBT model with the web corpus, such as the searching results of GOOGLE and Yahoo!, etc."
      ]
    }
  ]
}
