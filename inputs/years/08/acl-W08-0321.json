{
  "info": {
    "authors": [
      "Nguyen Bach",
      "Qin Gao",
      "Stephan Vogel"
    ],
    "book": "Proceedings of the Third Workshop on Statistical Machine Translation",
    "id": "acl-W08-0321",
    "title": "Improving Word Alignment with Language Model Based Confidence Scores",
    "url": "https://aclweb.org/anthology/W08-0321",
    "year": 2008
  },
  "references": [
    "acl-J03-1002",
    "acl-J93-2003",
    "acl-P02-1040",
    "acl-P03-1021",
    "acl-P07-2045",
    "acl-W07-0718",
    "acl-W07-0722",
    "acl-W07-0727",
    "acl-W07-0733"
  ],
  "sections": [
    {
      "text": [
        "Improving Word Alignment with Language Model Based Conidence Scores",
        "Nguyen Bach, Qin Gao, Stephan Vogel",
        "This paper describes the statistical machine translation systems submitted to the ACL-WMT 2008 shared translation task.",
        "Systems were submitted for two translation directions: English^ Spanish and Spanish^English.",
        "Using sentence pair confidence scores estimated with source and target language models, improvements are observed on the News-Commentary test sets.",
        "Genre-dependent sentence pair confidence score and integration of sentence pair confidence score into phrase table are also investigated."
      ]
    },
    {
      "heading": "1. Introduction",
      "text": [
        "Word alignment models are a crucial component in statistical machine translation systems.",
        "When estimating the parameters of the word alignment models, the sentence pair probability is an important factor in the objective function and is approximated by the empirical probability.",
        "The empirical probability for each sentence pair is estimated by maximum likelihood estimation over the training data (Brown et al., 1993).",
        "Due to the limitation of training data, most sentence pairs occur only once, which makes the empirical probability almost uniform.",
        "This is a rather weak approximation of the true distribution.",
        "In this paper, we investigate the methods of weighting sentence pairs using language models, and extended the general weighting method to genre-dependent weight.",
        "A method of integrating the weight directly into the phrase table is also explored."
      ]
    },
    {
      "heading": "2. The Baseline Phrase-Based MT System",
      "text": [
        "The ACL-WMT08 organizers provided Europarl and News-Commentary parallel corpora for English <-+ Spanish.",
        "Detailed corpus statistics is given in Table 1.",
        "Following the guidelines of the workshop we built baseline systems, using the lower-cased Europarl parallel corpus (restricting sentence length to 40 words), GIZA++ (Och and",
        "Ney, 2003), Moses (Koehn et al., 2007), and the SRI LM toolkit (Stolcke, 2002) to build 5-gram LMs.",
        "Since no News development sets were available we chose News-Commentary sets as replacements.",
        "We used test-2006 (E06) and nc-devtest2007 (NCd) as development sets for Europarl and News-Commentary; test-2007 (E07) and nc-test2007 (NCt) as held-out evaluation sets.",
        "To improve the baseline performance we trained systems on all true-cased training data with sentence length up to 100.",
        "We used two language models, a 5-gram LM build from the Europarl corpus and a 3-gram LM build from the News-Commentary data.",
        "Instead of interpolating the two language models, we explicitly used them in the decoder and optimized their weights via minimum-error-rate (MER) training (Och, 2003).",
        "To shorten the training time, a multi-threaded GIZA++ version was used to utilize multiprocessor servers (Gao and Vogel, 2008).",
        "Other parameters were the same as the baseline system.",
        "Table 2 shows results in lowercase BLEU (Pap-ineni et al., 2002) for both the baseline (B) and the improved baseline systems (B5) on development and heldout evaluation sets.",
        "We observed significant gains for the News-Commentary test sets.",
        "Our improved baseline systems obtained a comparable performance with the best English^Spanish systems in 2007 (Callison-Burch et al., 2007).",
        "1 English 1 Spanish",
        "Europarl (E)",
        "sentence pairs",
        "1,258,778",
        "unique sent.",
        "pairs",
        "1,235,134",
        "avg.",
        "sentence length",
        "27.9",
        "29.G",
        "# words",
        "35.14 M",
        "36.54 M",
        "vocabulary",
        "1G8.7 K",
        "164.8 K",
        "News-Commentary (NC)",
        "sentence pairs",
        "64,3G8",
        "unique sent.",
        "pairs",
        "64,2G5",
        "avg.",
        "sentence length",
        "24.G",
        "27.4",
        "# words",
        "1.54 M",
        "1.76 M",
        "vocabulary",
        "44.2 K",
        "56.9 K"
      ]
    },
    {
      "heading": "3. Weighting Sentence Pairs 3.1 Problem Definition",
      "text": [
        "The quality of word alignment is crucial for the performance of the machine translation system.",
        "In the well-known so-called IBM word alignment models (Brown et al., 1993), re-estimating the model parameters depends on the empirical probability P(ek, fk) for each sentence pair (ek,fk).",
        "During the EM training, all counts of events, e.g. word pair counts, distortion model counts, etc., are weighted by P(ek,fk).",
        "For example, in IBM Model 1 the lexicon probability of source word f given target word e is calculated as (Och and Ney, 2003):",
        "Therefore, the distribution of P(ek,fk) will affect the alignment results.",
        "In Eqn.",
        "2, P(ek,fk) determines how much the alignments of sentence pair (ek, fk) contribute to the model parameters.",
        "It will be helpful if the P(ek,fk) can approximate the true distribution of P (ek,f k).",
        "Consider that we are drawing sentence pairs from a given data source, and each unique sentence pair (ek, fk) has a probability P (ek ,f k) to be observed.",
        "If the training corpora size is infinite, the normalized frequency of each unique sentence pair will converge to P(ek,fk).",
        "In that case, equally assigning a number to each occurrence of (ek ,fk) and normalizing it will be valid.",
        "However, the assumption is invalid if the data source is finite.",
        "As we can observe in the training corpora, most sentences occur only one time, and thus P(ek, fk) will be uniform.",
        "To get a more informative P(ek,fk), we explored methods of weighting sentence pairs.",
        "We investigated three sets of features: sentence pair confidence (so), genre-dependent sentence pair confidence (gdso) and phrase alignment confidence (po) scores.",
        "These features were calculated over an entire training corpus and could be easily integrated into the phrase-based machine translation system.",
        "We can hardly compute the joint probability of P(ek, fk) without knowing the conditional probability P(ek \\fk) which is estimated during the alignment process.",
        "Therefore, to estimate P(ek, fk) before alignment, we make an assumption that P(ek ,f k) = P(ek)P(f k), which means the two sides of sentence pair are independent of each other.",
        "P(ek) and P(fk) can be obtained by using language models.",
        "P(ek) or P(fk), however, can be small when the sentence is long.",
        "Consequently, long sentence pairs will be assigned low scores and have negligible effect on the training process.",
        "Given limited training data, ignoring these long sentences may hurt the alignment result.",
        "To compensate this, we normalize the probability by the sentence length.",
        "We propose the following method to weighting sentence pairs in the corpora.",
        "We trained language models for source and target language, and the average log likelihood (AVG-LL) of each sentence pair was calculated by applying the corresponding language model.",
        "For each sentence pair (ek,fk), the AVG-LL L(ek,f k) is",
        "ekeek logP(ek\\h)",
        "where P(ek\\h) and P(fk\\h) are ngram probabilities.",
        "The sentence pair confidence score is then given by:",
        "sc(ek ,f k)=exp(L(ek ,f k )).",
        "Genre-Dependent Sentence Pair Confidence",
        "Genre adaptation is one of the major challenges in statistical machine translation since translation models suffer from data sparseness (Koehn and Schroeder, 2007).",
        "To overcome these problems previous works have focused on explicitly modeling topics and on using multiple language and translation models.",
        "Using a mixture of topic-dependent Viterbi alignments was proposed in (Civera and Juan, 2007).",
        "Language and translation model adaptation to Europarl and News-Commentary have been explored in (Paulik et al., 2007).",
        "Given the sentence pair weighting method, it is possible to adopt genre-specific language models into the",
        "EM c(f le; ek,fk)",
        "Pairs",
        "Europarl",
        "NC",
        "E06",
        "E07",
        "NCd",
        "NCt",
        "B B5",
        "33.00 33.33",
        "32.21 32.25",
        "31.84 35.10",
        "30.56 34.08",
        "B B5",
        "33.08 33.26",
        "33.23 33.23",
        "31.18 36.06",
        "31.34 35.56",
        "weighting process.",
        "The genre-dependent sentence pair confidence gdsc simulates weighting the training sentences again from different data sources, thus, given genre g, it can be formulated as:",
        "gdsc(ek ,f k )",
        "sc(ek ,f k\\g) (S) are estimated by genre-",
        "The score generally represents the likelihood of the sentence pair to be in a specific genre.",
        "Thus, if both sides of the sentence pair show a high probability according to the genre-specific language models, alignments in the pair should be more possible to occur in that particular domain, and put more weight may contribute to a better alignment for that genre.",
        "So far the confidence scores are used only in the training of the word alignment models.",
        "Tracking from which sentence pairs each phrase pair was extracted, we can use the sentence level confidence scores to assign confidence scores to the phrase pairs.",
        "Let S(e, f) denote the set of sentences pairs from which the phrase pair (e, f) was extracted.",
        "We calculate then a phrase alignment confidence score po as:",
        "log sc(ek,f k)",
        "This score is used as an additional feature of the phrase pair.",
        "The feature weight is estimated in MER training."
      ]
    },
    {
      "heading": "4. Experimental Results",
      "text": [
        "The first step in validating the proposed approach was to check if the different language models do assign different weights to the sentence pairs in the training corpora.",
        "Using the different language models NC (News-Commentary), EP (Europarl), NC+EP (both NC and EP) the genre-specific sentence pair confidence scores were calculated.",
        "Figure 1 shows the distributions of the differences in these scores across the two corpora.",
        "As expected, the language model build from the NC corpus assigns - on average - higher weights to sentence pairs in the NC corpus and lower weights to sentence pairs in the EP corpus (Figure 1a).",
        "The opposite is true for the EP LM.",
        "When comparing the scores calculated from the NC LM and the combined NC+EP LM we still see a clear separation (Figure 1b).",
        "No marked difference can be seen between using the EP LM and the NC+EP LM (Figure 1c), which again is expected, as the NC corpus is very small compared to the EP corpus.",
        "The next step was to retrain the word alignment models using sentences weights according to the various con-",
        "Figure 1: Histogram of weight differences genre specific confidence scores on NC and EP training corpora",
        "fidence scores.",
        "Table 3 shows training and test set perplexities for IBM model 4 for both training directions.",
        "Not only do we see a drop in training set perplexities, but also in test set perplexities.",
        "Using the genre specific confidence scores leads to lower perplexities on the corresponding test set, which means that using the proposed method does lead to small, but consistent adjustments in the alignment models.",
        "Table 3: IBM model 4 training and test set perplexities using genre specific sentence pair confidence scores.",
        "In the final step the specific alignment models were used to generate various phrase tables, which were then used in translation experiments.",
        "Results are shown in Table 4.",
        "We report lower-cased Bleu scores.",
        "We used nc-dev2007 (NCt1) as an additional held-out evaluation set.",
        "Bold cells indicate highest scores.",
        "As we can see from the results, improvements are obtained by using sentence pair confidence scores.",
        "Using confidence scores calculated from the EP LM gave overall the best performance.",
        "While we observe only a small improvement on Europarl sets, improvements on News-Commentary sets are more pronounced, especially on held-out evaluation sets NCt and NCt1.",
        "The experiments do not give evidence that genre-dependent confidence can improve over using the general confidence where P(ek\\h) and P(fk\\h) specific language models.",
        "Europal Data",
        "News Commentary Data",
        "\" , !",
        ",-\" yY",
        "-",
        "-0.06",
        "-0.04",
        "-0.02 0 0.02",
        "(a) Difference in Weight (NC-EP)",
        "0.04 0.06",
        "-",
        "Europal Data",
        "News Commentary Data \"",
        "-",
        "/ s \\ t v \\",
        "-",
        "-0.06",
        "-0.04",
        "-0.02 0 0.02",
        "(b) Difference in Weight (NC-NE)",
        "0.04 0.06",
        "-",
        "A \\Hz",
        "Europal Data",
        "News Commentary Data -",
        "-",
        "lk\\",
        "1 M 1 M",
        "\"j \\",
        "-",
        "-0.06",
        "-0.04",
        "-0.02 0 0.02",
        "(c) Difference in Weight (NE-EP)",
        "0.04 0.06",
        "Uniform",
        "NC+EP",
        "NC",
        "EP",
        "train",
        "En^Es Es^En",
        "46.76 70.18",
        "42.36 62.81",
        "42.97 62.95",
        "44.47 65.86",
        "test",
        "NC(En^Es) EP(En^Es) NC(Es^En) EP(Es^En)",
        "53.04 91.13 81.39 126.56",
        "53.44 90.89 81.28 125.96",
        "51.09",
        "91.84 78.23",
        "123.23",
        "55.94 90.77 80.33 122.11",
        "Table 5: Translation results (NIST-BLEU) using pc with different genre-specific language models for Es^En systems",
        "score.",
        "As the News-Commentary language model was trained on a very small amount of data further work is required to study this in more detail.",
        "Table 5 shows experiments results in NIST-BLEU using pc score as an additional feature on phrase tables in Es^En systems.",
        "We observed that across development and held-out sets the gains from pc are inconsistent, therefore our submissions are selected from the B5+EP system."
      ]
    },
    {
      "heading": "5. Conclusion",
      "text": [
        "In the ACL-WMT 2008, our major innovations are methods to estimate sentence pair confidence via language models.",
        "We proposed to use source and target language models to weight the sentence pairs.",
        "We developed sentence pair confidence (sc), genre-dependent sentence pair confidence (gdsc) and phrase alignment confidence (pc) scores.",
        "Our experimental results shown that we had a better word alignment and translation performance by using gdsc.",
        "We did not observe consistent improvements by using phrase pair conidence scores in our systems."
      ]
    },
    {
      "heading": "Acknowledgments",
      "text": [
        "This work is in part supported by the US DARPA under the GALE program.",
        "Any opinions, findings, and conclusions or recommendations expressed in this material are those of the authors and do not necessarily reflect the views of DARPA.",
        "Test Set",
        "E06 | E07 | NCd | NCt | NCtl",
        "Es^En",
        "B5",
        "33.26",
        "33.23",
        "36.06",
        "35.56",
        "35.64",
        "NC+EP",
        "33.23",
        "32.29",
        "36.12",
        "35.47",
        "35.97",
        "NC",
        "33.43",
        "33.39",
        "36.14",
        "35.27",
        "35.68",
        "EP",
        "33.36",
        "33.39",
        "36.16",
        "35.63",
        "36.17",
        "En^Es",
        "B5",
        "33.33",
        "32.25",
        "35.10",
        "34.08",
        "34.43",
        "NC+EP",
        "33.23",
        "32.29",
        "35.12",
        "34.56",
        "34.89",
        "NC",
        "33.30",
        "32.27",
        "34.91",
        "34.07",
        "34.29",
        "EP",
        "33.08",
        "32.29",
        "35.05",
        "34.52",
        "35.03",
        "Test Set",
        "E06 | E07 | NCd | NCt | NCt1",
        "Es^En",
        "B5",
        "33.26",
        "33.23",
        "36.06",
        "35.56",
        "35.64",
        "NC+EP+pc",
        "33.54",
        "33.39",
        "36.07",
        "35.38",
        "35.85",
        "NC+pc",
        "33.17",
        "33.31",
        "35.96",
        "35.74",
        "36.04",
        "EP+pc",
        "33.44",
        "32.87",
        "36.22",
        "35.63",
        "36.09",
        "En^Es",
        "B5",
        "33.33",
        "32.25",
        "35.10",
        "34.08",
        "34.43",
        "NC+EP+pc",
        "33.28",
        "32.45",
        "34.82",
        "33.68",
        "33.86",
        "NC+pc",
        "33.13",
        "32.47",
        "34.01",
        "34.34",
        "34.98",
        "EP+pc",
        "32.97",
        "32.20",
        "34.26",
        "33.99",
        "34.34"
      ]
    }
  ]
}
