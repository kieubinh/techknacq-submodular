{
  "info": {
    "authors": [
      "Greg Hanneman",
      "Edmund Huber",
      "Abhaya Agarwal",
      "Vamshi Ambati",
      "Alok Parlikar",
      "Erik Peterson",
      "Alon Lavie"
    ],
    "book": "Proceedings of the Third Workshop on Statistical Machine Translation",
    "id": "acl-W08-0324",
    "title": "Statistical Transfer Systems for French-English and German-English Machine Translation",
    "url": "https://aclweb.org/anthology/W08-0324",
    "year": 2008
  },
  "references": [
    "acl-J03-1002",
    "acl-P02-1040",
    "acl-W07-0718",
    "acl-W07-0734"
  ],
  "sections": [
    {
      "text": [
        "Greg Hanneman and Edmund Huber and Abhaya Agarwal and Vamshi Ambati and Alok Parlikar and Erik Peterson and Alon Lavie",
        "We apply the Stat-XFER statistical transfer machine translation framework to the task of translating from French and German into English.",
        "We introduce statistical methods within our framework that allow for the principled extraction of syntax-based transfer rules from parallel corpora given word alignments and constituency parses.",
        "Performance is evaluated on test sets from the 2007 WMT shared task."
      ]
    },
    {
      "heading": "1. Introduction",
      "text": [
        "The Carnegie Mellon University statistical transfer (Stat-XFER) framework is a general search-based and syntax-driven framework for developing MT systems under a variety of data conditions (Lavie, 2008).",
        "At its core is a transfer engine using two language-pair-dependent resources: a grammar of weighted synchronous context-free rules (possibly augmented with unification-style feature constraints), and a probabilistic bilingual lexicon of syntax-based word-and phrase-level translations.",
        "The Stat-XFER framework has been used to develop research MT systems for a number of language pairs, including Chinese-English, Hebrew-English, Urdu-English, and Hindi-English.",
        "In this paper, we describe our use of the framework to create new French-English and German-English MT systems for the 2008 Workshop on Statistical Machine Translation shared translation task.",
        "We first describe the acquisition and processing of resources for each language pair and the roles of those resources within the Stat-XFER system (Section 2); we then report results on common test sets (Section 3) and share some early analysis and future directions (Section 4)."
      ]
    },
    {
      "heading": "2. System Description",
      "text": [
        "Building a new machine translation system under the Stat-XFER framework involves constructing a bilingual translation lexicon and a transfer grammar.",
        "Over the past six months, we have developed new methods for extracting syntax-based translation lexicons and transfer rules fully automatically from parsed and word-aligned parallel corpora.",
        "These new methods are described in detail by Lavie et al.",
        "(2008).",
        "Below, we detail the statistical methods by which these resources were extracted for our French-English and German-English systems.",
        "The bilingual lexicon is automatically extracted from automatically parsed and word-aligned parallel corpora.",
        "To obtain high-quality statistical word alignments, we run GIZA++ (Och and Ney, 2003) in both the source-to-target and target-to-source directions, then combine the resulting alignments with the Sym2 symmetric alignment heuristic of Ortiz-Martinez et al.",
        "(2005).",
        "From this data, we extract a lexicon of both word-to-word and syntactic phrase-to-phrase translation equivalents.",
        "The word-level correspondences are extracted directly from the word alignments: parts of speech for these lexical entries are obtained from the preterminai nodes of parse trees of the source and target sentences.",
        "If parsers are unavailable for either language, we have also experimented with determining parts of speech with independent taggers such as TreeTagger (Schmid, 1995).",
        "Alternatively, parts of speech may be projected through the word alignments from one language to the other if the information is available on at least one side.",
        "Syntactic phrase-level correspondences are extracted from the parallel data by applying the PFA node alignment algorithm described by Lavie et al.",
        "(2008).",
        "The yields of the aligned parse tree nodes are extracted as constituent-level translation equivalents.",
        "Each entry in the lexicon is assigned a rule score, r, based on its source-side part of speech cs, source-side text ws, target-side part of speech ct, and target-side text wt.",
        "The score is a maximum-likelihood estimate of the distribution of target-language translation and source-and target-language parts of speech, given the source word or phrase.",
        "We employ add-one smoothing in the denominator of Equation 2 to counteract overestimation in the case that #(ws) is small.",
        "Rule scores provide a way to promote the more likely translation alternatives while still retaining a high degree of diversity in the lexicon.",
        "Table 1 shows part of the lexical distribution for the French (source) word paru.",
        "The result of the statistical word alignment process and lexical extraction is a bilingual lexicon containing 1,064,755 entries for French-English and 1,111,510 entries for German-English.",
        "Sample lexical entries are shown in Figure 1.",
        "Transfer grammars for our earlier statistical transfer systems were manually created by in-house experts of the languages involved and were therefore small.",
        "The Stat-XFER framework has since been extended with procedures for automatic grammar acquisition from a parallel corpus, given constituency parses for source or target data or both.",
        "Our French and German systems used the context-free grammar rule extraction process described by Lavie et al.",
        "(2008).",
        "For French, we used 300,000 parallel sentences from the Europarl training data parsed on the English side with the Stanford parser (Klein and Manning, 2003) and on the French side with the Xerox XIP parser (Ait-Mokhtar et al., 2001).",
        "For German, we used 300,000 Europarl sentence pairs parsed with the English and German versions of the Stanford parser.",
        "The set of rules extracted from the parsed corpora was filtered down after scoring to improve system performance and run time.",
        "The final French rule set was comprised of the 1500 most frequently occurring rules.",
        "For German, rules that occurred less than twice were filtered out, leaving a total of 16,469.",
        "In each system, rule scores were again calculated by Equation 2, with ws and wt representing the full right-hand sides of the source and target grammar rules.",
        "A secondary version of our French system used a word-level lexicon extracted from the intersection, rather than the symmetricization, of the GIZA++ alignments in each direction; we hypothesize that this tends to improve precision at the expense of recall.",
        "The word-level lexicon was supplemented with syntax-based phrase-level entries obtained from the PFA node alignment algorithm.",
        "The grammar contained the 700 highest-frequency and the 500 highest-scoring rules extracted from the parallel parsed corpus.",
        "This version had a total lexicon size of 2,023,531 entries and a total grammar of 1034 rules after duplicates were removed.",
        "Figure 2 shows sample grammar rules automatically learned by the process described above.",
        "ws",
        "Cs",
        "wt",
        "ct",
        "r",
        "paru",
        "V",
        "appeared",
        "V",
        "0.2054",
        "paru",
        "V",
        "seemed",
        "V",
        "0.1429",
        "paru",
        "V",
        "found",
        "V",
        "0.0893",
        "paru",
        "V",
        "published",
        "V",
        "0.0804",
        "paru",
        "V",
        "felt",
        "V",
        "0.0714",
        "paru",
        "V",
        "already",
        "ADV",
        "0.0089",
        "paru",
        "V",
        "appear",
        "V",
        "0.0089",
        "paru",
        "V",
        "authoritative",
        "ADJ",
        "0.0089",
        "The Stat-XFER transfer engine runs in a two-stage process, first applying the grammar and lexicon to an input sentence, then running a decoder over the resulting lattice of scored translation pieces.",
        "Scores for each translation piece are based on a log-linear combination ofseveral features: language model probability, rule scores, source-given-target and target-given-source lexical probabilities, parse fragmentation, and length.",
        "For more details, see Lavie (2008).",
        "The use of a German transfer grammar an order of magnitude larger than the corresponding French grammar was made possible due to a recent optimization made in the engine.",
        "When enabled, it constrains the search oftranslation hypotheses to the space of hypotheses whose structure satisfies the consituent structure of a source-side parse."
      ]
    },
    {
      "heading": "3. Evaluation",
      "text": [
        "We trained our model parameters on a subset of the provided \"dev2006\" development set, optimizing for case-insensitive IBM-style BLEU (Papineni et al., 2002) with several iterations of minimum error rate training on n-best lists.",
        "In each iteration's list, we also included the lists from previous iterations in order to maintain a diversity of hypothesis types and data sets, identical with the test data from the 2007 Workshop on Statistical Machine Translation shared task, were used as internal development tests.",
        "Tables 2, 3, and 4 report scores on these data sets for our primary French, secondary French, and German systems.",
        "We report case-insensitive scores for version 0.6 of METEOR (Lavie and Agarwal, 2007) with all modules enabled, version 1.04 of IBM-style BLEU (Papineni et al., 2002), and version 5 of TER (Snover et al., 2006).",
        "Table 3 : Results for the secondary French-English system on provided development and development test sets."
      ]
    },
    {
      "heading": "4. Analysis and Conclusions",
      "text": [
        "From the development test results in Section 3, we note that the Stat-XFER systems' performance currently lags behind the state-of-the-art scores on the 2007 test data.",
        "This may be in part due to the low volume of training data used for rule learning.",
        "A key research question in our approach is how to distinguish low-frequency correct and useful transfer rules from \"noisy\" rules that are due to parser errors and incorrect word alignments.",
        "We believe that learning rules from more data will help alleviate this problem by proportionally increasing the counts of good rules compared to incorrect ones.",
        "We also plan to study methods for more effective rule set pruning, regardless of the volume of training data used.",
        "The difference in metric scores between indomain and out-of-domain data is partly due to effects of reference length on the metrics used.",
        "Detailed output from METEOR and BLEU shows that the reference translations for the test2007 set are about 94% as long as the primary French-English system's translations.",
        "On this set, our system has approximately balanced precision (0.62) and recall (0.66).",
        "However, the nc-test2007 references are only 84% as long as our output, a situation that hurts our system's precision (0.57) but boosts its recall (0.68).",
        "METEOR, as a metric that favors recall, shows a negligible increase in score between these two test sets, while BLEU and TER report significant relative drops of 17.3% and 7.8%.",
        "This behavior appears to be consistent on the test2007 and nc-test2007 data sets across systems (Callison-Burch et al., 2007).",
        "Data Set",
        "METEOR",
        "BLEU",
        "TER",
        "dev2006",
        "0.5332",
        "0.2063",
        "64.81",
        "test2007",
        "0.5358",
        "0.2078",
        "64.75",
        "nc-test2007",
        "0.5369",
        "0.1719",
        "69.83",
        "Data Set",
        "METEOR",
        "BLEU",
        "TER",
        "dev2006",
        "0.5330",
        "0.2086",
        "65.02",
        "test2007",
        "0.5386",
        "0.2129",
        "64.29",
        "nc-test2007",
        "0.5311",
        "0.1680",
        "70.90"
      ]
    },
    {
      "heading": "Acknowledgments",
      "text": [
        "TRAS), and by the DARPA GALE program.",
        "We thank the members of the Parsing and Semantics group at Xerox Research Centre Europe forassisting in parsing the French data using their XIP parser.",
        "Data Set",
        "METEOR",
        "BLEU",
        "TER",
        "dev2006",
        "0.4967",
        "0.1794",
        "68.68",
        "test2007",
        "0.5052",
        "0.1878",
        "67.94",
        "nc-test2007",
        "0.4939",
        "0.1347",
        "74.38"
      ]
    }
  ]
}
