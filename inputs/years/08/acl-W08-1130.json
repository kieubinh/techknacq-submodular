{
  "info": {
    "authors": [
      "Emily Jamison",
      "Dennis Mehay"
    ],
    "book": "Proceedings of the Fifth International Natural Language Generation Conference",
    "id": "acl-W08-1130",
    "title": "OSU-2: Generating Referring Expressions with a Maximum Entropy Classifier",
    "url": "https://aclweb.org/anthology/W08-1130",
    "year": 2008
  },
  "references": [
    "acl-J96-1002",
    "acl-W01-0813"
  ],
  "sections": [
    {
      "text": [
        "Emily Jamison Dennis Mehay",
        "The Ohio State University The Ohio State University",
        "Columbus, OH 43210, USA Columbus, OH 43210, USA",
        "Selection of natural-sounding referring expressions is useful in text generation and information summarization (Kan et al., 2001).",
        "We use discourse-level feature predicates in a maximum entropy classifier (Berger et al., 1996) with binary and n-class classification to select referring expressions from a list.",
        "We find that while mention-type n-class classification produces higher accuracy of type, binary classification of individual referring expressions helps to avoid use of awkward referring expressions."
      ]
    },
    {
      "heading": "1. Introduction",
      "text": [
        "Referring expression generation is the task of inserting noun phrases that refer to a mentioned extralinguistic entity into a text.",
        "REG is helpful for tasks such as text generation and information summarization (Kan etal., 2001)."
      ]
    },
    {
      "heading": "2. Task Description",
      "text": [
        "The Referring Expressions Generation Challenge (Belz and Gatt, 2008) includes a task based on the GREC corpus, a collection of introductory texts from Wikipedia that includes articles about cities, countries, rivers, people, and mountains.",
        "In this corpus, the main topic of each text (MSR) has been replaced with a list of possible referring expressions (REs).",
        "The objective of the task is to identify the most appropriate referring expression from the list for each mention of the MSR, given the surrounding text and annotated syntactic and semantic information."
      ]
    },
    {
      "heading": "3. Predicates",
      "text": [
        "We created 13 predicates, in addition to the six predicates available with the corpus.",
        "All predicates can be used with the binary classification method; only non-RE-level predicates can be used with the n-class classification method.",
        "Predicates describe: string similarity of the RE and the title of the article, the mention's order in the article, distance between previous mention and current mention, and detection of a contrastive discourse entity in the text."
      ]
    },
    {
      "heading": "4. Maximum Entropy Classifier",
      "text": [
        "We defined indicator feature functions for a number of contextual predicates, each describing a pairing of some potential property of the syntactico-semantic and discourse context of a RE (a 'predicate') and a label.",
        "These feature functions fi were used to train a maximum entropy classifier (Berger et al., 1996) (Le, 2004) that assigns a probability to a RE re given context cx as follows:",
        "where Z (cx) is a normalizing sum and the Ai are the parameters (feature weights) learned.",
        "Two classification systems were used: binary and n-class.",
        "With the binary method, the classifier estimates the likelihood of a possible referring expression's correct insertion into the text, and inserts the RE with the highest 'yes' probability.",
        "With the n-class method, the mention is classified according to type of referring expression (proper name, common noun, pronoun, empty) and a RE of the proper type is chosen.",
        "A predicate combinator was implemented to create pairs of predicates for the classifier."
      ]
    },
    {
      "heading": "5. Results",
      "text": [
        "Our results are shown in tables 1 and 2; table 3 shows further per-category results.",
        "N-class classification has a higher type accuracy than the binary method(single: 61.13% versus 44.82%).",
        "Added predicates made a notable difference (single, original predicates: 40.40%; with added predicates: 50.30%).",
        "However, the predicates that detected contrasting discourse entities proved not to be helpful (combinations: 59.30% declined to 58.54%).",
        "Finally, the predicate combinator improved all results (binary, all predicates: 50.30% to 58.54%)."
      ]
    },
    {
      "heading": "6. Discussion",
      "text": [
        "The n-class method does not evaluate characteristics of each individual referring expression.",
        "However, the accuracy measure is designed to judge appropriateness of a referring expression based only on whether its type is correct.",
        "A typical high-accuracy n-class result is shown in example 1.",
        "Example 1: Albania The Republic of Albania itself is a",
        "Balkan country in Southeastern Europe.",
        "Which itself borders Montenegro to the north, the Serbian province of Kosovo to the northeast, the Republic of Macedonia in the east, and Greece in the south.",
        "In example 1, both mentions are matched with an RE that is the proper type (proper name and pronoun, respectively), yet the result is undesireable.",
        "A different example typical of the binary classification method is shown in example 2.",
        "Example 2: Alfred Nobel Alfred Nobel was a Swedish chemist, engineer, innovator, armaments manufacturer and the inventor of dynamite.",
        "[...] In his last will, Alfred Nobel used his enormous fortune to institute the Nobel Prizes.",
        "In example 2, the use of predicates specific to each RE besides the type causes use of the RE \"Alfred Nobel\" as a subject, and the RE \"his\" as a possessive pronoun.",
        "The text, if mildly repetitive, is still comprehensible."
      ]
    },
    {
      "heading": "7. Conclusion",
      "text": [
        "In this study, we used discourse-level predicates and binary and n-class maximum entropy classifiers to select referring expressions.",
        "Eventually, we plan to combine these two approaches, first selecting all REs of the appropriate type and then ranking them.",
        "Predicates Used",
        "Single Combinations",
        "GREC predicates all predicates no contrasting entities all non-RE-level preds",
        "40.40% 50.91% 50.30% 58.54% 50.30% 59.30% 44.82% 51.07%",
        "Table 1: Results with binary classification.",
        "Predicates Used",
        "Single Combinations",
        "all non-RE-level preds",
        "61.13% 62.50%",
        "System",
        "City",
        "Ctry",
        "Mnt",
        "River",
        "Pple",
        "b-all",
        "53.54",
        "57.61",
        "49.58",
        "75.00",
        "65.85",
        "b-nonRE",
        "51.52",
        "53.26",
        "45.83",
        "40.00",
        "57.07",
        "n-nonRE",
        "53.54",
        "63.04",
        "61.67",
        "65.00",
        "67.32"
      ]
    }
  ]
}
