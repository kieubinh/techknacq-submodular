{
  "info": {
    "authors": [
      "Chaveevan Pechsiri",
      "Phunthara Sroison",
      "J. Janviriyasopak"
    ],
    "book": "Coling 2008: Proceedings of the workshop on Cross-Framework and Cross-Domain Parser Evaluation",
    "id": "acl-W08-1603",
    "title": "Know-Why Extraction from Textual Data for Supporting What Questions",
    "url": "https://aclweb.org/anthology/W08-1603",
    "year": 2008
  },
  "references": [],
  "sections": [
    {
      "text": [
        "Know-Why Extraction from Textual Data for Supporting What",
        "Question",
        "Chaveevan Pechsiri Phunthara Sroison U. Janviriyasopak",
        "of Information Dept.",
        "of Information Eastern Industry Co.ltd.",
        "Technology, Technology, Bangkok, Thailand",
        "Bangkok, Thailand Bangkok, Thailand",
        "itdpu @hotmail.com phunthara@it.dpu.ac.th",
        "This research aims to automatically extract Know-Why from documents on the website to contribute knowledge sources to support the question-answering system, especially What-Question, for disease treatment.",
        "This paper is concerned about extracting Know-Why based on multiple EDUs (Elementary Discourse Units).",
        "There are two problems in extracting Know-Why: an identification problem and an effect boundary determination problem.",
        "We propose using Naïve Bayes with three verb features, a causative-verb-phrase concept set, a supporting causative verb set, and the effect-verb-phrase concept set.",
        "The Know-Why extraction results show the success rate of 85.5% precision and 79.8% recall."
      ]
    },
    {
      "heading": "1. Introduction",
      "text": [
        "Automatically Know Why extraction is essential for providing the rational knowledge source, to the society through question answering system, especially in herbal medicines when assisting the locals to understand more about herbs.",
        "According to Jana Trnkova and Wolfgang Theilmann (2004) Know-Why is the knowing of the reason of why something is the way it is.",
        "Therefore, Know-Why has to involve the causal relation which is \"an irreflexive, transitive and asymmetrical\" relation that contains the properties of \"productivity (effect is 'produced' by the cause) and locality (it obeys the markov © 2008.",
        "Some rights reserved.",
        "condition, for model A – B C, if there is no B, then A does not cause C)\"( Lemeire J. et al.",
        "(2004)).",
        "Wolff P. (2007) stated that the causal relation can be decomposed into 2 major approaches, the dependency model and the physicalist models.",
        "The dependency model can be represented by using statistical dependency model whereas in recent physicalist models are based on the concepts of force dynamic models consisting of 2 force entities in certain events; the agonist and the antagonist (Talmy, 2000).",
        "Later, the agonist form (Wolff P., 2007) can be viewed as the 'effect' and the antagonist as the 'cause'.",
        "According to Talmy (2000), if there is a situation where the antagonist is stronger, which can be expressed as 'event X happens because of event Y'(Y contains the antagonist.",
        "), it is a form of causation.",
        "Moreover, the causal relation can pivot on the distinction between causality and causation (Lehmann J. et al., 2004) whereas causality is 'a law-like relation between cause events and effect events' and causation is 'the actual causal relation that holds between individual events'.",
        "For example: \"Because a bird sings a song at a window, The rock is thrown at the window.\"",
        "Causality: \"An object vibrates.",
        "An object moves.\"",
        "Causation: \"A bird sings.",
        "The rock is thrown\" This research focuses only on 'causal relation' to provide both 'causality' for extracting Know-Why from the herbal medicine domain and 'causation' for answering What-question, since what questions contain ambiguities (Girju R. and Moldovan D., 2002) for example:",
        "Know-Why: \"Ivmzmnlmiivmvvmi unnauld imilifimi /A basil leaf is used as a medicine releasing gas.",
        "[The leaf] stops nausea.",
        "[The leaf] stops paining the abdomen.\"",
        "(where the [..] symbol means ellipsis.)",
        "Know-Why concept: \"A herb organ is used as being a carminative drug.",
        "[The organ] is anti nausea, [The organ] is anti stomachache.\"",
        "Question: \"\\%mullmœhimf\\àu\\ëfWhat herb is used for stopping nausea?\"",
        "From this example, 'A basil leaf is used as a medicine releasing gas ' is the causation and the concept is the causality.",
        "There are various forms of causal-relation expression such as in the form of intra-NP, inter-NP, and inter-sentence (Chang and Choi,2004).",
        "According to our research, we separated this relation into 2 main forms based on the elementary discourse unit (EDU) as defined by (Carlson et al., 2003) as a simple sentence or clause.",
        "We defined the intra-causal EDU as an expression within one simple EDU being equivalent to either the intra-NP form or inter-causal EDU is defined as an expression within more than one simple EDU which is equivalent to the inter-sentences of Chang and Choi (2004).",
        "However, this paper works on only the inter-causal EDU extraction because some cause-effect relation from the herbal web sites are expressed in the form of the EDU containing an EDU-like name entity with the causative action followed by some effect EDUs.",
        "Several techniques (Marcu and Echihabi,2002; Torisawa 2003; Inui and et al.,2004; Pechsiri and Kawtrakul, 2007) have been used to extract cause-effect knowledge varying from two adjacent sentences to multiple sentences.",
        "Our work aimed at mining and extracting Know-Why from Thai documents of herbal medicines.",
        "Thai has several specific characteristics, such as the existence of sentence-like name entity, zero anaphora or the implicit noun phrase.",
        "All of these characteristics are involved in the two main problems of Know-Why extraction: the first problem is how to identify the interesting causality events expressed by an EDU- like name entity from documents, and the second one is how to identify the effect boundary, where The problem of implicit delimiter of the boundary is involved.",
        "From all of these problems, we needed to develop a framework which combineed Language Processing and the machine learning technique as Naïve Bayes to learn features of three verb sets, a causative concept verb set, a supporting causative verb set, and an effect concept verb set, for solving those problems.",
        "In conclusion, unlike other methods (Marcu and Echihabi ,2002; Torisawa 2003; Inui and et al.,2004) where the emphasis is based on two adjacent sentences, this paper is based on multiple EDU extraction.",
        "Our research was separated into 5 sections.",
        "In section 2, related work was summarized.",
        "Problems in causality mining from Thai documents will be described in section 3 and in section 4 our framework for causality extraction was explained.",
        "In section 5, we evaluated and concluded our proposed model."
      ]
    },
    {
      "heading": "2. Related Work",
      "text": [
        "Several strategies such as those done by Marcu and Echihabi ,2002, Torisawa( 2003), Inui and et have been proposed to extract and discover knowledge from the textual data.",
        "Marcu and Echihabi (2002) presented the unsupervised approach to recognize the discourse relations by using word pair probabilities between two adjacent sentences for classifying the rhetorical relations, such as Contrast, Cause-Explanation, Condition, and Elaboration, between two adjacent sentences by using Naïve Bayes classifier to the BLIPP corpus (Charniak, 2000).",
        "They determined the word pairs in the cartesian product from the sentence pairs connected with or without discourse marker or connective marker , i.e. 'because' 'but' 'then', to classify the causal relation from other rhetorical relations.",
        "The result showed an accuracy of 75% of inter-sentence causality extraction from the corpus size of more than a million sentences for learning whereas our corpus size is 3000 sentences for learning.",
        "Therefore, our approach is the supervised approach with the statistical method because our corpus size is small.",
        "Inui's work (Inui and et al.,2004) proposed a method of extraction and classification of causal knowledge.",
        "The method of extraction was accomplished under two adjacent sentences by using explicit connective markers; e.g. \"because\" \"since\" \"if..then\" \"as the result\" etc.. SVM was used for the classification process in (Inui and et al.,2004).",
        "Four types of causal relations are studied, including the following: cause, precondition, mean, effect relations.",
        "Inui's work's precision is high: 90% but the recall is low: 30%, because of unresolved anaphora.",
        "However, in our work, we extract multiple EDUs with some implicit discourse markers.",
        "Torisawa( 2003)' s work in extracting the verb phrase pair from the news corpus worked on the assumption that if two events share a common participant (is specified by a noun) then the two events are likely to have a logical relation as causal relation.",
        "For example \"A man drank liquor and was intoxicated by the liquor.",
        "\"(a common participant is 'liquor').",
        "However, this assumption can not be applied in our research because most of our causality expression does not share a common participant; e. g. \"vMluai fsmo imnemn/Ginger is used as being laxative medicine.",
        "[The ginger] stops constipation.",
        "Pechsiri and Kawtrakul (2007), proposed verb-pair rules learned by two different machine learning techniques (NB and SVM) to extract causality with multiple EDUs of a causative unit and multiple EDUs of an effect unit with the problems of the discourse marker ambiguity and the implicit discourse marker.",
        "This verb-pair rule has been represented by the following equation (1) (Pechsiri and Kawtrakul, 2007) where Vcis the causative verb concept set, Ve is the effect verb concept set , C is the Boolean variables of causality and non-causality, and a causative verb concept (vc , where vc eVc) and an effect verb concept (ve , where ve eVe) are referred to Word-Net (http://wordnet.princeton.edu/) and the predefined plant disease information from Department of Agriculture (http://www.doa.go.th/).",
        "CausalityFunction: Vc a Ve C (1)",
        "They also proposed using Vc and Veto solve the boundary of the causative unit and using the Centering theory along with Veto solve the boundary of the effect unit.",
        "The outcomes of their research were the verb-pair rule, Vc, Ve, and the multiple EDUs of causality (extracted from textual data) was at their highest precision of 89% and their highest recall of 76%.",
        "The correctness of the causality-boundary determination is 88% on average.",
        "However, our causative unit consisted of only one EDU containing an EDU-like name entity as a cause, and this EDU was followed by several effect EDUs.",
        "In our current work, we aimed at extracting the Know-Why in Natural Language description instead of visualizing only associations of concepts, by applying both language processing and learning technique by Naïve Bayes to identify the causality expression."
      ]
    },
    {
      "heading": "3. Problem of Know-Why Extraction",
      "text": [
        "To extract the cause-effect expressions, there are two main problems that must be solved.",
        "The first problem is how to identify interesting cause-effect relations from the documents.",
        "The second problem is how to determine the effect boundary.",
        "There is also the problem of implicit noun phrase.",
        "The problem involves the word level and the sentence level.",
        "For the word level, the medicinal name entity may express in the form of a sentence like name entity or an EDU- like name entity which explains the medicinal action as the causative action of medicine, and medical characteristic.",
        "The problem of this level is how to identify the causative name entity.",
        "For example:",
        "a) \"hmximVA basil leaf litems used as vi/ medicine vu/releases mi/gas\" where 'a medicine releases gas' is an EDU-like name entity with the causative action, 'release'.",
        "b) \"imumxmx/Nkolson stem lmiis used for making vi/medicine mi/soaks in m£v liquor\" where 'a medicine soaks in liquor' is an EDU-like name entity with the characteristic of medicine being preserved in the alcohol.",
        "The above examples, a) and b), contain an EDU-like name entity which is a cause in a) and a non cause in b).",
        "For the sentence level, the EDU containing an EDU-like name entity with the causative action may be followed by an effect EDU(s) to form the cause-effect or causality relation between the EDU like name entity and that following EDU(s).",
        "For example:",
        "Causality",
        "EDU1 \"(zhfrisii/Lemon grass litems used as vi/medicine Uwontracts .umn/a uterus\" (where 'a medicine contracts a uterus.'",
        "is the EDU-like name entity with concept of 'the medicine causes uterus to contract'.)",
        "EDU2 \"[The plant ] vu/discharges ilrsfamow period.\"",
        "(=The plant discharges period.)",
        "Non causality",
        "EDU1 \"lumxtmi/A basil leaf litilu/is used as vi/medicine vu/releases em/gas.\"",
        "(where 'a medicine releases gas' is the causative EDU-like name entity.)",
        "EDU2 \"[the basil leaf]fnvi/relieves urn/ulcer lu/inn7stmssirii7/stomach.",
        "\"(= [The basil leaf relives ulcer in a stomach. )",
        "Where in this example, EDU 1 is the cause and EDU2 is the effect",
        "There are two problems of an implicit effect boundary cue and the effect EDU containing interrupts.",
        "3.2.1 Implicit Effect Boundary Cue Some cause-effect relations from the herbal web sites are expressed in the form of the EDU containing an EDU like name entity with the causative action followed by some effect EDUs without any cue of ending effect boundary, e.g. \"un-/ and\".",
        "For example:",
        "EDU1 \"lumstmA basil leaf litSwis used as vv medicine vu/releases em/gas\" (=A basil leaf is used as a medicine releasing gas.)",
        "EDU2 \"[The basil leaf ] tm/stops mull/ nauseate.\"",
        "(=The basil leaf stop being nausea.)",
        "EDU3 \"[And the leaf ] tm/stops Dif/pain isi/ abdomen.\"",
        "(= [And the leaf] stops paining abdomen.)",
        "Where in this example, EDU 1 is the cause and EDU 2 & EDU3 are the effects.",
        "EDU 2 and EDU3 help us to determine the boundary.",
        "3.2.2 Effect EDU Containing Interrupts There are some effect EDUs containing interrupts as shown in the following example:",
        "EDU1 \"'smtfii/A red onion litiluds used as vv medicine +iv /be laxztive\" (=A red onion is used as a laxative medicine.)",
        "EDU2 \"[And the red onion ] tm/stops riswn/ being constipation\" (= [And the red onion] stops being constipation.)",
        "EDU3 \"[The red onion ] vu/discharges Dtitms /urine.\"",
        "(= [The red onion] discharges urine.)",
        "EDU4 \"[The red onion makes a patient] mi-Binij/be appetite.\"",
        "(= [The red onion] makes a patient] be appetite. )",
        "Where the EDU-like name entity in EDU1 is a cause with EDU2 and EDU4 as its effects.",
        "The EDU3 is an interrupt.",
        "Although EDU3 is the effect of red onions, but EDU 3 is not the effect of laxatives."
      ]
    },
    {
      "heading": "4. A Framework for Know-Why Extraction",
      "text": [
        "There are three steps in our framework.",
        "First is the corpus preparation step followed by causality learning, and causality recognition steps (as shown in figure 1).",
        "There are two steps of pre-annotation and Causality annotation.",
        "This step is the preparation of the corpus in the form of EDU from the text.",
        "The step involves using Thai word segmentation tools to solve a boundary of a Thai word and tagging its part of speech (Sudprasert and Kawtrakul, 2003).",
        "This process includes Name entity (Chanlekha and Kawtrakul, 2004), and word-formation recognition (Pengphom, et al. 2002) to solve the boundary of Thai Name entity and Noun phrase.",
        "After the word segmentation is achieved, EDU segmentation is dealt with.",
        "According to Charo-ensuk et al.",
        "(2005), this process segments plain text into units of EDUs by using the rule based and the machine learning technique of C4.5 (Mitchell T.M., 1997).",
        "These generated EDUs will be kept as an EDU corpus.",
        "This corpus will contain 4500 EDUs and will be separated into 2 parts, one part is 3500 EDUs for causality learning and the other part of 1000 EDUs for causality recognition and extraction.",
        "Due to the problems in the causality identification, verbs from three EDUs (with one EDU as an EDU-like name entity) in the EDU corpus are used in this process to learn for extracting causality.",
        "Word ambiguity will be solved through the finding of word concepts from Wordnet.",
        "Since Thai Wordnet does not exist, we need to translate from Thai to English, using Lexitron (the Thai-English dictionary)( http://lexitron.nectec.or.th/), before using Wordnet(http://wordnet.princeton.",
        "edu/obtain).",
        "In this process, we manually annotate the causality EDUs by annotating the EDU containing the causative EDU-like name entity as the causative EDU.",
        "We annotate a verb phrase in the causative EDU-like name entity to be a causative-verb-phrase concept (referred to Wordnet).",
        "The verb from EDU which contains the causative EDU-like name entity is annotated with a concept and we call this verb as 'supporting causative verb'.",
        "We also annotate the effect-verb-phrase concept(referred to Wordnet and http://www.ars-grin.gov/duke/ethnobot.html) from effect EDUs following the EDU containing the causative EDU-like name, as shown in Figure",
        "Corpus preparation",
        "I",
        "Word net",
        "Causality learning",
        "The aim of this step was to learn cause-effect relation between causative events and effect events from annotating an EDU corpus.",
        "All annotated verb features from the previous step are extracted into database table (in Table 1) including surface forms of verb features along with their concepts used for probability determination in the next step.",
        "<EDU type =cause> <NP1 concept=a herb organ>lulnjxwiA basil leaf</NP1> <VS concept=use#1>liDu/is used as</VS> <EDU-Like-NE > <NP2 concept=drug>vimedicine</NP2> <CVC concept= be carminative/ eliminate gas from a body> vu/releases em/ gas <EDU type=effect> <EVC concept= stop nausea/ be anti nausea>tm/stops mu'W nauseate.",
        "<EVC concept=stop paining an abdomen/ relieve abdominal pain> mi/ stops Dif/pain mi/abdomen",
        "EDU= EDU, EDU-Like-NE= EDU-like name entity tag, C=cause tag, R=result or effect tag, VS= supporting verb tag , CVC=causative verb concept tag, EVC=effect verb concept tag NP1 NP2= noun phrase tag",
        "NP1",
        "NP1",
        "Concept",
        "Vs",
        "Vs Concept",
        "VPc",
        "VPc",
        "concept",
        "VPe",
        "VPe Concept",
        "Class",
        "Naringi",
        "herb",
        "use as",
        "cure",
        "be-antipyretic",
        "unÜita",
        "relieve muscle pain",
        "n",
        "crenulata",
        "poison",
        "ihun/ Asiatic Pennyworth",
        "herb leaf",
        "tfllÜH",
        "use as",
        "vn fnjjuan/",
        "apply externally",
        "apply",
        "topically",
        "heal wound",
        "y",
        "herb",
        "ÜH",
        "is",
        "fhjj/",
        "be-lexative",
        "stop being",
        "y",
        "red onion",
        "excrete",
        "constipation",
        "herb",
        "ÜH",
        "is",
        "be-lexative",
        "%u",
        "discharge urine",
        "n",
        "red onion",
        "excrete",
        "herb",
        "ÜH",
        "is",
        "be-lexative",
        "nlyy",
        "be appetite",
        "y",
        "red onion",
        "excrete",
        "herb",
        "ÜH",
        "is",
        "be-antiseptic",
        "ïnm",
        "cure skin",
        "y",
        "curcumin",
        "antiseptic",
        "disease",
        "Soianum indicum Linn",
        "herb",
        "VhlÜH",
        "make as",
        "a (allien a tmaata/ reduce blood",
        "balance blood sugar level",
        "stop coughing",
        "n",
        "sugar",
        "Basil",
        "herb leaf",
        "tfllÜH",
        "use as",
        "release gas",
        "be",
        "carminative",
        "relieve nausea",
        "y",
        "herb leaf",
        "tfllÜH",
        "use as",
        "release gas",
        "be",
        "stop paining",
        "y",
        "Basil",
        "carminative",
        "an abdomen",
        "/ ginger",
        "herb",
        "tfllÜH",
        "use as",
        "release gas",
        "be",
        "carminative",
        "relieve nausea",
        "y",
        "mn$ /",
        "be",
        "carminative",
        "bergamot",
        "herb leaf",
        "tfllÜH",
        "use as",
        "release",
        "relieve nausea",
        "y",
        "leaf",
        "gas",
        "by class1 (causality EDUs) and class0 (non causality EDUs).",
        "4.2.2 Probability Determination After we had obtained the extracted verb features, we then determined the probability of causal and non causal from the occurrences of the cartesian products of three verb feature concepts , shown in Table2, by using Weka which is a software tool for machine learning (http://www.cs.",
        "wai-kato.ac.nz/ml/weka/ ).",
        "The objective of this step was to recognize and extract the cause-effect relation from the testing EDU corpus.",
        "In order to start the causality recognition process, Naïve Bayes Classifer shown in equation (2) is applied with the feature probabilities in Table 2, where EDUs class is determined",
        "EDUclass= argmax P(class\\vs ,vpc ,vpe) =argmax P(vs \\class)P(vpc \\class)P(vpe Iclass)P(class) vs eVswhereVs isa Supporting Causative Verb concept set vpc eVPc whereVPc isa Causative VerbPhrase concept set vpe eVPe whereVPe isa Effect VerbPhraseconcept set",
        "Therefore, Causality Recognition can be separated into 2 steps: causality identification and effect boundary determination.",
        "This step was to determine the interesting locations that are cause-effect relations by searching any EDU which consists of a verb matching to a verb in the supporting causative concept set, Vs, and an EDU-like name entity containing a causative-verb-phrase concept as vpc (where vpceVPc).",
        "The effect EDU and the effect boundary were determined at the same time by checking all sequence EDUs right after the EDU containing vpc in the EDU-like name entity.",
        "If a verb phrase from the sequence of checked EDUs is not in VPe, the possible effect boundary is end.",
        "After the possible boundary is determined, vsinEDU1, vpc_inEDui and vpejnEDU2..vpe_mEDUn (where n>2) will be used to determine the causality class from the Naïve Bayes Classifier equation (2) as shown in Figure 3.",
        "The actual effect boundary is determined from the last class1 in the sequence of",
        "EDU2.. EDUn.",
        "Furthermore, where the implicit noun phrase occurs as the subject of the current EDU, this has to be solved in this step by using the heuristic rule which is that the noun phrase as a subject of the previous EDU will be the subject of the current EDU.",
        "Vs concept",
        "causality",
        "non causality",
        "tä-HÜHZuse as",
        "0.27619",
        "0.290323",
        "Be",
        "0.561905",
        "0.612903",
        "Vh+lÜHZmakeas",
        "0.009524",
        "0.032258",
        "TÜ+vn+lÜHZuse for making as",
        "0.066667",
        "0.053763",
        "VPc concept",
        "causality",
        "non",
        "causality",
        "'%U+83J/release-gas'",
        "0.371901",
        "0.192661",
        "'un+la/anti coughing'",
        "0.024793",
        "0.045872",
        "'Ml/apply'",
        "0.140496",
        "0.009174",
        "'%3J/be-bitter'",
        "0.041322",
        "0.009174",
        "'% U+Ü S SI ï/discharge-urine'",
        "0.057851",
        "0.06422",
        "'%ïl+lâ3JVit:/be expectorant'",
        "0.041322",
        "0.06422",
        "'UlJ+3J@an/contract uterus/oxytocic'",
        "0.041322",
        "0.027523",
        "'Sfim+mivmH/be antidiabetic'",
        "0.008264",
        "0.027523",
        "VPe concept",
        "causality",
        "non",
        "causality",
        "'un+Üia+wao/stop-stomachach/relieve abdominal pain'",
        "0.035714",
        "0.007813",
        "'un+PläHtä/stop-naucea/be anti nausea'",
        "0.035714",
        "0.007813",
        "'un+MaoaaViaoir) a/stop-flatulence/relieve indigestion'",
        "0.15",
        "0.007813",
        "'un+a3JWH/stop-rash/ be antiurti-caria'",
        "0.035714",
        "0.023438",
        "'aal%/reduce-fever'",
        "0.021429",
        "0.039063",
        "'%U+5n/eliminate-placenta'",
        "0.007143",
        "0.054688",
        "'tsyy+aivns/increase appetite'",
        "0.092857",
        "0.007813",
        "'%ïl+ivi3 a/release-sweat/be diaphoretic'",
        "0.007143",
        "0.070313",
        "Assume that each EDU is represented by (np vp) L is a list of EDU",
        "VPC is a causative-verb-phrase concept set, VPE /VPe is a effect-verb-phrase concept set VS is a supporting causative verb concept set CAUSALITY_EXTRACTION ( L, VC, VE, Vs )"
      ]
    },
    {
      "heading": "2. while i < length[L] do",
      "text": []
    },
    {
      "heading": "3. begin_while1",
      "text": []
    },
    {
      "heading": "6. begin_if",
      "text": [
        "tive EDU 7 while (vpi e VPE) do"
      ]
    },
    {
      "heading": "8. begin_while2",
      "text": []
    },
    {
      "heading": "10. if res=yes",
      "text": []
    },
    {
      "heading": "13. end_while2",
      "text": []
    },
    {
      "heading": "14. endif",
      "text": []
    },
    {
      "heading": "17. end_while1",
      "text": []
    },
    {
      "heading": "18. return R",
      "text": [
        "Figure3.",
        "Show Causality Extraction algorithm for the EDU containing the causative EDU-like name entity, and followed by multiple effect EDUs ."
      ]
    },
    {
      "heading": "5. Evaluation and Conclusion",
      "text": [
        "The Thai corpora used to evaluate the proposed causality extraction algorithm consist of about 1,000 EDUs collected from several herbal web sites.",
        "The evaluation of the causality extraction performance of this research methodology is expressed in terms of the precision and the recall as shown below, where R is the causality relation:",
        "Precision",
        "# of samples correctly extracted asR (4) # of all samples holding the target relation R",
        "The results of precision and recall are evaluated by three expert judgments with max win voting.",
        "The precision of the extracted causality 85.5% with 79.8% recall.",
        "The correctness of our effect boundary determination by these expert judgments is 86%.",
        "These research results can be increased if we use a larger corpus.",
        "However, our methodology will be very beneficial for contribute the causality knowledge for supporting What-question with the concept of causal relation from a web page by inference method of backward chaining, for example:",
        "Extracted causality: \"lulmzmlMuoivum ttnnauU tin",
        "Difisi /A basil leaf is used for a gas released medicine.",
        "[The leaf] stops nausea.",
        "[The leaf] stop stomachache.\"",
        "The above extracted causality can be represented by the following predication.",
        "a) Vx be_herb(x) A be_herb_medicine(y) Abe_carminative (y) a use_as(x,y)-> stop(x, z) a be_nausea(z) b) Vx be_herb(x) A be_herb_medicine(y) A be_carminative (y) Ause_as(x,y)- stop(x, z) A be_abdominal pain(z)",
        "Where x e X,{'1un«™n/basil leaf 'Wginger' 'iNtn'biei/black pepper' 'luu-ntfi/bergamot leaf..}, and X is the extracted NP1 set from EDUs containing the causative EDU-like name entities and being followed by the effect EDUs , e.g. (stop(x, z) A be_nausea(z)), (stop(x, z) A be_stomach ache(z)).",
        "Question: \"M/use mju'lm/herb ssfc/what an/stop niuli/nausea (What kind of herb is used for stop nausea?)",
        "The backward chaining from the above question and the extracted causality in a) is shown in the following where x is '1un«™n/basil leaf, 'Wginger', 'iNlfi'lra/black pepper', or 'luu-ntfi/bergamot leaf"
      ]
    }
  ]
}
