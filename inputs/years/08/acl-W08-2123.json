{
  "info": {
    "authors": [
      "Richard Johansson",
      "Pierre Nugues"
    ],
    "book": "CoNLL 2008: Proceedings of the Twelfth Conference on Computational Natural Language Learning",
    "id": "acl-W08-2123",
    "title": "Dependency-based Syntactic–Semantic Analysis with PropBank and NomBank",
    "url": "https://aclweb.org/anthology/W08-2123",
    "year": 2008
  },
  "references": [
    "acl-C96-1058",
    "acl-D07-1101",
    "acl-E06-1011",
    "acl-P05-1013"
  ],
  "sections": [
    {
      "text": [
        "Dependency-based Syntactic-Semantic Analysis with PropBank and",
        "NomBank",
        "Lund Univei",
        "{richard, pie]",
        "This paper presents our contribution in the closed track of the 2008 CoNLL Shared Task (Surdeanu et al., 2008).",
        "To tackle the problem of joint syntactic-semantic analysis, the system relies on a syntactic and a semantic subcomponent.",
        "The syntactic model is a bottom-up projective parser using pseudo-projective transformations, and the semantic model uses global inference mechanisms on top of a pipeline of classifiers.",
        "The complete syntactic-semantic output is selected from a candidate pool generated by the subsystems.",
        "The system achieved the top score in the closed challenge: a labeled syntactic accuracy of 89.32%, a labeled semantic Fl of 81.65, and a labeled macro Fl of 85.49."
      ]
    },
    {
      "heading": "1. Introduction: Syntactic-Semantic Analysis",
      "text": [
        "Intuitively, semantic interpretation should help syntactic disambiguation, and joint syntactic-semantic analysis has a long tradition in linguistic theory.",
        "This motivates a statistical modeling of the problem of finding a syntactic tree ysyn and a semantic graph ysem for a sentence x as maximizing a function F that scores the joint syntactic-semantic structure:",
        "{fjsyni fjsem) – arg Iliax F(x,ySyn,ysern^",
        "The dependencies in the feature representation used to compute F determine the tractability of the search procedure needed to perform the maximization.",
        "To be able to use complex syntactic features",
        "© 2008.",
        "Some rights reserved.",
        "and Pierre Nugues sity, Sweden such as paths when predicting semantic structures, exact search is clearly intractable.",
        "This is true even with simpler feature representations - the problem is a special case of multi-headed dependency analysis, which is NP-hard even if the number of heads is bounded (Chickering et al., 1994).",
        "This means that we must resort to a simplification such as an incremental method or a reranking approach.",
        "We chose the latter option and thus created syntactic and semantic submodels.",
        "The joint syntactic-semantic prediction is selected from a small list of candidates generated by the respective subsystems."
      ]
    },
    {
      "heading": "2. Syntactic Submodel",
      "text": [
        "We model the process of syntactic parsing of a sentence x as finding the parse tree ysyn = arg maxy F(x, y) that maximizes a scoring function F. The learning problem consists of fitting this function so that the cost of the predictions is as low as possible according to a cost function p. In this work, we consider linear scoring functions of the following form:",
        "where ^(x, y) is a numeric feature representation of the pair (a;, y) and w a vector of feature weights.",
        "We defined the syntactic cost p as the sum of link costs, where the link cost was 0 for a correct dependency link with a correct label, 0.5 for a correct link with an incorrect label, and 1 for an incorrect link.",
        "A widely used framework for fitting the weight vector is the max-margin model (Taskar et al., 2003), which is a generalization of the well-known support vector machines to general cost-based prediction problems.",
        "Since the large number of training examples and features in our case make an exact solution of the max-margin optimization problem impractical, we used the online passive-aggressive algorithm (Crammer et al., 2006), which approximates the optimization process in two ways:",
        "• The weight vector w is updated incrementally, one example at a time.",
        "• For each example, only the most violated constraint is considered.",
        "The algorithm is a margin-based variant of the per-ceptron (preliminary experiments show that it outperforms the ordinary perceptron on this task).",
        "Algorithm 1 shows pseudocode for the algorithm.",
        "Algorithm 1 The Online PA Algorithm",
        "input Training set T = {(xt,yt)}T=i Number of iterations N Regularization parameter C Initialize w to zeros repeat N times for (xt,yt) inT",
        "We used a C value of 0.01, and the number of iterations was 6.",
        "The feature function * is a second-order edge-factored representation (McDonald and Pereira, 2006; Carreras, 2007).",
        "The second-order representation allows us to express features not only of head-dependent links, but also of siblings and children of the dependent.",
        "This feature set forces us to adopt the expensive search procedure by Carreras (2007), which extends Eisner's span-based dynamic programming algorithm (1996) to allow second-order feature dependencies.",
        "Since the cost function p is based on the cost of single links, this procedure can also be used to find the maximizer of F(xi, ijij) + p(yi, ijij), which is needed at training time.",
        "The search was constrained to disallow multiple root links.",
        "Although only 0.4% of the links in the training set are nonprojective, 7.6% of the sentences contain at least one nonprojective link.",
        "Many of these links represent long-range dependencies - such as wh-movement - that are valuable for semantic processing.",
        "Nonprojectivity cannot be handled by span-based dynamic programming algorithms.",
        "For parsers that consider features of single links only, the Chu-Liu/Edmonds algorithm can be used instead.",
        "However, this algorithm cannot be generalized to the second-order setting - McDonald and Pereira (2006) proved that this problem is NP-hard, and described an approximate greedy search algorithm.",
        "To simplify implementation, we instead opted for the pseudo-projective approach (Nivre and Nilsson, 2005), in which nonprojective links are lifted upwards in the tree to achieve projectivity, and special trace labels are used to enable recovery of the nonprojective links at parse time.",
        "The use of trace labels in the pseudo-projective transformation leads to a proliferation of edge label types: from 69 to 234 in the training set, many of which occur only once.",
        "Since the running time of our parser depends on the number of labels, we used only the 20 most frequent trace labels."
      ]
    },
    {
      "heading": "3. Semantic Submodel",
      "text": [
        "Our semantic model consists of three parts:",
        "• A SRL classifier pipeline that generates a list of candidate predicate-argument structures.",
        "• A constraint system that filters the candidate list to enforce linguistic restrictions on the global configuration of arguments.",
        "• A global classifier that rescores the predicate-argument structures in the filtered candidate list.",
        "Rather than training the models on gold-standard syntactic input, we created an automatically parsed training set by 5-fold cross-validation.",
        "Training on automatic syntax makes the semantic classifiers more resilient to parsing errors, in particular adjunct labeling errors.",
        "The SRL pipeline consists of classifiers for predicate identification, predicate disambiguation, support identification (for noun predicates), argument identification, and argument classification.",
        "We trained one set of classifiers for verb predicates and another for noun predicates.",
        "For the predicate disambiguation classifiers, we trained one subclassifier for each lemma.",
        "All classifiers in the pipeline were L2-regularized linear logistic regression classifiers, implemented using the efficient Liblinear package (Lin et al., 2008).",
        "For multi-class problems, we used the one-vs-all binarization method, which makes it easy to prevent outputs not allowed by the PropBank or NomBank frame.",
        "Since our classifiers were logistic, their output values could be meaningfully interpreted as probabilities.",
        "This allowed us to combine the scores from subclassifiers into a score for the complete predicate-argument structure.",
        "To generate the candidate lists used by the global SRL models, we applied beam search based on these scores using a beam width of 4.",
        "The features used by the classifiers are listed in Tables 1 and 2.",
        "In the tables, the features used by the classifiers for noun and verb predicates are indicated by N and V, respectively.",
        "We selected the feature sets by greedy forward subset selection.",
        "Table 1: Classifier features in predicate identification and disambiguation.",
        "Feature Supp Argld ArgCl",
        "Table 2: Classifier features in argument identification and classification and support detection.",
        "Features Used in Predicate Identification and Disambiguation",
        "PredWord, PredLemma.",
        "The lexical form and lemma of the predicate.",
        "PredParentWord and PredParentPOS.",
        "Form and part-of-speech tag of the parent node of the predicate.",
        "ChildDepSet, ChildWordSet, ChildWordDepSet, ChildPOSSet, ChildPOSDepSet.",
        "These features represent the set of dependents of the predicate using combinations of dependency labels, words, and parts of speech.",
        "DepSubcat.",
        "Subcategorization frame: the concatenation of the dependency labels of the predicate dependents.",
        "PredRelToParent.",
        "Dependency relation between the predicate and its parent.",
        "Features Used in Argument Identification and Classification",
        "PredLemmaSense.",
        "The lemma and sense number of the predicate, e.g. give.01.",
        "voice.",
        "For verbs, this feature is Active or Passive.",
        "For nouns, it is not defined.",
        "position.",
        "Position of the argument with respect to the predicate: Before, After, or On.",
        "argword and ArgPOS.",
        "Lexical form and part-of-speech tag of the argument node.",
        "LeftWord, LeftPOS, RightWord, Right-POS.",
        "Form/part-of-speech tag of the leftmost/rightmost dependent of the argument.",
        "LeftSiblingWord, LeftSiblingPOS, RightSiblingWord, RightSibling-POS.",
        "Form/part-of-speech tag of the left/right sibling of the argument.",
        "PredPOS.",
        "Part-of-speech tag of the predicate.",
        "relpath.",
        "A representation of the complex grammatical relation between the predicate and the argument.",
        "It consists of the sequence of dependency relation labels and link directions in the path between predicate and argument, e.g. IMTOPRDtOBjj.",
        "pospath.",
        "An alternative view of the grammatical relation, which consists of the pos tags passed when moving from predicate to argument, e.g. VB|TOtVBP|PRP.",
        "RelPathToSupport.",
        "The RelPath from the argument to a support chain.",
        "VerbChainHasSubj.",
        "Binary feature that is set to true if the predicate verb chain has a subject.",
        "The purpose of this feature is to resolve verb coordination ambiguity as in Figure 1.",
        "ControllerHasObj.",
        "Binary feature that is true if the link between the predicate verb chain and its parent is OPRD, and the parent has an object.",
        "This feature is meant to resolve control ambiguity as in Figure 2.",
        "Feature",
        "Predld",
        "PredDis",
        "PredWord",
        "N,V",
        "N,V",
        "PredLemma",
        "N,V",
        "N,V",
        "PredParentWord/POS",
        "N,V",
        "N,V",
        "ChildDepSet",
        "N,V",
        "N,V",
        "ChildWordSet",
        "N,V",
        "N,V",
        "ChildWordDepSet",
        "N,V",
        "N,V",
        "ChildPOSSet",
        "N,V",
        "N,V",
        "ChildPOSDepSet",
        "N,V",
        "N,V",
        "DepSubcat",
        "N,V",
        "N,V",
        "PredRelToParent",
        "N,V",
        "N,V",
        "PredParentWord/POS",
        "N",
        "N,V",
        "ChildDepSet",
        "N",
        "N,V",
        "N,V",
        "PredLemmaSense",
        "N",
        "N,V",
        "N,V",
        "Voice",
        "V",
        "V",
        "Position",
        "N",
        "N,V",
        "N,V",
        "ArgWord/POS",
        "N",
        "N,V",
        "N,V",
        "LeftWord/POS",
        "N",
        "N,V",
        "RightWord/POS",
        "N",
        "N,V",
        "N,V",
        "LeftSiblingWord/POS",
        "N,V",
        "RightSiblingWord/POS",
        "N",
        "N",
        "PredPOS",
        "N",
        "N,V",
        "V",
        "RelPath",
        "N",
        "N,V",
        "N,V",
        "POSPath",
        "N",
        "RelPathToSupport",
        "N",
        "N",
        "VerbChainHasSubj",
        "V",
        "V",
        "ControllerHasObj",
        "V",
        "N",
        "PredRelToParent",
        "N",
        "N,V",
        "N,V",
        "Function",
        "N,V",
        "FUNCTION.",
        "The grammatical function of the argument node.",
        "For direct dependents of the predicate, this is identical to the RELPATH.",
        "I want him to sleep",
        "I want to sleep",
        "The following three global constraints were used to filter the candidates generated by the pipeline.",
        "Core Argument Consistency.",
        "Core argument labels must not appear more than once.",
        "Discontinuity Consistency.",
        "If there is a label C-X, it must be preceded by a label X.",
        "Reference Consistency.",
        "If there is a label R-X and the label is inside a relative clause, it must be preceded by a label X.",
        "Toutanova et al.",
        "(2005) have showed that a global model that scores the complete predicate-argument structure can lead to substantial performance gains.",
        "We therefore created a global SRL classifier using the following global features in addition to the features from the pipeline:",
        "Core Argument Label Sequence.",
        "The complete sequence of core argument labels.",
        "The sequence also includes the predicate and voice, for instance AO+break.01/Active+Al.",
        "Missing Core Argument Labels.",
        "The set of core argument labels declared in the Prop-Bank/NomBank frame that are not present in the predicate-argument structure.",
        "Similarly to the syntactic submodel, we trained the global SRL model using the online passive-aggressive algorithm.",
        "The cost function p was defined as the number of incorrect links in the predicate-argument structure.",
        "The number of iterations was 20 and the regularization parameter C was 0.01.",
        "Interestingly, we noted that the global SRL model outperformed the pipeline even when no global features were added.",
        "This shows that the global learning model can correct label bias problems introduced by the pipeline architecture."
      ]
    },
    {
      "heading": "4. Syntactic-Semantic Integration",
      "text": [
        "Our baseline joint feature representation contained only three features: the log probability of the syntactic tree and the log probability of the semantic structure according to the pipeline and the global model, respectively.",
        "This model was trained on the complete training set using cross-validation.",
        "The probabilities were obtained using the multinomial logistic function (\"softmax\").",
        "We carried out an initial experiment with a more complex joint feature representation, but failed to improve over the baseline.",
        "Time prevented us from exploring this direction conclusively."
      ]
    },
    {
      "heading": "5. Results",
      "text": [
        "The submitted results on the development and test corpora are presented in the upper part of Table 3.",
        "After the submission deadline, we corrected a bug in the predicate identification method.",
        "This resulted in improved results shown in the lower part.",
        "Table 4 shows the effect of adding second-order features to the parser in terms of accuracy as well as training and parsing time on a Mac Pro, 3.2 GHz.",
        "The training times were measured on the complete training set and the parsing time and accuracies on the development set.",
        "Similarly to Car-reras (2007), we see that these features have a very large impact on parsing accuracy, but also that the parser pays dearly in terms of efficiency as the search complexity increases from 0(n) to 0{nA).",
        "Corpus",
        "Syn acc",
        "SemFl",
        "Macro Fl",
        "Development",
        "88.47",
        "80.80",
        "84.66",
        "Test WSJ",
        "90.13",
        "81.75",
        "85.95",
        "Test Brown",
        "82.81",
        "69.06",
        "75.95",
        "Test WSJ + Brown",
        "89.32",
        "80.37",
        "84.86",
        "Development",
        "88.47",
        "81.86",
        "85.17",
        "Test WSJ",
        "90.13",
        "83.75",
        "86.61",
        "Test Brown",
        "82.84",
        "69.85",
        "76.34",
        "Test WSJ + Brown",
        "89.32",
        "81.65",
        "85.49",
        "Since the low efficiency of the second-order parser restricts its use to batch applications, we see an interesting research direction to find suitable compromises between the two approaches, for instance by sacrificing the exact search procedure.",
        "Table 5 shows the dependency types most affected by the addition of second-order features to the parser when ordered by the increase in Fl.",
        "As can be seen, they are all verb adjunct categories, which demonstrates the effect of grandchild features on PP attachment and labeling.",
        "To assess the effect of the components in the semantic submodel, we tested their performance on the top-scoring parses from the syntactic model.",
        "Table 6 shows the results.",
        "The baseline system consists of the SRL pipeline only (P).",
        "Adding linguistic constraints (C) results in a more precision-oriented system with slightly lower recall, but significantly higher Fl.",
        "Even higher performance is obtained when adding the global SRL model (G).",
        "The final experiment concerned the integration of syntactic and semantic analysis.",
        "In this setting, the system chooses the output that maximizes the joint syntactic-semantic score, based on the top N syntactic trees.",
        "Table 7 shows the results on the development set.",
        "We see that syntactic-semantic integration improves both syntactic accuracy and semantic Fl.",
        "This holds for the constraint-based SRL system as well as for the full system."
      ]
    },
    {
      "heading": "6. Conclusion",
      "text": [
        "We have described a system for syntactic and semantic dependency analysis based on PropBank and NomBank, and detailed the implementation of its subsystems.",
        "Crucial to our success was the high performance of the syntactic parser, which achieved a high accuracy.",
        "In addition, we reconfirmed the benefits of global inference in semantic analysis: both constraint-based and learning-based methods resulted in improvements over a baseline.",
        "Finally, we showed that integration of syntactic and semantic analysis is beneficial for both sub-tasks.",
        "We hope that this shared task will spur further research that leads to new feature representations and search procedures to handle the problem of joint syntactic and semantic analysis.",
        "Sern model",
        "N",
        "Syn acc",
        "SemFl",
        "Macro Fl",
        "P+C",
        "1",
        "88.33",
        "79.97",
        "84.17",
        "P+C",
        "16",
        "88.42",
        "80.42",
        "84.44",
        "P+C+G",
        "1",
        "88.33",
        "80.40",
        "84.39",
        "P+C+G",
        "16",
        "88.47",
        "80.80",
        "84.66",
        "System",
        "Training",
        "Parse",
        "Labeled",
        "Unlabeled",
        "1 st order",
        "65 min",
        "28 sec",
        "85.78",
        "89.51",
        "2nd order",
        "60 hours",
        "34 min",
        "88.33",
        "91.43",
        "Label",
        "Afi",
        "AP",
        "A Fi",
        "TMP",
        "14.7",
        "12.9",
        "13.9",
        "DTV",
        "0",
        "19.9",
        "10.5",
        "LOC",
        "7.8",
        "12.3",
        "9.9",
        "PRP",
        "12.4",
        "6.7",
        "9.6",
        "DIR",
        "5.9",
        "7.2",
        "6.5",
        "System",
        "P",
        "R",
        "Fl",
        "P",
        "80.74",
        "77.98",
        "79.33",
        "P+C",
        "82.42",
        "77.66",
        "79.97",
        "P+C+G",
        "83.64",
        "78.14",
        "80.40"
      ]
    }
  ]
}
