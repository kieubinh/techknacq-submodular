{
  "info": {
    "authors": [
      "Jun Suzuki",
      "Hideki Isozaki",
      "Xavier Carreras",
      "Michael John Collins"
    ],
    "book": "EMNLP",
    "id": "acl-D09-1058",
    "title": "An Empirical Study of Semi-supervised Structured Conditional Models for Dependency Parsing",
    "url": "https://aclweb.org/anthology/D09-1058",
    "year": 2009
  },
  "references": [
    "acl-C96-1058",
    "acl-D07-1014",
    "acl-D07-1015",
    "acl-D07-1070",
    "acl-D07-1096",
    "acl-D07-1101",
    "acl-E06-1011",
    "acl-H05-1066",
    "acl-J92-4003",
    "acl-P05-1012",
    "acl-P08-1061",
    "acl-P08-1068",
    "acl-P08-1076",
    "acl-P99-1065",
    "acl-W06-1615",
    "acl-W06-2920",
    "acl-W07-2216",
    "acl-W96-0213"
  ],
  "sections": [
    {
      "text": [
        "An Empirical Study of Semi-supervised Structured Conditional Models",
        "for Dependency Parsing",
        "Jun Suzuki, Hideki Isozaki Xavier Carreras, and Michael Collins",
        "NTT CS Lab., NTT Corp. MIT CSAIL",
        "Kyoto, 619-0237, Japan Cambridge, MA 02139, USA",
        "This paper describes an empirical study of high-performance dependency parsers based on a semi-supervised learning approach.",
        "We describe an extension of semi-supervised structured conditional models (SS-SCMs) to the dependency parsing problem, whose framework is originally proposed in (Suzuki and Isozaki, 2008).",
        "Moreover, we introduce two extensions related to dependency parsing: The first extension is to combine SS-SCMs with another semi-supervised approach, described in (Koo et al., 2008).",
        "The second extension is to apply the approach to second-order parsing models, such as those described in (Carreras, 2007), using a two-stage semi-supervised learning approach.",
        "We demonstrate the effectiveness of our proposed methods on dependency parsing experiments using two widely used test collections: the Penn Treebank for English, and the Prague Dependency Treebank for Czech.",
        "Our best results on test data in the above datasets achieve 93.79% parent-prediction accuracy for English, and 88.05% for Czech."
      ]
    },
    {
      "heading": "1. Introduction",
      "text": [
        "Recent work has successfully developed dependency parsing models for many languages using supervised learning algorithms (Buchholz and Marsi, 2006; Nivre et al., 2007).",
        "Semi-supervised learning methods, which make use of unlabeled data in addition to labeled examples, have the potential to give improved performance over purely supervised methods for dependency parsing.",
        "It is often straightforward to obtain large amounts of unlabeled data, making semi-supervised approaches appealing; previous work on semisupervised methods for dependency parsing includes (Smith and Eisner, 2007; Koo et al., 2008; Wang et al., 2008).",
        "In particular, Koo et al.",
        "(2008) describe a semi-supervised approach that makes use of cluster features induced from unlabeled data, and gives state-of-the-art results on the widely used dependency parsing test collections: the Penn Treebank (PTB) for English and the Prague Dependency Treebank (PDT) for Czech.",
        "This is a very simple approach, but provided significant performance improvements comparing with the state-of-the-art supervised dependency parsers such as (McDonald and Pereira, 2006).",
        "This paper introduces an alternative method for semi-supervised learning for dependency parsing.",
        "Our approach basically follows a framework proposed in (Suzuki and Isozaki, 2008).",
        "We extend it for dependency parsing, which we will refer to as a Semi-supervised Structured Conditional Model (SS-SCM).",
        "In this framework, a structured conditional model is constructed by incorporating a series of generative models, whose parameters are estimated from unlabeled data.",
        "This paper describes a basic method for learning within this approach, and in addition describes two extensions.",
        "The first extension is to combine our method with the cluster-based semi-supervised method of (Koo et al., 2008).",
        "The second extension is to apply the approach to second-order parsing models, more specifically the model of (Carreras, 2007), using a two-stage semi-supervised learning approach.",
        "We conduct experiments on dependency parsing of English (on Penn Treebank data) and Czech (on the Prague Dependency Treebank).",
        "Our experiments investigate the effectiveness of: 1) the basic SS-SCM for dependency parsing; 2) a combination of the SS-SCM with Koo et al.",
        "(2008)'s semi-supervised approach (even in the case we used the same unlabeled data for both methods); 3) the two-stage semi-supervised learning approach that in-",
        "Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing, pages 551-560, Singapore, 6-7 August 2009.",
        "©2009 ACL and AFNLP",
        "corporates a second-order parsing model.",
        "In addition, we evaluate the SS-SCM for English dependency parsing with large amounts (up to 3.72 billion tokens) of unlabeled data ."
      ]
    },
    {
      "heading": "2. Semi-supervised Structured",
      "text": [
        "Conditional Models for Dependency Parsing",
        "Suzuki et al.",
        "(2008) describe a semi-supervised learning method for conditional random fields (CRFs) (Lafferty et al., 2001).",
        "In this paper we extend this method to the dependency parsing problem.",
        "We will refer to this extended method as Semi-supervised Structured Conditional Models (SS-SCMs).",
        "The remainder of this section describes our approach.",
        "Throughout this paper we will use x to denote an input sentence, and y to denote a labeled dependency structure.",
        "Given a sentence x with n words, a labeled dependency structure y is a set of n dependencies of the form (h, m, I), where h is the index of the headword in the dependency, m is the index of the modifier word, and I is the label of the dependency.",
        "We use h = 0 for the root of the sentence.",
        "We assume access to a set of labeled training examples, {x^y^}^, and in addition a set of unlabeled examples, {x^}|£1.",
        "In conditional log-linear models for dependency parsing (which are closely related to conditional random fields (Lafferty et al., 2001)), a distribution over dependency structures for a sentence x is defined as follows:",
        "where Z{x) is the partition function, w is a parameter vector, and",
        "Here f(x, ft, m, Z) is a feature vector representing the dependency (ft, m, Z) in the context of the sentence x (see for example (McDonald et al., 2005a)).",
        "In this paper we extend the definition of #(x, y) to include features that are induced from unlabeled data.",
        "Specifically, we define",
        "In this model v\\,..., Vk are scalar parameters that may be positive or negative; q\\... qk are functions (in fact, generative models), that are trained on unlabeled data.",
        "The Vj parameters will dictate the relative strengths of the functions q\\... qk, and will be trained on labeled data.",
        "For convenience, we will use v to refer to the vector of parameters V\\... Vk, and q to refer to the set of generative models q\\... qk- The full model is specified by values for w,v, and q.",
        "We will write p(y|x;w, v, q) to refer to the conditional distribution under parameter values w, v, q.",
        "We will describe a three-step parameter estimation method that: 1) initializes the q functions (generative models) to be uniform distributions, and estimates parameter values w and v from labeled data; 2) induces new functions q\\ ... qk from unlabeled data, based on the distribution defined by the w, v, q values from step (1); 3) re-estimates w and v on the labeled examples, keeping the q\\.. .qk from step (2) fixed.",
        "The end result is a model that combines supervised training with generative models induced from unlabeled data.",
        "We now describe how the generative models q\\.. .qk are defined, and how they are induced from unlabeled data.",
        "These models make direct use of the feature-vector definition f (x, y) used in the original, fully supervised, dependency parser.",
        "The first step is to partition the d features in f(x, y) into k separate feature vectors, ri(x, y)... rfc(x, y) (with the result that f is the concatenation of the k feature vectors ri... r^).",
        "In our experiments on dependency parsing, we partitioned f into up to over 140 separate feature vectors corresponding to different feature types.",
        "For example, one feature vector rj might include only those features corresponding to word bigrams involved in dependencies (i.e., indicator functions tied to the word bigram (xm, Xh) involved in a dependency (x, ft, m, I)).",
        "We then define a generative model that assigns a probability to the (i,-dimensional feature vector rj(x, h,m,l).",
        "Lhe parameters of this model are 9jti...",
        "6jtd.",
        "; they form a multinomial distribution, with the constraints that 9j>a > 0, and J2a@j,a = 1 This model can be viewed as a very simple (naive-Bayes) model that defines a distribution over feature vectors rj G M.dj.",
        "The next section describes how the parameters 9j>a are trained on unlabeled data.",
        "Given parameters 9jA, we can simply define the functions q\\... qk to be log probabilities under the generative model:",
        "We modify this definition slightly, be introducing scaling factors cJ)(l > 0, and defining",
        "In our experiments, Cj>a is simply a count of the number of times the feature indexed by (j, a) appears in unlabeled data.",
        "Thus more frequent features have their contribution down-weighted in the model.",
        "We have found this modification to be beneficial.",
        "We now describe the method for estimating the parameters 9j>a of the generative models.",
        "We assume initial parameters w,v,q, which define a distribution p(y|x^;w,v,q) over dependency structures for each unlabeled example x^.",
        "We will re-estimate the generative models q, based on unlabeled examples.",
        "The likelihood function on unlabeled data is defined as where q'j is as defined in Eq.",
        "3.",
        "This function resembles the Q function used in the EM algorithm, where the hidden labels (in our case, dependency structures), are filled in using the conditional distribution p(y |x^; w, v, q).",
        "It is simple to show that the estimates 9j>a that maximize the function in Eq.",
        "5 can be defined as follows.",
        "First, define a vector of expected counts based on w, v, q as",
        "Note that it is straightforward to calculate these expected counts using a variant of the inside-outside algorithm (Baker, 1979) applied to the (Eisner, 1996) dependency-parsing data structures (Paskin, 2001) for projective dependency structures, or the matrix-tree theorem (Koo et al., 2007; Smith and Smith, 2007; McDonald and Satta, 2007) for non-projective dependency structures.",
        "The estimates that maximize Eq.",
        "5 are then @j,a – d ,.",
        "Sail ?j,a",
        "In a slight modification, we employ the following estimates in our model, where rj > 1 is a parameter of the model:",
        "This corresponds to a MAP estimate under a Dirichlet prior over the 9j>a parameters.",
        "This section describes the full parameter estimation method.",
        "The input to the algorithm is a set of labeled examples {x^y^}^, a set of unlabeled examples {x^}^£1, a feature-vector definition f (x, y ), and a partition of f into k feature vectors ri ... Vk which underly the generative models.",
        "The output from the algorithm is a parameter vector w, a set of generative models q\\.. .qk, and parameters v\\.. .Vk, which define a probabilistic dependency parsing model through Eqs.",
        "1 and 2.",
        "The learning algorithm proceeds in three steps:",
        "Step 1: Estimation of a Fully Supervised Model.",
        "We choose the initial value q° of the generative models to be the uniform distribution, i.e., we set 9j>a = 1/dj for all j, a.",
        "We then define the regularized log-likelihood function for the labeled examples, with the generative model fixed at q°, to be:",
        "This is a conventional regularized log-likelihood function, as commonly used in CRF models.",
        "The parameter C > 0 dictates the level of regularization in the model.",
        "We define the initial parameters (w°,v°) = argmaxW;V L(w, v; q°).",
        "These parameters can be found using conventional methods for estimating the parameters of regularized log-likelihood functions (in our case we use LBFGS (Liu and Nocedal, 1989)).",
        "Note that the gradient of the log-likelihood function can be calculated using the inside-outside algorithm applied to projective dependency parse structures, or the matrix-tree theorem applied to non-projective structures.",
        "Step 2: Estimation of the Generative Models.",
        "In this step, expected count vectors ri ... are first calculated, based on the distribution p(y|x; w°, v°, q°).",
        "Generative model parameters 9j>a are calculated through the definition in Eq.",
        "6; these estimates define updated generative models qj for j = 1... k through Eq.",
        "4.",
        "We refer to the new values for the generative models as q.",
        "the final step, w and v are estimated as arg maxW;V L(w, v; q) where L(w, v; q) is defined in an analogous way to L(w, v; q°).",
        "Thus w and v are re-estimated to optimize log-likelihood of the labeled examples, with the generative models q estimated in step 2.",
        "The final output from the algorithm is the set of parameters (w, v, q).",
        "Note that it is possible to iterate the method – steps 2 and 3 can be repeated multiple times (Suzuki and Isozaki, 2008) – but in our experiments we only performed these steps once."
      ]
    },
    {
      "heading": "3. Extensions",
      "text": [
        "Koo et al.",
        "(2008) describe a semi-supervised approach that incorporates cluster-based features, and that gives competitive results on dependency parsing benchmarks.",
        "The method is a two-stage approach.",
        "First, hierarchical word clusters are derived from unlabeled data using the Brown et al.",
        "clustering algorithm (Brown et al., 1992).",
        "Second, a new feature set is constructed by representing words by bit-strings of various lengths, corresponding to clusters at different levels of the hierarchy.",
        "These features are combined with conventional features based on words and part-of-speech tags.",
        "The new feature set is then used within a conventional discriminative, supervised approach, such as the averaged perception algorithm.",
        "The important point is that their approach uses unlabeled data only for the construction of a new feature set, and never affects to learning algorithms.",
        "It is straightforward to incorporate cluster-based features within the SS-SCM approach described in this paper.",
        "We simply use the cluster-based feature-vector representation f(x, y) introduced by (Koo et al., 2008) as the basis of our approach.",
        "Previous work (McDonald and Pereira, 2006; Carreras, 2007) has shown that second-order parsing models, which include information from \"sibling\" or \"grandparent\" relationships between dependencies, can give significant improvements in accuracy over first-order parsing models.",
        "In principle it would be straightforward to extend the SS-SCM approach that we have described to second-order parsing models.",
        "In practice, however, a bottleneck for the method would be the estimation of the generative models on unlabeled data.",
        "This step requires calculation of marginals on unlabeled data.",
        "Second-order parsing models generally require more costly inference methods for the calculation of marginals, and this increased cost may be prohibitive when large quantities of unlabeled data are employed.",
        "We instead make use of a simple 'two-stage' approach for extending the SS-SCM approach to the second-order parsing model of (Carreras, 2007).",
        "In the first stage, we use a first-order parsing model to estimate generative models q\\.. .qu from unlabeled data.",
        "In the second stage, we incorporate these generative models as features within a second-order parsing model.",
        "More precisely, in our approach, we first train a first-order parsing model by Step 1 and 2, exactly as described in Section 2.4, to estimate w°, v° and q.",
        "Then, we substitute Step 3 as a supervised learning such as MIRA with a second-order parsing model (McDonald et al., 2005a), which incorporates q as a real-values features.",
        "We refer this two-stage approach to as two-stage SS-SCM.",
        "In our experiments we use the 1-best MIRA algorithm (McDonald and Pereira, 2006) as a",
        "!We used a slightly modified version of 1-best MIRA, whose difference can be found in the third line in Eq.",
        "7, namely, including L(yt, y).",
        "(a) English dependency parsing (b) Czech dependency parsing",
        "Table 1: Details of training, development, test data (labeled data sets) and unlabeled data used in our experiments parameter-estimation method for the second-order parsing model.",
        "In particular, we perform the following optimizations on each update t = 1,T for re-estimating w and v:",
        "where L(yi, y) represents the loss between correct output of i'th sample y^ and y.",
        "Then, the scoring function S for each y can be defined as follows:",
        "where B represents a tunable scaling factor, and fi and Î2 represent the feature vectors of first and second-order parsing parts, respectively."
      ]
    },
    {
      "heading": "4. Experiments",
      "text": [
        "We now describe experiments investigating the effectiveness of the SS-SCM approach for dependency parsing.",
        "The experiments test basic, first-order parsing models, as well as the extensions to cluster-based features and second-order parsing models described in the previous section.",
        "We conducted experiments on both English and Czech data.",
        "We used the Wall Street lournal sections of the Penn Treebank (PTB) III (Marcus et al., 1994) as a source of labeled data for English, and the Prague Dependency Treebank (PDT) 1.0 (Hajic, 1998) for Czech.",
        "To facilitate comparisons with previous work, we used exactly the same training, development and test sets",
        "Table 2: Details of the larger unlabeled data set used in English dependency parsing: sentences exceeding 128 tokens in length were excluded for computational reasons.",
        "as those described in (McDonald et al., 2005a; McDonald et al., 2005b; McDonald and Pereira, 2006; Koo et al., 2008).",
        "The English dependency-parsing data sets were constructed using a standard set of head-selection rules (Yamada and Matsumoto, 2003) to convert the phrase structure syntax of the Treebank to dependency tree representations.",
        "We split the data into three parts: sections 02-21 for training, section 22 for development and section 23 for test.",
        "The Czech data sets were obtained from the predefined training/development/test partition in the PDT.",
        "The unlabeled data for English was derived from the Brown Laboratory for Linguistic Information Processing (BLLIP) Corpus (LDC2000T43), giving a total of 1,796,379 sentences and 43,380,315 tokens.",
        "The raw text section of the PDT was used for Czech, giving 2,349,224 sentences and 39,336,570 tokens.",
        "These data sets are identical to the unlabeled data used in (Koo et al., 2008), and are disjoint from the training, development and test sets.",
        "The datasets used in our experiments are summarized in Table 1.",
        "In addition, we will describe experiments that make use of much larger amounts of unlabeled data.",
        "Unfortunately, we have no data available other than PDT for Czech, this is done only for English dependency parsing.",
        "Table 2 shows the detail of the larger unlabeled data set used in our experiments, where we eliminated sentences that have more than 128 tokens for computational reasons.",
        "Note that the total size of the unlabeled data reaches 3.72G (billion) tokens, which is approximately 4,000 times larger than the size of labeled training data.",
        "Corpus",
        "article name (mm/yy)",
        "# of sent.",
        "# of tokens",
        "BLLIP",
        "wsj 00/87-00/89",
        "1,796,379",
        "43,380,315",
        "Tipster",
        "wsj 04/90-03/92",
        "1,550,026",
        "36,583,547",
        "North American",
        "wsj 07/94-12/96 reu 04/94-07/96",
        "2,748,803 4,773,701",
        "62,937,557 110,001,109",
        "Reuters",
        "reu 09/96-08/97",
        "12,969,056",
        "214,708,766",
        "English Gigaword",
        "afp 05/94-12/06 apw 11/94-12/06 ltw 04/94-12/06 nyt 07/94-12/06 xin 01/95-12/06",
        "21,231,470 46,978,725 10,524,545 60,752,363 12,624,835",
        "513,139,928 960,733,303 230,370,454 1,266,531,274 283,579,330",
        "total",
        "175,949,903",
        "3,721,965,583",
        "Data set (WSJ",
        "Sec.",
        "IDs)",
        "# of sentences",
        "# of tokens",
        "Training",
        "(02-21)",
        "39,832",
        "950,028",
        "Development",
        "(22)",
        "1,700",
        "40,117",
        "Test",
        "(23)",
        "2,012",
        "47,377",
        "Unlabeled",
        "1,796,379",
        "43,380,315",
        "Data set",
        "# of sentences",
        "# of tokens",
        "Training",
        "73,088",
        "1,255,590",
        "Development",
        "7,507",
        "126,030",
        "Test",
        "7,319",
        "125,713",
        "Unlabeled",
        "2,349,224",
        "39,336,570",
        "In general we will assume that the input sentences include both words and part-of-speech (POS) tags.",
        "Our baseline features (\"baseline\") are very similar to those described in (McDonald et al., 2005a; Koo et al., 2008): these features track word and POS bigrams, contextual features surrounding dependencies, distance features, and so on.",
        "English POS tags were assigned by MXPOST (Rat-naparkhi, 1996), which was trained on the training data described in Section 4.1.",
        "Czech POS tags were obtained by the following two steps: First, we used 'feature-based tagger' included with the PDT, and then, we used the method described in (Collins et al., 1999) to convert the assigned rich POS tags into simplified POS tags.",
        "In a second set of experiments, we make use of the feature set used in the semi-supervised approach of (Koo et al., 2008).",
        "We will refer to this as the \"cluster-based feature set\" (CL).",
        "The BLLIP (43M tokens) and PDT (39M tokens) unlabeled data sets shown in Table 1 were used to construct the hierarchical clusterings used within the approach.",
        "Note that when this feature set is used within the SS-SCM approach, the same set of unlabeled data is used to both induce the clusters, and to estimate the generative models within the SS-SCM model.",
        "As described in section 2.2, the generative models in the SS-SCM approach are defined through a partition of the original feature vector f(x, y) into k feature vectors ri(x, y)... rfc(x, y).",
        "We follow a similar approach to that of (Suzuki and Isozaki, 2008) in partitioning f(x, y), where the k different feature vectors correspond to different feature types or feature templates.",
        "Note that, in general, we are not necessary to do as above, this is one systematic way of a feature design for this approach.",
        "All results presented in our experiments are given in terms of parent-prediction accuracy on unla- beled dependency parsing.",
        "We ignore the parent-predictions of punctuation tokens for English, while we retain all the punctuation tokens for Czech.",
        "These settings match the evaluation setting in previous work such as (McDonald et al., 2005a; Koo et al., 2008).",
        "We used the method proposed by (Carreras, 2007) for our second-order parsing model.",
        "Since this method only considers projective dependency structures, we \"projectivized\" the PDT training data in the same way as (Koo et al., 2008).",
        "We used a non-projective model, trained using an application of the matrix-tree theorem (Koo et al., 2007; Smith and Smith, 2007; McDonald and Satta, 2007) for the first-order Czech models, and projective parsers for all other models.",
        "As shown in Section 2, SS-SCMs with lst-order parsing models have two tunable parameters, C and r], corresponding to the regularization constant, and the Dirichlet prior for the generative models.",
        "We selected a fixed value r] = 2, which was found to work well in preliminary experiments.",
        "The value of C was chosen to optimize performance on development data.",
        "Note that C for supervised SCMs were also tuned on development data.",
        "For the two-stage SS-SCM for incorporating second-order parsing model, we have additional one tunable parameter B shown in Eq.",
        "8.",
        "This was also chosen by the value that provided the best performance on development data.",
        "In addition to providing results for models trained on the full training sets, we also performed experiments with smaller labeled training sets.",
        "These training sets were either created through random sampling or by using a predefined subset of document IDs from the labeled training data."
      ]
    },
    {
      "heading": "5. Results and Discussion",
      "text": [
        "Table 3 gives results for the SS-SCM method under various configurations: for first and second-order parsing models, with and without the cluster features of (Koo et al., 2008), and for varying amounts of labeled data.",
        "The remainder of this section discusses these results in more detail.",
        "We can see from the results in Table 3 that our semi-supervised approach consistently gives gains",
        "(a) English dependency parsing: w/ 43M token unlabeled data (BLLIP) (b) Czech dependency parsing: w/ 39M token unlabeled data (PDT)",
        "Table 3: Dependency parsing results for the SS-SCM method with different amounts of labeled training data.",
        "Supervised SCM (lod) and Supervised MIRA (2od) are the baseline first and second-order approaches; SS-SCM (lod) and 2-stage SS-SCM(+MIRA) (2od) are the first and second-order approaches described in this paper.",
        "\"Baseline\" refers to models without cluster-based features, \"CL\" refers to models which make use of cluster-based features.",
        "in performance under various sizes of labeled data.",
        "Note that the baseline methods that we have used in these experiments are strong baselines.",
        "It is clear that the gains from our method are larger for smaller labeled data sizes, a tendency that was also observed in (Koo et al., 2008).",
        "One important observation from the results in Table 3 is that SS-SCMs can successfully improve the performance over a baseline method that uses the cluster-based feature set (CL).",
        "This is in spite of the fact that the generative models within the SS-SCM approach were trained on the same unlabeled data used to induce the cluster-based features.",
        "Table 3 also shows the effectiveness of the two-stage approach (described in Section 3.2) that integrates the SS-SCM method within a second-order parser.",
        "This suggests that the SS-SCM method can be effective in providing features (generative models) used within a separate learning algorithm, providing that this algorithm can make use of real-valued features.",
        "Unlabeled data size: [Log-scale]",
        "Figure 1 : Impact of unlabeled data size for the SS-SCM on development data of English dependency parsing.",
        "Figure 1 shows the dependency parsing accuracy on English as a function of the amount of unlabeled data used within the SS-SCM approach.",
        "(As described in Section 4.1, we have no unlabeled data other than PDT for Czech, hence this section only considers English dependency parsing.)",
        "We can see that performance does improve as more unlabeled data is added; this trend is seen both with and without cluster-based features.",
        "In addition, Table 4 shows the performance of our proposed method using 3.72 billion tokens of unla-",
        "WSJ sec.",
        "IDs",
        "# of sentences / tokens",
        "wsj_21 1,671 /40,039",
        "random selection 2,000/48,577",
        "random selection 8,000 / 190,958",
        "wsj_15-18 8,936/211,727",
        "wsj_02-21(all) 39,832/950,028",
        "feature type",
        "baseline",
        "CL",
        "baseline",
        "CL",
        "baseline",
        "CL",
        "baseline",
        "CL",
        "baseline",
        "CL",
        "Supervised SCM",
        "(lod) 85.63",
        "86.80",
        "87.02",
        "88.05",
        "89.23",
        "90.45",
        "89.43",
        "90.85",
        "91.21",
        "92.53",
        "SS-SCM",
        "(lod)",
        "87.16",
        "88.40",
        "88.07",
        "89.55",
        "90.06",
        "91.45",
        "90.23",
        "91.63",
        "91.72",
        "93.01",
        "(gain over Sup.",
        "SCM)",
        "(+1.53)",
        "(+1.60)",
        "(+1.05)",
        "(+1.50)",
        "(+0.83)",
        "(+1.00)",
        "(+0.80)",
        "(+0.78)",
        "(+0.51)",
        "(+0.48)",
        "Supervised MIRA",
        "(2od)",
        "87.99",
        "89.05",
        "89.20",
        "90.06",
        "91.20",
        "91.75",
        "91.50",
        "92.14",
        "93.02",
        "93.54",
        "2-stage SS-SCM(+MIRA) (2od)",
        "88.88",
        "89.94",
        "90.03",
        "90.90",
        "91.73",
        "92.51",
        "91.95",
        "92.73",
        "93.45",
        "94.13",
        "(gain over Sup.",
        "MIRA)",
        "(+0.89)",
        "(+0.89)",
        "(+0.83)",
        "(+0.84)",
        "(+0.53)",
        "(+0.76)",
        "(+0.45)",
        "(+0.59)",
        "(+0.43)",
        "(+0.59)",
        "PDT Doc.",
        "IDs",
        "# of sentences / tokens",
        "random selection 2,000/34,722",
        "c[0-9]* 3,526/53,982",
        "random selection 8,000 / 140,423",
        "l[a-i]* 14,891 /261,545",
        "(all)",
        "73,008/1,225,590",
        "feature type",
        "baseline",
        "CL",
        "baseline",
        "CL",
        "baseline",
        "CL",
        "baseline",
        "CL",
        "baseline",
        "CL",
        "Supervised SCM",
        "(lod)",
        "75.67",
        "77.82",
        "76.88",
        "79.24",
        "80.61",
        "82.85",
        "81.94",
        "84.47",
        "84.43",
        "86.72",
        "SS-SCM",
        "(lod)",
        "76.47",
        "78.96",
        "77.61",
        "80.28",
        "81.30",
        "83.49",
        "82.74",
        "84.91",
        "85.00",
        "87.03",
        "(gain over Sup.",
        "SCM)",
        "(+0.80)",
        "(+1.14)",
        "(+0.73)",
        "(+1.04)",
        "(+0.69)",
        "(+0.64)",
        "(+0.80)",
        "(+0.44)",
        "(+0.57)",
        "(+0.31)",
        "Supervised MIRA",
        "(2od)",
        "78.19",
        "79.60",
        "79.58",
        "80.77",
        "83.15",
        "84.39",
        "84.27",
        "85.75",
        "86.82",
        "87.76",
        "2-stage SS-SCM(+MIRA) (2od)",
        "78.71",
        "80.09",
        "80.37",
        "81.40",
        "83.61",
        "84.87",
        "84.95",
        "86.00",
        "87.03",
        "88.03",
        "(gain over Sup.",
        "MIRA)",
        "(+0.52)",
        "(+0.49)",
        "(+0.79)",
        "(+0.63)",
        "(+0.46)",
        "(+0.48)",
        "(+0.68)",
        "(+0.25)",
        "(+0.21)",
        "(+0.27)",
        "- I.38G",
        "(BLUP)",
        "™ baseline",
        "(a) English dependency parsing: w/ 3.72G token ULD",
        "Table 4: Parent-prediction accuracies on development data with 3.72G tokens unlabeled data for English dependency parsing.",
        "beled data.",
        "Note, however, that the gain in performance as unlabeled data is added is not as sharp as might be hoped, with a relatively modest difference in performance for 43.4 million tokens vs. 3.72 billion tokens of unlabeled data.",
        "The main computational challenge in our approach is the estimation of the generative models q = (qi... qk) from unlabeled data, particularly when the amount of unlabeled data used is large.",
        "In our implementation, on the 43M token BLLIP corpus, using baseline features, it takes about 5 hours to compute the expected counts required to estimate the parameters of the generative models on a single 2.93GHz Xeon processor.",
        "It takes roughly 18 days of computation to estimate the generative models from the larger (3.72 billion word) corpus.",
        "Fortunately it is simple to parallelize this step; our method takes a few hours on the larger data set when parallelized across around 300 separate processes.",
        "Note that once the generative models have been estimated, decoding with the model, or training the model on labeled data, is relatively inexpensive, essentially taking the same amount of computation as standard dependency-parsing approaches.",
        "Finally, Table 5 displays the final results on test data.",
        "There results are obtained using the best setting in terms of the development data performance.",
        "Note that the English dependency parsing results shown in the table were achieved using 3.72 billion tokens of unlabeled data.",
        "The improvements on test data are similar to those observed on the development data.",
        "To determine statistical significance, we tested the difference of parent-prediction error-rates at the sentence level using a paired Wilcoxon signed rank test.",
        "All eight comparisons shown in Table 5 are significant with",
        "(b) Czech dependency parsing: w/ 39M token ULD (PDT)",
        "Table 5 : Parent-prediction accuracies on test data using the best setting in terms of development data performances in each condition.",
        "(a) English dependency parsers on PTB",
        "Table 6: Comparisons with the previous top systems: (lod, 2od: 1st- and 2nd-order parsing model, ULD: unlabeled data).",
        "p < 0.01."
      ]
    },
    {
      "heading": "6. Comparison with Previous Methods",
      "text": [
        "Table 6 shows the performance of a number of state-of-the-art approaches on the English and Czech data sets.",
        "For both languages our approach gives the best reported figures on these datasets.",
        "Our results yield relative error reductions of roughly 27% (English) and 20% (Czech) over McDonald and Pereira (2006)'s second-order supervised dependency parsers, and roughly 9% (English) and 7% (Czech) over the previous best results provided by Koo et.",
        "al.",
        "(2008)'s second-order semi-supervised dependency parsers.",
        "Note that there are some similarities between our two-stage semi-supervised learning approach and the semi-supervised learning method introduced by (Blitzer et al., 2006), which is an extension of the method described by (Ando and Zhang, 2005).",
        "In particular, both methods use a two-stage approach; They first train generative models or auxiliary problems from unlabeled data, and then, they incorporate these trained models into a supervised learning algorithm as real valued features.",
        "Moreover, both methods make direct use of existing feature-vector definitions f(x, y) in inducing representations from unlabeled data.",
        "feature type",
        "baseline",
        "CL",
        "SS-SCM (lst-order) (gain over Sup.",
        "SCM)",
        "92.23 (+1.02)",
        "93.23 (+0.70)",
        "2-stage SS-SCM(+MIRA) (2nd-order) (gain over Sup.",
        "MIRA)",
        "93.68 (+0.66)",
        "94.26 (+0.72)",
        "feature set",
        "baseline",
        "CL",
        "SS-SCM (lst-order) (gain over Sup.",
        "SCM)",
        "91.89 (+0.92)",
        "92.70 (+0.58)",
        "2-stage SS-SCM(+MIRA) (2nd-order) (gain over Sup.",
        "MIRA)",
        "93.41 (+0.65)",
        "93.79 (+0.48)",
        "feature set",
        "baseline",
        "CL",
        "SS-SCM (lst-order) (gain over Sup.",
        "SCM)",
        "84.98 (+0.58)",
        "87.14 (+0.39)",
        "2-stage SS-SCM(+MIRA) (2nd-order) (gain over Sup.",
        "MIRA)",
        "86.90 (+0.15)",
        "88.05 (+0.36)",
        "dependency parser",
        "test",
        "description",
        "(McDonald et al., 2005a)",
        "90.9",
        "lod",
        "(McDonald and Pereira, 2006)",
        "91.5",
        "2od",
        "(Koo etal, 2008)",
        "92.23",
        "lod, 43M ULD",
        "SS-SCM (w/ CL)",
        "92.70",
        "lod, 3.72GULD",
        "(Koo etal, 2008)",
        "93.16",
        "2od, 43M ULD",
        "2-stage SS-SCM(+MIRA, w/ CL)",
        "93.79",
        "2od, 3.72GULD",
        "(b) Czech dependency parsers on PDT",
        "dependency parser",
        "test",
        "description",
        "(McDonald et al., 2005b)",
        "84.4",
        "lod",
        "(McDonald and Pereira, 2006)",
        "85.2",
        "2od",
        "(Koo et al„ 2008)",
        "86.07",
        "lod, 39M ULD",
        "(Koo et al„ 2008)",
        "87.13",
        "2od, 39M ULD",
        "SS-SCM (w/ CL)",
        "87.14",
        "lod, 39M ULD",
        "2-stage SS-SCM(+MIRA, w/ CL)",
        "88.05",
        "2od, 39M ULD"
      ]
    },
    {
      "heading": "7. Conclusion",
      "text": [
        "This paper has described an extension of the semi-supervised learning approach of (Suzuki and Isozaki, 2008) to the dependency parsing problem.",
        "In addition, we have described extensions that incorporate the cluster-based features of Koo et al.",
        "(2008), and that allow the use of second-order parsing models.",
        "We have described experiments that show that the approach gives significant improvements over state-of-the-art methods for dependency parsing; performance improves when the amount of unlabeled data is increased from 43.8 million tokens to 3.72 billion tokens.",
        "The approach should be relatively easily applied to languages other than English or Czech.",
        "We stress that the SS-SCM approach requires relatively little hand-engineering: it makes direct use of the existing feature-vector representation f(x, y) used in a discriminative model, and does not require the design of new features.",
        "The main choice in the approach is the partitioning of f (x, y) into components ri(x, y) ... r-fc(x, y), which in our experience is straightforward."
      ]
    }
  ]
}
