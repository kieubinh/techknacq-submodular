{
  "info": {
    "authors": [
      "Victoria Li Fossum",
      "Kevin Knight"
    ],
    "book": "HLT-NAACL, Companion Volume: Short Papers",
    "id": "acl-N09-2064",
    "title": "Combining Constituent Parsers",
    "url": "https://aclweb.org/anthology/N09-2064",
    "year": 2009
  },
  "references": [
    "acl-J05-1003",
    "acl-N06-2033",
    "acl-N07-1051",
    "acl-P03-1054",
    "acl-P05-1022",
    "acl-W06-1608",
    "acl-W99-0623"
  ],
  "sections": [
    {
      "text": [
        "Victoria Fossum",
        "Combining the 1-best output of multiple parsers via parse selection or parse hybridization improves f-score over the best individual parser (Henderson and Brill, 1999; Sagae and Lavie, 2006).",
        "We propose three ways to improve upon existing methods for parser combination.",
        "First, we propose a method of parse hybridization that recombines context-free productions instead of constituents, thereby preserving the structure of the output of the individual parsers to a greater extent.",
        "Second, we propose an efficient linear-time algorithm for computing expected f-score using Minimum Bayes Risk parse selection.",
        "Third, we extend these parser combination methods from multiple 1 best outputs to multiple n-best outputs.",
        "We present results on WSJ section 23 and also on the English side of a Chinese-English parallel corpus."
      ]
    },
    {
      "heading": "1. Introduction",
      "text": [
        "Parse quality impacts the quality of downstream applications such as syntax-based machine translation (Quirk and Corston-Oliver, 2006).",
        "Combining the output of multiple parsers can boost the accuracy of such applications.",
        "Parses can be combined in two ways: parse selection (selecting the best parse from the output of the individual parsers) or parse hybridization (constructing the best parse by recombining sub-sentential components from the output of the individual parsers).",
        "(Henderson and Brill, 1999) perform parse selection by maximizing the expected precision of the selected parse with respect to the set of parses being combined.",
        "(Henderson and Brill, 1999) and (Sagae and Lavie, 2006) propose methods for parse hybridization by recombining constituents.",
        "In this work, we propose three ways to improve upon existing methods for parser combination.",
        "First, while constituent recombination (Henderson and Brill, 1999; Sagae and Lavie, 2006) gives a significant improvement in f-score, it tends to flatten the structure of the individual parses.",
        "To illustrate, Figures 1 and 2 contrast the output of the Charniak parser with the output of constituent recombination on a sentence from WSJ section 24.",
        "We recombine context-free productions instead ofconstituents, producing trees containing only context-free productions that have been seen in the individual parsers' output (Figure 3).",
        "Second, the parse selection method of (Henderson and Brill, 1999) selects the parse with maximum expected precision; here, we present an efficient, linear-time algorithm for selecting the parse with maximum expected f-score within the Minimum Bayes Risk (MBR) framework.",
        "Third, we extend these parser combination methods from 1-best outputs to n-best outputs.",
        "We present results on WSJ section 23 and also on the English side of a Chinese-English parallel corpus."
      ]
    },
    {
      "heading": "2. Parse Selection",
      "text": [
        "In the MBR framework, although the true reference parse is unknown, we assume that the individual parsers' output forms a reasonable distribution over possible reference parses.",
        "We compute the expected f-score of each parse tree pi using this distribution:",
        "expected f (pi)",
        "where f (pi,pj) is the f-score of parse pi with respect to parse pj and pr(pj) is the prior probability of parse pj.",
        "We estimate pr(pj) as follows: pr(pj) = pr(parserk) • pr(pj\\parserk), where parserk is the parser generating pj.",
        "We set pr(parserk) according to the proportion of sentences in the development set for which the 1-best output of parserk achieves the highest f-score of any individual parser, breaking ties randomly.",
        "When n = 1, pr(pj\\parserk) = 1 for all pj; when n > 1 we must estimate pr(ppj\\parserk), the distribution over parses in the n-best list output by any given parser.",
        "We estimate this distribution using the model score, or log probability, given by parserk to each entry pj in its n-best list:",
        "pr(pj \\parserk ) eOt*sc(orejk",
        "We tune a on a development set to maximize f-score, and select the parse pi with highest expected f-score.",
        "Computing exact expected f-score requires O(m) operations per sentence, where m is the number of parses being combined.",
        "We can compute an approximate expected f-score in O(m) time.",
        "To do so, we compute expected precision for all parses in O(m) time by associating with each unique constituent Ci a list of parses in which it occurs, plus the total probability qi of those parses.",
        "For each parse p associated with Ci, we increment the expected precision of that parse by qi/size(p).",
        "This computation yields the same result as the O(m) algorithm.",
        "We carry out a similar operation for expected recall.",
        "We then compute the harmonic mean of expected precision and expected recall, which closely approximates the true expected f-score.",
        "Parser",
        "wsj",
        "ce",
        "dev",
        "test",
        "dev",
        "test",
        "Berkeley (Petrov and Klein, 2007)",
        "88.6",
        "89.3",
        "82.9",
        "83.5",
        "Bikel-Collins Model 2 (Bikel, 2002)",
        "87.0",
        "88.2",
        "81.2",
        "80.6",
        "Charniak",
        "(Charniak and Johnson, 2005)",
        "90.6",
        "91.4",
        "84.7",
        "84.1",
        "Soricut-Collins Model 2 (Soricut, 2004)",
        "87.3",
        "88.4",
        "82.3",
        "82.1",
        "Stanford",
        "(Klein and Manning, 2003)",
        "85.4",
        "86.4",
        "81.3",
        "80.1"
      ]
    },
    {
      "heading": "3. Constituent Recombination",
      "text": [
        "(Henderson and Brill, 1999) convert each parse into constituents with syntactic labels and spans, and weight each constituent by summing pr(parserk) over all parsers k in whose output the constituent appears.",
        "They include all constituents with weight above a threshold t = m+, where m is the number of input parses, in the combined parse.",
        "(Sagae and Lavie, 2006) extend this method by tuning t on a development set to maximize f-score.",
        "They populate a chart with constituents whose weight meets the threshold, and use a CKY-style parsing algorithm to find the heaviest tree, where the weight of a tree is the sum of its constituents' weights.",
        "Parsing is not constrained by a grammar; any context-free production is permitted.",
        "Thus, the combined parses may contain context-free productions not seen in the individual parsers' outputs.",
        "While this failure to preserve the structure of individual parses does not affect f-score, it may hinder downstream applications.",
        "To extend this method from 1-best to n-best lists, we weight each constituent by summing pr(parserk) • pr(pj\\parserk) over all parses pj generated by parserk in which the constituent appears."
      ]
    },
    {
      "heading": "4. Context-Free Production Recombination",
      "text": [
        "To ensure that all context-free productions in the combined parses have been seen in the individual parsers' outputs, we recombine context-free productions rather than constituents.",
        "We convert each parse into context-free productions, labelling each constituent in the production with its span and syntactic category and weighting each production by summing pr(parserk) • pr(pj\\parserk) over all parses pj generated by parserk in which the production appears.",
        "We re-parse the sentence with these productions, returning the heaviest tree (where the weight of a tree is the sum of its context-free productions' weights).",
        "We optimize f-score by varying the tradeoff between precision and recall using a derivation length penalty, which we tune on a development set."
      ]
    },
    {
      "heading": "5. Experiments",
      "text": [
        "Table 1 illustrates the 5 parsers used in our combination experiments and the f-scores of their 1-best output on our data sets.",
        "We use the n-best output of the Berkeley, Charniak, and Soricut parsers, and the 1-best output of the Bikel and Stanford parsers.",
        "All parsers were trained on the standard WSJ training sections.",
        "We use two corpora: the WSJ (sections 24 and 23 are the development and test sets, respectively) and English text from the LDC2007T02 Chinese-English parallel corpus (the development and test sets contain 400 sentences each)."
      ]
    },
    {
      "heading": "6. Discussion & Conclusion",
      "text": [
        "Results are shown in Tables 2, 3, and 4.",
        "On both test sets, constituent recombination achieves the best f-score (1.0 points on WSJ test and 2.3 points on Chinese-English test), followed by context-free production combination, then parse selection, though the differences in f-score among the combination methods are not statistically significant.",
        "Increasing the n-best list size from 1 to 10 improves parse selection and context-free production recombination,",
        "Parse Selection: Minimum Bayes Risk",
        "System",
        "1 wsj-dev",
        "1 wsj-test",
        "1 ce-dev",
        "| ce-test",
        "P",
        "R",
        "F",
        "P",
        "R",
        "F",
        "P",
        "R",
        "F",
        "P",
        "R",
        "F",
        "best individual parser",
        "91.3",
        "89.9",
        "90.6",
        "91.8",
        "91.0",
        "91.4",
        "86.1",
        "83.4",
        "84.7",
        "85.6",
        "82.6",
        "84.1",
        "n=1",
        "91.7",
        "90.5",
        "91.1",
        "92.5",
        "91.8",
        "92.0",
        "87.1",
        "84.6",
        "85.8",
        "86.7",
        "83.7",
        "85.2",
        "n=10",
        "92.1",
        "90.8",
        "91.5",
        "92.4",
        "91.7",
        "92.0",
        "87.9",
        "85.3",
        "86.6",
        "87.7",
        "84.4",
        "86.0",
        "n=25",
        "92.1",
        "90.9",
        "91.5",
        "92.4",
        "91.7",
        "92.0",
        "88.0",
        "85.4",
        "86.7",
        "87.4",
        "84.2",
        "85.7",
        "n=50",
        "92.1",
        "91.0",
        "91.5",
        "92.4",
        "91.7",
        "92.1",
        "88.0",
        "85.3",
        "86.6",
        "87.6",
        "84.3",
        "85.9",
        "Parse Hybridization: Constituent Recombination",
        "Table 3 : Precision, Recall, and F-score Results from Constituent Recombination though further increasing n does not, in general, help.",
        "Chinese-English test set f-score gets a bigger boost from combination than WSJ test set f-score, perhaps because the best individual parser's baseline f-score is lower on the out-of-domain data.",
        "We have presented an algorithm for parse hybridization by recombining context-free productions.",
        "While constituent recombination results in the highest f-score ofthe methods explored, context-free production recombination produces trees which better preserve the syntactic structure of the individual parses.",
        "We have also presented an efficient linear-time algorithm for selecting the parse with maximum expected f-score."
      ]
    },
    {
      "heading": "Acknowledgments",
      "text": [
        "We thank Steven Abney, John Henderson, and Kenji Sagae for helpful discussions.",
        "This research 0022) and by NSF ITR (grant IIS-0428020).",
        "System",
        "1 wsj-dev",
        "1 wsj-test",
        "1 ce-dev",
        "1 ce-test",
        "P",
        "R",
        "F",
        "P",
        "R",
        "F",
        "P",
        "R",
        "F",
        "P",
        "R",
        "F",
        "best individual parser",
        "91.3",
        "89.9",
        "90.6",
        "91.8",
        "91.0",
        "91.4",
        "86.1",
        "83.4",
        "84.7",
        "85.6",
        "82.6",
        "84.1",
        "n=1",
        "92.5",
        "90.3",
        "91.4",
        "93.0",
        "91.6",
        "92.3",
        "89.2",
        "84.6",
        "86.8",
        "89.1",
        "83.6",
        "86.2",
        "n=10",
        "92.6",
        "90.5",
        "91.5",
        "93.1",
        "91.7",
        "92.4",
        "89.9",
        "84.4",
        "87.1",
        "89.9",
        "83.2",
        "86.4",
        "n=25",
        "92.6",
        "90.5",
        "91.5",
        "93.2",
        "91.7",
        "92.4",
        "89.9",
        "84.4",
        "87.0",
        "89.7",
        "83.4",
        "86.4",
        "n=50",
        "92.6",
        "90.5",
        "91.5",
        "93.1",
        "91.7",
        "92.4",
        "89.9",
        "84.4",
        "87.1",
        "89.7",
        "83.2",
        "86.3",
        "Parse Hybridization: Context-Free Production Recombination",
        "System",
        "J wsj-dev",
        "J wsj-test",
        "J ce-dev",
        "J ce-test",
        "P",
        "R",
        "F",
        "P",
        "R",
        "F",
        "P",
        "R",
        "F",
        "P",
        "R",
        "F",
        "best individual parser",
        "91.3",
        "89.9",
        "90.6",
        "91.8",
        "91.0",
        "91.4",
        "86.1",
        "83.4",
        "84.7",
        "85.6",
        "82.6",
        "84.1",
        "n=1",
        "91.7",
        "91.0",
        "91.4",
        "92.1",
        "91.9",
        "92.0",
        "86.9",
        "85.4",
        "86.2",
        "86.2",
        "84.3",
        "85.2",
        "n=10",
        "92.1",
        "90.9",
        "91.5",
        "92.5",
        "91.8",
        "92.2",
        "87.8",
        "85.1",
        "86.4",
        "86.2",
        "84.3",
        "86.1",
        "n=25",
        "92.2",
        "91.0",
        "91.6",
        "92.5",
        "91.8",
        "92.2",
        "87.8",
        "85.1",
        "86.4",
        "87.6",
        "84.6",
        "86.1",
        "n=50",
        "92.1",
        "90.8",
        "91.4",
        "92.4",
        "91.7",
        "92.1",
        "87.6",
        "84.9",
        "86.2",
        "87.7",
        "84.6",
        "86.1"
      ]
    }
  ]
}
