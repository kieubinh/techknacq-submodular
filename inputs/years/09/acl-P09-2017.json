{
  "info": {
    "authors": [
      "Ioannis Korkontzelos",
      "Suresh Manandhar"
    ],
    "book": "ACL-IJCNLP: Short Papers",
    "id": "acl-P09-2017",
    "title": "Detecting Compositionality in Multi-Word Expressions.",
    "url": "https://aclweb.org/anthology/P09-2017",
    "year": 2009
  },
  "references": [
    "acl-J93-1003",
    "acl-P95-1026",
    "acl-P99-1004",
    "acl-W03-1809",
    "acl-W03-1810",
    "acl-W03-1812",
    "acl-W06-1203",
    "acl-W06-1669",
    "acl-W06-3812",
    "acl-W07-2002"
  ],
  "sections": [
    {
      "text": [
        "Detecting Compositionality in Multi-Word Expressions",
        "Identifying whether a multi-word expression (MWE) is compositional or not is important for numerous NLP applications.",
        "Sense induction can partition the context of MWEs into semantic uses and therefore aid in deciding compositionality.",
        "We propose an unsupervised system to explore this hypothesis on compound nominals, proper names and adjective-noun constructions, and evaluate the contribution of sense induction.",
        "The evaluation set is derived from WordNet in a semi-supervised way.",
        "Graph connectivity measures are employed for unsupervised parameter tuning."
      ]
    },
    {
      "heading": "1. Introduction and related work",
      "text": [
        "Multi-word expressions (MWEs) are sequences of words that tend to cooccur more frequently than chance and are either idiosyncratic or decomposable into multiple simple words (Baldwin, 2006).",
        "Deciding idiomaticity of MWEs is highly important for machine translation, information retrieval, question answering, lexical acquisition, parsing and language generation.",
        "Compositionality refers to the degree to which the meaning of a MWE can be predicted by combining the meanings of its components.",
        "Unlike syntactic compositionality (e.g. by and large), semantic compositionality is continuous (Baldwin, 2006).",
        "In this paper, we propose a novel unsupervised approach that compares the major senses of a MWE and its semantic head using distributional similarity measures to test the compositionality of the MWE.",
        "These senses are induced by a graph based sense induction system, whose parameters are estimated in an unsupervised manner exploiting a number of graph connectivity measures (Korkontzelos et al., 2009).",
        "Our method partitions the context space and only uses the major senses, filtering out minor senses.",
        "In our approach the only language dependent components are a PoS tagger and a parser.",
        "There are several studies relevant to detecting compositionality of noun-noun MWEs (Baldwin et al., 2003) verb-particle constructions (Bannard et al., 2003; McCarthy et al., 2003) and verb-noun pairs (Katz and Giesbrecht, 2006).",
        "Datasets with human compositionality judgements are available for these MWE categories (Cook et al., 2008).",
        "Here, we focus on compound nominals, proper names and adjective-noun constructions.",
        "Our contributions are three-fold: firstly, we experimentally show that sense induction can assist in identifying compositional MWEs.",
        "Secondly, we show that unsupervised parameter tuning (Korkontzelos et al., 2009) results in accuracy that is comparable to the best manually selected combination of parameters.",
        "Thirdly, we propose a semi-supervised approach for extracting non-compositional MWEs from WordNet, to decrease annotation cost."
      ]
    },
    {
      "heading": "2. Proposed approach",
      "text": [
        "Let us consider the non-compositional MWE \"red carpet\".",
        "It mainly refers to a strip of red carpeting laid down for dignitaries to walk on.",
        "However, it is possible to encounter instances of \"red carpet\" referring to any carpet of red colour.",
        "Our method first applies sense induction to identify the major semantic uses (senses) of a MWE (\"red carpet\") and its semantic head (\"carpet\").",
        "Then, it compares these uses to decide MWE compositionality.",
        "The more diverse these uses are, the more possibly the MWE is non-compositional.",
        "Our algorithm consists of 4 steps:",
        "A. Corpora collection and preprocessing.",
        "Our approach receives as input a MWE (e.g. \"red carpet\").",
        "The dependency output of Stanford Parser (Klein and Manning, 2003) is used to locate the",
        "II.",
        "collocations (legend)",
        "5: cinema_entrance 6: cinema_film 7: cinema_theatre 8: cinema_star 9: entrance theatre 10: Oscar cinema 11: Oscar film 12: Oscar star",
        "I. nouns and collocations of 2 web-text snippets actor, cinema, film, Oscar, star cinema, corridor, entrance, film, theatre",
        "Figure 1: \"red carpet\", sense induction example MWE semantic head.",
        "Two different corpora are collected (for the MWE and its semantic head).",
        "Each consists of webtext snippets of length 15 to 200 tokens in which the MWE/semantic head appears.",
        "Given a MWE, a set of queries is created: All synonyms of the MWE extracted from Word-Net are collected.",
        "The MWE is paired with each synonym to create a set of queries.",
        "For each query, snippets are collected by parsing the web-pages returned by Yahoo!.",
        "The union of all snippets produces the MWE corpus.",
        "The corpus for a semantic head is created equivalently.",
        "To keep the computational time reasonable, only the longest 3, 000 snippets are kept from each corpus.",
        "Both corpora are PoS tagged (GENIA tagger).",
        "In common with Agirre et al.",
        "(2006), only nouns are kept and lemmatized, since they are more discriminative than other PoS.",
        "B.",
        "Sense Induction methods can be broadly divided into vector-space models and graph based models.",
        "Sense induction methods are evaluated under the SemEval-2007 framework (Agirre and Soroa, 2007).",
        "We employ the collocational graph-based sense induction of Klapaftis and Manand-har (2008) in this work (henceforth referred to as KM).",
        "The method consists of 3 stages:",
        "Corpus preprocessing aims to capture nouns that are contextually related to the target MWE/head.",
        "Log-likelihood ratio (G) (Dunning, 1993) with respect to a large reference corpus, Web IT 5-gram Corpus (Brants and Franz, 2006), is used to capture the contextually relevant nouns.",
        "Pi is the G threshold below which nouns are removed from corpora.",
        "Graph creation.",
        "A collocation is defined as a pair of nouns cooccuring within a snippet.",
        "Each noun within a snippet is combined with every other, generating (2) collocations.",
        "Each collocation is represented as a weighted vertex.",
        "P2 thresholds collocation frequencies and P3 collocation weights.",
        "Weighted edges are drawn based on cooccurrence of the corresponding vertices in one or more snippets (e.g. Wg and Â«^9, fig. 1).",
        "In contrast to KM, frequencies for weighting vertices and edges are obtained from Yahoo!",
        "web-page counts to deal with data sparsity.",
        "Graph clustering uses Chinese Whispers (Bie-mann, 2006) to cluster the graph.",
        "Each cluster now represents a sense of the target word.",
        "KM produces larger number of clusters (uses) than expected.",
        "To reduce it we exploit the one sense per collocation property (Yarowsky, 1995).",
        "Given a cluster k, we compute the set Si of snippets that contain at least one collocation of U.",
        "Any clusters la and lb are merged if Sa C 56.",
        "lrThus, for \"red carpet\", corpora will be collected for \"red carpet\" and \"carpet\".",
        "The synonyms of \"red carpet\" are \"rug\", \"carpet\" and \"carpeting\"",
        "where A, B are sets of collocations.",
        "The second, Jsn, is based on the snippets that are tagged by the induced uses.",
        "Let Ki be the set of snippets in which at least one collocation of the use i occurs.",
        "Jsn = J(Kj,Kk), where j, k are the major uses of the MWE and its semantic head, respectively.",
        "D. Determining compositionality.",
        "Given the major uses of a MWE and its semantic head, the MWE is considered as compositional, when the corresponding distributional similarity measure (Jc or Jsn) value is above a parameter threshold, sim.",
        "Otherwise, it is considered as non-compositional."
      ]
    },
    {
      "heading": "3. TestsetofMWEs",
      "text": [
        "To the best of our knowledge there are no noun compound datasets accompanied with compositionality judgements available.",
        "Thus, we developed an algorithm to aid human annotation.",
        "For each of the 52,217 MWEs of WordNet 3.0 (Miller, 1995) we collected:",
        "C. Comparing the induced senses.",
        "We used two techniques to measure the distributional similarity of major uses of the MWE and its semantic head, both based on Jaccard coefficient (J).",
        "\"Major use\" denotes the cluster of collocations which tags the most snippets.",
        "Lee (1999) shows that J performs better than other symmetric similarity measures such as cosine, Jensen-Shannon diver IN on-compositional MWEs",
        "agony aunt, black maria, dead end, dutch oven, fish finger,fool's paradise, goat's rue, green light, high jump, joint chiefs, lip service, living rock, monkey puzzle, motor pool, prince Albert, stocking stuffer, sweet bay, teddy boy, think tank",
        "Compositional MWEs",
        "box white oak, cartridge brass, common iguana, closed chain, eastern pipistrel, field mushroom, hard candy, king snake, labor camp, lemon tree, life form, parenthesis-free notation, parking brake, petit juror, relational adjective, taxonomic category, telephone service, tea table, upland cotton",
        "Table 1: Test set with compositionality annotation.",
        "MWEs whose compositionality was successfully detected by: (a) Iclword baseline are in bold font, (b) manual parameter selection are underlined and (c) average cluster coefficient are in italics."
      ]
    },
    {
      "heading": "1.. all synonyms of the MWE",
      "text": []
    },
    {
      "heading": "2.. all hypernyms of the MWE",
      "text": []
    },
    {
      "heading": "3.. sister-synsets of the MWE, within distance 3 3",
      "text": [
        "4. synsets that are in holonymy or meronymy relation to the MWE, within distance 3",
        "If the semantic head of the MWE is also in the above collection then the MWE is likely to be compositional, otherwise it is likely that the MWE is non-compositional.",
        "6, 287 MWEs were judged as potentially non-compositional.",
        "We randomly chose 19 and checked them manually.",
        "Those that were compositional were replaced by other randomly chosen ones.",
        "The process was repeated until we ended up with 19 non-compositional examples.",
        "Similarly, 19 negative examples that were judged as compositional were collected (Table 1)."
      ]
    },
    {
      "heading": "4. Evaluation setting and results",
      "text": [
        "The sense induction component of our algorithm depends upon 3 parameters: P\\ is the G threshold below which noun are removed from corpora.",
        "P2 thresholds collocation frequencies and P3 collocation weights.",
        "We chose P\\ e {5,10,15}, P2 e {10,10,10,10} and P3 e {0.2, 0.3, 0.4}.",
        "For reference, P\\ values of 3.84, 6.63, 10.83 and 15.13 correspond to G values for confidence levels of 95%, 99%, 99.9% and 99.99%, respectively.",
        "To assess the performance of the proposed algorithm we compute accuracy, the percentage of MWEs whose compositionality was correctly determined against the gold standard.",
        "We compared the system's performance against a baseline, Iclword, that assigns the whole graph to a single cluster and no graph clustering is performed.",
        "Iclword corresponds to a relevant SemEval-2007 baseline (Agirre and Soroa, 2007) and helps in showing whether sense induction can assist determining compositionality.",
        "Our method was evaluated for each (Pi, P2, P3) combination and similarity measures Jc and Jsn> separately.",
        "We used our development set to determine if there are parameter values that verify our hypothesis.",
        "Given a sim value (see section 2, last paragraph), we chose the best performing parameter combination manually.",
        "The best results for manual parameter selection were obtained for sim = 95% giving an accuracy of 68.42% for detecting non-compositional MWEs.",
        "In all experiments, Jsn outperforms Jc.",
        "With manually selected parameters, our system's accuracy is higher than Iclword for all sim values (5% points) (fig.",
        "2, table 1).",
        "The initial hypothesis holds; sense induction improves MWE compositionality detection."
      ]
    },
    {
      "heading": "5. Unsupervised parameter tuning",
      "text": [
        "We followed Korkontzelos et al.",
        "(2009) to select the \"best\" parameters (^1,^2,^3) for the collocational graph of each MWE or head word.",
        "We applied 8 graph connectivity measures (weighted and unweighted versions of average degree, cluster coefficient, graph entropy and edge density) separately on each of the clusters (resulting from the application of the Chinese whispers algorithm).",
        "Each graph connectivity measure assigns a score to each cluster.",
        "We averaged the scores over the clusters from the same graph.",
        "For each connectivity measure, we chose the parameter combination (Pi, P2, P3) that gave the highest score.",
        "-----Average Degree /~*",
        "-Average Cluster Coefficient /",
        ".......Edge Density / \\",
        "----Average Graph Entropy",
        "f / ' '",
        " â - y /",
        "While manual parameter tuning chooses a single globally best set of parameters (see section 4), the graph connectivity measures generate different values of (Pi, P2, P3) for each graph.",
        "The best performing distributional similarity measure is Jsn- Unweighted versions of graph connectivity measures perform better than weighted ones.",
        "Figures 3 and 4 present a comparison between the unweighted and weighted versions of all graph connectivity measures, respectively, for all sim values.",
        "Average cluster coefficient performs better or equally well to the other graph connectivity measures for all sim values (except for sim e [90%, 100%]).",
        "The accuracy of average cluster coefficient is equal (68.42%) to that of manual parameter selection (section 4, table 1).",
        "The second best performing unweighted graph connectivity measures is average graph entropy.",
        "For weighted graph connectivity measures, average graph entropy performs best, followed by average weighted clustering coefficient."
      ]
    },
    {
      "heading": "6. Conclusion and Future Work",
      "text": [
        "We hypothesized that sense induction can assist in identifying compositional MWEs.",
        "We introduced an unsupervised system to experimentally explore the hypothesis, and showed that it holds.",
        "We proposed a semi-supervised way to extract non-compositional MWEs from WordNet.",
        "We showed that graph connectivity measures can be successfully employed to perform unsupervised parameter tuning of our system.",
        "It would be interesting to explore ways to substitute querying Yahoo!",
        "so as to make the system quicker.",
        "Experimentation with more sophisticated graph connectivity measures could possibly improve accuracy.",
        "-----Average Weighted Degree",
        "-Average Weighted Cluster Coefficient",
        ".......Weighted Edge Density",
        "^ / A",
        " â â Average Weighted Graph Entropy",
        "/Px A ~"
      ]
    }
  ]
}
