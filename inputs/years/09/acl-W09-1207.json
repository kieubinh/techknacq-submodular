{
  "info": {
    "authors": [
      "Wanxiang Che",
      "Zhenghua Li",
      "Yongqiang Li",
      "Yuhang Guo",
      "Bing Qin",
      "Ting Liu"
    ],
    "book": "Proceedings of the Thirteenth Conference on Computational Natural Language Learning (CoNLL 2009): Shared Task",
    "id": "acl-W09-1207",
    "title": "Multilingual Dependency-based Syntactic and Semantic Parsing",
    "url": "https://aclweb.org/anthology/W09-1207",
    "year": 2009
  },
  "references": [
    "acl-C04-1197",
    "acl-D07-1101",
    "acl-D08-1008",
    "acl-J96-1002",
    "acl-L08-1222",
    "acl-P05-1013",
    "acl-W02-1006",
    "acl-W07-2034",
    "acl-W08-2121",
    "acl-W08-2134",
    "acl-W09-1201"
  ],
  "sections": [
    {
      "text": [
        "Wanxiang Che, Zhenghua Li, Yongqiang Li, Yuhang Guo, Bing Qin, Ting Liu",
        "Information Retrieval Lab School of Computer Science and Technology Harbin Institute of Technology, China, 150001",
        "{car, lzh, yqli, yhguo, qinb, tliu}@ir.hit.edu.cn",
        "Our CoNLL 2009 Shared Task system includes three cascaded components: syntactic parsing, predicate classification, and semantic role labeling.",
        "A pseudo-projective high-order graph-based model is used in our syntactic dependency parser.",
        "A support vector machine (SVM) model is used to classify predicate senses.",
        "Semantic role labeling is achieved using maximum entropy (MaxEnt) model based semantic role classification and integer linear programming (ILP) based post inference.",
        "Finally, we win the first place in the joint task, including both the closed and open challenges."
      ]
    },
    {
      "heading": "1. System Architecture",
      "text": [
        "Our CoNLL 2009 Shared Task (Hajic et al., 2009): multilingual syntactic and semantic dependencies system includes three cascaded components: syntactic parsing, predicate classification, and semantic role labeling."
      ]
    },
    {
      "heading": "2. Syntactic Dependency Parsing",
      "text": [
        "1.",
        "We use bigram features to choose multiple possible syntactic labels for one arc, and decide the optimal label during decoding.",
        "2.",
        "We extend the model with sibling features (McDonald, 2006).",
        "3.",
        "We extend the model with grandchildren features.",
        "Rather than only using the leftmost and rightmost grandchildren as Carreras (2007) and Johansson and Nugues (2008) did, we use all left and right grandchildren in our model.",
        "4.",
        "We adopt the pseudo-projective approach introduced in (Nivre and Nilsson, 2005) to handle the non-projective languages including Czech, German and English.",
        "The model of (Che et al., 2008) decided one label for each arc before decoding according to unigram features, which caused lower labeled attachment score (LAS).",
        "On the other hand, keeping all possible labels for each arc made the decoding inefficient.",
        "Therefore, in the system of this year, we adopt approximate techniques to compromise, as shown in the following formulas.",
        "For each arc, we firstly use unigram features to choose the Ki best labels.",
        "The second parameter of fib(•) indicates whether the node is the head of the arc, and the third parameter indicates the direction.",
        "L denotes the whole label set.",
        "Then we re-rank the labels by combining the bigram features, and choose K2-best labels.",
        "During decoding, we only use the K2 labels chosen for each arc (K2 ^ Ki < |L|).",
        "Following the Eisner (2000) algorithm, we use spans as the basic unit.",
        "A span is defined as a substring of the input sentence whose sub-tree is already produced.",
        "Only the start or end words of a span can link with other spans.",
        "In this way, the algorithm parses the left and the right dependence of a word independently, and combines them in the later stage.",
        "We follow McDonald (2006)'s implementation of first-order Eisner parsing algorithm by modifying its scoring method to incorporate high-order features.",
        "Our extended algorithm is shown in Algorithm 1.",
        "There are four different span-combining operations.",
        "Here we explain two of them that correspond to right-arc (s < t), as shown in Figure 1 and 2.",
        "We Algorithm 1 High-order Eisner Parsing Algorithm",
        "5: if t>N then # Create incomplete spans # Create complete spans",
        "follow the way of (McDonald, 2006) and (Carreras, 2007) to represent spans.",
        "The other two operations corresponding to left-arc are similar.",
        "Figure 1 illustrates line 8 of the algorithm in Algorithm 1, which combines two complete spans into an incomplete span.",
        "A complete span means that only the head word can link with other words further, noted as \" – >\" or \".",
        "An incomplete span indicates that both the start and end words of the span will link with other spans in the future, noted as \"--->\" or \"<---\".",
        "In this operation, we combine two smaller spans, sps^r and spr+i^t, into sps – +t with adding arcs^t.",
        "As shown in the following formulas, the score of sps – +t is composed of three parts: the score of sps^r, the score of spr+i^t, and the score of adding arcs^t.",
        "The score of arcs^t is determined by four different feature sets: unigram features, bigram features, sibling features and left grandchildren features (or inside grandchildren features, meaning that the grandchildren lie between s and t).",
        "Note that the sibling features are only related to the nearest sibling node of t, which is denoted as sck here.",
        "And the inside grandchildren features are related to all the children of t. This is different from the models used by Carreras (2007) and Johansson and Nugues (2008).",
        "They only used the leftmost child of t, which is tck here.",
        "In Figure 2 we combine sps--+r and spr^t into sps^t, which explains line 10 in Algorithm 1.",
        "The score of sps^t also includes three parts, as shown in the following formulas.",
        "Although there is no new arc added in this operation, the third part is necessary because it reflects the right (or called outside) grandchildren information of arcs^r.",
        "fcp(sj rj t, l) = [Jj=i fgrand(si ri rcij l)",
        "As shown above, features used in our model can be decomposed into four parts: unigram features, bigram features, sibling features, and grandchildren features.",
        "Each part can be seen as two different sets: arc-related and label-related features, except sibling features, because we do not consider labels when using sibling features.",
        "Arc-related features can be understood as back-off of label-related features.",
        "Actually, label-related features are gained by simply attaching the label to the arc-features.",
        "The unigram and bigram features used in our model are similar to those of (Che et al., 2008), except that we use bigram label-related features.",
        "The sibling features we use are similar to those of (McDonald, 2006), and the grandchildren features are similar to those of (Carreras, 2007)."
      ]
    },
    {
      "heading": "3. Predicate Classification",
      "text": [
        "The predicate classification is regarded as a supervised word sense disambiguation (WSD) task here.",
        "The task is divided into four steps:",
        "1.",
        "Target words selection: predicates with multiple senses appearing in the training data are selected as target words.",
        "2.",
        "Feature extraction: features in the context around these target words are extracted as shown in Table 4.",
        "The detailed explanation about these features can be found from (Che et al., 2008).",
        "3.",
        "Classification: for each target word, a Support Vector Machine (SVM) classifier is used to classify its sense.",
        "As reported by Lee and Ng (2002) and Guo et al.",
        "(2007), SVM shows good performance on is used.",
        "The linear kernel function is used and the trade off parameter C is 1.",
        "4.",
        "Post processing: for each predicate in the test data which does not appear in the training data, its first sense in the frame files is used."
      ]
    },
    {
      "heading": "4. Semantic Role Labeling",
      "text": [
        "The semantic role labeling (SRL) can be divided into two separate stages: semantic role classification (SRC) and post inference (PI).",
        "During the SRC stage, a Maximum entropy (Berger et al., 1996) classifier is used to predict the probabilities of a word in the sentence to be each semantic role.",
        "We add a virtual role \"NULL\" (presenting none of roles is assigned) to the roles set, so we do not need semantic role identification stage anymore.",
        "For a predicate of each language, two classifiers (one for noun predicates, and the other for verb predicates) predict probabilities of each word in a sentence to be each semantic role (including virtual role \"NULL\").",
        "The features used in this stage are listed in Table 4.",
        "The probability of each word to be a semantic role for a predicate is given by the SRC stage.",
        "The results generated by selecting the roles with the largest probabilities, however, do not satisfy some constrains.",
        "As we did in the last year's system (Che et al., 2008), we use the ILP (Integer Linear Programming) (Punyakanok et al., 2004) to get the global optimization, which is satisfied with three constrains:",
        "C1: Each word should be labeled with one and only one label (including the virtual label \"NULL\").",
        "C2: Roles with a small probability should never be labeled (except for the virtual role \"NULL\").",
        "The threshold we use in our system is 0.3.",
        "C3: Statistics show that some roles (except for the virtual role \"NULL\") usually appear once for a predicate.",
        "We impose a no-duplicate-roles constraint with a no-duplicate-roles list, which is constructed according to the times of semantic roles' duplication for each single predicate.",
        "Table 1 shows the no-duplicate-roles for different languages.",
        "Our maximum entropy classifier is implemented with Maximum Entropy Modeling Toolkit.",
        "The classifier parameters are tuned with the development data for different languages respectively.",
        "lp_solve 5.5 is chosen as our ILP problem solver.",
        "Language",
        "No-duplicated-roles",
        "Catalan",
        "argO-agt, argO-cau, argl-pat, arg2-atr, arg2-loc",
        "Chinese",
        "AO, Al, A2, A3, A4, A5,",
        "Czech",
        "ACT, ADDR, CRIT, LOC, PAT, DIR3, COND",
        "English",
        "AO, Al, A2, A3, A4, A5,",
        "German",
        "AO, Al, A2, A3, A4, A5,",
        "Japanese",
        "DE, GA, TMP, WO",
        "Spanish",
        "argO-agt, argO-cau, argl-pat, argl-tem, arg2-atr,",
        "arg2-loc, arg2-null, arg4-des, argL-null, argM-",
        "cau, argM-ext, argM-fin"
      ]
    },
    {
      "heading": "5. Experiments",
      "text": [
        "We participate in the CoNLL 2009 shared task with all 7 languages: Catalan (Tauie et al., 2008), Chinese (Palmer and Xue, 2009), Czech (HajiC et al., 2006), English (Surdeanu et al., 2008), German (Burchardt et al., 2006), Japanese (Kawahara et al., 2002), and Spanish (Taule et al., 2008).",
        "Besides the closed challenge, we also submitted the open challenge results.",
        "Our open challenge strategy is very simple.",
        "We add the SRL development data of each language into their training data.",
        "The purpose is to examine the effect of the additional data, especially for out-of-domain (ood) data.",
        "Three machines (with 2.5GHz Xeon CPU and 16G memory) were used to train our models.",
        "During the peak time, Amazon's EC2 (Elastic Compute Cloud) was used, too.",
        "Our system requires 15G memory at most and the longest training time is about 36 hours.",
        "During training the predicate classification (PC) and the semantic role labeling (SRL) models, golden syntactic dependency parsing results are used.",
        "Previous experiments show that the PC and SRL test results based on golden parse trees are slightly worse than that based on cross trained parse trees.",
        "It is, however, a pity that we have no enough time and machines to do cross training for so many languages.",
        "In order to examine the performance of the ILP based post inference (PI) for different languages, we adopt a simple PI strategy as baseline, which selects the most likely label (including the virtual label \"NULL\") except for those duplicate non-virtual labels with lower probabilities (lower than 0.5).",
        "Table 2 shows their performance on development data.",
        "We can see that the ILP based post inference can improve the precision but decrease the recall.",
        "Except for Czech, almost all languages are improved.",
        "Among them, English benefits most.",
        "The final system results are shown in Table 3.",
        "syntactic parsing results on English, we can see that our new high-order model improves about 1%.",
        "For the open challenge, because we did not modify the syntactic training data, its results are the same as the closed ones.",
        "We can, therefore, examine the effect of the additional training data on SRL.",
        "We can see that along with the development data are added into the training data, the performance on the indomain test data is increased.",
        "However, it is interesting that the additional data is harmful to the ood test."
      ]
    },
    {
      "heading": "6. Conclusion and Future Work",
      "text": [
        "Our CoNLL 2009 Shared Task system is composed of three cascaded components.",
        "The pseudo-projective high-order syntactic dependency model outperforms our CoNLL 2008 model (in English).",
        "The additional in-domain (devel) SRL data can help the in-domain test.",
        "However, it is harmful to the ood test.",
        "Our final system achieves promising results.",
        "In the future, we will study how to solve the domain adaptive problem and how to do joint learning between syntactic and semantic parsing."
      ]
    },
    {
      "heading": "Acknowledgments",
      "text": [
        "This work was supported by National Natural Science Foundation of China (NSFC) via grant 60803093, 60675034, and the \"863\" National HighTech Research and Development of China via grant 2008AA01Z144.",
        "Precision",
        "Recall",
        "F1",
        "Catalan simple Catalan ILP",
        "78.68 79.42",
        "77.14 76.49",
        "77.90 77.93",
        "Chinese simple Chinese ILP",
        "80.74 81.97",
        "74.36 73.92",
        "77.42 77.74",
        "Czech simple Czech ILP",
        "88.54 89.23",
        "84.68 84.05",
        "86.57 86.56",
        "English simple English ILP",
        "83.03 85.63",
        "83.55 83.03",
        "83.29 84.31",
        "German simple German ILP",
        "78.88 82.04",
        "75.87 74.10",
        "77.34 77.87",
        "Japanese simple Japanese ILP",
        "88.04 89.23",
        "70.68 70.16",
        "78.41 78.56",
        "Spanish simple Spanish ILP",
        "76.73 77.71",
        "75.92 75.34",
        "76.33 76.51",
        "Syntactic Accuracy (LAS)",
        "Semantic Labeled F1",
        "Macro F1 Score",
        "devel",
        "test",
        "ood",
        "devel",
        "test",
        "ood",
        "devel",
        "test",
        "ood",
        "Catalan",
        "closed open",
        "86.65",
        "86.56",
        " – ",
        "ll.93",
        "ll.10 ll.36",
        "-",
        "82.30",
        "81.84 81.9l",
        " – ",
        "Chinese",
        "closed open",
        "l5.l3",
        "l5.49",
        " – ",
        "ll.l4",
        "ll.15 ll.23",
        "-",
        "l6.l9",
        "l6.38 l6.42",
        " – ",
        "Czech",
        "closed open",
        "80.0l",
        "80.01",
        "l6.03",
        "86.56",
        "86.51 86.5l",
        "85.26 85.21",
        "83.33",
        "83.2l 83.31",
        "80.66 80.63",
        "English",
        "closed open",
        "8l.09",
        "88.48",
        "81.5l",
        "84.30",
        "85.51 85.61",
        "l3.82 l3.66",
        "85.l0",
        "8l.00 8l.05",
        "ll.63",
        "German",
        "closed open",
        "85.69",
        "86.19",
        "l6.11",
        "ll.8l",
        "l8.61 l8.61",
        "l0.0l l0.09",
        "81.83",
        "82.44 82.44",
        "l3.19 l3.20",
        "Japanese",
        "closed open",
        "92.55",
        "92.5l",
        "-",
        "l8.56",
        "l8.26 l8.35",
        "-",
        "85.86",
        "85.65 85.l0",
        "-",
        "Spanish",
        "closed open",
        "8l.22",
        "8l.33",
        "-",
        "l6.51",
        "l6.4l l6.66",
        "-",
        "81.8l",
        "81.90 82.00",
        "-",
        "Average",
        "closed open",
        "-",
        "85.23",
        "ll.90",
        "-",
        "l9.94 80.06",
        "l6.38 l6.32",
        "-",
        "82.64 82.l0",
        "ll.19 ll.15",
        "Catalan",
        "Chinese",
        "Czech",
        "English",
        "German",
        "Japanese",
        "Spanish",
        "ChildrenPOS",
        "ChildrenPOSNoDup",
        "ConstituentPOSPattern",
        "ConstituentPOSPattern+DepRelation",
        "ConstituentPOSPattern+DepwordLemma",
        "ConstituentPOSPattern+HeadwordLemma",
        "DepRelation",
        "A A ♦ ♦",
        "A A ♦ ♦",
        "A A ♦ ♦",
        "A A",
        "A A ♦ ♦",
        "DepRelation+DepwordLemma",
        "DepRelation+Headword",
        "A A",
        "A A",
        "A",
        "A A",
        "A A",
        "A",
        "DepRelation+HeadwordLemma",
        "DepRelation+HeadwordLemma+DepwordLemma",
        "DepRelation+HeadwordPOS",
        "A A",
        "A A",
        "A A",
        "A A",
        "A A",
        "A",
        "Depword",
        "DepwordLemma",
        "DepwordLemma+HeadwordLemma",
        "DepwordLemma+RelationPath",
        "DepwordPOS",
        "A A",
        "A A",
        "A A ♦ ♦",
        "A A",
        "A A ♦ ♦",
        "A A",
        "DepwordPOS+HeadwordPOS",
        "DownPathLength",
        "FirstLemma",
        "FirstPOS",
        "FirstPOS+DepwordPOS",
        "FirstWord",
        "Headword",
        "A A",
        "A A",
        "A A",
        "A A",
        "A A ♦ ♦",
        "A",
        "HeadwordLemma",
        "A A ♦ ♦",
        "A A ♦ ♦",
        "A A ♦ ♦",
        "A A ♦ ♦",
        "A A ♦ ♦",
        "A",
        "HeadwordLemma+RelationPath",
        "HeadwordPOS",
        "A A",
        "A A",
        "A A ♦ ♦",
        "A A ♦ ♦",
        "A A ♦ ♦",
        "A A",
        "LastLemma",
        "LastPOS",
        "LastWord",
        "Path",
        "Path+RelationPath",
        "PathLength",
        "PFEAT",
        "A A",
        "A A",
        "A A",
        "PFEATSplit",
        "A A ♦ ♦",
        "A A ♦ ♦",
        "A A ♦ ♦",
        "A A ♦ ♦",
        "PFEATSplitRemoveNULL",
        "A A",
        "A A",
        "A A",
        "PositionWithPredicate",
        "Predicate",
        "A A ♦ ♦",
        "A A",
        "A A ♦ ♦",
        "A A",
        "A A",
        "A A ♦ ♦",
        "Predicate+PredicateFamilyship",
        "♦ ♦",
        "PredicateBagOfPOSNumbered",
        "A",
        "A A",
        "A A",
        "A A",
        "PredicateBagOfPOSNumberedWindow5",
        "A A",
        "A A",
        "A",
        "A",
        "A A",
        "A A",
        "PredicateBagOfPOSOrdered",
        "A A",
        "A A",
        "A A",
        "A A",
        "A",
        "PredicateBagOfPOSOrderedWindow5",
        "A A",
        "A A",
        "A A",
        "A A",
        "A A",
        "A A",
        "PredicateBagOfPOSWindow5",
        "A",
        "A A",
        "A A",
        "A A",
        "A A",
        "A",
        "PredicateBagOfWords",
        "A",
        "A A",
        "A",
        "A A",
        "A A",
        "PredicateBagOfWordsAndIsDesOfPRED",
        "A A",
        "A",
        "A",
        "A",
        "A A",
        "A A",
        "PredicateBagOfWordsOrdered",
        "A",
        "A A",
        "A A",
        "A",
        "A A",
        "A A",
        "PredicateChildrenPOS",
        "A A ♦ ♦",
        "A A",
        "A A",
        "A A",
        "A A",
        "A A ♦ ♦",
        "PredicateChildrenPOSNoDup",
        "A A",
        "A A",
        "A A",
        "A A",
        "A A",
        "A A",
        "PredicateChildrenREL",
        "A A ♦ ♦",
        "A A",
        "A A",
        "A A",
        "A A ♦ ♦",
        "A A",
        "PredicateChildrenRELNoDup",
        "A A ♦ ♦",
        "A A",
        "A A",
        "A A",
        "A A ♦ ♦",
        "A A",
        "PredicateFamilyship",
        "PredicateLemma",
        "A A ♦ ♦",
        "A A ♦ ♦",
        "A A ♦ ♦",
        "A A ♦ ♦",
        "A A ♦ ♦",
        "A A ♦ ♦",
        "PredicateLemma+PredicateFamilyship",
        "PredicateSense",
        "PredicateSense+DepRelation",
        "PredicateSense+DepwordLemma",
        "PredicateSense+DepwordPOS",
        "PredicateSiblingsPOS",
        "A A",
        "A A",
        "A",
        "A A",
        "A A",
        "A A",
        "PredicateSiblingsPOSNoDup",
        "A A ♦ ♦",
        "A A",
        "A A",
        "A A",
        "A A",
        "A A ♦ ♦",
        "PredicateSiblingsREL",
        "A A ♦ ♦",
        "A A",
        "A A",
        "A A",
        "A A",
        "A A",
        "PredicateSiblingsRELNoDup",
        "A A",
        "A A ♦ ♦",
        "A",
        "A A",
        "A A ♦ ♦",
        "A A ♦ ♦",
        "PredicateVoiceEn",
        "A A",
        "PredicateWindow5Bigram",
        "A A",
        "A A",
        "A A",
        "A A",
        "PredicateWindow5BigramPOS",
        "A A",
        "A A",
        "A A",
        "A A",
        "A A",
        "A A",
        "RelationPath",
        "SiblingsPOS",
        "SiblingsREL",
        "SiblingsRELNoDup",
        "UpPath",
        "♦",
        "UpPathLength",
        "UpRelationPath",
        "UpRelationPath+HeadwordLemma"
      ]
    }
  ]
}
