{
  "info": {
    "authors": [
      "Richard Bergmair"
    ],
    "book": "Proceedings of the 2009 Workshop on Applied Textual Inference (TextInfer)",
    "id": "acl-W09-2502",
    "title": "A Proposal on Evaluation Measures for RTE",
    "url": "https://aclweb.org/anthology/W09-2502",
    "year": 2009
  },
  "references": [
    "acl-J04-1005",
    "acl-P08-1008",
    "acl-W07-1401"
  ],
  "sections": [
    {
      "text": [
        "A Proposal on Evaluation Measures for rte",
        "recipient of a DOC-fellowship of the Austrian Academy of Sciences at the University of Cambridge Computer Laboratory; 15 JJ Thomson Avenue, Cambridge CB3 OFD, UK;",
        "rbergmair@acm.org",
        "We outline problems with the interpretation of accuracy in the presence of bias, arguing that the issue is a particularly pressing concern for rte evaluation.",
        "Furthermore, we argue that average precision scores are unsuitable for rte, and should not be reported.",
        "We advocate mutual information as a new evaluation measure that should be reported in addition to accuracy and confidence-weighted score."
      ]
    },
    {
      "heading": "1. Introduction",
      "text": [
        "We assume that the reader is familiar with the evaluation methodology employed in the rte challenge.",
        "We address the following three problems we currently see with this methodology.",
        "1.",
        "The distribution of three-way gold standard labels is neither balanced nor representative of an application scenario.",
        "Yet, systems are rewarded for learning this artificial bias from training data, while there is no indication of whether they could learn a different bias.",
        "2.",
        "The notion of confidence ranking is misleading in the context of evaluating a ranking by average precision.",
        "The criteria implicitly invoked on rankings by the current evaluation measures can, in fact, contradict those invoked on labellings derived by rank-based thresholding.",
        "3.",
        "Language allows for the expression of logical negation, thus imposing a symmetry on the judgements entailed vs. contradiction.",
        "Average precision does not properly reflect this symmetry.",
        "In this paper, we will first summarize relevant aspects of the current methodology, and outline these three problems in greater depth.",
        "Lhe problem of bias is quite general and widely known.",
        "Artstein and Poesio (2005) discuss it in the context of Cohen's kappa (Cohen, 1960), which is one way of addressing the problem.",
        "Yet, it has not received sufficient attention in the rte community, which is why we will show how it applies to rte, in particular, and why it is an especially pressing concern for rte.",
        "Average precision has been imported into the rte evaluation methodology from ir, tacitly assuming a great level of analogy between ir and rte.",
        "However, we will argue that the analogy is flawed, and that average precision is not suitable for rte evaluation.",
        "Lhen, we will then reframe the problem in information theoretic terms, advocating mutual information as a new evaluation measure.",
        "We will show that it addresses all of the issues raised concerning accuracy and average precision and has advantages over Cohen's kappa."
      ]
    },
    {
      "heading": "2. The Structure of RTE Data",
      "text": [
        "Let X be the set of all candidate entailments that can be formed over a natural language of interest, such as English.",
        "An rte dataset X <= X is a set of N candidate entailments X = {xi, x2,..., xn}.",
        "The rte task is characterized as a classification task.",
        "A given candidate entailment Xj can be associated with either a positive class label A (true / yes / entailed) or a negative class label V (false / no / not entailed), but never both.",
        "In the three-way subtask, the positive class, which we will denote as EE is defined as before, but the negative class v is further subdivided into a class B (no / contradiction) and a class 0 (unknown).",
        "To model this subdivision, we define equivalence classes [-]3 and [-]2 on the three-way labels as follows: [EB]3 = EEL [0]3 = 0, [Bh = EEL [EB]2 = A, [0]2 = V, and [B]2 = V-The gold standard G for dataset X is then a labelling G : X i ^ {EEL 0, □}• We call a candidate entailment Xj a A-instance iff [G(xj)]2 = A, and analogously for the other class labels.",
        "The output (L, >) of an rte system on dataset X also contains such a labelling L : X (-► {EB, 0, B}, in addition to a strict total order > on X representing a ranking of candidate entailments.",
        "The notation chosen here is inspired by modal logic.",
        "Let's say a candidate entailment Xj were of the logical form p – ► ip.",
        "The formula \"°{<p – ► ip)\" would then assert that ip necessarily follows from tp (entailment), and the formula \"□(<£ – [ip)\", which would be equivalent to \"^()(pAip)\", would mean that we can not possibly have tp a ip (contradiction).",
        "We think of the former as a positive form of necessity (B), and of the latter as a negative form of necessity (ED- The formula \"§(<p – ► ip)\" would assert that ip possibly follows from <p (unknown).",
        "We will have to assume that this negation operator -■ is in fact within the expressive power of the natural language of interest, i.e. \"tp ^> – >ip\" e X, whenever \"p – ► ip\" e X.",
        "It imposes a symmetry on the two labels B and EL with 0 being neutral.",
        "For example: \"Socrates is a man and every man is mortal; Therefore Socrates is mortal.\"",
        "This candidate entailment is a B-instance.",
        "It corresponds to the following B-instance: \"Socrates is a man and every man is mortal; Therefore Socrates is not mortal\".",
        "But then, consider the 0-instance \"Socrates is mortal; Therefore Socrates is a man \".",
        "Here \"Socrates is mortal; Therefore Socrates is not a man\" is still a 0-instance.",
        "It is this modal logic interpretation which matches most closely the ideas conveyed by the task definitions (TAC, 2009), and the annotation guidelines (de Marneffe and Manning, 2007).",
        "However, for the two-way task, they allude more to probabilistic logic or fuzzy logic, where a candidate entailment is a A-instance iff it holds to a higher degree or likelihood or probability than its negation, and a y-instance otherwise.",
        "We believe that either a three-way modal logic entailment task or a two-way probabilistic logic entailment task on its own could make perfect sense.",
        "However, they are qualitatively different and not trivially related by equating A with EL and subdividing y into 0 and EL"
      ]
    },
    {
      "heading": "3. Accuracy & Related Measures",
      "text": [
        "Both the system and the gold standard apply to the dataset X a total labelling L and G respectively, i.e. they are forced to assign their best guess label to every instance.",
        "A degree of agreement can be determined as a percentage agreement either on the two-way or the three-way distinction:",
        "where 1 is a counter which takes on a numerical value of one, when the logical expression in its argument is true, and zero otherwise.",
        "The rte-3 pilot (Voorhees, 2008) reported some accuracy measures conditioned on gold standard labels as follows:",
        "Assuming the usual analogy with ir, we note that A'2 (L; G, A) is akin to recall.",
        "On the other hand, A'2 (G; L, A), which conditions accuracy on the system-assigned labels rather than the gold standard labels, is precision.",
        "The conditioned accuracy measures do not provide a single summary statistic as the others do.",
        "However, such a summary could be defined by taking the mean across the different labels:",
        "A'2(L;G) = ^ £ A'2(L;G;<7).",
        "It is instructive to consider a number of trivial baseline systems.",
        "Let Sffl, S*, and SH, be the systems that uniformly assign to everything the labels EL 0, and EL respectively, so that for all i: Lffl(Xi) = B, LO(xi) = 0, and LS(x;) = B-Also consider system S*, which assigns labels at random, according to a uniform distribution.",
        "The performance of these systems depends on the distribution of gold-standard labels.",
        "The policy at rte was to sample in such a way that the resulting two-way labels in the gold standard would",
        "This means that all trivial baselines have an accuracy of A2 = A'2 = 50%.",
        "If the data were balanced on the three-way labels, which they are not, we would analogously have A3 = A'3 = 33%.",
        "When interpreting a two-way accuracy, one would thus expect values between 50% and 100%, where 50% indicates a trivial system and 100% indicates a perfect system.",
        "A value of, for example, 70% could be interpreted as-is, mindful of the above range restriction, or the range restriction could be factored into the value by using a linear transformation.",
        "One would then say that the accuracy of 70% is 40% of the way into the relevant range of 50% – 100%, and quote the value as a Cohen's Kappa of n = 0.4.",
        "While the rte datasets are balanced on two-way gold standard labels, they are not balanced on the three-way gold standard labels.",
        "Among the candidate entailments x» with [G(xj)]2 = y> m rte-4, 70% of all Xi had [G(x;)]3 = 0, while only 30% had [G(xj)]3 = B.",
        "In the rte-3 pilot, the distribution was even more skewed, at 82%/18%.",
        "So, we observe that Sffl has A3(Lffl; G) = .500 and therefore outperforms two thirds of all rte-3 pilot participants and one third of all rte-4 participants.",
        "On the other hand, only very few participants performed worse than the random choice system S*, which had A3(L*;G) = .394onRTE-4.",
        "The other trivial systems have A3(L*; G) = .350, followed by A3(LH; G) = .150 on rte-4.",
        "The conditioned accuracies seem to promise a way out, since they provide an artificial balance across the gold standard labels.",
        "We have A'3(Lffl;G) = A'3(L0;G) = A'3(LH;G) = .33.",
        "But this measure is then counter-intuitive in that the random-choice system S* gets A'3(L*; G) = .394 on rte-4 and would thus be considered strictly superior to the system Sffl, which, if nothing else, at least reproduces the right bias.",
        "Another caveat is that this would weigh errors on rare labels more heavily than errors on common labels.",
        "In some form or another the problem of bias applies not only to accuracy itself, but also to related statistics, such as precision, recall, precision/recall curves, and confidence weighted score.",
        "It is therefore quite general, and there are three responses which are commonly seen:",
        "1.",
        "For purposes of intrinsic evaluation, one can use samples that have been balanced artificially, as it is being done in the two-way rte task.",
        "Yet, it is impossible to balance a dataset both on a two-way and a three-way labelling at the same time.",
        "2.",
        "One can use representative samples and argue that the biased accuracies have an extrinsic interpretation.",
        "For example, in ir, precision is the probability that a document chosen randomly from the result set will be considered relevant by the user.",
        "Yet, for rte, one cannot provide a representative sample, as the task is an abstraction over a number of different applications, such as information extraction (ie), question answering (qa), and summarization (sum), all of which give rise to potentially very different distributions of labels.",
        "3.",
        "On statistical grounds, one can account for the possibility of random agreement in the presence of bias using Cohen's kappa (Artstein and Poesio, 2005; Di Eugenio and Glass, 2004).",
        "We will outline mutual information as an alternative, arguing that it has additional advantages."
      ]
    },
    {
      "heading": "4. Average Precision",
      "text": [
        "The purpose of average precision is to evaluate against the gold standard labelling G the system-assigned ranking >, rather than directly comparing the two labellings G and L.",
        "This is done by deriving from the ranking > a series of binary labellings.",
        "The i-th labelling in that series is that which labels all instances up to rank i as A.",
        "A precision value can be computed for each of these labellings, compared to the same gold standard, and then averaged.",
        "More formally, > is the strict total ordering on the dataset X which has been produced by the system.",
        "Let Xj > Xj iff Xj > Xi or xj = Xj.",
        "We can then associate with each instance x» a numeric rank, according to its position in >:",
        "We can then define the cutoff labelling >^ as",
        "I v otherwise; and average precision as",
        "The system-assigned labelling L and the series of ranking-based labellings >^ are initially independent, but, since both accuracy and average precision refer to the same gold standard G, we get the following condition on how L must relate to >: We call a system output (L, >) sound if there exists a cutoff rank r, such that L equals >(r\\ and self-contradictory otherwise.",
        "This is because, for a self-contradictory system output, there does not exist a gold standard for which it would be perfect, in the sense that both accuracy and average precision would simultaneously yield a value of 100%.",
        "So far, we avoided the common terminology referring to > as a \"confidence ranking\", as the notion of confidence would imply that we force the system to give its best guess labels, but also allow it to provide a measure of confidence, in this case by ranking the instances, to serve as a modality for the interpretation of such a best guess.",
        "This is not what is being evaluated by average precision.",
        "Here, a system can remain entirely ignorant as to what is a A-or a y-instance.",
        "System-assigned labels do not enter the definition, and systems are not required to choose a cutoff r to derive a labelling >(r\\ This sort of evaluation is adequate for ir purposes, where the system output is genuinely a ranking, and it is up to the user to set a cutoff on what is relevant to them.",
        "As for rte, it is unclear to us whether this applies.",
        "In the previous section, we have seen that it is somewhat misleading to see > as a confidence-ranking on the labelling L. Here, we argue that, even worse than that, the interpretations of > and L may contradict each other.",
        "It is impossible for a system to optimize its output (L, >) for accuracy A2(G;L) and simultaneously for average precision JUP(G; >), while maintaining as a side condition that the information state (L, >) remain sound at all times.",
        "We show this by indirect argument.",
        "For the sake of contradiction, assume that the system has come up with an internal information state consisting of the ranking > and the labelling L, as a best guess.",
        "Also assume that this information state is sound.",
        "Let's assume furthermore, again for the sake of contradiction, that the system is now allowed to query an oracle with access to the gold standard in order to revise the internal information state with the goal of improving its performance as measured by accuracy, and simultaneously also improving its performance as measured by average precision.",
        "First, the oracle reveals r, the number of A-instances in the gold standard.",
        "Let instance x; at rank #>(x{) = r be correctly classified, and the instance Xj at some rank #>(xj) > r + 1 be incorrectly classified.",
        "So we would have [L(xi)]2 = lir)(xi) = [G(Xi)]2 = A, and [L(Xj)]2 =",
        "Lir)(*j) = V * [G(xj)]2.",
        "Next, the oracle reveals the fact that xj had been misclassified.",
        "In response to that new information, the system could change the classification and set L(xj) A.",
        "This would lead to an increase in accuracy.",
        "Average precision would remain unaffected, as it is a function of >, not L.",
        "However, the information state (L, >) is now self-contradictory.",
        "The ranking > would have to be adapted as well to reflect the new information.",
        "Let's say xj were reranked by inserting it at some rank r' ^ r. This would lead to all intervening instances, including x;, to be ranked down, and thus to an increase in average precision.",
        "But, since x; has now fallen below the threshold r, which was, by definition, the correct threshold chosen by the oracle, the system would reclassify it as [L(xj)]2 = V> which now introduces a labelling error.",
        "While average precision would not react to this relabelling, accuracy would now drop.",
        "So there are two rather counterintuitive conclusions concerning the simultaneous application of accuracy, average precision, and thresholding.",
        "First, accuracy may prefer self-contradictory outputs to sound outputs.",
        "Second, when soundness is being forced, average precision may prefer lower accuracy to higher accuracy labellings.",
        "Again, it should be stressed that rte is the only prominent evaluation scheme we know of that insists on this combination of accuracy and average precision.",
        "If we had used precision and average precision, as in ir, the above argument would not hold.",
        "Also, in ir, average precision clearly dominates other measures in its importance.",
        "Besides the above arguments on bias, and on the contradictions between accuracy and average precision under a thresholding interpretation, there is a third problem with the current evaluation methodology.",
        "It arises from the symmetry between the classes EB and B which we introduced in section 2.1.",
        "This problem is a direct result of the inherent properties of language and logic, and is, thus, the argument which is most specific to rte.",
        "Let X = {xi, x2,..., xn} be a dataset, and let be the dataset resulting from the application of negation to each of the candidate entailments.",
        "Similarly, let G : X ^ {B, <), B} be a gold standard and for all x € X, let and analogously for the system-assigned labels L.",
        "Intuitively, we would now expect the following of an evaluation measure: A system that produces the labelling L for dataset X is equivalent, in terms of the evaluation measure, to a system that produces labelling for dataset ->X.",
        "This is indeed true for three-way accuracy, where A3(G;L) = A3 (-\"G; ->L), but it is not true for two-way accuracy, where the three-way classes are now lumped together in a different way.",
        "Also, this symmetry is not present in average precision, which looks only at positive instances.",
        "Since the set of A-instances of X and the set of A-instances of ^X are disjoint, the two average precisions AP(G; >) and iUP(->G; >'), regardless of how > relates to >', need not be functionally related.",
        "- This makes sense in ir, where the set of irrelevant and non-retrieved documents must not enter into the evaluation of a retrieval system.",
        "But it makes no sense for the rte task, where we do need to evaluate systems on the ability to assign a single label to all and only the contradictory candidate entailments."
      ]
    },
    {
      "heading": "5. Mutual Information",
      "text": [
        "In this section, we define mutual information as a possible new evaluation measure for rte.",
        "In particular, we return to the problem of bias and show that, like Cohen's kappa, mutual information does not suffer from bias.",
        "We will then introduce a new problem, which we shall call degradation.",
        "We show that Cohen's kappa suffers from degradation, but mutual information does not.",
        "Finally, we will extend the discussion to account for confidence.",
        "Recall that an rte dataset is a set of n candidate entailments X = {xi, x2,..., xn}, and let X be a random variable representing the result of a random draw from this set.",
        "Let P(X = Xj) be the probability that Xj comes up in the draw.",
        "This could represent, for example, the prior probability that a particular question is asked in a question answering scenario.",
        "In the absence of any extrinsically defined interpretations, one could set random variable X to be uniformly distributed, i.e. P(X = xi) = £ for all i.",
        "This yields a number of further random variables: Let G and L be the label G(xj) and L(xj) respectively, assigned to the candidate Xj which has been drawn at random.",
        "As usual, we will be interested in their joint distribution, and the resulting marginals and conditionals.",
        "We give the remaining definitions leading to mutual information in Figure 1, and will discuss them by considering the particular contingency table in Figure 2 as an example.",
        "It also spells out the information theoretic calculations in detail.",
        "Furthermore, we will present corresponding values for Cohen's kappa, which should be easy for the reader to retrace, and thus have been omitted from the Figure for brevity.",
        "The unconditional entropy H(G) serves as a convenient measure of the hardness of the classification task itself, taking into account the number of labels and their distribution in the gold standard.",
        "In the example, this distribution has been chosen to match that of the rte-4 dataset almost precisely, yielding a value for H(G) of 1.4277 bits.",
        "This indicates that it is much harder to guess the three-way gold standard label of an rte-4 candidate entailment than it is to guess the two-way label, or the outcome of a toss of a fair coin, which would both have an entropy of exactly 1 bit.",
        "On the other hand, due to the skewness of the distribution, it is easier to guess this outcome than it would be if the distribution was uniform, in which case we would have an entropy of 1.5850 bits.",
        "Similarly, we can calculate a conditional entropy H(G|L = I) over a conditional distribution of gold standard labels observed, given that the system has assigned label I to our randomly chosen candidate entailment.",
        "In the example, we have calculated a value of 1.0746 bits for H(G|L = El).",
        "So, while the hardness of guessing the correct label without any additional knowledge is 1.4277, it will be easier to guess this label correctly once the system-assigned label is known to be B-",
        "Our best guess would be to always assign label B, which would be successful 50% of the time.",
        "i(G;L) = h(G) – h(G|l).",
        "Figure 1: definitions for mutual information i(G; L) 27 , .27.",
        "20",
        "25",
        "5",
        "p(g",
        "= ffl)",
        "(45)",
        "(0)",
        "=",
        ".5",
        "9",
        "18",
        "9",
        "p(g",
        "= 0)",
        "(27)",
        "(0)",
        "=",
        ".36",
        "1",
        "7",
        "6",
        "p(g",
        "= □)",
        "(8)",
        "(0)",
        "=",
        ".14",
        "p(l = El)",
        "p(l = 0)",
        "p(l = El)",
        "= .3",
        "= .5",
        "= .2",
        "N =",
        "100",
        "(.8)",
        "(0)",
        "(■2)",
        "But, among the cases where the system in Figure 2 has assigned label El, this would be an even better guess.",
        "It would now be correct 66% of the time.",
        "We have gained information about the gold standard by looking at the system-assigned label.",
        "The conditional entropy H(G|L) is the expected value of the conditional entropy H(G|L = I) across all possible labels I, when, as before, we draw a candidate entailment at random.",
        "One very noteworthy property of this measure is that all of the baseline systems we considered, i.e. systems assigning constant labels, or systems assigning labels at random, would have H(G|L) = H(G), since the distribution of gold standard labels given the system labels, in all of these cases, is the same as the prior distribution.",
        "Furthermore, H(G) = 1.4277 is, in fact, an upper bound on H(G|L).",
        "All the trivial baseline systems would perform at this upper bound level.",
        "At the other extreme end of the spectrum, consider a perfect contingency table, where all the non-diagonal cells are zero.",
        "In this case all the conditional entropies H(G|L = I) would be entropies over delta distributions concentrating all probability mass on a single label.",
        "This would yield a value of H(G|L) = 0, which is a lower bound for any entropy.",
        "- For Cohen's kappa we would have k = 1.",
        "The system producing our contingency table performs worse than this ideal but better than the baselines, atH(G|L) = 1.3441.",
        "One can subtract H(G|L) from the upper bound H(G) to obtain the mutual information i(G;L).",
        "It is the information gained about G once the value of L is revealed.",
        "It is obviously still bounded between 0 and H(G), but is somewhat more intuitive as an evaluation measure, as it restores the basic intuition that larger values indicate higher performance.",
        "- Due to a surprising result of information theory it also turns out that i(G; L) = i(L; G).",
        "This symmetry is another property one would intuitively expect when comparing two labellings G and L to each other, and is also present for accuracy and kappa.",
        "We can compare the behaviour of this measure to that of accuracy.",
        "The accuracy of our example system is simply the sum of the diagonal contingency counts, so it scores at 44%, compared to 50% for the baseline that always assigns label El.",
        "The new bias-aware framework provides a quite different point of view.",
        "We would now note that the example system does provide i(L; G) = 0.0836 bits worth of information about G, showing an agreement of n = 0.1277, compared to zero information and n = 0 agreement for the baseline.",
        "The numbers in the example have been chosen so as to illustrate a problem we call degradation.",
        "The conditional distribution P(G = g\\L = 0) is the same as the unconditional distribution P(G = g), so when it turns out that L = (), no additional information has been revealed about G. But in information theoretic terms, it is considered good to know when exactly we know nothing.",
        "What happens if we conflate the labels 0 and El in the system output?",
        "In Figure, 2, the numbers in brackets illustrate this.",
        "Previously, the system assigned label El in 30% of all cases.",
        "In those cases, the system's choice was relatively well-informed, as El actually turned out to be the correct gold standard label 66% of the time.",
        "But now, with the labels conflated, the system chooses El in 80% of the cases; a choice which is now much less well-informed, as it is correct only 45% of the time.",
        "Mutual information shows a drop from 0.0836 bits down to 0.0262.",
        "On the other hand, accuracy increases from 44% to 51%, and Cohen's kappa also increases from 0.1277 to 0.1433.",
        "But this is clearly counter-intuitive.",
        "Surely, it must be a bad thing to conflate a well-informed label with a less well-informed label, thus obscuring the output to less certainty and more guesswork.",
        "One final issue that has still remained unaddressed is that of confidence ranking.",
        "This takes us back to the very first probabilistic notion we introduced, that of a probability distribution P(X = x») governing the choice of the test-instances Xj.",
        "The uniform distribution we suggested earlier results in all instances carrying equal weight in the evaluation.",
        "But for some applications, it makes sense to give the system some control over which test-instances it wants to be tested on, independently of the question of what results it produces for that test.",
        "- So, from a probabilistic point of view, the most natural take on confidence would be to have the system itself output the values P(X = Xj) as confidence weights.",
        "This would affect H(G), which we previously introduced as a measure of the difficulty of the task faced by the system.",
        "But now, the system has some control over what task it wants to try and solve.",
        "In an extreme scenario, it could concentrate all its confidence mass in a single instance.",
        "Another system might force itself to give equal weight to every instance.",
        "Clearly, these are two very different scenarios, so it seems natural that, as soon as the issue of confidence enters the scene, the evaluation has to consider two dimensions.",
        "The unconditional entropy h(G) would have to be reported for every system, together with the mutual information i(L; G).",
        "While h(G) would measure how effective a system was at using its confidence weighting as a tool to make the task easier on itself, i(L; G) would measure how successful the system ultimately was at the task it set for itself.",
        "The example of a system concentrating all of its confidence mass in a single instance shows that the ability to freely choose p(X = Xj) might not fit with realistic application scenarios.",
        "This leads to the idea of confidence ranking, where a system could only rank, not weigh, its decisions, and it would be up to the evaluation framework to then assign weights according to the ranks.",
        "For example, one could let",
        "This would assign a weight of N to the highest-ranked instance, a weight of N – 1 to the next, and continue in this manner down to the instance at rank N, which would get weight 1.",
        "The denominator in the above expression then serves to normalize this weighting to a probability distribution.",
        "Note that, in principle, nothing speaks against using any other series of weights.",
        "Perhaps further investigation into the application scenarios of RTE systems will provide an extrinsically motivated choice for such a confidence weighting."
      ]
    },
    {
      "heading": "6. Final Recommendations",
      "text": [
        "Ultimately, our proposal boils down to four points, which we believe are well-supported by the evidence presented throughout this paper:",
        "1.",
        "Additional clarification is needed as to the logical definitions of the two-way and the three-way distinction of entailment classes.",
        "2.",
        "Accuracy and related evaluation measures suffer from bias, and thus scores of theoretical baselines must be reported and compared to system scores.",
        "These include random choice and choice of a constant label.",
        "3.",
        "Average precision scores are misleading and should not be reported.",
        "The confidence-weighted score that has been dropped after rte-1 would be preferable to average precision, but still suffers from bias.",
        "4.",
        "Mutual information should be reported, in addition to accuracy and possibly confidence-weighted score, to account for bias and the degradation problem."
      ]
    },
    {
      "heading": "Acknowledgments",
      "text": [
        "I would like to thank the anonymous reviewers and my colleague Ekaterina Shutova for providing many helpful comments and my supervisor Ann Copestake for reading multiple drafts of this paper and providing a great number of suggestions within a very short timeframe.",
        "All errors and omissions are, of course, entirely my own.",
        "I gratefully acknowledge financial support by the Austrian Academy of Sciences."
      ]
    }
  ]
}
