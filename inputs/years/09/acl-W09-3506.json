{
  "info": {
    "authors": [
      "Jong-Hoon Oh",
      "Kiyotaka Uchimoto",
      "Kentaro Torisawa"
    ],
    "book": "Proceedings of the 2009 Named Entities Workshop: Shared Task on Transliteration (NEWS 2009)",
    "id": "acl-W09-3506",
    "title": "Machine Transliteration using Target-Language Grapheme and Phoneme: Multi-engine Transliteration Approach",
    "url": "https://aclweb.org/anthology/W09-3506",
    "year": 2009
  },
  "references": [],
  "sections": [
    {
      "text": [
        "Jong-Hoon Oh, Kiyotaka Uchimoto, and Kentaro Torisawa",
        "Language Infrastructure Group, MASTAR Project, National Institute of Information and Communications Technology (NICT) 3-5 Hikaridai Seika-cho, Soraku-gun, Kyoto 619-0289 Japan {rovellia,uchimoto,torisawa}@nict.go.jp",
        "This paper describes our approach to \"NEWS 2009 Machine Transliteration Shared Task.\"",
        "We built multiple transliteration engines based on different combinations of two transliteration models and three machine learning algorithms.",
        "Then, the outputs from these transliteration engines were combined using re-ranking functions.",
        "Our method was applied to all language pairs in \"NEWS 2009 Machine Transliteration Shared Task.\"",
        "The official results of our standard runs were ranked the best for four language pairs and the second best for three language pairs."
      ]
    },
    {
      "heading": "1. Outline",
      "text": [
        "This paper describes our approach to \"NEWS 2009 Machine Transliteration Shared Task.\"",
        "Our approach was based on two transliteration models - TM-G (Transliteration model based on target-language Graphemes) and TM-GP (Transliteration model based on target-language Graphemes and Phonemes).",
        "The difference between the two models lies in whether or not a machine transliteration process depends on target-language phonemes.",
        "TM-G directly converts source-language graphemes into target-language graphemes, while TM-GP first transforms source language graphemes into target-language phonemes and then target-language phonemes coupled with their corresponding source-language graphemes are converted into target-language graphemes.",
        "We used three different machine learning algorithms (conditional random fields (CRFs), margin infused relaxed algorithm (MIRA), and maximum entropy model (MEM)) (Berger et al., 1996; Crammer and Singer, 2003; Lafferty et al., 2001) for building multiple machine transliteration engines.",
        "We attempted to improve the transliteration quality by combining the outputs of different machine transliteration engines operating on the same input.",
        "Our approach was applied to all language pairs in \"NEWS 2009 Machine Transliteration Shared Task.\"",
        "The official results of our approach were ranked as the best for four language pairs and the second best for three language pairs (Li et al., 2009a)."
      ]
    },
    {
      "heading": "2. Transliteration Model",
      "text": [
        "Let S be a source-language word and T be a target-language transliteration of S. T is represented in two ways - TG, a sequence of target-language graphemes, and TP, a sequence of target-language phonemes.",
        "Here, a target-language grapheme is defined as a target-language character.",
        "We regard consonant and vowel parts in the romanized form of a target language grapheme as a target-language phoneme.",
        "Then TM-G and TM-GP are formulated as Eq (1) and (2), respectively.",
        "En",
        "S",
        "C",
        "l",
        "i",
        "n",
        "t",
        "o",
        "n",
        "Ch",
        "Tp",
        "KE",
        "L",
        "I",
        "N",
        "D",
        "U",
        "N",
        "To",
        "»■B",
        "»■I",
        "»■I",
        "«■B",
        "«■I",
        "«■I",
        "Ja",
        "Tp",
        "KU",
        "R",
        "I",
        "N",
        "T",
        "O",
        "N",
        "To",
        "U;B",
        "UI",
        ">B",
        "kB",
        "M",
        "1 '•' - 1 1",
        "C -\\",
        "C -s",
        "Clinton Clinton",
        "Clinton",
        "Clinton",
        "\\",
        "*",
        "KELINDUN",
        "KURINTON",
        "1",
        "1",
        "3£*« ?U>h> 1",
        "%»«",
        "Figure 1 illustrates the two transliteration models with examples, Clinton and its Chinese and Japanese transliterations.",
        "Target language graphemes are represented in terms ofthe BIO notation.",
        "This makes it easier to represent many-to-one correspondence between target language phoneme and grapheme."
      ]
    },
    {
      "heading": "3. Machine Learning Algorithms",
      "text": [
        "A machine transliteration problem can be converted into a sequential labeling problem, where each source-language grapheme is tagged with its corresponding target-language grapheme.",
        "This section briefly describes the machine learning algorithms used for building multiple transliteration engines.",
        "Machine transliteration based on the maximum entropy model was described in detail in Oh et al.",
        "(2006) along with comprehensive evaluation of its performance.",
        "We used the same way as that proposed by Oh et al.",
        "(2006), thus its full description is not presented here.",
        "CRFs, a statistical sequence modeling framework, was first introduced by Lafferty et al.",
        "(2001).",
        "CRFs has been used for sequential labeling problems such as text chunking and named entity recognition (McCallum and Li, 2003).",
        "CRF++was used in our experiment.",
        "The Margin Infused Relaxed Algorithm (MIRA) has been introduced by Crammer and Singer (2003) for large-margin multi-class classification.",
        "Kruengkrai et al.",
        "(2008) proposed a discriminative model for joint Chinese segmentation and POS tagging, where MIRA was used as their machine learning algorithm.",
        "We used the same model for our machine transliteration, exactly joint syllabi-cation and transliteration.",
        "We used the following features within the ±3 context window for the above mentioned three ma-",
        "grapheme corresponding to one target-language grapheme.",
        "The unit of context window is source-language grapheme or syllable.",
        "chine learning algorithms.",
        "• Left-three and right-three source-language graphemes (or syllables)",
        "• Left-three and right-three target-language phonemes",
        "• Target-language graphemes assigned to the previous three source-language graphemes (or syllables)"
      ]
    },
    {
      "heading": "4. Multi-engine Transliteration",
      "text": [
        "The main aim of the multi-engine transliteration approach is to combine the outputs ofmultiple engines so that the final output is better in quality than the output of each individual engine.",
        "We designed four transliteration engines using different combinations of source-language transliteration units, transliteration models, and machine learning algorithms as listed in Table 1.",
        "We named four transliteration engines as CRF-G, MEM-G, MEM-GP, and MIRA-G.",
        "Here, the prefixes represent applied machine learning algorithms (maximum entropy model (MEM), CRFs, and MIRA), while G and GP in the suffix represent the transliteration models, TM-G and TM-GP, respectively.",
        "Each individual engine produces 30-best transliterations for a given source-language word.",
        "We combined the outputs of multiple transliteration engines by means of a re-ranking function, g(x).",
        "Let X be a set of transliterations generated by multiple transliteration engines for source-language word s and ref be a reference transliteration of s. A re-ranking function is defined as Eq.",
        "(3), where it ranks ref in X higher and the others lower (Oh and Isahara, 2007).",
        "We designed two types of re-ranking functions by using the rank of each individual engine and machine learning algorithm.",
        "Source-language transliteration unit",
        "Grapheme",
        "Syllable",
        "TM-G",
        "ME-G, CRF-G",
        "MIRA-G",
        "TM-GP",
        "ME-GP",
        "N/A",
        "Two re-ranking functions based on the rank of each individual engine, grank and gFscore(x), are used for combining the outputs of multiple transliteration engines.",
        "Let X be a set of outputs of N transliteration engines for the same input.",
        "grank(x) re-ranks x £ X in the manner shown in Eq.",
        "(4), where Ranki(x) is the position of x in the n-best list generated by the ith transliteration engine.",
        "grank(x) can be interpreted as the average rank of x over outputs of each individual engine.",
        "If x is not in the n-best list of the ith transliteration",
        "{grank (x) ,gFscore (x)i Ranki(x)",
        " – 0.",
        "grank(xx) – ",
        "gFscore(x) is based on gmnk(x) and the F-score measure, which is one ofthe evaluation metrics in the \"NEWS 2009 Machine Transliteration the top three outputs of each individual engine as reference transliterations and defined them as virtual reference transliterations.",
        "We calculated the F-score measure between the virtual reference transliteration and each output ofmultiple transliteration engines.",
        "gFscore(x) is defined by Eq.",
        "(5), where VRef is a set of virtual reference transliterations, and Fscore(vr, x) is a function that restores the F-score measure between vr and x.",
        "gFscore (x) = grank(x) x MF(x)",
        "Fscore (vT, x)",
        "Since the F-score measure is calculated in terms of string similarity, x gets a high score from gMF (x) when it is orthographically similar to virtual reference transliterations.",
        "We used the maximum entropy model for learning re-ranking function gME(x).",
        "Let ref be a reference transliteration of source-language word s, feature(x) be a feature vector of x £ X, and y £{ref, wrong} be the training label for x. gME(x) assigns a probability to x £ X as shown in Eq.",
        "(6).",
        "gME(x) – P (ref \\feature(x)) A feature vector of x is composed of where Ran1k./x) and P (T \\S) of each individual engine are used as a feature.",
        "We estimated P(ref \\feature(x)) by using the development data."
      ]
    },
    {
      "heading": "5. Our Results",
      "text": [
        "Table 2 presents ACC of individual transliteration engines, which was applied to all language pairs in \"NEWS 2009 Machine Transliteration Shared Task\" (Li et al., 2004; Kumaran and Kellner, 2007; The CJK Dictionary Institute, 2009).",
        "CRF-G was the best transliteration engine in EnKa, EnKo, and EnRu.",
        "Owing to the high training costs of CRFs, we trained CRF-G in EnCh with a very small number of iterations.",
        "Hence, the performance of CRF-G was poorer than that of the other engines in EnCh.",
        "MEM-GP was the best transliteration engine in EnCh, EnHi, EnJa, and EnTa.",
        "These results indicate that joint use of source language graphemes and target language phonemes were very useful for improving performance.",
        "MIRA-G was sensitive to the training data size, because it was based on joint syllabication and transliteration.",
        "Therefore, the performance of MIRA-G was relatively better in EnCh and EnJa, whose training data size is bigger than other language pairs.",
        "CRF-G could not be applied to JnJk, mainly due to too long training time.",
        "Further, MEM-GP could not be applied to JnJk, because transliteration in JnJk can be regarded as conversion of target language phonemes to target language graphemes.",
        "MEM-G and MIRA-G were applied to JnJk and MIRA-G showed the best performance in JnJK.",
        "CRF-G",
        "MEM-G",
        "MEM-GP",
        "MIRA-G",
        "EnCh",
        "0.628",
        "0.686",
        "0.715",
        "0.684",
        "EnHi",
        "0.455",
        "0.469",
        "0.469",
        "0.412",
        "EnJa",
        "0.514",
        "0.517",
        "0.519",
        "0.490",
        "EnKa",
        "0.386",
        "0.380",
        "0.380",
        "0.338",
        "EnKo",
        "0.460",
        "0.438",
        "0.447",
        "0.367",
        "EnRu",
        "0.600",
        "0.561",
        "0.566",
        "0.568",
        "EnTa",
        "0.453",
        "0.459",
        "0.459",
        "0.412",
        "JnJk",
        "N/A",
        "0.532",
        "N/A",
        "0.571",
        "Table 3: Multi-engine transliteration results on the test data: the underlined figures are our official result",
        "Table 3 presents the ACC of our multi-engine transliteration approach and that of the best individual engine (I-Best) in each language pair.",
        "gME gave the best performance in EnCh, EnHi, EnJa, and EnKo, while gFscore did in EnCh, EnKa, EnRu, and EnTa.",
        "Comparison between the best individual transliteration engine and our multi-engine transliteration showed that grank and gME consistently showed better performance except in EnRu, while gFscore showed the poorer performance in EnKo.",
        "The results to be submitted as \"the standard run\" were selected among the results listed in Table 3 by using cross-validation on the development data.",
        "We submitted the results of gME as the standard run to \"NEWS 2009 Machine Transliteration Shared Task\" for the six language pairs in Table 3, while the result of gFscore is submitted as the standard run for EnRu.",
        "The official results of our standard runs were ranked the best for EnCh, EnJa, EnKa, and EnTa, and the second best for EnHi, EnKo, and EnRu (Li et al., 2009a)."
      ]
    },
    {
      "heading": "6. Conclusion",
      "text": [
        "In conclusion, we have applied multi-engine transliteration approach to \"NEWS 2009 Machine Transliteration Shared Task.\"",
        "We built multiple transliteration engines based on different combinations of transliteration models and machine learning algorithms.",
        "We showed that the transliteration model, which is based on target language graphemes and phonemes, and our multi-engine transliteration approach are effective, regardless of the nature of the language pairs.",
        "grank",
        "gFscore",
        "gME",
        "I-Best",
        "EnCh",
        "0.730",
        "0.731",
        "0.731",
        "0.715",
        "EnHi",
        "0.481",
        "0.475",
        "0.483",
        "0.469",
        "EnJa",
        "0.535",
        "0.535",
        "0.537",
        "0.519",
        "EnKa",
        "0.393",
        "0.399",
        "0.398",
        "0.386",
        "EnKo",
        "0.461",
        "0.444",
        "0.473",
        "0.460",
        "EnRu",
        "0.602",
        "0.605",
        "0.600",
        "0.600",
        "EnTa",
        "0.470",
        "0.478",
        "0.474",
        "0.459",
        "JnJk",
        "0.597",
        "0.593",
        "0.590",
        "0.571"
      ]
    }
  ]
}
