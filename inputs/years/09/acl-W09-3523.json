{
  "info": {
    "authors": [
      "Rejwanul Haque",
      "Sandipan Dandapat",
      "Ankit Kumar Srivastava",
      "Sudip Kumar Naskar",
      "Andy Way"
    ],
    "book": "Proceedings of the 2009 Named Entities Workshop: Shared Task on Transliteration (NEWS 2009)",
    "id": "acl-W09-3523",
    "title": "English-Hindi Transliteration Using Context-Informed PB-SMT: the DCU System for NEWS 2009",
    "url": "https://aclweb.org/anthology/W09-3523",
    "year": 2009
  },
  "references": [],
  "sections": [
    {
      "text": [
        "English – Hindi Transliteration Using Context-Informed PB-SMT: the DCU System for NEWS 2009",
        "Rejwanul Haque, Sandipan Dandapat, Ankit Kumar Srivastava, Sudip Kumar Naskar and Andy Way",
        "CNGL, School of Computing Dublin City University, Dublin 9, Ireland",
        "{rhaque,sdandapat,snaskar,asrivastava,away}@computing.dcu.ie",
        "This paper presents English – Hindi transliteration in the NEWS 2009 Machine Transliteration Shared Task adding source context modeling into state-of-the-art log-linear phrase-based statistical machine translation (PB-SMT).",
        "Source context features enable us to exploit source similarity in addition to target similarity, as modelled by the language model.",
        "We use a memory-based classification framework that enables efficient estimation of these features while avoiding data sparseness problems.We carried out experiments both at character and transliteration unit (TU) level.",
        "Position-dependent source context features produce significant improvements in terms of all evaluation metrics."
      ]
    },
    {
      "heading": "1. Introduction",
      "text": [
        "Machine Transliteration is of key importance in many cross-lingual natural language processing applications, such as information retrieval, question answering and machine translation (MT).",
        "There are numerous ways of performing automatic transliteration, such as noisy channel models (Knight and Graehl, 1998), joint source channel models (Li et al., 2004), decision-tree models (Kang and Choi, 2000) and statistical MT models (Matthews, 2007).",
        "For the shared task, we built our machine transliteration system based on phrase-based statistical MT (PB-SMT) (Koehn et al., 2003) using Moses (Koehn et al., 2007).",
        "We adapt PB-SMT models for transliteration by translating characters rather than words as in character-level translation systems (Lepage & Denoual, 2006).",
        "However, we go a step further from the basic PB-SMT model by using source-language context features (Stroppa et al., 2007).",
        "We also create translation models by constraining the character-level segmentations, i.e. treating a consonant-vowel cluster as one transliteration unit.",
        "The remainder of the paper is organized as follows.",
        "In section 2 we give a brief overview of PB-SMT.",
        "Section 3 describes how context-informed features are incorporated into state-of-art log-linear PB-SMT.",
        "Section 4 includes the results obtained, together with some analysis.",
        "Section 5 concludes the paper."
      ]
    },
    {
      "heading": "2. Log-Linear PB-SMT",
      "text": [
        "Translation is modelled in PB-SMT as a decision process, in which the translation = e1 .",
        ".",
        ".",
        "eI of where P( fJ | ) and P(e1) denote respectively the translation model and the target language model (Brown et al., 1993).",
        "In log-linear phrase-based SMT, the posterior probability",
        "P(| f1J) is directly modelled as a (log-linear) combination of features (Och and Ney, 2002), that usually comprise M translational features, and the language model, as in (2):",
        "fk = fbk ■■fjl (3)The translational features involved depend only on a pair of source/target phrases and do not take into account any context of these phrases.",
        "This means that each feature hm in (2) can be rewritten as in (4):",
        "where hm is a feature that applies to a single phrase-pair.",
        "Thus (2) can be rewritten as:",
        "where, h = Z ^mhm .",
        "In this context, the translation process amounts to: (i) choosing a segmentation of the source sentence, (ii) translating each source phrase."
      ]
    },
    {
      "heading": "3. Source Context Features in Log-Linear PB-SMT",
      "text": [
        "The context of a source phrase fk is defined as the sequence before and after a focus phrase fk= fi... fjt .",
        "Source context features (Stroppa et al., 2007) include the direct left and right context words (in our case, character/TU instead of word) of length I (resp.",
        "fh_v..f%tand fJt+v..fJt+,) of a given focus phrase fk = fit... fjt .",
        "A window of size 2/+1 features including the focus phrase is formed.",
        "Thus lexical contextual information (CI) can be described as in (6):",
        "As in (Haque et al., 2009), we considered a context window of ±1 and ±2 (i.e. l=1, 2) for our experiments.",
        "One natural way of expressing a context-informed feature is as the conditional probability of the target phrase given the source phrase and its context information, as in (7):",
        "into account, this estimation problem can only become worse.",
        "To avoid such problems, in this work we use three memory-based classifiers: IGTree, IB1 and TRIBL (Daelemans et al., 2005).",
        "When predicting a target phrase given a source phrase and its context, the source phrase is intuitively the feature with the highest prediction power; in all our experiments, it is the feature with the highest gain ratio (GR).",
        "In order to build the set of examples required to train the classifier, we modify the standard phrase-extraction method of (Koehn et al., 2003) to extract the context of the source phrases at the same time as the phrases themselves.",
        "Importantly, therefore, the context extraction comes at no extra cost.",
        "We refer interested readers to (Stroppa et al., 2007) and (Haque et al., 2009) as well as the references therein for more details of how Memory-Based Learning (MBL) is used for classification of source examples for use in the log-linear MT framework.",
        "We split named entities (NE) into characters.",
        "We break NEs into transliteration units (TU), which bear close resemblance to syllables.",
        "We split English NEs into TUs having C*V* pattern and Hindi NEs are divided into TUs having Ch+M pattern (M: Hindi Matra / vowel modifier, Ch: Characters other than Matras).",
        "We carry out experiments on both character-level (C-L) and TU-level (TU-L) data.",
        "We use a 5-gram language model for all our experiments.",
        "The Moses PB-SMT system serves as our baseline system.",
        "The distribution of target phrases given a source phrase and its contextual information is normalised to estimate P( êk\\fk, CI( fk )).",
        "Therefore our expected feature is derived as in (8):",
        "As (Stroppa et al., 2007) point out, directly estimating P( ek \\ fk , CI( fk )) using relative frequencies is problematic.",
        "Indeed, Zens and Ney (2004) showed that the estimation of P( ek | fk) using relative frequencies results in the overestimation of the probabilities of long phrases, so smoothing factors in the form of lexical-based features are often used to counteract this bias (Foster et al., 2006).",
        "In the case of context-informed features, since the context is also taken",
        "As for the standard phrase-based approach, their weights are optimized using Minimum Error Rate Training (MERT) of (Och, 2003) for each of the experiments.",
        "decoders such as Pharaoh (Koehn, 2004) or Moses (Koehn, 2007) rely on a static phrase-table represented as a list of aligned phrases accompanied with several features.",
        "Since these fea-",
        "l An implementation of IGTree, IBl and TRIBL is available in the TiMBL software package (http://ilk.uvt.nl/timbl).",
        "tures do not express the context in which those phrases occur, no context information is kept in the phrase-table, and there is no way to recover this information from the phrase-table.",
        "In order to take into account the context-informed features for use with such decoders, the devset and testset that need to be translated are pre-processed.",
        "Each token appearing in the testset and devset is assigned a unique id.",
        "First we prepare the phrase table using the training data.",
        "Then we generate all possible phrases from the devset and testset.",
        "These devset and testset phrases are then searched for in the phrase table, and if found, then the phrase along with its contextual information is given to MBL for classification.",
        "MBL produces class distributions according to the maximum-match of the features contained in the source phrase.",
        "We derive new scores from this class distribution and merge them with the initial information contained in the phrase table to take into account our feature functions (hmbl) in the log-linear model (2).",
        "In this way we create a dynamic phrase table containing both the standard and the context-informed features.",
        "The new phrase table contains the source phrase (represented by the sequence of ids of the words composing the phrase), target phrase and the new score.",
        "Similarly, replacing all the words by their ids in the development set, we perform MERT using our new phrase table to optimize the feature weights.",
        "We translate the test set (words represented by ids) using our new phrase table."
      ]
    },
    {
      "heading": "4. Results and Analysis",
      "text": [
        "We used 10,000 NEs from the NEWS 2009 English – Hindi training data (Kumaran and Kellner, 2007) for the standard submission, and the additional English – Hindi parallel person names data (105,905 distinct name pairs) of the Election Commission of India for the non-standard submissions.",
        "In addition to the baseline Moses system, we carried out three different set of experiments on IGTree, IB1 and TRIBL.",
        "Each of these experiments was carried out on both the standard data and the combined larger data, both at character level and the TU level, and considering ±1/±2 tokens as context.",
        "For each experiment, we produce the 10-best distinct hypotheses.",
        "The results are shown in Table 1.",
        "We observed that many of the (unseen) TUs in the testset remain untranslated in TU-L systems due to the problems of data sparseness.",
        "Whenever a TU-L system fails to translate a TU, we fallback on the corresponding CL system to translate the TU as a post-processing step.",
        "The accuracy of the TU-L baseline system (0.391) is much higher compared to the CL baseline system (0.290) on standard dataset.",
        "Furthermore, contextual modelling of the source language gives an accuracy of 0.416 and 0.399 for TU-L system and CL system respectively.",
        "Similar trends are observed in case of larger dataset.",
        "However, the highest accuracy (0.445) has been achieved with the TU-L system using the larger dataset."
      ]
    },
    {
      "heading": "5. Conclusion",
      "text": [
        "In this work, we employed source context modeling into the state-of-the-art log-linear PB-SMT for the English – Hindi transliteration task.",
        "We have shown that taking source context into account substantially improve the system performance (an improvement of 43.44% and 26.42% respectively for standard and larger datasets).",
        "IGTree performs best for TU-L systems while TRIBL seems to perform better for CL systems on both standard and non-standard datasets."
      ]
    },
    {
      "heading": "Acknowledgements",
      "text": [
        "We would like to thank Antal van den Bosch for his input on the use of memory based classifiers.",
        "We are grateful to SFI (http://www.sfi.ie) for generously sponsoring this research under grant 07/CE/I1142.",
        "S/B",
        "C/TU",
        "Context",
        "ACC",
        "M-F-Sc",
        "MRR",
        "MAP ref",
        "MAP 10",
        "MAPsys",
        "Baseline Moses",
        "S",
        "C",
        "0",
        ".290",
        ".814",
        ".393",
        ".286",
        ".131",
        ".131",
        "TU",
        "0",
        ".391",
        ".850",
        ".483",
        ".384",
        ".160",
        ".160",
        "B",
        "C",
        "0",
        ".352",
        ".830",
        ".463",
        ".346",
        ".156",
        ".156",
        "TU",
        "0",
        ".407",
        ".853",
        ".500",
        ".402",
        ".165",
        ".165",
        "IB1",
        "S",
        "C",
        "il",
        ".391",
        ".858",
        ".501",
        ".384",
        ".166",
        ".166",
        "i2",
        ".386",
        ".860",
        ".479",
        ".379",
        ".155",
        ".155",
        "TU",
        "il",
        ".406",
        ".858",
        ".466",
        ".398",
        ".178",
        ".178",
        "i2",
        ".359",
        ".838",
        ".402",
        ".349",
        ".165",
        ".165",
        "B",
        "C",
        "il",
        ".431",
        ".865",
        ".534",
        ".423",
        ".177",
        ".177",
        "i2 (NSD1)",
        ".42G",
        ".867",
        ".519",
        ".413",
        ".17G",
        ".17G",
        "TU",
        "il",
        ".437",
        ".863",
        ".507",
        ".429",
        ".191",
        ".191",
        "i2",
        ".427",
        ".862",
        ".487",
        ".418",
        ".194",
        ".194",
        "IGTree",
        "S",
        "C",
        "il",
        ".372",
        ".849",
        ".482",
        ".366",
        ".160",
        ".160",
        "i2",
        ".371",
        ".847",
        ".476",
        ".364",
        ".156",
        ".156",
        "TU",
        "il",
        ".412",
        ".859",
        ".486",
        ".404",
        ".164",
        ".164",
        "i2",
        ".416",
        ".860",
        ".493",
        ".409",
        ".166",
        ".166",
        "B",
        "C",
        "il",
        ".413",
        ".855",
        ".518",
        ".406",
        ".173",
        ".173",
        "i2 (NSD2)",
        ".4G7",
        ".856",
        ".5G7",
        ".399",
        ".168",
        ".168",
        "TU",
        "il",
        ".445",
        ".864",
        ".527",
        ".440",
        ".176",
        ".176",
        "i2",
        ".427",
        ".861",
        ".516",
        ".422",
        ".173",
        ".173",
        "TRIBL",
        "S",
        "C",
        "il",
        ".382",
        ".854",
        ".493",
        ".375",
        ".164",
        ".164",
        "i2 (SD)",
        ".399",
        ".863",
        ".488",
        ".392",
        ".157",
        ".157",
        "TU",
        "il",
        ".408",
        ".858",
        ".474",
        ".400",
        ".181",
        ".181",
        "i2",
        ".395",
        ".857",
        ".453",
        ".385",
        ".182",
        ".182",
        "B",
        "C",
        "il",
        ".439",
        ".866",
        ".543",
        ".430",
        ".179",
        ".179",
        "i2 (NSD3)",
        ".421",
        ".864",
        ".519",
        ".415",
        ".171",
        ".171",
        "TU",
        "il",
        ".444",
        ".863",
        ".512",
        ".436",
        ".193",
        ".193",
        "i2",
        ".439",
        ".865",
        ".497",
        ".430",
        ".197",
        ".197",
        "S*",
        "C",
        "i2 (NSD4)",
        ".419",
        ".868",
        ".464",
        ".419",
        ".338",
        ".338"
      ]
    }
  ]
}
