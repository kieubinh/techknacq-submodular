{
  "info": {
    "authors": [
      "Bill MacCartney",
      "Christopher D. Manning"
    ],
    "book": "Proceedings of the Eight International Conference on Computational Semantics",
    "id": "acl-W09-3714",
    "title": "An extended model of natural logic",
    "url": "https://aclweb.org/anthology/W09-3714",
    "year": 2009
  },
  "references": [],
  "sections": [
    {
      "text": [
        "Bill MacCartney and Christopher D. Manning",
        "Natural Language Processing Group, Stanford University",
        "We propose a model of natural language inference which identifies valid inferences by their lexical and syntactic features, without full semantic interpretation.",
        "We extend past work in natural logic, which has focused on semantic containment and monotonicity by incorporating both semantic exclusion and implicativity.",
        "Our model decomposes an inference problem into a sequence of atomic edits linking premise to hypothesis; predicts a lexical semantic relation for each edit; propagates these relations upward through a semantic composition tree according to properties of intermediate nodes; and joins the resulting semantic relations across the edit sequence.",
        "A computational implementation of the model achieves 70% accuracy and 89% precision on the PraCaS test suite.",
        "Moreover, including this model as a component in an existing system yields significant performance gains on the Recognizing Textual Entailment challenge."
      ]
    },
    {
      "heading": "1. Introduction",
      "text": [
        "Natural language inference (NLI) is the problem of determining whether a natural language hypothesis h can reasonably be inferred from a given premise p. For example:",
        "1) p~.",
        "Every firm polled saw costs grow more than expected, even after adjusting for inflation.",
        "A capacity for open-domain NLI is clearly necessary for full natural language understanding, and NLI can also enable more immediate applications, such as semantic search and question answering.",
        "Consequently, NLI has been the focus of intense research effort in recent years, centered around the annual Recognizing Textual Entailment (RTE) competition (6).",
        "For a semanticist, the most obvious approach to NLI relies on full semantic interpretation: first, translate p and h into some formal meaning representation, such as first-order logic (FOL), and then apply automated",
        "fl'.",
        "Every big company in the poll reported cost increases.",
        "reasoning tools to determine inferential validity.",
        "While the formal approach can succeed in restricted domains, it struggles with open-domain NLI tasks such as RTE.",
        "For example, the FOL-based system of (1) was able to find a proof for less than 4% of the problems in the RTE1 test set.",
        "The difficulty is plain: truly natural language is fiendishly complex.",
        "The formal approach faces countless thorny problems: idioms, ellipsis, paraphrase, ambiguity, vagueness, lexical semantics, the impact of pragmatics, and so on.",
        "Consider for a moment the difficulty of fully and accurately translating (1) to a formal meaning representation.",
        "Yet (1) also demonstrates that full semantic interpretation is often not necessary to determining inferential validity.",
        "To date, the most successful NLI systems have relied on surface representations and approximate measures of lexical and syntactic similarity to ascertain whether p subsumes h (9, 13, 10).",
        "However, these approaches face a different problem: they lack the precision needed to properly handle such commonplace phenomena as negation, antonymy, downward-monotone quantifiers, non-factive contexts, and the like.",
        "For example, if every were replaced by some or most throughout (1), the lexical and syntactic similarity of h to p would be unaffected, yet the inference would be rendered invalid.",
        "In this paper, we explore a middle way, by developing a model of what (11) called natural logic, which characterizes valid patterns of inference in terms of syntactic forms which are as close as possible to surface forms.",
        "For example, the natural logic approach might sanction (1) by observing that: in ordinary upward monotone contexts, deleting modifiers preserves truth; in downward monotone contexts, inserting modifiers preserves truth; and every is downward monotone in its restrictor NP.",
        "Natural logic thus achieves the semantic precision needed to handle inferences like (1), while sidestepping the difficulties of full semantic interpretation.",
        "The natural logic approach has a very long history, originating in the syllogisms of Aristotle and continuing through the medieval scholastics and the work of Leibniz.",
        "It was revived in recent times by (19, 20) and (17), whose monotonicity calculus explains inferences involving semantic containment and inversions of monotonicity, even when nested, as in Nobody can enter without a valid passport \\= Nobody can enter without a passport.",
        "However, because the monotonicity calculus lacks any representation of semantic exclusion, it fails to license many simple inferences, such as Stimpy is a cat |= Stimpy is not a poodle.",
        "Another model which arguably belongs to the natural logic tradition (though not presented as such) was developed by (15) to explain inferences involving implicatives and factives, even when negated or nested, as in Ed did not forget to force Dave to leave \\= Dave left.",
        "While the model bears some resemblance to the monotonicity calculus, it does not incorporate semantic containment or explain interactions between implicatives and monotonicity, and thus fails to license inferences such as John refused to dance \\= John didn't tango.",
        "In this paper, we propose a new model of natural logic which extends the monotonicity calculus to incorporate semantic exclusion, and partly unifies it with Nairn et al.",
        "'s account of implicatives.",
        "We first define an inventory of basic semantic relations which includes representations of both containment and exclusion (section 2).",
        "We then describe a general method for establishing the semantic relation between a premise p and a hypothesis h. Given a sequence of atomic edits which transforms p into h, we determine the lexical semantic relation generated by each edit (section 4); project each lexical semantic relation into an atomic semantic relation, according to properties of the context in which the edit occurs (section 5); and join atomic semantic relations across the edit sequence (section 3).",
        "We have previously presented an implemented system based on this model (14); here we offer a detailed account of its theoretical foundations."
      ]
    },
    {
      "heading": "2. An inventory of semantic relations",
      "text": [
        "The simplest formulation of the NLI task IS cLS cl binary decision problem: the relation between p and h is to be classified as either entailment (p |= h) or non-entailment (p ^= h).",
        "The three-way formulation refines this by dividing non-entailment into contradiction (p \\= -ih) and compatibility (p y= h Ap y= -i/z,).",
        "The monotonicity calculus carves things up differently: it interprets entailment as a semantic containment relation C analogous to the set containment relation C, and thus permits us to distinguish forward entailment (p C h) from reverse entailment (p □ h).",
        "Moreover, it defines C for expressions of every semantic type, including not only complete sentences but also individual words and phrases.",
        "Unlike the three-way formulation, however, it lacks any way to represent contradiction (semantic exclusion).",
        "For our model, we want the best of both worlds: a comprehensive inventory of semantic relations that includes representations of both semantic containment and semantic exclusion.",
        "Following Sanchez Valencia, we proceed by analogy with set relations.",
        "In a universe U, the set of ordered pairs (x, y) of subsets of U can be partitioned into 16 equivalence classes, according to whether each of the four sets x n y, xdy, xdy, and x D y is empty or non-empty.",
        "Of these 16 classes, nine represent degenerate cases in which either x or y is either empty or universal.",
        "Since expressions having empty denotations (e.g., round square cupola) or universal denotations (e.g., exists) fail to divide the world into meaningful categories, they can be regarded as semantically vacuous.",
        "Contradictions and tautologies may be common in logic textbooks, but they are rare in everyday speech.",
        "Thus, in a practical model of informal natural language inference, we will rarely go wrong by assuming the non-vacuity of the expressions we encounter.",
        "We therefore focus on the remaining seven classes, which we designate as the set 53 of basic semantic relations.",
        "symbol name example set theoretic definition x = y equivalence couch = sofa x = y x n. y forward entailment crow [Z bird x C y x □ y reverse entailment European HI French 1d9 x A y negation human A nonhuman xr\\y = $AxUy=U X ^ y cover animal ^ nonhuman xnt/^|AxUt/ = (/ x # y independence hungry ^ hippo (all other cases)",
        "First, the semantic containment relations (C and □) of the monotonicity calculus are preserved, but are factored into three mutually exclusive relations: equivalence (=), (strict) forward entailment (c), and (strict) reverse entailment (□).",
        "Next, we have two relations expressing semantic exclusion: negation (A), or exhaustive exclusion, which is analogous to set complement; and alternation (|), or non-exhaustive exclusion.",
        "The next relation is cover (^), or non-exclusive exhaustion.",
        "Though its utility is not immediately obvious, it is the dual under negation of the alternation relation.",
        "Finally, the independence relation (#) covers all other cases: it expresses non-equivalence, non-containment, non-exclusion, and non-exhaustion.",
        "Note that # is the least informative relation, in that it places the fewest constraints on its arguments.",
        "Following Sanchez Valencia, we define the relations in 53 for all semantic types.",
        "For semantic types which can be interpreted as characteristic functions of sets, the set-theoretic definitions can be applied directly.",
        "The definitions can then be extended to other types by interpreting each type as if it were a type of set.",
        "For example, propositions can be understood (per Montague) as denoting sets of possible worlds.",
        "Thus two propositions stand in the | relation iff there is no world where both hold (but there is some world where neither holds).",
        "Likewise, names can be interpreted as denoting singleton sets, with the result that two names stand in the = relation iff they refer to the same entity, or the | relation otherwise.",
        "By design, the relations in 53 are mutually exclusive, so that we can define a function f3(x, y) which maps every ordered pair of expressions to the unique relation in 53 to which it belongs."
      ]
    },
    {
      "heading": "3. Joining semantic relations",
      "text": [
        "If we know that semantic relation R holds between x and y, and that semantic relation S holds between y and z, then what is the semantic relation between x and zl The join of semantic relations R and S, which we denote",
        "Some joins are quite intuitive.",
        "For example, it is immediately clear that cmc = c, □md = D, ama = e, and for any R, (R x =) = (= m R) = R. Other joins are less obvious, but still accessible to intuition.",
        "For example, | m A = c This can be seen with the aid of Venn diagrams, or by considering simple examples: fish \\ human and human A nonhuman, thus fish rz nonhuman.",
        "But we soon stumble upon an inconvenient truth: not every join yields a relation in 53.",
        "For example, if x \\ y and y \\ z, the relation between x and z is not determined.",
        "They could be equivalent, or one might contain the other.",
        "They might be independent or alternative.",
        "All we can say for sure is that they are not exhaustive (since both are disjoint from y).",
        "Thus, the result of joining | and | is not a relation in 53, but a union of such relations, specifically \\J{=, c, |, #}.",
        "We will refer to (non-trivial) unions of relations in 53 as union relations.Of the 49 possible joins of relations in 53, 32 yield a relation in 53, while 17 yield a union relation, with larger unions conveying less information.",
        "Union relations can be further joined, and we can establish that the smallest set of relations which contains 53 and is closed under joining contains just 16 relations.",
        "One of these is the total relation, which contains all pairs of (non-vacuous) expressions.",
        "This relation, which we denote •, is the black hole of semantic relations, in the sense that (a) it conveys zero information about pairs of expressions which belong to it, and (b) joining a chain of semantic relations will, if it contains any noise and is of sufficient length,",
        "nIn Tarskian relation algebra, this operation is known as relation composition, and is often represented by a semi-colon: R; S. To avoid confusion with semantic composition (section 5), we prefer to use the term join for this operation, by analogy to the database JOIN operation (also commonly represented by m).",
        "LKM}, andUU-,#}.",
        "lead inescapably to •.",
        "This tendency of joining to devolve toward less-informative semantic relations places an important limitation on the power of the inference method described in section 7.",
        "A complete join table for relations in 53 is shown below:",
        "In an implemented model, the complexity introduced by union relations is easily tamed.",
        "Every union relation which results from joining relations in 53 contains and thus can safely be approximated by After all, # is already the least informative relation in 53 – loosely speaking, it indicates ignorance of the relationship between two expressions – and further joining will never serve to strengthen it.",
        "Our implemented model therefore has no need to represent union relations."
      ]
    },
    {
      "heading": "4. Lexical semantic relations",
      "text": [
        "Suppose X is cl compound linguistic expression, and let e(x) be the result of applying an atomic edit e (the deletion, insertion, or substitution of a subexpression) to x.",
        "The semantic relation f3(x, e(x)) will depend on (1) the lexical semantic relation generated by e, which we label /3(e), and (2) other properties of the context x in which e is applied (to be discussed in section 5).",
        "For example, suppose x is red car.",
        "If e is sub(car, convertible), then /3(e) is □ (because convertible is a hyponym of car).",
        "On the other hand, if e is del(red), then /3(e) is rz (because red is an intersective modifier).",
        "Crucially, /3(e) depends solely on the lexical items involved in e, independent of context.",
        "How are lexical semantic relations determined?",
        "Ultimately, this is the province of lexical semantics, which lies outside the scope of this work.",
        "However, the answers are fairly intuitive in most cases, and we can make a number of useful observations.",
        "M",
        "=",
        "c",
        "□",
        "A",
        "1",
        "#",
        "=",
        "=",
        "c",
        "□",
        "A",
        "1",
        "#",
        "c",
        "1",
        "1",
        "□",
        "□",
        "□",
        "□Al-#",
        "A",
        "A",
        "1",
        "=",
        "□",
        "#",
        "1",
        "1",
        "1",
        "=c=i|#",
        "c",
        "□Al-#",
        "□",
        "□",
        "#",
        "#",
        "□l#",
        "#",
        "•",
        "Substitutions.",
        "The semantic relation generated by a substitution edit is simply the relation between the substituted terms: /3(svB(x,y)) = [3(x,y).",
        "For open-class terms such as nouns, adjectives, and verbs, we can often determine the appropriate relation by consulting a lexical resource such as WordNet.",
        "Synonyms belong to the = relation (sofa = couch, forbid = prohibit); hyponym-hypernym pairs belong to the rz relation (crow rz bird, frigid C cold, soar rz rise); and antonyms and coordinate terms generally belong to the | relation (hot \\ cold, cat \\ dog).",
        "Proper nouns, which denote individual entities or events, will stand in the = relation if they denote the same entity (USA = United States), or the | relation otherwise (JFK \\ FDR).",
        "Pairs which cannot reliably be assigned to another semantic relation will be assigned to the # relation (hungry # hippo).",
        "Of course, there are many difficult cases, where the most appropriate relation will depend on subjective judgments about word sense, topical context, and so on – consider, for example, the pair system and approach.",
        "And some judgments may depend on world knowledge not readily available to an automatic system.",
        "For example, plausibly skiing \\ sleeping, but skiing # talking.",
        "Closed-class terms may require special handling.",
        "Substitutions involving generalized quantifiers generate a rich variety of semantic relations: all = every, every rz some, some A no, no \\ every, at least four ^ at most six, and most # ten or more.",
        "Two pronouns, or a pronoun and a noun, should ideally be assigned to the = relation if it can determined from context that they refer to the same entity, though this may be difficult for an automatic system to establish reliably.",
        "Prepositions are somewhat problematic.",
        "Some pairs of prepositions can be interpreted as antonyms, and thus assigned to the | relation (above \\ below), but many prepositions are used so flexibly in natural language that they are best assigned to the = relation (on [a plane] = in [a plane] = by [plane]).",
        "Generic deletions and insertions.",
        "For deletion edits, the default behavior is to generate the rz relation (thus red car rz car).",
        "Insertion edits are symmetric: by default, they generate the □ relation (sing □ sing off-key).",
        "This heuristic can safely be applied whenever the affected phrase is an in-tersective modifier, and can usefully be applied to phrases much longer than a single word (car which has been parked outside since last week rz car).",
        "Indeed, this principle underlies most current approaches the RTE task, in which the premise p often contains much extraneous content not found in the hypothesis h. Most RTE systems try to determine whether p subsumes h: they penalize new content inserted into h, but do not penalize content deleted from p.",
        "Special deletions and insertions.",
        "However, some lexical items exhibit special behavior upon deletion or insertion.",
        "The most obvious example is negation, which generates the A relation (didn't sleep A did sleep).",
        "Indicatives and factives (such as refuse to and admit that) constitute another important class of exceptions, but we postpone discussion of them to section 6.",
        "Then there are non-intersective adjectives such as former and alleged.",
        "These have various behavior: deleting former seems to generate the | relation (former student \\ student), while deleting alleged seems to generate the # relation (alleged spy # spy).",
        "We lack a complete typology of such cases, but consider this an interesting problem for lexical semantics.",
        "Finally, for pragmatic reasons, we typically assume that auxiliary verbs and punctuation marks are semantically vacuous, and thus generate the = relation upon deletion or insertion.",
        "When combined with the assumption that morphology matters little in inference, this allows us to establish, e.g., that is sleeping = sleeps and did sleep = slept."
      ]
    },
    {
      "heading": "5. Semantic relations and semantic composition",
      "text": [
        "How are semantic relations affected by semantic composition?",
        "In other words, how do the semantic relations between compound expressions depend on the semantic relations between their parts?",
        "Say we have established the value of [3(x,y), and let / be an expression which can take x or y as an argument.",
        "What is the value of l3(f(x),f(y)), and how does it depend on the properties of /?",
        "The monotonicity calculus of Sanchez Valencia provides a partial answer.",
        "It explains the impact of semantic composition on semantic relations =,□,□, and # by assigning semantic functions to one of three monotonicity classes: up, down, and non.",
        "If / has monotonicity up (the default), then the semantic relation between x and y is projected through / without change: l3(f(x),f(y)) = [3(x,y).",
        "Thus some parrots talk rz some birds talk.",
        "If / has monotonicity down, then rz and □ are swapped.",
        "Thus no carp talk □ no fish talk.",
        "Finally, if / has monotonicity non, then rz and □ are projected as Thus most humans talk # most animals talk.",
        "The monotonicity calculus also provides an algorithm for computing the effect on semantic relations of multiple levels of semantic composition.",
        "Although Sanchez Valencia's presentation of this algorithm uses a complex scheme for annotating nodes in a categorial grammar parse, the central idea can be recast in simple terms: propagate a lexical semantic relation upward through a semantic composition tree, from leaf to root, while respecting the monotonicity properties of each node along the path.",
        "Consider the sentence Nobody can enter without pants.",
        "A plausible semantic composition tree for this sentence could be rendered as (nobody (can ((without pants) enter))).",
        "Now consider replacing pants with clothes.",
        "We begin with the lexical semantic relation: pants rz clothes.",
        "The semantic function without has monotonicity down, so without pants □ without clothes.",
        "Continuing up the semantic composition tree, can has monotonicity up, but nobody has monotonicity down, so we get another reversal, and find that nobody can enter without pants rz nobody can enter without clothes.",
        "While the monotonicity calculus elegantly explains the impact of semantic composition on the containment relations (chiefly, rz and □), it lacks any account of the exclusion relations (A and |, and, indirectly, ^).",
        "To remedy this lack, we propose to generalize the concept of monotonicity to a concept of projectivity.",
        "We categorize semantic functions into a number of projectivity signatures, which can be seen as generalizations of both the three monotonicity classes of Sanchez Valencia and the nine implication signatures of Nairn et al.",
        "(see section 6).",
        "Each projectivity signature is defined by a map 53 i – > 53 which specifies how each semantic relation is projected by the function.",
        "(Binary functions can have different signatures for each argument.)",
        "In principle, there are up to 7 possible signatures; in practice, probably no more than a handful are realized by natural language expressions.",
        "Though we lack a complete inventory of projectivity signatures, we can describe a few important cases.",
        "Negation.",
        "We begin with simple negation (not).",
        "Like most functions, it projects = and # without change (not happy = not glad and isn't swimming # isn't hungry).",
        "As a downward monotone function, it swaps rz and □ (didn't kiss □ didn't touch).",
        "But we can also establish that it projects Awithout change (not human A not nonhuman) and swaps | and ^ (not French ^ not German and not more than 4 I not less than 6).",
        "Its projectivity signature is therefore {=:=, A : A, | :^, ^: |, #:#}.",
        "Intersective modification.",
        "Intersective modification has monotonicity up, but projects both A and | as | (living human \\ living nonhuman and French wine \\ Spanish wine), and projects ^ as # (metallic pipe # nonfer-rous pipe).",
        "It therefore has signature {=:=, A : |, | : |, ^:#, #:#}.",
        "Quantifiers.",
        "While semanticists are well acquainted with the monotonicity properties of common quantifiers, how they project the exclusion relations may be less familiar.",
        "The following table summarizes the projectivity signatures of the most common binary generalized quantifiers for each argument position:",
        "projectivity for 1st argument projectivity for 2nd argument",
        "A few observations:",
        "• All quantifiers (like most other semantic functions) project = and # without change.",
        "• The table confirms well-known monotonicity properties: no is downward-monotone in both arguments, every in its first argument, and not every in its second argument.",
        "• Relation | is frequently \"blocked\" by quantifiers (i.e., projected as #).",
        "Thus no fish talk # no birds talk and someone was early # someone was late.",
        "A notable exception is every in its second argument, where | is preserved: everyone was early \\ everyone was late.",
        "(Note the similarity to intersective modification.)",
        "• Because no is the negation of some, its projectivity signature can be found by projecting the signature of some through the signature of not.",
        "Likewise for not every and every.",
        "• Some results depend on assuming the non-vacuity of the other argument to the quantifier: those marked with 1 assume it to be non-empty, while those marked with $ assume it to be non-universal.",
        "Without these assumptions, # is projected.",
        "quantifier",
        "= rz",
        "□",
        "a",
        "|",
        "#",
        "= rz",
        "□",
        "a",
        "|",
        "some",
        "= rz",
        "□",
        "#",
        "= rz",
        "□",
        "no",
        "= □",
        "rz",
        "| t",
        "| t",
        "#",
        "= □",
        "rz",
        "| t",
        "| t",
        "every",
        "= □",
        "rz",
        "| t",
        "| t",
        "#",
        "= rz",
        "□",
        "| t",
        "| t",
        "not every",
        "= rz",
        "□",
        "#",
        "= □",
        "rz",
        "Verbs.",
        "Verbs (and verb-like constructions) exhibit diverse behavior.",
        "Most verbs are upward-monotone (though not all – see section 6), and many verbs project A, |, and ^ as # (eats humans # eats nonhumans, eats cats # eats dogs, and eats mammals # eats nonhumans).",
        "However, verbs which encode functional relations seem to exhibit the same projectivity as intersective modifiers, projecting A and | as |, and ^ as #.",
        "Categorizing verbs according to projectivity is an interesting problem for lexical semantics, which may involve codifying some amount of world knowledge."
      ]
    },
    {
      "heading": "6. Implicatives and factives",
      "text": [
        "(15) offer an elegant account of inferences involving implicatives and factives such as manage to, refuse to, and admit that.",
        "Their model classifies such operators into nine implication signatures, according to their implications – positive (+), negative (-), or null (o) – in both positive and negative contexts.",
        "Thus refuse to has implication signature -/o, because it carries a negative implication in a positive context (refused to dance implies didn't dance), and no implication in a negative context (didn't refuse to dance implies neither danced nor didn't dance).",
        "Most of the phenomena observed by Nairn et al.",
        "can be explained within our framework by specifying, for each implication signature, the relation generated when an operator of that signature is deleted from (or inserted into) a compound expression, as shown in the following table:",
        "This table invites several observations.",
        "First, as the examples make clear, there is room for variation regarding the appearance of infinitive arguments, complementizers, passivization, and morphology.",
        "An implemented model must tolerate such diversity.",
        "implicatives",
        "+/-",
        "=",
        "=",
        "he managed to escape = he escaped",
        "(UP)",
        "+/°",
        "rz",
        "□",
        "he was forced to sell C he sold",
        "°/-",
        "□",
        "rz",
        "he was permitted to live □ he lived",
        "implicatives",
        "-/+",
        "a",
        "a",
        "he forgot to pay A he paid",
        "(down)",
        "-/°",
        "|",
        "|",
        "he refused to fight \\ he fought",
        "°/+",
        "he hesitated to ask ^ he asked",
        "factives",
        "+/+",
        "rz",
        "□",
        "he admitted that he knew C he knew",
        "(non)",
        "-/-",
        "|",
        "|",
        "he pretended he was sick \\ he was sick",
        "o / o",
        "#",
        "he wanted to fly # he flew",
        "Second, some of the examples may seem more intuitive when one considers their negations.",
        "For example, deleting signature o/- generates under negation, this is projected as rz (he wasn't permitted to live rz he didn't live).",
        "Likewise, deleting signature o/+ generates ^; under negation, this is projected as | (he didn't hesitate to ask \\ he didn't ask).",
        "Third, a fully satisfactory treatment of the factives (signatures +/+, -/-, and o/o) would require an extension to our present theory.",
        "For example, deleting signature +/+ generates IZ; yet under negation, this is projected not as □, but as | (he didn't admit that he knew \\ he didn't know).",
        "The problem arises because the implication carried by a factive is not an entailment, but a presupposition.",
        "As is well known, the projection behavior of presuppositions differs from that of entailments (22).",
        "It seems likely that our model could be elaborated to account for projection of presuppositions as well as entailments, but we leave this for future work.",
        "We can further cement implicatives and factives within our model by specifying the monotonicity class for each implication signature: signatures +/-, +/o, and o/- have monotonicity up (force to tango rz force to dance); signatures -/+, -/o, and o/+ have monotonicity down (refuse to tango □ refuse to dance); and signatures +/+, -/-, and o/o (the propositional attitudes) have monotonicity non (think tangoing is fun # think dancing is fun).",
        "We are not yet able to specify the complete projectivity signature corresponding to each implication signature, but we can describe a few specific cases.",
        "For example, implication signature -/o seems to project A as | (refuse to stay | refuse to go) and both | and ^ as # (refuse to tango # refuse to waltz)."
      ]
    },
    {
      "heading": "7. Putting it all together",
      "text": [
        "We now have the building blocks of a general method to establish the semantic relation between a premise p and a hypothesis h. The steps are as follows:",
        "1.",
        "Find a sequence of atomic edits (ei,... ,en) which transforms p into h: thus h = (en o ... o e\\)(p).",
        "For convenience, let us define xq = p, xn = h, and Xi = ei(xi-\\) for i e [l,n].",
        "2.",
        "For each atomic edit ef.",
        "(a) Determine the lexical semantic relation /?",
        "(ej), as in section 4.",
        "(b) Project /?",
        "(ej) upward through the semantic composition tree of expression x%-\\ to find an atomic semantic relation [3(xi-\\,ei) = f3(xi-i,Xi), as in section 5.",
        "3.",
        "Join atomic semantic relations across the sequence of edits, as in section 3:",
        "However, this inference method has several important limitations, including the need to find an appropriate edit sequence connecting p and h;2Athe tendency of the join operation toward less informative semantic relations, as described in section 3; and the lack of a general mechanism for combining information from multiple premises.",
        "Consequently, the method has less deductive power than first-order logic, and fails to sanction some fairly simple inferences, including de Morgan's laws for quantifiers.",
        "But the method neatly explains many inferences not handled by the monotonicity calculus, including this example from section 1:"
      ]
    },
    {
      "heading": "0. Stimpy is a cat",
      "text": []
    },
    {
      "heading": "2. Stimpy is not a dog INS(not) a a q",
      "text": []
    },
    {
      "heading": "3. Stimpy is not a poodle SVB(dog, poodle) Z] IZ FZ",
      "text": [
        "Here, xq is transformed into xs by a sequence of three edits.",
        "First, replacing cat with its coordinate term dog generates |.",
        "Next, inserting not generates A, and | joined with A yields rz.",
        "Finally, replacing dog with its hyponym poodle generates □.",
        "Because of the downward-monotone context created by not, this is projected as rz, and rz joined with rz yields rz.",
        "Therefore, xo entails xs.",
        "For an example involving an implicative, consider:",
        "2BHowever, some inferences can be enabled by auxiliary premises encoded as lexical semantic relations.",
        "For example, men c mortal can enable the classic syllogism Socrates is a man c Socrates is mortal.",
        "VKe were not permitted to smoke",
        "VKe did not smoke",
        "We smoked Cuban cigars We smoked DEh(perm,itted to) DEL(ncrf) lNS(Cuban cigars)",
        "Again, xq is transformed into X3 by a sequence of three edits.",
        "First, deleting permitted to generates □, according to its implication signature; but because not is downward-monotone, this is projected as rz.",
        "Next, deleting not generates A, and rz joined with A yields |.",
        "Finally, inserting Cuban cigars restricts the meaning of smoked, generating □, and | joined with □ yields |.",
        "So xs contradicts xq.",
        "A more complex example is presented in (14)."
      ]
    },
    {
      "heading": "8. Implementation and evaluation",
      "text": [
        "The model of natural logic described here has been implemented in software as the NatLog system.",
        "In previous work (14), we have presented a description and evaluation of NatLog; this section summarizes the main results.",
        "Natlog faces three primary challenges:",
        "1.",
        "Finding an appropriate sequence of atomic edits connecting premise and hypothesis.",
        "NatLog does not address this problem directly, but relies instead on edit sequences from other sources.",
        "We have investigated this problem separately in (12).",
        "2.",
        "Determining the lexical semantic relation for each edit.",
        "NatLog learns to predict lexical semantic relations by using machine learning techniques and exploiting a variety of manually and automatically constructed sources of information on lexical relations.",
        "3.",
        "Computing the projection of each lexical semantic relation.",
        "NatLog identifies expressions with non-default projectivity and computes the likely extent of their arguments in a syntactic parse using hand-crafted tree patterns.",
        "We have evaluated NatLog on two different test suites.",
        "The first is the FraCaS test suite (5), which contains 346 NLI problems, divided into nine sections, each focused on a specific category of semantic phenomena.",
        "The goal is three-way entailment classification, as described in section 2.",
        "On this task, NatLog achieves an average accuracy of 70%.",
        "In the section concerning quantifiers, which is both the largest and the most amenable to natural logic, the system answers all problems but one correctly.",
        "Unsurprisingly, performance is mediocre in four sections concerning semantic phenomena (e.g., ellipsis) not relevant to natural logic and not modeled by the system.",
        "But in the other five sections (representing about 60% of the problems), NatLog achieves accuracy of 87%.",
        "What's more, precision is uniformly high, averaging 89% over all sections.",
        "Thus, even outside its areas of expertise, the system rarely predicts entailment when none exists.",
        "The RTE3 test suite (8) differs from FraCaS in several important ways: the goal is binary entailment classification; the problems have much longer premises and are more \"natural\"; and the problems employ a diversity of types of inference – including paraphrase, temporal reasoning, and relation extraction – which NatLog is not designed to address.",
        "Consequently, the NatLog system by itself achieves mediocre accuracy (59%) on RTE3 problems.",
        "However, its precision is comparatively high, which suggests a strategy of hybridizing with a broad-coverage RTE system.",
        "We were able to show that adding NatLog as a component in the Stanford RTE system (3) led to accuracy gains of 4%."
      ]
    },
    {
      "heading": "9. Conclusion",
      "text": [
        "The model of natural logic presented here is by no means a universal solution to the problem of natural language inference.",
        "Many NLI problems hinge on types of inference not addressed by natural logic, and the inference method we describe faces a number of limitations on its deductive power (discussed in section 7).",
        "Moreover, there is further work to be done in fleshing out our account, particularly in establishing the proper projectivity signatures for a broader range of quantifiers, verbal constructs, implicatives and factives, logical connectives, and other semantic functions.",
        "Nevertheless, we believe our model of natural logic fills an important niche.",
        "While approximate methods based on lexical and syntactic similarity can handle many NLI problems, they are easily confounded by inferences involving negation, antonymy, quantifiers, implicatives, and many other phenomena.",
        "Our model achieves the logical precision needed to handle such inferences without resorting to full semantic interpretation, which is in any case rarely possible.",
        "The practical value of the model is demonstrated by its success in evaluations on the FraCaS and RTE3 test suites."
      ]
    }
  ]
}
