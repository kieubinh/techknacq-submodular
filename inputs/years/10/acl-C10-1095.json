{
  "info": {
    "authors": [
      "Jong-Hoon Oh",
      "Ichiro Yamada",
      "Kentaro Torisawa",
      "Stijn De Saeger"
    ],
    "book": "COLING",
    "id": "acl-C10-1095",
    "title": "Co-STAR: A Co-training Style Algorithm for Hyponymy Relation Acquisition from Structured and Unstructured Text",
    "url": "https://aclweb.org/anthology/C10-1095",
    "year": 2010
  },
  "references": [
    "acl-C04-1135",
    "acl-C92-2082",
    "acl-D07-1073",
    "acl-D08-1061",
    "acl-D09-1025",
    "acl-D09-1098",
    "acl-I08-1025",
    "acl-I08-2126",
    "acl-N04-1041",
    "acl-P06-1101",
    "acl-P08-1047",
    "acl-P09-1049"
  ],
  "sections": [
    {
      "text": [
        "Jong-Hoon Oh, Ichiro Yamada, Kentaro Torisawa, and Stijn De Saeger",
        "Language Infrastructure Group, MASTAR Project, National Institute of Information and Communications Technology (NICT)",
        "{rovellia,iyamada,torisawa,stijn}@nict.go.jp",
        "This paper proposes a co-training style algorithm called Co-STAR that acquires hyponymy relations simultaneously from structured and unstructured text.",
        "In Co-STAR, two independent processes for hy-ponymy relation acquisition - one handling structured text and the other handling unstructured text - collaborate by repeatedly exchanging the knowledge they acquired about hyponymy relations.",
        "Unlike conventional co-training, the two processes in Co-STAR are applied to different source texts and training data.",
        "We show the effectiveness of this algorithm through experiments on large-scale hyponymy-relation acquisition from Japanese Wikipedia and Web texts.",
        "We also show that Co-STAR is robust against noisy training data."
      ]
    },
    {
      "heading": "1. Introduction",
      "text": [
        "Acquiring semantic knowledge, especially semantic relations between lexical terms, is regarded as a crucial step in developing high-level natural language applications.",
        "This paper proposes Co-STAR (a Co-training STyle Algorithm for hyponymy Relation acquisition from structured and unstructured text).",
        "Similar to co-training (Blum and Mitchell, 1998), two hy-ponymy relation extractors in Co-STAR, one for structured and the other for unstructured text, iteratively collaborate to boost each other's performance.",
        "Many algorithms have been developed to automatically acquire semantic relations from structured and unstructured text.",
        "Because term pairs are encoded in structured and unstructured text in different styles, different kinds of evidence have been used for semantic relation acquisition:",
        "Evidence from structured text: topic hierarchy, layout structure of documents, and HTML tags (Oh et al., 2009; Ravi and Paşca, 2008; Sumida and Torisawa, 2008; Shinzato and Torisawa, 2004).",
        "Recently, researchers have used both structured and unstructured text for semantic-relation acquisition, with the aim of exploiting such different kinds of evidence at the same time.",
        "They either tried to improve semantic relation acquisition by putting the different evidence together into a single classifier (Pennacchiotti and Pantel, 2009) or to improve the coverage of semantic relations by combining and ranking the semantic relations obtained from two source texts (Talukdar et al., 2008).",
        "In this paper we propose an algorithm called Co-STAR.",
        "The main contributions of this work can be summarized as follows.",
        "• Co-STAR is a semi-supervised learning method composed of two parallel and iterative processes over structured and unstructured text.",
        "It was inspired by bilingual co-training, which is a framework for hyponymy relation acquisition from source texts in two languages (Oh et al., 2009).",
        "Like bilingual co-training, two processes in Co-STAR operate independently on structured text and unstructured text.",
        "These two processes are trained in a supervised manner with their initial training data and then each of them tries to enlarge the existing training data of the other by iteratively exchanging what they",
        "have learned (more precisely, by transferring reliable classification results on common instances to one another) (see Section 4 for comparison Co-STAR and bilingual co-training).",
        "Unlike the ensemble semantic framework (Pennacchiotti and Pantel, 2009), Co-STAR does not have a single \"master\" classifier or ranker to integrate the different evidence found in structured and unstructured text.",
        "We experimentally show that, at least in our setting, Co-STAR works better than a single \"master\" classifier.",
        "• Common relation instances found in both structured and unstructured text act as a communication channel between the two acquisition processes.",
        "Each process in Co-STAR classifies common relation instances and then transfers its high-confidence classification results to training data of the other process (as shown in Fig. 1), in order to improve classification results of the other process.",
        "Moreover, the efficiency of this exchange can be boosted by increasing the \"bandwidth\" of this channel.",
        "For this purpose each separate acquisition process automatically generates a set of relation instances that are likely to be negative.",
        "In our experiments, we show that the above idea proved highly effective.",
        "• Finally, the acquisition algorithm we propose is robust against noisy training data.",
        "We show this by training one classifier in Co-STAR with manually labeled data and training the other with automatically generated but noisy training data.",
        "We found that Co-STAR performs well in this setting.",
        "This issue is discussed in Section 6.",
        "This paper is organized as follows.",
        "Sections 2 and 3 precisely describe our algorithm.",
        "Section 4 describes related work.",
        "Sections 5 and 6 describe our experiments and present their results.",
        "Conclusions are drawn in Section 7."
      ]
    },
    {
      "heading": "2. Co-STAR",
      "text": [
        "Co-STAR consists of two processes that simultaneously but independently extract and classify",
        "Structured Texts",
        "Classifier",
        "TrainingH_T",
        "Classifier^",
        "Training^L^",
        "Unstructured Texts",
        "Figure 1 : Concept of Co-STAR.",
        "hyponymy relation instances from structured and unstructured text.",
        "The core of Co-STAR is the collaboration between the two processes, which continually exchange and compare their acquired knowledge on hyponymy relations.",
        "This collaboration is made possible through common instances shared by both processes.",
        "These common instances are classified separately by each process, but high-confidence classification results by one process can be transferred as new training data to the other.",
        "Let S and U represent a source (i.e. corpus) of structured and unstructured text, respectively.",
        "In this paper, we use the hierarchical layout of Wikipedia articles and the Wikipedia category system as structured text S (see Section 3.1), and a corpus of ordinary Web pages as unstructured text U.",
        "Let Xs and Xu denote a set of hyponymy relation candidates extracted from S and U, respectively.",
        "Xs is extracted from the hierarchical layout of Wikipedia articles (Oh et al., 2009) and Xu is extracted by lexico-syntactic patterns for hyponymy relations (i.e., hyponym such as hyponymy) (Ando et al., 2004) (see Section 3 for a detailed explanation)",
        "We define two types of common instances, called \"genuine\" common instances (G) and \"virtual\" common instances (V).",
        "The set of common instances is denoted by F = G U V. Genuine common instances are hyponymy relation candidates found in both S and U (G = Xs n Xu).",
        "On the other hand, term pairs are obtained as virtual common instances when:",
        "c",
        "Common",
        "r",
        "instances",
        "Transferring",
        "reliable",
        "classifi cation",
        "results of",
        "classifiers",
        "Transferring",
        "reliable",
        "classification",
        "results of",
        "classifiers",
        "4",
        "• 1) they are extracted as hyponymy relation candidates in either S or U and;",
        "• 2) they do not seem to be a hyponymy relation in the other text",
        "The first condition corresponds to XS © Xu.",
        "Term pairs satisfying the second condition are defined as RS and Rjj , where RS n XS = 0 and Ru n Xj = 0.",
        "RS contains term pairs that are found in the Wikipedia category system but neither term appears as ancestor of the other.",
        "For example, (nu-trition,protein) and (viruses,viral disease), respectively, hold a category-article relation, where nutrition is not ancestor of viruses and vice versa in the Wikipedia category system.",
        "Here, term pairs, such as (nutrition, viruses) and (viral disease, nutrition), can be ones in RS.",
        "Rj is a set of term pairs extracted from U when:",
        "• they are not hyponymy relation candidates in Xj and;",
        "• they regularly co-occur in the same sentence as arguments of the same verb (e.g., A cause B or A is made by B);",
        "As a result, term pairs in Ru are thought as holding some other semantic relations (e.g., A and B in \"A cause B\" may hold a cause/effect relation) than hyponymy relation.",
        "Finally, virtual common instances are defined as:",
        "The virtual common instances, from the viewpoint of either S or U, are unlikely to hold a hy-ponymy relation even if they are extracted as hy-ponymy relation candidates in the other text.",
        "Thus many virtual common instances would be a negative example for hyponymy relation acquisition.",
        "On the other hand, genuine common instances (hyponymy relation candidates found in both S and U) are more likely to hold a hyponymy relation than virtual common instances.",
        "In summary, genuine and virtual common instances can be used as different ground for collaboration as well as broader collaboration channel between the two processes than genuine common instances used alone.",
        "We assume that classifier c assigns class label cl g {yes,no} (\"yes\" (hyponymy relation) or \"no\" (not a hyponymy relation)) to instances in x g X with confidence value r g R+, a non-negative real number.",
        "We denote the classification result by classifier c as c(x) = (x, cl, r).",
        "We used support vector machines (SVMs) in our experiments and the absolute value of the distance between a sample and the hyperplane determined by the SVMs as confidence value r.",
        "1: Input: Common instances (Y = G U V) and",
        "the initial training data (L°S and Lj ) 2: Output: Two classifiers (cg and cj)",
        "4: repeat",
        "The Co-STAR algorithm is given in Fig. 2.",
        "The algorithm is interpreted as an iterative procedure 1) to train classifiers (cj, c%S) with the existing training data (LS and Lj ) and 2) to select new training instances from the common instances to be added to existing training data.",
        "These are repeated until stop condition is met.",
        "In the initial stage, two classifiers cS and cj are trained with manually prepared labeled instances (or training data) LS and Lj, respectively.",
        "The learning procedure is denoted by c = LEARN (L) in lines 5-6, where c is a resulting classifier.",
        "Then cS and cj are applied to classify common instances in Y (lines 7-8).",
        "We denote CRS as a set of the classification results of cS for common instances, which are not included in the current training data LS U Lj.",
        "Lines 9-13 describe a way of selecting instances in CRS to be added to the existing training data in U.",
        "During the selection, cS acts as a teacher and cj as a student.",
        "TopN(CR%S) is a set of cS (y) = (y, clS, rS ), whose rS is the top-N highest in CRS.",
        "(In our experiments, N = 900.)",
        "The teacher instructs his student the class label of y if the teacher can decide the class label of y with a certain level of confidence (rS > a) and the student satisfies one of the following two conditions:",
        "• the student agrees with the teacher on class label of y (clS = cljj) or",
        "• the student's confidence in classifying y is",
        "r j < ß enables the teacher to instruct his student in spite of their disagreement over a class label.",
        "If one of the two conditions is satisfied, (y, clS) is added to existing labeled instances lJ+1).",
        "The roles are reversed in lines 14-18, so that cj becomes the teacher and cS the student.",
        "The iteration stops if the change in the difference between the two classifiers is stable enough.",
        "The stability is estimated by d(cS, c j) in Eq.",
        "(1), where a represents the change in the average difference between the confidence values of the two classifiers in classifying common instances.",
        "We terminate the iteration if d(cS, cj) is smaller than 0.001 in three consecutive rounds (Wang and",
        "Zhou, 2007)."
      ]
    },
    {
      "heading": "3. Hyponymy Relation Acquisition",
      "text": [
        "In this section we explain how each process extracts hyponymy relations from its respective text source either Wikipedia or Web pages.",
        "Each process extracts hyponymy relation candidates (denoted by (hyper,hypo) in this section).",
        "Because there are many non-hyponymy relations in these candidates, we classify hyponymy relation candidates into correct hyponymy relation or not.",
        "We used SVMs (Vapnik, 1995) for the classification in this paper.",
        "Taxonomy",
        "Subspecies Bengal tiger Malayan tiger Siberian tiger",
        "(a) Layout structure (b) Tree structure",
        "Figure 3: Example borrowed from Oh et al.",
        "(2009): Layout and tree structures of Wikipedia article Tiger acquiring hyponymy relations from the Japanese Wikipedia.",
        "Every article is transformed into a tree structure as shown in Fig. 3, based on the items in its hierarchical layout including title, (sub)section headings, and list items.",
        "Candidate relations are extracted from this tree structure by regarding a node as a hypernym candidate and all of its subordinate nodes as potential hyponyms of the hyper-nym candidate (e.g., (Tiger, Taxonomy) and (Tiger, Siberian tiger) from Fig. 3).",
        "We obtained 1.9 x 10 Japanese hyponymy relation candidates from Wikipedia.",
        "Type Description",
        "Feature from Wikipedia Lexical Morphemes and POS of hyper and hypo; hyper and hypo themselves (\"WikiFeature\") Structure Distance between hyper and hypo in a tree structure;",
        "Lexical patterns for article or section names, where listed items often appear; Frequently used section headings in Wikipedia (e.g., \"Reference\"); Layout item type (e.g., section or list); Tree node type (e.g., root or leaf); Parent and children nodes of hyper and hypo Infobox Attribute type and its value obtained from Wikipedia infoboxes Feature from Web texts Lexical Morphemes and POS of hyper and hypo; hyper and hypo themselves (\"WebFeature\") Pattern Lexico-syntactic patterns applied to hyper and hypo;",
        "PMI score between pattern and hyponymy relation candidate (hyper,hypo) Collocation PMI score between hyper and hypo Noun Class Noun classes relevant to hyper and hypo",
        "Table 1: Feature sets (WikiFeature and WebFeature): hyper and hypo represent hypernym and hyponym parts of hyponymy relation candidates, respectively.",
        "As features for classification we used lexical, structure, and infobox information from Wikipedia (WikiFeature), as shown in Table 1.",
        "Because they are the same feature sets as those used in Oh et al.",
        "(2009), here we just give a brief overview of the feature sets.",
        "Lexical featuresare used to recognize the lexical evidence for hyponymy relations encoded in hyper and hypo.",
        "For example, the common head morpheme tiger in (Tiger, Bengal tiger) can be used as the lexical evidence.",
        "Such information is provided along with the words/morphemes and the parts of speech of hyper and hypo, which can be multiword/morpheme nouns.",
        "Structure features provide evidence found in layout or tree structures for hyponymy relations.",
        "For example, hyponymy relations (Tiger, Bengal tiger) and (Tiger,Malayan tiger) can be obtained from tree structure \"(root node, children nodes of Subspecies)\" in Fig 3.",
        "As the target for hyponymy relation acquisition from the Web, we used 5 x 10 pages from the TSUBAKI corpus (Shinzato et al., 2008), a 10 page Japanese Web corpus that was dependency parsed with KNP (Kurohashi-Nagao Parser) (Kurohashi and Kawahara, 2005).",
        "Hy-ponymy relation candidates are extracted from the corpus based on the lexico-syntactic patterns such as \"hypo nado hyper (hyper such as hypo)\" and \"hypo to iu hyper (hyper called hypo)\" (Ando et al., 2004).",
        "We extracted 6 x 10 Japanese hyponymy relation candidates from the Japanese Web texts.",
        "Features (WebFeature) used for classification are summarized in Table 1.",
        "Similar to the hyponymy relation acquisition from Wikipedia, lexical features are used to recognize the lexical evidence for hyponymy relations.",
        "Lexico-syntactic patterns for hyponymy relation show different coverage and accuracy in hy-ponymy relation acquisition (Ando et al., 2004).",
        "Further if multiple lexico-syntactic patterns support acquisition of hyponymy relation candidates, these candidates are more likely to be actual hy-ponymy relations.",
        "The pattern feature of hy-ponymy relation candidates is used for these evidence.",
        "We use PMI (point-wise mutual information) of hyponymy relation candidate (hyper, hypo) as a collocation feature (Pantel and Ravichandran, 2004), where we assume that hyper and hypo in candidates would frequently co-occur in the same sentence if they hold a hyponymy relation.",
        "Semantic noun classes have been regarded as useful information in semantic relation acquisition (De Saeger et al., 2009).",
        "EM-based clustering (Kazama and Torisawa, 2008) is used for obtaining 500 semantic noun classes from 5 x 10 nouns (including single-word and multi-word ones) and their 4 x 10 dependency relations with 5 x 10 verbs and other nouns in our target Web corpus.",
        "For example, noun class C311 includes biological or chemical substances such as tatou (polysaccharide) and yuukikagoubutsu (organic compounds).",
        "Noun classes (i.e., C311) relevant to hyper and hypo, respectively, are used as a noun class feature."
      ]
    },
    {
      "heading": "4. Related Work",
      "text": [
        "There are two frameworks, which are most relevant to our work - bilingual co-training and ensemble semantics.",
        "The main difference between bilingual co-training and Co-STAR lies in an instance space.",
        "In bilingual co-training, instances are in different spaces divided by languages while, in Co-STAR, many instances are in different spaces divided by their source texts.",
        "Table 2 shows differences between co-training, bilingual co-training and Co-",
        "STAR.",
        "Ensemble semantics is a relation acquisition framework, where semantic relation candidates are extracted from multiple sources and a single ranker ranks or classifies the candidates in the final step (Pennacchiotti and Pantel, 2009).",
        "In ensemble semantics, one ranker is in charge of ranking all candidates extracted from multiple sources; while one classifier classifies candidates extracted from one source in Co-STAR."
      ]
    },
    {
      "heading": "5. Experiments",
      "text": [
        "We used the July version of Japanese Wikipedia (jawiki-20090701) as structured text.",
        "We randomly selected 24,000 hyponymy relation candidates from those identified in Wikipedia and manually checked them.",
        "20,000 of these samples were used as training data for our initial classifier, the rest was equally divided into development and test data for Wikipedia.",
        "They are called \"WikiSet.\"",
        "As unstructured text, we used 5 x 10 Japanese Web pages in the TSUBAKI corpus (Shinzato et al., 2008).",
        "Here, we manually checked 9,500 hyponymy relation candidates selected randomly from Web texts.",
        "7,500 of these were used as training data.",
        "The rest was split into development and test data.",
        "We named this data \"WebSet\".",
        "In both classifiers, the development data was used to select the optimal parameters, and the test data was used to evaluate our system.",
        "We used TinySVM (TinySVM, 2002) with a polynomial kernel of degree 2 as a classifier.",
        "a (the threshold value indicating high confidence), ß (the threshold value indicating low confidence), and TopN (the maximum number of training instances to be added to the existing training data in each iteration) were selected through experiments on the development set.",
        "The combination of a = 1, ß = 0.3, and TopN=900 showed the best performance and was used in the following experiments.",
        "Evaluation was done by precision (P), recall (R), and F-measure (F).",
        "We compare six systems.",
        "Three of these, B1-B3, show the effect of different feature sets (\"Wik-iFeature\" and \"WebFeature\" in Table 1) and different training data.",
        "We trained two separate classifiers in B1 and B2, while we integrated feature sets and training data for training a single classifier in B3.",
        "The classifiers in these three systems are trained with manually prepared training data (\"WikiSet\" and \"WebSet\").",
        "For the purpose of our experiment, we consider B3 as the closest possible approximation of the ensemble semantics framework (Pennacchiotti and Pantel, 2009).",
        "• B1 consists of two completely independent classifiers.",
        "Both S and U classifiers are trained and tested on their own feature and data sets (respectively \"WikiSet + WikiFea-ture\" and \"WebSet + WebFeature\").",
        "Co-training",
        "(Blum and Mitchell, 1998)",
        "Bilingual co-training (Oh et al., 2009)",
        "Co-STAR (Proposed method)",
        "Instance space",
        "Same",
        "Different",
        "Almost different",
        "Feature space",
        "Split by human decision",
        "Split by languages",
        "Split by source texts",
        "Common instances",
        "Genuine-common",
        "(or All unlabeled) instances",
        "Genuine-common instances (Translatable)",
        "Genuine-common and virtual-common instances",
        "• B2 is the same as B1, except that both classifiers are trained with all available training data – WikiSet and WebSet are combined (27,500 training instances in total).",
        "However, each classifier only uses its own feature set (WikiFeature or WebFeature).",
        "• B3 adds a master classifier to B1.",
        "This third classifier is trained on the complete 27,500 training instances (same as B2) using all available features from Table 1, including each instance's SVM scores obtained from the two B1 classifiers.",
        "The verdict of the master classifier is considered to be the final classification result.",
        "The other three systems, BICO, Co-B, and Co-STAR (our proposed method), are for comparison between bilingual co-training (Oh et al., 2009) (BICO) and variants of Co-STAR (Co-B and Co-STAR).",
        "Especially, we prepared Co-B and Co-STAR to show the effect of different configurations of common instances on the Co-STAR algorithm.",
        "We use both B1 and B2 as the initial classifiers of Co-B and Co-STAR.",
        "We notate CoB and Co-STAR without V when B1 is used as their initial classifier and those with V when B2 is used.",
        "• BICO implements the bilingual co-training algorithm of (Oh et al., 2009), in which two processes collaboratively acquire hy-ponymy relations in two different languages.",
        "For BICO, we prepared 20,000 English and 20,000 Japanese training samples (Japanese ones are the same as training data in the WikiSet) by hand.",
        "• Co-B is a variant of Co-STAR that uses only the genuine-common instances as common instances (67,000 instances), to demonstrate",
        "the effectiveness of the virtual common instances.",
        "• Co-STAR is our proposed method, which uses both genuine-common and virtual-common instances (643,000 instances in total).",
        "Table 3 summarizes the result.",
        "Features for common instances in Co-B and Co-STAR are prepared in the same way as training data in B2, so that both classifiers can classify the common instances with their trained feature sets.",
        "Comparison between B1-B3 shows that B2 and B3 outperform B1 in F-measure.",
        "More training data used in B2-B3 (27,500 instances for both WebSet and WikiSet) results in higher performance than that of B1 (7,500 and 20,000 instances used separately).",
        "We think that the lexical features, assigned regardless of source text to instances in B2-B3, are mainly responsible for the performance gain over B1, as they are the least domain-dependent type of features.",
        "B2-B3 are composed of different number of classifiers, each of which is trained with different feature sets and training instances.",
        "Despite this difference, B2 and B3 showed similar performance in F-measure.",
        "Co-STAR outperformed the algorithm similar to the ensemble semantics framework (B3), although we admit that a more extensive comparison is desirable.",
        "Further Co-STAR outperformed BICO.",
        "While the manual cost for building the initial training data used in Co-STAR and BICO is hard to quantify, Co-STAR achieves better performance with fewer training data in total (27,500 instances) than BICO (40,000 instances).",
        "The difference in performance between Co-B and Co-STAR shows the effectiveness of the automatically generated virtual-common instances.",
        "From these comparison, we can see that virtual-common instances coupled with genuine-common instances can be leveraged to enable more effective collaboration between the two classifiers in Co-STAR.",
        "WebSet",
        "WikiSet",
        "P",
        "R",
        "F",
        "P",
        "R",
        "F",
        "B1",
        "84.3",
        "65.2",
        "73.5",
        "87.8",
        "74.7",
        "80.7",
        "B2",
        "83.4",
        "69.6",
        "75.9",
        "87.4",
        "79.5",
        "83.2",
        "B3",
        "82.2",
        "72.0",
        "76.8",
        "86.1",
        "77.7",
        "81.7",
        "BICO",
        "N/A",
        "N/A",
        "N/A",
        "84.5",
        "81.8",
        "83.1",
        "Co-B",
        "86.2",
        "63.5",
        "73.2",
        "89.7",
        "74.1",
        "81.2",
        "Co-B*",
        "85.5",
        "69.9",
        "77.0",
        "89.6",
        "76.5",
        "82.5",
        "Co-STAR",
        "85.9",
        "76.0",
        "80.6",
        "88.0",
        "81.8",
        "84.8",
        "Co-STAR*",
        "83.3",
        "80.7",
        "82.0",
        "87.6",
        "81.8",
        "84.6",
        "As a result, our proposed method outperforms the others in F-measure by 1.4-8.5%.",
        "We obtained 4.3 x 10 hyponymy relations from Web texts and 4.6 x 10 ones from Wikipedia."
      ]
    },
    {
      "heading": "6. Co-STAR with Automatically Generated Training Data",
      "text": [
        "For Co-STAR, we need two sets of manually prepared training data, one for structured text and the other for unstructured text.",
        "As in any other supervised system, the cost of preparing the training data is an important issue.",
        "We therefore investigated whether Co-STAR can be trained for a lower cost by generating more of its training data automatically.",
        "We automatically built training data for Web texts by using definition sentences and category names in the Wikipedia articles, while we stuck to manually prepared training data for Wikipedia.",
        "To obtain hypernyms from Wikipedia article names, we used definition-specific lexico-syntactic patterns such as \"hyponym is hypernym\" and \"hy-ponym is a type of hypernym\" (Kazama and Tori-sawa, 2007; Sumida and Torisawa, 2008).",
        "Then, we extracted hyponymy relations consisting of pairs of Wikipedia category names and their member articles when the Wikipedia category name and the hypernym obtained from the definition of the Wikipedia article shared the same head word.",
        "Next, we selected a subset of the extracted hyponymy relations that are also hyponymy relation candidates in Web texts, as positive instances for hyponymy relation acquisition from Web text.",
        "We obtained around 15,000 positive instances in this way.",
        "Negative instances were chosen from virtual-common instances, which also originated from the Wikipedia category system and hyponymy relation candidates in Web texts (around 293,000 instances).",
        "The automatically built training data was noisy and its size was much bigger than manually prepared training data in WebSet.",
        "Thus 7,500 instances as training data (the same number of manually built training data in WebSet) were randomly chosen from the positive and negative instances with a positive:negative ratio of 1:4.",
        "With the automatically built training data for Web texts and manually prepared training data for Wikipedia, we evaluated B1-B3 and Co-STAR, which are the same systems in Table 3.",
        "The results in Table 4 are encouraging.",
        "Co-STAR was robust even when faced with noisy training data.",
        "Further Co-STAR showed better performance than B1-B3, although its performance in Table 4 dropped a bit compared to Table 3.",
        "This result shows that we can reduce the cost of manually preparing training data for Co-STAR with only small loss of the performance."
      ]
    },
    {
      "heading": "7. Conclusion",
      "text": [
        "This paper proposed Co-STAR, an algorithm for hyponymy relation acquisition from structured and unstructured text.",
        "In Co-STAR, two independent processes of hyponymy relation acquisition from structured texts and unstructured texts, collaborate in an iterative manner through common instances.",
        "To improve this collaboration, we introduced virtual-common instances.",
        "Through a series of experiments, we showed that Co-STAR outperforms baseline systems and virtual-common instances can be leveraged to achieve better performance.",
        "We also showed that Co-STAR is robust against noisy training data, which requires less human effort to prepare it.",
        "WebSet",
        "WikiSet",
        "P",
        "R",
        "F",
        "P",
        "R",
        "F",
        "B1",
        "81.0",
        "47.6",
        "60.0",
        "87.8",
        "74.7",
        "80.7",
        "B2",
        "80.0",
        "55.4",
        "65.5",
        "87.1",
        "79.5",
        "83.1",
        "B3",
        "82.0",
        "33.7",
        "47.8",
        "87.1",
        "75.6",
        "81.0",
        "Co-STAR",
        "82.2",
        "60.8",
        "69.9",
        "87.3",
        "80.7",
        "83.8",
        "Co-STAR*",
        "79.2",
        "69.6",
        "74.1",
        "87.0",
        "81.8",
        "84.4"
      ]
    }
  ]
}
