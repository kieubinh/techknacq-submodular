{
  "info": {
    "authors": [
      "Xian Qian",
      "Qi Zhang",
      "Xuangjing Huang",
      "Lide Wu"
    ],
    "book": "COLING",
    "id": "acl-C10-1102",
    "title": "2D Trie for Fast Parsing",
    "url": "https://aclweb.org/anthology/C10-1102",
    "year": 2010
  },
  "references": [
    "acl-D07-1033",
    "acl-N03-1028",
    "acl-P05-1012",
    "acl-P08-2060",
    "acl-P09-1039",
    "acl-P09-1040",
    "acl-P09-1087",
    "acl-W09-1201",
    "acl-W09-1210",
    "acl-W09-1212"
  ],
  "sections": [
    {
      "text": [
        "Xian Qian, Qi Zhang, Xuanjing Huang, Lide Wu",
        "Institute of Media Computing School of Computer Science, Fudan University",
        "{xianqian, qz, xjhuang, ldwu}@fudan.edu.cn",
        "In practical applications, decoding speed is very important.",
        "Modern structured learning technique adopts template based method to extract millions of features.",
        "Complicated templates bring about abundant features which lead to higher accuracy but more feature extraction time.",
        "We propose Two Dimensional Trie (2D Trie), a novel efficient feature indexing structure which takes advantage of relationship between templates: feature strings generated by a template are prefixes of the features from its extended templates.",
        "We apply our technique to Maximum Spanning Tree dependency parsing.",
        "Experimental results on Chinese Tree Bank corpus show that our 2D Trie is about 5 times faster than traditional Trie structure, making parsing speed 4.3 times faster."
      ]
    },
    {
      "heading": "1. Introduction",
      "text": [
        "In practical applications, decoding speed is very important.",
        "Modern structured learning technique adopts template based method to generate millions of features.",
        "Such as shallow parsing (Sha and Pereira, 2003), named entity recognition (Kazama and Torisawa, ), dependency parsing (McDonald et al., 2005), etc.",
        "The problem arises when the number of templates increases, more features generated, making the extraction step time consuming.",
        "Especially for maximum spanning tree (MST) dependency parsing, since feature extraction requires quadratic time even using a first order model.",
        "According to Bohnet's report (Bohnet, 2009), a fast",
        "Feature Generation",
        "Template: p0.word+p0.pos|",
        "Feature: lucky/ADJ",
        "Figure 1: Flow chart of dependency parsing.",
        "po.word, p0.pos denotes the word and POS tag of parent node respectively.",
        "Indexes correspond to the features conjoined with dependency types, e.g., lucky/ADJ/OBJ, lucky/ADJ/NMOD, etc.",
        "feature extraction beside of a fast parsing algorithm is important for the parsing and training speed.",
        "He takes 3 measures for a 40X speedup, despite the same inference algorithm.",
        "One important measure is to store the feature vectors in file to skip feature extraction, otherwise it will be the bottleneck.",
        "Now we quickly review the feature extraction stage of structured learning.",
        "Typically, it consists of 2 steps.",
        "First, features represented by strings are generated using templates.",
        "Then a feature indexing structure searches feature indexes to get corresponding feature weights.",
        "Figure 1 shows the flow chart of MST parsing, where p0.word, po.pos denote the word and POS tag of parent node respectively.",
        "We conduct a simple experiment to investigate decoding time of MSTParser, a state-of-the-art java implementation of dependency parsing .",
        "Chinese Tree Bank 6 (CTB6) corpus (Palmer and",
        "Parse Tree ^",
        "Index: 3228~3233",
        "Build lattice, inference etc.",
        "Table 1: Time spent of each step (seconds) of MSTParser on CTB6 standard test data (2660 sentences).",
        "Details of the hardware and corpus are described in section 5",
        "Xue, 2009) with standard train/development/test split is used for evaluation.",
        "Experimental results are shown in Table 1.",
        "The observation is that time spent of inference is trivial compared with feature extraction.",
        "Thus, speeding up feature extraction is critical especially when large template set is used for high accuracy.",
        "General indexing structure such as Hash and Trie does not consider the relationships between templates, therefore they could not speed up feature generation, and are not completely efficient for searching feature indexes.",
        "For example, feature string s1 generated by template \"p0..word\" is prefix of feature s2 from template \"p0.word + co.word\" (word pair of parent and child), hence index of si could be used for searching s2.",
        "Further more, if s1 is not in the feature set, then s2must be absent, its generation can be skipped.",
        "We propose Two Dimensional Trie (2D Trie), a novel efficient feature indexing structure which takes advantage of relationship between templates.",
        "We apply our technique to Maximum Spanning Tree dependency parsing.",
        "Experimental results on CTB6 corpus show that our 2D Trie is about 5 times faster than traditional Trie structure, making parsing speed 4.3 times faster.",
        "The paper is structured as follows: in section 2, we describe template tree which represents relationship between templates; in section 3, we describe our new 2D Trie structure; in section 4, we analyze the complexity of the proposed method and general string indexing structures for parsing; experimental results are shown in section 5; we conclude the work in section 6."
      ]
    },
    {
      "heading": "2. Template tree",
      "text": [
        "A template is a set of template units which are manually designed: T = {t1,... ,tm}.",
        "For convenience, we use another formulation: T = t1 + .. .+tm.",
        "All template units appearing in this paper are described in Table 2, most of them are widely used.",
        "For example, \"T = p0.word + c0.word|' \" denotes the word pair of parent and child nodes, conjoined with their distance.",
        "In the rest of the paper, for simplicity, let si be a feature string generated by template Tj.",
        "We define the relationship between templates: Ti is the ancestor of T2 if and only Ti C T2, and T2 is called the descendant of Ti.",
        "Recall that, feature string s1 is prefix of feature s2.",
        "Suppose T3 C T1 C T2, obviously, the most efficient way to look up indexes of s1, s2, s3 is to search s3 first, then use its index id3 to search s1, and finally use id1 to search s2.",
        "Hence the relationship between T2 and T3 can be neglected.",
        "Therefore we define direct ancestor of T1 : T2is a direct ancestor of T1 if T2 C T1 , and there is no template T' such that T2 C T' C T1.",
        "Correspondingly, T1 is called the direct descendant of",
        "T2.",
        "Template graph G = (V, E) is a directed graph that represents the relationship between templates, where V = {T1,... ,Tn} is the template set, E = {e1,..., eN} is the edge set.",
        "Edge from Ti to Tj exists, if and only if Ti is the direct ancestor of Tj.",
        "For templates having no ancestor, we add an empty template as their common direct ancestor, which is also the root of the graph.",
        "The left part of Figure 2 shows a template graph for templates T1 =p0.word, T2 =p0.pos , T3 =p0.word + p0.pos.",
        "In this example, T3 has 2 direct ancestors, but in fact s3 has only one prefix",
        "Step",
        "Feature Generation",
        "Index Retrieval",
        "Other",
        "Total",
        "Time",
        "300.27",
        "61.66",
        "59.48",
        "421.41",
        "Unit",
        "Meaning",
        "p – i/pi",
        "the ith node left/right to parent node",
        "c – i/ci",
        "the ith node left/right to child node",
        "r-i/ri",
        "the ith node left/right to root node",
        "n.word",
        "word of node n",
        "n.pos",
        "POS tag of node n",
        "n.length",
        "word length of node n",
        "\\l",
        "conjoin current feature with linear distance between child node and parent node",
        "Id",
        "conjoin current feature with direction of dependency (left/right)",
        "root root Pn.word p0.pos p0.word",
        "Figure 2: Left graph shows template graph for T1 =p0.word, T2 =p0.pos , T3 =p0.word + po-pos.",
        "Right graph shows the corresponding template tree, where each vertex saves the subset of template units that do not belong to its father",
        "p0.word + Po.pos.",
        "Figure 3: Templates that are partially overlapped: Tred H Tb1ue =p0.word, virtual vertexes shown in dashed circle are created to extract the common unit which depends on the order of template units in generation step.",
        "If S3 = s1 + s2, then its prefix is s 1, otherwise its prefix is s2.",
        "In this paper, we simply use the breadth-first tree of the graph for disambiguation, which is called template tree.",
        "The only direct ancestor T1 of T2 in the tree is called father of T2, and T2 is a child of Ti.",
        "The right part of Figure 2 shows the corresponding template tree, where each vertex saves the subset of template units that do not belong to its father.",
        "Figure 4: 2D Trie for single template, alphabets at level 1 and level 2 are the word set, POS tag set respectively",
        "Consider the template tree in the left part of Figure 3, red vertex and blue vertex are partially overlapped, their intersection is p0.word, if string s from template T =p0 .word is absent in feature set, then both nodes can be neglected.",
        "For efficiently pruning candidate templates, each vertex in template tree is restricted to have exactly one template unit (except root).",
        "Another important reason for such restriction will be given in the next section.",
        "To this end, virtual vertexes are created for multi-unit vertexes.",
        "For efficient pruning, the new virtual vertex should extract the most common template unit.",
        "A natural goal is to minimize the creation number.",
        "Here we use a simple greedy strategy, for the vertexes sharing a common father, the most frequent common unit is extracted as new vertex.",
        "Virtual vertexes are iteratively created in this way until all vertexes have one unit.",
        "The final template tree is shown in the right part of Figure 3, newly created virtual vertexes are shown in dashed circle."
      ]
    },
    {
      "heading": "3. 2D Trie",
      "text": [
        "Trie stores strings over a fixed alphabet, in our case, feature strings are stored over several alphabets, such as word list, POS tag list, etc.",
        "which are extracted from training corpus.",
        "To illustrate 2D Trie clearly, we first consider a simple case, where only one template used.",
        "The template tree degenerates to a sequence, we could use a Trie like structure for feature indexing, the only difference from traditional Trie is that nodes at different levels could have different alphabets.",
        "One example is shown in Figure 4.",
        "There are 3 feature strings from template \"p0.word + p0.pos\": [parse/VV, tag/VV, tag/VV}.",
        "Alphabets at level 1 and level 2 are the word set, POS tag set respectively, which are determined by corresponding template vertexes.",
        "As mentioned before, each vertex in template tree has exactly one template unit, therefore, at each level, we look up an index of a word or POS",
        "root p0.word",
        "root Po POS o",
        "tag in sentence, not their combinations.",
        "Hence the number of alphabets is limited, and all the indexes could be searched beforehand for reuse, as shown in Figure 5, the token table is converted to a index table.",
        "For example, when generating features at position i of a sentence, template \"r0.word + ri .word\" requires index of i + 1th word in the sentence, which could be reused for generation at position i + 1.",
        "Generally, for vertex in template tree with K children, children of corresponding Trie node are arranged in a matrix of K rows and L columns, L is the size of corresponding alphabet.",
        "If the vertex is not virtual, i.e., it generates features, one more row is added at the bottom to store feature indexes.",
        "Figure 6 shows the 2D Trie for a general template tree.",
        "When extracting features for a pair of nodes in a sentence, template tree and 2D Trie are visited in breath first traversal order.",
        "Each time, an alphabet and a token index j from index table are selected according to current vertex.",
        "For example, POS tag set and the index of the POS tag of parent node are selected as alphabet and token index respectively for vertex \"p0.pos\".",
        "Then children in the jth column of the Trie node are visited, valid children and corresponding template vertexes are saved for further retrieval or generate feature indexes if the child is at the bottom and current Trie node is not virtual.",
        "Two queues are maintained to",
        "Feature index array",
        "Figure 6: 2D trie for a general template tree.",
        "Dashed boxes are keys of columns, which are not stored in the structure save the valid children and Trie nodes.",
        "Details of feature extraction algorithm are described in Algorithm 1.",
        "When feature set is very large, space complexity of 2D Trie is expensive.",
        "Therefore, we use Double Array Trie structure (Aoe, 1989) for implementation.",
        "Since children of 2D Trie node are arranged in a matrix, not an array, so each element of the base array has a list of bases, not one base in standard structure.",
        "For children that store features, corresponding bases are feature indexes.",
        "One example is shown in Figure 7.",
        "The root node has 3 bases that point to three rows of the child matrix of vertex \"p0.word\" respectively.",
        "Number of bases in each element need not to be stored, since it can be obtained from template vertex in extraction procedure.",
        "Building algorithm is similarly to Double Array Trie, when inserting a Trie node, each row of the child matrix is independently insert into base and check arrays using brute force strategy.",
        "The inser-",
        "He",
        "PRP",
        "2648",
        "21",
        "had",
        "VBD",
        "2731",
        "27",
        "been",
        "VBN",
        "1121",
        "28",
        "a",
        "DT",
        "0411",
        "04",
        "sales",
        "NNS",
        "5064",
        "13",
        "and",
        "CC",
        "0631",
        "01",
        "marketing",
        "NN",
        "3374",
        "12",
        "executive",
        "NN",
        "1923",
        "12",
        "with",
        "IN",
        "6023",
        "06",
        "Chrysler",
        "NNP",
        "1560",
        "13",
        "for",
        "IN",
        "2203",
        "06",
        "20",
        "CD",
        "0056",
        "02",
        "years",
        "NNS",
        "6778",
        "14",
        "been",
        "had",
        "S^in valid",
        "p0.word – been",
        "^pjrWojrd^had",
        "He / ... \\ been",
        "n",
        "po.word+W0.word – had/He",
        "...",
        "p0.word+w0.word – had/been",
        "... nmod obj \\ sub",
        "vmod ...",
        "nmod",
        "obj",
        "sub vmod\\...\\",
        "\\...\\ 1 |3327|2510",
        "-1 \\",
        "i 1 i",
        "-1",
        "-1 I \\...\\",
        "Base array",
        "... ... ... ...",
        "Figure 7: Build base array for 2D Trie in Figure 6.",
        "String in the box represents the key of the child.",
        "Blank boxes are the invalid children.",
        "The root node has 3 bases that point to three rows of the child matrix of vertex \"po.word\" respectively Algorithm 1 Feature extraction using 2D Trie Input: 2D Trie that stores features, template tree, template graph, a table storing token indexes, parent and child positions Output: Feature index set S of dependency from parent to child.",
        "tion repeats recursively until all features stored."
      ]
    },
    {
      "heading": "4. Complexity analysis",
      "text": [
        "• |T | = number of templates",
        "• |t| = number of template units",
        "• |V | = number of vertexes in template tree, i.e, number of virtual vertexes",
        "• |F | = number of features",
        "• l = length of sentence",
        "• |f | = average length of feature strings",
        "The procedure of 2D Trie for feature extraction consists of 2 steps: tokens in string table are mapped to their indexes, then Algorithm 1 is carried out for all node pairs of sentence.",
        "In the first step, we use double array Trie for efficient mapping.",
        "In fact, time spent is trivial compared with step 2 even by binary search.",
        "The main time spent of Algorithm 1 is the traversal of the whole template tree, in the worst case, no vertexes removed, so the time complexity of a sentence is 1|V |, which is proportional to | V|.",
        "In other words, minimizing the number of virtual vertexes is important for efficiency.",
        "For other indexing structures, feature generation is a primary step of retrieval.",
        "For each node",
        "Create template vertex queue Q\\ and Trie node queue Q2.",
        "Push roots of template tree and Trie into Qi, Q2 respectively.",
        "S = 0 while Q1 is not empty, do",
        "Pop a template vertex T from Q1 and a Trie node N from Q2.",
        "Get token index j from index table according to T.",
        "for i = 1 to child number of T",
        "if child of N at row i column j is valid, push it into Q2 and push the ith child of T into Q1.",
        "remove decedents of ith child of T from template tree end if end for if T is not virtual and the last child of N in column j is valid",
        "Enumerate dependency types, add valid feature indexes to S end if end while Return S.",
        "been",
        "had-",
        "*| .",
        ".",
        ".",
        "1 1VBN| i .",
        ".",
        ".",
        "had",
        "base1",
        "root 1-base – *•",
        "been",
        "had",
        "... i »| ... i |VBD| ...",
        "___",
        "-•",
        "-=",
        "--",
        " – – – _ Feature index array",
        "1 ... 1 ... 1 ... 1 ...",
        "-1",
        "3327",
        "2510",
        "...",
        "...",
        "-1",
        "-1 | 1 ll ^1 ^1 ...",
        "pair of sentence, |t| template units are processed, including concatenations of tokens and split symbols (split tokens in feature strings), boundary check ( e.g, p-1.word is out of boundary for beginning node of sentence).",
        "Thus the generation requires l|t| processes.",
        "Notice that, time spent of each process varies on the length of tokens.",
        "For feature string s with length |s|, if perfect hashing technique is adopted for index retrieval, it takes s calculations to get hash value and a string comparison to check the string at the calculated position.",
        "So the time complexity is proportional to | s |, which is the same as Trie.",
        "Hence the total time for a sentence is l|f ||T |.",
        "If binary search is used instead, log ^ | string comparisons are required, complexity for a sentence is l|T| log ^|.",
        "Time complexity of these structures is summarized in Table 3."
      ]
    },
    {
      "heading": "5. Experiments",
      "text": [
        "We use Chinese Tree Bank 6.0 corpus for evaluation.",
        "The constituency structures are converted to dependency trees by Penn2Malt toolkit and the standard training/development/test split is used.",
        "257 sentences that failed in the conversion were removed, yielding 23316 sentences for training, 2060 sentences for development and 2660 sentences for testing respectively.",
        "Since all the dependency trees are projective, a first order projective MST parser is naturally adopted.",
        "Online Passive Aggressive algorithm (Crammer et al., 2006) is used for fast training, 2 parameters, i.e, iteration number and C, are tuned on development data.",
        "The quality of the parser is measured by the labeled attachment score (LAS), i.e., the percentage of tokens with correct head and dependency type.",
        "Table 5: Parsing accuracy and number of templates, vertexes in template tree, features in decoding stage (zero weighted features are excluded) of each group.",
        "We compare the proposed structure with Trie and binary search.",
        "We do not compare with perfect hashing, because it has the same complexity as Trie, and is often used for large data base retrieval, since it requires only one IO operation.",
        "For easy comparison, all feature indexing structures and the parser are implemented with C++.",
        "All experiments are carried out on a 64bit linux platform (CPU: Intel(R) Xeon(R) E5405, 2.00GHz, Memory: 16G Bytes).",
        "For each template set, we run the parser five times on test data and the averaged parsing time is reported.",
        "To investigate the scalability of our method, rich templates are designed to generate large feature sets, as shown in Table 4.",
        "All templates are organized into 4 groups.",
        "Each row of Table 5 shows the details of a group, including parsing accuracy and number of templates, vertexes in template tree, and features in decoding stage (zero weighted features are excluded).",
        "There is a rough trend that parsing accuracy increases as more templates used.",
        "Though such trend is not completely correct, the clear conclusion is that, abundant templates are necessary for accurate parsing.",
        "Though algorithm described in section 2.3 for minimizing the number of virtual vertexes is heuristic, empirical results are satisfactory, number of newly created vertexes is only 10% as original templates.",
        "The reason is that complex templates are often extended from simple ones, their differences are often one or two template units.",
        "Results of parsing time comparison are shown in Table 6.",
        "We can see that though time complexity of dynamic programming is cubic, parsing time of all systems is consistently dominated",
        "Structure",
        "Generation Retrieval",
        "2D Trie",
        "1|V |",
        "Hash / Trie",
        "l|t|",
        "l |f ||T |",
        "Binary Search",
        "l|t|",
        "1|T| log |F|",
        "Group",
        "IDs",
        "#Temp.",
        "#Vert.",
        "#Feat.",
        "LAS",
        "1",
        "1-2",
        "72",
        "91",
        "3.23M",
        "79.55%",
        "2",
        "1-3",
        "128",
        "155",
        "10.4M",
        "81.38%",
        "3",
        "1-4",
        "240",
        "275",
        "25.0M",
        "81.97%",
        "4",
        "1-5",
        "332",
        "367",
        "34.8M",
        "82.44%",
        "Templates",
        "Pi.word Ci .word Pi.pos ci.pos pi.word+pi.pos ci .word+ci.pos pi.length ci.",
        "length pi.length+pi.pos ci.length+ci.pos",
        "po .length+Co .length\\ldpo.length+po.pos+Co.pos|d;",
        "po.length+po.pos+Co.length|dpo.length+po.pos+Co.length+Co.pos|d po.length+Co.length+Co.pos|dpo.pos+Co.length+Co.pos|d",
        "pi .length+pj .length+Ck .length+cm .length | d",
        "ro.word ro.pos r_i .word+ro .word r_i.pos+ro.pos",
        "ro .word+ri.word ro.pos+ri.pos",
        "pi.word+Cj .",
        "word | dpi.word+pi .pos+Cj .word|d",
        "pi .word+Cj .word+Cj .pos^",
        "pi.pos+Cj .posy pi.word+pi.pos+Cj.pos| d pi .word+pi .pos+Cj .word+Cj .pos | d",
        "Conjoin templates in the row above with |' pi.word + pj.word + Ck.word d pi.pos + pj.pos + Ck.pos d",
        "pi.word + Cj .word + ck .word|d",
        "Conjoin templates in the row above with | pi.word + pj .word + pk .word + cm.word|dpi.word + Cj .word + ck .word + cm.word|d",
        "by feature extraction.",
        "When efficient indexing structure adopted, i.e, Trie or Hash, time index retrieval is greatly reduced, about 4-5 times faster than binary searCh.",
        "However, general struCtures searCh features independently, their results Could not guide feature generation.",
        "HenCe, feature generation is still time Consuming.",
        "The reason is that proCessing eaCh template unit inCludes a series of steps, muCh slower than one integer Comparison in Trie searCh.",
        "On the other hand, 2D Trie greatly reduCes the number of feature generations by pruning the template graph.",
        "In faCt, no string ConCatenation oCCurs when using 2D Trie, sinCe all tokens are Converted to indexes beforehand.",
        "The improvement is significant, 2D Trie is about 5 times faster than Trie on the largest feature set, yielding 13.4 sentenCes per seCond parsing speed, about 4.3 times faster.",
        "Space requirement of 2D Trie is about 2.1 times as binary search, and 1.7 times as Trie.",
        "One possible reason is that Column number of 2D Trie (e.g. size of words) is much larger than standard double array Trie, which has only 256 children, i.e, range of a byte.",
        "Therefore, inserting a 2D Trie node is more strict, yielding sparser double arrays.",
        "Recent works on dependency parsing speedup mainly focus on inference, such as expected linear time non-projective dependency parsing (Nivre, 2009), integer linear programming (ILP) for higher order non-projective parsing (Martins et al., 2009).",
        "They achieve 0.632 seconds per sentence over several languages.",
        "On the other hand, Goldberg and Elhadad proposed splitSVM (Goldberg and Elhadad, 2008) for fast low-degree polynomial kernel classifiers, and applied it to transition based parsing (Nivre, 2003).",
        "They achieve 53 sentences per second parsing speed on English corpus, which is faster than our results, since transition based parsing is linear time, while for graph based method, complexity of feature extraction is quadratic.",
        "Xavier Lluls et al.",
        "(Llufs et al., 2009) achieve 8.07 seconds per sentence speed on CoNLL09 (HajiC et al., 2009) Chinese Tree Bank test data with a second order graphic model.",
        "Bernd Bohnet (Bohnet, 2009) also uses second order model, and achieves 610 minutes on CoNLL09 English data (2399 sentences, 15.3 second per sentence).",
        "Although direct comparison of parsing time is difficult due to the differences in data, models, hardware and implementations,",
        "Table 6: Parsing time of 2660 sentences (seconds) on a 64bit linux platform (CPU: Intel(R) Xeon(R) E5405, 2.00GHz, Memory: 16G Bytes).",
        "Title \"Generation\" and \"Retrieval\" are short for feature generation and feature index retrieval steps respectively.",
        "Table 7: Comparison against state of the art, direct comparison of parsing time is difficult due to the differences in data, models, hardware and implementations.",
        "these results demonstrate that our structure can actually result in a very fast implementation of a parser.",
        "Moreover, our work is orthogonal to others, and could be used for other learning tasks."
      ]
    },
    {
      "heading": "6. Conclusion",
      "text": [
        "We proposed 2D Trie, a novel feature indexing structure for fast template based feature extraction.",
        "The key insight is that feature strings generated by a template are prefixes of the features from its extended templates, hence indexes of searched features can be reused for further extraction.",
        "We applied 2D Trie to dependency parsing task, experimental results on CTB corpus demonstrate the advantages of our technique, about 5 times faster than traditional Trie structure, yielding parsing speed 4.3 times faster, while using only 1.7 times as much memory."
      ]
    },
    {
      "heading": "7. Acknowledgments",
      "text": [
        "The author wishes to thank the anonymous reviewers for their helpful comments.",
        "This work was partially funded by 973 Program",
        "Shanghai Science and Technology Development",
        "Funds (08511500302).",
        "Group",
        "Structure",
        "Total",
        "Generation",
        "Retrieval",
        "Other",
        "Memory",
        "sent/sec",
        "1",
        "Trie",
        "87.39",
        "63.67",
        "10.33",
        "13.39",
        "402M",
        "30.44",
        "Binary Search",
        "127.84",
        "62.68",
        "51.52",
        "13.64",
        "340M",
        "20.81",
        "2D Trie",
        "39.74",
        "26.29",
        "13.45",
        "700M",
        "66.94",
        "2",
        "Trie",
        "264.21",
        "205.19",
        "39.74",
        "19.28",
        "1.3G",
        "10.07",
        "Binary Search",
        "430.23",
        "212.50",
        "198.72",
        "19.01",
        "1.2G",
        "6.18",
        "2D Trie",
        "72.81",
        "53.95",
        "18.86",
        "2.5G",
        "36.53",
        "3",
        "Trie",
        "620.29",
        "486.40",
        "105.96",
        "27.93",
        "3.2G",
        "4.29",
        "Binary Search",
        "982.41",
        "484.62",
        "469.44",
        "28.35",
        "2.9G",
        "2.71",
        "2D Trie",
        "146.83",
        "119.56",
        "27.27",
        "5.9G",
        "18.12",
        "4",
        "Trie",
        "854.04",
        "677.32",
        "139.70",
        "37.02",
        "4.9G",
        "3.11",
        "Binary Search",
        "1328.49",
        "680.36",
        "609.70",
        "38.43",
        "4.1G",
        "2.00",
        "2D Trie",
        "198.31",
        "160.38",
        "37.93",
        "8.6G",
        "13.41",
        "System",
        "sec/sent",
        "(Martins et al., 2009)",
        "0.63",
        "(Goldberg and Elhadad, 2008)",
        "0.019",
        "(Llufs et al., 2009)",
        "8.07",
        "(Bohnet, 2009)",
        "15.3",
        "(Galley and Manning, 2009)",
        "15.6",
        "ours group1",
        "0.015",
        "ours group2",
        "0.027",
        "ours group3",
        "0.055",
        "ours group4",
        "0.075"
      ]
    }
  ]
}
