{
  "info": {
    "authors": [
      "Altaf Rahman",
      "Vincent Ng"
    ],
    "book": "COLING",
    "id": "acl-C10-1105",
    "title": "Inducing Fine-Grained Semantic Classes via Hierarchical and Collective Classification",
    "url": "https://aclweb.org/anthology/C10-1105",
    "year": 2010
  },
  "references": [
    "acl-D09-1128",
    "acl-H92-1045",
    "acl-N03-1033",
    "acl-N04-1001",
    "acl-N06-2015",
    "acl-P04-1056",
    "acl-P05-1045",
    "acl-P06-1060",
    "acl-P07-1068",
    "acl-W06-1633"
  ],
  "sections": [
    {
      "text": [
        "Altaf Rahman and Vincent Ng",
        "Research in named entity recognition and mention detection has typically involved a fairly small number of semantic classes, which may not be adequate if semantic class information is intended to support natural language applications.",
        "Motivated by this observation, we examine the understudied problem of semantic subtype induction, where the goal is to automatically determine which of a set of 92 fine-grained semantic classes a noun phrase belongs to.",
        "We seek to improve the standard supervised approach to this problem using two techniques: hierarchical classification and collective classification.",
        "Experimental results demonstrate the effectiveness of these techniques, whether or not they are applied in isolation or in combination with the standard approach."
      ]
    },
    {
      "heading": "1. Introduction",
      "text": [
        "Semantic class determination refers to the task of classifying a noun phrase (NP), be it a name or a nominal, as one of a set of predefined semantic classes.",
        "A semantic class classifier is a basic text-processing component in many highlevel natural language processing (NLP) applications, including information-extraction (IE) systems and question-answering (QA) systems.",
        "In recent years, supervised semantic class determination has been tackled primarily in the context of (1) coreference resolution (e.g., Ng (2007), Huang et al.",
        "(2009)), where semantic classes are induced and subsequently used to disallow coreference between semantically incompatible NPs, and (2) the mention detection task in the ACE evaluations (e.g., Florian et al.",
        "(2004; 2006)), where the goal is to identify the boundary of a mention (i.e., a noun phrase that belongs to one of the predefined ACE semantic classes), its mention type (e.g., pronoun, name), and its semantic class.",
        "The output of a mention detector is then used by downstream IE components, which typically include a coref-erence resolution system and a relation extraction system.",
        "Owing in part to its potentially large influence on downstream IE components, accurate semantic class determination is crucial.",
        "Over the years, NLP researchers have focused on a relatively small number ofsemantic classes in both NE recognition and mention detection: seven classes in the MUC-6 and MUC-7 NE recognition task, four classes in the CoNLL 2002 and 2003 NE recognition shared task, and seven classes in the ACE 2005 mention detection task.",
        "Given that one of the uses of semantic class information is to support NLP applications, it is questionable whether this purpose can be adequately served by such a small number of semantic classes.",
        "For example, given the question \"Which city was the first Olympic Games held in?",
        "\", it would be helpful for a QA system to know which NEs are cities.",
        "However, virtually all of the existing NE recognizers and mention detectors can only determine whether an NE is a location or not.",
        "Our goal in this paper is to tackle the understudied problem of determining fine-grained semantic classes (henceforth semantic subtypes).",
        "More specifically, we aim to classify an NP as one of the 92 fine-grained, domain-independent semantic classes that are determined to be useful for supporting the development of QA and",
        "IE systems in the ACE and AQUAINT programs.",
        "These 92 semantic subtypes have been used to manually annotate the NPs in the BBN Entity Type Corpus (Weischedel and Brunstein, 2005).",
        "Given the availability of this semantic subtype-annotated corpus, we adopt a supervised machine learning approach to semantic subtype determination.",
        "Specifically, given (the boundary of) an NP, we train a classification model to determine which of the 92 semantic subtypes it belongs to.",
        "More importantly, we seek to improve the standard approach to semantic subtype induction described above by proposing two techniques.",
        "The first technique, collective classification, aims to address a common weakness in the standard supervised learning paradigm, where a classifier classifies each instance independently of the others and is unable to exploit any relational information between a pair (or a subset) of the instances that may be helpful for classification.",
        "The second technique, hierarchical classification, exploits the observation that these 92 semantic subtypes can be grouped into a smaller number of coarsegrained semantic types (henceforth semantic supertypes).",
        "With this two-level hierarchy, learning can proceed in a sequential fashion: given an NP, we first determine its semantic supertype and then classify it as one of the semantic subtypes that fall under the predicted supertype in the hierarchy.",
        "Empirical results show that these two techniques, when applied in isolation to the standard learning approach to subtype induction, can significantly improve its accuracy, and the best result is achieved when they are applied in combination.",
        "The rest of the paper is organized as follows.",
        "Section 2 provides an overview of the 92 semantic subtypes and the evaluation corpus.",
        "In Section 3, we present our baseline semantic subtype classification system.",
        "Sections 4 and 5 introduce collective classification and hierarchical classification respectively, and describe how these two techniques can be used to improve the baseline semantic subtype classifier.",
        "We show evaluation results in Section 6 and conclude in Section 7."
      ]
    },
    {
      "heading": "2. Semantic Subtypes",
      "text": [
        "As noted before, each name and nominal in the BBN Entity Type Corpus is annotated with one of the 92 semantic subtypes.",
        "In our experiments, we use all the 200 Penn Treebank Wall Street Journal articles in the corpus, yielding 17,292 NPs that are annotated with their semantic subtypes.",
        "Table 1 presents an overview of these subtypes.",
        "Since they have been manually grouped into 29 supertypes, we also show the supertypes in the table.",
        "More specifically, the first column shows the supertypes, the second column contains abrief description of a supertype, and the last column lists the subtypes that correspond to the supertype in the first column.",
        "In cases where a supertype contains only one subtype (e.g., person), the supertype is not further partitioned into different subtypes; for classification purposes, we simply treat the subtype as identical to its supertype (and hence the two always have the same name).",
        "A detailed description of these supertypes and subtypes can be found in Weischedel and Brunstein (2005).",
        "Finally, we show the class distribution: the parenthesized number after each subtype is the percentage of the 17,292 NPs annotated with the subtype."
      ]
    },
    {
      "heading": "3. Baseline Classification Model",
      "text": [
        "We adopt a supervised machine learning approach to train our baseline classifier for determining the semantic subtype of an NP.",
        "This section describes the details of the training process.",
        "Training corpus.",
        "As mentioned before, we use the Wall Street Journal articles in the BBN Entity Type Corpus for training the classifier.",
        "Training instance creation.",
        "We create one training instance for each annotated NP, np^, which is either a name or a nominal, in each training text.",
        "The classification of an instance is its annotated semantic subtype value, which is one of the 92 semantic subtypes.",
        "Each instance is represented by a set of 33 features, as described below.",
        "1.",
        "Mention String (3): Three features are derived from the string of npj.",
        "Specifically, we employ the NP string as a feature.",
        "If np^ contains more than one token, we create one feature for each of its constituent tokens.",
        "Finally, to distinguish the different senses of a nominal, we create",
        "'As we will see, since we employ an exponential model, an instance may be represented by fewer than 33 features.",
        "a feature whose value is the concatenation of the head of np^ and its WordNet sense number.",
        "2.",
        "Verb String (3): If npi is governed by a verb, the following three features are derived from the governing verb.",
        "First, we employ the string of the governing verb as a feature.",
        "Second, we create a feature whose value is the semantic role of the governing verb.",
        "Finally, to distinguish the different senses of the governing verb, we create a feature whose value is the concatenation of the verb and its WordNet sense number.",
        "Supertype",
        "Brief Description",
        "Subtypes",
        "PERSON",
        "Proper names of people.",
        "Person (9.2).",
        "PERSON DESC",
        "Any head word of a common noun referring to a person or group of people.",
        "Person Desc (16.8).",
        "NORP",
        "This type is named after its subtypes:",
        "Nationality (2.9), Religion (0.1), Political (0.6),",
        "nationality, religion, political, etc.",
        "Other (0.1).",
        "FACILITY",
        "Names of man-made structures, including",
        "Building (0.1), Bridge (0.02), Airport (0.01),",
        "infrastructure, buildings, monuments,",
        "Attraction (0.01), Highway Street (0.05),",
        "camps, farms, mines, ports, etc.",
        "Other (0.1).",
        "FACILITY DESC",
        "Head noun of a noun phrase describing",
        "Building (0.5), Bridge (0.05), Airport (0.01),",
        "buildings, bridges, airports, etc.",
        "Highway Street (0.2), Attraction (0.02), Other (0.5).",
        "ORGANIZATION",
        "Names of companies, government",
        "Government (3.6), Corporation (8.3), Political (0.5),",
        "agencies, educational institutions and",
        "Educational (0.3), Hotel (0.04), City (0.01),",
        "other institutions.",
        "Hospital (0.01), Religious (0.1), Other (0.7).",
        "ORG DESC",
        "Heads of descriptors of companies,",
        "Government (2.1), Corporation (4.3), Political (0.2),",
        "educational institutions and other",
        "Educational (0.1), Religious (0.1), Hotel (0.1),",
        "governments, government agencies, etc.",
        "City (0.01), Hospital (0.02), Other (0.7).",
        "GPE",
        "Names of countries, cities, states,",
        "Country (4.2), City (3.2), State Province (1.4),",
        "provinces, municipalities, boroughs.",
        "Other (0.1).",
        "GPE DESC",
        "Heads of descriptors of countries, cities,",
        "Country (0.8), City (0.3), State Province (0.3),",
        "states, provinces, municipalities.",
        "Other (0.1).",
        "LOCATION",
        "Names of locations other than GPEs.",
        "River (0.03), Lake Sea Ocean (0.05), Region (0.2),",
        "E.g., mountain ranges, coasts, borders,",
        "Continent (0.1), Other (0.2).",
        "planets, geo-coordinates, bodies of water.",
        "PRODUCT",
        "Name of any product.",
        "It does not",
        "Food (0.01), Weapon (0.02), Vehicle (0.2),",
        "include the manufacturer).",
        "Other (0.2).",
        "PRODUCT DESC",
        "Descriptions of weapons and vehicles",
        "Food (0.01), Weapon (0.2), Vehicle (0.97),",
        "only.",
        "Cars, buses, machine guns, missiles,",
        "Other (0.02).",
        "bombs, bullets, etc.",
        "DATE",
        "Classify a reference to a date or period.",
        "Date (7.99), Duration (1.9), Age (0.5), Other (0.4).",
        "TIME",
        "Any time ending with A.M. or P.M.",
        "Time (0.5).",
        "PERCENT",
        "Percent symbol or the actual word percent.",
        "Percent (2.07).",
        "MONEY",
        "Any monetary value.",
        "Money (2.9).",
        "QUANTITY",
        "Used to classify measurements.",
        "E.g., 4",
        "ID (0.11), 2D (0.08), 3D (0.1), Energy (0.01),",
        "miles, 4 grams, 4 degrees, 4 pounds, etc.",
        "Speed (0.01), Weight (0.1), Other (0.04).",
        "ORDINAL",
        "All ordinal numbers.",
        "E.g., First, fourth.",
        "Ordinal (0.6).",
        "CARDINAL",
        "Numerals that provide a count or quantity.",
        "Cardinal (5.1).",
        "EVENT",
        "Named hurricanes, battles, wars, sports events, and other named events.",
        "War (0.03), Hurricane (0.1), Other (0.24).",
        "PLANT",
        "Any plant, flower, tree, etc.",
        "Plant (0.2).",
        "ANIMAL",
        "Any animal class or proper name of an animal, real or fictional.",
        "Animal (0.7).",
        "SUBSTANCE",
        "Any chemicals, elements, drugs, and foods.",
        "E.g., boron, penicillin, plutonium.",
        "Food (1.1), Drug (0.46), Chemical (0.23), Other (0.9).",
        "DISEASE",
        "Any disease or medical condition.",
        "Disease (0.6).",
        "LAW",
        "Any document that has been made into a law.",
        "E.g., Bill of Rights, Equal Rights.",
        "Law (0.5).",
        "LANGUAGE",
        "Any named language.",
        "Language (0.2).",
        "CONTACT INFO",
        "Address, phone.",
        "Address (0.01), Phone (0.04).",
        "GAME",
        "Any named game.",
        "Game (0.1).",
        "WORK OF ART",
        "Titles of books, songs and other creations.",
        "Book (0.16), Play (0.04), Song (0.03), Painting (0.01), Other (0.4).",
        "3.",
        "Semantic (5): We employ five semantic features.",
        "First, if NPi is an NE, we create a feature whose value is the NE label of npi, as determined by the Stanford CRF-based NE recognizer (Finkel et al., 2005).",
        "However, if npi is a nominal, we create a feature that encodes the WordNet semantic class of which it is a hyponym, using the manually determined sense of npi.",
        "Moreover, to improve generalization, we employ a feature whose value is the WordNet synset number of the head noun of a nominal.",
        "If npi has a governing verb, we also create a feature whose value is the WordNet synset number of the verb.",
        "Finally, if npi is a nominal, we create a feature based on its WordNet equivalent concept.",
        "Specifically, for each entity type defined in ACE 2005, we create a list containing all the word-sense pairs in WordNet (i.e., synsets) whose glosses are compatible with that entity type.",
        "Then, given npi and its sense, we use these lists to determine if it belongs to any ACE 2005 entity type.",
        "If so, we create a feature whose value is the corresponding entity type.",
        "4.",
        "Morphological (8).",
        "If npi is a nominal, we create eight features: prefixes and suffixes of length one, two, three, and four.",
        "5.",
        "Capitalization (4): We create four capitalization features to determine whether npi IsAllCap, IsInitCap, IsCapPeriod, and IsAllLower (see Bikel et al.",
        "(1999)).",
        "6.",
        "Gazetteers (8): We compute eight gazetteer-based features, each of which checks whether npi is in a particular gazetteer.",
        "The eight dictionaries contain pronouns (77 entries), common words and words that are not names (399.6k), person names (83.6k), person titles and honorifics (761), vehicle words (226), location names (1.8k), company names (77.6k), and nouns extracted from WordNet that are hyponyms of person (6.3k).",
        "7.",
        "Grammatical (2): We create a feature that encodes the part-of-speech (POS) sequence of npiobtained via the Stanford POS tagger (Toutanova et al., 2003).",
        "In addition, we have a feature that determines whether npi is a nominal or not.",
        "We employ maximum entropy (MaxEnt) mod-eling for training the baseline semantic subtype classifier.",
        "MaxEnt is chosen because it provides a probabilistic classification for each instance, which we will need to perform collective classification, as described in the next section."
      ]
    },
    {
      "heading": "4. Collective Classification",
      "text": [
        "One weakness of the baseline classification model is that it classifies each instance independently.",
        "In particular, the model cannot take into account relationships between them that may be helpful for improving classification accuracy.",
        "For example, if two NPs are the same string in a given document, then it is more likely than not that they have the same semantic subtype according to the \"one sense per discourse\" hypothesis (Gale et al., 1992).",
        "Incorporating this kind of relational information into the feature set employed by the baseline system is not an easy task, since each feature characterizes only a single NP.",
        "To make use of the relational information, one possibility is to design a new learning procedure.",
        "Here, we adopt a different approach: we perform collective classification, or joint probabilistic inference, on the output of the baseline model.",
        "The idea is to treat the output for each NP, which is a probability distribution over the semantic subtypes, as its prior label/class distribution, and convert it into a posterior label/class distribution by exploiting the available relational information as an additional piece of evidence.",
        "For this purpose, we will make use of factor graphs.",
        "In this section, we first give a brief overview of factor graphs, and show how they can be used to perform joint inference for semantic subtype determination.",
        "Factor graphs model optimization problems of an objective function g, which is a real-valued function of n random variables X1; Xn.",
        "We assume that g can be decomposed into a product where each factor fk is a real-valued function of some subset of X1; ... , Xn, denoted as sk (X1; Xn).",
        "Each fk can be thought of as a feature function that computes the compatibility of an assignment of values to the variables in sk (X1; Xn) with respect to a user-defined feature.",
        "Hence, a larger function value is more desirable, as it corresponds to a more compatible assignment of values to the variables involved.",
        "A factor graph consists of two types of nodes: variable nodes and factor nodes.",
        "Each random variable Xi is represented by a variable node, and each factor fk is represented by a factor node.",
        "Each factor node fk is connected only to the nodes corresponding to sk.",
        "This results in a bipartite graph, where edges exist only between a variable node and a factor node.",
        "Given this graph, there are several methods for finding an optimal assignment of the random variables X1, Xn such that the objective function g is maximized.",
        "Exact inference using the sum-product algorithm (Kschischang et al., 2001) is possible if there are no cycles in the graph; otherwise a belief propagation algorithm, such as loopy belief propagation (Murphy et al., 1999), can be applied.",
        "Although there are no cycles in our factor graphs, we choose to use loopy beliefpropagation as our inferencer, since it performs approximate inference and is therefore computationally more efficient than an exact inferencer.",
        "To apply joint inference to semantic subtype induction, we create one factor graph for each test document, where each variable node is random variable Xi over the set of semantic subtype labels L and represents an NP, npi, in the document.",
        "To retain the prior probabilities over the semantic subtype labels lq G L obtained from the baseline classification model, each variable node is given a factor f (Xi) = P(Xi = lq).",
        "If no additional factors that model the relation between two nodes/instances are introduced, maximizing the objective function for this graph (by maximizing the product of factors) will find an assignment identical to the one obtained by taking the most probable semantic subtype label assigned to each instance by the baseline classifier.",
        "Next, we exploit the relationship between two random variables.",
        "Specifically, we want to encourage the inference algorithm to assign the same label to two variables if there exists a relation between the corresponding NPs that can provide strong evidence that they should receive the same label.",
        "To do so, we create a pairwise factor node that connects two variable nodes if the aforementioned relation between the underlying NPs is satisfied.",
        "However, to implement this idea, we need to address two questions.",
        "First, which relation between two NPs can provide strong evidence that they have the same semantic subtype?",
        "We exploit the coreference relation.",
        "Intuitively, the coreference relation is a reasonable choice, as coreferent entities are likely to have the same semantic subtype.",
        "Here, we naively posit two NPs as coreferent if at least one of the following conditions is satisfied: (1) they are the same string after determiners are removed; (2) they are aliases (i.e., one is an acronym or abbreviation of the other); and (3) they are both proper names and have at least one word in common (e.g., \"Delta\" and \"Delta Airlines\").",
        "Second, how can we define a pairwise factor, fpair, so that it encourages the inference algorithm to assign the same label to two nodes?",
        "One possibility is to employ the following definition:",
        "fpair (Xi, Xj )",
        "In essence, fpair prohibits the assignment of different labels to the two nodes it connects.",
        "In our",
        "fpair (Xi, Xj )",
        "experiments, however, we \"improve\" fpair by incorporating semantic supertype information into its definition, as shown below:",
        "= 0 otherwise",
        "In this definition, sup(lq) is the supertype of lqaccording to the semantic type hierarchy shown in Section 2, and Psup(sup(lq)|NPj) is the probability that npj belongs to sup(lq) according to the semantic supertype classification model Psup (see Section 5 for details on how this model can be trained).",
        "In essence, we estimate the joint probability by (1) assuming that the two events are independent, and then (2) computing each event using supertype information.",
        "Intuitively, this definition allows fpair to favor those label assignments that are more compatible with the predictions of Psup.",
        "After graph construction, we apply an inferencer to compute a marginal probability distribution over the labels for each node/instance in the graph by maximizing the objective function g, and output the most probable label for each instance according to its marginal distribution."
      ]
    },
    {
      "heading": "5. Hierarchical Classification",
      "text": [
        "The pairwise factor fpair defined above exploits supertype information in a soft manner, meaning that the most probable label assigned to an NP by an inferencer is not necessarily consistent with its predicted supertype (e.g., an NP may receive Hotel as its subtype even if its supertype is person).",
        "In this section, we discuss how to use supertype information for semantic subtype classification in a hard manner so that the predicted subtype is consistent with its supertype.",
        "To exploit supertype information, we first train a model, Psup, for determining the semantic supertype of an NP using MaxEnt.",
        "This model is trained in essentially the same way as the baseline model described in Section 3.",
        "In particular, it is trained on the same set of instances using the same feature set as the baseline model.",
        "The only difference is that the class value of each training instance is the semantic supertype of the associated NP rather than its semantic subtype.",
        "Next, we train 29 supertype-specific classification models for determining the semantic subtype of an NP.",
        "For instance, the organization-specific classification model will be used to classify an NP as belonging to one of its subtypes (e.g., Government, Corporation, Political agencies).",
        "A supertype-specific classification model is trained much like the baseline model.",
        "Each instance is represented using the same set of features as in the baseline, and its class label is its semantic subtype.",
        "The only difference is that the model is only trained only on the subset of the instances for which it is intended.",
        "For instance, the organization-specific classification model is trained only on instances whose class is a subtype of organization.",
        "After training, we can apply the supertype classification model and the supertype-specific subtype classification model to determine the semantic subtype of an NP in a hierarchical fashion.",
        "Specifically, we first employ the supertype model to determine its semantic supertype.",
        "Then, depending on this predicted semantic supertype, we use the corresponding subtype classification model to determine its subtype."
      ]
    },
    {
      "heading": "6. Evaluation",
      "text": [
        "For evaluation, we partition the 200 Wall Street Journal Articles in the BBN Entity Type corpus into a training set and a test set following a 80/20 ratio.",
        "As mentioned before, each text in the Entity Type corpus has its NPs annotated with their semantic subtypes.",
        "Test instances are created from these texts in the same way as the training instances described in Section 3.",
        "To investigate whether we can benefit from hierarchical and collective classifications, we apply these two techniques to the Baseline classification model in isolation and in combination, resulting in the four sets of results in Tables 2 and 3.",
        "The Baseline results are shown in the second column of Table 2.",
        "Due to space limitations, it is not possible to show the result for each semantic subtype.",
        "Rather, we present semantic supertype results, which are obtained by micro-averaging the corresponding semantic subtype results and are expressed in terms of recall (R), precision (P), and F-measure (F).",
        "Note that only those semantic supertypes with non-zero scores are shown.",
        "As we can see, only 16 of the 29 supertypes have nonzero scores.",
        "Among the \"traditional\" semantic types, the Baseline yields good performance for person, but only mediocre performance for organization and gpe.",
        "While additional experiments are needed to determine the reason, we speculate that this can be attributed to the fact that person and person desc have only one semantic subtype (which is the supertype itself), whereas",
        "organization and gpe have nine and four subtypes, respectively.",
        "The classification accuracy is shown in the last row of the table.",
        "As we can see, the Baseline achieves an accuracy of 81.56.",
        "Results obtained when hierarchical classification is applied to the Baseline are shown in the third column of Table 2.",
        "In comparison to the Baseline, accuracy rises from 81.56 to 82.60.",
        "This represents an error reduction of 5.6%, and the difference between these two accuracies is statistically significant at the p = 0.04 level.",
        "Semantic Supertype",
        "Baseline only RPF",
        "Baseline+Hierarchical RPF",
        "1",
        "PERSON",
        "91.9",
        "89.7",
        "90.8",
        "88.8",
        "91.1",
        "89.9",
        "2",
        "PERSON DESC",
        "91.3",
        "87.8",
        "89.5",
        "92.1",
        "89.8",
        "91.0",
        "3",
        "SUBSTANCE",
        "60.0",
        "66.7",
        "63.2",
        "70.0",
        "58.3",
        "63.6",
        "4",
        "NORP",
        "87.8",
        "90.3",
        "89.0",
        "91.9",
        "90.7",
        "91.3",
        "5",
        "FACILITY DESC",
        "72.7",
        "88.9",
        "80.0",
        "68.2",
        "93.8",
        "79.0",
        "6",
        "ORGANIZATION",
        "76.6",
        "73.8",
        "75.2",
        "78.5",
        "73.2",
        "75.8",
        "7",
        "ORG DESC",
        "75.0",
        "70.7",
        "72.8",
        "75.8",
        "75.2",
        "75.5",
        "8",
        "GPE",
        "75.6",
        "73.9",
        "74.7",
        "77.0",
        "75.4",
        "76.2",
        "9",
        "GPE DESC",
        "60.0",
        "75.0",
        "66.7",
        "70.0",
        "70.0",
        "70.0",
        "10",
        "PRODUCT DESC",
        "53.3",
        "88.9",
        "66.7",
        "53.3",
        "88.9",
        "66.7",
        "11",
        "DATE",
        "85.0",
        "85.0",
        "85.0",
        "84.5",
        "85.4",
        "85.0",
        "12",
        "PERCENT",
        "100.0",
        "100.0",
        "100.0",
        "100.0",
        "100.0",
        "100.0",
        "13",
        "MONEY",
        "83.9",
        "86.7",
        "85.3",
        "88.7",
        "96.5",
        "92.4",
        "14",
        "QUANTITY",
        "22.2",
        "100.0",
        "36.4",
        "66.7",
        "66.7",
        "66.7",
        "15",
        "ORDINAL",
        "100.0",
        "100.0",
        "100.0",
        "100.0",
        "100.0",
        "100.0",
        "16",
        "CARDINAL",
        "96.0",
        "77.4",
        "85.7",
        "94.0",
        "81.0",
        "87.0",
        "Accuracy",
        "81.56",
        "82.60",
        "Semantic Supertype",
        "Baseline+Collective RPF",
        "Baseline+Both RPF",
        "1",
        "PERSON",
        "93.8",
        "98.1",
        "95.9",
        "91.9",
        "100.0",
        "95.8",
        "2",
        "PERSON DESC",
        "93.9",
        "88.5",
        "91.1",
        "92.6",
        "89.5",
        "91.0",
        "3",
        "SUBSTANCE",
        "60.0",
        "85.7",
        "70.6",
        "70.0",
        "63.6",
        "66.7",
        "4",
        "NORP",
        "89.2",
        "93.0",
        "91.0",
        "90.5",
        "94.4",
        "92.4",
        "5",
        "FACILITY DESC",
        "63.6",
        "87.5",
        "73.7",
        "68.2",
        "93.8",
        "79.0",
        "6",
        "ORGANIZATION",
        "85.8",
        "76.2",
        "80.7",
        "87.4",
        "76.3",
        "81.3",
        "7",
        "ORG DESC",
        "75.8",
        "74.1",
        "74.9",
        "75.8",
        "74.6",
        "75.2",
        "8",
        "GPE",
        "74.1",
        "75.8",
        "74.9",
        "81.5",
        "81.5",
        "81.5",
        "9",
        "GPE DESC",
        "60.0",
        "60.0",
        "60.0",
        "70.0",
        "77.8",
        "73.7",
        "10",
        "PRODUCT DESC",
        "53.3",
        "88.9",
        "66.7",
        "53.3",
        "88.9",
        "66.7",
        "11",
        "DATE",
        "85.0",
        "85.4",
        "85.2",
        "85.0",
        "86.3",
        "85.6",
        "12",
        "PERCENT",
        "100.0",
        "100.0",
        "100.0",
        "100.0",
        "100.0",
        "100.0",
        "13",
        "MONEY",
        "83.9",
        "86.7",
        "85.3",
        "90.3",
        "96.6",
        "93.3",
        "14",
        "QUANTITY",
        "22.2",
        "100.0",
        "36.4",
        "66.7",
        "66.7",
        "66.7",
        "15",
        "ORDINAL",
        "100.0",
        "100.0",
        "100.0",
        "100.0",
        "100.0",
        "100.0",
        "16",
        "CARDINAL",
        "96.0",
        "78.7",
        "86.5",
        "94.0",
        "83.9",
        "88.7",
        "Accuracy",
        "83.70",
        "85.08",
        "Results obtained when collective classification alone is applied to the Baseline are shown in the second column of Table 3.",
        "In this case, the prior probability distribution over the semantic subtypes that is needed to create the factor associated with each node in the factor graph is simply the probabilistic classiication of the test instance that the node corresponds to.",
        "In comparison to the Baseline, accuracy rises from 81.56 to 83.70.",
        "This represents an error reduction of 11.6%, and the difference is significant at the p = 0.01 level.",
        "Also, applying collective clas-siication to the Baseline yields slightly better results than applying hierarchical classiication to the Baseline, and the difference in their results is significant at the p = 0.002 level.",
        "Finally, results obtained when both hierarchical and collective classiication are applied to the Baseline are shown in the third column of Table 3.",
        "In this case, the prior distribution needed to create the factor associated with each node in the factor graph is provided by the supertype-speciic classiication model that is used to classify the test instance in hierarchical classiication.",
        "In comparison to the Baseline, accuracy rises from 81.56 to 85.08.",
        "This represents an error reduction of 19.1%, and the difference is highly significant (p < 0.001).",
        "Also, applying both techniques to the Baseline yields slightly better results than applying only collective classiication to the Baseline, and the difference in their results is signii-cant at the p = 0.003 level.",
        "Next, we analyze the effects of the seven feature types described in Section 3 on classiication accuracy.",
        "To measure feature performance, we take the best-performing system (i.e., Baseline combined with both techniques), begin with all seven feature types, and iteratively remove them one by one so that we get the best accuracy.",
        "The results are shown in Table 4.",
        "Across the top line, we list the numbers representing the seven feature classes.",
        "The feature class that corresponds to each number can be found in Section 3, where they are introduced.",
        "For instance, \"2\" refers to the features computed based on the governing verb.",
        "The irst row of results shows the system performance after removing just one feature class.",
        "In this case, removing the sixth feature class (Gazetteers) improves accuracy to 85.6, while removing the mention string features reduces accuracy to 81.4.",
        "The second row repeats this, after removing the gazetteer features.",
        "Somewhat surprisingly, using only mention string, semantic, and grammatical features yields the best accuracy (87.6).",
        "This indicates that gazetteers, morphological features, capitalization, and features computed based on the governing verb are not useful.",
        "Removing the grammatical features yields a 3% drop in accuracy.",
        "After that, accuracy drops by 4% when semantic features are removed, whereas a 18% drop in accuracy is observed when the mention string features are removed.",
        "Hence, our analysis suggests that the mention string features are the most useful features for semantic subtype prediction."
      ]
    },
    {
      "heading": "7. Conclusions",
      "text": [
        "We examined the understudied problem of semantic subtype induction, which involves classifying an NP as one of 92 semantic classes, and showed that two techniques – hierarchical classification and collective classification – can signiicantly improve a baseline classiication model trained using an off-the-shelf learning algorithm on the BBN Entity Type Corpus.",
        "In particular, collective classiication addresses a major weakness of the standard feature-based learning paradigm, where a classiication model classi-ies each instance independently, failing to capture the relationships among subsets of instances that might improve classiication accuracy.",
        "However, collective classiication has not been extensively applied in the NLP community, and we hope that our work can increase the awareness of this powerful technique among NLP researchers.",
        "1",
        "3",
        "7",
        "4",
        "2",
        "5",
        "6",
        "81.4",
        "75.8",
        "83.3",
        "83.7",
        "84.1",
        "85.2",
        "85.6",
        "80.4",
        "74.9",
        "84.3",
        "85.3",
        "85.3",
        "86.1",
        "80.4",
        "78.3",
        "83.9",
        "86.5",
        "86.7",
        "81.8",
        "76.2",
        "85.2",
        "87.6",
        "75.4",
        "83.4",
        "84.6",
        "66.2",
        "80.9"
      ]
    },
    {
      "heading": "Acknowledgments",
      "text": [
        "We thank the three anonymous reviewers for their invaluable comments on an earlier draft of the paper.",
        "This work was supported in part by NSF Grant IIS-0812261."
      ]
    }
  ]
}
