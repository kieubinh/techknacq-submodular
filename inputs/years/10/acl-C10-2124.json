{
  "info": {
    "authors": [
      "Germán Sanchis",
      "Francisco Casacuberta"
    ],
    "book": "COLING – POSTERS",
    "id": "acl-C10-2124",
    "title": "Log-linear weight optimisation via Bayesian Adaptation in Statistical Machine Translation",
    "url": "https://aclweb.org/anthology/C10-2124",
    "year": 2010
  },
  "references": [
    "acl-C04-1059",
    "acl-J09-1002",
    "acl-J93-2003",
    "acl-N03-1017",
    "acl-P02-1038",
    "acl-P03-1021",
    "acl-P07-2045",
    "acl-P08-1012",
    "acl-W04-3225",
    "acl-W07-0722",
    "acl-W07-0733",
    "acl-W09-0432"
  ],
  "sections": [
    {
      "text": [
        "Log-linear weight optimisation via Bayesian Adaptation in Statistical",
        "Machine Translation",
        "German Sanchis-Trilles and Francisco Casacuberta",
        "Departamento de Sistemas Informaticos y Computation Instituto Tecnologico de Informatica Universidad Politecnica de Valencia {gsanchis,fcn} @dsic.upv.es",
        "We present an adaptation technique for statistical machine translation, which applies the well-known Bayesian learning paradigm for adapting the model parameters.",
        "Since state-of-the-art statistical machine translation systems model the translation process as a log-linear combination of simpler models, we present the formal derivation of how to apply such paradigm to the weights of the log-linear combination.",
        "We show empirical results in which a small amount of adaptation data is able to improve both the non-adapted system and a system which optimises the above-mentioned weights on the adaptation set only, while gaining both in reliability and speed."
      ]
    },
    {
      "heading": "1. Introduction",
      "text": [
        "The adaptation problem is a very common issue in statistical machine translation (SMT), where it is frequent to have very large collections ofbilingual data belonging to e.g. proceedings from international entities such as the European Parliament or the United Nations.",
        "However, if we are currently interested in translating e.g. printer manuals or news data, we will need to find a way in which we can take advantage of such data.",
        "The grounds of modern SMT were established in (Brown et al., 1993), where the machine translation problem was defined as follows: given a sentence f from a certain source language, an equivalent sentence ê in a given target language that maximises the posterior probability is to be found.",
        "According to the Bayes decision rule, such statement can be specified as follows:",
        "Recently, a direct modelling of the posterior probability Pr(e|f ) has been widely adopted, and, to this purpose, different authors (Papineni et al., 1998; Och and Ney, 2002) proposed the use of the so-called log-linear models, where and the decision rule is given by the expression where hk (f, ê) is a score function representing an important feature for the translation of f into ê, as for example the language model of the target language, a reordering model or several translation models.",
        "K is the number of models (or features) and Xk are the weights of the log-linear combination.",
        "Typically, the weights A = [X1;..., XK]Tare optimised with the use of a development set.",
        "The use of log-linear models implied an important breakthrough in SMT, allowing for a significant increase in the quality of the translations produced.",
        "In this work, we present a Bayesian technique for adapting the weights of such log-linear models according to a small set of adaptation data.",
        "In this paper, we will be focusing on adapting the weights vector A, since appropriate values of such vector for a given domain do not necessarily imply a good combination in other domains.",
        "One naive way in which some sort of adaptation can be performed on is to re-estimate these weights from scratch only on the adaptation data.",
        "However, such re-estimation may not be a good idea, whenever the amount of adaptation data available is not too big.",
        "On the one hand, because small amounts of adaptation data may easily yield overtrained values of A, which may even lead to a degradation of the translation quality.",
        "On the other hand, because in some scenarios it is not feasible to re-estimate them because of the time it would take.",
        "Moreover, considering a re-estimation of A by using both the out-of-domain data and the adaptation set would not be appropriate either.",
        "For small amounts of adaptation data, such data would have no impact on the final value of A, and the time required would be even higher.",
        "One such situation may be the Interactive Machine Translation (IMT) paradigm (Barrachina et al., 2009), in which a human translator may start translating a new document, belonging to a specific domain, and the system is required to produce an appropriate output as soon as possible without any prior re-training.",
        "In this paper, a Bayesian adaptation approach solving both problems is presented.",
        "Nevertheless, adapting A constitutes just a first step towards the adaptation of all the parameters of the SMT model.",
        "The rest of this paper is structured as follows.",
        "In next Section, we perform a brief review of current approaches to adaptation and Bayesian learning in SMT.",
        "Section 3 describes the typical framework for phrase-based translation in SMT.",
        "In Section 4, we present the way in which we apply Bayesian adaptation (BA) to log-linear models in SMT.",
        "In Section 5, we describe the practical approximations applied before implementing the BA technique described.",
        "In Section 6, experimental design and results are detailed.",
        "Conclusions and future work are explained in Section 7."
      ]
    },
    {
      "heading": "2. Related work",
      "text": [
        "Adaptation in SMT is a research field that is receiving an increasing amount of attention.",
        "In (Nepveu et al., 2004), adaptation techniques were applied to IMT, following the ideas by (Kuhn and Mori, 1990) and adding cache language models (LM) and TMs to their system.",
        "In (Koehn and Schroeder, 2007), different ways to combine available data belonging to two different sources was explored; in (Bertoldi and Federico, 2009) similar experiments were performed, but considering only additional source data.",
        "In (Civera and Juan, 2007), alignment model mixtures were explored as a way of performing topic-specific adaptation.",
        "Other authors (Zhao et al., 2004; Sanchis-Trilles et al., 2009), have proposed the use of clustering in order to extract sub-domains of a large parallel corpus and build more specific LMs and TMs, which are recombined in test time.",
        "With respect to BA in SMT, the authors are not aware of any work up to the date that follows such paradigm.",
        "Nevertheless, there have been some recent approaches towards dealing with SMT from the Bayesian learning point of view.",
        "In (Zhang et al., 2008), Bayesian learning was applied for estimating word-alignments within a synchronous grammar."
      ]
    },
    {
      "heading": "3. Phrase-based SMT",
      "text": [
        "One of the most popular instantiations of loglinear models in SMT are phrase-based (PB) models (Zens et al., 2002; Koehn et al., 2003).",
        "PB models allow to capture contextual information to learn translations for whole phrases instead of single words.",
        "The basic idea of PB translation is to segment the source sentence into phrases, then to translate each source phrase into a target phrase, and finally reorder the translated target phrases in order to compose the target sentence.",
        "For this purpose, phrase-tables are produced, in which a source phrase is listed together with several target phrases and the probability of translating the former into the latter.",
        "PB models were employed throughout this work.",
        "Typically, the weights of the log-linear combination in Equation 3 are optimised by means of Minimum Error Rate Training (MERT) (Och, 2003).",
        "Such algorithm consists of two basic steps.",
        "First, n-best hypotheses are extracted for each one of the sentences of a given development set.",
        "Next, the optimum A is computed so that the best hypotheses in the n-best list, according to a reference translation and a given metric, are ranked higher within such n-best list.",
        "These two steps are repeated until convergence.",
        "This approach has two main problems.",
        "On the one hand, that it heavily relies on having a fair amount of data available as development set.",
        "On the other hand, that it only relies on the data in the development set.",
        "These two problems have as consequence that, if the development set made available to the system is not big enough, MERT will most likely become unstable and fail in obtaining an appropriate weight vector A.",
        "However, it is quite common to have a great amount of data available in a given domain, but only a small amount from the specific domain we are interested in translating.",
        "Precisely this scenario is appropriate for BA: under this paradigm, the weight vector A is biased towards the optimal one according to the adaptation set, while avoiding over-training towards such set by not forgetting the generality provided by the training set.",
        "Furthermore, recomputing A from scratch by means of MERT may imply a computational overhead which may not be acceptable in certain environments, such as SMT systems configured for online translation, IMT or Computer Assisted Translation, in which the final human user is waiting for the translations to be produced."
      ]
    },
    {
      "heading": "4. Bayesian adaptation for SMT",
      "text": [
        "The main idea behind Bayesian learning (Duda et al., 2001; Bishop, 2006) is that model parameters are viewed as random variables having some kind of a priori distribution.",
        "Observing these random variables leads to a posterior density, which typically peaks at the optimal values of these parameters.",
        "Following the notation in Equation 1, previous statement is specified as where T represents the complete training set and 9 are the model parameters.",
        "However, since we are interested in Bayesian adaptation, we need to consider one training set T and one adaptation set A, leading to",
        "In Equation 5, the integral over the complete parametric space forces the model to take into account all possible values of the model parameters, although the prior over the parameters implies that our model will prefer parameter values which are closer to our prior knowledge.",
        "Two assumptions have been made: first, that the output sentence ê only depends on the model parameters (and not on the complete training and adaptation data).",
        "Second, that the model parameters do not depend on the actual input sentence f. Such simplifications lead to a decomposition of the integral in two parts: the first one, p(9|T, A) will assess how good the current model parameters are, and the second one, p(ê|f, 9), will account for the quality of the translation ê given the current model parameters.",
        "Then, the decision rule given in Equation 1 is redefined as",
        "Operating with the probability of 9, we obtain:",
        "where the probability of the adaptation data has been assumed to be independent of the training data and has been modelled as the probability of each bilingual sample (fa, êa ) G A being generated by our translation model.",
        "Assuming that the model parameters depend on the training data and follow a normal distribution, we obtain where 9T is the set of parameters estimated on the training set and the variance has been assumed to be bounded for all parameters.",
        "d is the dimensionality of9.",
        "Lastly, assuming that our translation model is a log-linear model as described in Equation 3 and that the only parameters we want to adapt are the log-linear weights:",
        "where the model parameters 9 have been instantiated to include only the log-linear weights A.",
        "Finally, combining Equations 8, 9 and 10, and considering only as model parameters the loglinear weights, we obtain:",
        "expE k Xk fk (fa, ê') exp k Xk fk(f, ê)",
        "Ee' expE k Xk fk (f, ê' )",
        "where Z is the denominator present in the previous equation and may be factored out because it does not depend on the integration variable.",
        "It has also been assumed that p(fa|9) is uniform and can also be factored out."
      ]
    },
    {
      "heading": "5. Practical approximations",
      "text": [
        "Although the integral described in Equation 11 is the right thing to do from the theoretical point of view, there are several issues which need to be treated first before implementing it.",
        "Since computing the integral over the complete parametric space is computationally impossible in the case of SMT, we decided to perform a Monte Carlo like sampling of these parameters by assuming that the parameters follow a normal distribution centred in AT, the weight vector obtained from the training data.",
        "This sampling was done by choosing alternatively only one of the weights in At , modifying it randomly within a given interval, and renormalising accordingly.",
        "Equation 11 is approximated in practise as",
        "AmeMC (At )",
        "where MC (AT) is the set of A m weights generated by the above-mentioned procedure.",
        "There is still one issue when trying to implement Equation 11.",
        "The denominator within the components p(A|A; T) and p(ê|f,A) contains a sum over all possible sentences of the target language, which is not computable.",
        "For this reason,",
        "e' is approximated as the sum over all the hypothesis within a given n-best list.",
        "Moreover, instead of performing a full search of the best possible translation of a given input sentence, we will perform a rerank of the n-best list provided by the decoder according to Equation 11.",
        "Typical state-of-the-art PB SMT systems do not guarantee complete coverage of all possible sentence pairs due to the great number of heuristic decisions involved in the estimation of the translation models.",
        "Moreover, out-of-vocabulary words may imply that the SMT model is unable to explain a certain bilingual sentence completely.",
        "Hence, p(A| A; T) is approximated as expE k Xk fk (fa,",
        "Ee' expE k Xk fk (fa, ê')",
        "where ê* represents the best hypothesis the search algorithm is able to produce, according to a given translation quality measure.",
        "As in Equation 11, p(fa|9) has been assumed uniform.",
        "Once the normalisation factor within Equation 7 has been removed, and the above-mentioned approximations have been introduced, p(ê|f ; T, A) is no longer a probability.",
        "This fact cannot be underestimated, since it means that the terms p(A|A; T) and p(ê|f,A) on the one hand, and p(A|T) on the other, may have very different numeric ranges.",
        "For this reason, and in order to weaken the influence of this fact, we introduce a leveraging term 5, such that",
        "Although there are other, more standard, ways of adding this leveraging term, we chose this one for numeric reasons."
      ]
    },
    {
      "heading": "6. Experiments",
      "text": [
        "Translation quality will be assessed by means of BLEU and TER scores.",
        "BLEU measures n-gram precision with a penalty for sentences that are too short (Papineni et al., 2001), whereas TER (Snover et al., 2006) is an error metric that thousands/millions of elements.",
        "_I Spanish English |",
        "Table 2: Main figures of the News-Commentary test sets.",
        "OoV stands for Out of Vocabulary words with respect to the Europarl corpus.",
        "computes the minimum number of edits required to modify the system hypotheses so that they match the references.",
        "Possible edits include insertion, deletion, substitution of single words and shifts of word sequences.",
        "For computing ê* as described in Equation 12, TER was used, since BLEU implements a geometrical average which is zero whenever there is no common 4-gram between reference and hypothesis.",
        "Hence, it is not well suited for our purposes since the complete set of n-best candidates provided by the decoder can score zero.",
        "As a first baseline system, we trained a SMT system on the Europarl Spanish-English training data, in the partition established in the Workshop 2006), using the training and development data provided that year.",
        "The Europarl corpus (Koehn, 2005) is built from the transcription of European Parliament speeches published on the web.",
        "Statistics are provided in Table 1.",
        "We used the open-source MT toolkit Moses (Koehn et al., 2007) in its default monotonic setup, and estimated the weights of the log-linear combination using MERT on the Europarl development set.",
        "A 5-gram LM with interpolation and Kneser-Ney smoothing (Kneser and Ney, 1995) was also estimated.",
        "Since our purpose is to adapt the initial weight vector obtained during the training stage (i.e. the one obtained after running MERT on the Eu-roparl development set), the tests sets provided for the 2008 and 2010 evaluation campaigns of the above-mentioned workshop (Table 2) were also used.",
        "These test sets, unlike the one provided in 2006, were extracted from a news data corpus, and can be considered out of domain if the system has been trained on Europarl data.",
        "All the experiments displaying BA results were carried out by sampling a total of 100 random weights, according to preliminary investigation, following the procedure described in Section 5.",
        "For doing this, one single weight was added a random amount between 0.5 and -0.5, and then the whole A was re-normalised.",
        "With the purpose of providing robustness to the results, every point in each plot of this paper constitutes the average of 10 repetitions, in which the adaptation data was randomly drawn from the News-Commentary test set 2008.",
        "The effect of increasing the number of adaptation samples made available to the system was investigated.",
        "The adaptation data was used either for estimating A using MERT, or as adaptation sample for our BA technique.",
        "Results can be seen in Figure 1.",
        "The 5 scaling factor described in Equation 13 was set to 8.",
        "As it can be seen, the BA adaptation technique is able to improve consistently the translation quality obtained by the non-adapted system, both in terms of BLEU and TER.",
        "These improvements are quite stable even with as few as 10 adaptation samples.",
        "This result is very interesting, since re-estimating A by means of MERT is only able to yield improvements when provided with at least 100 adaptation samples, displaying a very chaotic behaviour until that point.",
        "In order to get a bit more insight about this chaotic behaviour, confidence interval sizes are shown in Figure 2, at a 95% confidence level, resulting of the repetitions described above.",
        "MERT yields very large confidence intervals (as large as 10 TER/BLEU points for less than 100 samples), turning a bit more stable from that point on, where the size of the confidence interval converges slowly to 1 TER/BLEU point.",
        "In contrast,",
        "Spanish",
        "English",
        "Sentences",
        "731K",
        "Training",
        "Run.",
        "words",
        "15.7M",
        "15.2M",
        "Vocabulary",
        "103K",
        "64K",
        "Sentences",
        "2K",
        "Development",
        "Run.",
        "words",
        "61K",
        "59K",
        "OoV words",
        "208",
        "127",
        "Sentences",
        "2051",
        "Test 2008",
        "Run.",
        "words",
        "50K",
        "53K",
        "OoV.",
        "words",
        "1247",
        "1201",
        "Sentences",
        "2489",
        "Test 2010",
        "Run.",
        "words",
        "62K",
        "66K",
        "OoV.",
        "words",
        "1698",
        "1607",
        "Number of adaptation samples",
        "Figure 1: Comparison of translation quality, as measured by BLEU and TER, for baseline system, adapted systems by means of BA and MERT.",
        "Increasing number of samples is considered.",
        "Number of adaptation samples Number of adaptation samples",
        "adaptation samples.",
        "For visibility purposes, both axes are in logarithmic scale.",
        "our BA technique yields very small confidence intervals, about half a TER/BLEU point in the worst case, with only 10 adaptation samples.",
        "This is worth emphasising, since estimating A by means of MERT when very few adaptation data is available may improve the final translation quality, but may also degrade it to a much larger extent.",
        "In contrast, our BA technique shows stable and reliable improvements from the very beginning.",
        "Precisely under such circumstances is an adaptation technique useful: when the amount of adaptation data is small.",
        "In other cases, the best thing one can do is to re-estimate the model parameters from scratch.",
        "Example translations, extracted from the experiments detailed above, are shown in Figure 5.",
        "So as to understand the role of scaling factor 5, results obtained varying it are shown in Figure 3.",
        "Several things should be noted about these plots:",
        "• Increasing 5 leads to smoother adaptation curves.",
        "This is coherent with the confidence interval sizes shown in Figure 1.",
        "• Smaller values of 5 lead to a slight degradation in translation quality when the amount of adaptation samples becomes larger.",
        "The reason for this can be explained by looking at Equation 13.",
        "Since p(A|A; T) is implemented as a product of probabilities, the more adaptation samples the smaller becomes p(A| A; T), and a higher value of 5 is needed to compensate this fact.",
        "This suggests the need of a 5 which depends on the size of the adaptation sample.",
        "• Larger values of 5 do not suffer the problem described above, but yield smaller improvements in terms of translation quality for smaller amount of samples.",
        "^^^^^-^*=-*=^-+",
        "■",
        "X",
        "j\\",
        "X",
        "fx",
        "i l",
        "BA 5 = 8 – i – mert – -x – baseline -------",
        "Number of adaptation samples",
        "It might seem odd that translation quality as measured by BLEU drops almost constantly as the number of adaptation samples increases.",
        "However, it must be noted that the BA technique implemented is set to optimise TER, and not BLEU.",
        "Analysing the BLEU scores obtained, we realised that the n-gram precision does increase, but the final BLEU score drops because of a worsening brevity penalty, which is not taken into account when optimising the TER score.",
        "The effect of increasing the order of n-best considered was also analysed.",
        "In order to avoid an overwhelming amount of results, only those obtained when considering 100 adaptation samples are displayed in Figure 4.",
        "As it can be seen, TER drops monotonically for all ö values, until about 800, where it starts to stabilise.",
        "Similar behaviour is observed in the case of BLEU, although depending on ö the curve shows an improvement or a degradation.",
        "Again, this is due to the brevity penalty, which TER does not implement, and which induces this inverse correlation between TER and BLEU when optimising TER."
      ]
    },
    {
      "heading": "7. Conclusions and future work",
      "text": [
        "We have presented a Bayesian theoretical framework for adapting the parameters of a SMT system.",
        "We have derived the equations needed to implement BA of the log-linear weights of a SMT system, and present promising results with a state-of-the-art SMT system using standard corpora in SMT.",
        "Such results prove that the BA framework can be very effective when adapting the mentioned weights.",
        "Consistent improvements are obtained over the baseline system with as few as 10 adaptation samples.",
        "The BA technique implemented is able to yield results comparable with a complete re-estimation of the parameters even when the amount of adaptation data is sufficient for such re-estimation to be feasible.",
        "Experimental results show that our adaptation technique proves to be much more stable than MERT, which relies very heavily on the amount of adaptation data and turns very unstable whenever few adaptation samples are available.",
        "It should be emphasised that an adaptation technique, by nature, is only useful whenever few adaptation data is available, and our technique proves to behave well in such context.",
        "Intuitively, the BA technique presented needs first to compute a set of random weights, which are the result of sampling a gaussian distribution whose mean is the best weight vector obtained in training.",
        "Then, each hypothesis of a certain test source sentence is rescored according to the following three components:",
        "• The probability of the adaptation corpus under each specific random weight",
        "• The probability of such random weight according to a prior over the weight vector",
        "• The probability of the current hypothesis under those weights",
        "Concerning computational time, our adaptation technique can easily be implemented within the decoder itself, without any significant increase in computational complexity.",
        "We consider this im-",
        "i • • •« _ .",
        "_",
        "■ \\ Vv",
        "5 = 1 – i – \\ *",
        "' 5 = 2 – x – ",
        "5 = 4 – *--",
        "■ 5 = 8 b",
        "5 = 16 – ■ – ",
        "5 = 32 – o – ",
        "Order of n-best considered Order of n-best considered",
        "source reference baseline BAs10 BA s600 MERT s10",
        "source reference baseline en afganistan , barack obama espera que se repita el milagro .",
        "barack obama hopes that, in afghanistan , the miracle will repeat itself .",
        "in afghanistan , barack obama waiting to be repeated the miracle .",
        "in afghanistan , barack obama expected to repeat the miracle .",
        "in afghanistan , barack obama expected to repeat the miracle .",
        "in afghanistan , barack obama expected to repeat of the miracle .",
        "in afghanistan , barack obama hopes that a repetition of the miracle .",
        "al final todo fue mas rpido de lo que se penso .",
        "it all happened a lot faster than expected .",
        "at the end of all was more quickly than we thought .",
        "ultimately everything was more quickly than we thought .",
        "ultimately everything was more quickly than we though .",
        "the end all was quicker than i thought .",
        "ultimately everything was quicker than i thought .",
        "Figure 5: Example of translations found in the corpus.",
        "s10 means that only 10 adaptation samples were considered, whereas s600 means that 600 were considered.",
        "portant, since it implies that rerunning MERT for each adaptation set is not needed, and this is important whenever the final system is set up in an on-line environment.",
        "The derivation presented here can be easily extended in order to adapt the feature functions of the log-linear model (i.e. not the weights).",
        "This is bound to have a more important impact on translation quality, since the amount of parameters to be adapted is much higher.",
        "We plan to address this issue in future work.",
        "In addition, very preliminary experiments show that, when considering reordering, the advantages described here are larger.",
        "A preliminary version of the present paper was accepted at the Joint IAPR International Workshops on Structural and Syntactic Pattern Recognition and Statistical Techniques in Pattern Recognition 2010.",
        "The main contributions of the present paper constitute more extensive experiments, which have been conducted on standard SMT corpora.",
        "Furthermore, in this paper we present the results of adding the leveraging term ö, of applying a random, Monte-Carlo like weight sampling (which was not done previously), and an extensive analysis of the effect of varying the order of n-best considered.",
        "We also plan to implement Markov Chain Monte Carlo for sampling the parameters, and analyse the effect of combining the in-domain and out of domain data for MERT.",
        "Such results were not included here for time constraints."
      ]
    },
    {
      "heading": "Acknowledgments",
      "text": [
        "This paper is based upon work supported by the EC (FEDER/FSE) and the Spanish MICINN under the MIPRCV \"Consolider Ingenio 2010\" program (CSD2007-00018) and the iTrans2 (TIN2009-14511) project.",
        "Also supported by the Spanish MITyC under the erudito.com (TSI-020110-2009-439) project and by the Generalitat Valenciana under grant Prometeo/2009/014.",
        "The authors would like to thank the anonimous reviewers for their constructive comments.",
        "5 = 1",
        "-1-",
        "58.1 <",
        "5 = 2 5 = 4",
        " – -x- – – x - -",
        "58 '",
        "s. a.",
        "5 = 8",
        "5 = 16",
        "---■ – ",
        "57.9",
        "-",
        "^ m",
        "5 = 32",
        " – ",
        "---o – ",
        "---G-----{ ---■- – -__.",
        "57.8",
        "57.7 57.6"
      ]
    }
  ]
}
