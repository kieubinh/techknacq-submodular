{
  "info": {
    "authors": [
      "Minh-Thang Luong",
      "Preslav Nakov",
      "Min-Yen Kan"
    ],
    "book": "EMNLP",
    "id": "acl-D10-1015",
    "title": "A Hybrid Morpheme-Word Representation for Machine Translation of Morphologically Rich Languages",
    "url": "https://aclweb.org/anthology/D10-1015",
    "year": 2010
  },
  "references": [
    "acl-D07-1091",
    "acl-D09-1141",
    "acl-E06-1006",
    "acl-H05-1085",
    "acl-J04-4002",
    "acl-N03-1017",
    "acl-N04-4015",
    "acl-N06-2013",
    "acl-P02-1040",
    "acl-P03-1021",
    "acl-P05-1066",
    "acl-P07-1108",
    "acl-P07-2045",
    "acl-P08-1059",
    "acl-P08-1087",
    "acl-P08-2039",
    "acl-P09-1106",
    "acl-W05-0820",
    "acl-W07-0704",
    "acl-W09-0401",
    "acl-W09-0405",
    "acl-W09-0428",
    "acl-W09-0429",
    "acl-W09-0430"
  ],
  "sections": [
    {
      "text": [
        "A Hybrid Morpheme-Word Representation for Machine Translation of Morphologically Rich Languages*",
        "Minh-Thang Luong Preslav Nakov Min-Yen Kan",
        "We propose a language-independent approach for improving statistical machine translation for morphologically rich languages using a hybrid morpheme-word representation where the basic unit of translation is the morpheme, but word boundaries are respected at all stages of the translation process.",
        "Our model extends the classic phrase-based model by means of (1) word boundary-aware morpheme-level phrase extraction, (2) minimum error-rate training for a morpheme-level translation model using word-level BLEU, and (3) joint scoring with morpheme-and word-level language models.",
        "Further improvements are achieved by combining our model with the classic one.",
        "The evaluation on English to Finnish using Europarl (714K sentence pairs; 15.5M English words) shows statistically significant improvements over the classic model based on BLEU and human judgments."
      ]
    },
    {
      "heading": "1. Introduction",
      "text": [
        "The fast progress of statistical machine translation (SMT) has boosted translation quality significantly.",
        "While research keeps diversifying, the word remains the atomic token-unit of translation.",
        "This is fine for languages with limited morphology like English and French, or no morphology at all like Chinese, but it is inadequate for morphologically rich languages like Arabic, Czech or Finnish (Lee, 2004; Goldwater and McClosky, 2005; Yang and Kirchhoff, 2006).",
        "This research was sponsored in part by CSIDM (grant # 200805) and by a National Research Foundation grant entitled \"Interactive Media Search\" (grant # R-252-000-325-279).",
        "There has been a line of recent SMT research that incorporates morphological analysis as part of the translation process, thus providing access to the information within the individual words.",
        "Unfortunately, most of this work either relies on language-specific tools, or only works for very small datasets.",
        "Below we propose a language-independent approach to SMT of morphologically rich languages using a hybrid morpheme-word representation where the basic unit of translation is the morpheme, but word boundaries are respected at all stages of the translation process.",
        "We use unsupervised morphological analysis and we incorporate its output into the process of translation, as opposed to relying on preprocessing and post-processing only as has been done in previous work.",
        "The remainder of the paper is organized as follows.",
        "Section 2 reviews related work.",
        "Sections 3 and 4 present our morphological and phrase merging enhancements.",
        "Section 5 describes our experiments, and Section 6 analyzes the results.",
        "Finally, Section 7 concludes and suggests directions for future work."
      ]
    },
    {
      "heading": "2. Related Work",
      "text": [
        "Most previous work on morphology-aware approaches relies heavily on language-specific tools, e.g., the TreeTagger (Schmid, 1994) or the Buckwalter Arabic Morphological Analyzer (Buckwalter, 2004), which hampers their portability to other languages.",
        "Moreover, the prevalent method for incorporating morphological information is by heuristically-driven pre-or post-processing.",
        "For example, Sadat and Habash (2006) use different combinations of Arabic preprocessing schemes for Arabic-English SMT, whereas Oflazer and El-Kahlout (2007) post-processes Turkish morphemelevel translations by re-scoring n-best lists with a word-based language model.",
        "These systems, however, do not attempt to incorporate their analysis as part of the decoding process, but rather rely on models designed for word-token translation.",
        "We should also note the importance of the translation direction: it is much harder to translate from a morphologically poor to a morphologically rich language, where morphological distinctions not present in the source need to be generated in the target language.",
        "Research in translating into morphologically rich languages, has attracted interest for languages like Arabic (Badr et al., 2008), Greek (Avramidis and Koehn, 2008), Hungarian (Novak, 2009; Koehn and Haddow, 2009), Russian (Toutanova et al., 2008), and Turkish (Oflazer and El-Kahlout, 2007).",
        "These approaches, however, either only succeed in enhancing the performance for small bi-texts (Badr et al., 2008; Oflazer and El-Kahlout, 2007), or improve only modestly for large bi-texts."
      ]
    },
    {
      "heading": "3. Morphological Enhancements",
      "text": [
        "We present a morphologically-enhanced version of the classic phrase-based SMT model (Koehn et al., 2003).",
        "We use a hybrid morpheme-word representation where the basic unit of translation is the morpheme, but word boundaries are respected at all stages of the translation process.",
        "This is in contrast with previous work, where morphological enhancements are typically performed as pre-/post-processing steps only.",
        "In addition to changing the basic translation token unit from a word to a morpheme, our model extends the phrase-based SMT model with the following:"
      ]
    },
    {
      "heading": "1.. word boundary-aware morpheme-level phrase extraction;",
      "text": [
        "2. minimum error-rate training for a morphemelevel model using word-level BLEU;",
        "3. joint scoring with morpheme-and word-level language models.",
        "We first introduce our morpheme-level representation, and then describe our enhancements.",
        "Our morphological representation is based on the output of an unsupervised morphological analyzer.",
        "Following Virpioja et al.",
        "(2007), we use Morfessor, which is trained on raw tokenized text (Creutz and Lagus, 2007).",
        "The tool segments words into morphemes annotated with the following labels: PRE (prefix), STM (stem), SUF (suffix).",
        "Multiple prefixes and suffixes can be proposed for each word; word compounding is allowed as well.",
        "The output can be described by the following regular expression:",
        "WORD = ( PRE* STM SUF* )+ For example, uncarefully is analyzed as un/PRE+ care/STM+ ful/SUF+ ly/SUF",
        "The above token sequence forms the input to our system.",
        "We keep the PRE/STM/SUF tags as part ofthe tokens, and distinguishbetweencare/STM+ and care/STM.",
        "Note also that the \"+\" sign is appended to each nonfinal tag so that we can distinguish word-internal from word-final morphemes.",
        "The core translation structure of a phrase-based SMT model is the phrase table, which is learned from a bilingual parallel sentence-aligned corpus, typically using the alignment template approach (Och and Ney, 2004).",
        "It contains a set of bilingual phrase pairs, each associated with five scores: forward and backward phrase translation probabilities, forward and backward lexicalized translation probabilities, and a constant phrase penalty.",
        "The maximum phrase length n is normally limited to seven words; higher values of n increase the table size exponentially without actually yielding performance benefit (Koehn et al., 2003).",
        "However, things are different when translating with morphemes, for two reasons: (1) morpheme-token phrases of length n can span less than n words; and (2) morpheme-token phrases may only partially span words.",
        "The first point means that morpheme-token phrase pairs span fewer word tokens, and thus cover a smaller context, which may result in fewer total extracted pairs compared to a word-level approach.",
        "Figure 1 shows a case where three Finnish words consist of nine morphemes.",
        "Previously, this issue was addressed by simply increasing the value of n when using morphemes, which is of limited help.",
        "SRC = theSTM newSTM , uripRE+ democraticSTM immigrationSTM policysTM TGT = uusiSTM , epäPRE+demokraatSTM+ tSUF+ iSUF+sSUF+enSUFmaahanmuuttoPRE+ politiikanSTM (uusi=new , epädemo/craaff/sen=undemocratic maa/7anmuuffopo//f///can=immigration policy)",
        "Figure 1: Example of English-Finnish bilingual fragments morphologically segmented by Morfessor.",
        "Solid links represent IBM Model 4 alignments at the morpheme-token level.",
        "Translation glosses for Finnish are given below.",
        "The second point is more interesting: morphemelevel phrases may span words partially, making them potentially usable in translating unknown inflected forms of known source language words, but also creates the danger of generating sequences of morphemes that are not legal target language words.",
        "For example, let us consider the phrase in Figure 1: unpRE+ democraticSTM.",
        "The original algorithm will extract the spurious phrase epäpRE+ demokraatSTM+ tSUF+ iSUF+ ssuf+, beside the correct one that has enSUF appended at the end.",
        "Such a spurious phrase does not generally help in translating unknown inflected forms, especially for morphologically-rich languages that feature multiple affixes, but negatively affects the translation model in terms of complexity and quality.",
        "We solve both problems by modifying the phrase-pair extraction algorithm so that morpheme-token phrases can extend longer than n, as long as they span n words or less.",
        "We further require that word boundaries be respected, i.e., morpheme-token phrases span a sequence ofwhole words.",
        "This is a fair extension of the morpheme-token system with respect to a word-token one since both are restricted to span up to n word-tokens.",
        "Word-Token BLEU",
        "Modern phrase-based SMT systems use a log-linear model with the following typical feature functions: language model probabilities, word penalty, distortion cost, and the five parameters from the phrase table.",
        "Their weights are set by optimizing BLEU score (Papineni et al., 2001) directly using minimum error rate training (MERT), as suggested by Och (2003).",
        "In previous work, phrase-based SMT systems using morpheme-token input/output naturally performed MERT at the morpheme-token level as well.",
        "This is not optimal since the final expected system output is a sequence of words, not morphemes.",
        "The main danger is that optimizing a morpheme-token BLEU score could lead to a suboptimal weight for the word penalty feature function: this is because the brevity penalty of BLEU is calculated with respect to the number of morphemes, which may vary for sentences with an identical number of words.",
        "This motivates us to perform MERT at the word-token level, although our input consists of morphemes.",
        "In particular, for each iteration of MERT, as soon as the decoder generates a morpheme-token translation for a sentence, we convert it into a word-token sequence, which is used to calculate BLEU.",
        "We thus achieve MERT optimization at the word-token level while translating a morpheme-token input and generating a morpheme-token output.",
        "An SMT system that takes morpheme-token input and generates morpheme-token output should naturally use a morpheme-token language model (LM).",
        "This has the advantage of alleviating the problem of data sparseness, especially when translating into a morphologically rich language, since the LM would be able to handle some new unseen inflected forms of known words.",
        "On the negative side, a morpheme-token LM spans fewer word-tokens and thus has a more limited word \"horizon\" compared to one operating at the word level.",
        "As with the maximum phrase length, mechanically increasing the order of the morpheme-token LM has a limited impact.",
        "In order to address the issue in a more principled manner, we enhance our model with a second LM that works at the word-token level.",
        "This LM is used together with the morpheme-token LM, which is achieved by using two separate feature functions in the log-linear SMT model: one for each LM.",
        "We further had to modify the Moses decoder so that",
        "Previous hypotheses Current hypothesis",
        "(i) uusiSTM , epäpRE+ demokraatSTM+ tSUF+ iSUF+ sSUF+ enSUF maahanmuuttOpRE+ politiikanSTM (ii) • Score: \"sSUF+enSUF maahanmuuttoPRE+\" ; \"enSUF maahanmuuttoPRE+ politiikanSTM \"",
        "Concatenate: uusi , epädemokraattisen maahanmuuttopolitiikan Score: \", epädemokraattisen maahanmuuttopolitiikan\"",
        "Figure 2: Scoring with twin LMs.",
        "Shown are: (i) The current state of the decoding process with the target phrases covered by the current partial hypotheses.",
        "(ii, iii) Scoring with 3-gram morpheme-token and 3-gram word-token LMs, respectively.",
        "For the word-token LM, the morpheme-token sequence is concatenated into word-tokens before scoring.",
        "it can be enhanced with an appropriate word-token \"view\" on the partial morpheme-level hypotheses.",
        "The interaction of the twin LMs is illustrated in Figure 2.",
        "The word-token LM can capture much longer phrases and more complete contexts such as \", epädemokraattisen maahanmuuttopolitiikan'\" compared to the morpheme-token LM.",
        "Note that scoring with two LMs that see the output sequence as different numbers of tokens is not readily offered by the existing SMT decoders.",
        "For example, the phrase-based model in Moses (Koehn et al., 2007) allows scoring with multiple LMs, but assumes they use the same token granularity, which is useful for LMs trained on different monolingual corpora, but cannot handle our case.",
        "While the factored translation model (Koehn and Hoang, 2007) in Moses does allow scoring with models of different granularity, e.g., lemma-token and word-token LMs, it requires a 1:1 correspondence between the tokens in the different factors, which clearly is not our case.",
        "Note that scoring with twin LMs is conceptually superior to n-best re-scoring with a word-token LM, e.g., (Oflazer and El-Kahlout, 2007), since it is tightly integrated into decoding: it scores partial hypotheses and influenced the search process directly."
      ]
    },
    {
      "heading": "4. Enriching the Translation Model",
      "text": [
        "Another general strategy for combining evidence from the word-token and the morpheme-token representations is to build two separate SMT systems and then combine them.",
        "This can be done as a post-processing system combination step; see (Chen et al., 2009a) for an overview of such approaches.",
        "However, for phrase-based SMT systems, it is theoretically more appealing to combine their phrase tables since this allows the translation models of both systems to influence the hypothesis search directly.",
        "We now describe our phrase table combination approach.",
        "Note that it is orthogonal to the work presented in the previous section, which suggests combining the two (which we will do in Section 5).",
        "Figure 3 shows a general scheme of our twin translation model.",
        "First, we tokenize the input at different granularities: (1) morpheme-token and (2) word-token.",
        "We then build separate phrase tables (PT) for the two inputs: a word-token PTw and a morpheme-token PTm.",
        "Second, we re-tokenize PTw at the morpheme level, thus obtaining a new phrase table PTw^m, which is of the same granularity as PTm.",
        "Finally, we merge PTw^m and PTm, and we input the resulting phrase table to the decoder.",
        "Morpheme",
        "Word alignment",
        "Phrase Extraction",
        "Morphological segmentation J,",
        "PT merging",
        "Decoding",
        "Figure 3 : Building a twin phrase table (PT).",
        "First, separate PTs are generated for different input granularities: word-token and morpheme-token.",
        "Second, the word-token PT is retokenized at the morpheme-token level.",
        "Finally, the two PTs are merged and used by the decoder.",
        "GIZA++",
        "Morpheme alignment",
        "Phrase Extraction",
        "Below we first describe the two general phrase table combination strategies used in previous work: (1) direct merging using additional feature functions, and (2) phrase table interpolation.",
        "We then introduce our approach.",
        "Add-feature methods.",
        "The first line of research on phrase table merging is exemplified by (Niehues et al., 2009; Chen et al., 2009b; Do et al., 2009; Nakov and Ng, 2009).",
        "The idea is to select one of the phrase tables as primary and to add to it all non-duplicating phrase pairs from the second table together with their associated scores.",
        "For each entry, features can be added to indicate its origin (whether from the primary or from the secondary table).",
        "Later in our experiments, we will refer to these baseline methods as add-1 and add-2, depending on how many additional features have been added.",
        "The values we used for these features in the baseline are given in Section 5.4; their weights in the log-linear model were set in the standard way using MERT.",
        "Interpolation-based methods.",
        "A problem with the above method is that the scores in the merged phrase table that correspond to forward and backward phrase translation probabilities, and forward and backward lexicalized translation probabilities can no longer be interpreted as probabilities since they are not normalized any more.",
        "Theoretically, this is not necessarily a problem since the log-linear model used by the decoder does not assume that the scores for the feature functions come from a normalized probability distribution.",
        "While it is possible to re-normalize the scores to convert them into probabilities, this is rarely done; it also does not solve the problem with the dropped scores for the duplicated phrases.",
        "Instead, the conditional probabilities in the two phrase tables are often interpolated directly, e.g., using linear interpolation.",
        "Representative work adopting this approach is (Wu and Wang, 2007).",
        "We refer to this method as interpolation.",
        "Our method.",
        "The above phrase merging approaches have been proposed for phrase tables derived from different sources.",
        "This is in contrast with our twin translation scenario, where the morpheme-token phrase tables are built from the same training dataset; the main difference being that word alignments and phrase extraction were performed at the word-token level for PTw_m and at the morpheme-token level for PTm.",
        "Thus, we propose different merging approaches for the phrase translation probabilities and for the lexicalized probabilities.",
        "In phrase-based SMT, phrase translation probabilities are computed using maximum likelihood (ML) estimation (p(f\\e) = Y##(f,e), where #(/,e) is the number of times the pair (/, e) is extracted from the training dataset (Koehn et al., 2003).",
        "In order to preserve the normalized ML estimations as much as possible, we refrain from interpolation.",
        "Instead, we use the raw counts for the two models #m(/ , e) and #w_m(/, e) directly as follows:",
        "For lexicalized translation probabilities, we would like to use simple interpolation.",
        "However, we notice that when a phrase pair belongs to only one of the phrase tables, the corresponding lexicalized score for the other table would be zero.",
        "This might cause some good phrases to be penalized just because they were not extracted in both tables, which we want to prevent.",
        "We thus perform interpolation from PTm and PTw according to the following formula:",
        "where the concatenation of /m and em into word-token sequences yields /w and e w, respectively.",
        "If both ( /m, ëm) and ( /w, ëw ) are present in PTm and PTw, respectively, we have a simple interpolation of their corresponding lexicalized scores lexm and lexw.",
        "However, if one of them is missing, we do not use a zero for its corresponding lexicalized score, but use an estimate as follows.",
        "For example, if only the entry ( /m, em) is present in PTm, we first convert ( /m,em) into a word-token pair ( /m_w,em_w), and then induce a corresponding word alignment from the morpheme-token alignment of ( /m,em).",
        "We then estimate a lexicalized phrase score using the original formula given in (Koehn et al., 2003), where we plug this induced word alignment and word-token lexical translation probabilities estimated from the word-token dataset The case when ( /w, ew ) is present in PTw, but ( /m, em) is not, is solved similarly."
      ]
    },
    {
      "heading": "5. Experiments and Evaluation",
      "text": [
        "In our experiments, we use the English-Finnish data from the 2005 shared task (Koehn and Monz, 2005), which is split into training, development, and test portions; see Table 1 for details.",
        "We further split the training dataset into four subsets Ti, T2, T3, and T4 of sizes 40K, 80K, 160K, and 320K parallel sentence pairs, which we use for studying the impact of training data size on translation performance.",
        "Table 1: Dataset statistics.",
        "Shown are the number of parallel sentences, and the average number of words and Morfessor morphemes on the English and Finnish sides of the training, development and test datasets.",
        "We build two phrase-based baseline SMT systems, both using Moses (Koehn et al., 2007):",
        "w-system: works at the word-token level, extracts phrases of up to seven words, and uses a 4-gram word-token LM (as typical for phrase-based SMT);",
        "m-system: works at the morpheme level, tokenized using Morfessor and augmented with \"+\" as described in Section 3.1.",
        "Following Oflazer and El-Kahlout (2007) and Vir-pioja et al.",
        "(2007), we use phrases of up to 10 morpheme-tokens and a 5-gram morpheme-token LM.",
        "None of the enhancements described previously is applied yet.",
        "After decoding, morphemes are concatenated back to words using the \"+\" markers.",
        "To evaluate the translation quality, we compute BLEU (Papineni et al., 2001) at the word-token level.",
        "We further introduce a morpheme-token version of BLEU, which we call m-BLEU: it first segments the system output and the reference translation into morpheme-tokens and then calculates a BLEU score as usual.",
        "Table 2 shows the baseline results.",
        "We can see that the m-system achieves much w-system m-system",
        "Table 2: Baseline system performance (on the test dataset).",
        "Shown are word BLEU and morpheme m-BLEU scores for the w-system and m-system.",
        "higher m-BLEU scores, indicating that it may have better morpheme coverage.",
        "However, the m-system is outperformed by the w-system on the classic word-token BLEU, which means that it either does not perform as well as the w-system or that word-token BLEU is not capable of measuring the morphemelevel improvements.",
        "We return to this question later.",
        "We now add our three morphological enhancements from Section 3 to the baseline m-system:",
        "phr (training) allow morpheme-token phrases to get potentially longer than seven morpheme-tokens as long as they cover no more than seven words;",
        "tune (tuning) MERT for morpheme-token translations while optimizing word-token BLEU;",
        "lm (decoding) scoring morpheme-token translation hypotheses with a 5-gram morpheme-token and a 4-gram word-token LM.",
        "The results are shown in Table 3 (ii).",
        "As we can see, each of the three enhancements yields improvements in BLEU score over the m-system, both for small and for large training corpora.",
        "In terms of performance ranking, tune achieves the best absolute improvement of 0.66 BLEU points on T1 and of 0.47 points on the full dataset, followed by lm and phr.",
        "Table 3 (iii) further shows that using phr and lm together yields absolute improvements of 0.70 BLEU points on T1 and 0.50 points on the full training dataset.",
        "Further incorporating tune, however, only helps when training on T1 .",
        "Overall, the morphological enhancements are on par with the w-system baseline, and yield sizable imered the primary table.",
        "Table 4 shows the results when trying both strategies on add-1.",
        "As we can see, using PTw_m as primary performs better on T1 and on the full training dataset; thus, we will use it as primary on the test dataset for add-1 and add-2.",
        "BLEU",
        "m-BLEU",
        "BLEU",
        "m-BLEU",
        "Ti",
        "11.56",
        "45.57",
        "11.07",
        "49.15",
        "T2",
        "12.95",
        "48.63",
        "12.68",
        "53.78",
        "T3",
        "13.64",
        "50.30",
        "13.32",
        "54.40",
        "T4",
        "14.20",
        "50.85",
        "13.57",
        "54.70",
        "Full",
        "14.58",
        "53.05",
        "14.08",
        "55.26",
        "For interpolation-based methods, we need to choose a value for the interpolation parameters.",
        "Due to time constraints, we use the same value for the phrase translation probabilities and for the lexical-ized probabilities, and we perform grid search for a G {0.3, 0.4, 0.5, 0.6, 0.7} using interpolate on the full training dataset.",
        "As Table 5 shows, a = 0.6 turns out to work best on the development dataset; we will use this value in our experiments on the test dataset both for interpolate and for ourMethod.",
        "Table 5: Trying different values for interpolate (on dev dataset).",
        "BLEU (in %) is for the full training dataset.",
        "Evaluation on the test dataset.",
        "We integrate the morphologically enhanced system m+phr+lm and the word-token based w-system using the four merging methods above.",
        "The results for the full training dataset are shown in Table 6.",
        "As we can see, add-1 and add-2 make little difference compared to the m-system baseline.",
        "In contrast, interpolation and ourMethod yield sizable absolute improvements of 0.55 and 0.74 BLEU points, respectively, over the m-system; moreover, they outperform the w-system.",
        "Table 6: Merging m+phr+lm and w-system (on test dataset).",
        "BLEU (in %) is for the full training dataset.",
        "Superscripts indicate performance gain/loss w.r.tm-system."
      ]
    },
    {
      "heading": "6. Discussion",
      "text": [
        "Below we assess the significance of our results based on microanalysis and human judgments.",
        "Table 3: Impact of the morphological enhancements (on test dataset).",
        "Shown are BLEU scores (in %) for training on T and on the full dataset for (i) baselines, (ii) enhancements individually, and (iii) combined.",
        "Superscripts indicate absolute improvements w.r.t m-system.",
        "provements over the m-system baseline: 0.83 BLEU points on T1 and 0.50 on the full training dataset.",
        "Finally, we investigate the effect of combining phrase tables derived from a word-token and a morpheme-token input, as described in Section 4.",
        "We experiment with the following merging methods:",
        "add-1: phrase table merging using one table as primary and adding one extra feature;",
        "add-2: phrase table merging using one table as primary and adding two extra features;",
        "interpolation: simple linear interpolation with one parameter a;",
        "ourMethod: our interpolation-like merging method described in Section 4.2.",
        "Parameter tuning.",
        "We tune the parameters ofthe above methods on the development dataset.",
        "Table 4: Effectofselectionofprimaryphrasetablefor add-1 (on dev dataset): PTw^m, derived from a word-token input, vs. PTm, from a morpheme-token input.",
        "Shown is BLEU (in %) on T and the full training dataset.",
        "For add-1 and add-2, we need to decide which (PTw_ m or PTm) phrase table should be consid-",
        "a",
        "0.3",
        "0.4",
        "0.5",
        "0.6",
        "0.7",
        "BLEU",
        "14.17",
        "14.49",
        "14.6",
        "14.73",
        "14.52",
        "(i)",
        "m-system",
        "14.08",
        "w-system",
        "14.58",
        "(ii)",
        "add-1",
        "14.25+-",
        "add-2",
        "13.89-019",
        "(iii)",
        "interpolation",
        "14.63+",
        "ourMethod",
        "14.82+-",
        "We first compare the following three phrase tables: PTm of m-system, max mum phrase length of 10 morpheme-tokens; PTw_ m of w-system, maximum phrase length of 7 word-tokens, re-segmented into morpheme-tokens; and PTm+phr - morpheme-token input using word boundary-aware phrase extraction, maximum phrase length of 7 word-tokens.",
        "Table 7: Phrase table statistics.",
        "The number of phrase pairs in (i) individual PTs and (ii) PT overlap, is shown.",
        "PTm+phr versus PTm.",
        "Table 7 shows that PTm+phr is about half the size of PTm.",
        "Still, as Table 3 shows, m+phr outperforms the m-system.",
        "Moreover, 95.07% (21.4M/22.5M) of the phrase pairs in PTm+phr are also in PTm, which confirms that boundary-aware phrase extraction selects good phrase pairs from PTm to be retained in PTm+phr.",
        "PTm+phr versus PTw – m.",
        "These two tables are comparable in size: 22.5M and 28.9M pairs, but their overlap is only 47.67% (10.7M/22.5M) of PTm+phr.",
        "Thus, enriching the translation model with PTw_ m helps improve coverage.",
        "Table 8 shows the performance of our system compared to the two baselines: m-system and w-system.",
        "We achieve an absolute improvement of 0.74 BLEU points over the m-system, from which our system evolved.",
        "This might look modest, but note that the baseline BLEU is only 14.08, and thus the relative improvement is 5.6%, which is not trivial.",
        "Furthermore, we outperform the w-system by 0.24 points (1.56% relative).",
        "Both improvements are statistically significant with p < 0.01, according to Collins' sign test (Collins et al., 2005).",
        "In terms ofm-BLEU, we achieve an improvement of 2.59 points over the w-system, which suggest our system might be performing better than what standard BLEU suggests.",
        "Below we test this hypothesis _BLEU m-BLEU",
        "Table 8: Our system vs. the two baselines (on the test dataset): BLEU and m-BLEU scores (in %).",
        "by means of microanalysis and human evaluation.",
        "Translation Proximity Match.",
        "We performed automatic comparison based on corresponding phrases between the translation output (out) and the reference (ref), using the source (src) test dataset as a pivot.",
        "The decoding log gave us the phrases used to translate src to out, and we only needed to find correspondences between src and ref, which we accomplished by appending the test dataset to training and performing IBM Model 4 word alignments.",
        "We then looked for phrase triples (src, out, ref), where there was a high character-level similarity between out and ref, measured using longest common subsequence ratio with a threshold of 0.7, set experimentally.",
        "We extracted 16,262 triples: for 6,758 of them, the translations matched the references exactly, while in the remaining triples, they were close wordforms.",
        "These numbers support the hypothesis that our approach yields translations close to the reference wordforms but unjustly penalized by BLEU, which only gives credit for exact word matches.",
        "Human Evaluation.",
        "We asked four native Finnish speakers to evaluate 50 random test sentences.",
        "Following (Callison-Burch et al., 2009), we provided them with the source sentence, its reference translation, and the outputs of three SMT systems (m-system, w-system, and ourSystem), which were shown in different order for each example and were named sys1, sys2 and sys3 (by order of appearance).",
        "We asked for three pairwise judgments: (i) sys1 vs. sys2, (ii) sys1 vs. sys3, and (iii) sys2 vs. sys3.",
        "For each pair, a winner had to be designated; ties were allowed.",
        "The results are shown in Table 10.",
        "We can see that the judges consistently preferred",
        "P Tm",
        "43.5M",
        "(i)",
        "PT",
        "P Tw _ m PTm+phr",
        "28.9M 22.5M",
        "(ii)",
        "PTm+phr f PTm+phr f",
        "1 PTm PTw_ m",
        "21.4M 10.7M",
        "src: as a conservative , i am incredibly thrifty with taxpayers ' money .",
        "ref : maltillisen kokoomuspuolueen edustajana suhtaudun erittain saastavaisesti veronmaksajien rahoihin .",
        "our: konservatiivinen , olen erittain saastavaisesti veronmaksajien rahoja .",
        "w : konservatiivinen , olen aarettoman tarkeaa kanssa veronmaksajien rahoja .",
        "m : kuten konservatiivinen , olen erittain saastavaisesti veronmaksajien rahoja .",
        "Comment: our y m y w. our uses better paraphrases, from which the correct meaning could be inferred.",
        "The part \"aarettoman tarkeaa kanssa\" in w does not mention the \"thriftiness\" and replaces it with \"important\" (tarkeaa), which is wrong.",
        "m introduces \"kuten\", which slightly alters the meaning towards \"like a conservative, ...\" src: we were very constructive and we negotiated until the last minute of these talks in the hague .",
        "ref: olimme erittain rakentavia ja neuvottelimme haagissa viime hetkeen saakka .",
        "our: olemme olleet hyvin rakentavia ja olemme neuvotelleet viime hetkeen saakka naiden neuvottelujen haagissa .",
        "w : olemme olleet hyvin rakentavia ja olemme neuvotelleet viime tippaan niin naiden neuvottelujen haagissa .",
        "m : olimme erittain rakentavan ja neuvottelimme viime hetkeen saakka naiden neuvotteluiden haagissa .",
        "Comment: our y m y w. In our, the meaning is very close to ref with only a minor difference in tense at the beginning.",
        "m only gets the case wrong in \"rakentavan\", and the correct case is easily guessable.",
        "For w, the \"viime tippaan\" is in principle correct but somewhat colloquial, and the \"niin\" is extra and somewhat confusing.",
        "src: it would be a very dangerous situation if the europeans were to become logistically reliant on russia .",
        "ref: olisi erittain vaarallinen tilanne , jos eurooppalaiset tulisivat logistisesti riippuvaisiksi venajasta .",
        "our: olisi erittain vaarallinen tilanne , jos eurooppalaiset tulee logistisesti riippuvaisia venajan .",
        "w : se olisi erittain vaarallinen tilanne , jos eurooppalaisten tulisi logistically riippuvaisia venajan .",
        "m : se olisi hyvin vaarallinen tilanne , jos eurooppalaiset haluavat tulla logistisesti riippuvaisia venajan .",
        "Comment: our y w y m. our is almost correct except for the wrong inflections at the end.",
        "w is inferior since it failed to translate \"logistically\".",
        "\"haluavat tulla\" in m suggests that the Europeans would \"want to become logistically dependent\", which is not the case.",
        "The \"se\" (it), and \"hyvin\" (a synonym of \"erittain\") are minor mistakes/differences.",
        "Table 9: English-Finnish translation examples.",
        "Shown are the source (src), the reference (ref), and the translations of three systems (our, w, m).",
        "Text in bold indicates matches with respect to the ref, while italics show where a system was judged inferior to the rest, as judged by native Finnish speakers.",
        "(1) ourSystem to the m-system, (2) ourSystem to the w-system, (3) w-system to the m-system.",
        "These preferences are statistically significant, as found by the sign test.",
        "Comparing to Table 8, we can see that BLEU correlates with human judgments better than m-BLEU; we plan to investigate this in future work.",
        "Table 10: Human judgments: ourSystem (our) vs. m-system (m) vs. w-system (w).",
        "For each pair, we show the number of times each system was judged better than the other one, ignoring ties.",
        "Statistically significant differences are marked with | (p < 0.05) and I (p < 0.01).",
        "Finally, Table 9 shows some examples demonstrating how our system improves over the w-system and the m-system."
      ]
    },
    {
      "heading": "7. Conclusion and Future Work",
      "text": [
        "In the quest towards a morphology-aware SMT that only uses unannotated data, there are two key challenges: (1) to bring the performance of morpheme-token systems to a level rivaling the standard word-token ones, and (2) to incorporate morphological analysis directly into the translation process.",
        "This work satisfies the first challenge: we have achieved statistically significant improvements in BLEU for a large training dataset of 714K sentence pairs and this was confirmed by human evaluation.",
        "We think we have built a solid framework for the second challenge, and we plan to extend it further."
      ]
    },
    {
      "heading": "Acknowledgements",
      "text": [
        "We thank Joanna Bergsfröm-Lehtovirta (Helsinki Institute for Information Technology), Katri Haveri-nen (University of Turku and Turku Centre for Computer Science), Veronika Laippala (University of Turku), and Sampo Pyysalo (University of Tokyo) for judging the Finnish translations.",
        "our vs.",
        "m",
        "our vs. w",
        "w vs.",
        "m",
        "Judge 1",
        "25",
        "18",
        "19",
        "12",
        "21",
        "19",
        "Judge 2",
        "24",
        "16",
        "19",
        "15",
        "25",
        "14",
        "Judge 3",
        "27+",
        "12",
        "17",
        "11",
        "27+",
        "15",
        "Judge 4",
        "25",
        "20",
        "26+",
        "12",
        "22",
        "22",
        "Total",
        "101*",
        "66",
        "81*",
        "50",
        "95+",
        "70"
      ]
    }
  ]
}
