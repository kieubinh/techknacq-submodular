{
  "info": {
    "authors": [
      "Fabio De Bona",
      "Stefan Riezler",
      "Keith Hall",
      "Massimiliano Ciaramita",
      "Amaç Herdağdelen",
      "Maria Holmqvist"
    ],
    "book": "Human Language Technologies: the 2010 Annual Conference of the North American Chapter of the Association for Computational Linguistics",
    "id": "acl-N10-1071",
    "title": "Learning Dense Models of Query Similarity from User Click Logs",
    "url": "https://aclweb.org/anthology/N10-1071",
    "year": 2010
  },
  "references": [
    "acl-J90-1003",
    "acl-P02-1035"
  ],
  "sections": [
    {
      "text": [
        "Fabio De Bona*",
        "Friedrich Miescher Laboratory of the Max Planck Society Tübingen, Germany",
        "fabio@tuebingen.mpg.de",
        "Google Research Zürich, Switzerland",
        "Amac Herdagdelen*",
        "Maria Holmqvist*",
        "Linkopings University Linkopings, Sweden",
        "marho@ida.liu.se",
        "The goal of this work is to integrate query similarity metrics as features into a dense model that can be trained on large amoünts of qüery log data, in order to rank qüery rewrites.",
        "We propose features that incorporate varioüs notions of syntactic and semantic similarity in a generalized edit distance framework.",
        "We üse the implicit feedback of üser clicks on search results as weak labels in training linear ranking models on large data sets.",
        "We optimize different ranking objectives in a stochastic gradient descent framework.",
        "Our experiments show that a pairwise SVM ranker trained on multipartite rank levels outperforms other pairwise and listwise ranking methods under a variety of evaluation metrics."
      ]
    },
    {
      "heading": "1. Introduction",
      "text": [
        "Measures of query similarity are used for a wide range of web search applications, including query expansion, query suggestions, or listings of related queries.",
        "Several recent approaches deploy user query logs to learn query similarities.",
        "One set of approaches focuses on user reformulations of queries that differ only in one phrase, e.g., Jones et al.",
        "(2006).",
        "Such phrases are then identified as candidate expansion terms, and filtered by various signals such as co-occurrence in similar sessions, or log-likelihood ratio of original and expansion phrase.",
        "Other approaches focus on the relation of queries and search results, either by clustering queries based",
        "* The work presented in this paper was done while the authors were visiting Google Research, Zurich.",
        "on their search results, e.g., Beeferman and Berger (2000), or by deploying the graph of queries and results to find related queries, e.g., Sahami and Heilman (2006).",
        "The approach closest to ours is that of Jones et al.",
        "(2006).",
        "Similar to their approach, we create a training set of candidate query rewrites from user query logs, and use it to train learners.",
        "While the dataset used in Jones et al.",
        "(2006) is in the order of a few thousand query-rewrite pairs, our dataset comprises around 1 billion query-rewrite pairs.",
        "Clearly, manual labeling of rewrite quality is not feasible for our dataset, and perhaps not even desirable.",
        "Instead, our intent is to learn from large amounts of user query log data.",
        "Such data permit to learn smooth models because of the effectiveness of large data sets to capture even rare aspects of language, and they also are available as in the wild, i.e., they reflect the actual input-output behaviour that we seek to automate (Halevy et al., 2009).",
        "We propose a technique to automatically create weak labels from co-click information in user query logs of search engines.",
        "The central idea is that two queries are related if they lead to user clicks on the same documents for a large amount of documents.",
        "A manual evaluation of a small subset showed that a determination of positive versus negative rewrites by thresholding the number of co-clicks correlates well with human judgements of similarity, thus justifying our method of eliciting labels from co-clicks.",
        "Similar to Jones et al.",
        "(2006), the features of our models are not based on word identities, but instead on general string similarity metrics.",
        "This leads to dense rather than sparse feature spaces.",
        "The difference of our approach to Jones et al.",
        "(2006) lies in our particular choice of string similarity metrics.",
        "While Jones et al.",
        "(2006) deploy \"syntactic\" features such as Levenshtein distance, and \"semantic\" features such as log-likelihood ratio or mutual information, we combine syntactic and semantic aspects into generalized edit-distance features where the cost of each edit operation is weighted by various term probability models.",
        "Lastly, the learners used in our approach are applicable to very large datasets by an integration of linear ranking models into a stochastic gradient descent framework for optimization.",
        "We compare several linear ranking models, including a log-linear probability model for bipartite ranking, and pairwise and listwise SVM rankers.",
        "We show in an experimental evaluation that a pairwise SVM ranker trained on multipartite rank levels outperforms state-of-the-art pairwise and listwise ranking methods under a variety of evaluation metrics."
      ]
    },
    {
      "heading": "2. Query Similarity Measures",
      "text": [
        "In several of the similarity measures we describe below, we employ pointwise mutual information (PMI) as a measure of the association between two terms or queries.",
        "Let Wj and Wj be two strings that we want to measure the amount of association between.",
        "Let p(wj) and p(wj) be the probability of observing Wjand Wj in a given model; e.g., relative frequencies estimated from occurrence counts in a corpus.",
        "We also define p(wj; Wj) as the joint probability of Wi and Wj ; i.e., the probability of the two strings occurring together.",
        "We define PMI as follows:",
        "PMI has been introduced by Church and Hanks (1990) as word assosiatio ratio, and since then been used extensively to model semantic similarity.",
        "Among several desirable properties, it correlates well with human judgments (Recchia and Jones, 2009).",
        "As pointed out in earlier work, query transitions tend to correlate with taxonomic relations such as generalization and specialization (Lau and Horvitz, 1999; Rieh and Xie, 2006).",
        "Boldi et al.",
        "(2009) show how knowledge of transition types can positively impact query reformulation.",
        "We would like to exploit this information as well.",
        "However, rather than building a dedicated supervised classifier for this task we try to capture it directly at the source.",
        "First, we notice how string features; e.g., length, and edit distance already model this phenomenon to some extent, and in fact are part of the features used in Boldi et al.",
        "(2009).",
        "However, these measures are not always accurate and it is easy to find counterexamples both at the term level (e.g., \"camping\" to \"outdoor activities\" is a generalization) and character level (\"animal pictures\" to \"cat pictures\" is a specialization).",
        "Secondly, we propose that by manipulating PMI we can directly model taxonomic relations to some extent.",
        "Rather than using raw PMI values we re-normalize them.",
        "Notice that it is not obvious in our context how to interpret the relation between strings co-occurring less frequently than random.",
        "Such noisy events will yield negative PMI values since p(Wi; Wj) < p(Wi)p(Wj).",
        "We enforce zero PMI values for such cases.",
        "If PMI is thus constrained to non-negative values, normalization will bound PMI to the range between 0 and 1.",
        "The first type of normalization, called joint normalization, uses the negative log joint probability and is defined as",
        "PMI(J)(Wj, Wj ) = PMI( Wj, Wj )/-log(p(Wj,Wj )).",
        "The jointly normalized PMI(J) is a symmetric measure between Wj and Wj in the sense that PMI(J)(Wj,Wj) = PMI(J)(Wj,Wj).",
        "Intuitively it is a measure of the amount of shared information between the two strings relative to the sum of individual strings information.",
        "The advantages of the joint normalization of PMI have been noticed before (Bouma, 2009).",
        "To capture asymmetries in the relation between two strings, we introduce two non-symmetric normalizations which also bound the measure between 0 and 1.",
        "The second normalization is called specialization normalization and is defined as",
        "PMI(S)(Wj,Wj) = PMI(Wj,Wj)/ - log(p(Wj)).",
        "The reason we call it specialization is that PMI(S) favors pairs where the second string is a specialization of the first one.",
        "For instance, PMI(S) is at its maximum when p(Wj, Wj) = p(Wj) and that means the conditional probability p(Wj|Wj ) is 1 which is an indication of a specialization relation.",
        "The last normalization is called the generalization normalization and is defined in the reverse direction as",
        "PMI(G)(Wj,Wj) = PMI(Wj,Wj)/ - log(p(Wj)).",
        "Again, PMI(G) is a measure between 0 and 1 and is at its maximum value when p(Wj |Wj) is 1.",
        "The three normalizations provide a richer representation of the association between two strings.",
        "Furthermore, jointly, they model in an information-theoretic sense the generalization-specialization dimension directly.",
        "As an example, for the query transition \"apple\" to \"mac os\" PMI(G)=0.2917 and PMI(S)=0.3686; i.e., there is more evidence for a specialization.",
        "Conversely for the query transition \"ferrari models\" to \"ferrari\" we get PMI(G)=1 and PMI(S)=0.5558; i.e., the target is a \"perfect\" generalization of the source.",
        "Let V be a finite vocabulary and £ be the null symbol.",
        "An edit operation: insertion, deletion or substitution, is a pair (a, b) G {V U {£} x V U {£}} \\ {(£,£)}.",
        "An alignment between two sequences Wj and Wj is a sequence of edit operations w = (ai,6i),..., (an , bra).",
        "Given a non-negative cost function c, the cost of an alignment is c(w) = n=1 c(wj).",
        "The Levenshtein distance, or edit distance, defined over V, dV (Wj ,Wj ) between two sequences is the cost of the least expensive sequence of edit operations which transforms Wj into Wj (Levenshtein, 1966).",
        "The distance computation can be performed via dynamic programming in time O(|Wj||Wj|).",
        "Similarity at the string, i.e., character or term, level is an indicator of semantic similarity.",
        "Edit distance captures the amount of overlap between the queries as sequences of symbols and has been previously used in information retrieval (Boldi et al., 2009; Jones et al., 2006).",
        "We use two basic Levenshtein distance models.",
        "The first, called Edit1 (E1), employs a unit cost function for each of the three operations.",
        "That is, given a finite vocabulary T containing all terms occurring in queries:",
        "Va, b G T, cE1 (a, b) = 1 if (a = b), 0 else.",
        "The second, called Edit2 (E2), uses unit costs for insertion and deletion, but computes the character-based edit distance between two terms to decide on the substitution cost.",
        "If two terms are very similar at the character level, then the cost of substitution is lower.",
        "Given a finite vocabulary T of terms and a finite vocabulary A of characters, the cost function is defined as:",
        "Va, b G T, cE2(a, b) = d^(a, b) if a A b = £, 1 else.",
        "where d^(a, b) is linearly scaled between 0 and 1 dividing by max(|a|, |b|).",
        "We also investigate a variant of the edit distance algorithm in which the terms in the input sequences are sorted, alphabetically, before the distance computation.",
        "The motivation behind this variant is the observation that linear order in queries is not always meaningful.",
        "For example, it seems reasonable to assume that \"brooklyn pizza\" and \"pizza brooklyn\" denote roughly the same user intent.",
        "However, the pair has an edit distance oftwo (delete-insert), while the distance between \"brooklyn pizza\" and the less relevant \"brooklyn college\" is only one (substitute).",
        "The sorted variant relaxes the ordering constraint.",
        "In this section we extend the edit distance framework introduced in Section 2.3 with the semantic similarity measures described in Section 2.1, using the taxonomic normalizations defined in Section 2.2.",
        "Extending the Levenshtein distance framework to take into account semantic similarities between terms is conceptually simple.",
        "As in the Edit2 model above we use a modified cost function.",
        "We introduce a cost matrix encoding individual costs for term substitution operations; the cost is defined in terms of the normalized PMI measures of Section 2.2, recall that these measures range between 0 and 1.",
        "Given a normalized similarity measure f, an entry in a cost matrix S for a term pair (Wj, Wj) is defined as:",
        "We call these models SEdit (SE), where S specifies the cost matrix used.",
        "Given a finite term vocabulary T and cost matrix S, the cost function is defined as:",
        "Va, b G T, cSE (a, b) = s(a, b) if a A b = £, 1 else.",
        "The cost function has the following properties.",
        "Since insertion and deletion have unit cost, a term is substituted only if a substitution is \"cheaper\" than deleting and inserting another term, namely, if the similarity between the terms is not zero.",
        "The e correction, coupled with unit insertion and deletion cost, guarantees that for an unrelated term pair a combination of insertion and deletion will always be less costly then a substitution.",
        "Thus in the computation of the optimal alignment, each operation cost ranges between 0 and 2.",
        "As a remark on efficiency, we notice that here the semantic similarities are computed between terms, rather than full queries.",
        "At the term level, caching techniques can be applied more effectively to speed up feature computation.",
        "The cost function is implemented as a pre-calculated matrix, in the next section we describe how the matrix is estimated.",
        "In our experiments we evaluated two different sources to obtain the PMI-based cost matrices.",
        "In both cases, we assumed that the cost of the substitution of a term with itself (i.e. identity substitution) is always 0.",
        "The first technique uses a probabilistic clustering model trained on queries and clicked documents from user query logs.",
        "The second model estimates cost matrices directly from user session logs, consisting of approximately 1.3 billion U.S. English queries.",
        "A session is defined as a sequence of queries from the same user within a controlled time interval.",
        "Let qs and q* be a query pair observed in the session data where q* is issued immediately after qs in the same session.",
        "Let qS = 9s \\ q* and q* = 9* \\ 9S, where \\ is the set difference operator.",
        "The co-occurrence count of two terms Wj and Wj from a query pair qs, q* is denoted by (qs, q*) and is defined as:",
        "{ 1 if Wj = Wj A Wj G qs A Wj G q* 1/(|qS| |q*|) if Wj G qS A Wj G q* 0 else.",
        "In other words, if a term occurs in both queries, it has a co-occurrence count of 1.",
        "For all other term pairs, a normalized co-occurrence count is computed in order to make sure the sum of co-occurrence counts for a term Wj G qs sums to 1 for a given query pair.",
        "The normalization is an attempt to avoid the under representation of terms occurring in both queries.",
        "The final co-occurrence count of two arbitrary terms Wj and Wj is denoted by and it is defined as the sum over all query pairs in the session logs, the sum of co-occurrence counts over all term pairs.",
        "Then we define a joint probability for a term pair as p(Wj,Wj ) = .",
        "Similarly, we define the single-occurrence counts and probabilities of the terms by computing the marginalized sums over all term pairs.",
        "Namely, the probability ofatermWj occurring in the source query is p(i, •) = w /N and similarly the probability of a term Wj occurring in the target query is p(-, j) = ^Wi Nj;j/N.",
        "Plugging in these values in Eq.",
        "(1), we get the PMI(Wj, Wj) for term pair Wj and Wj, which are further normalized as described in Section 2.2.",
        "More explanation and evaluation of the features described in this section can be found in Ciaramita et al.",
        "(2010)."
      ]
    },
    {
      "heading": "3. Learning to Rank from Co-Click Data",
      "text": [
        "Several studies have shown that implicit feedback from clickstream data is a weaker signal than human relevance judgements.",
        "Joachims (2002) or Agrawal et al.",
        "(2009) presented techniques to convert clicks into labels that can be used for machine learning.",
        "Our goal is not to elicit relevance judgments from user clicks, but rather to relate queries by pivoting on commonly clicked search results.",
        "The hypothesis is that two queries are related if they lead to user clicks on the same documents for a large amount of documents.",
        "This approach is similar to the method proposed by Fitzpatrick and Dent (1997) who attempt to measure the relatedness between two queries by using the normalized intersection of the top 200 retrieval results.",
        "We add click information to this setup, thus strengthening the preference for precision over recall in the extraction of related queries.",
        "In our experiments we created two ground-truth ranking scenarios from the co-click signals.",
        "In a first scenario, called bipartite ranking, we extract a set of positive and a set of negative query-rewrite pairs from the user logs data.",
        "We define positive pairs as queries that have been co-clicked with at least 10 different results, and negative pairs as query pairs with fewer than 10 co-clicks.",
        "In a second scenario, called multipartite ranking, we define a hierarchy of levels of \"goodness\", by combining rewrites with the same number of co-clicks at the same level, with increasing ranks for higher number of co-clicks.",
        "Statistics on the co-click data prepared for our experiments are given in Table 1.",
        "For training and development, we collected query-rewrite pairs from user query logs that contained at least one positive rewrite.",
        "The training set consists of about 1 billion of query-rewrite pairs; the development set contains 10 million query-rewrite pairs.",
        "The average number of rewrites per query is around 4,500 for the training and development set, with a very small amount of 0.2% positive rewrites per query.",
        "In order to confirm the validity of our co-click hypothesis, and for final evaluation, we held out another sample of query-rewrite pairs for manual evaluation.",
        "This dataset contains 100 queries for each of which we sampled 30 rewrites in descending order of co-clicks, resulting in a high percentage of 43% positive rewrites per query.",
        "The query-rewrite pairs were annotated by 3 raters as follows: First the raters were asked to rank the rewrites in descending order of relevance using a graphical user interface.",
        "Second the raters assigned rank labels and binary relevance scores to the ranked list of rewrites.",
        "This labeling strategy is similar to the labeling strategy for synonymy judgements proposed by Ruben-stein and Goodenough (1965).",
        "Inter-rater agreements on binary relevance judgements, and agreement between rounded averaged human relevance scores and assignments of positive/negative labels by the co-click threshold of 10 produced a Kappa value of 0.65 (Siegel and Castellan, 1988).",
        "Let S = {(xq,yq))n=1 be a training sample of queries, each represented by a set of rewrites xq = {xq1,..., xq n(q)}, and set of rank labels yq = {yqi,...,yq,n(q)}, where n(q) is the number of rewrites for query q.",
        "For full rankings of all rewrites for a query, a total order on rewrites is assumed, with rank labels taking on values yqi G {1,..., n(q)}.",
        "Rewrites of equivalent rank can be specified by assuming a partial order on rewrites, where a multipartite ranking involves r < n(q) relevance levels such that yqi G {1,..., r} , and a bipartite ranking involves two rank values yqi G {1, 2} with relevant rewrites at rank 1 and non-relevant rewrites at rank 2.",
        "Let the rewrites in xq be identified by the integers {1,2,..., n(q)}, and let a permutation nq on xq be defined as a bijection from {1,2,..., n(q)} onto itself.",
        "Let nq denote the set of all possible permutations on xq, and let nqi denote the rank position of xqi.",
        "Furthermore, let (i, j) denote a pair of rewrites in xq and let Pq be the set of all pairs in xq.",
        "We associate a feature function 0(xqi) with each rewrite i = 1 , .",
        ".",
        ".",
        ", n( q) for each query q.",
        "Furthermore, a partial-order feature map as used in Yue et al.",
        "(2007) is created for each rewrite set as follows:",
        "0(xq ,nq ) = -- <Kxq*)-<Kxqj )sgn( ^---~) .",
        "The goal of learning a ranking over the rewrites xq for a query q can be achieved either by sorting the rewrites according to the rewrite-level ranking function f (xqi) = (w, 0(xqi)), or by finding the permutation that scores highest according to a query-level ranking function f (xq, nq) = (w, 0(xq, nq)).",
        "In the following, we will describe a variety of well-known ranking objectives, and extensions thereof, that are used in our experiments.",
        "Optimization is done in a stochastic gradient descent (SGD) framework.",
        "We minimize an empirical loss objective by stochastic updating",
        "train",
        "dev",
        "test",
        "number of queries",
        "250,000",
        "2,500",
        "100",
        "average number of",
        "rewrites per query",
        "4,500",
        "4,500",
        "30",
        "percentage of rewrites",
        "with > 10 coclicks",
        "0.2",
        "0.2",
        "43",
        "wt+i = wt - ntgt",
        "where r?t is a learning rate, and gt is the gradient",
        "Standard ranking evaluation metrics such as (Mean) Average Precision (Manning et al., 2008) are defined on permutations of whole lists and are not decomposable over instances.",
        "Joachims (2005), proposed multivariate SVM models to optimize such listwise evaluation metrics.",
        "The central idea is to formalize the evaluation metric as a prediction loss function L, and incorporate L via margin rescaling into the hinge loss function, such that an upper bound on the prediction loss is achieved (see Tsochantaridis et al.",
        "(2004), Proposition 2).",
        "The loss function is given by the following list-wise hinge loss:",
        "maxnqellq\\yq L(yq^ + (w,(Xxq, TTçO} expression, = max{0,z} and L(yq,nq) G [0,1] denotes a prediction loss of a predicted ranking nqcompared to the ground-truth ranking yq.",
        "In this paper, we use Average Precision (AP) as prediction loss function s.t.",
        "where AP is defined as follows:",
        "Note that the ranking scenario is in this case bipartite with yqi G {1, 2}.",
        "The derivatives for are as follows:",
        "^fc(xq,yq) - 0fc(xq, 7T*)) else.",
        "SGD optimization involves computing n* for each feature and each query, which can be done efficiently using the greedy algorithm proposed by Yue et al.",
        "(2007).",
        "We will refer to this method as the SVM-MAP model.",
        "Joachims (2002) proposed an SVM method that defines the ranking problem as a pairwise classification problem.",
        "Cortes et al.",
        "(2007) extended this method to a magnitude-preserving version by penalizing a pairwise misranking by the magnitude of the difference in preference labels.",
        "A position-sensitive penalty for pairwise ranking SVMs was proposed by Riezler and De Bona (2009) and Chapelle and Keerthi (2010), and earlier for perceptrons by Shen and Joshi (2005).",
        "In the latter approaches, the magnitude of the difference in inverted ranks is accrued for each misranked pair.",
        "The idea is to impose an increased penalty for misrankings at the top of the list, and for misrankings that involve a difference of several rank levels.",
        "Similar to the listwise case, we can view the penalty as a prediction loss function, and incorporate it into the hinge loss function by rescaling the margin by a pairwise prediction loss function L(yqi, yqj ).",
        "In our experiments we used a positionsensitive prediction loss function defined on the difference of inverted ranks.",
        "The margin-rescaled pairwise hinge loss is then defined as follows:",
        "Table 2: Experimental evaluation of random and best feature baselines, and log-linear, SVM-MAP, SVM-bipartite, SVM-multipartite, and SVM-multipartite-margin-rescaled learning-to-rank models on manually labeled test set.",
        "The derivative of ^ph is calculated as follows:",
        "else.",
        "Note that the effect of inducing a positionsensitive penalty on pairwise misrankings applies only in case of full rankings on n(q) rank levels, or in case of multipartite rankings involving 2 < r < n(q) rank levels.",
        "Henceforth we will refer to margin-rescaled pairwise hinge loss for multipartite rankings as the SVM-pos.-sens.",
        "method.",
        "Bipartite ranking is a special case where L(yqi, yqj ) is constant so that margin rescaling does not have the effect of inducing position-sensitivity.",
        "This method will be referred to as the SVM-bipartite model.",
        "Also note that for full ranking or multipartite ranking, predicting a low ranking for an instance that is ranked high in the ground truth has a domino effect of accruing an additional penalty at each rank level.",
        "This effect is independent of margin-rescaling.",
        "The method of pairwise hinge loss for multipartite ranking with constant margin will henceforth be referred to as the SVM-multipartite model.",
        "Computation in SGD optimization is dominated by the number of pairwise comparisons |Pq | for each query.",
        "For full ranking, a comparison of |Pq| = (n(2q)) pairs has to be done.",
        "In the case of multipartite ranking at r rank levels, each including | Zj | rewrites, pairwise comparisons between rewrites at the same rank level can be ignored.",
        "This reduces the number of comparisons to |Pq | =",
        "Zi=i £r=j+1 11j || lj |.",
        "For bipartite ranking of p positive and n negative instances, |Pq | = p • n comparisons are necessary.",
        "A probabilistic model for bipartite ranking can be defined as the conditional probability of the set of relevant rewrites, i.e., rewrites at rank level 1, given all rewrites at rank levels 1 and 2.",
        "A formalization in the family of log-linear models yields the following logistic loss function ^m that was used for discriminative estimation from sets of partially labeled data",
        "The gradient of is calculated as a difference between two expectations:"
      ]
    },
    {
      "heading": "9. dw fc",
      "text": [
        "^llm = -Pw [0fc |xq ; yqj = 1] + Pw [0fc |xq] .",
        "The SGD computation for the log-linear model is dominated by the computation of expectations for each query.",
        "The logistic loss for bipartite ranking is henceforth referred to as the log-linear model."
      ]
    },
    {
      "heading": "4. Experimental Results",
      "text": [
        "In the experiments reported in this paper, we trained linear ranking models on 1 billion query-rewrite pairs using 60 dense features, combined ofthe building blocks of syntactic and semantic similarity metrics under different estimations of cost matrices.",
        "Development testing was done on a data set that was held-out from the training set.",
        "Final testing was carried out on the manually labeled dataset.",
        "Data statistics for all sets are given in Table 1.",
        "MAP",
        "NDCG@10",
        "AUC",
        "Prec@1",
        "Prec@3",
        "Prec@5",
        "Random",
        "51.8",
        "48.7",
        "50.4",
        "45.6",
        "45.6",
        "46.6",
        "Best-feature",
        "71.9",
        "70.2",
        "74.5",
        "70.2",
        "68.1",
        "68.7",
        "SVM-bipart.",
        "73.7",
        "73.7",
        "74.7",
        "79.4",
        "70.1",
        "70.1",
        "SVM-MAP",
        "74.3",
        "75.2",
        "75.3",
        "76.3",
        "71.8",
        "72.0",
        "Log-linear",
        "74.7",
        "75.1",
        "75.7",
        "75.3",
        "72.2",
        "71.3",
        "SVM-pos.-sens.",
        "75.7",
        "76.0",
        "76.6",
        "82.5",
        "72.9",
        "73.0",
        "SVM-multipart.",
        "76.5",
        "77.3",
        "77.2",
        "83.5",
        "74.2",
        "73.6",
        "Table 3: P-values computed by approximate randomization test for 15 pairwise comparisons of result differences.",
        "Model selection was performed by adjusting meta-parameters on the development set.",
        "We trained each model at constant learning rates n G {1,0.5,0.1, 0.01, 0.001}, and evaluated each variant after every fifth out of 100 passes over the training set.",
        "The variant with the highest MAP score on the development set was chosen and evaluated on the test set.",
        "This early stopping routine also served for regularization.",
        "Evaluation results for the systems are reported in Table 2.",
        "We evaluate all models according to the following evaluation metrics: Mean Average Precision (MAP), Normalized Discounted Cumulative Gain with a cutoff at rank 10 (NDCG@10), Area-under-the-ROC-curve (AUC), Precision@n. As baselines we report a random permutation of rewrites (random), and the single dense feature that performed best on the development set (best-feature).",
        "The latter is the log-probability assigned to the query-rewrite pair by the probabilistic clustering model used for cost matrix estimation (see Section 2.5).",
        "P-values are reported in Table 3 for all pairwise comparisons of systems (except the random baseline) using an Approximate Randomization test where stratified shuffling is applied to results on the query level (see Noreen (1989)).",
        "The rows in Tables 2 and 3 are ranked according to MAP values of the systems.",
        "SVM-multipartite outperforms all other ranking systems under all evaluation metrics at a significance level > 0.995.",
        "For all other pairwise comparisons of result differences, we find result differences of systems ranked next to each other to be not statistically significant.",
        "All systems outperform the random and best-feature baselines with statistically significant result differences.",
        "The distinctive advantage of the SVM-multipartite models lies in the possibility to rank rewrites with very high co-click numbers even higher than rewrites with reasonable numbers of co-clicks.",
        "This preference for ranking the top co-clicked rewrites high seems the best avenue for transferring co-click information to the human judgements encoded in the manually labeled test set.",
        "Position-sensitive margin rescaling does not seem to help, but rather seems to hurt."
      ]
    },
    {
      "heading": "5. Discussion",
      "text": [
        "We presented an approach to learn rankings of query rewrites from large amounts of user query log data.",
        "We showed how to use the implicit co-click feedback about rewrite quality in user log data to train ranking models that perform well on ranking query rewrites according to human quality standards.",
        "We presented large-scale experiments using SGD optimization for linear ranking models.",
        "Our experimental results show that an SVM model for multipartite ranking outperforms other linear ranking models under several evaluation metrics.",
        "In future work, we would like to extend our approach to other models, e.g., sparse combinations of lexicalized features.",
        "Best-feature",
        "SVM-bipart.",
        "SVM-MAP",
        "Log-linear",
        "SVM-pos.-sens.",
        "SVM-multipart.",
        "Best-feature",
        "-",
        "< 0.005",
        "< 0.005",
        "< 0.005",
        "< 0.005",
        "< 0.005",
        "SVM-bipart.",
        "-",
        "-",
        "0.324",
        "< 0.005",
        "< 0.005",
        "< 0.005",
        "SVM-MAP",
        "-",
        "-",
        "-",
        "0.374",
        "< 0.005",
        "< 0.005",
        "Log-linear",
        "-",
        "-",
        "-",
        "-",
        "0.053",
        "< 0.005",
        "SVM-pos.-sens.",
        "-",
        "-",
        "-",
        "-",
        "-",
        "< 0.005",
        "SVM-multipart.",
        "-",
        "-",
        "-",
        "-",
        "-",
        "-"
      ]
    }
  ]
}
