{
  "info": {
    "authors": [
      "Veselin Stoyanov",
      "Claire Cardie",
      "Nathan Gilbert",
      "Ellen Riloff",
      "David Buttler",
      "David Hysom"
    ],
    "book": "Proceedings of the ACL 2010 Conference Short Papers",
    "id": "acl-P10-2029",
    "title": "Coreference Resolution with Reconcile",
    "url": "https://aclweb.org/anthology/P10-2029",
    "year": 2010
  },
  "references": [
    "acl-D08-1031",
    "acl-H05-1004",
    "acl-J01-4004",
    "acl-J94-4002",
    "acl-L08-1328",
    "acl-M95-1005",
    "acl-N07-1051",
    "acl-P03-1023",
    "acl-P04-1018",
    "acl-P05-1045",
    "acl-P07-1107",
    "acl-P09-1074"
  ],
  "sections": [
    {
      "text": [
        "Center for Language and Speech Processing Johns Hopkins Univ.",
        "Baltimore, MD",
        "Claire Cardie Nathan Gilbert",
        "Computer Science School of Computing",
        "Cornell University University of Utah",
        "Ithaca, NY Salt Lake City, UT",
        "David Buttler David Hysom Lawrence Livermore National Laboratory Livermore, CA",
        "buttler1@llnl.gov hysom1@llnl.gov",
        "Despite the existence of several noun phrase coreference resolution data sets as well as several formal evaluations on the task, it remains frustratingly difficult to compare results across different corefer-ence resolution systems.",
        "This is due to the high cost of implementing a complete end-to-end coreference resolution system, which often forces researchers to substitute available gold-standard information in lieu of implementing a module that would compute that information.",
        "Unfortunately, this leads to inconsistent and often unrealistic evaluation scenarios.",
        "With the aim to facilitate consistent and realistic experimental evaluations in coreference resolution, we present Reconcile, an infrastructure for the development of learning-based noun phrase (NP) coreference resolution systems.",
        "Reconcile is designed to facilitate the rapid creation of corefer-ence resolution systems, easy implementation of new feature sets and approaches to coreference resolution, and empirical evaluation of coreference resolvers across a variety of benchmark data sets and standard scoring metrics.",
        "We describe Reconcile and present experimental results showing that Reconcile can be used to create a coreference resolver that achieves performance comparable to state-of-the-art systems on six benchmark data sets."
      ]
    },
    {
      "heading": "1. Introduction",
      "text": [
        "Noun phrase coreference resolution (or simply coreference resolution) is the problem of identifying all noun phrases (NPs) that refer to the same entity in a text.",
        "The problem of coreference resolution is fundamental in the field of natural language processing (NLP) because of its usefulness for other NLP tasks, as well as the theoretical interest in understanding the computational mechanisms involved in government, binding and linguistic reference.",
        "Several formal evaluations have been conducted for the coreference resolution task (e.g., MUC-6 (1995), ACE NIST (2004)), and the data sets created for these evaluations have become standard benchmarks in the field (e.g., MUC and ACE data sets).",
        "However, it is still frustratingly difficult to compare results across different coreference resolution systems.",
        "Reported coreference resolution scores vary wildly across data sets, evaluation metrics, and system configurations.",
        "We believe that one root cause of these disparities is the high cost of implementing an end-to-end coreference resolution system.",
        "Coreference resolution is a complex problem, and successful systems must tackle a variety of non-trivial subproblems that are central to the coreference task – e.g., mention/markable detection, anaphor identification – and that require substantial implementation efforts.",
        "As a result, many researchers exploit gold-standard annotations, when available, as a substitute for component technologies to solve these subproblems.",
        "For example, many published research results use gold standard annotations to identify NPs (substituting for mention/markable detection), to distinguish anaphoric NPs from non-anaphoric NPs (substituting for anaphoricity determination), to identify named entities (substituting for named entity recognition), and to identify the semantic types of NPs (substituting for semantic class identification).",
        "Unfortunately, the use of gold standard annotations for key/critical component technologies leads to an unrealistic evaluation setting, and makes it impossible to directly compare results against coreference resolvers that solve all of these subproblems from scratch.",
        "Comparison of coreference resolvers is further hindered by the use of several competing (and non-trivial) evaluation measures, and data sets that have substantially different task definitions and annotation formats.",
        "Additionally, coreference resolution is a pervasive problem in NLP and many NLP applications could benefit from an effective coreference resolver that can be easily configured and customized.",
        "To address these issues, we have created a platform for coreference resolution, called Reconcile, that can serve as a software infrastructure to support the creation of, experimentation with, and evaluation of coreference resolvers.",
        "Reconcile was designed with the following seven desiderata in mind:",
        "• implement the basic underlying software ar-",
        "chitecture of contemporary state-of-the-art learning-based coreference resolution systems;",
        "• support experimentation on most of the standard coreference resolution data sets;",
        "• implement most popular coreference resolution scoring metrics;",
        "• exhibit state-of-the-art coreference resolution performance (i.e., it can be configured to create a resolver that achieves performance close to the best reported results);",
        "• can be easily extended with new methods and features;",
        "• is relatively fast and easy to configure and run;",
        "• has a set of pre-built resolvers that can be used as black-box coreference resolution systems.",
        "While several other coreference resolution systems are publicly available (e.g., Poesio and al.",
        "(2008)), none meets all seven of these desiderata (see Related Work).",
        "Reconcile is a modular software platform that abstracts the basic architecture of most contemporary supervised learning-based coreference resolution systems (e.g., Soon",
        "Roth (2008)) and achieves performance comparable to the state-of-the-art on several benchmark data sets.",
        "Additionally, Reconcile can be easily reconfigured to use different algorithms, features, preprocessing elements, evaluation settings and metrics.",
        "In the rest of this paper, we review related work (Section 2), describe Reconcile's organization and components (Section 3) and show experimental results for Reconcile on six data sets and two evaluation metrics (Section 4)."
      ]
    },
    {
      "heading": "2. Related Work",
      "text": [
        "Several coreference resolution systems are currently publicly available.",
        "JavaRap (Qiu et al., 2004) is an implementation of the Lappin and Leass' (1994) Resolution of Anaphora Procedure (RAP).",
        "JavaRap resolves only pronouns and, thus, it is not directly comparable to Reconcile.",
        "GuiTaR (Poesio and Kabadjov, 2004) and BART (Versley et al., 2008) (which can be considered a successor of GuiTaR) are both modular systems that target the full coreference resolution task.",
        "As such, both systems come close to meeting the majority of the desiderata set forth in Section 1.",
        "BART, in particular, can be considered an alternative to Reconcile, although we believe that Reconcile's approach is more flexible than BART's.",
        "In addition, the architecture and system components of Reconcile (including a comprehensive set of features that draw on the expertise of state-of-the-art supervised learning approaches, such as Bengtson and Roth (2008)) result in performance closer to the state-of-the-art.",
        "Coreference resolution has received much research attention, resulting in an array of approaches, algorithms and features.",
        "Reconcile is modeled after typical supervised learning approaches to coreference resolution (e.g. the architecture introduced by Soon et al.",
        "(2001)) because of the popularity and relatively good performance of these systems.",
        "However, there have been other approaches to coreference resolution, including unsupervised and semi-supervised approaches (e.g. Haghighi and Klein (2007)), structured approaches (e.g. McCallum and Wellner (2004) and Finley and Joachims (2005)), competition approaches (e.g. Yang et al.",
        "(2003)) and a bell-tree search approach (Luo et al.",
        "(2004)).",
        "Most of these approaches rely on some notion of pairwise feature-based similarity and can be directly implemented in Reconcile."
      ]
    },
    {
      "heading": "3. System Description",
      "text": [
        "Reconcile was designed to be a research testbed capable of implementing most current approaches to coreference resolution.",
        "Reconcile is written in Java, to be portable across platforms, and was designed to be easily reconfigurable with respect to subcomponents, feature sets, parameter settings, etc.",
        "Reconcile's architecture is illustrated in Figure 1.",
        "For simplicity, Figure 1 shows Reconcile's operation during the classification phase (i.e., assuming that a trained classifier is present).",
        "The basic architecture of the system includes five major steps.",
        "Starting with a corpus of documents together with a manually annotated corefer-ence resolution answer key, Reconcile performs",
        "!Only required during training.",
        "the following steps, in order:",
        "1.",
        "Preprocessing.",
        "All documents are passed through a series of (external) linguistic processors such as tokenizers, part-of-speech taggers, syntactic parsers, etc.",
        "These components produce annotations of the text.",
        "Table 1 lists the preprocessors currently interfaced in Reconcile.",
        "Note that Reconcile includes several in-house NP detectors, that conform to the different data sets' definitions of what constitutes a NP (e.g., MUC vs.",
        "ACE).",
        "All of the extractors utilize a syntactic parse of the text and the output of a Named Entity (NE) extractor, but extract different constructs as specialized in the corresponding definition.",
        "The NP extractors successfully recognize about 95% of the NPs in the MUC and ACE gold standards.",
        "2.",
        "Feature generation.",
        "Using annotations produced during preprocessing, Reconcile produces feature vectors for pairs of NPs.",
        "For example, a feature might denote whether the two NPs agree in number, or whether they have any words in common.",
        "Reconcile includes over 80 features, inspired by other successful coreference resolution systems such as Soon et al.",
        "(2001) and Ng and Cardie (2002).",
        "3.",
        "Classification.",
        "Reconcile learns a classifier that operates on feature vectors representing pairs of NPs and it is trained to assign a score indicating the likelihood that the NPs in the pair are coreferent.",
        "4.",
        "Clustering.",
        "A clustering algorithm consolidates the predictions output by the classifier and forms the final set of coreference clusters (chains).",
        "5.",
        "Scoring.",
        "Finally, during testing Reconcile runs scoring algorithms that compare the chains produced by the system to the goldstandard chains in the answer key.",
        "Each of the five steps above can invoke different components.",
        "Reconcile's modularity makes it easy for new components to be implemented and existing ones to be removed or replaced.",
        "Recon-cile's standard distribution comes with a comprehensive set of implemented components - those available for steps 2-5 are shown in Table 2.",
        "Reconcile contains over 38,000 lines of original Java code.",
        "Only about 15% of the code is concerned with running existing components in the preprocessing step, while the rest deals with NP extraction, implementations of features, clustering algorithms and scorers.",
        "More details about Recon-cile's architecture and available components and features can be found in Stoyanov et al.",
        "(2010).",
        "Task",
        "Systems",
        "Sentence splitter",
        "UIUC (CC Group, 2009) OpenNLP (Baldridge, J., 2005)",
        "Tokenizer",
        "OpenNLP (Baldridge, J., 2005)",
        "POS",
        "Tagger",
        "OpenNLP (Baldridge, J., 2005) + the two parsers below",
        "Parser",
        "Stanford (Klein and Manning, 2003) Berkeley (Petrov and Klein, 2007)",
        "Dep.",
        "parser",
        "Stanford (Klein and Manning, 2003)",
        "NE",
        "Recognizer",
        "OpenNLP (Baldridge, J., 2005) Stanford (Finkel et al., 2005)",
        "NP Detector",
        "In-house"
      ]
    },
    {
      "heading": "4. Evaluation",
      "text": [
        "Reconcile incorporates the six most commonly used coreference resolution data sets, two from the MUC conferences (MUC-6, 1995; MUC-7, 1997) and four from the ACE Program (NIST, 2004).",
        "For ACE, we incorporate only the newswire portion.",
        "When available, Reconcile employs the standard test/train split.",
        "Otherwise, we randomly split the data into a training and test set following a 70/30 ratio.",
        "Performance is evaluated according to the B and MUC scoring metrics.",
        "Reconcile can be easily configured with different algorithms for markable detection, anaphoric-ity determination, feature extraction, etc., and run against several scoring metrics.",
        "For the purpose of this sample evaluation, we create only one particular instantiation of Reconcile, which we will call ReconcHe20\\0 to differentiate it from the general platform.",
        "ReconcHe20\\0 is configured using the following components:"
      ]
    },
    {
      "heading": "1.. Preprocessing",
      "text": [
        "(a) Sentence Splitter: OpenNLP (b) Tokenizer: OpenNLP (c) POS Tagger: OpenNLP (d) Parser: Berkeley (e) Named Entity Recognizer: Stanford",
        "2.",
        "Feature Set - A hand-selected subset of 60 out of the more than 80 features available.",
        "The features were selected to include most of the features from Soon et al.",
        "Soon et al.",
        "(2001), Ng and Cardie (2002) and Bengtson and Roth (2008)."
      ]
    },
    {
      "heading": "3.. Classifier - Averaged Perceptron",
      "text": [
        "4.",
        "Clustering - Single-link - Positive decision threshold was tuned by cross validation of the training set.",
        "The irst two rows of Table 3 show the performance of Reconcile2oio.",
        "For all data sets, Bscores are higher than MUC scores.",
        "The MUC score is highest for the MUC6 data set, while Bscores are higher for the ACE data sets as compared to the MUC data sets.",
        "Due to the difficulties outlined in Section 1, results for Reconcile presented here are directly comparable only to a limited number of scores reported in the literature.",
        "The bottom three rows of Table 3 list these comparable scores, which show that Reconcile20\\0 exhibits state-of-the-art performance for supervised learning-based coreference resolvers.",
        "A more detailed study of Reconcile-based coreference resolution systems in different evaluation scenarios can be found in",
        "Stoyanov et al.",
        "(2009)."
      ]
    },
    {
      "heading": "5. Conclusions",
      "text": [
        "Reconcile is a general architecture for coreference resolution that can be used to easily create various coreference resolvers.",
        "Reconcile provides broad support for experimentation in coreference resolution, including implementation of the basic architecture of contemporary state-of-the-art coref-erence systems and a variety of individual modules employed in these systems.",
        "Additionally, Reconcile handles all of the formatting and scoring peculiarities of the most widely used coref-erence resolution data sets (those created as part of the MUC and ACE conferences) and, thus, allows for easy implementation and evaluation across these data sets.",
        "We hope that Reconcile will support experimental research in coreference resolution and provide a state-of-the-art corefer-ence resolver for both researchers and application developers.",
        "We believe that in this way Reconcile will facilitate meaningful and consistent comparisons of coreference resolution systems.",
        "The full Reconcile release is available for download at",
        "http://www.cs.utah.edu/nlp/reconcile/.",
        "Step",
        "Available modules",
        "Classification",
        "various learners in the Weka toolkit libSVM (Chang and Lin, 2001) SVMught (Joachims, 2002)",
        "Clustering",
        "Single-link",
        "Best-First",
        "Most Recent First",
        "Scoring",
        "MUC score (Vilain et al., 1995)",
        "B score (Bagga and Baldwin, 1998)",
        "CEAF score (Luo, 2005)"
      ]
    },
    {
      "heading": "Acknowledgments",
      "text": [
        "This research was supported in part by the National Science Foundation under Grant # 0937060 to the Computing Research Association for the CIFellows Project, Lawrence Livermore National Laboratory subcontract B573245, Department of Homeland Security Grant N0014-07-1-0152, and Air Force Contract FA8750-09-C-0172 under the DARPA Machine Reading Program.",
        "The authors would like to thank the anonymous reviewers for their useful comments.",
        "System",
        "Score",
        "Data sets",
        "MUC6",
        "MUC7",
        "ACE-2",
        "ACE03",
        "ACE04",
        "ACE05",
        "Reconcile2oio",
        "MUC",
        "68.50",
        "62.80",
        "65.99",
        "67.87",
        "62.03",
        "67.41",
        "B",
        "70.88",
        "65.86",
        "78.29",
        "79.39",
        "76.50",
        "73.71",
        "Soon et al.",
        "(2001)",
        "MUC",
        "62.6",
        "60.4",
        "-",
        "-",
        "-",
        "-",
        "Ng and Cardie (2002)",
        "MUC",
        "70.4",
        "63.4",
        "-",
        "-",
        "-",
        "-",
        "Yang et al.",
        "(2003)",
        "MUC",
        "71.3",
        "60.2",
        "-",
        "-",
        "-",
        "-"
      ]
    }
  ]
}
