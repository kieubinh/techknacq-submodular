{
  "info": {
    "authors": [
      "Gregor Leusch",
      "Hermann Ney"
    ],
    "book": "Proceedings of the Joint Fifth Workshop on Statistical Machine Translation and MetricsMATR",
    "id": "acl-W10-1747",
    "title": "The RWTH System Combination System for WMT 2010",
    "url": "https://aclweb.org/anthology/W10-1747",
    "year": 2010
  },
  "references": [
    "acl-C04-1032",
    "acl-C96-2141",
    "acl-D08-1039",
    "acl-D09-1022",
    "acl-E06-1005",
    "acl-J03-1002",
    "acl-J93-2003",
    "acl-L08-1403",
    "acl-P02-1040",
    "acl-P05-3026",
    "acl-P07-1040",
    "acl-W06-3110",
    "acl-W09-0410"
  ],
  "sections": [
    {
      "text": [
        "Gregor Leusch and Hermann Ney",
        "RWTH Aachen University Aachen, Germany",
        "{leusch,ney}@cs.rwth-aachen.de",
        "RWTH participated in the System Combination task of the Fifth Workshop on Statistical Machine Translation (WMT 2010).",
        "For 7 of the 8 language pairs, we combine 5 to 13 systems into a single consensus translation, using additional n-best reranking techniques in two of these language pairs.",
        "Depending on the language pair, improvements versus the best single system are in the range of +0.5 and +1.7 on BLEU, and between – 0.4 and – 2.3 on TER.",
        "Novel techniques compared with RWTH's submission to WMT 2009 include the utilization of n-best reranking techniques, a consensus true casing approach, a different tuning algorithm, and the separate selection of input systems for CN construction, primary/skeleton hypotheses, HypLM, and true casing."
      ]
    },
    {
      "heading": "1. Introduction",
      "text": [
        "The RWTH approach to MT system combination is a refined version of the ROVER approach in ASR (Fiscus, 1997), with additional steps to cope with reordering between different hypotheses, and to use true casing information from the input hypotheses.",
        "The basic concept of the approach has been described by Matusov et al.",
        "(2006).",
        "Several improvements have been added later (Matusov et al., 2008).",
        "This approach includes an enhanced alignment and reordering framework.",
        "In contrast to existing approaches (Jayaraman and Lavie, 2005; Rosti et al., 2007), the context of the whole corpus rather than a single sentence is considered in this iterative, unsupervised procedure, yielding a more reliable alignment.",
        "Majority voting on the generated lattice is performed using prior weights for each system as well as other statistical models such as a special n-gram language model.",
        "In addition to lattice rescoring, n-best list reranking techniques can be applied to n best paths of this lattice.",
        "True casing is considered a separate step in RWTH's approach, which also takes the input hypotheses into account.",
        "The pipeline, and consequently the description of the pipeline given in this paper, is based on our pipeline for WMT 2009 (Leusch et al., 2009), with several extensions as described."
      ]
    },
    {
      "heading": "2. System Combination Algorithm",
      "text": [
        "In this section we present the details of our system combination method.",
        "Figure 1 gives an overview of the system combination architecture described in this section.",
        "After preprocessing the MT hypotheses, pairwise alignments between the hypotheses are calculated.",
        "The hypotheses are then reordered to match the word order of a selected primary or skeleton hypothesis.",
        "From this, we create a lattice which we then rescore using system prior weights and a language model (LM).",
        "The single best path in this CN then constitutes the consensus translation; alternatively the n best paths are generated and reranked using additional statistical models.",
        "The consensus translation is then true cased and postprocessed.",
        "The proposed alignment approach is a statistical one.",
        "It takes advantage of multiple translations for a whole corpus to compute a consensus translation for each sentence in this corpus.",
        "It also takes advantage of the fact that the sentences to be aligned are in the same language.",
        "For each of the K source sentences in the test corpus, we select one of its translations En, n = 1,..., M, as the primary hypothesis.",
        "Then we align the secondary hypotheses Em(m = 1,..., M ; n = m) with En to match the word order in En.",
        "Since it is not clear which hypothesis should be primary, i. e. has the \"best\" word order, we let several or all hypothesis play the role of the primary translation, and align all pairs of hypotheses (En, Em); n = m. In this paper, we denote the number of possible primary hypotheses by N.",
        "The word alignment is trained in analogy to the alignment training procedure in statistical MT.",
        "The difference is that the two sentences that have to be aligned are in the same language.",
        "We use the IBM Model 1 (Brown et al., 1993) and the Hidden Markov Model (HMM, (Vogel et al., 1996))",
        "nbest rescoring (Triplets, LM, ...) Consensus Translation",
        "The alignment training corpus is created from a test corpus of effectively N • (M – 1) • K sentences translated by the involved MT engines.",
        "Model parameters are trained iteratively using the GIZA++ toolkit (Och and Ney, 2003).",
        "The training is performed in the directions Em – En and En – Em.",
        "The final alignments are determined using a cost matrix C for each sentence pair (Em, En).",
        "Elements of this matrix are the local costs C(j, i) of aligning a word emj from Em to a word en>ifrom En.",
        "Following Matusov et al.",
        "(2004), we compute these local costs by interpolating the negated logarithms of the state occupation probabilities from the \"source-to-target\" and \"target-to-source\" training of the HMM model.",
        "After reordering each secondary hypothesis Em and the rows of the corresponding alignment cost matrix, we determine M – 1 monotone one-to-one alignments between En as the primary translation and Em, m = 1,..., M ; m = n. We then construct the confusion network.",
        "We consider words without a correspondence to the primary translation (and vice versa) to have a null alignment with the empty word e, which will be transformed to an e-arc in the corresponding confusion network.",
        "The M – 1 monotone one-to-one alignments can then be transformed into a confusion network, as described by Matusov et al.",
        "(2008).",
        "Instead of choosing a fixed sentence to define the word order for the consensus translation, we generate confusion networks for N possible hypotheses as primary, and unite them into a single lattice.",
        "In our experience, this approach is advantageous in terms of translation quality compared to a minimum Bayes risk primary (Rosti et al., 2007).",
        "Weighted majority voting on a single confusion network is straightforward and analogous to ROVER (Fiscus, 1997).",
        "We sum up the probabilities of the arcs which are labeled with the same word and have the same start state and the same end state.",
        "This can also be regarded as having a binary system feature in a log-linear model.",
        "The lattice representing a union of several confusion networks can then be directly rescored with an n-gram language model (LM).",
        "A transformation of the lattice is required, since LM history has to be memorized.",
        "We train a trigram LM on the outputs of the systems involved in system combination.",
        "For LM training, we take the system hypotheses for the same test corpus for which the consensus translations are to be produced.",
        "Using this \"adapted\" LM for lattice rescoring thus gives bonus to n-grams from the original system hypotheses, in most cases from the original phrases.",
        "Presumably, many of these phrases have a correct word order.",
        "Previous experimental results show that using this LM in rescoring together with a word penalty notably improves translation quality.",
        "This even results in better translations than using a \"classical\" LM trained on a monolingual training corpus.",
        "We attribute this to the fact that most of the systems we combine already include such general LMs.",
        "To generate our consensus translation, we extract the single-best path from the rescored lattice, using \"classical\" decoding as in MT.",
        "Alternatively, we can extract the n best paths for n-best list rescoring.",
        "If n-best lists were generated in the previous steps, additional sentence-based features can be calculated on these sentences, and combined in a loglinear way.",
        "These scores can then be used to rerank the sentences.",
        "For the WMT 2010 FR-EN and the DE-EN task, we generated 200-best lists, and calculated the following features:"
      ]
    },
    {
      "heading": "1.. Total score from the lattice rescoring",
      "text": []
    },
    {
      "heading": "2.. NGram posterior weights on those (Zens and",
      "text": []
    },
    {
      "heading": "3.. Word Penalty",
      "text": [
        "4.",
        "HypLM trained on a different set of hypotheses (FR-EN only)"
      ]
    },
    {
      "heading": "5.. Large fourgram model trained on Gigaword",
      "text": [
        "6.",
        "IBM1 scores and deletion counts based on a word lexicon trained on WMT training data to estimate the alignment mo",
        "GIZA++-",
        "Weighting &",
        "alignment",
        "j",
        "Network",
        "j",
        "generation",
        "*\"",
        "Reordering",
        "Rescoring"
      ]
    },
    {
      "heading": "7.. Discriminative word lexicon score (Mauser et",
      "text": [
        "Other features were also calculated, but did not seem to give an improvement on the DEV set.",
        "Previous approaches to achieve true cased output in system combination operated on true-cased lattices, used a separate input-independent true caser, or used a general true-cased LM to differentiate between alternative arcs in the lattice, as in (Leusch et al., 2009).",
        "For WMT 2010, we use per-sentence information from the input systems to determine the consensus case of each output word.",
        "Lattice generation, rescoring, and rerank-ing are performed on lower-cased input, with a lower-cased consensus hypothesis as their result.",
        "For each word in this hypothesis, we count how often each casing variant occurs in the input hypotheses for this sentence.",
        "We then use the variant with the highest support for the final consensus output.",
        "One advantage is that the set of systems used to determine the consensus case does not have to be identical to those used for building the lattice: Assuming that each word from the consensus hypothesis also occurs in one or several of the true casing input hypotheses, we can focus on systems that show a good true casing performance."
      ]
    },
    {
      "heading": "3. Tuning",
      "text": [
        "For lattice rescoring, we need to tune system weights, LM factor, and word penalty to produce good consensus translations.",
        "The same holds for the log-linear weights in n-best reranking.",
        "For the WMT 2010 Workshop, we selected a linear combination of BLEU (Papineni et al., 2002) and TER (Snover et al., 2006) as optimization criterion, 6 := argmax@ {BLEU – TER}, based on previous experience (Mauser et al., 2008).",
        "For more stable results, we use the case-insensitive variants for both measures, despite the explicit use of case information in the pipeline.",
        "System weights were tuned to this criterion using the Downhill Simplex method.",
        "Because we considered the number of segments in the tuning set to be too small to allow for a further split into an actual tuning and a control (dev) part, we went for a method closely related to 5-fold cross validation: We randomly split the tuning set into 5 equal-sized parts, and tune parameters on four fifth of the set, measuring progress on the remaining fifth.",
        "This was repeated for the other four choices for the \"dev\" part.",
        "Only settings which reliably showed progress on these five different versions were used later on the test set.",
        "For the actual weights and numerical parameters to be used on the test set, we calculate the median of the five variants, which lowered the risk of outliers and overfitting.",
        "With the large numbers of input systems - e.g., 17 for DE-EN - and their large spread in translation quality - e.g. 10% abs.",
        "in BLEU - not all systems should participate in the system combination process.",
        "For the generation of lattices, we considered several variants of systems, often starting from the top, and either replacing some of the systems very similar to others with systems further down the list, or not considering those as primary, adding further systems as additional secondaries.",
        "For true casing, and the additional HypLM for FR-EN, we selected a set of 8 to 12 promising systems, and ran an exhaustive search on all combinations of those to optimize the LM perplexity on the dev set (LM) or the true case BLEU/TER score on a consensus translation (TC).",
        "Further research may include a weighted combination here, followed by an optimization of the weights as described in the previous paragraph."
      ]
    },
    {
      "heading": "4. Experimental Results",
      "text": [
        "Each language pair and each direction in WMT 2010 had its own set of systems, so we selected and tuned for each direction separately.",
        "After submission of our system combination output to WMT 2010, we also calculated scores on the test set (TEST), to validate our results, and as a preparation for this report.",
        "Note that the scores reported for DEV are calculated on the full DEV set, but not on any combination of the one-fifth \"cross validation\" subcorpora.",
        "For French-English, we selected a set of eight systems for the primary submission, and eleven systems for the contrastive system, of which six served as skeleton.",
        "Six different systems were used for an additional HypLM, five for consensus true casing.",
        "Table 1 shows the distribution of these systems.",
        "We see the results of system combination on DEV and TEST (the latter calculated after submission) in Table 2.",
        "System combination itself turns out to have the largest improvement, +0.5 in BLEU and -0.7 in TER on TEST over the best single system.",
        "n-best reranking improves this result even more, by +0.3/-0.3.",
        "The influence of tuning and of TC selection is measurable on DEV, but rather small on TEST.",
        "For English-French, 13 systems were used to construct the lattice, 5 serving as skeleton.",
        "Five different systems were used for true casing.",
        "No n-best list reranking was performed here, as preliminary experiments did not show any significant",
        "\"A\" is the primary, \"B\" the contrastive submission.",
        "\"P\" denotes a system that served as skeleton.",
        "\"S\" a system that was only aligned to others.",
        "\"L\" denotes a system used for a larger HypLM-n-best- rescoring.",
        "\"C\" is a system used for consensus true casing.",
        "\"SC\" stands for System Combination output.",
        "\"CV\" denotes the split into five different tuning and validation parts.",
        "\"sel.",
        "TC\" is the separate selection for consensus true casing.",
        "Systems in bold were submitted for WMT 2010.",
        "For abbreviations see Table 1.",
        "For abbreviations see Table 2.",
        "gain in this direction.",
        "As a contrastive submission, we submitted the consensus of 8 systems.",
        "These are also listed in Table 1.",
        "The results can be found in Table 3.",
        "Note that the contrastive system was not tuned using the \"cross validation\" approach; as a result, we expected it to be sensitive to over-fitting.",
        "We see improvements around +1.7/-1.4 on",
        "TEST.",
        "In the German-English language pair, 17 systems were available, but incorporating only six of them turned out to deliver optimal results on DEV.",
        "As shown in Table 4, we used a combination of seven systems in the contrastive submission.",
        "While a",
        "System",
        "DE-EN",
        "EN-DE",
        "A",
        "B",
        "A",
        "B",
        "cu-zeman",
        "S",
        "cmu",
        "C",
        "P",
        "dfki",
        "S",
        "p",
        "fbk",
        "PC",
        "p",
        "P",
        "jhu",
        "p",
        "kit",
        "PC",
        "p",
        "PC",
        "p",
        "koc",
        "SC",
        "p",
        "limsi",
        "P",
        "p",
        "PC",
        "p",
        "liu",
        "C",
        "SC",
        "p",
        "rwth",
        "P",
        "p",
        "PC",
        "p",
        "sfu",
        "S",
        "uedin",
        "PC",
        "p",
        "PC",
        "p",
        "umd",
        "P",
        "p",
        "uppsala",
        "p",
        "S",
        "System",
        "FR-EN",
        "EN-FR",
        "A",
        "B",
        "A",
        "B",
        "cambridge",
        "PLC",
        "p",
        "P",
        "p",
        "cu-zeman",
        "S",
        "cmu-statxfer",
        "L",
        "s",
        "dfki",
        "S",
        "eu",
        "S",
        "geneva",
        "S",
        "huicong",
        "s",
        "jhu",
        "PL",
        "p",
        "S",
        "p",
        "koc",
        "S",
        "lig",
        "s",
        "limsi",
        "P C",
        "p",
        "SC",
        "p",
        "lium",
        "PLC",
        "s",
        "PC",
        "p",
        "nrc",
        "P C",
        "s",
        "S",
        "p",
        "rali",
        "PL",
        "p",
        "PC",
        "p",
        "rwth",
        "P",
        "p",
        "PC",
        "p",
        "uedin",
        "PLC",
        "p",
        "PC",
        "p",
        "TUNE",
        "TEST",
        "BLEU",
        "TER",
        "BLEU",
        "TER",
        "Best single",
        "23.8",
        "59.7",
        "23.5",
        "59.7",
        "Lattice SC",
        "24.7",
        "58.5",
        "25.0",
        "57.9",
        "+ tuning",
        "25.1",
        "57.6",
        "25.0",
        "57.6",
        "+ CV tuning",
        "24.8",
        "58.0",
        "24.9",
        "57.8",
        "+ nbest rerank.",
        "25.3",
        "57.6",
        "24.9",
        "57.6",
        "+ sel.",
        "for TC",
        "25.5",
        "57.5",
        "24.9",
        "57.6",
        "Contrast.",
        "SC",
        "25.2",
        "57.7",
        "24.8",
        "57.7",
        "TUNE",
        "TEST",
        "BLEU",
        "TER",
        "BLEU",
        "TER",
        "Best single",
        "27.9",
        "55.4",
        "28.5",
        "54.0",
        "Lattice SC",
        "28.4",
        "55.0",
        "29.0",
        "53.3",
        "+ tuning",
        "28.8",
        "54.5",
        "29.1",
        "53.3",
        "+ CV tuning",
        "28.6",
        "54.7",
        "29.1",
        "53.3",
        "+ nbest rerank.",
        "29.0",
        "54.4",
        "29.4",
        "53.0",
        "+ sel.",
        "for TC",
        "29.1",
        "54.3",
        "29.3",
        "53.0",
        "Contrast.",
        "SC",
        "28.9",
        "54.3",
        "28.8",
        "53.4",
        "TUNE",
        "TEST",
        "BLEU",
        "TER",
        "BLEU",
        "TER",
        "Best single",
        "27.1",
        "55.7",
        "26.5",
        "56.1",
        "Primary SC",
        "28.3",
        "55.2",
        "28.2",
        "54.7",
        "Contrast.",
        "SC",
        "28.5",
        "54.7",
        "28.1",
        "54.6",
        "TUNE",
        "TEST",
        "BLEU",
        "TER",
        "BLEU",
        "TER",
        "Best single",
        "16.1",
        "66.3",
        "16.4",
        "65.7",
        "Primary SC",
        "16.4",
        "64.9",
        "17.0",
        "63.7",
        "Contrast.",
        "SC",
        "16.4",
        "64.9",
        "17.3",
        "63.4",
        "For abbreviations see Table 1.",
        "No contrastive systems were built for this language pair.",
        "different set of five systems was used for consensus true casing, it turned out that using the same six systems for the \"additional\" HypLM as for the lattice seemed to be optimal in our approach.",
        "Table 5 shows the outcome of our experiments: Again, we see that the largest effect on TEST results from system combination as such (+1.5/-1.8).",
        "The other steps, in particular tuning and selection for TC, seem to help on DEV, but make hardly a difference on TEST.",
        "n-best reranking brings an improvement of -0.2 in TER, but at a minor deterioration (-0.1) in BLEU.",
        "In the opposite direction, English-German, we combined all twelve systems, five of them serving as skeleton.",
        "The contrastive submission consists of a combination of eight systems.",
        "Six systems were used for true casing.",
        "Again, n-best list rescoring did not result in any improvement in preliminary experiments, and was skipped.",
        "Results are shown in Table 6: We see that even though both versions perform equally well on DEV (+0.4/-1.4), the contrastive system performs better by +0.3/-0.3 on TEST (+0.9/-2.3).",
        "In both directions involving Czech, the number of systems was rather limited, so no additional selection turned out to be necessary, and we did not build a contrastive system.",
        "For Czech-English, all six systems were used; three of them for true casing.",
        "For English-Czech, all eleven systems were used in building the lattice, six of them also as skeleton.",
        "Five systems were used in the true casing step.",
        "Table 7 lists these systems.",
        "From the results in Table 8, we see that for CZ-EN, system combination gains around +0.5 in BLEU, but at costs of+0.4 to +0.7 in TER.",
        "For EN-CZ, the results look more positive: While we see only -0.3/1.7 on DEV, there is a significant improvement of +1.2/-2.8 on TEST.",
        "In the Spanish-English language pair, we did not see any improvement at all on the direction with English as target in preliminary experiments.",
        "Consequently, and given the time constraints, we did not further investigate on this language pair.",
        "Post-eval experiments revealed that improvements of +0.3/-0.3 are possible, with far off-center weights favoring the top three systems.",
        "On English-Spanish, where these preliminary experiments showed a gain, we used seven out of the available ten systems in building the lattice for the primary system, eight for the contrastive.",
        "Five of those were uses for consensus true casing.",
        "Table 9 lists these systems.",
        "Table 10 shows the results on this language pair: For both the primary and the contrastive systems we see improvements of around +1.7/-2.3 on DEV, and +1.3/-2.6 on TEST.",
        "Except for the TER on TEST, these two submissions differ only by ±0.1 from each other.",
        "System",
        "CZ-EN",
        "EN-CZ",
        "aalto",
        "P",
        "cmu",
        "PC",
        "cu-bojar",
        "P",
        "P",
        "cu-tecto",
        "S",
        "cu-zeman",
        "P",
        "SC",
        "dcu",
        "P",
        "eurotrans",
        "S",
        "google",
        "PC",
        "PC",
        "koc",
        "PC",
        "pc-trans",
        "S",
        "potsdam",
        "PC",
        "sfu",
        "S",
        "uedin",
        "PC",
        "PC",
        "System",
        "EN-ES",
        "A",
        "B",
        "cambridge",
        "PC",
        "p",
        "dcu",
        "P",
        "p",
        "dfki",
        "PC",
        "p",
        "jhu",
        "PC",
        "p",
        "sfu",
        "PC",
        "p",
        "uedin",
        "PC",
        "p",
        "upv",
        "p",
        "upv-nnlm",
        "P",
        "p",
        "TUNE BLEU 1 TER",
        "TEST BLEU 1 TER",
        "ES-EN",
        "Best single",
        "28.7",
        "53.6",
        "-",
        "-",
        "SC",
        "29.0",
        "53.3",
        "-",
        "-",
        "EN-ES",
        "Best single",
        "27.8",
        "55.2",
        "28.7",
        "54.0",
        "Primary SC",
        "29.5",
        "52.9",
        "30.0",
        "51.4",
        "Contrast.",
        "SC",
        "29.6",
        "52.8",
        "30.1",
        "51.7",
        "TUNE",
        "TEST",
        "BLEU",
        "TER",
        "BLEU",
        "TER",
        "CZ-EN",
        "Best single",
        "21.8",
        "58.4",
        "22.9",
        "57.5",
        "Primary SC",
        "22.4",
        "59.1",
        "23.4",
        "57.9",
        "EN-CZ",
        "Best single",
        "17.0",
        "67.1",
        "16.6",
        "66.4",
        "Primary SC",
        "16.7",
        "65.4",
        "17.4",
        "63.6"
      ]
    },
    {
      "heading": "5. Conclusions",
      "text": [
        "We have shown that our system combination system can lead to significant improvements over single best MT output where a significant number of comparably good translations is available on a single language pair.",
        "n-best reranking can further improve the quality of the consensus translation; results vary though.",
        "While consensus true casing turned out to be very useful despite of its simplicity, we were unable to find significant improvements on TEST from the selection of a separate set of true casing input systems."
      ]
    },
    {
      "heading": "Acknowledgments",
      "text": [
        "This work was partly realized as part of the Quaero Programme, funded by OSEO, French State agency for innovation.",
        "This work was partly supported by the Defense Advanced Research Projects Agency (DARPA) under Contract",
        "No.",
        "HR0011-06-C-0023."
      ]
    }
  ]
}
