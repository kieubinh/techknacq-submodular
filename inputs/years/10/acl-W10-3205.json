{
  "info": {
    "authors": [
      "Takashi Tsunakawa",
      "Hiroyuki Kaji"
    ],
    "book": "Proceedings of the Eighth Workshop on Asian Language Resouces",
    "id": "acl-W10-3205",
    "title": "Augmenting a Bilingual Lexicon with Information for Word Translation Disambiguation",
    "url": "https://aclweb.org/anthology/W10-3205",
    "year": 2010
  },
  "references": [
    "acl-C02-1058",
    "acl-H05-1097",
    "acl-H93-1052",
    "acl-J90-1003",
    "acl-J90-2002",
    "acl-J93-1003",
    "acl-J93-1007",
    "acl-J96-1001",
    "acl-J98-1001",
    "acl-P02-1044",
    "acl-P09-1058",
    "acl-P95-1050"
  ],
  "sections": [
    {
      "text": [
        "Takashi Tsunakawa Hiroyuki Kaji",
        "Faculty o f Informatics Faculty o f Informatics",
        "Shizuoka University Shizuoka University",
        "We describe a method for augmenting a bilingual lexicon with additional information for selecting an appropriate translation word.",
        "For each word in the source language, we calculate a correlation matrix of its association words versus its translation candidates.",
        "We estimate the degree of correlation by using comparable corpora based on these assumptions: \"parallel word associations\" and \"one sense per word association.\"",
        "In our word translation disambiguation experiment, the results show that our method achieved 42% recall and 49% precision for Japanese-English newspaper texts, and 45% recall and 76% precision for Chinese-Japanese technical documents."
      ]
    },
    {
      "heading": "1. Introduction",
      "text": [
        "The bilingual lexicon, or bilingual dictionary, is a fundamental linguistic resource for multilingual natural language processing (NLP).",
        "For each word, multiword, or expression in the source language, the bilingual lexicon provides translation candidates representing the original meaning in the target language.",
        "Selecting the right words for translation is a serious problem in almost all of multilingual NLP.",
        "One word in the source language almost always has two or more translation candidates in the target language by looking up them in the bilingual lexicon.",
        "Because each translation candidate has a distinct meaning and property, we must be careful in selecting the appropriate translation candidate that has the same sense as the word inputted.",
        "This task is often called word translation disambiguation.",
        "In this paper, we describe a method for adding information for word translation disambiguation into the bilingual lexicon.",
        "Comparable corpora can be used to determine which word associations suggest which translations of the word (Kaji and Morimoto, 2002).",
        "First, we extract word associations in each language corpus and align them by using a bilingual dictionary.",
        "Then, we construct a word correlation matrix for each word in the source language.",
        "This correlation matrix works as information for word translation disambiguation.",
        "We carried out word translation experiments on two settings: English-to-Japanese and Chinese-to-Japanese.",
        "In the experiments, we tested Dice/Jaccard coefficients, pointwise mutual information, log-likelihood ratio, and Student's ?-score as the association measures for extracting word associations.",
        "2 Constructing word correlation matrices for word translation disambiguation",
        "In this section, we describe the method for calculating a word correlation matrix for each word in the source language.",
        "The correlation matrix for a word f consists of its association words and its translation candidates.",
        "Among the translation candidates, we choose the most acceptable one that is strongly suggested by its association words occurring around f.",
        "We use two assumptions for this framework: (i) Parallel word associations:",
        "Translations of words associated with each other in a language are also associated with each other in another language (Rapp, 1995).",
        "For example, two English words \"tank\" and \"soldier\" are associated with each other and their Japanese translations \"IPc^ï (sensha)\" and \"Äi (hei-shi)\" are also associated with each other.",
        "(ii) One sense per word association:",
        "A polysemous word exhibits only one sense of a word per word association (Yarowsky, 1993).",
        "For example, a poly-semous word \"tank\" exhibits the \"military vehicle\" sense of a word when it is associated with \"soldier,\" while it exhibits the \"container for liquid or gas\" sense when it is associated with \"gasoline.\"",
        "Under these assumptions, we determine which of the words associated with an input word suggests which of its translations by aligning word associations by using a bilingual dictionary.",
        "Consider the associated English words (tank, soldier) and their Japanese translations (IPc^ï (sensha), (heishi)).",
        "When we translate the word \"tank\" into Japanese, the associated word \"soldier\" helps us to translate it into \"IPc^ (sensha)\", not to translate it into \" ^l/ty (tanku)\" which means \"a storage",
        "This naive method seems to suffer from the following difficulties:",
        "• A disparity in topical coverage between two corpora in two languages",
        "• A shortage in the bilingual dictionary",
        "• The existence of polysemous associated words that cannot determine the correct sense of the input word",
        "For these difficulties, we use the tendency that the two words associated with a third word are likely to suggest the same sense of the third word when they are also associated with each other.",
        "For example, consider an English associated word pair (tank, troop).",
        "The word \"troop\" cannot distinguish the different meanings because it can co-occur with the word \"tank\" in both senses of the word.",
        "The third word \"soldier,\" which is associated with both \"tank\" and \"troop,\" can suggest the translation \" IPc^ (sensha).\"",
        "The overview of our method is shown in Figure 1.",
        "We first extract associated word pairs in the source and target languages from comparable corpora.",
        "Using a bilingual dictionary, we obtain alignments of these word associa-",
        "Source language (SL) corpus Target language (TL) corpus Extract word associations Extract word associations SL associated word pairs with association scores TL associated word pairs with association scores Bilingual dictionary Align SL and TL word associations For each SLword.",
        "calculate correlation scores between its associated SL words and its translations Co-occurring words",
        "Translation Selection Output word",
        "tions.",
        "Then, we iteratively calculate a correlation matrix for each word in the source language.",
        "Finally, we select the translation with the highest correlation from the translation candidates of the input word and the co-occurring words.",
        "For each input word in the source language, we calculate correlation values between their translation candidates and their association words.",
        "The algorithm is shown in Figure 2.",
        "In Algorithm 1, the initialization of correlation values is based on word associations, where D is a set of word pairs in the bilingual dictionary, and Af and Ae are the sets of associated word pairs.",
        "First, we retain associated words f'(i) when its translation e' exists and when e' is associated with e. In the iteration, the correlation values of associated words f'(i) that suggest e(j) increase relatively by using association scores a(/'(0</) and",
        "Correlation matrix for each SL word Input word",
        "a(f'(i),f\").",
        "In our experiments, we set the number of iterations Nr to 10.",
        "2.2 Alternative association measures for extracting word associations",
        "We extract co-occurring word pairs and calculate their association scores.",
        "In this paper, we focus on some frequently used metrics for finding word associations based on their occurrence/co-occurrence frequencies.",
        "Suppose that words x and y frequently co-occur.",
        "Let n1 and n2 be the occurrence frequencies of x and y respectively, and let m be the frequency that x and y co-occur between w content words.",
        "The parameter w is a window size that adjusts the range of co-occurrences.",
        "Let N and M be the sum of occurrences/co-occurrences of all words/word pairs, respectively.",
        "The frequencies are summarized in Table 1.",
        "The word association scores a(x, y) are defined as follows:",
        "Jaccard coefficient (Smadja et al., 1996)",
        "Pointwise mutual information (pMI)",
        "Log-likelihood ratio (LLR) (Dunning,",
        "Student's t-score (TScore) (Church et al.,",
        "We calculate association scores for all pairs of words when their occurrence frequencies are not less than a threshold Tfand when their Algorithm 1: Input:",
        "f: an input word Nr: number of iterations A bilingual lexicon Word association scores a for both languages",
        "x",
        "occur",
        "x not occur",
        "Total",
        "y",
        "occur",
        "m",
        "n2 -m",
        "n2",
        "y not",
        "occur",
        "n1 -m",
        "M- n1-n2 + m",
        "N-n2",
        "Total",
        "n1",
        "N-n1",
        "N",
        "Table 2.",
        "Word correlation matrix for a word \"home,\" as information for word translation disambiguation threshold Tc.",
        "We handle word pairs whose association scores are not less than a predefined value TA; some of the thresholds were evaluated in our experiment.",
        "The associated word pair sets Af and Ae in Algorithm 1 includes only word pairs whose scores are not less than TA in the source and target language, respectively."
      ]
    },
    {
      "heading": "3. Word Translation Disambiguation",
      "text": [
        "Consider that a translator changes a word in an input sentence.",
        "Usually, two or more translation candidates are enumerated in the bilingual dictionary for a word.",
        "The translator should select a translation word that is grammatically/ syntactically correct, semantically equivalent to the input, and pragmatically appropriate.",
        "We assume that the translation word e for an input word ftends to be selected if words occurring around fare strongly correlated with e. Using the correlation matrices, we select e as a translation if the associated word f' occurs around f and the score C(f',é) is large.",
        "In addition, we take distance between fand f' into account.",
        "We define the score of the translation word e(f0) for an input word f0 as follows.",
        "Consider an input word f0 that occurs in the context of \"...f2 f-1 f f1 f The score for a translation word e(f0) for an input word f is defined as where p is the relative position of the words surrounding f0, C/o(f,,e(f0)) is the value of the correlation matrix for f0, and y",
        "A career .284 hitter, Beltran batted .267 in the regular season, split between Kansas City and Houston, but came alive in the playoffs.",
        "He hit .435 in 12 postseason games, with six stolen bases, eight home runs and 14 runs batted in.",
        "is the window size for word translation disambiguation.",
        "A simple example is shown in Figure 3.",
        "The word \"home\" in this context means the sense of \"home base\" used in baseball games, not \"house\" or \"hometown.\"",
        "The surrounding words such as \"games,\" \"bases,\" and \"runs\" can be clues for indicating the correct sense of the word.",
        "By using the correlation matrix (Table 2) and formula (8), we calculate a score for each translation candidate and select the best translation with the largest score.",
        "In this case, Score(^M (honrui)) = 0.1134 was the best score and the correct translation was selected.",
        "4Experiment",
        "We carried out word translation experiments on two different settings.",
        "In the first experiment (Experiment A), we used large-scale comparable corpora from English and Japanese newspaper texts.",
        "The second experiment (Experiment B) was targeted at translating technical terms by using Chinese and Japanese domain-specific corpora.",
        "We used the following linguistic resources for the experiments: • Experiment A■ Training comparable corpora",
        "<home>",
        "(kuni) [country]",
        "(honrui) [home base]",
        "(ie)",
        "[house]",
        "(jitaku) [my home]",
        "WM",
        "(katei) [homeplace]",
        "(shisetsu) [facilities]",
        "base",
        "0.009907",
        "0.017649",
        "0.005495",
        "0.006117",
        "0.005186",
        "0.005597",
        "game",
        "0.043507",
        "0.048358",
        "0.025145",
        "0.028208",
        "0.019987",
        "0.023014",
        "Kansas",
        "0.010514",
        "0.003786",
        "0.004280",
        "0.007307",
        "0.004320",
        "0.005459",
        "run",
        "0.023468",
        "0.042035",
        "0.014430",
        "0.015765",
        "0.012061",
        "0.012986",
        "season",
        "0.044855",
        "0.050952",
        "0.025406",
        "0.028506",
        "0.020716",
        "0.023631",
        "- The New York Times texts from English Gigaword Corpus Fourth Edition (LDC2009T13): 1.6 billion words■ Test corpus",
        "• Experiment B1",
        "■ Training comparable corpus",
        "- In-house Chinese-Japanese parallel corpus in the environment domain: 53,027 sentence pairs• Experiment B2",
        "- In-house Chinese-Japanese parallel corpus in the medical domain: 123,175 sentence pairs• Dictionaries",
        "■ Japanese-English bilingual dictionaries: Total 333,656 term pairs",
        "- EDR Electronic Dictionary - Eijiro, Third Edition■ Chinese-English bilingual dictionary",
        "- Wanfang Data Chinese-English Science/Technology Bilingual Dictionary: 525,259 term pairs",
        "For the Chinese-Japanese translation, we generated a Chinese-Japanese bilingual dictionary by merging Chinese-English and Japanese-English dictionaries.",
        "The Chinese-Japanese bilingual dictionary includes",
        "We could prepare only parallel corpora for Chinese-Japanese language pair as training corpora.",
        "For our experiments, we assumed them as comparable corpora and did not use the correspondence of sentence pairs.",
        "every Chinese-Japanese term pair (tC, tJ) when (tC, tE) and (tJ, tE) were present in the dictionaries for one or more English terms tE.",
        "This merged dictionary contains about two million term pairs.",
        "While these Chinese-Japanese term pairs include wrong translations, it was not a serious problem in our experiments because wrong translations were excluded in the procedure of our method.",
        "We applied morphological analysis and part-of-speech tagging by using TreeTagger (Schmid, 1994) for English, JUMAN for Japanese, and mma (Kruengkrai et al., 2009) for Chinese, respectively.",
        "In the test corpus, we manually annotated reference translations for each target word.",
        "The parameters we used were as follows: Experiment A:",
        "Tf= 100, Tc = 4, w = 10, y = 25.",
        "Some of the parameters were empirically adjusted.",
        "In the experiments, the matrices could be obtained for 9103 English words (A), 674 Chinese words (B1) and 1258 Chinese words (B2), respectively.",
        "In average one word had 3.24 (A), 1.15 (B1) and 1.51 (B2) translation candidates by using the best setting.",
        "Table 2 is the resulted matrix for the word \"home\" in the Experiment A.",
        "Table 3 shows the results of Experiment A.",
        "We classified the translation results for 1,420 target English words into four categories: True, False, R, and M. When the translation was output, the result was True if the output is included in the reference translations, and it was False otherwise.",
        "The result was R when all the associated words in the correlation matrix did not occur around the input word.",
        "The result was M when no correlation matrix existed for the input word.",
        "We did not select a translation output in these cases.",
        "The recall and precision are shown in the parentheses below.",
        "Among the settings, we obtained the best results, 42% recall and 49% precision, when we used the Jaccard coefficient for association scores and TA = 0, which means all pairs were taken into consideration.",
        "Among other settings, the Dice coefficient achieved a comparable performance with Jaccard.",
        "Tables 4 and 5 show the results of Experiment B.",
        "In each domain, we tested only the settings on Dice, pMI, and LLR with TA = 0.",
        "In the environmental domain, the pointwise mutual information score achieved the best performance, 45% recall and 76% precision.",
        "However, the Dice coefficient gave the best recall (55%) for the medical domain.",
        "This result indicates that Experiment B1/B2 had higher precision and more words without the correlation matrix than Experiment A had.",
        "As a result, we could generate bilingual lexicons with word translation disambiguation information for 9103 English words and 1932 Chinese words.",
        "Although the number of words might be augmented by changing the settings, the size does not seem to be sufficient as bilingual dictionaries.",
        "The availability of larger output should be investigated.",
        "The experimental results show that our method selected correct translations for at least half of the input words if a correlation matrix existed and if the associated words co-occur.",
        "Among all input words, at least 40% of the input words can be translated.",
        "The bilingual dictionaries included 24.4, 38.6, and 52.0 translation candidates for one input word in Experiment A, B1, and B2, respectively.",
        "When we select the most frequent word, the precisions were 7%, 1%, and 1%, respectively.",
        "Meanwhile, the average numbers of translation",
        "(40%/67%) Table 5.",
        "Results of Chinese-Japanese word translation for medical domain (B2).",
        "candidates in the correlation matrices for one input word are shown in Table 6.",
        "These indicate that our method effectively removed noisy translations from the Chinese-Japanese dictionary merged Japanese-English and Chinese-English dictionaries, and that the association scores contributed word translation disambiguation.",
        "Score TA",
        "True False R M",
        "Dice 0 0.001 0.01",
        "588 627 90 115 (41%/48%)",
        "586 619 94 121 (41%/49%)",
        "479 507 243 191 (34%/49%)",
        "Jacc- 0 ard",
        "0.001 0.01",
        "594 621 90 115 (42%/49% )",
        "584 609 105 122 (41%/49%)",
        "348 378 374 320 (25%/48%)",
        "pMI 0 1",
        "292 309 704 115 (21%/49%)",
        "293 308 703 116 (21%/49%)",
        "LLR 10 100",
        "530 747 28 115 (37%/42%)",
        "529 744 32 115 (37%/42%)",
        "T- 1",
        "Score",
        "4",
        "Table 3.",
        "Resu translation (A)",
        "Score TA",
        "486 793 26 115 (34%/38%)",
        "489 787 26 118 (34%/38%) lts of English-Japanese word",
        "True False R M",
        "Dice 0 pMI 0 LLR 0",
        "1984 895 82 621 (55%/69%)",
        "1886 804 271 621 (53%/70%)",
        "1652 1246 63 621 (46%/57%)",
        "Among the settings, the Jaccard/Dice coefficients were proven to be effective, although pointwise mutual information (pMI) was also effective for technical domains and the Chinese-Japanese language pair.",
        "Because the Jac-card/Dice coefficients were originally used for measuring the proximity of sets, these might be effective for collecting related words by using the similarity of kinds of co-occurring words.",
        "However, pMI tends to emphasize low-frequency words as associated words.",
        "The consequence of this tendency might be that low-frequency associated words do not appear around the input word in the newspaper text.",
        "In most metrics for the association score, the lowest threshold value TA achieved the best performance.",
        "This result indicates that the cut-off of associated words by some thresholds was not effective, although it requires more time and memory space to obtain correlation matrices without cut-off.",
        "How to optimize other parameters in our method remains unsolved.",
        "More words without the correlation matrix were present in Experiment B1/B2 than in Experiment A because the input word was often a technical term that was not in the bilingual dictionary.",
        "The better recall and precision of Experiment B1/B2 came from several reasons, including difference of test sets and language pairs.",
        "In addition, it might have an impact on this result that the fact that word translation disambiguation of technical terms is easier than word translation disambiguation of common words.",
        "We handled only nouns as input words and associated words in this study.",
        "Considering only the co-occurrence in a fixed window would be insufficient to apply this method to the translation of verbs and other parts of speech.",
        "In future work, we will consider syntactic co-occurrence, which is obtained by conducting dependency parsing of the results of a sentence.",
        "The correlation between associated words and translation candidates also needs to be re-examined.",
        "Similarly, we will handle verbs as associated words to the input nouns by using syntactic co-occurrence."
      ]
    },
    {
      "heading": "5. Related Work",
      "text": [
        "Statistical machine translation (Brown et al., 1990) automatically acquires knowledge for word translation disambiguation from parallel corpora.",
        "Word translation disambiguation is based on probabilities calculated from the word alignment, phrase pair extraction, and the language model.",
        "However, much broad context/domain information is not considered.",
        "Carpuat and Wu (2007) proposed context-dependent phrasal translation lexicons by introducing context-dependent features into statistical machine translation.",
        "Unsupervised methods using dictionaries and corpora were proposed for monolingual WSD (Ide and Veronis, 1998).",
        "They used grammatical information including parts-of-speech, syntactically related words, and co-occurring words as the clues for the WSD.",
        "Our method uses a part of the clues for bilingual WSD and word translation disambiguation.",
        "Li and Li (2002) constructed a classifier for word translation disambiguation by using a bilingual dictionary with bootstrapping techniques.",
        "We also conducted recursive calculation by dealing with the bilingual dictionary as the seeds of the iteration.",
        "Vickrey et al.",
        "(2005) introduced a context as a feature for a statistical MT system and they generated word-level translations.",
        "How to introduce the word-level translation disambiguation into sentence-level translation is a considerable problem."
      ]
    },
    {
      "heading": "6. Conclusion",
      "text": [
        "In this paper, we described a method for adding information for word translation disambiguation into the bilingual lexicon, by considering the associated words that co-occur with the input word.",
        "We based our method on the following two assumptions: \"parallel word associations\" and \"one sense per word association.\"",
        "We aligned word associations by using a bilingual dictionary, and constructed a correlation matrix for each word in the source language for word translation disambiguation.",
        "Experiments showed that our method was applicable for both common newspaper text and domain-specific text and for two language pairs.",
        "The Jaccard/Dice coefficients were proven to be more effective than the other metrics as word association scores.",
        "Future work includes extending our method to handle verbs as input words by introducing syntactic co-occurrence.",
        "The comparisons with other disambiguation methods and machine translation systems would strengthen the effectiveness of our method.",
        "We consider also evaluations on real NLP tasks including machine translation."
      ]
    },
    {
      "heading": "Acknowledgments",
      "text": [
        "This work was partially supported by Japanese/Chinese Machine Translation Project in Special Coordination Funds for Promoting Science and Technology (MEXT, Japan)."
      ]
    }
  ]
}
