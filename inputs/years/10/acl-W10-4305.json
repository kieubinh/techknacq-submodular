{
  "info": {
    "authors": [
      "Jie Cai",
      "Michael Strube"
    ],
    "book": "Proceedings of the SIGDIAL 2010 Conference",
    "id": "acl-W10-4305",
    "title": "Evaluation Metrics for End-to-End Coreference Resolution Systems",
    "url": "https://aclweb.org/anthology/W10-4305",
    "year": 2010
  },
  "references": [],
  "sections": [
    {
      "text": [
        "Commonly used coreference resolution evaluation metrics can only be applied to key mentions, i.e. already annotated mentions.",
        "We here propose two variants of the B and CEAF coreference resolution evaluation algorithms which can be applied to coreference resolution systems dealing with system mentions, i.e. automatically determined mentions.",
        "Our experiments show that our variants lead to intuitive and reliable results."
      ]
    },
    {
      "heading": "1. Introduction",
      "text": [
        "The coreference resolution problem can be divided into two steps: (1) determining mentions, i.e., whether an expression is referential and can take part in a coreferential relationship, and (2) deciding whether mentions are coreferent or not.",
        "Most recent research on coreference resolution simplifies the resolution task by providing the system with key mentions, i.e. already annotated mentions (Luo et al.",
        "(2004), Denis & Baldridge (2007), Culotta et al.",
        "(2007), Haghighi & Klein (2007), inter alia; see also the task description of the recent SemEval task on coref-erence resolution at http : //stel.",
        "ub.",
        "edu/ semeval2010-coref), or ignores an important part of the problem by evaluating on key mentions only (Ponzetto & Strube, 2006; Bengtson & Roth, 2008, inter alia).",
        "We follow here Stoyanov et al.",
        "(2009, p.657) in arguing that such evaluations are \"an unrealistic surrogate for the original problem\" and ask researchers to evaluate end-to-end coreference resolution systems.",
        "However, the evaluation of end-to-end coref-erence resolution systems has been inconsistent making it impossible to compare the results.",
        "Nico-lae & Nicolae (2006) evaluate using the MUC score (Vilain et al., 1995) and the CEAF algorithm (Luo, 2005) without modifications.",
        "Yang et al. (2008) use only the MUC score.",
        "Bengtson & Roth (2008) and Stoyanov et al. (2009) derive variants from the B algorithm (Bagga & Baldwin, 1998).",
        "Rahman & Ng (2009) propose their own variants of B and CEAF.",
        "Unfortunately, some of the metrics' descriptions are so concise that they leave too much room for interpretation.",
        "Also, some of the metrics proposed are too lenient or are more sensitive to mention detection than to coreference resolution.",
        "Hence, though standard corpora are used, the results are not comparable.",
        "This paper attempts to fill that desideratum by analysing several variants of the B and CEAF algorithms.",
        "We propose two new variants, namely B^ys and CEAFsys, and provide algorithmic details in Section 2.",
        "We describe two experiments in Section 3 showing that Bsys and CEAFsys lead to intuitive and reliable results.",
        "Implementations of Bsys and CEAFsys are available open source along with extended examples."
      ]
    },
    {
      "heading": "2. Coreference Evaluation Metrics",
      "text": [
        "We discuss the problems which arise when applying the most prevalent coreference resolution evaluation metrics to end-to-end systems and propose our variants which overcome those problems.",
        "We provide detailed analyses of illustrative examples.",
        "The MUC score (Vilain et al., 1995) counts the minimum number of links between mentions to be inserted or deleted when mapping a system response to a gold standard key set.",
        "Although pairwise links capture the information in a set, they cannot represent singleton entities, i.e. entities, which are mentioned only once.",
        "Therefore, the MUC score is not suitable for the ACE data (http : //www .itl.nist.gov/iad/mig/tests/ace/), which includes singleton entities in the keys.",
        "Moreover, the MUC score does not give credit for separating singleton entities from other chains.",
        "This becomes problematic in a realistic system setup, when mentions are extracted automatically.",
        "The B algorithm (Bagga & Baldwin, 1998) overcomes the shortcomings of the MUC score.",
        "Instead of looking at the links, B computes precision and recall for all mentions in the document, which are then combined to produce the final precision and recall numbers for the entire output.",
        "For each mention, the B algorithm computes a precision and recall score using equations 1 and 2:",
        "Precision(mi) Recall(mi)",
        "where Rmi is the response chain (i.e. the system output) which includes the mention mi, and Kmiis the key chain (manually annotated gold standard) with mi.",
        "The overall precision and recall are computed by averaging them over all mentions.",
        "Since B's calculations are based on mentions, singletons are taken into account.",
        "However, a problematic issue arises when system mentions have to be dealt with: B assumes the mentions in the key and in the response to be identical.",
        "Hence, B has to be extended to deal with system mentions which are not in the key and key mentions not extracted by the system, so called twinless mentions (Stoyanov et al., 2009).",
        "A few variants of the B algorithm for dealing with system mentions have been introduced recently.",
        "Stoyanov et al.",
        "(2009) suggest two variants of the B algorithm to deal with system mentions, Bj] and Ban.",
        "For example, a key and a response are provided as below:",
        "Bj] discards all twinless system mentions (i.e. mention d) and penalizes recall by setting recallmi = 0 for all twinless key mentions (i.e. mention c).",
        "The Bj] precision, recall and F-score (i.e. F = calculated as:",
        "Precision-Recall Precision+Recall",
        ") for the example are",
        "FbL.",
        "Tables 1, 2 and 3 illustrate the problems with B0 and Ball.",
        "The rows labeled System give the original keys and system responses while the rows labeled B0, Bail and BSys show the performance generated by Stoyanov et al.",
        "'s variants and the one we introduce in this paper, BSys (the row labeled CEAFgys is discussed in Subsection 2.3).",
        "In Table 1, there are two system outputs (i.e. System 1 and System 2).",
        "Mentions d and e are the twinless system mentions erroneously resolved and c a twinless key mention.",
        "System 1 is supposed to be slightly better with respect to precision, because System 2 produces one more spurious resolution (i.e. for mention e ).",
        "However, B0 computes exactly the same numbers for both systems.",
        "Hence, there is no penalty for erroneous coreference relations in B0, if the mentions do not appear in the key, e.g. putting mentions d or e in Set 1 does not count as precision errors.",
        " â€“ B0 is too lenient by only evaluating the correctly ex-tacted mentions.",
        "retains twinless system mentions.",
        "It assigns 1/| Rmi | to a twinless system mention as its precision and similarly 1 /1 Kmi | to a twinless key mention as its recall.",
        "For the same example above, the Ball precision, recall and F-score are given by:",
        "Set 1",
        "System 1",
        "key",
        "response",
        "{abc} {abd}",
        "P",
        "R",
        "F",
        "B",
        "1.0",
        "0.444",
        "0.615",
        "Ball",
        "0.556",
        "0.556",
        "0.556",
        "Br&n;0.556",
        "0.556",
        "0.556",
        "0.667",
        "0.556",
        "0.606",
        "CEAFsys",
        "0.5",
        "0.667",
        "0.572",
        "System 2",
        "key",
        "response",
        "{abc} {ab de}",
        "P",
        "R",
        "F",
        "to",
        "1.0",
        "0.444",
        "0.615",
        "B'all",
        "0.375",
        "0.556",
        "0.448",
        "0.375",
        "0.556",
        "0.448",
        "Bsys",
        "0.5",
        "0.556",
        "0.527",
        "CEAFsys",
        "0.4",
        "0.667",
        "0.500",
        "B^u deals well with the problem illustrated in Table 1, the figures reported correspond to intuition.",
        "However, Ball can output different results for identical coreference resolutions when exposed to different mention taggers as shown in Tables 2 and 3.",
        "BaU manages to penalize erroneous resolutions for twinless system mentions, however, it ignores twinless key mentions when measuring precision.",
        "In Table 2, System 1 and System 2 generate the same outputs, except that the mention tagger in System 2 also extracts mention c. Intuitively, the same numbers are expected for both systems.",
        "However, Ball gives a higher precision to System 2, which results in a higher F-score.",
        "Ball retains all twinless system mentions, as can be seen in Table 3.",
        "System 2's mention tagger tags more mentions (i.e. the mentions i, j and k), while both System 1 and System 2 have identical coref-erence resolution performance.",
        "Still, Ball outputs quite different results for precision and thus for F-score.",
        "This is due to the credit Ball takes from unresolved singleton twinless system mentions (i.e. mention i, j, k in System 2).",
        "Since the metric is expected to evaluate the end-to-end coreference system performance rather than the mention tagging quality, it is not satisfying to observe that Ball s numbers actually fluctuate when the system is exposed to different mention taggers.",
        "Rahman & Ng (2009) apply another variant, denoted here as B3&n. They remove only those twin-less system mentions that are singletons before applying the B algorithm.",
        "So, a system would not be rewarded by the the spurious mentions which are correctly identified as singletons during resolution (as has been the case with Ball s higher precision for System 2 as can be seen in Table 3).",
        "We assume that Rahman & Ng apply a strategy similar to Ball after the removing step (this is not clear in Rahman & Ng (2009)).",
        "While it avoids the problem with singleton twinless system mentions, B3&n still suffers from the problem dealing with twinless key mentions, as illustrated in Table 2.",
        "We here propose a coreference resolution evaluation metric, Bsys, which deals with system mentions more adequately (see the rows labeled Bsysin Tables 1, 2, 3, 4 and 5).",
        "We put all twinless key mentions into the response as singletons which enables Bsys to penalize non-resolved coreferent key mentions without penalizing non-resolved singleton key mentions, and also avoids the problem Balland B&n have as shown in Table 2.",
        "All twinless system mentions which were deemed not coref-erent (hence being singletons) are discarded.",
        "To calculate Bsys precision, all twinless system mentions which were mistakenly resolved are put into the key since they are spurious resolutions (equivalent to the assignment operations in Ball), which should be penalized by precision.",
        "Unlike Bail, B'ys does not benefit from unresolved twinless system mentions (i.e. the twinless singleton system mentions).",
        "For recall, the algorithm only goes through the original key sets, similar to Ball and B&n. Details are given in Algorithm 1.",
        "For example, a coreference resolution system has the following key and response:",
        "To calculate the precision of Bsys, the key and response are altered to:",
        "Set 1",
        "Singletons",
        "System 1",
        "key",
        "response",
        "{abc} {abd}",
        "P",
        "R",
        "F",
        "0.556",
        "0.556",
        "0.556",
        "Br&n;0.556",
        "0.556",
        "0.556",
        "0.667",
        "0.556",
        "0.606",
        "CEAFsys",
        "0.5",
        "0.667",
        "0.572",
        "System 2",
        "key",
        "response",
        "{abc} {abd}",
        "{c}",
        "P",
        "R",
        "F",
        "B'all",
        "0.667",
        "0.556",
        "0.606",
        "0.667",
        "0.556",
        "0.606",
        "sys",
        "0.667",
        "0.556",
        "0.606",
        "CEAFsys",
        "0.5",
        "0.667",
        "0.572",
        "Set 1",
        "Singletons",
        "System 1",
        "key",
        "response",
        "{ab} {abd}",
        "P",
        "R",
        "F",
        "Ball",
        "0.556",
        "1.0",
        "0.715",
        "0.556",
        "1.0",
        "0.715",
        "Br",
        "sys",
        "0.556",
        "1.0",
        "0.715",
        "CEAFsys",
        "0.667",
        "1.0",
        "0.800",
        "System 2",
        "key",
        "response",
        "{ab} {abd}",
        "{i} {J} {k}",
        "P",
        "R",
        "F",
        "Ball",
        "0.778",
        "1.0",
        "0.875",
        "0.556",
        "1.0",
        "0.715",
        "B",
        "sys",
        "0.556",
        "1.0",
        "0.715",
        "CEAFsys",
        "0.667",
        "1.0",
        "0.800",
        "Input: key sets key, response sets response Output: precision P, recall R and F-score F 1: Discard all the singleton twinless system mentions in response; 2: Put all the twinless annotated mentions into response; 3: if calculating precision then 4: Merge all the remaining twinless system mentions",
        "with key to form keyp; 5: Use response to form responsep6: Through keyp and responsep; 7: Calculate Br precision P. 8: end if 9: if calculating recall then 10: Discard all the remaining twinless system mentions in",
        "response to from response ; 11 : Use key to form keyr12: Through key and response ; 13: Calculate B recall R 14: end if 15: Calculate F-score F",
        "So, the precision of Bsys is given by:",
        "The modified key and response for recall are:",
        "The resulting recall of Bsys is:",
        "Thus the F-score number is calculated as:",
        "Bsys indicates more adequately the performance of end-to-end coreference resolution systems.",
        "It is not easily tricked by different mention taggers.",
        "Luo (2005) criticizes the B algorithm for using entities more than one time, because B computes precision and recall of mentions by comparing entities containing that mention.",
        "Hence Luo proposes the CEAF algorithm which aligns entities in key and response.",
        "CEAF applies a similarity metric (which could be either mention based or entity based) for each pair of entities (i.e. a set of mentions) to measure the goodness of each possible alignment.",
        "The best mapping is used for calculating CEAF precision, recall and F-measure.",
        "Luo proposes two entity based similarity metrics (Equation 3 and 4) for an entity pair (Kt, Rj) originating from key, Kt, and response, Rj.",
        "(/>3(Kj,Rj) = |Kj n Rj | (3) Further example analyses can be found in Appendix A.",
        "The CEAF precision and recall are derived from the alignment which has the best total similarity (denoted as $($*)), shown in Equations 5 and 6.",
        "If not specified otherwise, we apply Luo's 03(*, *) in the example illustrations.",
        "We denote the original CEAF algorithm as CEAForig.",
        "Detailed calculations are illustrated below:",
        "So the CEAFo3ig evaluation numbers are:",
        "CEAFo3ig was intended to deal with key mentions.",
        "Its adaptation to system mentions has not been addressed explicitly.",
        "Although CEAForig theoretically does not require to have the same number of mentions in key and response, it still cannot be directly applied to end-to-end systems, because the entity alignments are based on mention mappings.",
        "As can be seen from Table 4, CEAForig fails to produce intuitive results for system mentions.",
        "System 2 outputs one more spurious entity (containing mention i and j) than System 1 does, however, achieves a same CEAFo3ig precision.",
        "Since twinless system mentions do not have mappings in key, they contribute nothing to the mapping similarity.",
        "So, resolution mistakes for system mentions are not calculated, and moreover, the precision is easily skewed by the number of output entities.",
        "CEAFo3ig reports very low precision for system mentions (see also Stoyanov et al.",
        "(2009)).",
        "2.3.2 Existing CEAF variants Rahman & Ng (2009) briefly introduce their CEAF variant, which is denoted as CEAF3&nhere.",
        "They use 03(*,*), which results in equal CEAF3&n precision and recall figures when using true mentions.",
        "Since Rahman & Ng s experiments using system mentions produce unequal precision and recall figures, we assume that, after removing",
        "2: Put all the twinless annotated mentions into response; 3: if calculating precision then 4: Merge all the remaining twinless system mentions 9: if calculating recall then 10: Discard all the remaining twinless system mentions in 15: Calculate F-score F",
        "Table 5 : Problems of CEAF3&n twinless singleton system mentions, they do not put any twinless mentions into the other set.",
        "In the example in Table 5, CEAF3&n does not penalize adequately the incorrectly resolved entities consisting of twinless sytem mentions.",
        "So CEAF3&ndoes not tell the difference between System 1 and System 2.",
        "It can be concluded from the examples that the same number of mentions in key and response is needed for computing the CEAF score.",
        "We propose to adjust CEAF in the same way as we did for Bsys, resulting in CEAFsys.",
        "We put all twinless key mentions into the response as singletons.",
        "All singleton twinless system mentions are discarded.",
        "For calculating CEAFsys precision, all twinless system mentions which were mistakenly resolved are put into the key.",
        "For computing CEAFsys recall, only the original key sets are considered.",
        "That way CEAFsys deals adequately with system mentions (see Algorithm 2 for details).",
        "Algorithm 2 CEAFsys",
        "Input: key sets key, response sets response Output: precision P, recall R and F-score F 1: Discard all the singleton twinless system mentions in response;",
        "with key to form keyp; 5: Use response to form responsep 6: Form Map g* between keyp and responsep7: Calculate CEAF precision P using 0r(*, *)",
        "response to form responser; 11 : Use key to form keyr12: Form Map g* between keyr and responser13: Calculate CEAF recall R using (f>r(-k, *)",
        "Taking System 2 in Table 4 as an example, key and response are altered for precision:",
        "So the 03(*,*) are as below, only listing the best mappings:",
        "The precision is thus give by:",
        "The key and response for recall are:",
        "The recall and F-score are thus calculated as:",
        "However, one additional complication arises with regard to the similarity metrics used by CEAF.",
        "It turns out that only 03(*,*) is suitable for dealing with system mentions while 04(*,*) produces uninituitive results (see Table 6).",
        "04(*,*) computes a normalized similarity for each entity pair using the summed number ofmentions in the key and the response.",
        "CEAF precision then distributes that similarity evenly over the response set.",
        "Spurious system entities, such as the one with mention i and j in Table 6, are not penalized.",
        "03 (*, *) calculates unnormalized similarities.",
        "It compares the two systems in Table 6 adequately.",
        "Hence we use only 03(*, *) in CEAFsys.",
        "Set 1",
        "Set2",
        "Singletons",
        "Set 1",
        "Set 2",
        "Set 3",
        "Singletons",
        "System 1",
        "key",
        "response",
        "{abc} {ab}",
        "{c} {i} {j}",
        "System 1",
        "key",
        "response",
        "{abc} {ab}",
        "{ij}",
        "{kl}",
        "{c}",
        "P",
        "R",
        "F",
        "P",
        "R",
        "F",
        "CEAForig",
        "0.4",
        "0.667",
        "0.500",
        "CEAFr&n;0.286",
        "0.667",
        "0.400",
        "Br",
        "sys",
        "1.0",
        "0.556",
        "0.715",
        "Br",
        "sys",
        "0.714",
        "0.556",
        "0.625",
        "CEAFsys",
        "0.667",
        "0.667",
        "0.667",
        "CEAFsys",
        "0.571",
        "0.667",
        "0.615",
        "System 2",
        "key",
        "response",
        "{abc} {ab}",
        "{ij}",
        "{c}",
        "System 2",
        "key",
        "response",
        "{abc} {ab}",
        "{ij kl}",
        "{c}",
        "P",
        "R",
        "F",
        "P",
        "R",
        "F",
        "CEAF",
        "orig",
        "0.4",
        "0.667",
        "0.500",
        "CEAFr&n;0.286",
        "0.667",
        "0.400",
        "Br",
        "sys",
        "0.8",
        "0.556",
        "0.656",
        "Br",
        "Bsys",
        "0.571",
        "0.556",
        "0.563",
        "CEAFsys",
        "0.6",
        "0.667",
        "0.632",
        "CEAFsys",
        "0.429",
        "0.667",
        "0.522",
        "are shown in Table 7.",
        "When normalizing the similarities by the number of entities or mentions in the key (for recall) and the response (for precision), the CEAF algorithm considers all entities or mentions to be equally important.",
        "Hence CEAF tends to compute quite low precision for system mentions which does not represent the system performance adequately.",
        "Here, we do not address this issue.",
        "Recently, a new coreference resolution evaluation algorithm, BLANC, has been introduced (Re-casens & Hovy, 2010).",
        "This measure implements the Rand index (Rand, 1971) which has been originally developed to evaluate clustering methods.",
        "The BLANC algorithm deals correctly with singleton entities and rewards correct entities according to the number of mentions.",
        "However, a basic assumption behind BLANC is, that the sum of all coreferential and non-coreferential links is constant for a given set ofmentions.",
        "This implies that BLANC assumes identical mentions in key and response.",
        "It is not clear how to adapt BLANC to system mentions.",
        "We do not address this issue here."
      ]
    },
    {
      "heading": "3. Experiments",
      "text": [
        "While Section 2 used toy examples to motivate our metrics Â£>ys and CEAFsys, we here report results on two larger experiments using ACE2004 data.",
        "We use the ACE2004 (Mitchell et al., 2004) English training data which we split into three sets following Bengtson & Roth (2008): Train (268 docs), Dev (76), and Test (107).",
        "We use two in-house mention taggers.",
        "The first (SM1) implements a heuristic aiming at high recall.",
        "The second (SM2) uses the J48 decision tree classifier (Wit-ten & Frank, 2005).",
        "The number of detected mentions, head coverage, and accuracy on testing data",
        "For the artificial setting we report results on the development data using the SM1 tagger.",
        "To illustrate the stability of the evaluation metrics with respect to different mention taggers, we reduce the number of twinless system mentions in intervals of 10%, while correct (non-twinless) ones are kept untouched.",
        "The coreference resolution system used is the BART (Versley et al., 2008) reimplementation of Soon et al.",
        "(2001).",
        "The results are plotted in Figures 1 and 2.",
        "Set 1",
        "Singletons",
        "SM1",
        "SM2",
        "System 1",
        "key",
        "response",
        "{abc} {ab}",
        "{c} {i} {j}",
        "training",
        "mentions twin mentions",
        "31,370 13,072",
        "16,081 14,179",
        "P",
        "R",
        "F",
        "development",
        "mentions",
        "8,045",
        "-",
        "<t>i(*,*)",
        "0.4",
        "0.8",
        "0.533",
        "twin mentions",
        "3,371",
        "-",
        "<i>r(*,*)",
        "0.667",
        "0.667",
        "0.667",
        "test",
        "mentions",
        "8,387",
        "4,956",
        "System 2",
        "key",
        "response",
        "{abc} {ab} {ij}",
        "{c}",
        "twin mentions head coverage",
        "4,242 79.3% 57.3%",
        "4,212 73.3%",
        "81.2%",
        "P",
        "R",
        "F",
        "accuracy",
        "<M*>*)",
        "0.489",
        "0.8",
        "0.607",
        "T\"_1_1_ 7 AT_",
        "â– \\r\\ a t~\\ _ i _",
        "<>r(*,*)",
        "0.6",
        "0.667",
        "0.632",
        "Table 7: Mention Taggers on ACE2004 Data",
        "Table 6: Problems of 04(*,*)",
        "1.1 _ n",
        "Omitting twinless system mentions from the training data while keeping the number of correct mentions constant should improve the corefer-ence resolution performance, because a more precise coreference resolution model is obtained.",
        "As can be seen from Figures 1 and 2, the MUC-score, BQys and CEAFsys follow this intuition.",
        "B0 is almost constant.",
        "It does not take twinless mentions into account.",
        "BjH's curve, also, has a lower slope in comparison to BQys and MUC (i.e. Ban computes similar numbers for worse models).",
        "This shows that the BjH score can be tricked by using a high recall mention tagger, e.g. in cases with the worse models (i.e. ones on the left side of the figures) which have much more twinless system mentions.",
        "The original CEAF algorithm, CEAForig, is too sensitive to the input system mentions making it less reliable.",
        "CEAFsys is parallel to BQys.",
        "Thus both of our metrics exhibit the same intuition.",
        "For the realistic setting we compare SM1 and SM2 as preprocessing components for the BART (Ver-sley et al., 2008) reimplementation of Soon et al.",
        "(2001).",
        "The coreference resolution system with the SM2 tagger performs better, because a better coreference model is achieved from system mentions with higher accuracy.",
        "The MUC, BQys and CEAFsys metrics have the same tendency when applied to systems with different mention taggers (Table 8, 9 and 10 and the bold numbers are higher with a p-value of 0.05, by a paired-t test).",
        "Since the MUC scorer does not evaluate singleton entities, it produces too low numbers which are not informative any more.",
        "As shown in Table 9, BjH reports counterintuitive results when a system is fed with system mentions generated by different mention taggers.",
        "BjH cannot be used to evaluate two different end-to-end coreference resolution systems, because the mention tagger is likely to have bigger impact than the coreference resolution system.",
        "Bq fails to generate the right comparison too, because it is too lenient by ignoring all twinless mentions.",
        "The CEAForig numbers in Table 10 illustrate the big influence the system mentions have on precision (e.g. the very low precision number for Soon (SM1)).",
        "The big improvement for Soon (SM2) is largely due to the system mentions it uses, rather than to different coreference models.",
        "Both BQ&n and CEAFr&n show no serious problems in the experimental results.",
        "However, as discussed before, they fail to penalize the spurious entities with twinless system mentions adequately.",
        "We compare results of Bengtson & Roth's (2008) system with our Soon (SM2) system.",
        "Bengtson & Roth s embedded mention tagger aims at high precision, generating half of the mentions SM1 generates (explicit statistics are not available to us).",
        "Bengtson & Roth report a B F-score for system mentions, which is very close to the one for true mentions.",
        "Their B-variant does not impute errors of twinless mentions and is assumed to be quite similar to the Bq strategy.",
        "We integrate both the B0 and BQys variants into their system and show results in Table 11 (we cannot report significance, because we do not have access to results for single documents in Bengtson & Roth s system).",
        "It can be seen that, when different variants of evaluation metrics are applied, the performance of the systems vary wildly."
      ]
    },
    {
      "heading": "4. Conclusions",
      "text": [
        "In this paper, we address problems of commonly used evaluation metrics for coreference resolution and suggest two variants for B and CEAF, called Bsys and CEAFsys.",
        "In contrast to the variants proposed by Stoyanov et al.",
        "(2009), Bsys and CEAFsys are able to deal with end-to-end systems which do not use any gold information.",
        "The numbers produced by BQys and CEAFsys are able to indicate the resolution performance of a system more adequately, without being tricked easily by twisting preprocessing components.",
        "We believe that the explicit description of evaluation metrics, as given in this paper, is a precondition for the reliabe comparison of end-to-end coreference resolution systems.",
        "MUC",
        "R",
        "Pr",
        "F",
        "Soon (SMI)",
        "51.7",
        "53.1",
        "52.4",
        "Soon (SM2)",
        "49.1",
        "69.9",
        "57.7",
        "n3",
        "Bsys",
        "B0",
        "R",
        "Pr",
        "F",
        "R",
        "Pr",
        "F",
        "Soon (SM2)",
        "64.1",
        "87.3",
        "73.9",
        "54.7",
        "91.3",
        "68.4",
        "Bengtson",
        "66.1",
        "81.9",
        "73.1",
        "69.5",
        "74.7",
        "72.0",
        "Acknowledgements.",
        "This work has been funded by the Klaus Tschira Foundation, Heidelberg, Germany.",
        "The first author has been supported by a HITS PhD.",
        "scholarship.",
        "We would like to thank Ã‰va Mujdricza-Maydt for implementing the mention taggers.",
        "R",
        "R",
        "sys",
        "Pr",
        "F",
        "R",
        "B0",
        "Pr",
        "F",
        "R",
        "RBall",
        "Pr",
        "F",
        "R",
        "R",
        "Pr",
        "F",
        "Soon (SM1) Soon (SM2)",
        "65.7 64.1",
        "76.8 87.3",
        "70.8",
        "73.9",
        "57.0 54.7",
        "91.1 91.3",
        "70.1",
        "68.4",
        "65.1 64.3",
        "85.8 87.1",
        "74.0 73.9",
        "65.1 64.3",
        "78.7 84.9",
        "71.2",
        "73.2",
        "CEAFs y s",
        "CEAF",
        "CEAFr&n;R",
        "Pr",
        "F",
        "R",
        "Pr",
        "F",
        "R",
        "Pr",
        "F",
        "Soon (SM1)",
        "66.4",
        "61.2",
        "63.7",
        "62.0",
        "39.9",
        "48.5",
        "62.1",
        "59.8",
        "60.9",
        "Soon (SM2)",
        "67.4",
        "65.2",
        "66.3",
        "60.0",
        "56.6",
        "58.2",
        "60.0",
        "66.2",
        "62.9",
        "Set 1",
        "Set 2",
        "B",
        "key",
        "{abcde}",
        "P",
        "R",
        "F",
        "responsei",
        "{ab}",
        "{ij}",
        "0.857",
        "0.280",
        "0.422",
        "response2",
        "{abc}",
        "{ij}",
        "0.857",
        "0.440",
        "0.581",
        "response3",
        "{ab cd}",
        "{ij}",
        "0.857",
        "0.68",
        "0.784",
        "response4",
        "{abcde}",
        "{ij}",
        "0.857",
        "1.0",
        "0.923",
        "Set 1",
        "Set2",
        "B3",
        "key",
        "{abcde}",
        "P",
        "R",
        "F",
        "responsei",
        "{abc}",
        "{ij}",
        "0.857",
        "0.440",
        "0.581",
        "response2",
        "{abc}",
        "{ij k}",
        "0.75",
        "0.440",
        "0.555",
        "response3",
        "{abc}",
        "{ij kl}",
        "0.667",
        "0.440",
        "0.530",
        "response4",
        "{abc}",
        "{ijklm}",
        "0.6",
        "0.440",
        "0.508",
        "Set 1",
        "key",
        "{abcde}",
        "P",
        "R",
        "F",
        "responsei",
        "{abij}",
        "0.643",
        "0.280",
        "0.390",
        "response2",
        "{abcij}",
        "0.6",
        "0.440",
        "0.508",
        "response3",
        "{abcdij}",
        "0.571",
        "0.68",
        "0.621",
        "response4",
        "{a b c d e i j}",
        "0.551",
        "1.0",
        "0.711",
        "Set 1",
        "B3",
        "key",
        "{abcde}",
        "P",
        "R",
        "F",
        "response].",
        "{abcij}",
        "0.6",
        "0.440",
        "0.508",
        "response2",
        "{abcij k}",
        "0.5",
        "0.440",
        "0.468",
        "response3",
        "{a b c ij k l}",
        "0.429",
        "0.440",
        "0.434",
        "response4",
        "{a b c i j k l m}",
        "0.375",
        "0.440",
        "0.405"
      ]
    }
  ]
}
