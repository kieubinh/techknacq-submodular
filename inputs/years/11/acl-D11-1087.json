{
  "info": {
    "authors": [
      "Moshe Dubiner",
      "Yoram Singer"
    ],
    "book": "EMNLP",
    "id": "acl-D11-1087",
    "title": "Entire Relaxation Path for Maximum Entropy Problems",
    "url": "https://aclweb.org/anthology/D11-1087",
    "year": 2011
  },
  "references": [
    "acl-J96-1002"
  ],
  "sections": [
    {
      "text": [
        "Moshe Dubiner Yoram Singer",
        "We discuss and analyze the problem of finding a distribution that minimizes the relative entropy to a prior distribution while satisfying max-norm constraints with respect to an observed distribution.",
        "This setting generalizes the classical maximum entropy problems as it relaxes the standard constraints on the observed values.",
        "We tackle the problem by introducing a re-parametrization in which the unknown distribution is distilled to a single scalar.",
        "We then describe a homotopy between the relaxation parameter and the distribution characterizing parameter.",
        "The homotopy also reveals an aesthetic symmetry between the prior distribution and the observed distribution.",
        "We then use the reformulated problem to describe a space and time efficient algorithm for tracking the entire relaxation path.",
        "Our derivations are based on a compact geometric view of the relaxation path as a piecewise linear function in a two dimensional space of the relaxation-characterization parameters.",
        "We demonstrate the usability of our approach by applying the problem to Zipfian distributions over a large alphabet."
      ]
    },
    {
      "heading": "1. Introduction",
      "text": [
        "Maximum entropy (max-ent) models and its dual counterpart, logistic regression, is a popular and effective tool in numerous natural language processing tasks.",
        "The principle of maximum entropy was spelled out explicitly by E.T.",
        "Jaynes (1968).",
        "Applications of maximum entropy approach to natural language processing are numerous.",
        "A notable example and probably one of the earliest usages and generalizations of the maximum entropy principle to language processing is the work of Berger, Della Pietrax2, and Lafferty (Berger et al., 1996, Della Pietra et al., 1997).",
        "The original formulation of max-ent cast the problem as the task of finding the distribution attaining the highest entropy subject to equality constraints.",
        "While this formalism is aesthetic and paves the way to a simple dual in the form of a unique Gibbs distribution (Della Pietra et al., 1997), it does not provide sufficient tools to deal with input noise and sparse representation of the target Gibbs distribution.",
        "To mitigate these issues, numerous relaxation schemes of the equality constraints have been proposed.",
        "A notable recent work by Dudik, Phillips, and Schapire (2007) provided a general constraint-relaxation framework.",
        "See also the references therein for an in depth overview of other approaches and generalizations of max-ent.",
        "The constraint relaxation surfaces a natural parameter, namely, a relaxation value.",
        "The dual form of this free parameter is the regularization value of penalized logistic regression problems.",
        "Typically this parameter is set by experimentation using cross validation technique.",
        "The relaxed maximum-entropy problem setting is the starting point of this paper.",
        "In this paper we describe and analyze a framework for efficiently tracking the entire relaxation path of constrained max-ent problems.",
        "We start in Sec. 2 with a generalization in which we discuss the problem of finding a distribution that minimizes the relative entropy to a given prior distribution while satisfying max-norm constraints with respect to an observed distribution.",
        "In Sec. 3 we tackle the problem by introducing a re-parametrization in which the unknown distribution is distilled to a single scalar.",
        "We next describe in Sec. 4 a homotopy between the relaxation parameter and the distribution characterizing parameter.",
        "This formulation also reveals an aesthetic symmetry between the prior distribution and the observed distribution.",
        "We use the reformulated problem to describe in Secs.",
        "5-6 space and time efficient algorithms for tracking the entire relaxation path.",
        "Our derivations are based on a compact geometric view of the relaxation path as a piecewise linear function in a two dimensional space of the relaxation-characterization parameters.",
        "In contrast to common homotopy methods for the Lasso Osborne et al.",
        "(2000), our procedure for tracking the max-ent homotopy results in an uncharacteristically low complexity bounds thus renders the approach applicable for large alphabets.",
        "We provide preliminary experimental results with Zipf distributions in Sec. 8 that demonstrate the merits of our approach.",
        "Finally, we conclude in Sec. 9 with a brief discussion of future directions."
      ]
    },
    {
      "heading": "2. Notations and Problem Setting",
      "text": [
        "We denote vectors with bold face letters, e.g. v. Sums are denoted by calligraphic letters, e.g. M = J2j mj.",
        "We use the shorthand [n] to denote the set of integers {1,..., n}.",
        "The n'th dimensional simplex, denoted A, consists of all vectors p such that, Yljj=i Pj = 1 and for all j G [n], pj > 0.",
        "We generalize this notion to multiplicity weighted vectors.",
        "Formally, we say that a vector p with multiplicity m is in the simplex, (p, m) G A, if ^ jj=1 mj pj = 1, and for all j G [n], pj > 0, and mj > 0.",
        "The generalized relaxed maximum-entropy problem is concerned with obtaining an estimate p, given a prior distribution u and an observed distribution q such that the relative entropy between p and u is as small as possible while p and q are within a given max-norm tolerance.",
        "Formally, we cast the following constrained optimization problem,",
        "mm Y^mfPj kg [^-J v is a relaxation parameter.",
        "We use 1/v rather than v itself for reasons that become clear in the sequel.",
        "We next describe the dual form of (1).",
        "We derive the dual by introducing Lagrange-Legendre multipliers for each of the constraints appearing in (1).",
        "Let a+ > 0 denote the multiplier for the constraint Qj – Pj < 1/v and a > 0 the multiplier for the constraint Qj – pj > – 1/v.",
        "In addition, we use 7 as the multiplier for the constraint j mj pj = 1. fter some routine algebraic manipulations we get that the Lagrangian is,",
        "To find the dual form we take the partial derivative of the Lagrangian with respect to each pj, equate to zero, and get that log j +1 – aj + 7 = 0, which implies that pj ~ Uj eaj.",
        "We now employ the fact that (p, m) G A to get that the exact form for pj is",
        "Ej=1 miUieaiUsing (3) in the compact form of the Lagrangian we obtain the following dual problem",
        "where Z = ^ n=1 mj Uj eaj.",
        "We make rather little use of the dual form of the problem.",
        "However, the complementary slackness conditions that are necessary for optimality to hold play an important role in the next section in which we present a reformulation of the relaxed maximum entropy problem."
      ]
    },
    {
      "heading": "3. Problem Reformulation",
      "text": [
        "First note that the primal problem is a strictly convex function over a compact convex domain.",
        "Thus, its optimum exists and is unique.",
        "Let us now characterize the form of the solution.",
        "We partition the set of indices in [n] into three disjoint sets depending on whether the constraint |pj – Qj | < 1/v is active and its form.",
        "Concretely, we define",
        "i+ = { < j < n | pj = Qj + 1/v} .",
        "Recall that Z = Ej=1 mj Uj eaj.",
        "Thus, from (3) we can rewrite pj = Ujeaj /Z.",
        "We next use the complementary slackness conditions (see for instance (Boyd and Vandenberghe, 2004)) to further characterize the solution.",
        "For any j G I_ we must have a =0 and a+ > 0 therefore aj > 0, which immediately implies that pj > Uj/Z.",
        "By definition we have that pj = Qj – 1/v for j G I-.",
        "Combining these two facts we get that Uj/Z < Qj – 1/v for j G I-.",
        "Analogous derivation yields that Uj/Z > Qj + 1/v for j G I+.",
        "Last, if the set I0 is not empty then for each j in I0 we must have a+ = 0 and a j = 0 thus a j = 0.",
        "Resorting again to the definition of p from (3) we get that pj = Uj/Z for j G I0.",
        "Since |pj – Qj | < 1/v for j G I0 we get that | Uj/Z – Qj| < 1/v.",
        "To recap, there exists Z > 0 such that the optimal solution takes the following form,",
        "We next introduce an key re-parametrization, defining ß = v/Z.",
        "We also denote by F(•) the capping function F (x) = max { – 1, min A simple illustration of the capping function is given in Fig. 1.",
        "Equipped with these definition we can rewrite (6) as follows, structure of the general solution.",
        "Note that ß, u are interchangeable with v, q.",
        "We can thus swap the roles of the prior distribution with the observed distribution and obtain an analogous characterization.",
        "In the next section we further explore the dependence of ß on v. The structure we reveal shortly serves as our infrastructure for deriving efficient algorithms for following the regularization path."
      ]
    },
    {
      "heading": "4. The function ß(u)",
      "text": [
        "In order to explore the dependency of ß on v let us introduce the following sums",
        "M = E mj – E mj",
        "Fixing v and using (9), we can rewrite (8) as follows",
        "Given u, q, and v, the value of ß can be found by using j mjpj = j mjQj = 1, which implies",
        "We defer the derivation of the actual algorithm for computing ß (and in turn p) to the next section.",
        "In the meanwhile let us continue to explore the rich",
        "Clearly, so long as the partition of [n] into the sets I+, I-, I0 is intact, there is a simple linear relation between ß and v. The number of possible subsets I ,I0 ,I+ is finite.",
        "Thus, the range 0 < v < oo decomposes into a finite number of intervals each of which corresponds to a fixed partition of [n] into I+, I-; I0.",
        "In each interval ß is a linear function of v, unless I0 is empty.",
        "Let vœ be the smallest v value for which I0 is empty.",
        "Let ßTO be its corresponding ß value.",
        "If I0 is never empty for any finite value of v we define vœ = ßTO = oo.",
        "Clearly, replacing (v, ß) with (kv, Kß) for any k > 1 and v > vœ yields the same feasible solution as I+ (kv) = I+(v), I (av) = I (v).",
        "Hence, as far as the original problem is concerned there is no reason to go past vœduring the process ofcharacterizing the solution.",
        "We recap our derivation so far in the following lemma.",
        "Lemma 4.1 For 0 < v < vœ, the value of ß as defined by (7) is a unique.",
        "Further, the function ß(v ) is a piecewise linear continuous function in v. When v > letting ß = ßTO v/vœ keeps (7) valid.",
        "We established the fact that ß(v) is a piecewise linear function.",
        "The lingering question is how many linear subintervals the function can attain.",
        "To study this property, we take a geometric view of the plane defined by (v, ß).",
        "Our combinatorial characterization of the number of subintervals makes use of the following definitions of lines in R, where – o < v < o and j G [n].",
        "The next theorem gives an upper bound on the number of linear segments the function ß() may attain.",
        "While the bound is quadratic in the dimension, for both artificial data and real data the bound is way too pessimistic.",
        "Theorem 4.2 The piecewise linear function ß(v) consists ofat most n linear segments for v G R+.",
        "Proof Since we showed that that ß(v) is a piecewise linear function, it remains to show that it has at most n linear segments.",
        "Consider the two dimensional function G(v, ß) from (8).",
        "The (v, ß) plane is divided by the 2n straight lines li,l2,... ,ln,l-1,l-2,... ,l-n intoatmost2n + 1 polygons.",
        "The latter property is proved by induction.",
        "It clearly holds for n = 0.",
        "Assume that it holds for n – 1 .",
        "Line lj intersects the previous 2n – 2 lines at no more than 2n – 2 points, thus splitting at most 2n – 1 polygons into two separate polygonal parts.",
        "Line l-j is parallel to lj , again adding at most 2n – 1 polygons.",
        "Recapping, we obtain at",
        "This result stands in contrast to the Lasso homotopy tracking procedure (Osborne et al., 2000), where the worst case number of segments seems to be exponential in n. Moreover, when the prior u is uniform, Uj = 1/Ejj=1 mj for all j G [n], the number of segments is at most n + 1.",
        "We defer the analysis of the uniform case to a later section as the proof stems from the algorithm we describe in the sequel."
      ]
    },
    {
      "heading": "5. Algorithm for a Single Relaxation Value",
      "text": [
        "Suppose we are given u, q, m and a specific relaxation value z>.",
        "How can we find p?",
        "The obvious approach is to solve the one dimensional monotonically nondecreasing equation G(ß) = G(z>, ß) = 0 by bisection.",
        "In this section we present a more efficient and direct procedure that is guaranteed to find the optimal solution p in a finite number of steps.",
        "Clearly G(ß) is a piecewise linear function with at most 2n easily computable change points of the slope.",
        "See also Fig.",
        "(5) for an illustration of In order to find the slope change points we need to calculate the point (v, ßj ) for all the lines l±j where 1 < j < n. Concretely, these values are",
        "We next sort the above values of ßj and denote the resulting sorted list as ßni < ßn2 < • • • < ßn2n.",
        "For any 0 < j < 2n let M j, Uj, Qj be the sums, defined starting from 0.",
        "Once the",
        "From the above sums we can compute the value of the function G(v, ß) at the end point of the line segment (ßnj-1 ,ßnj), which is the same as the start point of the line segment (ßnj, ßnj+1 ),",
        "The optimal value ofß resides in the line segment for which G( ) attains 0.",
        "Such a segment must exist since G0 = M0 = – Ej=1 mi < 0 and G2n =",
        "M0 > 0.",
        "Therefore, there exists an index 1 < j < 2n, where Gj < 0 < Gj+1.",
        "Once we bracketed the feasible segment for ß, the optimal value of ß is found by solving the linear equation (10),",
        "More formally, the local homotopy tracking follows the piecewise linear function ß(v), segment by segment.",
        "Each segment corresponds to a subset of the line l0 for a given triplet (M, U, Q).",
        "It is simple to show that ß(0) = 0, hence we start with",
        "We now track the value of ß as v increases, and the relaxation parameter 1/v decreases.",
        "The characterization of l0 remains intact until l0 hits one of the lines lj for 1 < |j| < n. To find the line intersecting l0 we need to compute the potential intersection points (vj, ßj) = l0 n lj which amounts to calculating v-n, v-n+1,..., v-1, v1, v2, • • • , vn where",
        "The lines for which the denominator is zero correspond to infeasible intersection and can be discarded.",
        "The smallest value vj which is larger than the current traced value of v corresponds to the next line intersecting l0.",
        "While the above description is mathematically sound, we devised an equivalent intersection inspection scheme which is more numerically stable and efficient.",
        "We keep track of partition I-, I0, I1through the vector,",
        "From the optimal value of ß it is straightforward to construct p using (7).",
        "Due to the sorting step, the algorithm's run time is O(n log(n)) and it takes linear space.",
        "The number of operations can be reduced to O(n) using a randomized search procedure."
      ]
    },
    {
      "heading": "6. Homotopy Tracking",
      "text": [
        "We now shift gears and focus on the main thrust of this paper, namely, an efficient characterization of the entire regularization path for the maximum entropy problem.",
        "Since we have shown that the optimal solution p can be straightforwardly obtained from the variable ß, it suffices to efficiently track the function ß(v) as we traverse the plane (v, ß) from v = 0 through the last change point which we denoted as (v^,ßTC).",
        "In this section we give an algorithm that traverses ß(v) by locating the intersections of l0 with the fixed lines n+1,..., l-1, I1,..., ln and updating I0 after each intersection.",
        "Initially s1 = s2 = • • • = sn = 0.",
        "What kind of intersection does £q have with I p. Recall that ^ is the slope of £0 while is the slope of £j.",
        "Thus ^ > |^ means that the |j|'th constraint is moving \"up\" from /_ to Iq or from I0 to I+.",
        "When § < ^ the | j |'th constraint is moving \"down\" from I+ to I0or from I0 to I .",
        "See also Fig. 4 for an illustration of the possible transitions between the sets.",
        "For instance, the slope of ß(v) on the bottom left part of the figure is larger than the slope the line it intersects.",
        "Since this line defines the boundary between I-and I0, we transition from Ito I0.",
        "We need only consider 1 < | j| < n of the following types.",
        "Moving \"up\" from Ito I0 requires the sums Mj Uj Qj incrementally,",
        "M0 = – Ej=1 mi, U0 = Q0 = values of j – 1'th sums are known, we can compute the next sums in the sequence as follows,",
        "Figure 4: Illustration of the possible intersections between ß(v) and lj and the corresponding transition between the sets I±, Iq .",
        "Similarly, moving \"down\" from I+ to I0 requires",
        "Finally, moving \"up\" or \"down\" from I0 entails",
        "If there are no eligible vj's, we have finished traversing ß().",
        "Otherwise let index j belong to the the smallest eligible vj.",
        "Infinite accuracy guarantees that vj > v. In practice we perform the update",
        "Figure 5: The result of the homotopy tracking for a 4 dimensional problem.",
        "The lines lj for j < 0 are drawn in blue and for j > 0 in red.",
        "The function ß(v) is drawn in green and its change points in black.",
        "Note that although the dimension is 4 the number of change points is rather small and does not exceed 4 either in this simple example.",
        "edge u is the uniform distribution,",
        "def U = Uj",
        "We are done with the tracking process when I0 is empty, i.e. for all j sj = 0.",
        "The local homotopy algorithm takes O (n) memory and O (nk) operations where k is the number of change points in the function ß( v) .",
        "This algorithm is simple to implement, and when k is relatively small it is efficient.",
        "An illustration of the tracking result, ß(v), along with the lines l±j, that provide a geometrical description of the problem, is given in Fig. 5."
      ]
    },
    {
      "heading": "7. Uniform Prior",
      "text": [
        "We chose to denote the prior distribution as u to underscore the fact that in the case of no prior knowl-",
        "In this case the objective function amounts to the negative entropy and by flipping the sign of the objective we obtain the classical maximum entropy problem.",
        "The fact that the prior probability is the same for all possible observations infuses the problem with further structure which we show how to exploit in this section.",
        "Needless to say though that all the results we obtained thus far are still valid.",
        "Let us consider a point (v, ß) on the boundary between I0 and I+, namely, there exist a line l+i such ßUi – vQi = ßU – vQi = 1 .",
        "By definition, for any j G I0 we have ßUj – vQj = ßU – vQj < 1 = ßU – vQi .",
        "Thus, Qi < Qj for all j G I0 which implies that j eio j eio and we must be moving \"up\" from I0 to I+ when the line l0 hits li.",
        "Similarly we must be moving \"down\" from when l0 hits on the boundary between I0 and I .",
        "We summarize these properties in the following theorem.",
        "Theorem 7.1 When the prior distribution u is uniform, I (v) and I+(v) are monotonically nonde-creasing and I0(v) is monotonically nonincreasing in v > 0 .",
        "Further, the piecewise linear function ß(v) consists ofat most n + 1 line segments.",
        "The homotopy tracking procedure when the prior is uniform is particularly simple and efficient.",
        "Intuitively, there is a sole condition which controls the order in which indices would enter I± from I0, which is simply how \"far\" each Qi is from U, the single prior value.",
        "Therefore, the algorithm starts by sorting q.",
        "Let Qn1 > Qn2 > • • • > Qnn denote the sorted vector.",
        "Instead of maintaining the vector of set indicators s, we merely maintain two indices j-and j+ which designate the size of I-and I+ that were constructed thus far.",
        "Due to the monotonicity property of the sets I± as v grows, the two sets can be written as, I = {nj 11 < j < j-} and I+ = {nj | j+ < j < n}.",
        "The homotopy tracking procedure starts as before with v = 0, M = 0, U = Q = 1.",
        "We also set j = 1 and j+ = n which by definition imply that I± are empty and I0 = [n].",
        "In each tracking iteration we need to compare only two values which we compactly denote as,",
        "When v < v+ we just encountered a transition from I0 to I-and as we encroach I-we perform the updates, v – v-, M – M – , U – ",
        "Q – Q – mnj+ Qnj+, j+ – j+ – 1.",
        "The tracking process stops when j > j+ as we exhausted the transitions out of the set I0 which becomes empty.",
        "Homotopy tracking for a uniform prior takes O(n) memory and O(n log(n)) operations and is very simple to implement.",
        "We also devised a global homotopy tracking algorithms that requires a priority queue which facilitates insertions, deletions, and finding the largest element",
        "Figure 6: The number of line-segments in the homotopy as a function of the number of samples used to build the observed distribution q.",
        "in the queue in O(log(n)) time.",
        "The algorithm requires O(n) memory and O(n log(n)) operations.",
        "Clearly, if the number of line segments constituting ß(v) is greater than n log(n) (recall that the upper bound is O(n)) then the global homotopy procedure is faster than the local one.",
        "However, as we show in Sec. 8, in practice the number of line segments is merely linear and it thus suffices to use the local homotopy tracking algorithm."
      ]
    },
    {
      "heading": "8. Number of line segments in practice",
      "text": [
        "The focus of the paper is the design and analysis of a novel homotopy method for maximum entropy problems.",
        "We thus left with relatively little space to discuss the empirical aspects of our approach.",
        "In this section we focus on one particular experimental facet that underscores the usability ofour apparatus.",
        "We briefly discuss current natural language applications that we currently work on in the next section.",
        "The practicality of our approach hinges on the number of line segments that occur in practice.",
        "Our bounds indicate that this number can scale quadratically with the dimension, which would render the homotopy algorithm impractical when the size ofthe alphabet is larger than a few thousands.",
        "We therefore extensively tested the actual number ofline segments in the resulting homotopy when u and q are Zipf (1949) distributions.",
        "We used an alphabet of size 50, 000 in our experiments.",
        "The distribution u was set to be the Zipf distribution with an offset parameter of 2, that is, Ui ~ + 2).",
        "We defined a \"mother\" distribution for q, denoted q, which is a plain Zipf distribution without an offset, namely Qi ~ We then sampled n/2 letters according to the distribution q where l G – 3,..., 3.",
        "Thus the smallest sample was n/2 = 6,250 and the largest sample was n/3-3 = 40,000.",
        "Based on the sample we defined the observed distribution q such that Qiis proportional to the number of times the i'th letter appeared in the sample.",
        "We repeated the process 100 times for each sample size and report average results.",
        "Note that when the sample is substantially smaller than the dimension the observed distribution q tends to be \"simple\" as it consists of many zero components.",
        "In Fig. 6 we depict the average number line segments for each sample size.",
        "When the sample size is one eighth of the dimension we average st most 0.1 n line segments.",
        "More importantly, even when the size of the sample is fairly large, the number of lines segments is linear in the dimension with a constant close to one.",
        "We also performed experiments with large sample sizes for which the empirical distribution q is very close to the mother distribution q.",
        "We seldom found that the number of line segments exceeds 4n and the mode is around 2n.",
        "These findings render our approach usable even in the very large natural language applications."
      ]
    },
    {
      "heading": "9. Conclusions",
      "text": [
        "We presented a novel efficient apparatus for tracking the entire relaxation path of maximum entropy problems.",
        "We currently study natural language processing applications.",
        "In particular, we are in the process of devising homotopy methods for domain adaptation Blitzer (2008) and language modeling based on context tree weighting (Willems et al., 1995).",
        "We also examine generalization of our approach in which the relative entropy objective is replaced with a separable Bregman (Censor and Zenios, 1997) function.",
        "Such a generalization is likely to distill further connections to the other homotopy methods, in particular the least angle regression algorithm of Efron et al.",
        "(2004) and homotopy methods for the Lasso in general (Osborne et al., 2000).",
        "We also plan to study separable Bregman functions in order to derive entire path solutions for less explored objectives such as the Itakura-Saito spectral distance (Rabiner and Juang, 1993) and distances especially suited for natural language processing."
      ]
    }
  ]
}
