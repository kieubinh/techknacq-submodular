{
  "info": {
    "authors": [
      "Marco Kuhlmann",
      "Carlos Gómez-Rodríguez",
      "Giorgio Satta"
    ],
    "book": "Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies",
    "id": "acl-P11-1068",
    "title": "Dynamic Programming Algorithms for Transition-Based Dependency Parsers",
    "url": "https://aclweb.org/anthology/P11-1068",
    "year": 2011
  },
  "references": [
    "acl-D08-1059",
    "acl-D09-1005",
    "acl-D09-1127",
    "acl-J08-4003",
    "acl-J99-4004",
    "acl-P08-1110",
    "acl-P10-1110",
    "acl-P89-1018",
    "acl-P96-1025",
    "acl-P99-1059",
    "acl-W04-0308",
    "acl-W06-2922"
  ],
  "sections": [
    {
      "text": [
        "Marco Kuhlmann Carlos Gomez-Rodriguez Giorgio Satta",
        "of Linguistics and Philology Departamento de Computaciön Dept.",
        "of Information Engineering",
        "Uppsala University, Sweden Universidade da Coruna, Spain University of Padua, Italy",
        "marco.kuhlmann@lingfil.uu.se cgomezr@udc.es satta@dei.unipd.it",
        "We develop a general dynamic programming technique for the tabulation of transition-based dependency parsers, and apply it to obtain novel, polynomial-time algorithms for parsing with the arc-standard and arc-eager models.",
        "We also show how to reverse our technique to obtain new transition-based dependency parsers from existing tabular methods.",
        "Additionally, we provide a detailed discussion of the conditions under which the feature models commonly used in transition-based parsing can be integrated into our algorithms."
      ]
    },
    {
      "heading": "1. Introduction",
      "text": [
        "Dynamic programming algorithms, also known as tabular or chart-based algorithms, are at the core of many applications in natural language processing.",
        "When applied to formalisms such as context-free grammar, they provide polynomial-time parsing algorithms and polynomial-space representations of the resulting parse forests, even in cases where the size of the search space is exponential in the length of the input string.",
        "In combination with appropriate semirings, these packed representations can be exploited to compute many values of interest for machine learning, such as best parses and feature expectations (Goodman, 1999; Li and Eisner, 2009).",
        "In this paper, we follow the line of investigation started by Huang and Sagae (2010) and apply dynamic programming to (projective) transition-based dependency parsing (Nivre, 2008).",
        "The basic idea, originally developed in the context of push-down automata (Lang, 1974; Tomita, 1986; Billot and Lang, 1989), is that while the number of computations of a transition-based parser may be exponential in the length of the input string, several portions of these computations, when appropriately represented, can be shared.",
        "This can be effectively implemented through dynamic programming, resulting in a packed representation of the set of all computations.",
        "The contributions of this paper can be summarized as follows.",
        "We provide (declarative specifications of) novel, polynomial-time algorithms for two widely-used transition-based parsing models: arc-standard (Nivre, 2004; Huang and Sagae, 2010) and arc-eager (Nivre, 2003; Zhang and Clark, 2008).",
        "Our algorithm for the arc-eager model is the first tabular algorithm for this model that runs in polynomial time.",
        "Both algorithms are derived using the same general technique; in fact, we show that this technique is applicable to all transition-parsing models whose transitions can be classified into \"shift\" and \"reduce\" transitions.",
        "We also show how to reverse the tabulation to derive a new transition system from an existing tabular algorithm for dependency parsing, originally developed by Gömez-Rodrfguez et al.",
        "(2008).",
        "Finally, we discuss in detail the role of feature information in our algorithms, and in particular the conditions under which the feature models traditionally used in transition-based dependency parsing can be integrated into our framework.",
        "While our general approach is the same as the one of Huang and Sagae (2010), we depart from their framework by not representing the computations of a parser as a graph-structured stack in the sense of Tomita (1986).",
        "We instead simulate computations as in Lang (1974), which results in simpler algorithm specifications, and also reveals deep similarities between transition-based systems for dependency parsing and existing tabular methods for lexicalized context-free grammars."
      ]
    },
    {
      "heading": "2. Transition-Based Dependency Parsing",
      "text": [
        "We start by briefly introducing the framework of transition-based dependency parsing; for details, we refer to Nivre (2008).",
        "Let w = w0 ••• wn-l be a string over some fixed alphabet, where n > 1 and wo is the special token root.",
        "A dependency graph for w is a directed graph G = (Vw, A), where Vw = {0,.. .,n – 1} is the set of nodes, and A ç Vw x Vw is the set of arcs.",
        "Each node in Vw encodes the position of a token in w, and each arc in A encodes a dependency relation between two tokens.",
        "To denote an arc (i, j) 2 A, we write i !",
        "j ; here, the node i is the head, and the node j is the dependent.",
        "A sample dependency graph is given in the left part of Figure 2.",
        "A transition system is a structure S = (C, T, I, Ct), where C is a set of configurations, T is a finite set of transitions, which are partial functions t : C * C, I is a total initialization function mapping each input string to a unique initial configuration, and Ct ç C is a set of terminal configurations.",
        "The transition systems that we investigate in this paper differ from each other only with respect to their sets of transitions, and are identical in all other aspects.",
        "In each of them, a configuration is defined relative to a string w as above, and is a triple c = (o,ß,A), where a and ß are disjoint lists of nodes from Vw, called stack and buffer, respectively, and A ç Vw x Vw is a set of arcs.",
        "We denote the stack, buffer and arc set associated with c by a(c), ß(c), and A(c), respectively.",
        "We follow a standard convention and write the stack with its topmost element to the right, and the buffer with its first element to the left; furthermore, we indicate concatenation in the stack and in the buffer by a vertical bar.",
        "The initialization function maps each string w to the initial configuration ([], [0,..., |w| – 1], 0).",
        "The set of terminal configurations contains all configurations of the form ([0], [], A), where A is some set of arcs.",
        "Given an input string w, a parser based on S processes w from left to right, starting in the initial configuration I(w).",
        "At each point, it applies one of the transitions, until at the end it reaches a terminal configuration; the dependency graph defined by the arc set associated with that configuration is then returned as the analysis for w. Formally, a computation of S on w is a sequence y = c0,..., cm, m > 0, of configurations (defined relative to w) in which each configuration is obtained as the value of the preceding one under some transition.",
        "It is called complete whenever c0 = I(w), and cm 2 Ct. We note that a computation can be uniquely specified by its initial configuration c0 and the sequence of its transitions, understood as a string over T. Complete computations, where c0 is fixed, can be specified by their transition sequences alone."
      ]
    },
    {
      "heading": "3. Arc-Standard Model",
      "text": [
        "To introduce the core concepts of the paper, we first look at a particularly simple model for transition-based dependency parsing, known as the arc-standard model.",
        "This model has been used, in slightly different variants, by a number of parsers (Nivre, 2004; Attardi, 2006; Huang and Sagae, 2010).",
        "The arc-standard model uses three types of transitions: Shift (sh) removes the first node in the buffer and pushes it to the stack.",
        "Left-Arc (la) creates a new arc with the topmost node on the stack as the head and the second-topmost node as the dependent, and removes the second-topmost node from the stack.",
        "Right-Arc (ra) is symmetric to Left-Arc in that it creates an arc with the second-topmost node as the head and the topmost node as the dependent, and removes the topmost node.",
        "The three transitions can be formally specified as in Figure 1.",
        "The right half of Figure 2 shows a complete computation of the arc-standard transition system, specified by its transition sequence.",
        "The picture also shows the contents of the stack over the course of the computation; more specifically, column i shows the stack a(ct ) associated with the configuration a.",
        "root This news had little effect on the markets sh sh sh lash lash sh lash sh sh la ra ra ra ra",
        "Figure 2: A dependency tree (left) and a computation generating this tree in the arc-standard system (right).",
        "The key to the tabulation of transition-based dependency parsers is to find a way to decompose computations into smaller, shareable parts.",
        "For the arc-standard model, as well as for the other transition systems that we consider in this paper, we base our decomposition on the concept of push computations.",
        "By this, we mean computations on some input string w with the following properties:",
        "(P1) The initial stack a(c0) is not modified during the computation, and is not even exposed after the first transition: For every 1 < i < m, there exists a non-empty stack at such that a(ct) = a(c0) jat.",
        "(P2) The overall effect of the computation is to push a single node to the stack: The stack a(cm) can be written as a(cm) = a(c0)jh, for some h 2 Vw.",
        "We can verify that the computation in Figure 2 is a push computation.",
        "We can also see that it contains shorter computations that are push computations; one example is the computation y0 = ci,...,ci6, whose overall effect is to push the node 3.",
        "In Figure 2, this computation is marked by the zigzag path traced in bold.",
        "The dashed line delineates the stack a(c\\), which is not modified during y0.",
        "Every computation that consists of a single sh transition is a push computation.",
        "Starting from these atoms, we can build larger push computations by means of two (partial) binary operations fja and fra, defined as follows.",
        "Let yi = ci0,...,cimi and y2 = c20,..., c2m2 be push computations on the same input string w such that cimi = c20.",
        "Then where c is obtained from c2m2 by applying the ra transition.",
        "(The operation fja is defined analogously.)",
        "We can verify that fra (yi, y2) is another push computation.",
        "For instance, with respect to Figure 2, fra(yi, y2) = y0.",
        "Conversely, we say that the push computation y0 can be decomposed into the subcom-putations yi and y2, and the operation fra.",
        "Building on the compositional structure of push computations, we now construct a deduction system (in the sense of Shieber et al.",
        "(1995)) that tabulates the computations of the arc-standard model for a given input string w = w0 ••• wn-i.",
        "For 0 < i < n, we shall write ßt to denote the buffer [i,... ,n – 1].",
        "Thus, ß0 denotes the full buffer, associated with the initial configuration I(w), and ßn denotes the empty buffer, associated with a terminal configuration c 2 Ct.",
        "Item form.",
        "The items of our deduction system take the form [i, h, j], where 0 < i < h < j < n. The intended interpretation of an item [i,h,j] is: For every configuration c0 with ß(c0) = ßt, there exists a push computation y = c0, .",
        ".",
        ".",
        ", cm such that ß(cm) = ßj ,and a(cm) = a(c0)jh.",
        "Goal.",
        "The only goal item is [0, 0, n], asserting that there exists a complete computation for w.",
        "Axioms.",
        "For every stack a, position i < n and arc set A, by a single sh transition we obtain the push computation (a, ßt, A), (a ji, ßt+i, A).",
        "Therefore we can take the set of all items of the form C 1] as the axioms of our system.",
        "Inference rules.",
        "The inference rules parallel the composition operations f\\a and fra.",
        "Suppose that we have deduced the items [i, hi,k] and [k, h2, j], where 0 < i < hi < k < h2 < j < n. The item [i, hi,k] asserts that for every configuration ci0 means of fra, we can then compose yi and y2 into a new push computation",
        "-y\\ -",
        "-y2-",
        ">",
        "8",
        ";",
        "y",
        "7",
        "7",
        "8",
        ";",
        "y",
        "5",
        "6",
        "6",
        "6",
        "6",
        "6",
        "j",
        "2",
        "3",
        "k",
        "/",
        "4",
        "4",
        "5",
        "5",
        "5",
        "5",
        "5",
        "5",
        "5",
        "-y",
        "À",
        "1",
        "2",
        "2",
        "3",
        "3",
        "3",
        "3",
        "3",
        "3",
        "3",
        "3",
        "3",
        "3",
        "3",
        "H",
        "0",
        "0",
        "0",
        "0",
        "0",
        "0",
        "0",
        "0",
        "0",
        "0",
        "0",
        "0",
        "0",
        "0",
        "0",
        "0",
        "1",
        "2",
        "3",
        "4",
        "5",
        "6",
        "7",
        "8",
        "9",
        "10",
        "11",
        "12",
        "13",
        "14",
        "15",
        "16",
        "17",
        "fra(yi , y2) = ci0, .",
        ".",
        ".",
        ", cim , c2i , .",
        ".",
        ".",
        ", c2m2, c .",
        "Here, ß(c) = ßj, and a(c) = a(ci0)| hi .",
        "Therefore, we may generate the item [i, hi , j].",
        "The inference rule for la can be derived analogously.",
        "We have informally argued that our deduction system is sound.",
        "To show completeness, we prove the following lemma: For all 0 < i < h < j < jwj and every push computation y = c0, .",
        ".",
        ".",
        ", cm on w with ß(c0) = ßt, ß(cm) = ßj and a(cm) = a(o)|h, the item [i,h, j] is generated.",
        "The proof is by induction on m, and there are two cases:",
        "m = 1.",
        "In this case, y consists of a single sh transition, h = i , j = i C 1 , and we need to show that the item [i, i, i C 1] is generated.",
        "This holds because this item is an axiom.",
        "m > 2.",
        "In this case, y ends with either a la or a ra transition.",
        "Let c be the rightmost configuration in y that is different from cm and whose stack size is one larger than the size of a(c0).",
        "The computations are both push computations with strictly fewer transitions than y.",
        "Suppose that the last transition in y is ra.",
        "In this case, ß(c) = ßk for some i < k < j, a(c) = a(c0)jh with h < k, ß(cm-i) = ßj, and a(cm-i) = a(c0)lhjh' for some k < h < j.",
        "By induction, we may assume that we have generated items [i,h, k] and [k,h, j].",
        "Applying the inference rule for ra, we deduce the item [i, h, j].",
        "An analogous argument can be made for f\\a.",
        "Apart from being sound and complete, our deduction system also has the property that it assigns at most one derivation to a given item.",
        "To see this, note that in the proof of the lemma, the choice of c is uniquely determined: If we take any other configuration c' that meets the selection criteria, then the computation y2 = c , .",
        ".",
        ".",
        ", cm-i is not a push computation, as it contains c as an intermediate configuration, and thereby violates property P1.",
        "Let us briefly take stock of what we have achieved so far.",
        "We have provided a deduction system capable of tabulating the set of all computations of an arc-standard parser on a given input string, and proved the correctness of this system relative to an interpretation based on push computations.",
        "Inspecting the system, we can see that its generic implementation takes space in O(|w|) and time in O(\\wl).",
        "Our deduction system is essentially the same as the one for the CKY algorithm for bilexicalized context-free grammar (Collins, 1996; Gömez-Rodnguez et al., 2008).",
        "This equivalence reveals a deep correspondence between the arc-standard model and bilexical-ized context-free grammar, and, via results by Eisner and Satta (1999), to head automata.",
        "In particular, Eisner's and Satta's \"hook trick\" can be applied to our tabulation to reduce its runtime to Odw |)."
      ]
    },
    {
      "heading": "4. Adding Features",
      "text": [
        "The main goal with the tabulation of transition-based dependency parsers is to obtain a representation based on which semiring values such as the highest-scoring computation for a given input (and with it, a dependency tree) can be calculated.",
        "Such computations involve the use of feature information.",
        "In this section, we discuss how our tabulation of the arc-standard system can be extended for this purpose.",
        "Figure 4: Extended inference rules under the feature model 0 = (si.w, s0.w).",
        "The annotations indicate how to calculate a candidate for an update of the Viterbi score of the conclusion using the Viterbi scores of the premises.",
        "For the sake of concreteness, suppose that we want to score computations based on the following model, taken from Zhang and Clark (2008).",
        "The score of a computation y is broken down into a sum of scores score(t, ct) for combinations of a transition t in the transition sequence associated with y and the configuration ct in which t was taken:",
        "The score score(t, ct ) is defined as the dot product of the feature representation of ct relative to a feature model 0 and a transition-specific weight vector at :",
        "The feature model 0 is a vector (<pi,... ,<pn) of elementary feature functions, and the feature representation 0(c) of a configuration c is a vector x = (<fii (c),..., <pn(c)) of atomic values.",
        "Two examples of feature functions are the word form associated with the topmost and second-topmost node on the stack; adopting the notation of Huang and Sagae (2010), we will write these functions as s0.w and si .w, respectively.",
        "Feature functions like these have been used in several parsers (Nivre, 2006; Zhang and",
        "Clark, 2008; Huang et al., 2009).",
        "To integrate feature models into our tabulation of the arc-standard system, we can use extended items of the form [i, h, j ; Xl,Xr] with the same intended interpretation as the old items [i,h, j], except that the initial configuration of the asserted computations y = c0,...,cm now is required to have the feature representation xl, and the final configuration is required to have the representation :xr :",
        "We shall refer to the vectors xel and xer as the left-context vector and the right-context vector of the computation y, respectively.",
        "We now need to change the deduction rules so that they become faithful to the extended interpretation.",
        "Intuitively speaking, we must ensure that the feature values can be computed along the inference rules.",
        "As a concrete example, consider the feature model 0 = (si.w, s0.w).",
        "In order to integrate this model into our tabulation, we change the rule for ra as in Figure 4, where xi,... ,x4 range over possible word forms.",
        "The shared variable occurrences in this rule capture the constraints that hold between the feature values of the subcomputations yi and y2 asserted by the premises, and the computations fra (yi, y2) asserted by the conclusion.",
        "To illustrate this, suppose that yi and y2 are as in Figure 2.",
        "Then the three occurrences of x3 for instance encode that",
        "[s0.w](c6) = [si.w](ci5) = [s0.w](ci6) = V)3 .",
        "We also need to extend the axioms, which correspond to computations consisting of a single sh transition.",
        "The most conservative way to do this is to use a generate-and-test technique: Extend the existing axioms by all valid choices of left-context and right-context vectors, that is, by all pairs Xl,Xr such that there exists a configuration c with 0(c) = Xl and 0(sh(c)) = Xr.",
        "The task of filtering out useless guesses can then be delegated to the deduction system.",
        "A more efficient way is to only have one axiom, for the case where c = I(w), and to add to the deduction system a new, unary inference rule for sh as in Figure 4.",
        "This rule only creates items whose left-context vector is the right-context vector of some other item, which prevents the generation of useless items.",
        "In the following, we take this second approach, which is also the approach of Huang and Sagae (2010).",
        "[i,h,j ;(x2,x1), (xi,x3)] : (p,v) .",
        ", .",
        "Figure 5: Extended inference rules under the feature model 0 = (s0.w, si .w).",
        "The annotations indicate how to calculate a candidate for an update of the prefix score and Viterbi score of the conclusion.",
        "Once we have extended our deduction system with feature information, many values of interest can be computed.",
        "One simple example is the Viterbi score for an input w, defined as where r(w) denotes the set of all complete computations for w .",
        "The score of a complex computation ft (yi, y2) is the sum of the scores of its subcomputa-tions yi, y2, plus the transition-specific dot product.",
        "Since this dot product only depends on the feature representation of the final configuration of y2, the Viterbi score can be computed on top of the inference rules using standard techniques.",
        "The crucial calculation is indicated in Figure 4.",
        "Another interesting value is the prefix score of an item, which, apart from the Viterbi score, also includes the cost of the best search path leading to the item.",
        "Huang and Sagae (2010) use this quantity to order the items in a beam search on top of their dynamic programming method.",
        "In our framework, prefix scores can be computed as indicated in Figure 5.",
        "Alternatively, we can also use the more involved calculation employed by Huang and Sagae (2010), which allows them to get rid of the left-context vector from their items.",
        "So far we have restricted our attention to a concrete and extremely simplistic feature model.",
        "The feature models that are used in practical systems are considerably more complex, and not all of them are compatible with our framework in the sense that they can be integrated into our deduction system in the way described in Section 4.2.",
        "For a simple example of a feature model that is incompatible with our tabulation, consider the model 0' = (s0.rc.w), whose single feature function extracts the word form of the right child (rc) of the topmost node on the stack.",
        "Even if we know the values of this feature for two computations yi, y2, we have no way to compute its value for the composed computation fra (yi, y2) : This value coincides with the word form of the topmost node on the stack associated with y2, but in order to have access to it in the context of the ra rule, our feature model would need to also include the feature function s0.w.",
        "The example just given raises the question whether there is a general criterion based on which we can decide if a given feature model is compatible with our tabulation.",
        "An attempt to provide such a criterion has been made by Huang and Sagae (2010), who define a constraint on feature models called \"monotonicity\" and claim that this constraint guarantees that feature values can be computed using their dynamic programming approach.",
        "Unfortunately, this claim is wrong.",
        "In particular, the feature model 0 given above is \"monotonic\", but cannot be tabulated, neither in our nor in their framework.",
        "In general, it seems clear that the question of compatibility is a question about the relation between the tabulation and the feature model, and not about the feature model alone.",
        "To find practically useful characterizations of compatibility is an interesting avenue for future research."
      ]
    },
    {
      "heading": "5. Arc-Eager Model",
      "text": [
        "Up to now, we have only discussed the arc-standard model.",
        "In this section, we show that the framework of push computations also provides a tabulation of another widely-used model for dependency parsing, the arc-eager model (Nivre, 2003).",
        "The arc-eager model has three types of transitions, shown in Figure 6: Shift (sh) works just like in arc-standard, moving the first node in the buffer to the stack.",
        "Left-Arc (lae) creates a new arc with the first node in the buffer as the head and the topmost node on the stack as the dependent, and pops the stack.",
        "It can only be applied if the topmost node on the stack has not already been assigned a head, so as to preserve the single-head constraint.",
        "Right-Arc (rae) creates an arc in the opposite direction as Left-Arc, and moves the first node in the buffer to the stack.",
        "Finally, Reduce (re) simply pops the stack; it can only be applied if the topmost node on the stack has already been assigned a head.",
        "Note that, unlike in the case of arc-standard, the parsing process in the arc-eager model is not bottom-up: the right dependents of a node are attached before they have been assigned their own right dependents.",
        "If we look at the specification of the transitions of the arc-standard and the arc-eager model and restrict our attention to the effect that they have on the stack and the buffer, then we can see that all seven transitions fall into one of three types:",
        "We refer to transitions of type T1 as shift and to transitions of type T2 and T3 as reduce transitions.",
        "The crucial observation now is that the concept of push computations and the approach to their tabulation that we have taken for the arc-standard system can easily be generalized to other transition systems whose transitions are of the type shift or reduce.",
        "In particular, the proof of the correctness of our deduction system that we gave in Section 3 still goes through if instead of sh we write \"shift\" and instead of la and ra we write \"reduce\".",
        "Generalizing our construction for the arc-standard model along these lines, we obtain a tabulation of the arc-eager model.",
        "Just like in the case of arc-standard, each single shift transition in that model (be it sh or rae) constitutes a push computation, while the reduce transitions induce operations fjae and fre.",
        "The only difference is that the preconditions of lae and re must be met.",
        "Therefore, fjae (yi, y2) is only defined if the topmost node on the stack in the final configuration of y2 has not yet been assigned a head, and /re(y1, y2) is only defined in the opposite case.",
        "Item form.",
        "In our deduction system for the arc-eager model we use items of the form [/, hb, j], where 0 < / < h < j < \\w\\, and b 2 {0,1g.",
        "An item [/, hb, j] has the same meaning as the corresponding item in our deduction system for arc-standard, but also keeps record of whether the node h has been assigned a head (b = 1) or not (b = 0).",
        "Axioms.",
        "Reasoning as in arc-standard, the axioms of the deduction system for the arc-eager model are the items of the form [/, /, / + 1] and [j, j, j C 1], where j > 0: the former correspond to the push computations obtained from a single sh, the latter to those obtained from a single rae, which apart from shifting a node also assigns it a head.",
        "Inference rules.",
        "Also analogously to arc-standard, if we know that there exists a push computation y1 of the form asserted by the item [/, hb, k], and a push computation y2 of the form asserted by [k,g, j], where j < \\ w \\ , then we can build the push computation fjae (y1, y2) of the form asserted by the item [/, hb, j].",
        "Similarly, if y2 is of the form asserted by [k, g, j], then we can build fre(y1, y2), which again is of the form by asserted [/, hb, j].",
        "Thus:",
        "-fT^b-j- (lae) , -fT^b-j- (re) .",
        "(a,/\\ß)",
        "h",
        "(a\\/,ß)",
        "sh,rae",
        "(T1)",
        "(a\\/LAß)",
        "h",
        "(a \\j,ß)",
        "la",
        "(T2)",
        "(a\\/,ß)",
        "h",
        "(a,ß)",
        "ra, lae, re",
        "(T3)",
        "As mentioned above, the correctness and non-ambiguity of the system can be proved as in Section 3.",
        "Features can be added in the same way as discussed in Section 4.",
        "Looking at the inference rules, it is clear that an implementation of the deduction system for arc-eager takes space in O(\\w\\) and time in O(\\w\\ ), just like in the case of arc-standard.",
        "However, a closer inspection reveals that we can give even tighter bounds.",
        "In all derivable items [/, hb, j], it holds that / = h. This can easily be shown by induction: The property holds for the axioms, and the first two indexes of a consequent of a deduction rule coincide with the first two indexes of the left antecedent.",
        "Thus, if we use the notation [/b, k] as a shorthand for [/, /b, k], then we can rewrite the inference rules for the arc-eager system as in Figure 7, where, additionally, we have added unary rules for sh and ra and restricted the set of axioms along the lines set out in Section 4.2.",
        "With this formulation, it is apparent that the space complexity of the generic implementation of the deduction system is in fact even in O(\\w\\), and its time complexity is in O(\\w\\)."
      ]
    },
    {
      "heading": "6. Hybrid Model",
      "text": [
        "We now reverse the approach that we have taken in the previous sections: Instead of tabulating a transition system in order to get a dynamic-programming parser that simulates its computations, we start with a tabular parser and derive a transition system from it.",
        "In the new model, dependency trees are built bottom-up as in the arc-standard model, but the set of all computations in the system can be tabulated in space O(\\w\\) and time O(\\w\\), as in arc-eager.",
        "Gomez-Rodriguez et al.",
        "(2008) present a deductive version of the dependency parser of Yamada and Matsumoto (2003); their deduction system is given in Figure 8.",
        "The generic implementation of the deduction system takes space O(\\w\\) and time O(\\w\\).",
        "In the original interpretation of the deduction system, an item [/, j] asserts the existence of a pair of (projective) dependency trees: the first tree rooted at token w,, having all nodes in the substring w; • • • w^-1 as descendants, where / < k < j ; and the second tree rooted at token wy, having all nodes in the substring wk • • • wy as descendants.",
        "(Note that we use fencepost indexes, while Gomez-Rodriguez et al.",
        "(2008) indexes positions.)",
        "In the context of our tabulation framework, we adopt a new interpretation of items: An item [/, j] has the same meaning as an item [/, / , j] in the tabulation of the arc-standard model; for every configuration c with ß(c) = ß;, it asserts the existence of a push computation that starts with c and ends with a configuration c for which ß(c) = ßy and a(c) = a(c)\\/.",
        "If we interpret the inference rules of the system in terms of composition operations on push computations as usual, and also take the intended direction of the dependency arcs into account, then this induces a transition system with three transitions:",
        "We call this transition system the hybrid model, as sh and ra are just like in arc-standard, while lah is like the Left-Arc transition in the arc-eager model (lae), except that it does not have the precondition.",
        "Like the arc-standard but unlike the arc-eager model, the hybrid model builds dependencies bottom-up."
      ]
    },
    {
      "heading": "7. Conclusion",
      "text": [
        "In this paper, we have provided a general technique for the tabulation of transition-based dependency parsers, and applied it to obtain dynamic programming algorithms for two widely-used parsing models, arc-standard and (for the first time) arc-eager.",
        "The basic idea behind our technique is the same as the one implemented by Huang and Sagae (2010) for the special case of the arc-standard model, but instead of their graph-structured stack representation we use a tabulation akin to Lang's approach to the simulation of pushdown automata (Lang, 1974).",
        "This considerably simplifies both the presentation and the implementation of parsing algorithms.",
        "It has also enabled us to give simple proofs of correctness and establish relations between transition-based parsers and existing parsers based on dynamic programming.",
        "While this paper has focused on the theoretical aspects and the analysis of dynamic programming versions of transition-based parsers, an obvious avenue for future work is the evaluation of the empirical performance and efficiency of these algorithms in connection with specific feature models.",
        "The feature models used in transition-based dependency parsing are typically very expressive, and exhaustive search with them quickly becomes impractical even for our cubic-time algorithms of the arc-eager and hybrid model.",
        "However, Huang and Sagae (2010) have provided evidence that the use of dynamic programming on top of a transition-based dependency parser can improve accuracy even without exhaustive search.",
        "The tradeoff between expressivity of the feature models on the one hand and the efficiency of the search on the other is a topic that we find worth investigating.",
        "Another interesting observation is that dynamic programming makes it possible to use predictive features, which cannot easily be integrated into a non-tabular transition-based parser.",
        "This could lead to the development of parsing models that cross the border between transition-based and tabular parsing."
      ]
    },
    {
      "heading": "Acknowledgments",
      "text": [
        "All authors contributed equally to the work presented in this paper.",
        "M. K. wrote most of the manuscript.",
        "C. G.-R. has been partially supported by Ministerio de Educaciön y Ciencia and FEDER (HUM2007-66607-C04) and Xun-ta de Galicia (PGIDIT07SIN005206PR, Rede Galega de Procesamento da Linguaxe e Recuperaciön de Infor-maciön, Rede Galega de Lingiiïstica de Corpus, Bolsas Estadfas INCITE/FSE cofinanced)."
      ]
    }
  ]
}
