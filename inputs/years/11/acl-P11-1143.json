{
  "info": {
    "authors": [
      "Shuguang Li",
      "Suresh Manandhar"
    ],
    "book": "Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies",
    "id": "acl-P11-1143",
    "title": "Improving Question Recommendation by Exploiting Information Need",
    "url": "https://aclweb.org/anthology/P11-1143",
    "year": 2011
  },
  "references": [
    "acl-C00-2163",
    "acl-D10-1010",
    "acl-J03-1002",
    "acl-J93-2003",
    "acl-P08-1019",
    "acl-W10-0404",
    "acl-W10-1201"
  ],
  "sections": [
    {
      "text": [
        "In this paper we address the problem of question recommendation from large archives of community question answering data by exploiting the users' information needs.",
        "Our experimental results indicate that questions based on the same or similar information need can provide excellent question recommendation.",
        "We show that translation model can be effectively utilized to predict the information need given only the user's query question.",
        "Experiments show that the proposed information need prediction approach can improve the performance of question recommendation."
      ]
    },
    {
      "heading": "1. Introduction",
      "text": [
        "There has recently been a rapid growth in the number of community question answering (CQA) services such as Yahoo!",
        "Answers, Askville and WikiAnswer where people answer questions posted by other users.",
        "These CQA services have built up very large archives of questions and their answers.",
        "They provide a valuable resource for question answering research.",
        "Table 1 is an example from Yahoo!",
        "Answers web site.",
        "In the CQA archives, the title part is the user's query question, and the user's information need is usually expressed as natural language statements mixed with questions expressing their interests in the question body part.",
        "In order to avoid the lag time involved with waiting for a personal response and to enable high quality answers from the archives to be retrieved, we need to search CQA archives of previous questions that are closely associated with answers.",
        "If a question is found to be interesting to the user, then a previous answer can be provided with very little delay.",
        "Question search and question recommendation are proposed to facilitate finding highly relevant or potentially interesting questions.",
        "Given a user's question as the query, question search tries to return the most semantically similar questions from the question archives.",
        "As the complement of question search, we define question recommendation as recommending questions whose information need is the same or similar to the user's original question.",
        "For example, the question \"What aspects of my computer do I need to upgrade ...\" with the information need \"... making a skate movie, my computer freezes,...\" and the question \"What is the most cost effective way to expend memory space ... \" with information need \"... in need of more space for music and pictures ... \" are both good recommendation questions for the user in Table 1.",
        "So the recommended questions are not necessarily identical or similar to the query question.",
        "In this paper, we discuss methods for question recommendation based on using the similarity between information need in the archive.",
        "We also propose two models to predict the information need based on the query question even if there's no information need expressed in the body of the question.",
        "We show that with the proposed models it is possible to recommend questions that have the same or similar information need.",
        "The remainder of the paper is structured as follows.",
        "In section 2, we briefly describe the related work on question search and recommendation.",
        "Section 3 addresses in detail how we measure the similarity between short texts.",
        "Section 4 describes two models for information need prediction that we use for the experiment.",
        "Section 5 tests the performance of the proposed models for the task of question recommendation.",
        "Section 7 is the conclusion of this paper."
      ]
    },
    {
      "heading": "2. Related Work 2.1 Question Search",
      "text": [
        "Burke et al.",
        "(1997) combined a lexical metric and a simple semantic knowledge-based (WordNet) similarity method to retrieve semantically similar questions from frequently asked question (FAQ) data.",
        "Jeon et al.",
        "(2005a) retrieved semantically similar questions from Korean CQA data by calculating the similarity between their answers.",
        "The assumption behind their research is that questions with very similar answers tend to be semantically similar.",
        "Jeon et al.",
        "(2005b) also discussed methods for grouping similar questions based on using the similarity between answers in the archive.",
        "These grouped question pairs were further used as training data to estimate probabilities for a translation-based question retrieval model.",
        "Wang et al.",
        "(2009) proposed a tree kernel framework to find similar questions in the C-QA archive based on syntactic tree structures.",
        "Wang et al.",
        "(2010) mined lexical and syntactic features to detect question sentences in CQA data.",
        "Wu et al.",
        "(2008) presented an incremental automatic question recommendation framework based on probabilistic latent semantic analysis.",
        "Question recommendation in their work considered both the users' interests and feedback.",
        "Duan et al.",
        "(2008) made use of a tree-cut model to represent questions as graphs of topic terms.",
        "Questions were recommended based on this topic graph.",
        "The recommended questions can provide different aspects around the topic of the query question.",
        "The above question search and recommendation research provide different ways to retrieve questions from large archives of question answering data.",
        "However, none of them considers the similarity or diversity between questions by exploring their information needs."
      ]
    },
    {
      "heading": "3. Short Text Similarity Measures",
      "text": [
        "In question retrieval systems accurate similarity measures between documents are crucial.",
        "Most traditional techniques for measuring the similarity between two documents mainly focus on comparing word co-occurrences.",
        "The methods employing this strategy for documents can usually achieve good results, because they may share more common words than short text snippets.",
        "However the state-of-the-art techniques usually fail to achieve desired results due to short questions and information need texts.",
        "In order to measure the similarity between short texts, we make use of three kinds of text similarity measures: TFIDF based, Knowledge based and Latent Dirichlet Allocation (LDA) based similarity measures in this paper.",
        "We will compare their performance for the task of question recommendation in the experiment section.",
        "Baeza-Yates and Ribeiro-Neto (1999) provides a T-FIDF method to calculate the similarity between two texts.",
        "Each document is represented by a term vector using TFIDF score.",
        "The similarity between two text Di and Dj is the cosine similarity in the vector space model:",
        "Q Title",
        "If I want a faster computer should I buy more memory or storage space?",
        "...",
        "QBody",
        "I edit pictures and videos so I need them to work quickly.",
        "Any advice?",
        "Answer",
        "...",
        "If you are running out of space on your hard drive, then ... to boost your computer speed usually requires more RAM ...",
        "This method is used in most information retrieval systems as it is both efficient and effective.",
        "However if the query text contains only one or two words this method will be biased to shorter answer texts (Jeon et al., 2005a).",
        "We also found that in CQA data short contents in the question body cannot provide any information about the users' information needs.",
        "Based on the above two reasons, in the test data sets we do not include the questions whose information need parts contain only a few noninformative words",
        "Mihalcea et al.",
        "(2006) proposed several knowledge-based methods for measuring the semantic level similarity of texts to solve the lexical chasm problem between short texts.",
        "These knowledge-based similarity measures were derived from word semantic similarity by making use of WordNet.",
        "The evaluation on a paraphrase recognition task showed that knowledge-based measures outperform the simpler lexical level approach.",
        "We follow the definition in (Mihalcea et al., 2006) to derive a text-to-text similarity metric mcs for two given texts Di and Dj:",
        "topics discovered by Latent Dirichlet Allocation (L-DA) methods.",
        "In contrast to the TFIDF method which measures \"common words\", short texts are not compared to each other directly in probabilistic topic models.",
        "Instead, the texts are compared using some \"third-party\" topics that relate to them.",
        "A passage D in the retrieved documents (document collection) is represented as a mixture of fixed topics, with topic z getting weight öiD) in passage D and each topic is a distribution over a finite vocabulary of words, with word w having a probability (W in topic z. Gibbs Sampling can be used to estimate the corresponding expected posterior probabilities P(z|D) = öZD) and P(w|z) = (Griffiths and Steyvers, 2004).",
        "In this paper we use two LDA based similarity measures in (Celikyilmaz et al., 2010) to measure the similarity between short information need texts.",
        "The first LDA similarity method uses KL divergence to measure the similarity between two documents under each given topic:",
        "simLDAl(Dl,Dj ) = k £ igw (Drfc),Drfc))",
        "For each word w in Di, maxSim(w, Dj) computes the maximum semantic similarity between w and any word in Dj.",
        "In this paper we choose lin (Lin, 1998) and jcn (Jiang and Conrath, 1997) to compute the word-to-word semantic similarity.",
        "We only choose nouns and verbs for calculating mcs.",
        "Additionally, when w is a noun we restrict the words in document Di (and Dj) to just nouns.",
        "Similarly, when w is a verb, we restrict the words in document Di (and Dj) to just verbs.",
        "Celikyilmaz et al.",
        "(2010) presented probabilistic topic model based methods to measure the similarity between question and candidate answers.",
        "The candidate answers were ranked based on the hidden",
        "W (D(z k), Djz k)) calculates the similarity between two documents under topic z = k using KL divergence measure.",
        "Di is the probability distribution of words in document Di given a fixed topic z.",
        "The second LDA similarity measure from (Griffiths and Steyvers, 2004) treats each document as a probability distribution of topics:",
        "where ö(Di) is document Di's probability distribution of topics as defined earlier.",
        "4 Information Need Prediction using Statistical Machine Translation Model",
        "There are two reasons that we need to predict information need.",
        "It is often the case that the query question does not have a question body part.",
        "So we need a model to predict the information need part based on the query question in order to recommend questions based on the similarity of their information needs.",
        "Another reason is that information need prediction plays a crucial part not only in Question Answering but also in information retrieval (Liu et al., 2008).",
        "In this paper we propose an information need prediction method based on a statistical machine translation model.",
        "(f(s), e(s)), s = 1,...,S is a parallel corpus.",
        "In a sentence pair (f, e), source language String, f = fif2---fj has J words, and e = e\\e2---ei has I words.",
        "And alignment a = aia2---aJ represents the mapping information from source language words to target words.",
        "Statistical machine translation models estimate Pr(f|e), the translation probability from source language string e to target language string f (Och et al., 2003):",
        "EM-algorithm is usually used to train the alignment models to estimate lexicon parameters p(f |e).",
        "In E-step, the counts for one sentence pair (f ,e) are:",
        "Pr(f, a|e).",
        "For different alignment models different approaches were proposed to estimate the corresponding alignments and parameters.",
        "The details can be found in (Och et al., 2003; Brown et al.,",
        "1993).",
        "After estimating the statistical translation probabilities, we treat the information need prediction as the process of ranking words by p(w|Q), the probability of generating word w from question Q:",
        "The word-to-word translation probability Ptr(w^) is the probability of word w is translated from a word t in question Q using the translation model.",
        "The above formula uses linear interpolation smoothing of the document model with the background language model P(t|C).",
        "X is the smoothing parameter.",
        "P(t|Q) and P(t|C) are estimated using the maximum likelihood estimator.",
        "One important consideration is that statistical machine translation models first estimate Pr (f|e) and then calculate Pr(e|f) using Bayes' theorem to minimize ordering errors (Brown et al., 1993):",
        "But in this paper, we skip this step as we found out the order of words in information need part is not an important factor.",
        "In our collected CQA archive, question title and information need pairs can be considered as a type of parallel corpus, which is used for estimating word-to-word translation probabilities.",
        "More specifically, we estimated the IBM-4 model by GIZA++ with the question part as the source language and information need part as the target language.",
        "In the M-step, lexicon parameters become:",
        "Different alignment models such as IBM-1 to IBM-5 (Brown et al., 1993) and HMM model (Och and Ney, 2000) provide different decompositions of"
      ]
    },
    {
      "heading": "5. Experiments and Results 5.1 Text Preprocessing",
      "text": [
        "The questions posted on community QA sites often contain spelling or grammar errors.",
        "These errors influence the calculation of similarity and the performance of information retrieval (Zhao et al., 2007; Bunescu and Huang, 2010).",
        "In this paper, we use an open source software afterthedeadline to automatically correct the spelling errors in the question and information need texts first.",
        "We also made use of Web 1T 5-gram to implement an N-Gram based method (Cheng et al., 2008) to further filter out the false positive corrections and re-rank correction suggestions (Mudge, 2010).",
        "The texts are tagged by Brill's Part-of-Speech Tagger as the rule-based tagger is more robust than the state-of-art statistical taggers for raw web contents.",
        "This tagging information is only used for WordNet similarity calculation.",
        "Stop word removal and lemmatization are applied to the all the raw texts before feeding into machine translation model training, the LDA model estimating and similarity calculation.",
        "We made use of the questions crawled from Yahoo!",
        "Answers for the estimating models and evaluation.",
        "More specifically, we obtained 2 million questions under two categories at Yahoo!",
        "Answers: 'travel' (1 million), and 'computers&internet' (1 million).",
        "Depending on whether the best answers have been chosen by the asker, questions from Yahoo!",
        "answers can be divided into 'resolved' and 'unresolved' categories.",
        "From each of the above two categories, we randomly selected 200 resolved questions to construct two testing data sets: 'Test_t' ('travel'), and 'Test_c' ('computers&internet').",
        "In order to measure the information need similarity in our experiment we selected only those questions whose information needs part contained at least 3 informative words after stop word removal.",
        "The rest of the questions 'Train_t' and 'Train_c' under the two categories are left for estimating the LDA topic models and the translation models.",
        "We will show how we obtain these models later.",
        "For each question (query question) in 'Test_t' or 'Test_c', we used the words in the question title part as the main search query and the other words in the information need part as search query expansion to retrieve candidate recommended questions from Yahoo!",
        "Answers website.",
        "We obtained an average of 154 resolved questions under 'travel' or 'computer-s&internet' category, and three assessors were involved in the manual judgments.",
        "Given a question returned by a recommendation method, two assessors are asked to label it with 'good' or 'bad'.",
        "The third assessor will judge the conflicts.",
        "The assessors are also asked to read the information need and answer parts.",
        "If a recommended question is considered to express the same or similar information need, the assessor will label it 'good'; otherwise, the assessor will label it as 'bad'.",
        "Test_c",
        "Test_t",
        "Methods",
        "MRR",
        "Precision@5",
        "Precision@10",
        "MRR",
        "Precision@5",
        "Precision@10",
        "TFIDF",
        "84.2%",
        "67.1%",
        "61.9%",
        "92.8%",
        "74.8%",
        "63.3%",
        "Knowledge1",
        "82.2%",
        "65.0%",
        "65.6%",
        "78.1%",
        "67.0%",
        "69.6%",
        "Knowledge2",
        "76.7%",
        "54.9%",
        "59.3%",
        "61.6%",
        "53.3%",
        "58.2%",
        "LDA1",
        "92.5%",
        "68.8%",
        "64.7%",
        "91.8%",
        "75.4%",
        "69.8%",
        "LDA2",
        "61.5%",
        "55.3%",
        "60.2%",
        "52.1%",
        "57.4%",
        "54.5%",
        "Table 2: Question recommendation results without information need prediction",
        "Test_c",
        "Test_t",
        "Methods",
        "MRR",
        "Precision@5",
        "Precision@10",
        "MRR",
        "Precision@5",
        "Precision@10",
        "TFIDF",
        "86.2%",
        "70.8%",
        "64.3%",
        "95.1%",
        "77.8%",
        "69.3%",
        "Knowledge1",
        "82.2%",
        "65.0%",
        "66.6%",
        "76.7%",
        "68.0%",
        "68.7%",
        "Knowledge2",
        "76.7%",
        "54.9%",
        "60.2%",
        "61.6%",
        "53.3%",
        "58.2%",
        "LDA1",
        "95.8%",
        "72.4%",
        "68.2%",
        "96.2%",
        "79.5%",
        "69.2%",
        "LDA2",
        "61.5%",
        "55.3%",
        "58.9%",
        "68.1%",
        "58.3%",
        "53.9%",
        "Three measures for evaluating the recommendation performance are utilized.",
        "They are Mean Reciprocal Rank (MRR), top five prediction accuracy (precision@5) and top ten prediction accuracies (precision@10) (Voorhees and Tice, 2004; Cao et al., 2008).",
        "In MRR the reciprocal rank of a query question is the multiplicative inverse of the rank of the first 'good' recommended question.",
        "The top five prediction accuracy for a query question is the number of 'good' recommended questions out of the top five ranked questions and the top ten accuracy is calculated out of the top ten ranked questions.",
        "The first experiment conducted question recommendation based on their information need parts.",
        "Different text similarity methods described in section 3 were used to measure the similarity between the information need texts.",
        "In TFIDF similarity measure (TFIDF), the idf values for each word were computed from frequency counts over the entire Aquaint corpus.",
        "For calculating the word-to-word knowledge-based similarity, a WordNet::Similarity Java implementation of the similarity measures lin (Knowledge2) and jcn (Knowledge1) is used in this paper.",
        "For calculating topic model based similarity, we estimated two LDA models from 'Train_t' and 'Train_c' using GibbsLDA++.",
        "We treated each question including the question title and the information need part as a single document of a sequence of words.",
        "These documents were preprocessed before being fed into LDA model.",
        "1800 iterations for Gibbs sampling 200 topics parameters were set for each LDA model estimation.",
        "The results in table 2 show that TFIDF and LDA1 methods perform better for recommending questions than the others.",
        "After further analysis of the questions recommended by both methods, we discovered that the ordering of the recommended questions from TFIDF and LDA1 are quite different.",
        "TFIDF similarity method prefers texts with more common words, while the LDA1 method can find the relation between the non-common words between short texts based on a series of third-party topics.",
        "The L-DA1 method outperforms the TFIDF method in two ways: (1) the top recommended questions' information needs share less common words with the query question's; (2) the top recommended questions span wider topics.",
        "The questions highly recommended by LDA1 can suggest more useful topics to the user.",
        "Q1:",
        "If I want a faster computer should I buy more memory or storage space?",
        "InfoN",
        "If I want a faster computer should I buy more memory or storage space?",
        "What-s the difference?",
        "I edit pictures and videos so I need them to work quickly.",
        "RQ1",
        "Would buying 1gb memory upgrade make my computer faster?",
        "InfoN",
        "I have an inspiron B130.",
        "It has 512mb memory now.",
        "I would add another 1gb into 2nd slot...",
        "RQ2",
        "whats the difference between memory and hard drive space on a computer and why is.....?",
        "InfoN",
        "see I am starting edit videos on my computer but i am running out of space.",
        "why is so expensive to buy memory but not external drives?",
        "...",
        "Q2:",
        "Where should my family go for spring break?",
        "InfoN",
        "... family wants to go somewhere for a couple days during spring break ... prefers a warmer climate and we live in IL, so it shouldn't be SUPER far away.",
        "... a family road trip.",
        "...",
        "RQ1",
        "Whats a cheap travel destination for spring break?",
        "InfoN",
        "I live in houston texas and i'm trying to find i inexpensive place to go for spring break with my family.My parents don't want to spend a lot of money due to the economy crisis,... a fun road trip...",
        "RQ2",
        "Alright you creative deal-seekers, I need some help in planning a spring break trip for my family",
        "InfoN",
        "Spring break starts March 13th and goes until the 21st ... Someplace WARM!!!",
        "Family-oriented hotel/resort ... North American Continent (Mexico, America, Jamaica, Bahamas, etc.)",
        "Cost= Around $5,000...",
        "Knowledge-based methods are also shown to perform worse than TFIDF and LDA1.",
        "We found that some words were mis-tagged so that they were not included in the word-to-word similarity calculation.",
        "Another reason for the worse performance is that the words out of the WordNet dictionary were also not included in the similarity calculation.",
        "The Mean Reciprocal Rank score for TFIDF and LDA1 are more than 80%.",
        "That is to say, we are able to recommend questions to the users by measuring their information needs.",
        "The first two recommended questions for Q1 and Q2 using LDA1 method are shown in table 4.",
        "InfoN is the information need part associated with each question.",
        "In the preprocessing step, some words were successfully corrected such as \"What should I do this saturday?",
        "... and staying in a hotell...\" and \"my faimly is traveling to florda However, there are still a small number of texts such as \"How come my Gforce visualization doesn't work?\"",
        "and \"Do i need an Id to travel from new york to maimi?\"",
        "failed to be corrected.",
        "So in the future, a better method is expected to correct these failure cases.",
        "There are some retrieved questions whose information need parts are empty or become empty or almost empty (one or two words left) after the preprocessing step.",
        "The average number of such retrieved questions for each query question is 10 in our experiment.",
        "The similarity ranking scores of these questions are quite low or zero in the previous experiment.",
        "In this experiment, we will apply information need prediction to the questions whose information needs are missing in order to find out whether we improve the recommendation task.",
        "The question and information need pairs in both 'Train_t' and 'Train_c' training sets were used to train two IBM-4 translation models by GIZA++ toolkit.",
        "These pairs were also preprocessed before training.",
        "And the pairs whose information need part become empty after preprocessing were disregarded.",
        "During the experiment, we found that some ofthe generated words in the information need parts are themselves.",
        "This is caused by the self translation problem in translation model: the highest translation score for a word is usually given to itself if the target and source languages are the same (Xue et al., 2008).",
        "This has always been a tough question: not using self-translated words can reduce retrieval performance as the information need parts need the terms to represent the semantic meanings; using self-translated words does not take advantage of the translation approach.",
        "To tackle this problem, we control the number of the words predicted by the translation model to be exactly twice the number of words in the corresponding preprocessed question.",
        "The predicted information need words for the retrieved questions are shown in Table 5.",
        "In Q1, the information need behind question \"recommend website for custom built computer parts\" may imply that the users need to know some information about building computer parts such as \"ram\" and \"motherboard\" for a different purpose such as \"gaming\".",
        "While in Q2, the user may want to compare computers in different brands such as \"dell\" and \"mac\" or consider the \"price\" factor for \"purchasing a laptop for a college student\".",
        "We also did a small scale comparison between the generated information needs against the real questions whose information need parts are not empty.",
        "Q3 and Q4 in Table 5 are two examples.",
        "The original information need for Q3 is \"looking for beautiful beaches and other things to do such as museums, zoos, shopping, and great seafood \" in CQA.",
        "The generated content for Q3 contains words in wider topics such as ' wedding', ' surf' and the price information ('cheap').",
        "This reflects that there are some other users asking similar questions with the same or other interests.",
        "From the results in Table 3, we can see that the performance of most similarity methods were improved by making use of information need prediction.",
        "Different similarity measures received different degrees of improvement.",
        "LDA1 obtained the highest improvement followed by the TFIDF based method.",
        "These two approaches are more sensitive to the contents generated by a translation model.",
        "However we found out that in some cases the L-DA1 model failed to give higher scores to good recommendation questions.",
        "For example, Q5, Q6, and Q7 in table 5 were retrieved as recommendation candidates for the query question in Table 1.",
        "All of the three questions were good recommendation candidates, but only Q6 ranked fifth while Q5 and Q7 were out of the top 30 by LDA1 method.",
        "Moreover, in a small number of cases bad recommendation questions received higher scores and jeopardized the performance.",
        "For example, for query question \"How can you add subtitles to videos?\"",
        "with information need \"... add subtitles to a music video ... got off youtube ...download for this ...\", a retrieved question \"How would i add a music file to a video clip.",
        "... \" was highly recommended by TFIDF approach as predicted information need contained ' youtube', 'video ', 'music ', 'download ',....",
        "The MRR score received an improvement from 92.5% to 95.8% in the 'Testx' and from 91.8% to 96.2% in 'Test_t'.",
        "This means that the top one question recommended by our methods can be quite well catering to the users information needs.",
        "The top five precision and the top ten precision scores using TFIDF and LDA1 methods also received different degrees of improvement.",
        "Thus, we can improve the performance of question recommendation by predicting information needs."
      ]
    },
    {
      "heading": "6. Conclusions",
      "text": [
        "In this paper we addressed the problem of recommending questions from large archives of community question answering data based on users information needs.",
        "We also utilized a translation model and a LDA topic model to predict the information need only given the user s query question.",
        "Different information need similarity measures were compared to prove that it is possible to satisfy user s information need by recommending questions from large archives of community QA.",
        "The Latent Dirich-let allocation based approach was proved to perform better on measuring the similarity between short texts in the semantic level than traditional methods.",
        "Experiments showed that the proposed translation based language model for question information need prediction further enhanced the performance of question recommendation methods.",
        "Q1:",
        "Please recommend A good website for Custom Built Computer parts?",
        "InfoN",
        "custom, site, ram, recommend, price, motherboard, gaming,...",
        "Q2:",
        "What is the best laptop for a college student?",
        "InfoN",
        "know, brand, laptop, college, buy, price, dell, mac,...",
        "Q3:",
        "What is the best Florida beach for a honeymoon?",
        "InfoN",
        "Florida, beach, honeymoon, wedding, surf, cheap, fun,...",
        "Q4:",
        "Are there any good clubs in Manchester",
        "InfoN",
        "club, bar, Manchester, music, age, fun, drink, dance,...",
        "Q5:",
        "If i buy a video card for my computer will that make it faster?",
        "InfoN",
        "nvidia, video, ati, youtube, card, buy, window, slow, computer, graphics, geforce, faster,...",
        "Q6:",
        "If I buy a bigger hard drive for my laptop, will it make my computer run faster or just increase the memory?",
        "InfoN",
        "laptop, ram, run, buy, bigger, memory, computer, increase, gb, hard, drive, faster,",
        "Q7:",
        "Is there a way I can make my computer work faster rather than just increasing the ram or harware space?",
        "InfoN",
        "space, speed, ram, hardware, main, gig, slow, computer, increase, work, gb, faster,"
      ]
    }
  ]
}
