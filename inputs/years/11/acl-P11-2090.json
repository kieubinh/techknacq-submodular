{
  "info": {
    "authors": [
      "Delip Rao",
      "David Yarowsky"
    ],
    "book": "Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies",
    "id": "acl-P11-2090",
    "title": "Typed Graph Models for Learning Latent Attributes from Names",
    "url": "https://aclweb.org/anthology/P11-2090",
    "year": 2011
  },
  "references": [
    "acl-D08-1061",
    "acl-H05-1066"
  ],
  "sections": [
    {
      "text": [
        "Typed Graph Models for Semi-Supervised Learning of Name Ethnicity",
        "of Computer Science Johns Hopkins University",
        "This paper presents an original approach to semi-supervised learning of personal name ethnicity from typed graphs of morphophonemic features and first/last-name co-occurrence statistics.",
        "We frame this as a general solution to an inference problem over typed graphs where the edges represent labeled relations between features that are parameterized by the edge types.",
        "We propose a framework for parameter estimation on different constructions of typed graphs for this problem using a gradient-free optimization method based on grid search.",
        "Results on both in-domain and out-of-domain data show significant gains over 30% accuracy improvement using the techniques presented in the paper."
      ]
    },
    {
      "heading": "1. Introduction",
      "text": [
        "In the highly relational world of NLP, graphs are a natural way to represent relations and constraints among entities of interest.",
        "Even problems that are not obviously graph based can be effectively and productively encoded as a graph.",
        "Such an encoding will often be comprised of nodes, edges that represent the relation, and weights on the edges that could be a metric or a probability-based value, and type information for the nodes and edges.",
        "Typed graphs are a frequently-used formalism in natural language problems including dependency parsing (McDonald et al., 2005), entity disambiguation (Minkov and Cohen, 2007), and social networks to just mention a few.",
        "In this paper, we consider the problem of identifying a personal attribute such as ethnicity from only an observed first-name/last-name pair.",
        "This has important consequences in targeted advertising and personalization in social networks, and in gathering intelligence for business and government research.",
        "We propose a parametrized typed graph framework for this problem and perform the hidden attribute inference using random walks on typed graphs.",
        "We also propose a novel application of a gradient-free optimization technique based on grid search for parameter estimation in typed graphs.",
        "Although, we describe this in the context of person-attribute learning, the techniques are general enough to be applied to various typed graph based problems."
      ]
    },
    {
      "heading": "2. Data for Person-Ethnicity Learning",
      "text": [
        "Name ethnicity detection is a particularly challenging (and practical) problem in Nigeria given that it has more than 250 ethnicities with minor variations.",
        "We constructed a dictionary of Nigerian names and their associated ethnicity by crawling baby name sites and other Nigerian diaspora websites (e.g. onlinenigeria.com) to compile a name dictionary of 1980 names with their ethnicity.",
        "We retained the top 4 ethnicities - Yoruba, Igbo, Efik Ibibio, and Benin Edo.",
        "In addition we also crawled Facebook to identify Nigerians from different communities.",
        "There are more details to this dataset that will be made available with the data itself for future research."
      ]
    },
    {
      "heading": "3. Random Walks on Typed Graphs",
      "text": [
        "Consider a graph G = (V, E), with edge set E defined on the vertices in V. A typed graph is one where every vertex v in V has an associated type tv G Tv.",
        "Analogously, we also use edge types TE ç Tv x Tv.",
        "Some examples of typed edges and vertices used in this paper are shown in Table 1.",
        "These will be elaborated further in Section 4.",
        "Vertices",
        "POSITIONAL_BIGRAM, BIGRAM, TRIGRAM, FIRSTNAME, LAST_NAME,...",
        "POSITION (POSITIONALJBIGRAM – BIGRAM), 32BACKOFF (TRIGRAM – BIGRAM), CONCURRENCE (FIRSTNAME – LAST_NAME),",
        "which correspond to different feature types.",
        "Some of the target nodes can optionally have label information, these are called seed nodes and are excluded from evaluation.",
        "Every feature instance has its own node and an edge exists between a target node and a feature node if the target node instantiates the feature.",
        "Features are not independent.",
        "For example the trigram aba also indicates the presence of the bi-grams ab and ba .",
        "We encode this relationship and the bi-",
        "With every edge type te G TE we associate a real-valued parameter 6 G [0,1].",
        "Thus our graph is parameterized by a set of parameters 6 with |6| = |Te |.",
        "We will need to learn these parameters from the training data; more on this in Section 5.",
        "We relax the estimation problem by forcing the graph to be undirected.",
        "This effectively reduces the number of parameters by half.",
        "We now have a weighted graph with a weight matrix w(6).",
        "The probability transition matrix p(6) for the random walk is derived by noting p(6) = d(6)-1w(6) where d(6) is the diagonal weighted-degree matrix, i.e, du(6) = ^j w%j(6).",
        "From this point on, we rely on standard label-propagation based semi-supervised classification techniques (Zhu et al., 2003; Baluja et al., 2008; Talukdar et al., 2008) that work by spreading probability mass across the edges in the graph.",
        "While traditional label propagation methods proceed by constructing graphs using some kernel or arbitrary similarity measures, our method estimates the appropriate weight matrix from training data using grid search."
      ]
    },
    {
      "heading": "4. Graph construction",
      "text": [
        "Our graphs have two kinds of nodes - nodes we want to classify - called target nodes and feature nodes",
        "First name/Last name (FN_LN) graph",
        "As a first attempt, we only considered first and last names as features generated by a name.",
        "The name we wish to classify is treated as a target node.",
        "There are two typed relations 1) between the first and last name, called CONCURRENCE, where the first and last names occur together and 2) Where an edge, SHAREDJNAME, exists between two first (last) names if they share a last (first) name.",
        "Hence there are only two parameters to estimate here.",
        "Character Ngram graph",
        "The ethnicity of personal names are often indicated by morphophonemic features of the individual's given/first or family/last names.",
        "For example, the last names Polanski, Piotrowski, Soszyn-ski, Sikorski with the suffix I ski I indicate Polish descent.",
        "Instead of writing suffix rules, we generate character n-gram features from names ranging from between features by adding typed edges.",
        "For instance, in the previous case, a typed edge (32BACK-",
        "OFF) is added between the trigram [ gram | ab",
        "I representing the backoff relation.",
        "In the",
        "absence of these edges between features, our graph would have been bipartite.",
        "We experimented with three kinds of graphs for this task:",
        "Figure 2: A part of the character n-gram graph: Observe how the suffix | osun | contributes to the inference of adeosun as a Yoruba name even though it was never seen in training.",
        "The different colors on the edges represent edge types whose weights are estimated from the data.",
        "bigrams to 5-grams and all orders in-between.",
        "We further distinguish n-grams that appear in the beginning (corresponding to prefixes), middle, and end (corresponding to suffixes).",
        "Thus the last name, mosun in the graph is connected to the follow",
        "mos-BEG , osu-MID",
        "a 32BACKOFF edge.",
        "The resulting graph has four typed relations - 32BACKOFF, 43BACKOFF, 45BACKOFF, and POSITION - and four corresponding parameters to be estimated.",
        "Combined graph",
        "Finally, we consider the union of the character n-gram graph and the FirstName-LastName graph.",
        "Table 2 lists some summary statistics for the various graphs."
      ]
    },
    {
      "heading": "5. Grid Search for Parameter Estimation",
      "text": [
        "The typed graph we constructed in the previous section has as many parameters as the number of edge types, i.e, |6| = |Te|.",
        "We further constrain the values taken by the parameters to be in the range [0, 1].",
        "Note that there is no loss of representation in doing so, as arbitrary real-valued weights on edges can be normalized to the range [0, 1].",
        "Our objective is to find a set of values for 6 that maximizes the classification accuracy.",
        "Towards that effect, we quantize the range [0,1] into k equally sized bins and convert this to a discrete-valued optimization problem.",
        "While this is an approximation, our experience finds that relative values of the various 6j G 6 are more important than the absolute values for label propagation.",
        "The complexity of this search procedure is O(kn) for k bins and n parameters.",
        "For problems with small number of parameters, like ours (n = 4 or n = 2 depending on the graph model), and with fewer bins this search is still tractable although computationally expensive.",
        "We set k = 4; this results in 256 combinations to be searched at most and we evaluate each combination in parallel on a cluster.",
        "Clearly, this exhaustive search works only for problems with few parameters.",
        "However, grid search can still be used in problems with large number of edge types using one of the following two techniques: 1) Randomly sample with replacement from a Dirichlet distribution with same order as the number of bins.",
        "Evaluate using parameter values from each sample on the development set.",
        "Select the parameter values that result in highest accuracy on the development set from a large number of samples.",
        "2) Perform a ing positional trigrams",
        "I besides positional n-grams of other or-",
        "ders.",
        "The positional trigram mos-BEG connected to the position-independent trigram [mos |using the typed edge POSITION.",
        "Further, the trigram | mos | is connected to the bigrams | mo | and | os | using coarse grained search first using a small k on the range [0,1] and use that result to shrink the search range.",
        "Perform grid search again on this smaller range.",
        "We simply search exhaustively given the nature of our problem.",
        "#Vertices",
        "#Edges",
        "Avg.",
        "degree",
        "FN_LN",
        "22.8K",
        "137.2K",
        "3.6",
        "Char.",
        "Ngram",
        "282.6K",
        "1.2M",
        "8.7",
        "Combined",
        "282.6K",
        "1.3M",
        "9.2"
      ]
    },
    {
      "heading": "6. Experiments & Results",
      "text": [
        "We evaluated our three different model variants under two settings: 1) When only a weak prior from the dictionary data is present; we call this 'out-of-domain' since we don't use any labels from Face-book and 2) when both the dictionary prior and some labels from the Facebook data is present; we call this 'in-domain'.",
        "The results are reported using 10-fold cross-validation.",
        "In addition to the proposed typed graph models, we show results from a smoothed-Naive Bayes implementation and two standard baselines 1) where labels are assigned uniformly at random (UNIFORM) and 2) where labels are assigned according the empirical prior distribution (PRIOR).",
        "The baseline accuracies are shown in Table 3.",
        "We performed similar in-domain and out-of-domain experiments for each of the graph models proposed in Section 4 and list the results in Table 4, without using grid search.",
        "Some points to note about the results reported in Table 4: 1) These results were obtained without using parameters from the grid search based optimization.",
        "2) The character n-gram graph model performs better than the first-name/last-name graph model by itself, as expected due to the smoothing induced by the backoff edge types.",
        "3) The combination of firstname/last-name graph and the n-gram improves accuracy by over 30%.",
        "Table 5 reports results from using parameters estimated using grid search.",
        "The parameter estimation was done on a development set that was not used in the 10-fold cross-validation results reported in the table.",
        "Observe that the parameters estimated via grid search always improved performance of label propagation."
      ]
    },
    {
      "heading": "7. Conclusions",
      "text": [
        "We considered the problem of learning a person's ethnicity from his/her name as an inference problem over typed graphs, where the edges represent labeled relations between features that are parameterized by the edge types.",
        "We developed a framework for parameter estimation on different constructions of typed graphs for this problem using a gradientfree optimization method based on grid search.",
        "We also proposed alternatives to scale up grid search for large problem instances.",
        "Our results show a significant performance improvement over the baseline and this performance is further improved by parameter estimation resulting over 30% improvement in accuracy using the conjunction of techniques proposed for the task.",
        "Out-of-domain",
        "In-domain",
        "fn_ln",
        "59.1",
        "61.4",
        "Char.",
        "Ngram",
        "76.7",
        "78.5",
        "Combined",
        "78.6",
        "80.1",
        "Improvements by grid search (c.f., Table 4)",
        "fn_ln",
        "2.6%",
        "2%",
        "Char.",
        "Ngram",
        "4.8%",
        "2.2%",
        "Combined",
        "1.5%",
        "1.7%",
        "Out-of-domain",
        "In-domain",
        "uniform",
        "25.0",
        "25.0",
        "prior",
        "42.6",
        "42.6",
        "Naïve Bayes",
        "75.1",
        "77.2",
        "Out-of-domain",
        "In-domain",
        "fn_ln",
        "57.6",
        "60.2",
        "Char.",
        "Ngram",
        "73.2",
        "76.8",
        "%gain over fn_ln",
        "27%",
        "27.6%",
        "Combined",
        "77.1",
        "78.7",
        "%gain over Char.",
        "Ngram",
        "5.3%",
        "2.5%"
      ]
    }
  ]
}
