{
  "info": {
    "authors": [
      "Smruthi Mukund",
      "Debanjan Ghosh",
      "Rohini K. Srihari"
    ],
    "book": "Proceedings of the Fifteenth Conference on Computational Natural Language Learning",
    "id": "acl-W11-0308",
    "title": "Using Sequence Kernels to identify Opinion Entities in Urdu",
    "url": "https://aclweb.org/anthology/W11-0308",
    "year": 2011
  },
  "references": [
    "acl-C10-2099",
    "acl-H05-1091",
    "acl-I08-2119",
    "acl-J08-2003",
    "acl-L08-1088",
    "acl-N10-1121",
    "acl-P04-1054",
    "acl-W03-0404",
    "acl-W06-0301"
  ],
  "sections": [
    {
      "text": [
        "Smruthi Mukundf and Debanjan Ghosh Rohini K Srihari",
        "SUNY at Buffalo, NY SUNY at Buffalo, NY",
        "Automatic extraction of opinion holders and targets (together referred to as opinion entities) is an important subtask of sentiment analysis.",
        "In this work, we attempt to accurately extract opinion entities from Urdu newswire.",
        "Due to the lack of resources required for training role labelers and dependency parsers (as in English) for Urdu, a more robust approach based on (i) generating candidate word sequences corresponding to opinion entities, and (ii) subsequently disambiguating these sequences as opinion holders or targets is presented.",
        "Detecting the boundaries of such candidate sequences in Urdu is very different than in English since in Urdu, grammatical categories such as tense, gender and case are captured in word inflections.",
        "In this work, we exploit the morphological inflections associated with nouns and verbs to correctly identify sequence boundaries.",
        "Different levels of information that capture context are encoded to train standard linear and sequence kernels.",
        "To this end the best performance obtained for opinion entity detection for Urdu sentiment analysis is 58.06% F-Score using sequence kernels and 61.55% F-Score using a combination of sequence and linear kernels."
      ]
    },
    {
      "heading": "1. Introduction",
      "text": [
        "Performing sentiment analysis on newswire data facilitates the development of systems capable of answering perspective questions like \"How did people react to the latest presidential speech?\"",
        "and \"Does General Musharraf support the Indo-Pak peace treaty?\".",
        "The components involved in developing such systems require accurate identification of opinion expressions and opinion entities.",
        "Several of the approaches proposed in the literature to automatically extract the opinion entities rely on the use of thematic role labels and dependency parsers to provide new lexical features for opinion words (Bethard et al., 2004).",
        "Semantic roles (SRL) also help to mark the semantic constituents (agent, theme, proposition) of a sentence.",
        "Such features are extremely valuable for a task like opinion entity detection.",
        "English is a privileged language when it comes to the availability of resources needed to contribute features for opinion entity detection.",
        "There are other widely spoken, resource poor languages, which are still in the infantile stage of automatic natural language processing (NLP).",
        "Urdu is one such language.",
        "The main objective of our research is to provide a solution for opinion entity detection in the Urdu language.",
        "Despite Urdu lacking NLP resources required to contribute features similar to what works for the English language, the performance of our approach is comparable with English for this task (compared with the work of Weigand and Klalow, 2010 ~ 62.61% F1).",
        "The morphological richness of the Urdu language enables us to extract features based on noun and verb inflections that effectively contribute to the opinion entity extraction task.",
        "Most importantly, these features can be generalized to other Indic languages (Hindi, Bengali etc.)",
        "owing to the grammatical similarity between the languages.",
        "English has seen extensive use of sequence kernels (string and tree kernels) for tasks such as relation extraction (Culotta and Sorensen, 2004) and semantic role labeling (Moschitti et al., 2008).",
        "But, the application of these kernels to a task like opinion entity detection is scarcely explored (Weigand and Klalow, 2010).",
        "Moreover, existing works in English perform only opinion holder identification using these kernels.",
        "What makes our approach unique is that we use the power of sequence kernels to simultaneously identify opinion holders and targets in the Urdu language.",
        "Sequence kernels allow efficient use of the learning algorithm exploiting massive number of features without the traditional explicit feature representation (such as, Bag of Words).",
        "Often, in case of sequence kernels, the challenge lies in choosing meaningful subsequences as training samples instead of utilizing the whole sequence.",
        "In Urdu newswire data, generating candidate sequences usable for training is complicated.",
        "Not only are the opinion entities diverse in that they can be contained within noun phrases or clauses, the clues that help to identify these components can be contained within any word group - speech events, opinion words, predicates and connectors.",
        "Pakistan ke swaat sarhad ke janoobi shahar Banno ka havayi adda zarayye ablaagk tavvju ka markaz ban gaya hai.",
        "[Pakistan's provincial border's south city's airbase has become the center of attraction for all reporters.]",
        "Here, the opinion target spans across four noun chunks, \"Pakistan's | provincial border's | south city's | airbase\".",
        "The case markers (connectors) \"ke\"and\"ka\" indicate the span._ Habib miyan ka ghussa bad gaya aur wo apne aurat ko maara.",
        "[Habib miya's anger increased and he hit his own wife.]",
        "Here, the gender (Masculine) inflection of the verb \"maara\" (hit) indicates that the agent performing this action is \"Habib miya\" (Masculine)_ Ansari ne kaha \"mere rayee mein Aamir Sohail eek badimaak aur Ziddi insaan hai\".",
        "[Ansari said, \"according to me Aamir Sohail is one crazy and stubborn man\"]",
        "Here, cues similar to English such as \"mere rayee mein \" (according to) indicate the opinion holder.",
        "Another interesting behavior here is the presence of nested opinion holders.",
        "\"kaha\" (said) indicates that this statement was made by Ansari only.",
        "Sutlan bahut khush tha, naseer key kaam se.",
        "[Sultan was very happy with Naseer's work]",
        "Here, the target of the expression \"khush\" is after the verb \"khush tha\"(was happy) - SVO structure_",
        "Another contributing factor is the free word order of the Urdu language.",
        "Although the accepted form is SOV, there are several instances where the object comes after the verb or the object is before the subject.",
        "In Urdu newswire data, the average number of words in a sentence is 42 (Table 3).",
        "This generates a large number of candidate sequences that are not opinion entities, on account of which the data used for training is highly unbalanced.",
        "The lack of tools such as dependency parsers makes boundary detection for Urdu different from English, which in turn makes opinion entity extraction a much harder task.",
        "Examples shown in table 1 illustrate the complexity of the task.",
        "One safe assumption that can be made for opinion entities is that they are always contained in a phrase (or clause) that contains a noun (common noun, proper noun or pronoun), which is either the subject or the object of the predicate.",
        "Based on this, we generate candidate sequences by considering contextual information around noun phrases.",
        "In example 1 of Table 1, the subsequence that is generated will consider all four noun phrases \"Pakistan's | provincial border's | south city's | airbase\" as a single group for opinion entity.",
        "We demonstrate that investigating postpositions to capture semantic relations between nouns and predicates is crucial in opinion entity identification.",
        "Our approach shows encouraging performance.",
        "Related Work",
        "Choi et al., (2005) consider opinion entity identification as an information extraction task and the opinion holders are identified using a conditional random field (Lafferty et al., 2001) based sequence-labeling approach.",
        "Patterns are extracted using AutoSlog (Riloff et al., 2003).",
        "Bloom et al., (2006) use hand built lexicons for opinion entity identification.",
        "Their method is dependent on a combination of heuristic shallow parsing and dependency parsing information.",
        "Kim and Hovy (2006) map the semantic frames of FrameNet (Baker et al., 1998) into opinion holder and target for adjectives and verbs to identify these components.",
        "Stoyanov and Cardie (2008) treat the task of identifying opinion holders and targets as a co-reference resolution problem.",
        "Kim et al., (2008) used a set of communication words, appraisal words from Senti-WordNet (Esuli and Sebastiani, 2006) and NLP tools such as NE taggers and syntactic parsers to identify opinion holders accurately.",
        "Kim and Hovy (2006) use structural features of the language to identify opinion entities.",
        "Their technique is based on syntactic path and dependency features along with heuristic features such as topic words and named entities.",
        "Weigand and Klalow (2010) use convolution kernels that use predicate argument structure and parse trees.",
        "For Urdu specifically, work in the area of classifying subjective and objective sentences is attempted by Mukund and Srihari, (2010) using a vector space model.",
        "NLP tools that include POS taggers, shallow parser, NE tagger and morphological analyzer for Urdu is provided by Mukund et al., (2010).",
        "This is the only extensive work done for automating Urdu NLP, although other efforts to generate semantic role labels and dependency parsers are underway."
      ]
    },
    {
      "heading": "3. Linguistic Analysis for Opinion Entities",
      "text": [
        "In this section we introduce the different cues used to capture the contextual information for creating candidate sequences in Urdu by exploiting the morphological richness of the language.",
        "Urdu is a head final language with postpositional case markers.",
        "Some postpositions are associated with grammatical functions and some with specific roles associated with the meaning of verbs (Davison, 1999).",
        "Case markers play a very important role in determining the case inflections of nouns.",
        "The case inflections that are useful in the context of opinion entity detection are \"ergative\", \"dative\", \"genitive\", \"instrumental\" and \"locative\" .",
        "Table 2 outlines the constructs.",
        "Consider example 1 below.",
        "(a) is a case where \"Ali\" is nominative.",
        "However, in (b) \"Ali\" is dative.",
        "The case marker \"ko\" helps to identify subjects of certain experiential and psychological predicates: sensations, psychological or mental states and obligation or compulsion.",
        "Such predicates clearly require the subject to be sentient, and further, indicate that they are affected in some manner, correlating with the semantic properties ascribed to the dative's primary use (Grimm, 2007).",
        "(a) Ali khush hua (Ali became happy)",
        "(b) Ali ko khushi hui (Ali became happy) Example (2):",
        "(a) Sadaf kaam karne ki koshish karti hai (Sadaf tries to do work)",
        "Semantic information in Urdu is encoded in a way that is very different from English.",
        "Aspect, tense and gender depend on the noun that a verb governs.",
        "Example 2 shows the dependency that verbs have on nouns without addressing the linguistic details associated with complex predicates.",
        "In example 2, the verb \"karti\"(do) is feminine and the noun it governs ~Sadaf is also feminine.",
        "The doer for the predicate \"karti hai\"(does) is \"Sadaf\" and there exists a gender match.",
        "This shows that we can obtain strong features if we are able to accurately (i) identify the predicates, (ii) find the governing noun, and (iii) determine the gender.",
        "In this work, for the purpose of generating candidate sequences, we encompass the post-position responsible for case inflection in nouns, into the noun phrase and group the entire chunk as one single candidate.",
        "In example 1, the dative inflection on 'Ali' is due to the case marker 'ko'.",
        "Here, 'Ali ko' will always be considered together in all candidate sequences that this sentence generates.",
        "This behavior can also be observed in example 1 of table 1.",
        "Case",
        "Clitic Form",
        "Examples",
        "Ergative",
        "(ne)",
        "Ali ne ghussa dikhaya ~ Ali showed anger",
        "Accusative",
        "(ko)",
        "Ali ko mainey maara ~ I hit Ali",
        "Dative",
        "(ko,ke)",
        "Similar to accusative",
        "Instrumental",
        "(se)",
        "Yeh kaam Ali se hua ~ This work was done by",
        "Ali",
        "Genitive",
        "(ka, ke, ki)",
        "Ali ka ghussa, baap re baap!",
        "~ Ali's anger, oh my God!",
        "Locative",
        "(mein, par, tak, tale, talak)",
        "Ali mein ghussa zyaada hai ~ there is a lot of anger in Ali",
        "We use Semantex™ (Srihari et al., 2008) - an end to end NLP framework for Urdu that provides POS, NE, shallow parser and morphological analyzer, to mark tense, mood, aspect, gender and number inflections of verbs and case inflections of nouns.",
        "For ease of parsing, we enclose dative and accusative inflected nouns and the respective case markers in a tag called POSSESS.",
        "We also enclose locative, genitive and ergative inflections and case markers in a tag called DOER."
      ]
    },
    {
      "heading": "4. Methodology",
      "text": [
        "Sequence boundaries are first constructed based on the POSSESS, DOER and NP (noun chunk) tags prioritized by the position of the tag while parsing.",
        "We refer to these chunks as \"candidates\" as they are the possible opinion entity candidates.",
        "We generate candidate sequences by combining these candidates with opinion expressions (Mu-kund and Srihari, 2010) and the predicates that contain or follow the expression words (~khushi in (b) of example 1 above).",
        "We evaluate our approach in two steps:",
        "(i) Boundary Detection - detecting opinion entities that contain both holders and targets",
        "(ii) Entity Disambiguation - disambiguating opinion holders from opinion targets",
        "In the following sections, we briefly describe our research methodology including sequence creation, choice of kernels and the challenges thus encountered.",
        "The data used for the experiments are newswire articles from BBC Urdu that are manually annotated to reflect opinion holders, targets, and expressions (emotion bearing words).",
        "Table 3 summarizes the corpus statistics.",
        "The inter annotator agreement established between two annotators over 30 documents was found to be 0.85 using Cohen's Kappa score (averaged over all tags).",
        "The agreement is acceptable as tagging emotions is a difficult and a personalized task.",
        "SVMs belong to a class of supervised machine learning techniques that merge the nuances of statistical learning theory, kernel mapping and optimization techniques to discover separating hyperplanes.",
        "Given a set of positive and negative data points, based on structural risk minimization, SVMs attempt to find not only a separating hyperplane that separates two categories (Vapnik and Kotz, 2006) but also maximize the boundary between them (maximal margin separation technique).",
        "In this work, we propose to use a variation of sequence kernels for opinion entity detection.",
        "The lack of parsers that capture dependencies in Urdu sentences inhibit the use of 'tree kernels' (Weigand and Klalow, 2010).",
        "In this work, we exploit the power of a set of sequence kernels known as 'gap sequence string kernels' (Lodhi et al., 2002).",
        "These kernels provide numerical comparison of phrases as entire sequences rather than a probability at the chunk level.",
        "Gap sequence kernels measure the similarity between two sequences (in this case a sequence of Urdu words) by counting the number of common subsequences.",
        "Gaps between words are penalized with suitable use of decay factor (A;0 < A < 1) to compensate for matches between lengthy word sequences.",
        "Formally, let 2;.",
        "be the feature space over words.",
        "Consequently, we declare other disjoint feature spaces 2J.,2i...2/ (stem words, POS, chunks, gender inflections, etc.)",
        "and 2^ = 2; x2 .",
        "x2Ä:...2, For any two-feature vectors s,tE.2x let f(s,t) compute the number of common features between s and t. Table 5 lists the features used to compute f(s,t) .",
        "Given two sequences, s and t and the kernel function Kes(s,t,X) that calculates the number of weighted sparse subsequences of length n (say, n=2: bigram) common to both s and t, then Kes(s,t,X) is as shown in eq 1 (Bunescu and",
        "Number of subjective sentences",
        "824",
        "Average word length of each sentence",
        "42",
        "Number of opinion holders",
        "974",
        "Number of opinion targets",
        "833",
        "Number of opinion expressions",
        "894",
        "Table 3: Corpus Statistics",
        "www.bbc.co.uk/urdu/",
        "Mooney, 2005).",
        "(i,j,k are dimensions) ......Eq 1.",
        "Generating correct sequences is a prior requirement for sequence kernels.",
        "For example, in the task of relation extraction, features included in the shortest path between the mentions of the two sequences (which hold the relation) play a decisive role (Bunescu and Mooney, 2005).",
        "Similarly, in the task of role labeling (SRL - Moschitti et al., 2008), syntactic sub-trees containing the arguments are crucial in finding the correct associations.",
        "Our approach to create candidate sequences for opinion entity detection in Urdu is explained in the next section.",
        "Candidate Sequence Generation",
        "Each subjective sentence in Urdu contains several noun phrases with one or more opinion expressions.",
        "The words that express opinions (expression words) can be contained within a verb predicate (if the predicate is complex) or precede the verb predicate.",
        "These subjective sentences are first preprocessed to mark the morphological inflections as mentioned in §3.",
        "A sentence is parsed to extract all likely candidate chunks - POSSESS, DOER, NP in that order.",
        "<expression, predicate> tuples are first selected based on nearest neighbor rule :",
        "1.",
        "Predicates that are paired with the expression words either contain the expressions or follow the expressions.",
        "2.",
        "Stand alone predicates are simply ignored as they do not contribute to the holder identification task (they contribute to either the sentence topic or the reason for the emotion).",
        "For each candidate, <candidate, expression, predicate> tuples are generated without changing the word order.",
        "(Fig.",
        "1 - example candidates maintain the same word order)_",
        "We define training candidate sequences as the shortest substring t which is a tuple that contains the candidate noun phrase (POSSESS, DOER or NP), an emotion expression and the closest predicate.",
        "Table 4 outlines the steps taken to create the candidate sequences and figure 1 illustrates the different tuples for a sample sentence.",
        "Experiments conducted by Weigand and Klakow (2010) consider <candidate, predicate> and <candidate, expression> tuples.",
        "However, in Urdu the sense of expression and predicate are so tightly coupled (in many examples they subsume each other and hence inseparable), that specifically trying to gauge the influence of predicate and expression separately on candidates is impossible.",
        "There are three advantages in our approach to creating candidate sequences: (i) by pairing expressions with their nearest predicates, several unnecessary candidate sequences are eliminated, (ii) phrases that do not contain nouns are automatically not considered (see RBP chunk in figure 1), and (iii) by considering only one candidate chunk at a time in generating the candidate sequence, we ensure that the sequence that is generated is short for better sequence kernel performance.",
        "For linear kernels we define features explicitly based on the lexical relationship between the candidate and its context.",
        "Table 5 outlines the features used.",
        "Feature Sets and Description",
        "Set 1 Baseline",
        "1. head word of candidate",
        "2. case marker contained within candidate?",
        "3. expression words",
        "4. head word of predicate",
        "5.",
        "POS sequence of predicate words",
        "6.",
        "# of NPs between candidate and emotion",
        "Set 2",
        "7. the DOER",
        "8. expression right after candidate?",
        "Set 3",
        "9. gender match between candidate and predicate",
        "10. predicate contains emotion words?",
        "Set 4",
        "11.",
        "POS sequence of candidate",
        "Set 5",
        "12.",
        "\"kah\" feature in the predicate",
        "13. locative feature?",
        "14. genitive feature on noun?",
        "Table 5: Linear Kernel Features",
        "Postpositions (te, to) - determine the noun inflections",
        "NNP CM NNP NN CM NNPCM JJ NN",
        "English Translation - Pakistan's provincial border's south city's airbase has become the center of attraction for all reporters (ex.",
        "1 in table 1) Candidate sequence formation: < [Candidate (C,)], [Expression (£)], [Predicate (P)] > [Pakistan ke swaat sarhad ke janoobi shahar Banno ka havayi adda jo] [tawaju ka markaz] [tawaju ka markaz ban gaya hai] ...opinion target",
        "Features commonly used for sequence kernels are based on words (such as character-based or word-based sequence kernels).",
        "In this work, we consider 2;.to be a feature space over Urdu words along with other disjoint features such as POS, gender, case inflections.",
        "In the kernel, however, for each combination (see table 6) the similarity matching function f(s,t) that computes the number of similar features remains the same.",
        "Sequence kernels are robust and can deal with complex structures.",
        "There are several overlapping features between the feature sets used for linear kernel and sequence kernel.",
        "Consider the POS path information feature.",
        "This is an important feature for the linear kernel.",
        "However this feature need not be explicitly mentioned for the sequence kernel as the model internally learns the path information.",
        "In addition, several Boolean features explicitly described for the linear kernel (2 and 13 in table 5) are also learned automatically in the sequence kernel by matching subsequences."
      ]
    },
    {
      "heading": "1.. [ghuzishta daur] [tawaju ka markaz] [ban gaya hai]",
      "text": [
        "2.",
        "[Jangi helicoptaron ki] [tawaju ka markaz] [tawaju ka markaz ban gaya hai] 3.",
        "[taanyati ki vajah se] [tawaju ka markaz] [tawaju ka markaz ban gaya hai]"
      ]
    },
    {
      "heading": "5. Experiments",
      "text": [
        "The data used for our experiments is explained in §4.1.",
        "Figure 2 gives a flow diagram of the entire process.",
        "LIBSVM's (Chang and Lin, 2001) linear kernel is trained using the manually coded features mentioned in table 5.",
        "We integrated our proposed sequence kernel with the same toolkit.",
        "This sequence kernel uses the features mentioned in table 6 and the decay factor A is set to 0.5.",
        "KID",
        "Kernel Type",
        "1",
        "word based kernel (baseline)",
        "2",
        "word + POS (parts of speech)",
        "3",
        "word + POS + chunk",
        "4",
        "word + POS + chunk + gender inflection",
        "The candidate sequence generation algorithm generated 8,329 candidate sequences (contains all opinion holders and targets - table 3) that are used for training both the kernels.",
        "The data is parsed using SemantexTM to apply POS, chunk and morphology information.",
        "Our evaluation is based on the exact candidate boundary (whether the candidate is enclosed in a POSSESS, DOER or NP chunk).All scores are averaged over a 5-fold cross validation set.",
        "Comparison of Kernels",
        "We apply both linear kernels (LK) and sequence kernels (SK) to identify the entities as well as disambiguate between the opinion holders and targets.",
        "Table 7 illustrates the baselines and the best results for boundary detection of opinion entities.",
        "ID 1 of table 7 represents the result of using LK with feature set 1 (table 5).",
        "We interpret this as our baseline result.",
        "The best F1 score for this classifier is 50.17%.",
        "Table 8 compares various kernels and combinations.",
        "Set 1 of table 8 shows the relative effect of feature sets for LK and how each set contributes to detecting opinion entity boundaries.",
        "Although several features are inspired by similar classification techniques (features used for SRL and opinion mining by Choi et al., (2005) ~ set 1, table 5), the free word nature of Urdu language renders these features futile.",
        "Moreover, due to larger average length of each sentence and high occurrences of NPs (candidates) in each sentence, the number of candidate instances (our algorithm creates 10 sequences per sentence on average) is also very high as compared to any English corpus.",
        "This makes the training corpus highly imbalanced.",
        "Interestingly, when features like - occurrence of postpositions, \"kah\" predicate, gender inflections etc.",
        "are used, classification improves (set 1, Feature set 1,2,3,4,5, table 8).",
        "ID 3 of table 7 displays the baseline result for SK.",
        "Interestingly enough, the baseline F1 for SK is very close to the best LK performance.",
        "This shows the robustness of SK and its capability to learn complex substructures with only words.",
        "A sequence kernel considers all possible subsequence matching and therefore implements a concept of partial (fuzzy) matching.",
        "Because of its tendency to learn all fuzzy matches while penalizing the gaps between words intelligently, the performance of SK in general has better recall (Wang, 2008).",
        "To explain the recall situation, consider set 2 of table 8.",
        "This illustrates the effect of disjoint feature scopes of each feature (POS, chunk, gender).",
        "Each feature adds up and expands the feature space of sequence kernel and allows fuzzy matching thereby improving the recall.",
        "Hence KID 4 has almost 20% recall gain over the baseline (SK baseline).",
        "However, in many cases, this fuzzy matching accumulates in wrong classification and lowers precision.",
        "A fairly straightforward approach to overcome this problem is to employ a high precision kernel in addition to sequence kernel.",
        "Another limitation of SK is its inability to capture complex grammatical structure and dependencies making it highly dependent on only the order of the string sequence that is supplied.",
        "Set",
        "Kernel",
        "KID",
        "Prec.",
        "(%)",
        "Rec.",
        "(%)",
        "F1",
        "(%)",
        "Baseline",
        "39.58",
        "51.49",
        "44.75",
        "(Set 1)",
        "Set 1,2",
        "39.91",
        "52.57",
        "45.38",
        "Set 1, 2, 3",
        "43.55",
        "57.72",
        "49.65",
        "1",
        "LK",
        "Set 1,2,3,4",
        "44.10",
        "56.90",
        "49.68",
        "Feature set",
        "44.20",
        "57.99",
        "50.17",
        "1,2,3,4,5",
        "Baseline -",
        "58.22",
        "42.75",
        "49.30",
        "KID 1",
        "2",
        "SK",
        "KID 2",
        "58.98",
        "47.55",
        "52.65",
        "KID 3",
        "58.18",
        "49.62",
        "53.59",
        "KID 4",
        "54.00",
        "62.79",
        "58.06",
        "KID 1 +",
        "51.44",
        "68.89",
        "58.90",
        "best LK",
        "KID 2 +",
        "59.18",
        "62.98",
        "61.02",
        "3",
        "SK +",
        "best LK",
        "LK",
        "KID 3 + best LK",
        "55.18",
        "68.38",
        "61.07",
        "KID 4 +",
        "58.43",
        "65.04",
        "61.55",
        "best LK",
        "I",
        "D",
        "Kernel",
        "Features (table",
        "5/6)",
        "Prec.",
        "(%)",
        "Rec.",
        "(%)",
        "F1",
        "(%)",
        "1",
        "LK",
        "Baseline (Set 1)",
        "39.58",
        "51.49",
        "44.75",
        "2",
        "LK(best)",
        "Set 1, 2, 3, 4, 5",
        "44.20",
        "57.99",
        "50.17",
        "3",
        "SK",
        "Baseline (KID 1)",
        "58.22",
        "42.75",
        "49.30",
        "4",
        "SK (best)",
        "KID 4",
        "54.00",
        "62.79",
        "58.06",
        "5",
        "Best LK",
        "+ best SK",
        "KID 4, Set 1, 2, 3, 4, 5",
        "58.43",
        "65.04",
        "61.55",
        "We also combine the similarity scores of SK and LK to obtain the benefits of both kernels.",
        "This permits SK to expand the feature space by naturally adding structural features (POS, chunk) resulting in high recall.",
        "At the same time, LK with strict features (such as the use of \"kah\" verb) or rigid word orders (several Boolean features) will help maintain acceptable precision.",
        "By summing the contribution of both kernels, we achieve an F1 of 61.55% (Set 3, table 8), which is 17.8%, more (relative gain - around 40%) than the LK baseline results (ID 1, table 7).",
        "Table 9: Opinion entity disambiguation for best features Our next sets of experiments are conducted to disambiguate opinion holders and targets.",
        "A large number of candidate sequences that are created are not candidates for opinion entities.",
        "This results in a huge imbalance in the data set.",
        "Jointly classify opinion holders, opinion targets and false candidates with one model can be attempted if this imbalance in the data set due to false candidates can be reduced.",
        "However, this has not been attempted in this work.",
        "In order to showcase the feasibility of our method, we train our model only on the gold standard candidate sequences that contain opinion entities for entity disambiguation.",
        "The two kernels are applied on just the two classes (opinion holder vs. opinion target).",
        "Combined kernels identify holders with a 65.26% F1 (table 9).",
        "However, LK performs best for target identification (61.23%).",
        "We believe that this is due to opinion holders and targets sharing similar syntactic structures.",
        "Hence, the sequence information that SK learns affects accuracy but improves recall."
      ]
    },
    {
      "heading": "6. Challenges",
      "text": [
        "Based on the error analysis, we observe some common mistakes and provide some examples.",
        "1.",
        "Mistakes resulting due to POS tagger and shallow chunker errors.",
        "2.",
        "Errors due to heuristic rules for morphological analysis.",
        "3.",
        "Mistakes due to inaccurate identification of expression words by the subjectivity classifier.",
        "4.",
        "Errors due to complex and unusual sentence structures which the kernels failed to capture.",
        "Is na-insaafi ka badla hamein zaroor layna chahiye.",
        "[we have to certainly take revenge for this injustice.]",
        "Example (4):",
        "Kya hum dayshadgardi ka shikar banna chahatein hai?",
        "[Do we want to become victims of terrorism?]",
        "Example (5):",
        "Jab secretary kisi aur say baat karke husthi hai, tho Pinto ko ghussa aata hai.",
        "[When the secretary talks to someone and laughs, Pinto gets angry.]",
        "Example 3 is a false positive.",
        "The emotion is \"anger\", indicated by \"na-insaafi ka badla\" (revenge for injustice) and \"zaroor\" (certainly).",
        "But only the second expression word is identified accurately.",
        "The sequence kernel model determines na-insaafi (injustice) to be the opinion holder when it is actually the reason for the emotion.",
        "However, it also identifies the correct opinion holder - hamein (we).",
        "Emotions associated with interrogative sentences are not marked (example 4) as there exists no one word that captures the overall emotion.",
        "However, the subjectivity classifier identifies such sentences as subjective candidates.",
        "This results in false negatives for opinion entity detection.",
        "The target (secretary) in example 5, fails to be detected as no candidate sequence that we generate indicates the noun \"secretary\" to be the target.",
        "We propose to address these issues in our future work."
      ]
    },
    {
      "heading": "7. Conclusion",
      "text": [
        "We describe an approach to identify opinion entities in Urdu using a combination of kernels.",
        "To the best of our knowledge this is the first attempt where such an approach is used to identify opinion entities in a language lacking the availability of resources for automatic text processing.",
        "The performance for this task for Urdu is equivalent to the state of the art performance for English (Weigand and Klakow, 2010) on the same task.",
        "Kernel",
        "Opinion",
        "Prec.",
        "Rec.",
        "F1",
        "Entity",
        "(%)",
        "(%)",
        "(%)",
        "LK",
        "Holder",
        "58.71",
        "66.67",
        "62.44",
        "(best)",
        "Target",
        "65.53",
        "57.48",
        "61.23",
        "SK",
        "Holder",
        "60.26",
        "69.46",
        "64.54",
        "Target",
        "59.75",
        "49.73",
        "54.28",
        "Both",
        "Holder",
        "62.90",
        "69.81",
        "65.26",
        "kernels",
        "Target",
        "60.71",
        "55.44",
        "57.96"
      ]
    }
  ]
}
