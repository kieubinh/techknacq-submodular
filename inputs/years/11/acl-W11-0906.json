{
  "info": {
    "authors": [
      "Jinho D. Choi",
      "Martha Palmer"
    ],
    "book": "Proceedings of the ACL 2011 Workshop on Relational Models of Semantics",
    "id": "acl-W11-0906",
    "title": "Transition-based Semantic Role Labeling Using Predicate Argument Clustering",
    "url": "https://aclweb.org/anthology/W11-0906",
    "year": 2011
  },
  "references": [
    "acl-C10-1081",
    "acl-D07-1002",
    "acl-D08-1008",
    "acl-D08-1059",
    "acl-D09-1004",
    "acl-E06-1011",
    "acl-J02-3001",
    "acl-J05-1004",
    "acl-J08-2006",
    "acl-J08-4003",
    "acl-P10-1110",
    "acl-P11-2121",
    "acl-W04-3212",
    "acl-W05-0620",
    "acl-W08-2122",
    "acl-W09-1201",
    "acl-W10-1811"
  ],
  "sections": [
    {
      "text": [
        "This paper suggests two ways of improving semantic role labeling (SRL).",
        "First, we introduce a novel transition-based SRL algorithm that gives a quite different approach to SRL.",
        "Our algorithm is inspired by shift-reduce parsing and brings the advantages of the transition-based approach to SRL.",
        "Second, we present a self-learning clustering technique that effectively improves labeling accuracy in the test domain.",
        "For better generalization of the statistical models, we cluster verb predicates by comparing their predicate argument structures and apply the clustering information to the final labeling decisions.",
        "All approaches are evaluated on the CoNLL'09 English data.",
        "The new algorithm shows comparable results to another state-of-the-art system.",
        "The clustering technique improves labeling accuracy for both in-domain and out-of-domain tasks."
      ]
    },
    {
      "heading": "1. Introduction",
      "text": [
        "Semantic role labeling (srl) has sparked much interest in nlp (Shen and Lapata, 2007; Liu and Gildea, 2010).",
        "Lately, dependency-based srl has shown advantages over constituent-based srl (Johansson and Nugues, 2008).",
        "Two main benefits can be found.",
        "First, dependency parsing is much faster than constituent parsing, whereas constituent parsing is usually considered to be a bottleneck to srl in terms of execution time.",
        "Second, dependency structure is more similar to predicate argument structure than phrase structure because it specifically defines relations between a predicate and its arguments with labeled arcs.",
        "Unlike constituent-based srl that maps phrases to semantic roles, dependency-based srl maps headwords to semantic roles because there is no phrasal node in dependency structure.",
        "This may lead to a concern about getting the actual semantic chunks back, but Choi and palmer (2010) have shown that it is possible to recover the original chunks from the headwords with minimal loss, using a certain type of dependency structure.",
        "Traditionally, either constituent or dependency-based, semantic role labeling is done in two steps, argument identification and classification (Gildea and Jurafsky, 2002).",
        "This is from a general belief that each step requires a different set of features (Xue and Palmer, 2004), and training these steps in a pipeline takes less time than training them as a joint-inference task.",
        "However, recent machine learning algorithms can deal with large scale vector spaces without taking too much training time (Hsieh et al., 2008).",
        "Furthermore, from our experience in dependency parsing, handling these steps together improves accuracy in identification as well as classification (unlabeled and labeled attachment scores in dependency parsing).",
        "This motivates the development of a new semantic role labeling algorithm that treats these two steps as a joint inference task.",
        "Our algorithm is inspired by shift-reduce parsing (Nivre, 2008).",
        "The algorithm uses several transitions to identify predicates and their arguments with semantic roles.",
        "One big advantage of the transition-based approach is that it can use previously identified arguments as features to predict the next argument.",
        "We apply this technique to our approach and achieve comparable results to another state-of-the-art system evaluated on the same data sets.",
        "Table 1: Transitions in our bidirectional top-down search algorithm.",
        "For each row, the first line shows a transition and the second line shows preconditions of the transition.",
        "For better generalization of the statistical models, we apply a self-learning clustering technique.",
        "We first cluster predicates in test data using automatically generated predicate argument structures, then cluster predicates in training data by using the previously found clusters as seeds.",
        "Our experiments show that this technique improves labeling accuracy for both in-domain and out-of-domain tasks."
      ]
    },
    {
      "heading": "2. Transition-based semantic role labeling",
      "text": [
        "Dependency-based semantic role labeling can be viewed as a special kind of dependency parsing in the sense that both try to find relations between word pairs.",
        "However, they are distinguished in two major ways.",
        "First, unlike dependency parsing that tries to find some kind of relation between any word pair, semantic role labeling restricts its search only to top-down relations between predicate and argument pairs.",
        "Second, dependency parsing requires one head for each word, so the final output is a tree, whereas semantic role labeling allows multiple predicates for each argument.",
        "Thus, not all dependency parsing algorithms, such as a maximum spanning tree algorithm (Mcdonald and Pereira, 2006), can be naively applied to semantic role labeling.",
        "Some transition-based dependency parsing algorithms have been adapted to semantic role labeling and shown good results (Henderson et al., 2008; Titov et al., 2009).",
        "However, these algorithms are originally designed for dependency parsing, so are not necessarily customized for semantic role labeling.",
        "Here, we present a novel transition-based algorithm dedicated to semantic role labeling.",
        "The key difference between this algorithm and most other transition-based algorithms is in its directionality.",
        "Given an identified predicate, this algorithm tries to find top-down relations between the predicate and the words on both left and right-hand sides, whereas other transition-based algorithms would consider words on either the left or the right-hand side, but not both.",
        "This bidirectional top-down search makes more sense for semantic role labeling because predicates are always assumed to be the heads of their arguments, an assumption that cannot be generalized to dependency parsing, and arguments can appear either side of the predicate.",
        "Table 1 shows transitions used in our algorithm.",
        "All parsing states are represented as tuples (Ai , A2, p, A3, A4, A), where Ai..4 are lists of word indices and p is either a word index of the current predicate candidate or $ indicating no predicate candidate.",
        "Ai;4 contain indices to be compared withp and A2;3 contain indices already compared with p. A is a set of labeled arcs representing previously identified arguments with respect to their predicates.",
        " – and f indicate parsing directions.",
        "L is a semantic role label, and i, j represent indices of their corresponding word tokens.",
        "The initial state is ([ ], [ ], 1, [ ], [2,..., n], 0), where wi and wn are the first and the last words in a sentence, respectively.",
        "The final state is (Ai, A2, $,[],[ ], A), i.e., the algorithm terminates when there is no more predicate candidate left.",
        "No-Pred",
        "( Ai , A2, j, A3, [i|A4], A ) ( [Ai|j], A2, i, A3, A4 , A ) 3j.",
        "oracle (j ) = predicate",
        "Shift",
        "( Ai , A2, j, [i|A3], A4, A ) ( [A2|j], [ ] , i, [ ] , A3, A ) 3j.",
        "oracle (j ) = predicate A A1 = [ ] A A4 = [ ]",
        "No-Arc^",
        "( [Ai|i], A2, j, A3, A4, A ) ( Ai, [i|A2], j, A3, A4, A ) 3j.",
        "oracle(j) = predicate A 3i.oracle(i, j) = {i – j}",
        "No-Arc^",
        "( Ai, A2, j, A3 , [i|A4], A ) ( Ai, A2, j, [A3|i], A4 , A ) 3j.",
        "oracle(j) = predicate A 3i.oracle(i, j) = {j f i}",
        "Left-ArcL\"",
        "( [Ai|i], A2 , j, A3, A4, A ) ( Ai , [i|A2], j, A3, A4, A U {i – j} ) 3j.",
        "oracle(j) = predicate A 3i.oracle(i, j) = {i – j}",
        "RlGHT-ARCjL*",
        "( Ai, A2, j, A3, [i|A4], A ) ( Ai, A2, j, [A3|i], A4 , A u {j f i} ) 3j.",
        "oracle(j) = predicate A 3i.oracle(i, j) = {j f i}",
        "Figure 1: An example of a dependency tree with semantic roles.",
        "The upper and lower arcs stand for syntactic and semantic dependencies, respectively.",
        "SBJ, OBJ, oprd, im, nmod stand for a subject, object, object predicative, infinitive marker, and noun-modifier.",
        "A0, A1 stand for ARG0, ARG1 in PropBank (Palmer et al., 2005).",
        "The algorithm uses six kinds of transitions.",
        "No-Pred is performed when an oracle identifies Wj as not a predicate.",
        "All other transitions are performed when Wj is identified as a predicate.",
        "Shift is performed when both Ai and A4 are empty, meaning that there are no more argument candidates left for the predicate Wj.",
        "No-Arc is performed when is identified as not an argument of Wj.",
        "Left-ArCl and Right-ArCl are performed when is identified as an argument of Wj with a label L. These transitions can be performed in any order as long as their preconditions are satisfied.",
        "For our experiments, we use the following generalized sequence:",
        "Notice that this algorithm does not take separate steps for argument identification and classification.",
        "By adding the NO-ARC transitions, we successfully merge these two steps together without decrease in labeling accuracy.",
        "Since each word can be a predicate candidate and each predicate considers all other words as argument candidates, a worst-case complexity of the algorithm is O(n ).",
        "To reduce the complexity, Zhao et al.",
        "(2009) reformulated a pruning algorithm introduced by Xue and Palmer (2004) for dependency structure by considering only direct dependents of a predicate and its ancestors as argument candidates.",
        "This pruning algorithm can be easily applied to our algorithm: the oracle can pre-filter such dependents and uses the information to perform NO-ARC transitions without consulting statistical models.",
        "Transition",
        "Ai",
        "A2",
        "p",
        "A3",
        "A4",
        "A",
        "0",
        "[]",
        "[]",
        "1",
        "[]",
        "[2..6]",
        "0",
        "1",
        "No-Pred",
        "[1]",
        "[]",
        "2",
        "[]",
        "[3..6]",
        "2",
        "Left-Arc",
        "[]",
        "[1]",
        "2",
        "[]",
        "[3..6]",
        "A U",
        "3",
        "right-Arc",
        "[]",
        "[1]",
        "2",
        "[3]",
        "[4..6]",
        "A U",
        "4",
        "No-Arc",
        "[]",
        "[1]",
        "2",
        "[3..4]",
        "[5..6]",
        "5",
        "No-Arc",
        "[]",
        "[1]",
        "2",
        "[3..5]",
        "[6]",
        "6",
        "No-Arc",
        "[]",
        "[1]",
        "2",
        "[3..6]",
        "[]",
        "7",
        "Shift",
        "[1..2]",
        "[]",
        "3",
        "[]",
        "[4..6]",
        "8",
        "No-Pred",
        "[1..3]",
        "[]",
        "4",
        "[]",
        "[5..6]",
        "9",
        "No-Arc",
        "[1..2]",
        "[3]",
        "4",
        "[]",
        "[5..6]",
        "10",
        "No-Arc",
        "[1]",
        "[2..3]",
        "4",
        "[]",
        "[5..6]",
        "11",
        "Left-Arc",
        "[]",
        "[1..3]",
        "4",
        "[]",
        "[5..6]",
        "AU",
        "12",
        "No-Arc",
        "[]",
        "[1..3]",
        "4",
        "[5]",
        "[6]",
        "13",
        "right-Arc",
        "[]",
        "[1..3]",
        "4",
        "[5..6]",
        "[]",
        "AU",
        "14",
        "Shift",
        "[1..4]",
        "[]",
        "5",
        "[]",
        "[6]",
        "15",
        "No-Pred",
        "[1..5]",
        "[]",
        "6",
        "[]",
        "[]",
        "16",
        "No-Pred",
        "[1..6]",
        "[]",
        "$",
        "[]",
        "[]",
        "Table 2 shows parsing states generated by our algorithm.",
        "Our experiments show that this algorithm gives comparable results against another state-of-the-art system."
      ]
    },
    {
      "heading": "3. Predicate argument clustering",
      "text": [
        "Some studies showed that verb clustering information could improve performance in semantic role labeling (Gildea and Jurafsky, 2002; Pradhan et al., 2008).",
        "This is because semantic role labelers usually perform worse on verbs not seen during training, for which the clustering information can provide useful features.",
        "Most previous studies used either bag-of-words or syntactic structure to cluster verbs; however, this may or may not capture the nature ofpredi-cate argument structure, which is more semantically oriented.",
        "Thus, it is preferable to cluster verbs by their predicate argument structures to get optimized features for semantic role labeling.",
        "in this section, we present a self-learning clustering technique that effectively improves labeling accuracy in the test domain.",
        "First, we perform semantic role labeling on the test data using the algorithm in Section 2.",
        "Next, we cluster verbs in the test data using predicate argument structures generated by our semantic role labeler (Section 3.2).",
        "Then, we cluster verbs in the training data using the verb clusters we found in the test data (Section 3.3).",
        "Finally, we rerun our semantic role labeler on the test data using the clustering information.",
        "Our experiments show that this technique gives improvement to labeling accuracy for both in and out-of domain tasks.",
        "Before clustering, we need to project the predicate argument structure of each verb into vector space.",
        "Two kinds of features are used to represent these vectors: semantic role labels and joined tags of semantic role labels and their corresponding word lemmas.",
        "Figure 2 shows vector representations of predicate argument structures of verbs, want and buy, in Figure 1.",
        "initially, all existing and non-existing features are assigned with a value of 1 and 0, respectively.",
        "However, assigning equal values to all existing features is not necessarily fair because some features have higher confidence, or are more important than the others; e.g., ARG0 and ARG1 are generally predicted with higher confidence than modifiers, nouns give more important information than some other grammatical categories, etc.",
        "instead, we assign each existing feature with a value computed by the following equations:",
        "vi is the current verb, lj is the j'th label of Vj, and nij is lj's corresponding lemma.",
        "score(lj |vi) is a score of lj being a correct argument label of Vi; this is always 1 for training data and is provided by our statistical models for test data.",
        "Thus, s(lj| Vi) is an approximated probability of lj being a correct argument label of Vi, estimated by the logistic function.",
        "s(mj, lj) is equal to 1 if Wj is not a noun.",
        "If Wj is a noun, it gets a value > 1 given a maximum likelihood of n j being co-occurred with lj.",
        "With the vector representation, we can apply any kind of clustering algorithm (Hofmann and Puzicha, 1998; Kamvar et al., 2002).",
        "For our experiments, we use k-best hierarchical clustering for test data, and k-means clustering for training data.",
        "Given automatically generated predicate argument structures in the test data, we apply k-best hierarchical clustering; that is, a relaxation of classical hierarchical agglomerative clustering (from now on, HAC; Ward (1963)), to find verb clusters.",
        "Unlike HAC that merges a pair of clusters at each iteration, k-best hierarchical clustering merges k-best pairs at each iteration (Lo et al., 2009).",
        "Instead of merging a fixed number of k-clusters, we use a threshold to dynamically determine the top k-clusters.",
        "Our studies indicate that this technique produces almost as finegrained clusters as HAC, yet converges much faster.",
        "Verb",
        "A0",
        "A1",
        "john:A0",
        "to:A1",
        "car:A1",
        "want",
        "1",
        "1",
        "0s",
        "1",
        "1",
        "0",
        "0s",
        "buy",
        "1",
        "1",
        "0s",
        "1",
        "0",
        "1",
        "0s",
        "Our algorithm for k-best hierarchical clustering is presented in Algorithm 1. thup is a threshold that determines which k-best pairs are to be merged (in our case, kup = 0.8).",
        "sim(ci, Cj) is a similarity between clusters ci and Cj.",
        "For our experiments, we use cosine similarity with average-linkage.",
        "It is possible that other kinds of similarity metrics would work better, which we will explore as future work.",
        "Conditions in line 15 ensure that each cluster is merged with at most one other cluster at each iteration, and conditions in line 17 force at least one cluster to be merged with one other cluster at each iteration.",
        "Thus, the algorithm is guaranteed to terminate after at most (n – 1) iterations.",
        "When the algorithm terminates, it returns a set of one cluster with different hierarchical levels.",
        "For our experiments, we set another threshold, thlow, for early break-out: if there is no cluster pair whose similarity is greater than thlow, we terminate the algorithm (in our case, thlow = 0.7).",
        "A cluster set generated by this early breakout contains several unit clusters that are not merged with any other cluster.",
        "All of these unit clusters are discarded from the set to improve set quality.",
        "This is reasonable because our goal is not to cluster all verbs but to find a useful set of verb clusters that can be mapped to verbs in training data, which can lead to better performance in semantic role labeling.",
        "Given the verb clusters we found in the test data, we search for verbs that are similar to these clusters in the training data.",
        "K-means clustering (Hartigan, 1975) is a natural choice for this case because we already know k-number of center clusters to begin with.",
        "Each verb in the training data is compared with all verb clusters in the test data, and merged with the cluster that gives the highest similarity.",
        "To maintain the quality of the clusters, we use the same threshold, thlow, to filter out verbs in the training data that are not similar enough to any verb cluster in the test data.",
        "By doing so, we keep only verbs that are more likely to be helpful for semantic role labeling.",
        "input : C = [ci,.., cn]: ci is a unit cluster.",
        "thup G R: threshold.",
        "output: C = [ci,.., cm]: Cj is a unit or merged cluster, where m < n."
      ]
    },
    {
      "heading": "1. begin",
      "text": []
    },
    {
      "heading": "10. descendingSortBySimilarity(L)",
      "text": [
        "15 if i G S or j G S then"
      ]
    },
    {
      "heading": "16. continue",
      "text": []
    },
    {
      "heading": "21. break",
      "text": [
        "Algorithm 1: k-best hierarchical clustering."
      ]
    },
    {
      "heading": "4. Features",
      "text": [
        "For a baseline approach, we use features similar to ones used by Johansson and Nugues (2008).",
        "All features are assumed to have dependency structures as input.",
        "Table 3 shows n-gram feature templates used for our experiments (f: form, m: lemma, p: pos tag, d: dependency label).",
        "warfl and wpred are the current argument and predicate candidates.",
        "hd(w) stands for the head of w, lm(w), rm(w) stand for the leftmost, rightmost dependents of w, and ls(w), rs(w) stand for the left-nearest, right-nearest siblings of w, with respect to the dependency structures.",
        "Some of these features can be presented as a joined feature; e.g., a combination of warfl's pos tag and lemma.",
        "Table 3: N gram feature templates.",
        "Besides the n-gram features, we use several structural features such as dependency label set, subcat-egorization, POS path, dependency path, and dependency depth.",
        "Dependency label set features are derived by collecting all dependency labels of wpred's direct dependents.",
        "Unlike Johansson and Nugues, we decompose subcategorization features into two parts: one representing the left-hand side and the other representing the right-hand side dependencies of wpred.",
        "For the predicate wants in Figure 3, we generate sbj and oprd as separate subcategorization features.",
        "SBJ .",
        "PRP:John",
        "We also decompose path features into two parts: given the lowest common ancestor (LCA) of wargand wpred, we generate path features from warg to the LCA and from the LCA to wpred, separately.",
        "For example, the predicate buy and the argument John in Figure 3 have a LCA at wants, so we generate two sets of path features, {|PRP, |to|vb} with POS tags, and {|sbj, jOPRDjlM} with dependency labels.",
        "Such decompositions allow more generalization of those features; even if one part is not matched to the current parsing state, the other part can still participate as a feature.",
        "Throughout our experiments, these generalized features give slightly higher labeling accuracy than ungeneralized features although they form a smaller feature space.",
        "In addition, we apply dependency path features to wpred's highest verb chain, which often shares arguments with the predicate (e.g., John is a shared argument of the predicate buy and its highest verb chain wants).",
        "To retrieve the highest verb chain, we apply a simple heuristic presented below.",
        "The function getHighestVerbChain takes a predicate, pred, as input and returns its highest verb chain, vNode, as output.",
        "If there is no verb chain for the predicate, it returns null instead.",
        "Note that this heuristic is designed to work with dependency relations and labels described by the CoNLL'09 shared task (Hajic et al., 2009).",
        "func getHighestVerbChain(pred) vNode = pred; regex = \"CONJ|COORD|IM|OPRD|VC\";",
        "while (regex.matches(vNode.deprel)) vNode = vNode.head;",
        "Dependency depth features are a reduced form of path features.",
        "Instead of specifying POS tags or dependency labels, we indicate paths with their depths.",
        "For instance, John and buy in Figure 3 have a dependency depth feature of |1|2, which implies that the depth between John and its LCA (wants) is 1, and the depth between the LCA and buy is 2.",
        "Finally, we use four kinds of binary features: if warg is a syntactic head of wpred, if wpred is a syntactic head of warg, if wpred is a syntactic ancestor of warg, and if wpred's verb chain has a subject.",
        "Each feature gets a value of 1 if true; otherwise, it gets a value of 0.",
        "All dynamic features are derived by using previously identified arguments.",
        "Two kinds of dynamic features are used for our experiments.",
        "One is a label of the very last predicted numbered argument of wpred.",
        "For instance, the parsing state 3 in Table 2 uses a label A0 as a feature to make its prediction, wants – to, and the parsing states 4 to 6 use a label A1 as a feature to make their predictions, NO-ARC s. With this feature, the oracle can narrow down the scope of expected arguments of wpred.",
        "The other is a previously identified argument label of warg.",
        "The existence of this feature implies that warg is already identified as an argument of some other predicate.",
        "For instance, when warg = John and wpred = buy in Table 2, a label A0 is used as a feature to make the prediction, John – buy, because John is already identified as an A0 of wants.",
        "Word tokens",
        "Features",
        "warg, wpred",
        "f,m,p,d",
        "Warg±i, hd, lm, rm, ls, rs (Warg)",
        "m,p",
        "Wpred±i, hd, lm, rm (Wpred)",
        "m,p",
        "Finally, we use wpred's cluster ID as a feature.",
        "The dynamic and clustering features combine a very small portion of the entire feature set, but still give a fair improvement to labeling accuracy."
      ]
    },
    {
      "heading": "5. Experiments",
      "text": [
        "All models are trained on Wall Street Journal sections 2-21 and developed on section 24 using automatically generated lemmas and POS tags, as distributed by the CoNLL'09 shared task (Hajic et al., 2009).",
        "CoNLL 09 data contains semantic roles for both verb and noun predicates, for which we use only ones related to verb predicates.",
        "Furthermore, we do not include predicate sense classification as a part of our task, which is rather a task of word sense disambiguation than semantic role labeling.",
        "For in-domain and out-of-domain evaluations, Wsj section 23 and the Brown corpus are used, also distributed by CoNLL 09.",
        "To retrieve automatically generated dependency trees as input to our semantic role labeler, we train our open source dependency parser, called ClearParser, on the training set and run the parser on the evaluation sets.",
        "ClearParser uses a transition-based dependency parsing algorithm that gives near state-of-the-art results (Choi and Palmer, 2011), and mirrors our SRL algorithm.",
        "We use Liblinear L2-L1 SVM for learning; a linear classification algorithm using L2 regularization and L1 loss function.",
        "This algorithm is designed to handle large scale data: it assumes the data to be linearly separable so does not use any kind of kernel space (Hsieh et al., 2008).",
        "As a result, it significantly reduces training time compared to typical SVM, yet performs accurately.",
        "For our experiments, we use the following learning parameters: c = 0.1 (cost), e = 0.2 (termination criterion), B = 0 (bias).",
        "Since predicate identification is already provided in the CoNLL'09 data, we do not train No-Pred.",
        "Shift does not need to be trained in general because the preconditions of Shift can be checked deterministically without consulting statistical models.",
        "No-Arc^ and LEFT-ARCjL are trained together using the one-vs-all method as are No-Arc^ and RlGHT-ARCjL*.",
        "Even with multi-classifications, it takes less than two minutes for the entire training using Liblinear.",
        "Tables 4 and 5 show accuracy comparisons between three models evaluated on the Wsj and Brown corpora, respectively.",
        "'Baseline' uses the features described in Section 4.1.",
        "'+Dynamic' uses all baseline features and the dynamic features described in Section 4.2.",
        "'+Cluster' uses all previous features and the clustering feature.",
        "Even though our baseline system already has high performance, each model shows an improvement over its previous model (very slight for '+Cluster ).",
        "The improvement is greater for the out-of-domain task, implying that the dynamic and clustering features help more on new domains.",
        "The differences between 'Baseline' and '+Dynamic' are statistically significant for both in and out-of domain tasks (Wilcoxon signed-rank test, treating each sentence as an individual event, p < 0.025).",
        "Table 4: Labeling accuracies evaluated on the WSJ (P: precision, R: recall, F1: F1-score, all in %).",
        "'AI' and 'AC' stand for argument identification and argument classification, respectively.",
        "We also compare our results against another state-of-the-art system.",
        "Unfortunately, no other system has been evaluated with our exact environmental settings.",
        "However, Johansson and Nugues (2008), who showed state-of-the-art performance in CoNLL 08, evaluated their system with settings very similar to ours.",
        "Their task was exactly the same as ours; given predicate identification, they evaluated their dependency-based semantic role labeler for argument identification and classification on the Wsj and Brown corpora, distributed by the CoNLL 05 shared task (Carreras and Marquez, 2005).",
        "Since the CoNLL 05 data was not dependency-based, they applied heuristics to build dependency-based predicate argument structures.",
        "Their converted data may appear to be a bit different from the CoNLL 09 data we use (e.g., hyphenated words are tokenized by the hyphens in CoNLL 09 data whereas they are not in CoNLL 05 data), but semantic role annotations on headwords should look very similar.",
        "Task",
        "P",
        "R",
        "F1",
        "Baseline",
        "AI",
        "AI+AC",
        "92.57 87.20",
        "88.44 83.31",
        "90.46 85.21",
        "+Dynamic",
        "AI",
        "AI+AC",
        "92.38 87.33",
        "88.76 83.91",
        "90.54 85.59*",
        "+Cluster",
        "AI",
        "AI+AC",
        "92.62 87.43",
        "88.90 83.92",
        "90.72 85.64",
        "JN (2008)",
        "AI+AC",
        "88.46",
        "83.55",
        "85.93",
        "Task",
        "P",
        "R",
        "F1",
        "Baseline",
        "AI",
        "AI+AC",
        "90.96 77.11",
        "81.57 69.14",
        "86.01 72.91",
        "+Dynamic",
        "AI",
        "AI+AC",
        "90.90 77.41",
        "82.25 70.05",
        "86.36 73.55*",
        "+Cluster",
        "AI",
        "AI+AC",
        "90.87 77.47",
        "82.43 70.28",
        "86.44 73.70",
        "JN (2008)",
        "AI+AC",
        "77.67",
        "69.63",
        "73.43",
        "Johansson and Nugues s results are presented as JN (2008) in Tables 4 and 5.",
        "Our final system shows comparable results against this system.",
        "These results are meaningful in two ways.",
        "First, JN used a graph-based dependency parsing algorithm that gave higher parsing accuracy for these test sets than the transition-based dependency parsing algorithm used in ClearParser (about 0.9% better in labeled attachment score).",
        "Even with poorer parse output, our srl system performed as well as theirs.",
        "Furthermore, our system used only one set of features, which makes the feature engineering easier than JN s approach that used different sets of features for argument identification and classification."
      ]
    },
    {
      "heading": "6. Conclusion and future work",
      "text": [
        "This paper makes two contributions.",
        "First, we introduce a transition-based semantic role labeling algorithm that shows comparable performance against another state-of-the-art system.",
        "The new algorithm takes advantage of using previous predictions as features to make the next predictions.",
        "Second, we suggest a self-learning clustering technique that improves labeling accuracy slightly in both the domains.",
        "The clustering technique shows potential for improving performance in other new domains.",
        "These preliminary results are promising; however, there is still much room for improvement.",
        "Since our algorithm is transition-based, many existing techniques such as k-best ranking (Zhang and Clark, 2008) or dynamic programming (Huang and Sagae, 2010) designed to improve transition-based parsing can be applied.",
        "We can also apply different kinds of clustering algorithms to improve the quality of the verb clusters.",
        "Furthermore, more features, such as named entity tags or dependency labels, can be used to form a better representation of feature vectors for the clustering.",
        "One of the strongest motivations for designing our transition-based srl system is to develop a joint-inference system between dependency parsing and semantic role labeling.",
        "Since we have already developed a dependency parser, ClearParser, based on a parallel transition-based approach, it will be straightforward to integrate this srl system with the parser.",
        "We will also explore the possiblity of adding empty categories during semantic role labeling."
      ]
    },
    {
      "heading": "7. Related work",
      "text": [
        "Nivre (2008) introduced several transition-based dependency parsing algorithms that have been widely used.",
        "Johansson and Nugues (2008) and Zhao et al.",
        "(2009) presented dependency-based semantic role labelers showing state-of-the-art performance for the CoNLL'08 and '09 shared tasks in English.",
        "Scheible (2010) clustered predicate argument structures using EM training and the MDL principle.",
        "Wagner et al.",
        "(2009) used predicate argument clustering to improve verb sense disambiguation."
      ]
    },
    {
      "heading": "Acknowledgments",
      "text": [
        "We gratefully acknowledge the support of the National Science Foundation Grants CISE-IIS-RI-0910992, Richer Representations for Machine Translation, a subcontract from the Mayo Clinic and Harvard Children s Hospital based on a grant from the ONC, 90TR0002/01, Strategic Health Advanced Research Project Area 4: Natural Language Processing, and a grant from the Defense Advanced Research Projects Agency (DARPA/IPTO) under the GALE program, DARPA/CMO Contract No.",
        "HR0011-06-C-0022, subcontract from BBN, Inc. Any opinions, findings, and conclusions or recommendations expressed in this material are those of the authors and do not necessarily reflect the views of the National Science Foundation."
      ]
    }
  ]
}
