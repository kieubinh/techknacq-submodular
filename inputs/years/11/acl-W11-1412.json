{
  "info": {
    "authors": [
      "Chung-chi Huang",
      "Mei-hua Chen",
      "Shih-ting Huang",
      "Hsien-Chin Liou",
      "Jason S. Chang"
    ],
    "book": "Proceedings of the Sixth Workshop on Innovative Use of NLP for Building Educational Applications",
    "id": "acl-W11-1412",
    "title": "GRASP: Grammar-and Syntax-based Pattern-Finder in CALL",
    "url": "https://aclweb.org/anthology/W11-1412",
    "year": 2011
  },
  "references": [
    "acl-A00-2019",
    "acl-C08-1022",
    "acl-J93-1007",
    "acl-L08-1322",
    "acl-P04-3019",
    "acl-P06-1032",
    "acl-P07-1011",
    "acl-P10-2065",
    "acl-P95-1026",
    "acl-W09-2108",
    "acl-W10-0804",
    "acl-W10-1005"
  ],
  "sections": [
    {
      "text": [
        "Chung-Chi Huang* Mei-Hua Chen* Shih-Ting Huang+ Hsien-Chin Liou** Jason S. Chang+",
        "* Institute of Information Systems and Applications, NTHU, HsinChu, Taiwan, R.O.C.",
        "300",
        "+Department of Computer Science, NTHU, HsinChu, Taiwan, R.O.C.",
        "300 ** Department of Foreign Languages and Literature, NTHU, HsinChu, Taiwan, R.O.C.",
        "300 {u901571,chen.meihua,koromiko1104,hsienchin,jason.j schang}gmail.",
        "com",
        "We introduce a method for learning to describe the attendant contexts of a given query for language learning.",
        "In our approach, we display phraseological information in the form of a summary of general patterns as well as lexical bundles anchored at the query.",
        "The method involves syntactical analyses and inverted file construction.",
        "At run-time, grammatical constructions and their lexical instantiations characterizing the usage of the given query are generated and displayed, aimed at improving learners' deep vocabulary knowledge.",
        "We present a prototype system, GRASP, that applies the proposed method for enhanced collocation learning.",
        "Preliminary experiments show that language learners benefit more from GRASP than conventional dictionary lookup.",
        "In addition, the information produced by GRASP is potentially useful information for automatic or manual editing process."
      ]
    },
    {
      "heading": "1. Introduction",
      "text": [
        "Many learners submit word or phrase queries (e.g., \"role\") to language learning sites on the Web to get usage information every day, and an increasing number of services on the Web specifically target such queries.",
        "Language learning tools such as concordancers typically accept single-word queries and respond with example sentences containing the words.",
        "There are also collocation reference tools such as Sketch Engine and TANGO that provide co-occurring words for the query word.",
        "Another collocation tool, JustTheWord further organizes and displays collocation clusters.",
        "Learners may want to submit phrase queries (fixed or rigid collocaions) to learn further how to use the phrase in context, or in other words, to acquire the knowledge on the attendant phraseology of the query.",
        "These queries could be answered more appropriately if the tool accepted long queries and returned a concise summary of their surrounding contexts.",
        "Consider the query \"play role'\".",
        "The best responses for this query are probably not just example sentences, but rather the phraseological tendencies described grammatically or lexically.",
        "A good response of such a summary might contain patterns such as \"play Det Adj role'\" (as in \"play an important role\") and \"play ~ role in V-ing\" (as in \"play ~ role in shaping ...\").",
        "Intuitively, by exploiting simple part-of-speech analysis, we can derive such patterns, inspired by the grammatical theory of Pattern Grammar in order to provide more information on demand beyond what is given in a grammar book.",
        "We present a system, GRASP, that provide a usage summary of the contexts of the query in the form of patterns and frequent lexical bundles.",
        "Such rich information is expected to help learners and lexicographers grasp the essence of word usages.",
        "An example GRASP response for the query \"play role\" is shown in Figure 1.",
        "GRASP has retrieved the sentences containing the query in a reference corpus.",
        "GRASP constructs these query-to-sentence index in the preparation stage (Section 3).",
        "Type your search query, and push GRASP!",
        "Search query: |p|ay role | | GRASP |",
        "Mapping query words to (position, sentence) pairs:",
        "\"play\" occurs in (10,77), (4,90), (6,102), and so on.",
        "\"role\" occurs in (7,90), (12,122), (6,167), and so on.",
        "At run-time, GRASP starts with a search query (e.g., \"play role\") submitted by the user.",
        "GRASP then retrieves example sentences and generates a summary of representative contexts, using patterns (e.g., \"play ~ role in V-ing\") and lexical bundles (e.g., \"play ~ role in shaping.",
        "In our implementation, GRASP also returns the translations and the example sentences of the lexical instances, so the learner can use their knowledge of native language to enhance the learning process."
      ]
    },
    {
      "heading": "2. Related Work",
      "text": [
        "Computer-assisted language learning (CALL) has been an area of active research.",
        "Recently, more and more research based on natural language processing techniques has been done to help language learners.",
        "In our work, we introduce a language learning environment, where summarized usage information are provided, including how function words and verb forms are used in combination with the query.",
        "These usage notes often help contrast the common sources of error in learners' writing (Nicholls, 1999).",
        "In our pilot teaching experiment, we found learners have problems using articles and prepositions correctly in sentence composition (as high as 80% of the articles and 60% of the prepositions were used incorrectly), and GRASP is exactly aimed at helping ESL or EFL learners in that area.",
        "Until recently, collocations and usage information are compiled mostly manually (Benson et al., 1986).",
        "With the accessibility to large-scale corpora and powerful computers, it has become common place to compile a list of collocations automatically (Smadja, 1993).",
        "In addition, there are many collocation checkers developed to help non-native language learners (Chang et al., 2008), or learners of English for academic purposes (Durrant, 2009).",
        "Recently, automatic generation of collocations for computational lexicography and online language learning has drawn much attention.",
        "Sketch Engine (Kilgarriff et al., 2004) summarizes a word's grammatical and collocation behavior, while JustTheWord clusters the co-occurring words of single-word queries and TANGO (Jian et al., 2004) accommodates cross-lingual collocation searches.",
        "Moreover, Cheng et al.",
        "(2006) describe how to retrieve mutually expected words using concgrams.",
        "In contrast, GRASP, going one step further, automatically computes and displays the information that reveals the regularities of the contexts of user queries in terms of grammar patterns.",
        "Recent work has been done on incorporating word class information into the analyses of phraseological tendencies.",
        "Stubbs (2004) introduces phrase-frames, which are based on lexical ngrams with variable slots, while Wible et al.",
        "(2010) describe a database called StringNet, with lexico-syntactic patterns.",
        "Their methods of using word class information are similar in spirit to our work.",
        "The main differences are that our patterns is anchored with query words directly and generalizes query's contexts via parts-of-speech, and that we present the query's usage summary in",
        "A. In-between pattern grammar:",
        "e.g., 'play a greater role' (17), 'play a larger role' (8), ...",
        "e.g., 'play important role' (15), 'play different role' (6), ...",
        "B.",
        "Subsequent pattern grammar:",
        "e.g., 'play ~ role in society' (7), 'play ~ role in relation' (5), ...",
        "C. Precedent pattern grammar: NN MD play ~ role (83):",
        "e.g., 'communication will play ~ role ' (2), ...",
        "e.g., 'voluntary groups play ~ role' (2), ...",
        "terms of function words as well as content word form (e.g., \"play ~ role in V-ing\"), as well as elastic lexical bundles (e.g., \"play ~ role in shaping\").",
        "Additionally, we also use semantic codes (e.g., PERSON) to provide more information in a way similar what is provided in learner dictionaries."
      ]
    },
    {
      "heading": "3. The GRASP System",
      "text": [
        "We focus on constructing a usage summary likely to explain the contexts of a given linguistic search.",
        "The usage summary, consisting of the query's predominant attendant phraseology ranging from pattern grammar to lexical phrases, is then returned as the output of the system.",
        "The returned summary, or a set of patterns pivoted with both content and function words, can be used for learners' benefits directly, or passed on to an error detection and correction system (e.g., (Tsao and Wible, 2009) and some modules in (Gamon et al., 2009) as rules.",
        "Therefore, our goal is to return a reasonable-sized set of lexical and grammatical patterns characterizing the contexts of the query.",
        "We now formally state the problem that we are addressing.",
        "Problem Statement: We are given a reference corpus C from a wide range of sources and a learner search query Q.",
        "Our goal is to construct a summary of word usages based on C that is likely to represent the lexical or grammatical preferences on Q's contexts.",
        "For this, we transform the words in Q into sets of (word position, sentence record) pairs such that the context information, whether lexically-or grammatical-oriented, of the querying words is likely to be acquired efficiently.",
        "In the rest of this section, we describe our solution to this problem.",
        "First, we define a strategy for preprocessing our reference corpus (Section 3.2).",
        "Then, we show how GRASP generates contextual patterns, comprising the usage summary, at runtime (Section 3.3).",
        "We attempt to find the word-to-sentence mappings and the syntactic counterparts of the L1 sentences expected to speed up runtime pattern generation.",
        "Our preprocessing procedure has two stages.",
        "Lemmatizing and PoS Tagging.",
        "In the first stage, we lemmatize each sentence in the reference corpus C and generate its most probable POS tag sequence.",
        "The goal of lemmatization is to reduce the impact of morphology on statistical analyses while that of POS tagging is to provide a way to grammatically describe and generalize the contexts/usages of a linguistic query.",
        "Actually, using POS tags is quite natural: they are often used for general description in grammar books, such as one's (i.e., possessive pronoun) in the phrase \"make up one's mind\", oneself (i.e., reflexive pronoun) in \"enjoy oneself very much\", superlativeadjective in \"the most superlative_adjective\", NN (i.e., noun) and VB (i.e., base form of a verb) in \"insist/suggest/demand that",
        "NN VB\" and so on.",
        "Constructing Inverted Files.",
        "In the second stage, we build up inverted files of the lemmas in C for quick runtime search.",
        "For each lemma, we record the sentences and positions in which it occurs.",
        "Additionally, its corresponding surface word and POS tag are kept for runtime pattern grammar generation.",
        "procedure GRASPusageSurmnaryBuilding(^ue?y ,proximi'tyN,C) (1) queries=queryReformulation(query)",
        "(2) GRASPresponses= f for each query in queries",
        "(3) inter/nviist=findInvertedFile(w1 in query) for each lemma wi in query except for w1 (4) 7nvList=findInvertedFile(wi)",
        "//AND operation on interlnvList and InvList (5a) newInterInvList= f ; i=1; j=1 (5b) while i<=length(interInvList) and j<=lengh(InvList) (5c) if interInvList[i].SentNo==InvList[/].SentNo (5d) if withinProximity(interInvList[i].",
        "wordPosi/nvList j].wordPosi,proximity) (5e) Insert(newInterInvList, interInvList[i]JnvList[j]) else if interInvList[i].wordPosi<InvListj].wordPosi else //interInvList[i] .wordPosi>InvListj] .wordPosi else if interInvList[i].SentNo<InvList[/'].SentNo",
        "else //interInvList[i] .SentNo>InvListj] .SentNo (5i) /'++ (5j) interInvList=newInterInvList //construction of GRASP usage summary for this query for each element in interInvList (7) Usage+={PatternGrammarGeneration(query,element,C)} (8a) Sort patterns and their instances in Usage in descending order of frequency (8b) GRASPresponse=the N patterns and instances in Usage with highest frequency (9) append GRASPresponse to GRASPresponses (10) return GRASPresponses",
        "Once the word-to-sentence mappings and syntactic analyses are obtained, GRASP generates the usage summary of a query using the procedure in Figure 2.",
        "In Step (1) we reformulate the user query into new ones, queries, if necessary.",
        "The first type of query reformulation concerns the language used in query.",
        "If it is not in the same language as C, we translate query and append the translations to queries as if they were submitted by the user.",
        "The second concerns the length of the query.",
        "Since single words may be ambiguous in senses and contexts or grammar patterns are closely associated with words' meanings (Hunston and Francis, 2000), we transform single-word queries into their collocations, particularly focusing on one word sense (Yarowsky, 1995), as stepping stones to GRASP patterns.",
        "Notice that, in implementation, users may be allowed to choose their own interested translation or collocation of the query for usage learning.",
        "The prototypes for first-language (i.e., Chinese) queries and English queries of any length are at A and B respectively.",
        "The goal of cross-lingual GRASP is to assist EFL users even when they do not know the words of their searches and to avoid incorrect queries largely because of miscollocation, misapplication, and misgeneralization.",
        "Afterwards, we initialize GRASPresponses to collect usage summaries for queries (Step (2)) and leverage inverted files to extract and generate each query's syntax-based contexts.",
        "In Step (3) we prep interInvList for the intersected inverted files of the lemmas in query.",
        "For each lemma wi within, we first obtain its inverted file, InvList (Step (4)) and perform an AND operation on interInvList (intersected results from previous iteration) and InvList (Step (5a) to (5j)), defined as follows.",
        "First, we enumerate the inverted lists (Step (5b)) after the initialization of their indices i and j and temporary resulting intersection newInterInvList (Step (5a)).",
        "Second, we incorporate a new instance of (position, sentence), based on interInvList[i] and InvList[j], into newInterInvList (Step (5e)) if the sentence records of the indexed list elements are the same (Step (5c)) and the distance between their words are within proximity (Step (5d)).",
        "Otherwise, i and j are moved accordingly.",
        "To accommodate the contexts of queries' positional variants (e.g., \"role to play\" and \"role ~ play by\" for the query \"play role\"), Step (5d) considers the absolute distance.",
        "Finally, interInvList is set for the next",
        "AND iteration (Step (5j)).",
        "Once we obtain the sentences containing query, we construct its context summary as below.",
        "For each element, taking the form ([wordPosi(w1), wordPosi(wn)], sentence record) denoting the positions of query's lemmas in the sentence, we generate pattern grammar involving replacing words in the sentence with POS tags and words in wordPosi(wi) with lemmas, and extracting fixed-window segments surrounding query from the transformed sentence.",
        "The result is a set of grammatical patterns with counts.",
        "Their lexical realizations also retrieved and displayed.",
        "The procedure finally generates top N predominant syntactic patterns and their N most frequent lexical phrases as output (Step (8)).",
        "The usage summaries GRASP returns are aimed to accelerate EFL learners' language understanding and learning and lexicographers' word usage navigation.",
        "To acquire more semantic-oriented patterns, we further exploit WordNet and majority voting to categorize words, deriving the patterns like \"provide PERSON with.\""
      ]
    },
    {
      "heading": "4. Experimental Results",
      "text": [
        "GRASP was designed to generate usage summarization of a query for language learning.",
        "As such, GRASP will be evaluated over CALL.",
        "In this section, we first present the setting of GRASP (Section 4.1) and report the results of different consulting systems on language learning in Section 4.2.",
        "We used British National Corpus (BNC) as our underlying reference corpus C. It is a British English text collection.",
        "We exploited GENIA tagger to obtain the lemmas and POS tags of C's sentences.",
        "After lemmatizing and syntactic analyses, all sentences in BNC were used to build up inverted files and used as examples for grammar pattern extraction.",
        "In our experiments, we showed GRASP to two classes of Chinese EFL (first-year) college students.",
        "32 and 86 students participated, and were trained to use GRASP and instructed to perform a sentence translation/composition task, made up of pretest and posttest.",
        "In (30-minute) pretest, participants were to complete 15 English sentences with Chinese translations as hints, while, in (20-minute) posttest, after spending 20 minutes familiarizing word usages of the test candidates from us by consulting traditional tools or GRASP, participants were also asked to complete the same English sentences.",
        "We refer to the experiments as constrained ones since the test items in pre-and post-test are the same except for their order.",
        "A more sophisticated testing environment, however, are to be designed.",
        "Each test item contains one to two blanks as shown in the above table.",
        "In the table, the first item is supposed to test learners' knowledge on the adjective and prepositional collocate of \"have impact\" while the second test the verb collocate make, subsequent preposition on, and preceding article a of \"record profit\".",
        "On the other hand, the third tests the ability to produce the adjective enrichment of \"in future\", and the fourth the in-between article a or possessive his and the following infinitive of \"in attempt\".",
        "Note that as existing collocation reference tools retrieve and display collocates, they typically ignore function words like articles and determiners, which happen to be closely related to frequent errors made by the learners (Nicholls, 1999), and fail to provide an overall picture of word usages.",
        "In contrast, GRASP attempts to show the overall picture with appropriate function words and word forms.",
        "We selected 20 collocations and phrases manually from 100 most frequent collocations in",
        "BNC whose MI values exceed 2.2 and used them as the target for learning between the pretest and posttest.",
        "To evaluate GRASP, half of the participants were instructed to use GRASP for learning and the other half used traditional tools such as online dictionaries or machine translation systems (i.e., Google Translate and Yahoo!",
        "Babel Fish).",
        "We summarize the performance of our participants on pre-and post-test in Table 1 where GRASP denotes the experimental group and TRAD the control group.",
        "We observe in Table 1 that (1) the partition of the classes was quite random (the difference between GRASP and TRAD was insignificant under pretest); (2) GRASP summaries of words' contexts were more helpful in language learning (across class 1, class 2 and combined).",
        "Specifically, under the column of the 1st class, GRASP helped to boost students' achievements by 15.5%, almost tripled (15.5 vs. 5.6) compared to the gain using TRAD; (3) the effectiveness of GRASP in language learning do not confine to students at a certain level.",
        "Encouragingly, both high-and low-achieving students benefited from GRASP if we think of students in class 2 and those in class 1 as the high and the low respectively (due to the performance difference on pretests).",
        "We have analyzed some participants' answers and found that GRASP helped to reduce learners' article and preposition errors by 28% and 8%, comparing to much smaller error reduction rate 7% and 2% observed in TRAD group.",
        "Additionally, an experiment where Chinese EFL students were asked to perform the same task but using GRASP as well as GRASP with translation information was conducted.",
        "We observed that with Chinese translation there was an additional 5% increase in students' test performance.",
        "This suggests to some extent learners still depend on their first languages in learning and first-language information may serve as another quick navigation index even when English GRASP is presented.",
        "English (E) sentence with corresponding Chinese (C) translation",
        "answer to 1st blank",
        "answer to 2nd blank",
        "c: mmuMmmmmm^Bw",
        "E: Environmental protection has impact .",
        "a profound",
        "on the Earth",
        "E: The real estate agent record profit .",
        "made a",
        "on house selling",
        "E: They plan to release their new album in future",
        "the near",
        "none",
        "E: He waited for her for a long time in attempt again.",
        "an",
        "to see her",
        "class 1",
        "class 2",
        "combined",
        "pretest posttest",
        "pretest posttest",
        "pretest posttest",
        "GRASP",
        "26.4 41.9",
        "43.6 58.4",
        "38.9 53.9",
        "TRAD",
        "27.1 32.7",
        "43.8 53.4",
        "39.9 48.6",
        "Overall, we are modest to say that (in the constrained experiments) GRASP summarized general-to-specific usages, contexts, or phraseologies of words are quite effective in assisting learners in collocation and phrase learning."
      ]
    },
    {
      "heading": "5. Applying GRASP to Error Correction",
      "text": [
        "To demonstrate the viability of GRASP-retrieved lexicalized grammar patterns (e.g., \"play ~ role In V-ING\" and \"look forward to V-ING\") in error detection and correction, we incorporate them into an extended Levenshtein algorithm (1966) to provide broad-coverage sentence-level grammatical edits (involving substitution, deletion, and insertion) to inappropriate word usages in learner text.",
        "Previously, a number of interesting rule-based error detection/correction systems have been proposed for some specific error types such as article and preposition error (e.g., (Uria et al., 2009) , (Lee et al., 2009), and some modules in (Gamon et al., 2009)).",
        "Statistical approaches, supervised or unsupervised, to grammar checking have become the recent trend.",
        "For example, unsupervised systems of (Chodorow and Leacock, 2000) and (Tsao and Wible, 2009) leverage word distributions in general and/or word-specific corpus for detecting erroneous usages while (Hermet et al., 2008) and (Gamon and Leacock, 2010) use Web as a corpus.",
        "On the other hand, supervised models, typically treating error detection/correction as a classification problem, utilize the training of well-formed texts ((De Felice and Pulman, 2008) and (Tetreault et al., 2010)), learner texts, or both pairwisely (Brockett et al., 2006).",
        "Moreover, (Sun et al., 2007) describes a way to construct a supervised error detection system trained on well-formed and learner texts neither pairwise nor error tagged.",
        "In contrast to the previous work in grammar checking, our pattern grammar rules are automatically inferred from a general corpus (as described in Section 3) and helpful for correcting errors resulting from the others (e.g., \"to close\" in \"play ~ role to close\"), our pattern grammar lexicalizes on both content and function words and lexical items within may be contiguous (e.g., \"look forward to V-ING PRP\") or non-contiguous (e.g., \"play ~ role In V-ING\"), and, with word class (POS) information, error correction or grammatical suggestion is provided at sentence level.",
        "Figure 3 shows how we check grammaticality and provide suggestions for a given text with accurate spelling.",
        "In Step (1), we initiate a set Suggestions to collect grammar suggestions to the user text T according to a bank of patterns PatternGrammarBank, i.e., a collection of summaries of grammatical usages (e.g., \"play ~ role In V-ING\") of queries (e.g., \"play role\") submitted to GRASP.",
        "Since we focus on grammar checking at sentence level, T is heuristically split (Step (2)).",
        "For each sentence, we extract user-proposed word usages (Step (3)), that is, the user grammatical contexts of ngram and collocation sequences.",
        "Take for example the (ungrammatical) sentences and their corresponding POS sequences \"he/PRP play/VBP an/DT important/JJ roles/NNS to/TO close/VB this/DT deals/NNS\" and \"he/PRP looks/VBZ forward/RB to/TO hear/VB you/PRP\".",
        "Ngram contexts include \"he VBP DT\", \"play an JJ NNS\", \"this NNS\" for the first sentence and \"look forward to VB PRP\" and \"look forward to hear PRP\" for the second.",
        "And collocation contexts for",
        "procedure GrammarChecking(TPatternGrammarBank) (1) Suggestions=\"\"//candidate suggestions",
        "(2) sentences=sentenceSplitting(T) for each sentence in sentences",
        "(3) userProposedUsages=extractUsage(sentence) for each userUsage in userProposedUsages (4) patGram=findPatternGrammar(userUsage.",
        "lexemes, PatternGrammarBank)",
        "(5) minEditedCost=SystemMax; minEditedSug=\"\" for each pattern in patGram",
        "(6) cost=extendedLevenshtein(userUsage,pattern) if cost<minEditedCost",
        "(7) minEditedCost=cost; minEditedSug=pattern if minEditedCost>0 (8) append (userUsage,minEditedSug) to Suggestions (9) Return Suggestions",
        "the first sentence are \"play ~ role to VERB\" and \"close ~ deal .\"",
        "For each userUsage in the sentence (e.g., \"play ~ role TO VB\" and \"look forward to hear PRP\"), we first acquire the pattern grammar of its lexemes (e.g., \"play role\" and \"look forward to hear\") such as \"play ~ role in V-ing\" and \"look forward to hear from\" in Step (4), and we compare the user-proposed usage against the corresponding predominant, most likely more proper, ones (from Step (5) to (7)).",
        "We leverage an extended Levenshtein's algorithm in Figure 4 for usage comparison, i.e. error detection and correction, after setting up minEditedCost and minEditedSug for the minimum-cost edit from alleged error usage into appropriate one (Step (5)).",
        "In Step (1) of the algorithm in Figure 4 we allocate and initialize costArray to gather the dynamic programming based cost to transform userUsage into a specific pattern.",
        "Afterwards, the algorithm defines the cost of performing substitution (Step (2)), deletion (Step (3)) and insertion (Step (4)) at i-indexed userUsage and j-indexed pattern.",
        "If the entries userUsage[i] and pattern[j] are equal literally (e.g., \"VB\" and 'VB\") or grammatically (e.g., \"DT\" and \"PRP$\"), no edit is needed, hence, no cost (Step (2a)).",
        "On the other hand, since learners tend to select wrong word form and preposition, we make less the cost of the substitution of the same word group, say from \"IN(on)\" (Step (2b)) compared to a total edit (Step (2c)).",
        "In addition to the conventional deletion and insertion (Step (3b) and (4b) respectively), we look ahead to the elements userUsage[i+1] and pattern[j+1] considering the fact that \"with or without preposition\" and \"transitive or intransitive verb\" often puzzles EFL learners (Step (3a) and (4a)).",
        "Only a small edit cost is applied if the next elements in userUsage and Pattern are \"equal\".",
        "In Step (6) the extended Levenshtein's algorithm returns the minimum cost to edit userUsage based on pattern.",
        "Once we obtain the costs to transform the userUsage into its related frequent patterns, we propose the minimum-cost one as its grammatical suggestion (Step (8) in Figure 3), if its minimum edit cost is greater than zero.",
        "Otherwise, the usage is considered valid.",
        "At last, the gathered suggestions Suggestions to T are returned to users (Step (9)).",
        "Example edits to the user text \"he play an important roles to close this deals.",
        "he looks forward to hear you.\"",
        "from our working prototype, EdIt, is shown in Figure 5.",
        "Note that we exploit context checking of collocations to cover longer span than ngrams', and longer ngrams like fourgrams and fivegrams to (more or less) help semantic checking (or word sense disambiguation).",
        "For example, \"hear\" may be transitive or intransitive, but, in the context of \"look forward to\", there is strong tendency it is used intransitively and follows by \"from\", as EdIt would suggest (see Figure 5).",
        "There are two issues worth mentioning on the development of EdIt.",
        "First, grammar checkers typically have different modules examining different types of errors with different priority.",
        "In our unified framework, we set the priority of checking collocations' usages higher than that of ngrams', set the priority of checking longer ngrams' usages higher than that of shorter, and we do not double check.",
        "Alternatively, one may first check usages of all sorts and employ majority voting to determine the grammaticality of a sentence.",
        "Second, we further incorporate",
        "procedure extendedLevenshtein(userUsage,pattern) (1) allocate and initialize costArray for i in range(len(userUsage)) for j in range(len(pattern)) //substitution",
        "if equal(userUsage[i],pattern[j]) (2a) substiCost=costArray[i-1,j-1]+0",
        "elseif sameWordGroup(userUsage[i],pattern [j]) (2b) substiCost=costArray[i- 1j-1]+0.5",
        "(2c) su bstiCost=costArray[ i-//deletion",
        "if equal(userUsage[i+1 ] pattern (3a) delCost=costArray[i-1 j]+smallCost else",
        "(3b) delCost=costArray[i-1j]+1 //insertion",
        "if equal(userUsage[ pattern ]) (4a) insCost=costArray[ij-1 ] +smallCost else (5) costArray[i,j]=min(substiCost,delCost,insCost) (6) Return costArray[len(userUsage),len(pattern)]",
        "Table 2.",
        "Three common score-related error types and their examples with suggestions from EdIt and ESL Assistant.",
        "Type your article and push the buttom \"EdIt\" !",
        "Article:",
        "he play an important roles to close this deals.",
        "he looks forward to hear you.",
        "Related pattern grammar (a) of collocation sequences includes \"play ~ role IN(in) NN\", \"play ~ role IN(in) DT\", \"play ~ role IN(in) VBG\" and so on.",
        "(b) of ngram sequences includes \"he VBD DT\", \"play an JJ NN\", \"this NN\", \"look forward to VBG PRP\" and \"look forward to hear IN(from) PRP\" and so on.",
        "Grammatical/Usage suggestion:",
        "For sentence 1:",
        "probabilities conditioned on word positions to weigh edit costs.",
        "For example, the conditional probability of \"VERB\" being the immediate follower of \"look forward to\" is virtually zero, but the probability of \"V-ing\" is around 0.3.",
        "We examined three common error types in learner text that are highly correlated with essay scores the results of a state-of-the-art checker, ESL Assistant (www.eslassistant.com/), are shown for comparison, and information produced by both systems are underscored.",
        "As indicated, GRASP retrieves patterns which are potential useful if incorporated into an extension of Levenshtein's algorithm to correct substitution, deletion, and insertion errors in learner."
      ]
    },
    {
      "heading": "6. Summary",
      "text": [
        "We have introduced a new method for producing a general-to-specific usage summary of the contexts of a linguistic search query aimed at accelerating learners' grasp on word usages.",
        "We have implemented and evaluated the method as applied to collocation and phrase learning and grammar checking.",
        "In the preliminary evaluations we show that GRASP is more helpful than traditional language learning tools, and that the patterns and lexical bundles provided are promising in detecting and correcting common types of errors in learner writing.",
        "Erroneous sentence",
        "EdIt suggestion",
        "ESL Assistant suggestion",
        "Wrong word form",
        "... a sunny days ...",
        "a sunny NN",
        "a sunny day",
        "every days, I ...",
        "every NN",
        "every day",
        "I would said to ...",
        "would VB",
        "would say",
        "he play a ...",
        "he VBD",
        "none",
        "... should have tell the truth",
        "should have VBN",
        "should have to tell",
        "... look forward to see you",
        "look forward to VBG",
        "none",
        "... in an attempt to seeing you",
        "an attempt to VB",
        "none",
        ".",
        "be able to solved this problem",
        "able to VB",
        "none",
        "Wrong preposition",
        "he plays an important role to close ...",
        "play ~ role IN(in)",
        "none",
        "he has a vital effect at her.",
        "have ~ effect IN(on)",
        "effect on her",
        "it has an effect on reducing ...",
        "have ~ effect IN(of) VBG",
        "none",
        "... depend of the scholarship",
        "depend IN(on)",
        "depend on",
        "Confusion between intransitive and transitive verb",
        "he listens the music.",
        "missing \"to\" after \"listens\"",
        "missing \"to\" after \"listens\"",
        "it affects to his decision.",
        "unnecessary \"to\"",
        "unnecessary \"to\"",
        "I understand about the situation.",
        "unnecessary \"about\"",
        "unnecessary \"about\"",
        "we would like to discuss about this matter.",
        "unnecessary \"about\"",
        "unnecessary \"about\"",
        "Mixture",
        "she play an important roles to close this deals.",
        "she VBD; an JJ NN;",
        "play an important role;",
        "play ~ role IN(in) VBG; this NN",
        "close this deal",
        "I look forward to hear you.",
        "look forward to VBG; missing \"from\" after \"hear\"",
        "none"
      ]
    }
  ]
}
