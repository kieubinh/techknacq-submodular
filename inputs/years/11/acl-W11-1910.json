{
  "info": {
    "authors": [
      "Hamidreza Kobdani",
      "Hinrich Schütze"
    ],
    "book": "Proceedings of the Fifteenth Conference on Computational Natural Language Learning: Shared Task",
    "id": "acl-W11-1910",
    "title": "Supervised Coreference Resolution with SUCRE",
    "url": "https://aclweb.org/anthology/W11-1910",
    "year": 2011
  },
  "references": [
    "acl-D08-1031",
    "acl-H05-1004",
    "acl-J01-4004",
    "acl-M95-1005",
    "acl-P11-1079",
    "acl-S10-1001",
    "acl-S10-1018",
    "acl-W11-1901"
  ],
  "sections": [
    {
      "text": [
        "Hamidreza Kobdani and Hinrich Schütze",
        "Institute for Natural Language Processing University of Stuttgart, Germany",
        "kobdani@ims.uni-stuttgart.de",
        "In this paper we present SUCRE (Kobdani and Schütze, 2010) that is a modular coref-erence resolution system participating in the CoNLL-2011 Shared Task: Modeling Unrestricted Coreference in OntoNote (Pradhan et al., 2011).",
        "The SUCRE's modular architecture provides a clean separation between data storage, feature engineering and machine learning algorithms."
      ]
    },
    {
      "heading": "1. Introduction",
      "text": [
        "Noun phrase coreference resolution is the process of finding markables (noun phrase) referring to the same real world entity or concept.",
        "In other words, this process groups the markables of a document into entities (equivalence classes) so that all markables in an entity are coreferent.",
        "Examples of applications of coreference resolution are Information Extraction, Question Answering and Automatic Summarization.",
        "Coreference is an equivalence relation between two markables, i.e., it is reflexive, symmetric and transitive.",
        "The first solution that intuitively comes to mind is binary classification of markable pairs (links).",
        "Therefore at the heart of most existing approaches there is a binary classifier that classifies links to coreferent/disreferent.",
        "One can also use the transitive property of coreference relation to build the entities; this is done using a clustering method.",
        "Our approach in this paper consist of the above mentioned steps, namely:",
        "1.",
        "Classification of links to coreferent/disreferent.",
        "2.",
        "Clustering of links which are classified as coreferent.",
        "This paper is organized as follows.",
        "In Section 2, we present our feature engineering approach.",
        "Section 3 presents the system architecture.",
        "Data set is described in Section 4.",
        "Sections 5 and 6 present results and conclusions."
      ]
    },
    {
      "heading": "2. Feature Engineering",
      "text": [
        "In recent years there has been substantial work on the problem of coreference resolution.",
        "Most methods present and report on the benchmark data sets for English.",
        "The feature sets they use are based on (Soon et al., 2001).",
        "These features consist of string-based features, distance features, span features, part-of-speech features, grammatical features, and agreement features.",
        "We defined a comprehensive set of features based on previous coreference resolution systems for English, e.g. (Bengtson and Roth, 2008).",
        "In the common approach to coreference resolution we have chosen, features are link features, i.e., features are defined over a pair of markables.",
        "For link feature definition and extraction, the head words of mark-ables are usually used, but in some cases the head word is not a suitable choice.",
        "For example, consider these two markables: the book and a book, in both cases book is the head word but to distinguish which markable is definite and which indefinite additional information about the markables has to be taken into account.",
        "Now consider these two mark-ables: the university students in Germany and the university students in France in this case the head words and the first four words of each markable are the same but they cannot be coreferent, and this could be detected only by looking at the entire noun phrase.",
        "Some features require complex preprocessing or complex definitions.",
        "Consider the two mark-ables the members of parliament and the members of the European Union.",
        "The semantic class ofmembers is person in the first case and country in the second.",
        "To cover all such cases, we introduced a feature definition language (Kobdani et al., 2010).",
        "With the feature definition language we will be able to access all information that is connected to a markable, including the first, last and head words of the two mark-ables; all other words of the two markables; and the two markables as atomic elements.",
        "After defining new features (new definition from scratch or definition by combination of existing features), we have to evaluate them.",
        "In principle, we could use any figure of merit to evaluate the usefulness of a feature or to compare two similar features, including Gini coefficient, mutual information, and correlation coefficient.",
        "In our current system, expected information gain (IG) and information gain ratio (IGR) are used.",
        "As an example, consider the following two features, which can be considered different attempts to formalize the same linguistic property:",
        "1.",
        "The noun phrase has a subject role and is definite (e.g. markable begins with a definite article)",
        "2.",
        "The noun phrase has a subject role and is not indefinite (e.g. markable begins with an indefinite article)",
        "The information gain ratios of the above mentioned features are equal to 0.0026 for the first and 0.0051 for the second one - this shows that the second one is a better choice.",
        "We now define IG and",
        "IGR.",
        "The change in entropy from a prior state to a state that takes some information is the expected information gain (Mitchell, 1997):",
        "Where f is the feature value, C its corresponding class, and entropy is defined as follows:",
        "If a feature takes a large number of distinct values, the information gain would not be a good measure for deciding its relevance.",
        "In such cases the information gain ratio is used instead.",
        "The information gain ratio for a feature is calculated as follows:",
        "Equation (4) can be used as an indicator for which features are likely to improve classification accuracy."
      ]
    },
    {
      "heading": "3. System Architecture",
      "text": [
        "The architecture of the system has two main parts: preprocessing and coreference resolution.",
        "In preprocessing the text corpus is converted to a relational data model.",
        "The main purpose of the relational model in our system is the use of a feature definition language (Kobdani et al., 2010).",
        "After modeling the text corpus, coreference resolution can be performed.",
        "The main steps of the system are presented as follows.",
        "In this step, tokens are extracted from the corpus.",
        "In the CoNLL-2011 Shared Task this step is as simple as reading each line of the input data set and extracting its corresponding token.",
        "Atomic features of the tokens are extracted in this step.",
        "The extracted atomic features are: part of speech, number, pronoun person (first, second and third), pronoun type (subjec-tive,,predeterminer,reflexive,objective and possessive), WordNet semantic class and gender.",
        "We use a rather simple method to extract semantic class of each token from WordNet.",
        "We look at the synonyms of the token and if one of them is in the predefined keyword set, we take it as its corresponding semantic class.",
        "The example of the keywords are person, time, abstraction, device, human action, organization, place and animal.",
        "In this step all noun phrases from the parse tree are extracted.",
        "After clustering step all markables which are not included in a chain are deleted from the list of markables.",
        "In other word we will not have any cluster with less than 2 members.",
        "In this step, the atomic attributes of the markables are extracted.",
        "In the data set of the CoNLL-2011 shared task the named entity property of a markable can be used as its atomic attribute.",
        "For training, the system generates a positive training instance for an adjacent coreferent markable pair (m, n) and negative training instances for the markable m and all markables disreferent with m that occur before n (Soon et al., 2001).",
        "For decoding it generates all the possible links inside a window of 100 markables.",
        "The output of the link generator, which is the list of the generated links, is the input to the link feature extractor for creating train and test data sets.",
        "To do this, the feature definitions are used to extract the feature values of the links (Kobdani et al., 2011).",
        "For learning we implemented a decision tree classifier (Quinlan, 1993).",
        "To achieve state-of-the-art performance, in addition to decision tree we also tried support vector machine and maximum entropy that did not perform better than decision tree.",
        "In this part, the links inside one document are classified then the coreference chains are created.",
        "We use best-first clustering for this purpose.",
        "It searches for the best predicted antecedent from right to left starting from the end of the document.",
        "For the documents with more than a predefined number of mark-ables we apply a limit for searching.",
        "In this way, in addition to better efficiency, the results also improve."
      ]
    },
    {
      "heading": "1.. A markable M is presented by a set of three words:",
      "text": [
        "Begin (Mh), End (Me) and Head (Mh).",
        "2.",
        "Let DM be the set of detected markables."
      ]
    },
    {
      "heading": "3.. Let T i be the node i in the parse tree with label L i",
      "text": [
        "(if node is a word then Li is equal to Wi).",
        "FindJMarkables(T ,L,DM )"
      ]
    },
    {
      "heading": "1.. If L is equal to noun phrase, then extract the markable M:",
      "text": [
        "(a) Set the begin word of the markable: Mh = Noun_Phrase_Begin(T ,L)",
        "(b) Set the end word of the markable: Me = Noun_Phrase_End(T ,L)",
        "(c) Set the head word of the markable: Mh = Noun_Phrase_Head(T ,L)",
        "(d) Add the markable M to the set of detected markables DM.",
        "2.",
        "Repeat for all Ti the daughters of T: Fin^Markables(Ti,Li,DM ) Noun_Phrase_Begin(T ,L)",
        "If T has no daughter then return L; else set Th to the first daughter of T and return",
        "Noun_Phrase_Begin(Th,Lh).",
        "Noun_Phrase_End(T ,L) else set Th to the last daughter of T and return",
        "Noun_Phrase_End(T,,Lh).",
        "NounJ>hrase_Head(T ,L) else set Th to the biggest noun phrase daughter of T and return Noun_Phrase_Head(Th,Lh).",
        "Table 1: Results of SUCRE on the development data set for the automatically detected markables.",
        "MD: Markable Detection."
      ]
    },
    {
      "heading": "4. Data Sets",
      "text": [
        "OntoNotes has been used for the CoNLL-2011 shared task.",
        "The OntoNotes project is to provide a large-scale, accurate corpus for general anaphoric coreference.",
        "It aims to cover entities and events (i.e. it is not limited to noun phrases or a limited set of entity types) (Pradhan et al., 2007).",
        "For training we used 4674 documents containing a total of 1909175 tokens, 190700 markables and 50612 chains.",
        "SUCRE participated in the closed track of the shared task.",
        "Experiments have been performed for the two kind of documents, namely, the automatically preprocessed documents and the gold preprocessed documents.",
        "In this paper, we report only the scores on the development data set using the official scorer of the shared task.",
        "The automatically preprocessed part consists of 303 documents containing a total of 136257 tokens, 52189 automatically detected markables, 14291 true markables and 3752 chains.",
        "The gold preprocessed part consists of 303 documents containing a total of 136257 tokens, 52262 automatically detected markables, 13789 true markables and 3752 chains."
      ]
    },
    {
      "heading": "5. Results",
      "text": [
        "We report recall, precision, and F1 for MUC (Vilain et al., 1995), B (Bagga and Baldwin, 1998), CEAFm/CEAFe (Luo, 2005) and BLANC (Re-casens et al., 2010).",
        "Table 1 presents results of our system for the automatically detected markables.",
        "It is apparent from this table that the application of the gold preprocessed documents slightly improves the performance (MD-F1: +1.51; MUC-F1: +2.15; B-F1:",
        "Table 2: Results of SUCRE on the development data set for the true markables (i.e. no singletone is included).",
        "+1.02; CEAFM-F1: +0.71; CEAFE-F1: +1.44; BLANC-F1: +0.70).",
        "Table 2 presents results of our system for the true markables that were all and only part of coreference chains.",
        "Again the results show that the application of gold preprocessed documents slightly improves +0.37 ).",
        "Comparing the results of tables 1 and 2, there is a significant difference between the scores on the automatically detected markables and the scores on the true markables (e.g. for the automatically preprocessed documents: MUC-F1: +17.28; CEAFm-F1: +13.45; CEAFE-F1: +12.74; BLANC-F1: +7.37).",
        "No significant improvement in B is seen (automatic: +1.49; gold: +1.33).",
        "We suspect that this is partly due to the very sensitive nature of B against the singleton chains.",
        "Because in the implementation of scorer for the CoNLL-2011 shared task the non-detected key markables are automatically included into the response as singletons."
      ]
    },
    {
      "heading": "6. Conclusion",
      "text": [
        "In this paper, we have presented our system SUCRE participated in the CoNLL-2011 shared task.",
        "We took a deeper look at the feature engineering of SUCRE.",
        "We presented the markable detection method we applied.",
        "We showed that the application of the gold preprocessed documents improves the performance.",
        "It has been demonstrated that the availability of the true markables significantly improves the results.",
        "Also it has been shown that the singletons have a large impact on the B scores.",
        "Automatic",
        "Gold",
        "Rec.",
        "Prec.",
        "Fi",
        "Rec.",
        "Prec.",
        "Fi",
        "MD",
        "60.17",
        "60.92",
        "60.55",
        "62.50",
        "61.62",
        "62.06",
        "MUC",
        "54.30",
        "51.84",
        "53.06",
        "57.44",
        "53.15",
        "55.21",
        "B",
        "71.39",
        "64.68",
        "67.87",
        "74.07",
        "64.39",
        "68.89",
        "CEAFm",
        "46.36",
        "46.36",
        "46.36",
        "47.07",
        "47.07",
        "47.07",
        "CEAFE",
        "35.38",
        "37.26",
        "35.30",
        "35.19",
        "38.44",
        "36.74",
        "BLANC",
        "65.01",
        "64.93",
        "64.97",
        "66.23",
        "65.16",
        "65.67",
        "Automatic",
        "Gold",
        "Rec.",
        "Prec.",
        "Fi",
        "Rec.",
        "Prec.",
        "Fi",
        "MUC",
        "58.63",
        "87.88",
        "70.34",
        "60.48",
        "88.25",
        "71.78",
        "B",
        "57.91",
        "86.47",
        "69.36",
        "59.21",
        "86.25",
        "70.22",
        "CEAFm",
        "59.81",
        "59.81",
        "59.81",
        "60.91",
        "60.91",
        "60.91",
        "CEAFE",
        "70.49",
        "36.43",
        "48.04",
        "71.09",
        "37.73",
        "49.30",
        "BLANC",
        "69.67",
        "76.27",
        "72.34",
        "70.34",
        "76.01",
        "72.71"
      ]
    }
  ]
}
