{
  "info": {
    "authors": [
      "Anais Cadilhac",
      "Nicholas Asher",
      "Farah Benamara",
      "Alex Lascarides"
    ],
    "book": "Proceedings of the SIGDIAL 2011 Conference",
    "id": "acl-W11-2023",
    "title": "Commitments to Preferences in Dialogue",
    "url": "https://aclweb.org/anthology/W11-2023",
    "year": 2011
  },
  "references": [
    "acl-J98-4001",
    "acl-W05-0613"
  ],
  "sections": [
    {
      "text": [
        "Anais Cadilhac*, Nicholas Asher*, Farah Benamara*, Alex Lascarides**",
        "*IRIT, University of Toulouse, **School of Informatics, University of Edinburgh",
        "We propose a method for modelling how dialogue moves influence and are influenced by the agents' preferences.",
        "We extract constraints on preferences and dependencies among them, even when they are expressed indirectly, by exploiting discourse structure.",
        "Our method relies on a study of 20 dialogues chosen at random from the Verbmobil corpus.",
        "We then test the algorithms predictions against the judgements of naive annotators on 3 random unseen dialogues.",
        "The average annotator-algorithm agreement and the average inter-annotator agreement show that our method is reliable."
      ]
    },
    {
      "heading": "1. Introduction",
      "text": [
        "Dialogues are structured by various moves that the participants make – e.g., answering questions, asking follow-up questions, elaborating prior claims, and so on.",
        "Such moves come with commitments to certain attitudes such as intentions and preferences.",
        "While mapping utterances to their underlying intentions is well studied through the application of plan recognition techniques (e.g., Grosz and Sidner (1990), Allen andLitman (1987)), game-theoretic models of rationality generally suggest that intentions result from a deliberation to find the optimal tradeoff between one's preferences and one's beliefs about possible outcomes (Rasmusen, 2007).",
        "So mapping dialogue moves to preferences is an important task: for instance, they are vital in decisions on how to re-plan and repair should the agents' current plan fail, for they inform the agents about the relative importance of their various goals.",
        "Classical game theory, however, demands a complete and cardinal representation of preferences for the optimal intention to be defined.",
        "This is not realistic for modelling dialogue because agents often lack complete information about preferences prior to talking: they learn about the domain, each other's preferences and even their own preferences through dialogue exchange.",
        "For instance, utterance (1) implies that the speaker wants to go to the mall given that he wants to eat, but we do not know his preferences over \"go to the mall\" if he does not want to eat.",
        "(1) I want to go to the mall to eat something.",
        "Existing formal models of dialogue content either do not formalise a link between utterances and preferences (e.g., Ginzburg (to appear)), or they encode such links in a typed feature structure, where desire is represented as a feature that takes conjunctions of values as arguments (e.g., Poesio and Traum (1998)), making the language too restricted to express dependencies among preferences of the kind we just described.",
        "Existing implemented dialogue systems likewise typically represent goals as simple combinations of values on certain information 'slots' (e.g., He and Young (2005), Lemon and Pietquin (2007)); thus (1) yields a conjunction of preferences, to go to the mall and to eat something.",
        "But such a system could lead to suboptimal dialogue moves – e.g., to help the speaker go to the mall even if he has already received food.",
        "What's required, then, is a method for extracting partial information about preferences and the dependencies among them that are expressed in dialogue, perhaps indirectly, and a method for exploiting that partial information to identify the next optimal action.",
        "This paper proposes a method for achieving these tasks by exploiting discourse structure.",
        "We exploited the corpus of Baldridge and Lascarides (2005a), who annotated 100 randomly chosen spontaneous face-to-face dialogues from the Verbmobil corpus (Wahlster, 2000) with their discourse structure according to Segmented Discourse Representation Theory (sdrt, Asher and Lascarides (2003)) – these structures represent the types of (relational) speech acts that the agents perform.",
        "Here's a typical fragment:",
        "b.",
        "A: What days are good for you?",
        "c. B: Well, I have some free time on almost every day except Fridays.",
        "d. B: In fact, I'm busy on Thursday too.",
        "e. A: So perhaps Monday?",
        "Across the corpus, more than 30% of the discourse units are either questions or assertions that help to elaborate a plan to achieve the preferences revealed by a prior part of the dialogue – these are marked respectively with the discourse relations Q-Elab and Plan-Elab in sdrt, and utterances (2b) and (2e) and the segments (2c) and (2d) invoke these relations (see Section 2).",
        "Moreover, 10% of the moves revise or correct prior preferences (like (2d)).",
        "We will model the interaction between dialogue content and preferences in two steps.",
        "The first maps utterances and their rhetorical connections into a partial description of the agents' preferences.",
        "The mapping is compositional and monotonie over the dialogue's logical form (i.e., the description of preferences for an extended segment is defined in terms of and always subsumes those for its subsegments): it exploits recursion over discourse structure.",
        "The descriptions partially describe ceteris paribus preference nets or CP-nets with Boolean variables (Boutilier et al., 2004).",
        "We chose CP-nets over alternative logics of preferences, because they provide a compact, computationally efficient, qualitative and relational representation of preferences and their dependencies, making them compatible with the kind of partial information about preferences that utterances reveal.",
        "Our mapping from the logical form of dialogue to partial descriptions of Boolean CP-nets proceeds in a purely linguistic or domain independent way (e.g., it ignores information such as Monday and Tuesday cannot co-refer) and will therefore apply to dialogue generally and not just Verbmobil.",
        "In a second stage, we \"compress\" and refine our description making use of constraints proper to CP-nets (e.g., that preference is transitive) and constraints provided by the domain – in this case constraints about times and places, as well as constraints from deep semantics.",
        "This second step reduces the complexity of inferring which CP-net(s) satisfy the partial description and allows us to identify the minimal CP-net that satisfies the domain-dependent description of preferences.",
        "We can thus exploit dependencies between dialogue moves and mental states in a compact, efficient and intuitive way.",
        "We start by motivating and describing the semantic representation of dialogue from which our CP-net descriptions and then our CP-nets will be constructed."
      ]
    },
    {
      "heading": "2. The Logical Form of Dialogue",
      "text": [
        "Our starting point for representing dialogue content is sdrt.",
        "Like Hobbsetal.",
        "(1993) and Mann and Thompson (1987), it structures discourse into units that are linked together with rhetorical relations such as Explanation, Question Answer Pair (QAP), Q-Elab, Plan-Elab, and so on.",
        "Logical forms in sdrt consist of Segmented Discourse Representation Structures (sdrss).",
        "As defined in Asher and Lascarides (2003), an sdrs is a set of labels representing discourse units, and a mapping from each label to an sdrs-formula representing its content – these formulas are based on those for representing clauses or elementary discourse units (edus) plus rhetorical relation symbols between labels.",
        "Lascarides and Asher (2009) argue that to make accurate predictions about acceptance and denial, both of which can be implicated rather than linguistically explicit, the logical form of dialogue should track each agent's commitments to content, including rhetorical connections.",
        "They represent a dialogue turn (where turn boundaries occur whenever the speaker changes) as a set of sdrss – one for each agent representing all his current commitments, from the beginning of the dialogue to the end of that turn.",
        "The representation of the dialogue overall – a Dialogue sdrs or dsdrs – is that of each of its turns.",
        "Each agent constructs the sdrss for all other agents as well as his own.",
        "For instance, (2) is assigned the dsdrs in Table 1, with the content of the edus omitted for reasons of space (see Lascarides and Asher (2009) for details).",
        "We adopt a convention of indexing the root label of the nth turn, spoken by agent d, as nd; and n : >|> means that >|> describes n's content (we'll sometimes also write >n to identify this description).",
        "We now return to our example (2).",
        "Intuitively, (2a) commits A to a preference for meeting next week but it does so indirectly: the preference is not asserted, or equivalently entailed at the level of content from the semantics of Q-Elab(a, b).",
        "Accordingly, responding with \"I do too\" (meaning \"I want to meet next week too\") is correctly predicted to be highly anomalous.",
        "A's sdrs for turn 1 in Table 1 commits him to the questions (2a) and (2b) because Q-Elab is veridical: i.e. Q-Elab(a, lb) entails the dynamic conjunction >a A >b.",
        "Since intuitively (2a) commits A to the implicature that he prefers next week, our algorithm for eliciting preferences from dialogue must ascribe this preference to A on the basis of his move Q-Elab(a, b).",
        "Furthermore, Q-Elab(a, lb) entails that any answer to (2b) must elaborate a plan to achieve the preference revealed by (2a); this makes | b paraphrasable as \"What days next week are good for you?",
        "\", which does not add new preferences.",
        "B's contribution in the second turn attaches to (2b) with QAP and also Plan-Elab – he answers with a non-empty extension for what days.",
        "Lascarides and Asher (2009) argue that this means that B is also committed to the illo-cutionary contribution of (2b), as shown in Table 1 by the addition of Q-Elab(a,lb) to B's sdrs.",
        "This addition commits B also to the preference of meeting next week, with his answer making the preference more precise: (2c) reveals that B prefers any day except Friday; by linking (2d) with Plan-Correction he retracts the preference for Thursday.",
        "This compels A to revise his inferences about B's preference for meeting on Thursday.",
        "A's Plan-Elab move (2e) in the third turn reveals another preference for Monday.",
        "This may not match his preferred day when the dialogue started: perhaps that was Friday.",
        "He may continue to prefer that day.",
        "But engaging in dialogue can compel agents to revise their commitments to preferences as they learn about the domain and each other.",
        "The above discussion of (2) exhibits how different types of rhetorical relations between utterances rather than Searle-like speech acts like question, construed as a property of an utterance, are useful for encoding how preferences evolve in a dialogue and how they relate to one another.",
        "While the Grounding Acts dialogue model (Poesio and Traum, 1998) and the Question Under Discussion (qud) model (Ginzburg, to appear) both have many attractive features, they do not encode as finegrained a taxonomy of types of speech acts and their semantic effects as sdrt: in sdrt each rhetorical relation is a different kind of (relational) speech act, so that, for instance, the speech act of questioning is divided into the distinct types Q-Elab, Plan-Correction, and others.",
        "For the qud model to encode such relations would require implicit questions of all sorts of different types to be included in the taxonomy, in which case the result may be equivalent to the sdrt taxonomy of dialogue moves.",
        "We have not explored this eventual equivalence here."
      ]
    },
    {
      "heading": "3. CP-nets and CP-net descriptions",
      "text": [
        "A preference is standardly understood as an ordering by an agent over outcomes; at the very least it entails a comparison between one entity and another (outcomes being one sort of entity among others).",
        "As indicated in the introduction, we are interested in an ordinal definition of preferences, which consists in imposing an ordering over all (relevant) possible outcomes.",
        "Among these outcomes, some are acceptable for the agent, in the sense that the agent is ready to act in such a way as to realize them; and some outcomes are not acceptable.",
        "Amongst the acceptable outcomes, the agent will typically prefer some to others.",
        "Our method does not try to determine the most preferred outcome of an agent but follows rather the evolution of their commitments to certain preferences as the dialogue proceeds.",
        "To give an example, if an agent proposes to meet on a certain day X and at a certain time Y, we infer that among the agent's acceptable outcomes is a meeting on X at Y, even if this is not his most preferred outcome (see earlier discussion of (2e)).",
        "A CP-net (Boutilier et al., 2004) offers a compact representation of preferences.",
        "It is a graphical model that exploits conditional preferential independence so as to structure the decision maker's preferences under a ceteris paribus assumption.",
        "Although CP-nets generally consider variables with a finite range of values, to define the mapping from dialogue turns to descriptions of CP-nets in a domain independent and compositional way, we use Boolean propositional variables: each variable describes an action that an agent can choose to perform, or not.",
        "We will then refine the CP-net description by using domain-specific information, transforming CP-nets with binary valued variables to CP-nets with multiple valued variables.",
        "This reduces the complexity of the evaluation of the CP-net by a large factor.",
        "More formally, let V be a finite set of propositional variables and LV the description language built from V via Boolean connectives and the constants T (true) and ± (false).",
        "Formulas of LV are denoted by >>, \\|/, etc.",
        "2V is the set of interpretations for V, and as usual for M e 2V and x e V, M gives the value true to x if x e M and false otherwise.",
        "Where X Ç V, let 2X be the set of X-interpretations.",
        "X-interpretations are denoted by listing all variables of X, with a \" symbol when the variable is set to false: e.g., where X = {a,b,d}, the X-interpretation M = {a,d} is expressed as abd.",
        "A preference relation >z is a reflexive and transitive binary relation on 2V with strict preference >- defined in the usual way (i.e., M >z M but M ^ M).",
        "Note that preference orderings are not necessarily complete, since some candidates may not be comparable by a given agent.",
        "An agent is said to be indifferent between two options M, M' e 2V, written M - M, if M h M' and M' h M. As we stated earlier, CP-nets exploit conditional preferential independence to compute a preferential ranking over outcomes:",
        "Definition 1 Let V be a set of propositional variables and {X,Y,Z} a partition ofV.",
        "X is conditionally preferentially independent of Y given Z if and only if Vz e 2Z, Vx1, x2 e 2X and Vy1, y2 e 2Y we have: x1y1z h x2y1z iff x1y2z h x2y2z.",
        "Turn",
        "A's sdrs",
        "B's sdrs",
        "1",
        "%ia '■ Q-Elab(a,b)",
        "0",
        "2",
        "%ia '■ Q-Elab(a,b)",
        "%2b : Q-Elab{a,b) A QAP{b,%) APlan-Elab{b,%) % : Plan-Correction(c,d)",
        "3",
        "%3a : Q-Elab{a,b) A QAP{b,%) APlan-Elab{b,%)A Plan-Elab(%, e)",
        "%2b : Q-Elab{a,b) A QAP{b,%) APlan-Elab{b,%) % : Plan-Correction(c,d)",
        "For each variable X, the agent specifies a set of parent variables Pa(X) that can affect his preferences over the values of X.",
        "Formally, X is conditionally preferentially independent of V \\ ({X} UPa(X)).",
        "This is then used to create the CP-net.",
        "Definition 2 Let V be a set of propositional variables.",
        "N = {G, T ) is a CP-net on V, where Q is a directed graph over V, and T is a set of Conditional Preference Tables (CPTs) with indifference.",
        "That is, T = {CPT(Xj): Xj e V}, where CPT(Xj ) specifies for each instantiation p g 2Pa(xj*> either Xj >-p x], x] >-p Xj or Xj ^p x].",
        "The following simple example illustrates these definitions.",
        "Suppose our agent prefers to go from Paris to Hong Kong by day rather than overnight.",
        "If he takes an overnight trip, he prefers a non stop flight, but if he goes by day, he prefers a flight with a stop.",
        "Figure 1 shows the associated CP-net.",
        "The variable T stands for the preference over the period of travel.",
        "Its values are Td for a day trip and Tn for a night one.",
        "The variable St stands for the preference over stops.",
        "Its values are S for a trip with stops and S without.",
        "St CPT(St)",
        "With CP-nets defined, we proceed to a description language for them.",
        "The description language formula w y y(CPT) describes a CP-net where a CPT contains an entry of the form w yp y for some possibly empty list of parent variables p. A CP-net description is a set of such formulas.",
        "The CP-net N = x1,... xn : w y y(CPT) iff the CP-net N 's CPT T contains an entry w yg y – also written u : w y y – where x1,... xn figure in u.",
        "Satisfaction of a description formula by a CP-net yields a notion of logical consequence between a CP-net description D N and a description formula in the obvious way.",
        "Dialogue turns also sometimes inform us that certain variables enter into preference statements.",
        "We'll express the fact that the variables x1 , .",
        ".",
        ".",
        ", xn are associated with discourse constituent n by the formula x1,..., xn (P(n)), where P(n) refers to the partial description of the preferences expressed by the discourse unit n (see Section 4).",
        "The description language allows us to impose constraints on the CP-nets that agents commit to without specifying the CP-net completely, as is required for utterances like (1).",
        "In section 6, we describe how to construct a minimal CP-net from a satisfiable CP-net description.",
        "One can then use the forward sweep procedure for outcome optimisation (Boutilier et al., 2004).",
        "This is a procedure of linear complexity, which consists in instantiating variables following an order compatible with the graph, choosing for each variable (one of) its preferred values given the value of the parents."
      ]
    },
    {
      "heading": "4. From EDU s to Preferences",
      "text": [
        "EDUs are described in SDRT using essentially Boolean formulas over labels (Asher and Lascarides, 2003); thus (>(n) A means that (> and \\|/ describe aspects of n's content.",
        "Not(n1, n) A means that the logical form of the edu n is of the form -n1 and that n1 is described by >>; so n has the content Our task is to map such descriptions of content into descriptions of preferences.",
        "Our preference descriptions will use Boolean connectives and operators over preference entries (e.g., of the form x y y): namely, &, y, ^ and a modal operator O.",
        "The rules below explain the semantics of preference operators (they are in effect defined in terms of the semantics of buletic attitudes and Boolean connectives) and how to recursively calculate preference descriptions from the EDU's logical structure.",
        "Simple EDUs can provide atomic preference statements (e.g., I want X or We need X).",
        "This means that with this EDU the speaker commits to a preference for X. X will typically involve a Boolean variable and a preference entry for its CPT.",
        "P(n) is the label of the preference description associated with discourse unit n. Hence for a simple edu n, we have X(P(n)) as its description.",
        "Simple EDUs also sometimes express preferences in an indirect way (see (2a)).",
        "More generally, P recursively exploits the logical structure of an EDU's logical form to produce an EDU preference representation (EDUPR).",
        "For instance, since the logical form of the EDU I want fish and wine features conjunction, likewise so does its preference description: §&\\\\f(P(%)) means that among the preferences included in n, the agent prefers to have both > and \\|/ and prefers either one if he can't have both.",
        "We also have disjunctions (let's meet Thursday or Friday), and negations (I don't want to meet on Friday), whose preferences we'll express respectively as Thursy Fri(P(n)) and -Fri(P(n)).",
        "Some EDUs express commitments to dependencies among preferences.",
        "For example, in the sentence What about Monday, in the afternoon?, there are two preferences: one for the day Monday, and, given the Monday preference, one for the time afternoon (of Monday), at least on one syntactic disambiguation.",
        "We represent this dependency as Mon i-> Aft(P(n)).",
        "Note that i-> is not expressible with just Boolean operators.",
        "Finally, EDUs can express commitment to preferences via free choice modalities; I am free on Thursday, or OThurs(P(n)), tells us that Thursday is a possible day to meet.",
        "O>> says that ( is an acceptable outcome (as described earlier, this means the agent is ready to act so as to realize an outcome that entails >>).",
        "Thus, entails and O-embedded preferences obey reduction axioms permitting O to be eliminated when combined with other preference operators.",
        "But a O preference statement does affect a preference description when is is conjoined in Boolean fashion with another O preference statement in an EDU or combined via a discourse relation like Continuation.",
        "This is because O is a free choice modality and obeys the equivalence (3) below, which in turn yields a disjunctive preference >> y Y(P(n) ) from what appeared to be a conjunction.",
        "The variables introduced by a discourse segment n are integrated into the CP-net description D N via the operation Commit(n, DN ).",
        "The following seven rules cover the different possible logical structures for the EDU preference representation.",
        "In the following, X, Y, Z, W denote propositional variables and > , | propositional formulas from EDUPR.",
        "Var(>) are the variables in >>, and yXthe preference relation describing CPT(X).",
        "Sat(>) (or non-Sat(O) is a conjunction of literals from Var(>) that satisfy (or do not satisfy) >>.",
        "Sat(>>) - X is the formula that results from removing the conjunct with X from Sat(> ).",
        "• For each X e Var(>), add Var(yr) to Pa(X) and modify CPT(X) as follows:",
        "If Sati(\\\\r), Sat/(§) h X (resp.",
        "X), then Saf;(\\|/), Satj{ty) -X:XyX (resp.",
        "X >- X), for all satisfies i and j.",
        "• Similarly for each Y e Var (yf).",
        "ically, this yields the following preference relation (where one way arrows denote preference, two way arrows denote indifference or equal preference, and no arrow means the options are incomparable):",
        "• Var(X) e Pa(Var(Y))_ and ©SVJ h * : ^ ~ Y{CPT{Y)),V9i \\=X :Y yY(CPT(Y)).",
        "• Var(7) G Pa(Var(X)_)_ and ©rv: h i : ^ ~ X{CPT{X)),V9i \\=Y :X yX(CPT(X)).",
        "This corresponds to the following preference relation:",
        "As before, the use of indifference allows us to find the best outcomes (XY, XY and XY) easily.",
        "• Var(X) G Pa(Var(7)) and V9£ \\=X :Y yY(CPT(Y)).",
        "Note that this description is also produced by Elab(%i,%j) below where X(P(rti)) and Y(P(nj)) (see rule 8).",
        "Thus the implication symbol - is a \"shortcut\" in that it represents elaborations whose arguments are in the same EDU.",
        "5.",
        "Where O>(P(n)) (the agent prefers a free choice of >>).",
        "Given the behaviour of O, this reduces to treating >(P(n)).",
        "6.",
        "Where ->(P(n)).",
        "We can apply rules 1-5 by converting into conjunctive normal form.",
        "7.",
        "Where >(P(n)) A\\|/(P(tc)), with >> and \\|/ nonmodal, we simply apply the rule for > and that for | ."
      ]
    },
    {
      "heading": "5. From Discourse Structure to Preferences",
      "text": [
        "We must now define how the agents' preferences, represented as a partial description of a CP-net, are built compositionally from the discourse structure over EDUs.",
        "The constraints are different for different discourse relations, reflecting the fact that the semantics of connections between segments influences how their preferences relate to one another.",
        "We will add rules for defining Commit over labels n whose content >n express rhetorical relations R(ni,%j) – indeed, we overload the notation and write Commit(R(ni,%j),DN).",
        "Since Commit applies compositionally, starting with the EDUs and working up the discourse structure towards the unique root label of the SDRS, we can assume in our definition of Commit(R(ni,%j), DN ) that the EDUPRs are already defined.",
        "We give rules for all the relations in the Verbmobil corpus, though we will be very brief with those that are less prevalent.",
        "A complete example using our rules is in appendix A.",
        "IExplanation, Elab, Plan-Elab, Q-elab IExplanation(ni, nj): i.e., rc/s preferences explain ni's (e.g., see (1), where P(ni) would be going to the mall and P(nj) is eating something).",
        "With Elab(ni, %j) a preference in ni is elaborated on or developed in nj, as in: I want wine.",
        "I want white wine.",
        "That is, a preference for white wine depends on a preference for wine.",
        "Plan-Elab(ni, nj) means that %j describes a plan for achieving the preferences expressed by ni, and with Q-Elab we have a similar dependence between preferences, but the second constituent is a question (so often in practice this means preference commitments from nitransfer from one agent to another).",
        "Plan-Elab(nj,ni), Elab(nj,ni) and IExplanation(ni,nj) all follow the same two-step rule, and so from the point of view of preference updates they are equivalent:",
        "8. i Firstly, preference description DN is updated according to P(nj) by applying Commit(nj, DN ), if n j expresses a new preference.",
        "If not go to step (ii).",
        "ii.",
        "Secondly, description DN is modified so that each variable in P(ni) depends on each variable in P(nj): i.e., VX e Var(P(m)), VY e Var(P(nj)), Y e Pa(X).",
        "Then, DN is enriched according to P(ni), if ni expresses a preference.",
        "If it does not, then end.",
        "We now give some details concerning step (ii) above.",
        "To this end, let >> denote a formula with SDRS description predicates, (j)' its corresponding boolean (preference) formula and (j)' its negation.",
        "Then for § = Y, we define (j)' = Y and (j)' = Y; for § = Y i – > Z we define = Y A Z and (j)' = Y V Z; and for § = Y y Z and § = Y&Z, we have cj>' = YVZmdf = YAZ.",
        "a. X (P(ni ) ) and >> (P(nj ) ).",
        "The agent explains his preferences on X by | .",
        "So, if no preferences on X are afready defined, is a reason to prefer X.",
        "That is, DN h f : X y X(CPT(X)).",
        "However, it is not possible to define preferences on X if >> is false.",
        "If, on the other hand, preferences on X are already defined, the agent prefers X if >> is satisfied, and does not modify his preferences otherwise – i.e., yX = X y",
        "For >> = Y, if yX is not already defined, we obtain the following preference relation (no information on the preference for X if Y is false makes XY and XIincomparable):",
        "b. X y Z^dn-)) and >|>(P(rcj)).",
        "The agent explains his preferences X y Z by >>: he wants to satisfy X or Z if >> is satisfied.",
        "First, we set Var(Z) e Pa(Var(X)), Var(X) e Pa(Var(Z)).",
        "If yx is not already defined, we have: DN \\=<\\>'AZ: X ~x{CPT{X)), DN \\= AZ: XyX{CPT{X)).",
        "CPT (Z) is defined as CPT (X ) by inverting X and Z.",
        "For >> = Y, if yX and yZ are not already defined, we obtain the following preference relation (again, the lack of preference information on X and Z when Y is false yields incomparability among states whereY is false):",
        "XYZ^XYZ^XYZ XYZ XYZ XYZ",
        "c. X&Z(P(ni)) and >|>(P(rcj)).",
        "The agent explains his preferences on X&Z by >>.",
        "• If >-x is not already defined, we have: D N \\= <t>' : X yX(CPT(X)).",
        "Otherwise, yXtf = X yX, yx^= yx, by Z.• CPT (Z) is defined as CPT (X ) by replacing X",
        "d. X – Z^n-)) and >(P(nj)).",
        "The agent explains his preferences on X – Z by >>: he wants to satisfy X and after Z if >> is satisfied.",
        "e. \\|/(P(ni)) and >>(P(nj)).",
        "We can apply rules 8 by decomposing \\|/.",
        "f. 0(iy)(P(n)) and 0(>>)(P(nj)).",
        "We treat this like a free choice EDU (see rule 5).",
        "Let's briefly look at how the rule changes for Q-elabA(n1,n2) (where the subscript A identifies the speaker of n2):",
        "9.",
        "Q-ElabA(n1,n2) implies that we update A's CP-net description d n by applying the rule for Elab(n1, n2), where if n2 expresses no preferences on their own, we simply make the P(n2) description equal to the P( n1 ) description.",
        "Thus A s CP-net description is updated with the preferences expressed by utterance n1, regardless of who said n1.",
        "QAP Answers to questions affect preferences in complex ways:",
        "10.",
        "The first case concerns yes/no questions and there are two cases, depending on whether B replies yes or no:",
        "Yes QAPB (n1, n2) where n2 is yes.",
        "B's preference descriptions are updated by applying Commit(ElabB(n1,n2),DN) (and so B's preference description include preferences expressed by n1 and n2).",
        "No QAPB(n1,n2) where n2 is no.",
        "If P(n1) and P(n2) are consistent, then B s preference descriptions are updated by applying CommitB(ElabB(n1,n2), dn ); otherwise, they are updated by applying Commit (Correction^, n2), DN ) (see rule 13).",
        "11.",
        "When n1 is a wh-question and QAPB(n1,n2), B's preferences over variables in n1 and n2 are exactly the same as the ones defined for a yes/no question where the answer is yes.",
        "Variables in n2 will refine preferences over variables in n1.",
        "So, B 's preference descriptions are updated by applying CommitB (ElabB (n1, n2 ), dn ).",
        "In previous rules, it is relatively clear how to update the preference commitments.",
        "However, in some cases it ' s not clear what the answer in a QAP targets: in Could we meet the 25 in the morning?",
        "No, I can't., we do not know if No is about the 25 and the morning, or only about the morning.",
        "So, we define the following rule for managing cases where the target is unknown :",
        "12.",
        "If we know the target, we can change the description of the CP-net.",
        "Otherwise, we wait to learn more.",
        "Correction and Plan-Correction allow a speaker to rectify a prior commitment to preferences.",
        "Self-corrections also occur in the corpus: I could do it on the 27th.",
        "No I can not make it on the 27th, sorry I have a seminar.",
        "Correction and Plan-Correction can have several effects on the preferences.",
        "For instance, they can correct preference entries.",
        "That is, given Correction^,n2), some variables in P(n1 ) are replaced by variables in P(n2) (in the self-correction example, every occurrence of 27 in P(%i ) is replaced with 27 and vice versa).",
        "We have a set of rules of the formX – {Y1,..., Ym}, which means that the variable X e Var(P(n1)) is replaced by the set of variables {Y1,..., Ym} Ç Var(P(n2)).",
        "We assume that X can ' t depend on {Y1,..., Ym} before the Correction is performed.",
        "Then replacement proceeds as follows:",
        "13.",
        "If Pa(X) = 0, we add the description dn \\=Yky Y_k{CPT{Yk)) forall fc e {1,... ,m} and removed y X(CPT(X)) (orX yX{CPT{X))).",
        "Otherwise, we replace every description of CPT (X ) with an equivalent statement using Yk (to describe CPT(Yk)), for all k e {1,... m}.",
        "The specific target of the correction behaves similarly to the target of a QAP.",
        "In some cases we don t know the target, in which case we apply rule 12.",
        "Plan-Correction can also lead to the modification of an agent s own plan because of other agent s proposals.",
        "In this case it corrects the list of parent variables on which a preference depends.",
        "We call that list of variables the operative variables.",
        "Once the operative variables are changed, Plan-Correction can elaborate a plan if some new preferences are expressed.",
        "For example, all agents have agreed to meet next week, so in their CP-net description, there is the entry Weekl >- Weekl.",
        "Then discussion shows that their availabilities are not compatible and one of them says \"okay, that week is not going to work.\".",
        "That does not mean the agent prefers Weekl to Weekl because both agreed on Week1 as preferable.",
        "Rather, Week1 has been removed as an operative variable in the following discourse segments.",
        "This leads us to the following rule:",
        "14.",
        "For Plan-Correction^,n2) which corrects the list of parent variables, the operative variable list becomes the intersection of all Pa(X) where X e Var( P( n1 )) .",
        "We can now apply Commit(Plan-Elab(n1,n2), dn ), if P(n2) contains some new preferences > .",
        "If the CPT affected by a rule has no entry for the current operative variable list o, then o : >> has to be added to dn.",
        "Continuation, Contrast and Q-Cont pattern with the rule for Elab.",
        "Alternation patterns with rule 8.b.",
        "Explanation, Explanation*, Result, Qclar (clarification question), Commentary, Summary and Acknowledgment either do nothing or have the same effect on preference elicitation as Elab.",
        "Sometimes, adding these preferences via the Elab rule may yield an unsatisfiable CP-net description, because an implicit correction is involved.",
        "If an evaluation of the CP-net (see next section) is performed after a processing of one of these rules shows that the CP-net description is not satisfiable, then we apply the rule 13, associated with Correction."
      ]
    },
    {
      "heading": "6. From Descriptions to Models",
      "text": [
        "Each dialogue turn adds constraints monotonically to the descriptions of the CP-nets to which the dialogue participants commit.",
        "We have interpreted each new declared variable in our rules as independent, which allows us to give a domain independent description of preference elicitation.",
        "However, when it comes to evaluating a CP-net description for satisfiability, we need to take into account various axioms about preference (irreflexivity and transitivity), and axioms for the domain of conversation: in our case, temporal designations (Wednesdays are not Tuesdays and so on).",
        "This typically adds dependencies among the variables in the description.",
        "In the case of the Verbmobil domain, since the variable Monday means essentially \"to meet on Monday\", Monday implies Meet, and this must be reflected via a dependency in the CP-net: we must view the variable Meet as filling a hidden slot in the variable Monday in the preference description, Meet : Mon >- Mon.",
        "This likewise allows us to fill in the negative clauses of the CP-net description: we can now infer that Meet : Mon >- Mon.",
        "These axioms also predict certain preference descriptions to be unsatisfiable.",
        "For instance, if we have Mon >- Mon, our axioms imply Mon >- Tues, Mon y Wed, etc.",
        "At this point we can calculate, ceteris paribus, inconsistencies on afternoons and mornings of particular days.",
        "Domain knowledge also allows us to collapse Boolean valued variables that all denote, say, days or times of the day into multiple valued variables.",
        "So for instance, our domain independent algorithm from dialogue moves to preference descriptions might yield:",
        "Domain knowledge collapses all Boolean variables for distinct days into one variable with values fordays to get:",
        "This leads to a sizeable reduction in the set of variables that are used in the CP-net.",
        "We can test any CP-net description for satisfiability by turning the description formulas into CP-net entries.",
        "Our description automatically produces a directed graph over the parent variables.",
        "We have to check that the y statements form an irreflexive and transitive relation and that each variable introduced into the CP-net has a preference entry consistent given these constraints.",
        "If the description does not yield a preference entry for a given variable X, we will add the indifference formula X ~ X as the entry.",
        "If our CP-net description meets these requirements, this procedure yields a minimal CP-net.",
        "Testing for satisfiability is useful in eliciting preferences from several discourse moves like Explanation, Qclar or Result, since in the case of unsatisfiability, we will exploit the Correction rule 13 with these moves."
      ]
    },
    {
      "heading": "7. Evaluation of the proposed method",
      "text": [
        "We evaluate our method by testing it against the judgments of three annotators on three randomly chosen unseen test dialogues from the Verbmobil corpus.",
        "The test corpus contains 75 edus and the proportion of discourse relations is the same as in the corpus overall.",
        "The three annotators were naive in the sense that they were not familiar with preference representations and preference reasoning strategies.",
        "For each dialogue segment, we checked if the judges had the same intuitions that we did on: (i) how commitments to preferences are extracted from edus, and (ii) how preferences evolve through dialogue exchange.",
        "The judges were given a manual with all the instructions and definitions needed to make the annotations.",
        "For example, the manual defined preference to be \"a notion of comparison between one thing at least one other\".",
        "The manual also instructs annotators to label each edu with the following four bits of information: (1) preferences (if any) expressed in the edu; (2) dependencies between preferences expressed in the edu; (3) dependencies between preferences in the current edu and previous ones; and (4) preference evolution (namely, the appearance of a new factor that affects preferred outcomes, update to preferences over values for an existing factor, and so on).",
        "For each of these four components, example dialogues were given for each type of decision they would need to make, and instructions were given on the format in which to code their judgements.",
        "Appendix A shows an example of an annotated dialogue.",
        "Table 2 presents results of the evaluation of (i).",
        "For each edu, we asked the annotator to list the preferences expressed in the edu and we compared the preferences extracted by each judge with those extracted by our algorithm.",
        "The triple (a, b, c) respectively indicates the proportion of common preferences (two preference sets riand Tj are common if (Ti = Tj ) or (3x e Ti, y e Tj, x – y) – for example, the preference MeetBefore2 >- MeetAtl implies MeetAt2 >- MeetAt2), the proportion of preferences that one judge extracts and the other judge or our algorithm misses and the proportion of preferences missed by one judge and extracted by the other judge or by our algorithm.",
        "The average annotator-algorithm agreement (AAA) is 75.6% and the average inter-annotator agreement (IAA) is 77.9%; this shows that our method for extracting preferences from edus is reliable.",
        "The evaluation (ii) proceeds as follows.",
        "For each edu, we ask the judge if the segment introduces new preferences or if it updates, corrects or deletes preferences commited in previous turns.",
        "As in (i), judges have to justify their choices.",
        "Table 3 presents the preliminary results where the couple (a,b) indicates respectively the proportion of common elaborations (preference updates or new preferences) and the proportion of common corrections.",
        "Since elaboration is also applied in case of other discourse relations (e.g., Q-Elab), the measure a evaluates the rules 8, 9, 10 (yes) and 11.",
        "Similarly, the measure b evaluates the rules 10 (no), 13 and 14.",
        "We obtain AAA=91% IAA=92.7% for elaboration and AAA=85.7% IAA=81% for correction."
      ]
    },
    {
      "heading": "8. Conclusion",
      "text": [
        "We have proposed a compositional method for eliciting preferences from dialogue consisting of a domain-independent algorithm for constructing a partial CP-net description of preferences, followed by a domain-specific method for identifying the minimal CP-net satisfying the partial description and domain constraints.",
        "The method supports qualitative and partial information about preferences, with CP-nets benefiting from linear algorithms for computing the optimal outcome from a set of preferences and their dependencies.",
        "The need to compute intentions from partially defined preferences is crucial in dialogue, since preferences are acquired and change through dialogue exchange.",
        "Our work partially confirms that CP-nets have a certain naturalness, as the map from dialogue moves to preferences using the CP-net formalism is relatively intuitive.",
        "The next step is to implement our method.",
        "This depends on extracting discourse structure from text, which, though difficult, is becoming increasingly tractable for simple domains (Baldridge and Lascarides, 2005b).",
        "We plan to extract CP-net descriptions from edus and to evaluate these descriptions using \"multi-valued variables\" automatically.",
        "We will then evaluate our method on a large number of dialogues.",
        "Our work here is also and more generally a first step towards modelling the complex interaction between what agents say, what their preferences are, and what they take the preferences of other dialogue agents to be.",
        "It leads to a conception of dialogue that s more general than one based purely on Gricean cooperative principles (Grice, 1975).",
        "On a purely Gricean approach, conversation is cooperative in at least two ways: a basic level concerning the conventions that govern linguistic meaning (basic cooperativity); and a level concerning shared attitudes towards what is said, including shared intentions (content cooperativity).",
        "While basic cooperation is needed for communication to work at all, content cooperativ-ity involves strongly cooperative axioms like Coopera-tivity (interlocutors normally adopt the speaker s intentions) (Allen and Litman, 1987, Grosz and Sidner, 1990, Lochbaum, 1998).",
        "Our approach allows for divergent preferences and divergent intentions, i.e. conversations that aren t based on content cooperativity.",
        "This will allow us to exploit information about conflicting agents ' preferences and game-theoretic techniques that are inherent in the logics of CP-nets for computing optimal moves (Bonzon, 2007).",
        "And in contrast to Franke et al.",
        "(2009), who analyse conversations where content cooperativity doesn t hold using a game-theoretic framework, our approach allows for partial and qualitative representations of preferences rather than demanding complete and quantitative representations of them.",
        "Our algorithm",
        "Jl",
        "J2",
        "J3",
        "% of e dus that commit to preferences",
        "Our algorithm",
        "(83,4, 13)",
        "(91,0, 9)",
        "(91,0, 9)",
        "76%",
        "Jl",
        "(83, 13, 4)",
        "(85, 7, 8)",
        "(91,4, 5)",
        "80%",
        "J2",
        "(91,9, 0)",
        "(85, 8, 7)",
        "(92, 4,4)",
        "86%",
        "J3",
        "(91,9, 0)",
        "(91,5, 4)",
        "(92, 4,4)",
        "84%",
        "Our algorithm",
        "Jl",
        "J2",
        "J3",
        "Our algorithm",
        "(85,71)",
        "(96, 100)",
        "(93, 86)",
        "Jl",
        "(85,71)",
        "(89,71)",
        "(91, 86)",
        "J2",
        "(96, 100)",
        "(89,71)",
        "(98, 86)",
        "J3",
        "(93, 86)",
        "(91, 86)",
        "(98, 86)",
        "We illustrate in this section how our rules work on an example.",
        "Since this dialogue was also evaluated by our judges (cf section 7), we give where relevant some details on those annotations.",
        "The example is as follows:",
        "n2.",
        "A: how long do you think it should be for.",
        "n3.",
        "B: well, I think we have quite a bit to talk about.",
        "n7.",
        "A: but, let us do it anyways.",
        "n8.",
        "B: okay, do you have any time next week?",
        "n9.",
        "B: I have got, afternoons on Tuesday and Thursday.",
        "n10.",
        "A: I am out of Tuesday Wednesday Thursday, n11.",
        "A: so, how about Monday or Friday",
        "Table 4 is the dsdrs associated with (6).",
        "Relation(ni, [nj - nk]) indicates that a rhetorical relation holds between the segment ni and a segment consisting of nj, n ..., nk n1 provides an atomic preference.",
        "We apply the rule 1 and so Commita(%i, ®Na) adds the description Vît a h M >- M(CPT(M)) where M means Meet.",
        "n2 We have Q-Elab(n1, n2).",
        "A continues to commit to M in n2 and no new preferences are introduced by n2.",
        "We apply rule 9, which makes the P(n2) description the same as P(n1) s.",
        "n3 is linked to n2 with QAP.",
        "B accepts A s preference and we apply the rule 11 since n2 is a wh-question.",
        "Thus CommitB(ElabB(%2,%3),(DNb) adds the description DNb h M >- M(CPT(M)).",
        "It is interesting to note that some judges consider that agent s utterance in n3 indicates a preference towards \"talking a long time\" while other judges consider, as our method predicts, that this segment does not convey any preference.",
        "n4 is linked to n3 by Q-Elab.",
        "B commits to a new preference.",
        "We apply rule 9, rule 8 and then rule 8.a.",
        "The preference on the hour is now dependent on the preference on meeting; i.e., DN.b \\= M : 2h y 2h(CPT(2h)), where the variable 2h means two hours.",
        "n5 is related to n4 with the Q-Cont relation.",
        "We then follow the same rule as the continued relation, namely Q-Elab.",
        "We apply rule 9 which does not change the CP-net description of B because n5 does not convey any preference.",
        "n6 is related to n5 with QAP relation.",
        "In this case, it s not clear what is the QAP target and so we apply rule 12: we wait to learn more and we do not change B's CP-net description.",
        "All the Judges indicated that segments n5 and n6 are ambiguous and therefore hesitated to say if they commit to preferences.",
        "For example in n6, do we have a preference for meeting more than 2 hours or less than 2 hours?",
        "This indecision is compatible with the predictions of rule 12.",
        "n7 A accepts B s preference.",
        "We apply rule 9 and then rule 8 to obtain:",
        "®9£A \\=M yM(CPT(M)), D9iA ^M:2hy2h(CPT(2h)).",
        "n8 is linked to n7 by Q-Elab.",
        "B introduces a new preference for meeting next week.",
        "We apply rule 9 and then 8 to obtain:",
        "V9£B \\=M yM(CPT(M)), D9iB ^M:2hy2h(CPT(2h)), D9iBhMA2h-NW >- ~NW(CPT (NW)) where the variable NW means next week.",
        "n9 is linked to n8 by Plan-Elab.",
        "n9 expresses commitments to preference that already involve a CP-net description.",
        "B introduces three preferences: one for meeting on Tuesday, the other for meeting on Thursday and given the conjunction of preferences Tues A Thurs, one for time afternoon (of Tuesday and Thursday).",
        "That is, ((O(Tues) A O(Thurs)) – Aft)(P(n9,)).",
        "We apply the equivalence (3) and obtain : (0(Tuesy Thurs) – Aft)(P(n9)).",
        "Then, we apply rules 8.g, 8.b and 8.d.",
        "The CP-net description of B is thus updated as follows: D9iB |= M A 2h A NW A Tues : Thurs y Thurs(CPT (Thürs)),",
        "D9jB |= M A 2h A NW A Tues : Thurs ~ Thurs(CPT(Thurs)), D9iB |= M A 2h A NW A Thurs : Tues y Tues(CPT(Tues)), 'D9lB \\= M A 2h A NW A (Thurs V Tues) : Aft y Äft(CPT(Aft)).",
        "Most judges express here a preference ranking over outcomes.",
        "For instance, if B elaborates by adding the preference \"I have got Monday morning too\" (as it is in the test corpus), some consider the ranking \"(Tuesday or Thursday afternoons) y (Monday morning) >- (other days)\", while others consider the ranking \"(Tuesday or Thursday afternoon) or (Monday morning) >- (other days)\".",
        "We did not treat such preference ranking.",
        "n1o is related to n9 by QAP where A answers no to B 's question asked in 7is.",
        "We apply rule 10 (no).",
        "Since Tues&Weds&Thurs(P(%io)) is not consistent with ((O(Tues) A O(Thurs)) – Aft)(P(n9)), we apply CommitA(Correction(n9,n10),DNA), which adds the preference Weds to A ' s description and then the rule 13 where Tues and Thurs are respectively replaced by Tues and Thurs : ®NA \\= M A2h ANW : Tues >- Tues(CPT(Tues)), DNa h M A 2h A NW : Thurs y Thurs(CPT (Thurs)), Weds(CPT(Weds)).",
        "n11 Finally, this segment is linked to n10 with Q-Elab where Mond y Fri(P(n11)).",
        "We apply rules 9 and 8.b and update A's CP-net description as follows:",
        "DNa \\=MA2hANWATuesAThursAWedsAFri:",
        "DNa h M A 2h A NW A Tues A Thurs A Weds A DNa h M A 2h A NW A Tues A Thurs A Weds A Mond : F ri - Fri(CPT(Fri)).",
        "The evaluation of this dialogue also reveals to what extent naive annotators reason with binary (Monday preferred to not Monday) or multivalued variables (Monday preferred to Tuesday).",
        "Most judges use multivalued variables to express the preference extracted from an edu, and the way in which our method exploits domain knowledge to yield the minimal CP-net satisfying the description reflects this.",
        "In addition, some judges use a small set of variables (for example the variable time of meeting that groups together the notion of week, day, hours, etc.)",
        "while others use a distinct variable for each preference.",
        "Finally, we also noticed that judges do not describe the same preference dependencies.",
        "For example, in:",
        "(7) We could have lunch together and then have the meeting from one to three?",
        "some consider that the preference on having lunch is independent from the preference on the meeting (in this case, they consider that the preference on the period one to three is independent from the preference on meeting) while others consider that the two preferences are dependent.",
        "Turn",
        "A's sdrs",
        "B'S sdrs",
        "1",
        "7tiA : Q-Elab(%i,%2)",
        "0",
        "2",
        "%iA-is the same as in turn 1",
        "7i2B : Q-Elab(%u [%2 -7i5]) AßAP(7i2, [713 -7i5])A",
        "Q-Elab(%3,%) 71 : Q-Cont(714,715)",
        "3",
        "%3a : Q-Elab(%u[%2-K7}) A gAP(7i2, N -7i7])A",
        "Q-Elab(%3, [714,717]) A QAP(%,%') 71 : Q-Cont(%4,ii5),ii' : Contrast^,717)",
        "7I2b: is the same as in turn 2",
        "4",
        "%3a: is the same as in turn 3",
        "7i4B : Q-Elab(%i, [%2 -7i9]) AßAP(7i2, [713 -7i9])A Q-Elab(%3, [714 -719]) A ßAP(7i, [%6-%ç>])A Q-Elab(%',%\")",
        "71 : ß-Co«f(7i4,7i5),7i' : Contrast(%ß,iij)",
        "71\" : Plan-Elabiji%^)",
        "5",
        "%5a : Q-Elab(%i, [%2-%n]) A gAP(7i2, [7i3 -7in])A Q-Elab(%3, [7t4 -Ttn]) A gAP(7i, [7t6 -7in])A Q-Elab(%>, [Tig -Tin]) A gAP(7l\",7l'\") 71 : Q-Cont(%4,ii5),ii' : Contrast^,717) 71\" : Plan-Elab(%8,%9): Q-Elab(%io,Kn)",
        "%4b: is the same as in turn 4"
      ]
    }
  ]
}
