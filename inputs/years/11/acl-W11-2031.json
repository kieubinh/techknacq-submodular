{
  "info": {
    "authors": [
      "Eliza Margaretha",
      "David DeVault"
    ],
    "book": "Proceedings of the SIGDIAL 2011 Conference",
    "id": "acl-W11-2031",
    "title": "An Approach to the Automated Evaluation of Pipeline Architectures in Natural Language Dialogue Systems",
    "url": "https://aclweb.org/anthology/W11-2031",
    "year": 2011
  },
  "references": [
    "acl-N09-2014",
    "acl-P97-1035"
  ],
  "sections": [
    {
      "text": [
        "Eliza Margaretha* and David DeVault",
        "USC Institute for Creative Technologies, 12015 Waterfront Dr., Playa Vista, CA 90094",
        "We present an approach to performing automated evaluations of pipeline architectures in natural language dialogue systems.",
        "Our approach addresses some of the difficulties that arise in such automated evaluations, including the lack of consensus among human annotators about the correct outputs within the processing pipeline, the availability of multiple acceptable system responses to some user utterances, and the complex relationship between system responses and internal processing results.",
        "Our approach includes the development of a corpus of richly annotated target dialogues, simulations of the pipeline processing that could occur in these dialogues, and an analysis of how system responses vary based on internal processing results within the pipeline.",
        "We illustrate our approach in two implemented virtual human dialogue systems."
      ]
    },
    {
      "heading": "1. Introduction",
      "text": [
        "Natural language dialogue systems are typically implemented as complex modular systems, with a range of internal modules performing tasks such as automatic speech recognition (ASR), natural language understanding (NLU), dialogue management (DM), natural language generation (NLG), and speech synthesis (TTS).",
        "A common design is for systems to adopt a pipeline architecture.",
        "In a pipeline, each user utterance is processed in a series of successive processing steps, with the output of each module serving as the input of the next module, until the system's response is determined.",
        "* Now at Saarland University, Germany.",
        "While there are many approaches to dialogue system evaluation (see e.g. (Walker et al., 1997; Eckert et al., 1997; Walker, 2005)), in many ways, the primary data for assessing the performance of a dialogue system comes from the collection of live interactive dialogues between an implemented system and members of its intended user population.",
        "Yet, live dialogue-based evaluation suffers from a number of limitations and drawbacks.",
        "Each dialogue set can be expensive and time-consuming to collect, and may only reflect a specific version of a system under active development.",
        "Additional effort is also generally necessary to identify specific system responses as problematic or unacceptable.",
        "Further annotation and analysis is then necessary to diagnose and pinpoint the cause of the problematic responses, so that the relevant pipeline module(s) may be improved.",
        "In this paper, we present and discuss an approach to performing automated evaluations of pipeline architectures.",
        "Our approach involves the development of a corpus of annotated target dialogues, starting from Wizard-of-Oz data.",
        "Our automated evaluation assesses the support for these target dialogues in a pipeline system architecture.",
        "It is not designed as a substitute for live system evaluations, but rather as a complement to them which may help to alleviate some of these challenges to understanding system performance and streamlining development.",
        "In particular, unlike the PARADISE framework (Walker et al., 1997), which aims to evaluate dialogue agent strategies – by relating overall user satisfaction to various other metrics (task success, efficiency measures, and qualitative measures) – our approach takes the agent's dialogue strategy for granted (in",
        "typed system utterance NLU speech act DM (speech act)",
        "the form of a set of target dialogues that exemplify the desired strategy), and instead zooms in and aims to directly evaluate the dialogue system's module pipeline.",
        "Specifically, our approach quantifies the ability of the pipeline to replicate the processing steps needed to reproduce a set of target responses.",
        "In our analysis, we place a special emphasis on the possible lack of consensus among human annotators about what the processing results should be.",
        "We do not aim to further analyze the system's live dialogue behavior in terms of user satisfaction, task success, or other global measures."
      ]
    },
    {
      "heading": "2. Research Setting",
      "text": [
        "The work presented in this paper has been designed to support the dialogue behavior of two virtual human systems, the SimCoach and Tactical Questioning (TACQ) systems.",
        "SimCoach (Rizzo et al., 2011) is an ongoing project aiming at empowering military personnel and their significant others with online healthcare assistance for Post-Traumatic Stress Disorder (PTSD), depression, and family-related problems.",
        "The SimCoach character encourages users to talk about any concerns or problems they may have.",
        "TACQ (Gandhe et al., 2008) is designed to support simulation and training for tactical questioning skills, and provides virtual humans who have information but will not answer certain questions unless the user cooperates by agreeing to their requests, offering promises in their favor, and so on.",
        "In this work, we have developed target dialogues for the Amani character, who has been an eyewitness of a recent shooting incident.",
        "For simplicity, in the experiments reported in this paper, we have used simplified versions of these two dialogue systems.",
        "The simplification removes ASR from TACQ, and removes NLG and TTS from both systems.",
        "This yields a simple two-module pipeline architecture that we depict in Figure 1.",
        "Note that the input to NLU is a typed English utterance, and the output of the NLU module (also the input to the DM module) is a speech act representation.",
        "The output of the DM, which we treat here as the system's response to the user, is also a speech act representation.",
        "Both of these systems use statistical classification models for NLU (Leuski and Traum, 2010; Sagae et al., 2009), and finite state machine models for DM (Gandhe et al., 2008; Rizzo et al., 2011)."
      ]
    },
    {
      "heading": "3. Target Dialogues",
      "text": [
        "Target dialogues are annotated versions of dialogues a system designer would like the system to support.",
        "Wizard-of-Oz (WoZ) and role play dialogues provide valuable data to designers of dialogue systems, especially in the form of natural dialogue data and insights into human-level performance and strategies for the specific dialogue task.",
        "However, in practice, system builders may not be able to implement all of the strategies and competences of the wizards or role players, and simplifications may be needed.",
        "SimCoach target dialogues were developed from a collection of 10 WoZ dialogues in which clinicians (wizards) and veterans (users) interacted with each other.",
        "We also built Amani target dialogues for TACQ starting from 19 WoZ dialogues.",
        "Each user utterance and wizard's response was annotated with a target NLU speech act and one or more target DM speech acts (i.e., the system response).",
        "The 10 SimCoach target dialogues contain 376 user utterances and 547 target system response speech acts.",
        "The 19 Amani target dialogues contain 317 user utterances and 354 target system response speech acts.",
        "For excerpts of the SimCoach and Amani target dialogues, see Tables A.1 and A.2 in the Appendix.",
        "To create our target dialogues, we adjusted the WoZ dialogues to reflect a number of system design limitations as well as wizard deviations from the desired dialogue policy.",
        "These changes included removing unsupported wizard utterances and subdialogues, inserting or reordering system responses due to wizard mistakes, and introducing clarification subdialogues for unsupported user utterances.",
        "Let P = (pi, ...,pk) be the pipeline in a system containing k modules.",
        "We use St to denote the pipeline state, which includes the internal states of any modules that maintain an internal state, at time t.",
        "For a user input xt that occurs at time t, when the pipeline state is St, we write A(P,St,xt) = (yi,...,yk) to represent the actual sequence of outputs from the pipeline modules, where yi is the output of module pi for i = l...k.",
        "For a variety of reasons, these actual module outputs may differ from the target module outputs for this input and pipeline state.",
        "Let T(P, St,xt) = (z1,...,zk) be the target pipeline response to input xt, i.e. the sequence of target outputs from each of the pipeline modules.",
        "A target dialogue D = ((xi,Ti),(xn,Tn)), then, is a sequence of user inputs and corresponding target pipeline responses.",
        "Specifically, for time t = 1...N, Tt = T (P,S* ,xt) = (zi,...,zk ) is the target pipeline response to input xt, where St* is the target pipeline state at each time t.",
        "An important detail is that the target pipeline state S* is the state that the pipeline would be in if all previous user inputs had triggered exactly the target pipeline responses.",
        "Formally, let Si* be the initial state of the dialogue system pipeline.",
        "Then, let S*+1 = update(S*,xt,Tt), where we use an update function to capture the effect on the internal state of the pipeline of the target response Tt to xt.",
        "Note that the target pipeline state may differ from the actual pipeline state, if an actual pipeline response differs from the target pipeline response.",
        "For example, if a previous user utterance was misunderstood by an NLU module, then at run-time, the actual information state inside the DM module would reflect this earlier misunderstanding, while the target pipeline state would include a corrected version of the information state.",
        "Using corrected information states, and corrected pipeline states more generally, enables the utterances within a target dialogue to be considered independently in a pipeline evaluation.",
        "We can say that a pipeline P is compatible with a target dialogue D = ((xi,Ti),(xN,TN)) iff A(P,S**,xt)[k] = Tt[k] for all t = 1...N. In other words, for every user utterance, the actual system response, as emitted by the last (kth) module in the pipeline, matches the target system response.",
        "Both the SimCoach and TACQ pipelines are compatible in this sense with their target dialogues (Section 3.1).",
        "A considerable challenge in the improvement of pipeline performance is the lack of consensus about the desired internal processing steps: different system designers or human annotators often disagree about what the intermediate results should be.",
        "For example, in a system such as TACQ or SimCoach, there may be substantial disagreement among human annotators about the correct NLU output for each utterance; see e.g. (Artstein et al., 2009).",
        "Table 1 exemplifies 3 different possible NLU speech act annotations for a user utterance to SimCoach.",
        "Note that for the first two, the DM outputs the same system response (which incidentally is the target response).",
        "However, the third speech act yields a different response.",
        "In our automated evaluations, rather than trying to resolve all disagreements, our approach is to characterize the frequency with which these kinds of phenomena occur in the pipeline.",
        "To support this analysis, for a target dialogue D = ((xi,Ti),(xN,TN)), we assume then that each input xt is associated not only with the target pipeline response Tt, but also with a collection ofan-notations At = (ai,...,ak ).",
        "These annotations may be derived from a number of independent sources",
        "User Utterance",
        "NLU Speech Act",
        "DM Response",
        "Having difficulty sleeping... bad dreams.. Wake up a few times every night",
        "answer.observable.",
        "sleeping-problems",
        "question.",
        "depression-pre-",
        "check-list.1",
        "answer.observable.",
        "wakeup-generic",
        "question.",
        "depression-pre-",
        "check-list.1",
        "answer.observable.",
        "wakeup-nightmare",
        "question.",
        "ptsd-pre-checklist.1",
        "S = {si,si], and we write ai(s) = wi to denote the correct output wi for module pi according to annotation source s G S. These independent \"annotation sources\" might be human annotators, or competing module algorithms, for example.",
        "We can then capture the hypothetical effect of using annotation source s in place of some module pi within the pipeline.",
        "To do so, we consider the effect of replacing the output of module pi with ai(s), and using this as the input to subsequent modules in the pipeline.",
        "Let Pik+i = (pi+i, ...,pk) be the remainder of the pipeline, starting at module pi+i.",
        "For input xt, we can notate the hypothetical pipeline response, if module i were replaced by annotation source s, by H(P+i, S*, a;(s)) = (ym,yk).",
        "We will write hf^ for the hypothetical system response to the user input at time t, if source s were substituted for the output of module i: h°v = H(Pf+1, St*, a*(s))[k] = yk.",
        "For a target dialogue of length N, we can summarize the frequency with which the hypothetical pipeline response would match the target system response by a performance measure:",
        "Pstrict = n ]C match(hsV,Tt[k])",
        "A second form of lack of consensus issue is the existence of multiple acceptable system responses within a system.",
        "Returning to the example in Table 1, system designers might decide that either of the two system responses here would be acceptable.",
        "In some cases, actual NLU outputs which differ from the target NLU output will simply result in the system giving alternative acceptable system responses, as in this example.",
        "In other cases, they may lead to unacceptable system responses.",
        "We measure the frequency with which these phenomena occur as follows.",
        "For a target dialogue D = ((xi, Ti),(xN,TN)), let each input xt be associated with a set Rt = {ri,rm] of system responses which differ from the target system response Tt[k], but are also acceptable in design terms.",
        "Given these alternative responses, we can then define a more permissive performance measure:",
        "match(h?\\i,Tt[k],Rt) = I 1 if G Rt .",
        "[ 0 otherwise"
      ]
    },
    {
      "heading": "4. Results",
      "text": [
        "We collected a range ofannotations for the 19 TACQ Amani target dialogues, including 6 sources of NLU speech acts for the 317 user utterances: target (the target NLU speech act for each utterance); 3 independent human annotations of the best NLU speech act for each utterance; humanan (a set containing all of the alternative acceptable NLU speech acts for each utterance, according to the same single researcher who prepared target); and NPCEditor, the NLU speech act output from NPCEditor (Leuski and",
        "Traum, 2010), the NLU module for TACQ.",
        "We analyzed the effect of differing NLU speech act sources on the responses given by the system.",
        "We present the results in Table 2.",
        "(For a detailed processing example, see Table A.2 in the Appendix.)",
        "The first (leftmost) column of numbers shows the percentage of NLU speech acts from each source that are identical to the target NLU speech act.",
        "These results highlight how human annotators do not always agree with each other, or with the target.",
        "The agreement among the human annotators themselves, measured by Krippendorf's alpha (Krippendorff, 2007) is 0.599 (see also (Artstein et al., 2009)).",
        "In the second column of numbers, we tabulate the frequency with which the NLU speech acts are present in humanan.",
        "While these numbers are higher, they do not reach 100% for the human annotators, suggesting that a single annotator is unlikely to be able to circumscribe all the NLU speech acts that other annotators might find acceptable.",
        "NLU",
        "Percent of NLU",
        "Percent of system",
        "speech act",
        "speech acts",
        "response speech",
        "source",
        "identical to...",
        "acts identical to...",
        "(N=317)",
        "(N=354)",
        "the",
        "the target",
        "a target",
        "a target or",
        "target",
        "or other",
        "system",
        "acceptable",
        "NLU",
        "acceptable",
        "response",
        "system",
        "speech",
        "NLU",
        "speech",
        "response",
        "act",
        "speech act",
        "act",
        "speech act",
        "(target)",
        "(humanaii)",
        "target",
        "100%",
        "100%",
        "99.4%",
        "100%",
        "humani",
        "79.3%",
        "95.4%",
        "84.2%",
        "88.4%",
        "human2",
        "76.7%",
        "99.7%",
        "86.7%",
        "93.8%",
        "human3",
        "59.3%",
        "90.2%",
        "69.6%",
        "78.8%",
        "NPCEditor",
        "42.3%",
        "50.5%",
        "55.3%",
        "57.4%",
        "Despite the frequent disagreements among human annotators, this evaluation shows that the impact on the target system responses is less than might be expected.",
        "In the third column of numbers, we calculate Pstrict which measures the effect of using each of NLU sources, in place of the NLU module's actual output, on the pipeline's ability to produce the target response.",
        "As the table implies, the pipeline often produces the target system response (third column) even when the NLU source disagrees with the target (first column).",
        "Indeed, for all the NLU sources except for target, the pipeline is significantly more likely to produce the target system response than the NLU source is to produce the target NLU speech act (Wilcoxon test, p < 0.001 for each source).",
        "We also calculate Pmultiple (last column) which measures the effect of using each NLU source on the pipeline's ability to produce either the target or any other acceptable system response.",
        "As the table shows, the actual system responses are often acceptable when they differ from the target responses.",
        "Although this effect seems weaker for NPCEditor, Wilcoxon tests reveal that for every source other than target, the differences between Pstrict and Pmultiple are significant at p < 0.005.",
        "This evaluation confirms that the pipeline is significantly more likely to deliver an acceptable system response than a target response, and helps quantify to what extent NLU outputs that differ from the target remain problematic for the pipeline performance.",
        "We gathered a set of annotations for the 10 Sim-Coach target dialogues, including 3 sources of NLU speech acts for the 376 user utterances: target, humani , and mxNLU (the NLU speech act output from mxNLU (Sagae et al., 2009), the NLU module for SimCoach).",
        "We present the evaluation results in Table 3.",
        "As the table shows, our independent human annotator often disagreed with the target NLU speech act.",
        "Despite the 72.1% agreement rate, the system's response to the human NLU speech act agreed with the target response 93.3% of the time.",
        "In comparison, mxNLU shows somewhat higher agreement (75.3%) with the target NLU annotation.",
        "While this might at first suggest \"super-human\" NLU performance, in reality it is because the target NLU annotation was constructed in very close consultation with the training data for mxNLU.",
        "Despite showing higher agreement with target NLU speech acts, the system responses were not more likely to match the target system responses with mxNLU.",
        "The explanation is that disagreements for mxNLU were more serious, reflecting more misunderstandings and failures to understand than occur with a human annotator, and more deviations from the target responses.",
        "This highlights the value of looking beyond the performance of individual modules."
      ]
    },
    {
      "heading": "5. Conclusions and Future Work",
      "text": [
        "We have presented an approach to performing automated evaluations of pipeline architectures, and demonstrated its application in two implemented virtual human dialogue systems.",
        "The pipeline evaluation provided several insights into the current pipeline performance, including what performance would be attainable if human-level NLU were possible.",
        "In future work, we would like to expand beyond our simplified two-module pipeline, and investigate the connection between our automated pipeline evaluations and performance in live dialogues."
      ]
    },
    {
      "heading": "Acknowledgments",
      "text": [
        "We thank our reviewers, Sudeep Gandhe, Fabrizio Morbini, and David Traum.",
        "The project effort described here has been sponsored by the U.S. Army Research, Development, and Engineering Command (RDECOM).",
        "Statements and opinions expressed do not necessarily reflect the position or the policy of the United States Government, and no official endorsement should be inferred.",
        "NLU speech",
        "NLU speech acts",
        "System response",
        "act source",
        "identical to target",
        "speech acts identical",
        "(N = 376)",
        "to target (N = 547)",
        "target",
        "100%",
        "100%",
        "human i",
        "72.1%",
        "93.3%",
        "mxNLU",
        "75.3%",
        "91.1%",
        "t",
        "User Utterance",
        "Target NLU Speech Act (t1)",
        "Target System Response (t2)",
        "Textual Version of Target System Response",
        "9",
        "my husband seems distant, and we have been arguing a lot more lately",
        "answer.observable.",
        "family-problem",
        "question.bio-info.",
        "has-kids",
        "Does he have children?",
        "10",
        "yes, 2",
        "answer.yes",
        "question.family-pre-checklist.6",
        "In his family, do people collaborate together to find the best way to solve problems?",
        "t",
        "User Utterance",
        "Source of NLU Speech Act",
        "NLU Speech Act (gloss)",
        "System Response Speech Acts (gloss)",
        "1",
        "hi amani.",
        "NPCEditor",
        "hello",
        "hello",
        "target NLU",
        "hello",
        "hello",
        "2",
        "i wanted to talk to you about the recent shooting that occurred",
        "NPC Editor",
        "Tell me more about the_ incident",
        "location of the_incident is the_shop",
        "target NLU",
        "Is amani willing to talk?",
        "amani is willing to talk",
        "3",
        "do you know who was",
        "NPC Editor",
        "What is perpetrator of the_ incident ?",
        "perpetrator of the_incident is Saif",
        "responsible?",
        "target NLU",
        "What is name of strange_man ?",
        "player should offer 'give-safety'"
      ]
    }
  ]
}
