{
  "info": {
    "authors": [
      "Andrew Gordon",
      "Zornitsa Kozareva",
      "Melissa Roemmele"
    ],
    "book": "SemEval",
    "id": "acl-S12-1052",
    "title": "SemEval-2012 Task 7: Choice of Plausible Alternatives: An Evaluation of Commonsense Causal Reasoning",
    "url": "https://aclweb.org/anthology/S12-1052",
    "year": 2012
  },
  "references": [],
  "sections": [
    {
      "text": [
        "the defeasible inferences that can be drawn from the interpretation of a sentence.",
        "In this respect, COPA overlaps in its aims with the task of recognizing causal relations in text through automated discourse processing (e.g. Marcu, 1999).",
        "Some progress in automated discourse processing has been made using supervised machine learning methods, where system learn the lexical-syntactic patterns that are most correlated with causal relations from a large annotated corpus (Sagae, 2009).",
        "Lacking a dedicated training corpus, the COPA evaluation encourages competitors to capture commonsense causal knowledge from any available corpus or existing knowledge repository.",
        "3 SemEval-2012 Systems and Results The COPA evaluation was accepted as Task 7 of the 6th International Workshop on Semantic Evaluation (SemEval-2012).",
        "In several respects, the COPA evaluation was different than the typical shared task offered as part of this series of work-shops.",
        "First, the task materials were available and distributed long before the evaluation period be-gan, and there were published results of previous systems using this evaluation.1 Second, the task included no training data, only sets of development and test questions (500 each).",
        "Participants were encouraged to use any available text corpus or knowledge repositories in the construction of their systems.",
        "Success on the task would not be possible simply through the selection of machine learning algorithms and feature encodings.",
        "Instead, some creativity and ingenuity was needed to find a suitable source of commonsense causal information, and determine an automated mechanism for applying this information to COPA questions.",
        "Only one team successfully completed the task and submitted results during the official two-week SemEval-2012 evaluation period.",
        "This team was Travis Goodwin, Bryan Rink, Kirk Roberts, and Sanda M. Harabagiu from the University of Texas at Dallas, Human Language Technology Research Institute.",
        "This team submitted results from two different systems (Goodwin et al., 2012), which they described to us as follows: UTDHLT Bigram PMI: The team's first approach selects the alternative with the maximum Pointwise Mutual Information (PMI) statistic 1 http://www.ict.usc.edu/~gordon/copa.html (Church & Hanks, 1990) over all pairs of bigrams (at the token level) between the candidate alternative and the premise.",
        "PMI statistics were collected using 8.4 million documents from the LDC Giga-word corpus (Graff & Cieri, 2003).",
        "A window of 100 terms was used for finding pairs of co-occurring bigrams, and a window/slop size of 2 for the bigram itself.",
        "UTDHLT SVM Combined: The team's second approach augments the first by combining it with several other features and casting the task as a classification problem.",
        "To this end, they consider the PMI between events participating in a temporal link on a Time-ML annotated Gigaword corpus.",
        "That is, events that occur together frequently will have a higher PMI.",
        "They also consider the difference between the number of positive and negative polarity words between an alternative and premise using information from the Harvard Inquisitor.",
        "In addition, they used the count of matching cause-effect pairs extracted using patterns on dependency structures from the Gigaword corpus.",
        "Combining all of these sources of information, they trained a support vector machine (SVM) learning algorithm to classify the alternative that is most causally related to the premise.",
        "These systems were assessed based on their accuracy on the 500 questions in the test split of the COPA evaluation, presented in Table 1.",
        "Both systems significantly outperformed the random baseline (50% accuracy), but the gains seen in the second approach were not significantly different than those of the first.",
        "System Accuracy UTDHLT Bigram PMI 61.8% UTDHLT SVM Combined 63.4% Table 1.",
        "SemEval-2012 Task 7 system accuracy on 500 questions in the COPA test split 4 Comparison to Previous Results In order to better evaluate the success of these two systems, we compared these results with the published results of other systems that have used the COPA evaluation.",
        "Three other systems were con-sidered.",
        "PMI Gutenberg (W=5): Described in Roem-mele et al. (2011), this approach calculated the PMI between words (unigrams) in the premise and",
        "each alternative, and selected the alternative with the stronger correlation.",
        "The PMI statistic was calculated using every English-language document in Project Gutenberg (16GB of text), using a window of 5 words.",
        "PMI Story 1M (W=25): Described in Gordon et al. (2011), this approach was identical to that of Roemmele et al. (2011) except that the PMI statistic was calculated using a corpus of nearly one million personal stories extracted from Internet weblogs (Gordon & Swanson, 2009), with 1.9 GB of text.",
        "Using this corpus instead of Project Guten-berg, the best results were obtained by using a window of 25 words for the PMI statistic.",
        "PMI Story 10M (W=25): Also described in Gordon et al. (2011), this approach explores the gains that can be achieved by calculating the PMI statistic using a much larger corpus of weblog sto-ries.",
        "The story extraction technology used by Gordon and Swanson (2009) was applied to 621 million English-language weblog entries posted to the Internet in 2010 to create a corpus of 10.4 million personal stories (37GB of text).",
        "Again, the best results were obtained by using a window of 25 words for the PMI statistic.",
        "Table 2 compares the results of these three previous systems with the two SemEval-2012 sys-tems.",
        "Although the last two of these three previous systems achieved higher scores than both of the SemEval-2012 submissions, the differences are not statistically significant.",
        "System Accuracy PMI Gutenberg (W=5) 58.8% UTDHLT Bigram PMI 61.8% UTDHLT SVM Combined 63.4% PMI Story 1M (W=25) 65.2% PMI Story 10M (W=25) 65.4% Table 2.",
        "Comparison of SemEval-2012 Task 7 systems (in bold) with previously published results on the 500 questions in the COPA test split 5 Discussion The two systems from the University of Texas at Dallas make an important contribution to progress on open-domain commonsense reasoning.",
        "Some lessons are evident from the short descriptions of their systems that they provided to us.",
        "As in each of the previously successful systems, this team focused their efforts on calculating corre-lational statistics between words in COPA questions using very large text corpora.",
        "In this case, the Gigaword corpus is used, and the calculation is based on bigrams rather than unigrams.",
        "We believe that the content of the news articles that comprise the Gigaword corpus is a step further away from the concerns of COPA questions than both the Project Gutenberg corpus and the weblog story corpora used in previous efforts.",
        "Indeed, the gains achieved by Gordon et al. (2011) appear to be entirely due to the relationship between COPA questions and the personal stories that people write about in their public weblogs.",
        "However, the use of a large news corpus affords the use of more sophisticated analysis techniques that have been developed for this genre.",
        "Here, the Gigaword corpus is annotated using Time-ML relationships, which in turn are used to modify the PMI strength between words.",
        "The use of bigrams is an additional enhancement explored by this team, as is the casting of COPA questions as a classification task using a diverse set of lexical and discourse features.",
        "Such an approach can facilitate the combining of diverse systems in the future, where correlational statistics are gathered from a diverse set of text corpora, each suited for specific domains of COPA questions or yielding complimentary feature sets.",
        "Still, the modest COPA performance seen from all existing systems is somewhat discouraging.",
        "With the best systems performing in the 60-65% range, we remain much closer to random performance (50%) than human performance (99%).",
        "These results cast some doubt that the information necessary to answer COPA questions can be readily obtained from large text corpora.",
        "Certainly the use of simple correlational statistics between nearby words is not enough.",
        "In the best case, we might wish for perfect identification of causal relationships between events in an extremely large text corpus of narratives similar in content to COPA questions.",
        "Semantic similarity between these events and COPA sentences could be computed to gather evidence to select the best alternative.",
        "Even if it were possible to achieve this ideal, it is difficult to imagine that such an approach could mirror human performance on this task.",
        "To move closer to human performance, systems may need to stretch beyond corpus statistics into"
      ]
    }
  ]
}
