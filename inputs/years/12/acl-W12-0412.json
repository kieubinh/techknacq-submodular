{
  "info": {
    "authors": [
      "Siegfried Ludwig Sporer"
    ],
    "book": "Proceedings of the Workshop on Computational Approaches to Deception Detection",
    "id": "acl-W12-0412",
    "title": "Making the Subjective Objective? Computer-Assisted Quantification of Qualitative Content Cues to Deception",
    "url": "https://aclweb.org/anthology/W12-0412",
    "year": 2012
  },
  "references": [],
  "sections": [
    {
      "text": [
        "Proceedings of the EACL 2012 Workshop on Computational Approaches to Deception Detection, pages 78?85, Avignon, France, April 23 - 27 2012. c?2012 Association for Computational Linguistics Making the Subjective Objective?",
        "Computer-Assisted Quantification of Qualitative Content Cues to Deception Siegfried L. Sporer Department of Psychology and Sports Science University of Giessen, Germany Siegfried.L.Sporer@psychol.uni-giessen.de Abstract Research syntheses suggest that verbal content cues are more diagnostic than other cues in discriminating between truth and deception.",
        "In many studies on content cues, raters are trained to rate the presence of specific content cues, an inherently subjective process.",
        "This necessitates to demonstrate inter-coder reliability first.",
        "Depending on the statistical coefficient used, establishing adequate inter-rater reliabilities for these subjective judgments often creates a problem.",
        "To address some of these problems, a new method for coding these content cues with a computer program developed for qualitative research, MaxQDA (www.maxqda.de), is proprosed.",
        "The application of the program is demonstrated using the Aberdeen Report Judgment Scales (ARJS; Sporer, 2004) with a set of 72 deceptive and true accounts of a driving examination.",
        "Data on different types of inter-coder reliabilities are presented and implications for future research with computer-assisted qualitative coding procedures as well as training of coders are outlined.",
        "Credits This research has been supported by a grant from the German Science Foundation (Deutsche Forschungsgemeinschaft (DFG): Sp262/3-2) to the present author.",
        "The author would like to thank Edda Niederstadt and Nina F. Petermann for the coding of the data, and to Jaume Masip, Valerie Hauch, and Sarah Treiber for comments on an earlier version of this manuscript.",
        "Introduction Human judges are often only slightly better than chance at discriminating between truths and lies (Bond, & DePaulo, 2006).",
        "Likewise, a recent meta-analysis of training programs designed to teach lie detection has shown only small to medium effect sizes in improving judges' detection accuracy (e.g., Hauch, Sporer, Michael, & Meissner, 2010).",
        "This meta-analysis has also shown that training effects are larger when the content of messages are considered than when only relying on nonverbal or paraverbal cues.",
        "In a series of studies, Reinhard, Sporer, Scharmach, and Marksteiner (2011) further demonstrated that paying attention to verbal content cues improved lie detection accuracy compared to participants who relied on heuristic nonverbal cues.",
        "Therefore, particular attention should be paid to find valid content cues to detect deception (DePaulo, Lindsay, Malone, Muhlenbruck, Charlton, & Cooper, 2003; Sporer, 2004; Vrij, 2008).",
        "Most of the research to date has relied on Criteria-based Content Analysis (CBCA; Steller & Koehnken, 1989; for a review, see Vrij, 2005) or reality monitoring approaches (e.g., Sporer, 1997; for reviews, see Masip, Sporer, Garrido, & Herrero, 2005; Sporer, 2004).",
        "Usually, a small set of raters is trained more or less extensively with these content criteria to apply them to transcripts of oral accounts.",
        "Due to the subjective nature of these codings, establishing inter-coder reliability of any such coding system is a necessary prerequisite for its validity (Anson, Golding, & Gully, 1993).",
        "1.1 The Problem of Inter-Coder Reliability Whenever content cues are to be coded from transcripts, raters usually assign a binary code (0/1) regarding the presence of a certain criterion to the whole account.",
        "Alternatively, coders rate the extent of the presence of a criterion on some scale (0/1/2; 0-4; 1-7), which is usually treated as",
        "a Likert type scale and analyzed statistically as if it were an interval-scale measurement.",
        "Using frequency counts of criteria.",
        "Other researchers have raters count the frequencies of occurrences of a given criterion and use this as a dependent variable, similarly treating it as an interval-scale measurement.",
        "In other words, not the overall presence vs. absence in an account is coded, but specific instances of occurrencies of a given criterion throughout a text corpus are noted which are subsequently added up.",
        "One problem with this method is that the resulting distributions may be skewed which will obfuscate the use of Pearson's r as a measure of inter-rater agreement.",
        "Therefore, in case of skewness, Spearman rho may be a preferred method for ordinal-scale data.",
        "Another potential problem with the frequency count method is that the frequency of occurrence of a given criterion depends on the length of a given account (i.e., the number of words it contains).",
        "To the extent to which true accounts are likely to be longer than deceptive accounts (e.g., Colwell, Hiscock-Anisman, Memon, Taylor, & Prewett, 2007; but see the meta-analyses by DePaulo et al., 2003; Sporer & Schwandt, 2006), using frequency counts may yield erroneous conclusions.",
        "For example, if longer accounts contain more details, which are considered as an indicator of truthfulness, merely counting the number of details may be an artefact of story length.",
        "To our knowledge, in most studies the length of the accounts (i.e., the number of words) has not been considered in the resulting statistical analyses although standardizing frequencies per minute (or per 100 words) appears to be a common procedure when investigating nonverbal and paraverbal cues; see DePaulo et al., 2003; Sporer & Schwandt, 2006, 2007; for a noteworthy exception see Granhag, Stroemwall, & Olsson, 2001).",
        "Binary coding of criteria.",
        "Some authors dichotomize the obtained frequency distributions via a median-split, resulting in a binary judgment regarding the presence/absence of a given criterion for the whole account (e.g., Vrij, Akehurst, Soukara, & Bull, 2004).",
        "For binary judgments, percentage agreement is usually reported as a measure of inter-coder reliability, yielding usually quite high levels of agreement, which in turn are interpreted as being highly satisfactory (see Vrij, 2005, 2008).",
        "However, it has long been known that percentage agreement is a problematic measure of inter-rater reliability because it does not correct for chance agreement (Cohen, 1960, 1973; Rosenthal, 1995; Shrout & Fleiss, 1974; Wirtz & Caspar, 2002).",
        "Here, Cohen's (1960) kappa would be preferable.",
        "In addition, phi should be reported to make results more comparable with other studies' reporting of reliabilty coefficients like Pearson r for continuous ratings.",
        "Reliability of coding of specific occurrencies.",
        "A problem inherent to frequency counts is the fact that even though two raters may have agreed upon the presence of some criterion (e.g., \"Unusual detail\") in a given account, this agreement may or may not refer to the same factual aspect of a statement.",
        "Thus, different segments of a transcript may be assigned a specific code by different raters.",
        "This begs the question regarding the segment length and the semantic boundaries of a given cue in this text corpus.",
        "A given cue may occur at a specific location in a given text corpus, which has to be marked by a coder.",
        "Hence, it is possible that raters may not agree on the specific text passage where a criterion occurs although they may both conclude that a given criterion is present in an account.",
        "To my knowledge, this issue has never even been addressed in the literature on deception of detection (except for a German legal dissertation that illustrated this problem with a case of perjury in the Appendix; Bender, 1987).",
        "Thus, in practically all empirical studies to date, inter-rater reliability for any given content cue is only established for each account as a whole--not for specific text passages.",
        "This is where computer programs developed for qualitative research can be useful.",
        "For example, the program MAXQDA (see below) allows different coders to mark specific text passages in a text corpus (either words, phrases, sentences or longer passages) and assign a given code, which is shown at the margin.",
        "Different codes for different criteria, as well as codes from different raters, can be entered in different colors which allows comparisons between raters.",
        "This way, reliability can be established not only across accounts but for any single account.",
        "Adding up occurrences of a given criterion.",
        "When raters code the presence of certain criteria rater in a given account, and researchers subsequently add up the frequencies for this account, another problem arises.",
        "For example, rater A may observe the occurrence of a given criterion in sentence 1, 3, 5, 7, and 9, while rater B observes this criterion in sentences 2, 4, 6, 8, and 10 in the same account.",
        "For each rater, 5",
        "occurences will be noted.",
        "This may lead to an illusion of perfect agreement, as both raters report an agreement of 5 occurrences for this account, even though they did not actually agree in a single instance.",
        "Again, computerized coding as demonstrated here could help to detect such problems.",
        "Here, we only report overall agreement as in previous studies across accounts, not separately for each account as suggested in this example, which would be very tedious for a large number of accounts.",
        "1.2 Goal of the Present Study These issues will be addressed in the present study.",
        "Using the computer program MaxQDA (www.maxqda.de) which was developed for qualitative research in the social sciences, accounts of true and fabricated experiences were coded by two independent raters with respect to specific occurrences of the Aberdeen Report Judgment Scales criteria (ARJS; Sporer, 2004) at specific text passages.",
        "In the following, the adaptation of MaxQDA applied to these content criteria is demonstrated and results for different reliability coefficients are presented.",
        "Method 1.3 Design In a 2 x 2 x 2 factorial design, truth status (experienced vs. deceptive) and format of questions (W-questions vs. Content-criteria questions) were manipulated as between-, and report form (free report vs. subsequent interview) as within-participants factor.",
        "Questions varied only during the interview.",
        "1.4 Participants and Procedure Young adults (N = 72; 36 male, 36 female) between 17 and 45 years of age (Mdn = 18 years; mostly high school students) were asked to provide a convincing story of their driving test for obtaining their driver's license, which they either had recently passed (true condition), or which was immediately ahead of them (deceptive condition).",
        "Participants first provided a free report and subsequently were randomly assigned to one of two question types in the following interview.",
        "During the interview, participants answered either a series of W-questions (Who?",
        "What?",
        "Where?",
        "etc.",
        "; cf., Camparo, Wagner, & Saywitz, 2001) or questions that specifically asked for information typically used to evaluate the presence of content criteria of credibility.",
        "Importantly, the interviewer was blind with respect to truth status.",
        "To enhance participants' motivation they were promised 5 Euros (in addition to the participation fee of 8 Euros) if their account was judged to be truthful by the experimenter at the end of the interview.",
        "1.5 Stimulus Material and Coding All interviews were both video-and audiotaped, and transcripts were typed from audiotapes according to specified transcription rules.",
        "The transcripts were coded by two independent raters who were blind with respect to the truth status of the accounts.",
        "1.6 Computer-based Coding In the following, we explain the different menus of the program and explain step by step the coding procedure.",
        "1.",
        "Accounts are entered into MaxQDA as Microsoft Word *.rtf files (in a newer version of the program, *.doc files can also be used).",
        "2.",
        "A list of codes is entered into MaxQDA using short labels which later can be used as variable labels in Excel spreadsheets or in SPSS analyses.",
        "Figure 1 lists codes to be assigned to text passages.",
        "New codes can be added via a context menu.",
        "3.",
        "Codes are assigned to specific text passages by highlighting a passage in the text browser and then assigning a specific code (see Figure 2).",
        "More than one code can be assigned to a specific code, and the codes assigned are visible in the margin of the text window.",
        "presented at the 20th Conference of the European Association of Psychology and Law, Gothenburg, Sweden.",
        "Masip, J., Bethencourt, M., Lucas, G., S?nchez-San Segundo, M., & Herrero, C. (2011).",
        "Deception detection from written accounts.",
        "Scandinavian Journal of Psychology.",
        "DOI: 10.1111/j.1467-9450.2011.00931.x Masip, J., Sporer, S. L., Garrido, E., & Herrero, C. (2005).",
        "The detection of deception with the reality monitoring approach: A review of the empirical evidence.",
        "Psychology, Crime, and Law, 11, 99-122.",
        "McGraw, K. O., & Wong, S. P. (1996).",
        "Forming inferences about some intraclass correlations coefficients.",
        "Psychological Methods, 1, 31-43.",
        "Newman, M. L., Pennebaker, J. W., Berry, D. S., & Richards, J. M. (2003).",
        "Lying words: Predicting deception from linguistic styles.",
        "Personality and Social Psychology Bulletin, 29, 665?675.",
        "Orwin, R. G., & Vevea, J. L. (2009).",
        "Evaluating coding decisions.",
        "In H. Cooper, L. V., Hedges, & J. C. Valentine (Eds.",
        "), The handbook of research synthesis and meta-analysis (2nd ed., pp.",
        "177-203).",
        "New York, NY: Russell Sage Foundation.",
        "Reinhard, M. A., Sporer, S. L., Scharmach, M., & Marksteiner, T. (2011, June 27).",
        "Listening, not watching: Situational familiarity and the ability to detect deception.",
        "Journal of Personality and Social Psychology.",
        "Advance online publication.",
        "doi: 10.1037/a0023726 Rosenthal, R. (1995).",
        "Methodology.",
        "In A. Tesser (Ed.",
        "), Advanced social psychology (pp.",
        "17-49).",
        "New York: McGraw-Hill.",
        "Sporer, S. L. (1997).",
        "The less traveled road to truth: Verbal cues in deception detection in accounts of fabricated and self-experienced events.",
        "Applied Cognitive Psychology, 11, 373-397.",
        "Sporer, S. L. (2004).",
        "Reality monitoring and the detection of deception.",
        "In P.-A.",
        "Granhag & L. Stromwall (Eds.",
        "), Deception detection in forensic contexts (pp.",
        "64-102).",
        "Cambridge University Press.",
        "Sporer, S. L., & Schwandt, B.",
        "(2006).",
        "Paraverbal indicators of deception: A meta-analytic synthesis.",
        "Applied Cognitive Psychology, 20, 421 - 446.",
        "Sporer, S. L., & Schwandt, B.",
        "(2007).",
        "Moderators of nonverbal indicators of deception: A meta-analytic synthesis.",
        "Psychology, Public Policy, and Law, 13, 1-34.",
        "Vrij, A.",
        "(2005).",
        "Criteria-Based Content Analysis.",
        "A qualitative review of the first 37 studies.",
        "Psychology, Public Policy, and Law, 11, 3-41.",
        "Vrij, A.",
        "(2008).",
        "Detecting lies and deceit: Pitfalls and opportunities.",
        "Chichester, England: Wiley.",
        "Vrij, A., Akehurst, L., Soukara, S., & Bull, R. (2004).",
        "Let me inform you how to tell a convincing story: CBCA and Reality Monitoring scores as a function of age, coaching and deception.",
        "Canadian Journal of Behavioral Science, 36, 113-126.",
        "Winer, B. J.",
        "(1971).",
        "Statistical principles in experimental design.",
        "New York: McGraw-Hill.",
        "Wirtz, M., & Caspar, F. (2002).",
        "Beurteiler-?bereinstimmung und Beurteilerreliabilit?t [Inter-rater agreement and inter-rater reliability].",
        "G?ttingen: Hogrefe."
      ]
    }
  ]
}
