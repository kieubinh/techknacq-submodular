{
  "info": {
    "authors": [
      "Bonan Min",
      "Ralph Grishman",
      "Li Wan",
      "Chang Wang",
      "David Gondek"
    ],
    "book": "NAACL",
    "id": "acl-N13-1095",
    "title": "Distant Supervision for Relation Extraction with an Incomplete Knowledge Base",
    "url": "https://aclweb.org/anthology/N13-1095",
    "year": 2013
  },
  "references": [
    "acl-A00-2030",
    "acl-D12-1042",
    "acl-D12-1094",
    "acl-N07-1015",
    "acl-P04-3022",
    "acl-P05-1053",
    "acl-P07-1073",
    "acl-P09-1113",
    "acl-P11-1055",
    "acl-P11-2048",
    "acl-P12-1076"
  ],
  "sections": [
    {
      "heading": "Abstract",
      "text": [
        "Distant supervision, heuristically labeling a corpus using a knowledge base, has emerged as a popular choice for training relation extractors.",
        "In this paper, we show that a significant number of ?negative?",
        "examples generated by the labeling process are false negatives because the knowledge base is incomplete.",
        "Therefore the heuristic for generating negative examples has a serious flaw.",
        "Building on a state-of-the-art distantly-supervised extraction algorithm, we proposed an algorithm that learns from only positive and unlabeled labels at the pair-of-entity level.",
        "Experimental results demonstrate its advantage over existing algorithms."
      ]
    },
    {
      "heading": "1 Introduction",
      "text": [
        "Relation Extraction is a well-studied problem (Miller et al., 2000; Zhou et al., 2005; Kambhatla, 2004; Min et al., 2012a).",
        "Recently, Distant Supervision (DS) (Craven and Kumlien, 1999; Mintz et al., 2009) has emerged to be a popular choice for training relation extractors without using manually labeled data.",
        "It automatically generates training examples by labeling relation mentions1 in the source corpus according to whether the argument pair is listed in the target relational tables in a knowledge base (KB).",
        "This method significantly reduces human efforts for relation extraction.",
        "The labeling heuristic has a serious flaw.",
        "Knowledge bases are usually highly incomplete.",
        "For exam-1An occurrence of a pair of entities with the source sentence.",
        "ple, 93.8% of persons from Freebase2 have no place of birth, and 78.5% have no nationality (section 3).",
        "Previous work typically assumes that if the argument entity pair is not listed in the KB as having a relation, all the corresponding relation mentions are considered negative examples.3 This crude assumption labeled many entity pairs as negative when in fact some of their mentions express a relation.",
        "The number of such false negative matches even exceeds the number of positive pairs, by 3 to 10 times, leading to a significant problem for training.",
        "Previous approaches (Riedel et al., 2010; Hoffmann et al., 2011; Surdeanu et al., 2012) bypassed this problem by heavily under-sampling the ?negative?",
        "class.",
        "We instead deal with a learning scenario where we only have entity-pair level labels that are either positive or unlabeled.",
        "We proposed an extension to Surdeanu et al. (2012) that can train on this dataset.",
        "Our contribution also includes an analysis on the incompleteness of Freebase and the false negative match rate in two datasets of labeled examples generated by DS.",
        "Experimental results on a realistic and challenging dataset demonstrate the advantage of the algorithm over existing solutions."
      ]
    },
    {
      "heading": "2 Related Work",
      "text": [
        "Distant supervision was first proposed by Craven and Kumlien (1999) in the biomedical domain.",
        "deanu et al. (2011) and Sun et al. (2011) use a pair < e, v > as a negative example, when it is not listed in Freebase, but e is listed with a different v?.",
        "These assumptions are also problematic in cases where the relation is not functional.",
        "Since then, it has gain popularity (Mintz et al., 2009; Bunescu and Mooney, 2007; Wu and Weld, 2007; Riedel et al., 2010; Hoffmann et al., 2011; Surdeanu et al., 2012; Nguyen and Moschitti, 2011).",
        "To tolerate noisy labels in positive examples, Riedel et al. (2010) use Multiple Instance Learning (MIL), which assumes only at-least-one of the relation mentions in each ?bag?",
        "of mentions sharing a pair of argument entities which bears a relation, indeed expresses the target relation.",
        "MultiR (Hoffmann et al., 2011) and Multi-Instance Multi-Label (MIML) learning (Surdeanu et al., 2012) further improve it to support multiple relations expressed by different sentences in a bag.",
        "Takamatsu et al. (2012) models the probabilities of a pattern showing relations, estimated from the heuristically labeled dataset.",
        "Their algorithm removes mentions that match low-probability patterns.",
        "Sun et al. (2011) and Min et al.",
        "(2012b) also estimate the probablities of patterns showing relations, but instead use them to relabel examples to their most likely classes.",
        "Their approach can correct highly-confident false negative matches."
      ]
    },
    {
      "heading": "3 Problem Definition",
      "text": [
        "Distant Supervision: Given a KB D (a collection of relational tables r(e1, e2), in which r?R (R is the set of relation labels), and < e1, e2 > is a pair of entities that is known to have relation r) and a corpus C, the key idea of distant supervision is that we align D to C, label each bag4 of relation mentions that share argument pair < e1, e2 > with r, otherwise OTHER.",
        "This generates a dataset that has labels on entity-pair (bag) level.",
        "Then a relation extractor is trained with single-instance learning (by assuming all mentions have the same label as the bag), or Multiple-Instance Learning (by assuming at-least-one of the mentions expresses the bag-level label), or Multi-Instance Multi-Label learning (further assuming a bag can have multiple labels) algorithms.",
        "All of these works treat the OTHER class as examples that are labeled as negative.",
        "The incomplete KB problem: KBs are usually incomplete because they are manually constructed, and it is not possible to cover all human knowledge 4A bag is defined as a set of relation mentions sharing the same entity pair as relation arguments.",
        "We will use the terms bag and entity pair interchangeably in this paper.",
        "nor stay current.",
        "We took frequent relations, which involve an entity of type PERSON, from Freebase for analysis.",
        "We define the incompleteness ?",
        "(r) of a relation r as follows:",
        "?",
        "(r) is the percentage of all persons {e} that do not have an attribute e?",
        "(with which r(e, e?)",
        "holds).",
        "Table 1 shows that 93.8% of persons have no place of birth, and 78.5% of them have no nationality.",
        "These are must-have attributes for a person.",
        "This shows that Freebase is highly incomplete.",
        "have attributes for a person).",
        "We further investigate the rate of false negative matches, as the percentage of entity-pairs that are not listed in Freebase but one of its mentions generated by DS does express a relation in the target set of types.",
        "We randomly picked 200 unlabeled bags5 from each of the two datasets (Riedel et al., 2010; Surdeanu et al., 2012) generated by DS, and we manually annotate all relation mentions in these bags.",
        "The result is shown in Table 2, along with a few examples that indicate a relation holds in the set of false negative matches (bag-level).",
        "Both datasets have around 10% false negative matches in the unlabeled set of bags.",
        "Taking into consideration that the number of positive bags and unlabeled bags are highly imbalanced (1:134 and 1:37 in the Riedel and KBP dataset respectively, before under-sampling the unlabeled class), the number of false negative matches are 11 and 4 times the number of positive bags in Reidel and KBP dataset, respectively.",
        "Such a large ratio shows false negatives do have a significant impact on the learning process."
      ]
    },
    {
      "heading": "4 A semi-supervised MIML algorithm",
      "text": [
        "Our goal is to model the bag-level label noise, caused by the incomplete KB problem, in addition 585% and 95.7% of the bags in the Riedel and KBP datasets have only one relation mention.",
        "numbers are on bag (pairs of entities) level.",
        "BD* are the numbers before downsampling the negative set to 10% and 5% in Riedel and KBP dataset, respectively.",
        "to modeling the instance-level noise using a 3-layer MIL or MIML model (e.g., Surdeanu et al. (2012)).",
        "We propose a 4-layer model as shown in Figure 1.",
        "The input to the model is a list of n bags with a vector of binary labels, either Positive (P), or Un-labled (U) for each relation r. Our model can be viewed as a semi-supervised6 framework that extends a state-of-the-art Multi-Instance Multi-Label (MIML) model (Surdeanu et al., 2012).",
        "Since the input to previous MIML models are bags with per-relation binary labels of either Positive (P) or Negative (N), we add a set of latent variables ?",
        "which models the true bag-level labels, to bridge the observed bag labels y and the MIML layers.",
        "We consider this as our main contribution to the model.",
        "Our hierarchical model is shown in Figure 1.",
        "Let i, j be the index in the bag and mention level, respectively.",
        "Following Surdeanu et al. (2012), we model mention-level extraction p(zrij |xij ;wz) and multi-instance multi-label aggregation p(?ri |zi;wr?)",
        "in the bottom 3 layers.",
        "We define: ?",
        "r is a relation label.",
        "r?R ?",
        "{OTHER}, in which OTHER denotes no relation expressed.",
        "?",
        "yri ?",
        "{P,U}: r holds for ith bag or the bag is unlabeled.",
        "6We use the term semi-supervised because the algorithm uses unlabeled bags but existing solutions requires bags to be labeled either positive or negative.",
        "?",
        "?ri ?",
        "{P,N}: a hidden variable that denotes whether r holds for the ith bag.",
        "?",
        "?",
        "is an observed constant controlling the total number of bags whose latent label is positive.",
        "We define the following conditional probabilities:",
        "It encodes the constraints between true bag-level labels and the entity pair labels in the KB.",
        "number.",
        "?",
        "is the fraction of the bags that are positive.",
        "It is an observed parameter that depends on both the source corpus and the KB used.",
        "Similar to Surdeanu et al. (2012), we also define the following parameters and conditional probabilities (details are in Surdeanu et al. (2012)): ?",
        "zij?R ?",
        "{OTHER}: a latent variable that denotes the relation type of the jth mention in the ith bag.",
        "?",
        "xij is the feature representation of the jth relation mention in the ith bag.",
        "We use the set of features in Surdeanu et al. (2012).",
        "?",
        "wz is the weight vector for the multi-class relation mention-level classifier.",
        "?",
        "wr?",
        "is the weight vector for the rth binary top-level aggregation classifier (from mention labels to bag-level prediction).",
        "We usew?",
        "to represent w1?",
        ",w2?",
        ", ...w",
        "probability produced by the rth top-level classifier, from the mention-label level to the bag-label level.",
        "?",
        "p(zrij |xij ;wz) ?",
        "Multi(fz(wz,xij)) where fz",
        "is probability produced by the mention-level classifier, from the mentions to the mention-label level.7"
      ]
    },
    {
      "heading": "4.1 Training",
      "text": [
        "We use hard Expectation-Maximization (EM) algorithm for training the model.",
        "Our objective function is to maximize log-likelihood:",
        "Since solving it exactly involves exploring an exponential assignment space for ?, we approximate and",
        "1: for i = 1, 2 to T do 2: ?ri ?",
        "N for all yri = U and r?R 3: ?ri ?",
        "P for all yri = P and r?R 4: I = {< i, r > |?ri = N}; I ?",
        "= {< i, r > |?ri = P} 5: for k = 0, 1 to ?n?",
        "|I ?",
        "|do 6: < i?, r?",
        ">= argmax<i,r>?I p(?ri |xi;wz,w?)",
        "7: ?r?i?",
        "?",
        "P ; I = I\\{< i?, r?",
        ">} 8: end for 9: for i = 1, 2 to n do 10: z?i = argmaxzi p(zi|?i,xi;wz,w?)",
        "11: end for 12: w?z = argmaxwz",
        "In the E-step, we do a greedy search (steps 5-8 in algorithm 1) in all p(?ri |xi;wz,w?)",
        "and update ?ri until the second term is maximized.",
        "wz , w?",
        "are the model weights learned from the previous iteration.",
        "After fixed ?, we seek to maximize:",
        "p(?i, zi|xi;wz,w?)",
        "which can be solved with an approximate solution in Surdeanu et al. (2012) (step 9-11): update zi independently with: z?i = argmaxzi p(zi|?i,xi;wz,w?).",
        "More details can be found in Surdeanu et al. (2012).",
        "In the M-step, we retrain both of the mention-level and the aggregation level classifiers.",
        "The full EM algorithm is shown in algorithm 1."
      ]
    },
    {
      "heading": "4.2 Inference",
      "text": [
        "Inference on a bag xi is trivial.",
        "For each mention: z?ij = argzij?R?",
        "{OTHER} max p(zij |xij ,wz) Followed by the aggregation (directly with w?",
        "):"
      ]
    },
    {
      "heading": "4.3 Implementation details",
      "text": [
        "We implement our model on top of the MIML(Surdeanu et al., 2012) code base.8 We use the same mention-level and aggregate-level feature sets as Surdeanu et al. (2012).",
        "We adopt the same idea of using cross validation for the E and M steps to avoid overfitting.",
        "We initialize our algorithm by sampling 5% unlabeled examples as negative, in essence using 1 epoch of MIML to initialize.",
        "Empirically it performs well."
      ]
    },
    {
      "heading": "5 Experiments",
      "text": [
        "Data set: We use the KBP (Ji et al., 2011) dataset9 prepared and publicly released by Surdeanu et al. (2012) for our experiment since it is 1) large and realistic, 2) publicly available, 3) most importantly, it is the only dataset that has associated human-labeled ground truth.",
        "Any KB held-out evaluation without manual assessment will be significantly affected by KB incompleteness.",
        "In KBP",
        "Mintz++ compared to the same MIML-Semi curve, respectively.",
        "MIML-Semi is shown in red curves (lighter curves in black and white) while other algorithms are shown in black curves (darker curves in black and white).",
        "dataset, the training bags are generated by mapping Wikipedia (http://en.wikipedia.org) infoboxes (after merging similar types following the KBP 2011 task definition) into a large unlabeled corpus (consisting of 1.5M documents from the KBP source corpus and a complete snapshot of Wikipedia).",
        "The KBP shared task provided 200 query named entities with their associated slot values (in total several thousand pairs).",
        "We use 40 queries as development dataset (dev), and the rest (160 queries) as evaluation dataset.",
        "We set ?",
        "= 0.25 by tuning on the dev set and use it in the experiments.",
        "For a fair comparison, we follow Surdeanu et al. (2012) and begin by downsampling the ?negative?",
        "class to 5%.",
        "We also set T=8 and use the following noisy-or (for ith bag) of mention-level probability to rank predicted types (r) of pairs and plot the precision-recall curves for all experiments.",
        "Evaluation: We compare our algorithm (MIML-semi) to three algorithms: 1) MIML (Surdeanu et al., 2012), the Multiple-Instance Multiple Label algorithm which labels the bags directly with the KB (y = ?).",
        "2) MultiR (denoted as Hoffmann) (Hoffmann et al., 2011), a Multiple-Instance algorithm that supports overlapping relations.",
        "It also imposes y = ?.",
        "3) Mintz++ (Surdeanu et al., 2012), a variant of the single-instance learning algorithm (section 3).",
        "The first two are stat-of-the-art Multi-Instance Multi-Label algorithms.",
        "Mintz++ is a strong baseline (Surdeanu et al., 2012) and an improved version of Mintz et al. (2009).",
        "Figure 2 shows that our algorithm consistently outperforms all three algorithms at almost all recall levels (with the exception of a very small region in the PR-curve).",
        "This demonstrates that by treating unla-beled data set differently and leveraging the missing positive bags, MIML-semi is able to learn a more accurate model for extraction.",
        "Although the proposed solution is a specific algorithm, we believe the idea of treating unlabeled data differently can be incorporated into any of these algorithms that only use unlabeled data as negative examples."
      ]
    },
    {
      "heading": "6 Conclusion",
      "text": [
        "We show that the distant-supervision labeling process generates a significant number of false negatives because the knowledge base is incomplete.",
        "We proposed an algorithm that learns from only positive and unlabeled bags.",
        "Experimental results demonstrate its advantage over existing algorithms."
      ]
    },
    {
      "heading": "Acknowledgments",
      "text": [
        "Supported in part by the Intelligence Advanced Research Projects Activity (IARPA) via Department of Interior National Business Center contract number D11PC20154.",
        "The U.S. Government is authorized to reproduce and distribute reprints for Governmental purposes notwithstanding any copyright annotation thereon.",
        "The views and conclusions contained herein are those of the authors and should not be interpreted as necessarily representing the official policies or endorsements, either expressed or implied, of IARPA, DoI/NBC, or the U.S. Government."
      ]
    }
  ]
}
