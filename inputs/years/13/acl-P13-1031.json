{
  "info": {
    "authors": [
      "Spence Green",
      "Sida Wang",
      "Daniel Cer",
      "Christopher D. Manning"
    ],
    "book": "ACL",
    "id": "acl-P13-1031",
    "title": "Fast and Adaptive Online Training of Feature-Rich Translation Models",
    "url": "https://aclweb.org/anthology/P13-1031",
    "year": 2013
  },
  "references": [
    "acl-C04-1072",
    "acl-D07-1080",
    "acl-D08-1024",
    "acl-D08-1089",
    "acl-D11-1125",
    "acl-J04-4002",
    "acl-J93-2004",
    "acl-L08-1460",
    "acl-N06-1014",
    "acl-N07-1008",
    "acl-N09-1025",
    "acl-N09-1069",
    "acl-N10-1069",
    "acl-N10-2003",
    "acl-N12-1023",
    "acl-N12-1026",
    "acl-N12-1047",
    "acl-P02-1038",
    "acl-P02-1040",
    "acl-P03-1021",
    "acl-P03-1054",
    "acl-P06-1091",
    "acl-P06-1096",
    "acl-P11-2074",
    "acl-P12-1002",
    "acl-P12-1016",
    "acl-P12-1031",
    "acl-W05-0908",
    "acl-W08-0304",
    "acl-W08-0336",
    "acl-W10-2925",
    "acl-W11-2130",
    "acl-W12-3154"
  ],
  "sections": [
    {
      "heading": "Abstract",
      "text": [
        "We present a fast and scalable online method for tuning statistical machine translation models with large feature sets.",
        "The standard tuning algorithm?MERT?only scales to tens of features.",
        "Recent discriminative algorithms that accommodate sparse features have produced smaller than expected translation quality gains in large systems.",
        "Our method, which is based on stochastic gradient descent with an adaptive learning rate, scales to millions of features and tuning sets with tens of thousands of sentences, while still converging after only a few epochs.",
        "Large-scale experiments on Arabic-English and Chinese-English show that our method produces significant translation quality gains by exploiting sparse features.",
        "Equally important is our analysis, which suggests techniques for mitigating overfitting and domain mismatch, and applies to other recent discriminative methods for machine translation."
      ]
    },
    {
      "heading": "1 Introduction",
      "text": [
        "Sparse, overlapping features such as words and n-gram contexts improve many NLP systems such as parsers and taggers.",
        "Adaptation of discriminative learning methods for these types of features to statistical machine translation (MT) systems, which have historically used idiosyncratic learning techniques for a few dense features, has been an active research area for the past half-decade.",
        "However, despite some research successes, feature-rich models are rarely used in annual MT evaluations.",
        "For example, among all submissions to theWMT and IWSLT 2012 shared tasks, just one participant tuned more than 30 features (Hasler et al., 2012a).",
        "Slow uptake of these methods may be due to implementation complexities, or to practical difficulties of configuring them for specific translation tasks (Gimpel and Smith, 2012; Simianer et al., 2012, inter alia).",
        "We introduce a new method for training feature-rich MT systems that is effective yet comparatively easy to implement.",
        "The algorithm scales to millions of features and large tuning sets.",
        "It optimizes a logistic objective identical to that of PRO (Hopkins and May, 2011) with stochastic gradient descent, although other objectives are possible.",
        "The learning rate is set adaptively using AdaGrad (Duchi et al., 2011), which is particularly effective for the mixture of dense and sparse features present in MT models.",
        "Finally, feature selection is implemented as efficient L1 regularization in the forward-backward splitting (FOBOS) framework (Duchi and Singer, 2009).",
        "Experiments show that our algorithm converges faster than batch alternatives.",
        "To learn good weights for the sparse features, most algorithms?including ours?benefit from more tuning data, and the natural source is the training bitext.",
        "However, the bitext presents two problems.",
        "First, it has a single reference, sometimes of lower quality than the multiple references in tuning sets from MT competitions.",
        "Second, large bi-texts often comprise many text genres (Haddow and Koehn, 2012), a virtue for classical dense MT models but a curse for high dimensional models: bitext tuning can lead to a significant domain adaptation problem when evaluating on standard test sets.",
        "Our analysis separates and quantifies these two issues.",
        "We conduct large-scale translation quality experiments on Arabic-English and Chinese-English.",
        "As baselines we use MERT (Och, 2003), PRO, and the Moses (Koehn et al., 2007) implementation of k-best MIRA, which Cherry and Foster (2012) recently showed to work as well as online MIRA (Chiang, 2012) for feature-rich models.",
        "The first experiment uses standard tuning and test sets from the NIST OpenMT competitions.",
        "The second experiment uses tuning and test sets sampled from the large bitexts.",
        "The new method yields significant improvements in both experiments.",
        "Our code is included in the Phrasal (Cer et al., 2010) toolkit, which is freely available."
      ]
    },
    {
      "heading": "2 Adaptive Online Algorithms",
      "text": [
        "Machine translation is an unusual machine learning setting because multiple correct translations exist and decoding is comparatively expensive.",
        "When we have a large feature set and therefore want to tune on a large data set, batch methods are infeasible.",
        "Online methods can converge faster, and in practice they often find better solutions (Liang and Klein, 2009; Bottou and Bousquet, 2011, inter alia).",
        "Recall that stochastic gradient descent (SGD), a fundamental online method, updates weights w according to",
        "with loss function1 `t(w) of the tth example, (sub)gradient of the loss with respect to the parameters ?`t(wt?1), and learning rate ?.",
        "SGD is sensitive to the learning rate ?, which is difficult to set in an MT system that mixes frequent ?dense?",
        "features (like the language model) with sparse features (e.g., for translation rules).",
        "Furthermore, ?",
        "applies to each coordinate in the gradient, an undesirable property in MT where good sparse features may fire very infrequently.",
        "We would instead like to take larger steps for sparse features and smaller steps for dense features."
      ]
    },
    {
      "heading": "2.1 AdaGrad",
      "text": [
        "AdaGrad is a method for setting an adaptive learning rate that comes with good theoretical guarantees.",
        "The theoretical improvement over SGD is most significant for high-dimensional, sparse features.",
        "AdaGrad makes the following update:",
        "A diagonal approximation to ?",
        "can be used for a high-dimensional vector wt.",
        "In this case, AdaGrad is simple to implement and computationally cheap.",
        "Consider a single dimension j, and let scalars vt ="
      ]
    },
    {
      "heading": "2.2 Prior Online Algorithms in MT",
      "text": [
        "AdaGrad is related to two previous online learning methods for MT.",
        "MIRA Chiang et al. (2008) described an adaption of MIRA (Crammer et al., 2006) to MT.",
        "MIRA makes the following update:",
        "The first term expresses conservativity: the weight should change as little as possible based on a single example, ensuring that it is never beneficial to overshoot the minimum.",
        "The relationship to SGD can be seen by lineariz-ing the loss function `t(w) ?",
        "`t(wt?1) + (w ?",
        "wt?1)>?`t(wt?1) and taking the derivative of (6).",
        "The result is exactly (1).",
        "AROW Chiang (2012) adapted AROW (Crammer et al., 2009) to MT.",
        "AROW models the current weight as a Gaussian centered at wt?1 with covariance ?t?1, and does the following update upon seeing training example xt:",
        "The KL-divergence term expresses a more general, directionally sensitive conservativity.",
        "Ignoring the third term, the ?",
        "that minimizes the KL is actually ?t?1.",
        "As a result, the first two terms of (7) generalize MIRA so that we may be more conservative in some directions specified by ?.",
        "To see this, we can write out the KL-divergence between two Gaussians in closed form, and observe that the terms involving w do not interact with the terms",
        "The third term in (7), called the confidence term, gives us adaptivity, the notion that we should have smaller variance in the direction v as more data xt",
        "is seen in direction v. For example, if ?",
        "is diagonal and xt are indicator features, the confidence term then says that the weight for a rarer feature should have more variance and vice-versa.",
        "Recall that for generalized linear models?`t(w) ?",
        "xt; if we substitute xt = ?t?`t(w) into (9), differentiate and solve, we get:",
        "The precision ?",
        "?1t generally grows as more datais seen.",
        "Frequently updated features receive an especially high precision, whereas the model maintains large variance for rarely seen features.",
        "If we substitute (10) into (8), linearize the loss `t(w) as before, and solve, then we have the lin-earized AROW update",
        "which is also an adaptive update with per-coordinate learning rates specified by ?t (as opposed to ?1/2tin AdaGrad)."
      ]
    },
    {
      "heading": "2.3 Comparing AdaGrad, MIRA, AROW",
      "text": [
        "Compare (3) to (10) and observe that if we set ?",
        "?10 = 0 and ?t = 1, then the only differencebetween the AROW update (11) and the AdaGrad update (2) is a square root.",
        "Under a constant gradient, AROW decays the step size more aggressively (1/t) compared to AdaGrad (1/?t), and it is sensitive to the specification of ?",
        "?10 .Informally, SGD can be improved in the conservativity direction using MIRA so the updates do not overshoot.",
        "Second, SGD can be improved in the adaptivity direction using AdaGrad where the decaying stepsize is more robust and the adaptive stepsize allows better weight updates to features differing in sparsity and scale.",
        "Finally, AROW combines both adaptivity and conservativity.",
        "For MT, adaptivity allows us to deal withmixed dense/sparse features effectively without specific normalization.",
        "Why do we choose AdaGrad over AROW?",
        "MIRA/AROW requires selecting the loss function `(w) so that wt can be solved in closed-form, by a quadratic program (QP), or in some other way that is better than linearizing.",
        "This usually means choosing a hinge loss.",
        "On the other hand, AdaGrad/linearized AROW only requires that the gradient of the loss function can be computed efficiently.",
        "Algorithm 1 Adaptive online tuning for MT.",
        "Require: Tuning set {fi, e1:ki }i=1:M1: Set w0 = 02: Set t = 1",
        "3: repeat 4: for i in 1 .",
        ".",
        ".M in random order do 5: Decode n-best list Ni for fi6: Sample pairs {dj,+, dj,?",
        "}j=1:s from Ni7: Compute Dt = {?(dj,+)?",
        "?(dj,?",
        ")}j=1:s8: Set gt = ?`(Dt; wt?1)} 9: Set ?",
        "?1t = ?",
        "?1t?1 + gtg>t .",
        "Eq.",
        "(3) 10: Update wt = wt?1 ?",
        "?",
        "?1/2t gt .",
        "Eq.",
        "(2)11: Regularize wt .",
        "Eq.",
        "(15)12: Set t = t+ 1 13: end for 14: until convergence",
        "Linearized AROW, however, is less robust than AdaGrad empirically2 and lacks known theoretical guarantees.",
        "Finally, by using AdaGrad, we separate adaptivity from conservativity.",
        "Our experiments suggest that adaptivity is actually more important."
      ]
    },
    {
      "heading": "3 Adaptive Online MT",
      "text": [
        "Algorithm 1 shows the full algorithm introduced in this paper.",
        "AdaGrad (lines 9?10) is a crucial piece, but the loss function, regularization technique, and parallelization strategy described in this section are equally important in the MT setting."
      ]
    },
    {
      "heading": "3.1 Pairwise Logistic Loss Function",
      "text": [
        "Algorithm 1 lines 5?8 describe the gradient computation.",
        "We cast MT tuning as pairwise ranking (Herbrich et al., 1999, inter alia), which Hopkins and May (2011) applied to MT.",
        "The pairwise approach results in simple, convex loss functions suitable for online learning.",
        "The idea is that for any two derivations, the ranking predicted by the model should be consistent with the ranking predicted by a gold sentence-level metric G like BLEU+1 (Lin and Och, 2004).",
        "Consider a single source sentence f with associated references e1:k. Let d be a derivation in an n-best list of f that has the target e = e(d) and the feature map ?(d).",
        "Let M(d) = w ?",
        "?",
        "(d) be the model score.",
        "For any derivation d+ that is better than d?",
        "under G, we desire pairwise agreement such that",
        "Ensuring pairwise agreement is the same as ensuring w ?",
        "[?(d+)?",
        "?(d?)]",
        "> 0.",
        "For learning, we need to select derivation pairs (d+, d?)",
        "to compute difference vectors x+ = ?",
        "(d+) ?",
        "?(d?).",
        "Then we have a 1-class separation problem trying to ensure w ?",
        "x+ > 0.",
        "The derivation pairs are sampled with the algorithm of Hopkins and May (2011).",
        "We compute difference vectors Dt = {x1:s+ } (Al-gorithm 1 line 7) from s pairs (d+, d?)",
        "for source sentence ft. We use the familiar logistic loss:",
        "Choosing the hinge loss instead of the logistic loss results in the 1-class SVM problem.",
        "The 1 class separation problem is equivalent to the binary classification problem with x+ = ?(d+)?",
        "?(d?)",
        "as positive data and x?",
        "= ?x+ as negative data, which may be plugged into an existing logistic regression solver.",
        "We find that Algorithm 1 works best with mini-batches instead of single examples.",
        "In line 4 we simply partition the tuning set so that i becomes a mini-batch of examples."
      ]
    },
    {
      "heading": "3.2 Updating and Regularization",
      "text": [
        "Algorithm 1 lines 9?11 compute the adaptive learning rate, update the weights, and apply regularization.",
        "Section 2.1 explained the AdaGrad learning rate computation.",
        "To update and regularize the weights we apply the Forward-Backward Splitting (FOBOS) (Duchi and Singer, 2009) framework, which separates the two operations.",
        "The two-step",
        "where (13) is just an unregularized gradient descent step and (14) balances the regularization term r(w) with staying close to the gradient step.",
        "Equation (14) permits efficient L1 regularization, which is well-suited for selecting good features from exponentially many irrelevant features (Ng, 2004).",
        "It is well-known that feature selection is very important for feature-rich MT.",
        "For example, simple indicator features like lexicalized reordering classes are potentially useful yet bloat the the feature set and, in the worst case, can negatively impact Algorithm 2 ?Stale gradient?",
        "parallelization method for Algorithm 1.",
        "Require: Tuning set {fi, e1:ki }i=1:M1: Initialize threadpool p1, .",
        ".",
        ".",
        ", pj2: Set t = 1",
        "3: repeat 4: for i in 1 .",
        ".",
        ".M in random order do 5: Wait until any thread p is idle 6: Send (fi, e1:ki , t) to p .",
        "Alg.",
        "1 lines 5?87: while ?",
        "p?",
        "done with gradient gt?",
        "do .",
        "t?",
        "?",
        "t8: Update wt = wt?1 ?",
        "?gt?",
        ".",
        "Alg.",
        "1 lines 9?119: Set t = t+ 1 10: end while 11: end for 12: until convergence",
        "search.",
        "Some of the features generalize, but many do not.",
        "This was well understood in previous work, so heuristic filtering was usually applied (Chiang et al., 2009, inter alia).",
        "In contrast, we need only select an appropriate regularization strength ?.",
        "Specifically, when r(w) = ?",
        "?w?1, the closed-form solution to (14) is",
        "where [x]+ = max(x, 0) is the clipping function that in this case sets a weight to 0 when it falls below the threshold ?t?1?.",
        "It is straightforward to adapt this to AdaGrad with diagonal ?",
        "by setting each dimension of ?t?1,j = ?",
        "?",
        "t,jj and by takingelement-wise products.",
        "We find that?`t?1(wt?1) only involves several hundred active features for the current example (or mini-batch).",
        "However, naively following the FOBOS framework requires updating millions of weights.",
        "But a practical benefit of FOBOS is that we can do lazy updates on just the active dimensions without any approximations."
      ]
    },
    {
      "heading": "3.3 Parallelization",
      "text": [
        "Algorithm 1 is inherently sequential like standard online learning.",
        "This is undesirable in MT where decoding is costly.",
        "We therefore parallelize the algorithm with the ?stale gradient?",
        "method of Langford et al. (2009) (Algorithm 2).",
        "A fixed threadpool of workers computes gradients in parallel and sends them to a master thread, which updates a central weight vector.",
        "Crucially, the weight updates need not be applied in order, so synchronization is unnecessary; the workers only idle at the end of an epoch.",
        "The consequence is that the update in line 8 of Algorithm 2 is with respect to gradient gt?",
        "with t?",
        "?",
        "t. Langford et al. (2009) gave convergence results for",
        "stale updating, but the bounds do not apply to our setting since we use L1 regularization.",
        "Nevertheless, Gimpel et al. (2010) applied this framework to other non-convex objectives and obtained good empirical results.",
        "Our asynchronous, stochastic method has practical appeal for MT.",
        "During a tuning run, the online method decodes the tuning set under many more weight vectors than a MERT-style batch method.",
        "This characteristic may result in broader exploration of the search space, and make the learner more robust to local optima local optima (Liang and Klein, 2009; Bottou and Bousquet, 2011, inter alia).",
        "The adaptive algorithm identifies appropriate learning rates for the mixture of dense and sparse features.",
        "Finally, large data structures such as the language model (LM) and phrase table exist in shared memory, obviating the need for remote queries."
      ]
    },
    {
      "heading": "4 Experiments",
      "text": [
        "We built Arabic-English and Chinese-English MT systems with Phrasal (Cer et al., 2010), a phrase-based system based on alignment templates (Och and Ney, 2004).",
        "The corpora3 in our experiments (Table 1) derive from several LDC sources from 2012 and earlier.",
        "We de-duplicated each bitext according to exact string match, and ensured that no overlap existed with the test sets.",
        "We produced alignments with the Berkeley aligner (Liang et al., 2006b) with standard settings and symmetrized via the grow-diag heuristic.",
        "For each language we used SRILM (Stolcke, 2002) to estimate 5-gram LMs with modified Kneser-Ney smoothing.",
        "We included the monolingual English data and the respective target bitexts."
      ]
    },
    {
      "heading": "4.1 Feature Templates",
      "text": [
        "The baseline ?dense?",
        "model contains 19 features: the nine Moses baseline features, the hierarchical lexicalized reordering model of Galley and Manning (2008), the (log) count of each rule, and an indicator for unique rules.",
        "To the dense features we add three high dimensional ?sparse?",
        "feature sets.",
        "Discrimina",
        "in these experiments.",
        "The monolingual English data comes from the AFP and Xinhua sections of English Gigaword 4 (LDC2009T13).",
        "tive phrase table (PT): indicators for each rule in the phrase table.",
        "Alignments (AL): indicators for phrase-internal alignments and deleted (unaligned) source words.",
        "Discriminative reordering (LO): indicators for eight lexicalized reordering classes, including the six standard monotone/swap/discontinuous classes plus the two simpler Moses monotone/non-monotone classes."
      ]
    },
    {
      "heading": "4.2 Tuning Algorithms",
      "text": [
        "The primary baseline is the dense feature set tuned with MERT (Och, 2003).",
        "The Phrasal implementation uses the line search algorithm of Cer et al. (2008), uniform initialization, and 20 random starting points.4 We tuned according to BLEU-4 (Pap-ineni et al., 2002).",
        "We built high dimensional baselines with two different algorithms.",
        "First, we tuned with batch PRO using the default settings in Phrasal (L2 regularization with ?=0.1).",
        "Second, we ran the k-best batch MIRA (kb-MIRA) (Cherry and Foster, 2012) implementation in Moses.",
        "We did implement an online version of MIRA, and in small-scale experiments found that the batch variant worked just as well.",
        "Cherry and Foster (2012) reported the same result, and their implementation is available in Moses.",
        "We ran their code with standard settings.",
        "Moses5 also contains the discriminative phrase table implementation of (Hasler et al., 2012b), which is identical to our implementation using Phrasal.",
        "Moses and Phrasal accept the same phrase table and LM formats, so we kept those data structures in common.",
        "The two decoders also use the same multi-stack beam search (Och and Ney, 2004).",
        "For our method, we used uniform initialization, 16 threads, and a mini-batch size of 20.",
        "We found that ?=0.02 and ?=0.1 worked well on development sets for both languages.",
        "To compute the gradients 4Other system settings for all experiments: distortion limit of 5, a maximum phrase length of 7, and an n-best size of 200.",
        "sentences.",
        "OpenMT 2009 did not include Zh-En, hence the asymmetry with Table 2. we sampled 15 derivation pairs for each tuning example and scored them with BLEU+1."
      ]
    },
    {
      "heading": "4.3 NIST OpenMT Experiment",
      "text": [
        "The first experiment evaluates our algorithm when tuning and testing on standard test sets, each with four references.",
        "When we add features, our algorithm tends to overfit to a standard-sized tuning set like MT06.",
        "We thus concatenated MT05, MT06, and MT08 to create a larger tuning set.",
        "Table 2 shows the Ar-En results.",
        "Our algorithm is competitive with MERT in the low dimensional ?dense?",
        "setting, and compares favorably to PRO with the PT feature set.",
        "PRO does not benefit from additional features, whereas our algorithm improves with both additional features and data.",
        "The underperformance of kb-MIRA may result from a difference between Moses and Phrasal: Moses MERT achieves only 45.62 on MT09.",
        "Moses PRO with the PT feature set is slightly worse, e.g., 44.52 on MT09.",
        "Nevertheless, kb-MIRA does not improve significantly over MERT, and also selects an unnecessarily large model.",
        "The full feature set PT+AL+LO does help.",
        "With the PT feature set alne, our algorithm tuned on MT05/6/8 scores well below the best model, e.g.",
        "thus has the desirable property of benefiting from more and better features, and more data.",
        "Table 3 shows Zh-En results.",
        "Somewhat surprisingly our algorithm improves over MERT in the dense setting.",
        "When we add the discriminative phrase table, our algorithm improves over kb-MIRA, and over batch PRO on two evaluation sets.",
        "With all features and the MT05/6/8 tuning set, we improve significantly over all other models.",
        "PRO learns a smaller model with the PT+AL+LO feature set which is surprising given that it applies L2 regularization (AdaGrad uses L1).",
        "We speculate that this may be an consequence of stochastic learning.",
        "Our algorithm decodes each example with a new weight vector, thus exploring more of the search space for the same tuning set."
      ]
    },
    {
      "heading": "4.4 Bitext Tuning Experiment",
      "text": [
        "Tables 2 and 3 show that adding tuning examples improves translation quality.",
        "Nevertheless, even the larger tuning set is small relative to the bitext from which rules were extracted.",
        "He and Deng (2012) and Simianer et al. (2012) showed significant translation quality gains by tuning on the bitext.",
        "However, their bitexts matched the genre of their test sets.",
        "Our bitexts, like those of most large-scale systems, do not.",
        "Domain mismatch matters for the dense feature set (Haddow and Koehn, 2012).",
        "We show that it also matters for feature-rich MT.",
        "Before aligning each bitext, we randomly sampled and sequestered 5k and 15k sentence tuning sets, and a 5k test set.",
        "We prevented overlap be",
        "tween the tuning sets and the test set.",
        "We then tuned a dense model with MERT on MT06, and feature-rich models on both MT05/6/8 and the bitext tuning set.",
        "Table 4 shows the Ar-En results.",
        "When tuned on bitext5k the translation quality gains are significant for bitext5k-test relative to tuning on MT05/6/8, which has multiple references.",
        "However, the bitext5k models do not generalize as well to the NIST evaluation sets as represented by the MT04 result.",
        "Table 5 shows similar trends for Zh-En."
      ]
    },
    {
      "heading": "5 Analysis",
      "text": []
    },
    {
      "heading": "5.1 Feature Overlap Analysis",
      "text": [
        "How many sparse features appear in both the tuning and test sets?",
        "In Table 6, A is the set of phrase table features that received a non-zero weight when tuned on datasetDA (same forB).",
        "ColumnDA lists several Zh-En test sets used and column DB lists tuning sets.",
        "Our experiments showed that tuning on MT06 generalizes better to MT04 than tuning",
        "on bitext5k, whereas tuning on bitext5k generalizes better to bitext5k-test than tuning on MT06.",
        "These trends are consistent with the level of feature overlap.",
        "Phrase table features in A ?",
        "B are overwhelmingly short, simple, and correct phrases, suggesting L1 regularization is effective for feature selection.",
        "It is also important to balance the number of features with how well weights can be learned for those features, as tuning on bitext15k produced higher coverage for MT04 but worse generalization than tuning on MT06."
      ]
    },
    {
      "heading": "5.2 Domain Adaptation Analysis",
      "text": [
        "To understand the domain adaptation issue we compared the non-zero weights in the discriminative phrase table (PT) for Ar-En models tuned on bi-text5k and MT05/6/8.",
        "Table 7 illustrates a statistical idiosyncrasy in the data for the American and British spellings of program/programme.",
        "The mass is concentrated along the diagonal, probably because MT05/6/8 was prepared by NIST, an American agency, while the bitext was collected from many sources including Agence France Presse.",
        "Of course, this discrepancy is consequential for both dense and feature-rich models.",
        "However, we observe that the feature-rich models fit the tuning data more closely.",
        "For example, the MT05/6/8 model learns rules like l .",
        "?A KQK.",
        "??",
        "?JK ?",
        "program includes, l .",
        "?A KQK.",
        "?",
        "program of, and l .",
        "?A KQ.",
        "?",
        "@ ?",
        "Y ?A K?",
        "program window.",
        "Crucially, it does not learn the basic rule l .",
        "?A KQK.",
        "?",
        "program.",
        "In contrast, the bitext5k model contains basic rules such l .",
        "?A KQK.",
        "?",
        "programme, l .",
        "?A KQ.",
        "?",
        "@ @ Y?",
        "?",
        "this programme, and l .",
        "?A KQ.",
        "?",
        "@ ??",
        "X ?",
        "that programme.",
        "It also contains more elaborate rules such as l .",
        "?A KQ.",
        "?",
        "@ HA?",
        "?",
        "K I KA?",
        "?",
        "programme expenses were and ???",
        "?",
        "space flight programmes.",
        "We observed similar trends for ?defense/defence?, ?analyze/analyse?, etc.",
        "This particular genre problem could be addressed with language-specific pre-processing, but our system solves it in a data-driven manner."
      ]
    },
    {
      "heading": "5.3 Reordering Analysis",
      "text": [
        "We also analyzed reordering differences.",
        "Arabic matrix clauses tend to be verb-initial, meaning that the subject and verb must be swapped when translating to English.",
        "To assess reordering differences?",
        "if any?between the dense and feature-rich models, we selected all MT09 segments that began with one",
        "Ar-En tuning sets for programme and program.",
        "Bottom: rule counts in the discriminative phrase table (PT) for models tuned on the two tuning sets.",
        "Both spellings correspond to the Arabic l .",
        "?A KQK.",
        ".",
        "of seven common verbs: ?A?",
        "qaal ?said?, hQ??",
        "SrH ?declared?, PA ?",
        "@ ashaar ?indicated?, ?A?",
        "kaan ?was?,",
        "acln ?announced?.",
        "We compared the output of the MERT Dense model to our method with the full feature set, both tuned on MT06.",
        "Of the 208 source segments, 32 of the translation pairs contained different word order in the matrix clause.",
        "Our feature-rich model was correct 18 times (56.3%), Dense was correct 4 times (12.5%), and neither method was correct 10 times (31.3%).",
        "(1) ref: lebanese prime minister , fuad siniora , announced a. and lebanese prime minister fuad siniora that b. the lebanese prime minister fouad siniora announced (2) ref: the newspaper and television reported a. she said the newspaper and television",
        "b. television and newspaper said In (1) the dense model (1a) drops the verb while the feature-rich model correctly reorders and inserts it after the subject (1b).",
        "The coordinated subject in (2) becomes an embedded subject in the dense output (2a).",
        "The feature-rich model (2b) performs the correct re-ordering."
      ]
    },
    {
      "heading": "5.4 Runtime Comparison",
      "text": [
        "Table 8 compares our method to standard implementations of the other algorithms.",
        "MERT parallelizes easily but runtime increases quadratically with n-best list size.",
        "PRO runs (single-threaded) L-BFGS to convergence on every epoch, a potentially slow procedure for the larger feature set.",
        "Moreover, both",
        "approximate runtime per epoch in minutes (?min.?)",
        "for selected Zh-En experiments tuned on MT06.",
        "All runs executed on the same dedicated system with the same number of threads.",
        "(*) Moses and kb-MIRA are written in C++, while all other rows refer to Java implementations in Phrasal.",
        "the Phrasal and Moses PRO implementations use L2 regularization, which regularizes every weight on every update.",
        "kb-MIRA makes multiple passes through the n-best lists during each epoch.",
        "The Moses implementation parallelizes decoding but weight updating is sequential.",
        "The core of our method is an inner product between the adaptive learning rate vector and the gradient.",
        "This is easy to implement and is very fast even for large feature sets.",
        "Since we applied lazy regularization, this inner product usually involves hundred-dimensional vectors.",
        "Finally, our method does not need to accumulate n-best lists, a practice that slows down the other algorithms."
      ]
    },
    {
      "heading": "6 Related Work",
      "text": [
        "Our work relates most closely to that of Hasler et al. (2012b), who tuned models containing both sparse and dense features with Moses.",
        "A discriminative phrase table helped them improve slightly over a dense, online MIRA baseline, but their best results required initialization with MERT-tuned weights and retuning a single, shared weight for the discriminative phrase table with MERT.",
        "In contrast, our algorithm learned good high dimensional models from a uniform starting point.",
        "Chiang (2012) adapted AROW to MT and extended previous work on online MIRA (Chiang et al., 2008; Watanabe et al., 2007).",
        "It was not clear if his improvements came from the novel Hope/Fear search, the conservativity gain from MIRA/AROW by solving the QP exactly, adaptivity, or sophisticated parallelization.",
        "In contrast, we show that AdaGrad, which ignores conservativity and only capturing adaptivity, is sufficient.",
        "Simianer et al. (2012) investigated SGD with a pairwise perceptron objective.",
        "Their best algorithm used iterative parameter mixing (McDonald et al., 2010), which we found to be slower than the stale gradient method in section 3.3.",
        "They regularized once at the end of each epoch, whereas we regularized each weight update.",
        "An empirical comparison of these two strategies would be an interesting future contribution.",
        "Watanabe (2012) investigated SGD and even randomly selected pairwise samples as we did.",
        "He considered both softmax and hinge losses, observing better results with the latter, which solves a QP.",
        "Their parallelization strategy required a line search at the end of each epoch.",
        "Many other discriminative techniques have been proposed based on: ramp loss (Gimpel, 2012); hinge loss (Cherry and Foster, 2012; Haddow et al., 2011; Arun and Koehn, 2007); maximum entropy (Xiang and Ittycheriah, 2011; Ittycheriah and Roukos, 2007; Och and Ney, 2002); perceptron (Liang et al., 2006a); and structured SVM (Till-mann and Zhang, 2006).",
        "These works use radically different experimental setups, and to our knowledge only (Cherry and Foster, 2012) and this work compare to at least two high dimensional baselines.",
        "Broader comparisons, though time-intensive, could help differentiate these methods."
      ]
    },
    {
      "heading": "7 Conclusion and Outlook",
      "text": [
        "We introduced a new online method for tuning feature-rich translation models.",
        "The method is faster per epoch than MERT, scales to millions of features, and converges quickly.",
        "We used efficient L1 regularization for feature selection, obviating the need for the feature scaling and heuristic filtering common in prior work.",
        "Those comfortable with implementing vanilla SGD should find our method easy to implement.",
        "Even basic discriminative features were effective, so we believe that our work enables fresh approaches to more sophisticated MT feature engineering.",
        "Acknowledgments We thank John DeNero for helpful comments on an earlier draft.",
        "The first author is supported by a National Science Foundation Graduate Research Fellowship.",
        "We also acknowledge the support of the Defense Advanced Research Projects Agency (DARPA) Broad Operational Language Translation (BOLT) program through IBM.",
        "Any opinions, findings, and conclusions or recommendations expressed in this material are those of the author(s) and do not necessarily reflect the view of the DARPA or the US government."
      ]
    }
  ]
}
