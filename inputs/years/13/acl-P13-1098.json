{
  "info": {
    "authors": [
      "Vasileios Lampos",
      "Daniel Preo≈£iuc-Pietro",
      "Trevor Cohn"
    ],
    "book": "ACL",
    "id": "acl-P13-1098",
    "title": "A user-centric model of voting intention from Social Media",
    "url": "https://aclweb.org/anthology/P13-1098",
    "year": 2013
  },
  "references": [],
  "sections": [
    {
      "text": [
        "Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 993?1003, Sofia, Bulgaria, August 4-9 2013. c?2013 Association for Computational Linguistics A user-centric model of voting intention from Social Media"
      ]
    },
    {
      "heading": "Abstract",
      "text": [
        "Social Media contain a multitude of user opinions which can be used to predict real-world phenomena in many domains including politics, finance and health.",
        "Most existing methods treat these problems as linear regression, learning to relate word frequencies and other simple features to a known response variable (e.g., voting intention polls or financial indicators).",
        "These techniques require very careful filtering of the input texts, as most Social Media posts are irrelevant to the task.",
        "In this paper, we present a novel approach which performs high quality filtering automatically, through modelling not just words but also users, framed as a bilinear model with a sparse regulariser.",
        "We also consider the problem of modelling groups of related output variables, using a structured multi-task regularisation method.",
        "Our experiments on voting intention prediction demonstrate strong performance over large-scale input from Twitter on two distinct case studies, outperforming competitive baselines."
      ]
    },
    {
      "heading": "1 Introduction",
      "text": [
        "Web Social Media platforms have ushered a new era in human interaction and communication.",
        "The main by-product of this activity is vast amounts of user-generated content, a type of information that has already attracted the interest of both marketeers and scientists because it offers ?",
        "for the first time at a large-scale ?",
        "unmediated access to peoples?",
        "observations and opinions.",
        "One exciting avenue of research concentrates on mining interesting signals automatically from this stream of text input.",
        "For example, by exploiting Twitter posts, it is possible to infer time series that correlate with financial indicators (Bollen et al., 2011), track infectious diseases (Lampos and Cristianini, 2010; Lampos et al., 2010; Paul and Dredze, 2011) and, in general, nowcast the magnitude of events emerging in real-life (Sakaki et al., 2010; Lampos and Cristianini, 2012).",
        "Other studies suggest ways for modelling opinions encapsulated in this content in order to forge branding strategies (Jansen et al., 2009) or understand various socio-political trends (Tumasjan et al., 2010; O?Connor et al., 2010; Lansdall-Welfare et al., 2012).",
        "The main theme of the aforementioned works is linear regression between word frequencies and a real-world quantity.",
        "They also tend to incorporate hand-crafted lists of search terms to filter irrelevant content and use sentiment analysis lexicons for extracting opinion bias.",
        "Consequently, they are quite often restricted to a specific application and therefore, generalise poorly to new data sets (Gayo-Avello et al., 2011).",
        "In this paper, we propose a generic method that aims to be independent of the characteristics described above (use of search terms or sentiment analysis tools).",
        "Our approach is able to explore not only word frequencies, but also the space of users by introducing a bilinear formulation for this learning task.",
        "Regularised regression on both spaces allows for an automatic selection of the most important terms and users, performing at the same time an improved noise filtering.",
        "In addition, more advanced regularisation functions enable multi-task learning schemes that can exploit shared structure in the feature space.",
        "The latter property becomes very useful in multi-output regression scenarios, where selected features are expected to have correlated as well as anti-correlated impact on each output (e.g., when inferring voting intentions for competing political parties).",
        "We evaluate our methods on the domain of politics using data from the microblogging service of Twitter to infer voting trends.",
        "Our pro",
        "posed framework is able to successfully predict voting intentions for the top-3 and top-4 parties in the United Kingdom (UK) and Austria respectively.",
        "In both case studies ?",
        "bound by different characteristics (including language, timespan and number of users) ?",
        "the average prediction error is smaller than 1.5% for our best model using multi-task learning.",
        "Finally, our qualitative analysis shows that the models uncover interesting and semantically interpretable insights from the data."
      ]
    },
    {
      "heading": "2 Data",
      "text": [
        "For the evaluation of the proposed methodologies we have created two data sets of Social Media content with different characteristics based in the UK and Austria respectively.",
        "They are used for performing regression aiming to infer voting intention polls in those countries.",
        "Data processing is performed using the TrendMiner architecture for Social Media analysis (Preot?iuc-Pietro et al., 2012).",
        "2.1 Tweets from users in the UK The first data set (we refer to it as Cuk) used in our experimental process consists of approx.",
        "60 million tweets produced by approx.",
        "42K UK Twitter users from 30/04/2010 to 13/02/2012.",
        "We assumed each user to be from the UK, if the location field in their profile matched with a list of common UK locations and their time zone was set to G.M.T.",
        "In this way, we were able to extract hundreds of thousands of UK users, from which we sub-sampled 42K users to be distributed across the UK geographical regions proportionally to their population figures.1"
      ]
    },
    {
      "heading": "2.2 Tweets for Austria",
      "text": [
        "The second data set (Cau) is shorter in terms of the number of users involved (1.1K), its time span (25/01 to 01/12/2012) and, consequently, of the total number of tweets considered (800K).",
        "However, this time the selection of users has been made by Austrian political experts who decided which accounts to monitor by subjectively assessing the value of information they may provide towards political-oriented topics.",
        "Still, we assume that the different users will produce information of varying quality, and some should be eliminated entirely.",
        "However, we emphasise that there may be smaller",
        "Austria.",
        "potential gains from user modelling compared to the UK case study.",
        "Another important distinction is language, which for this data set is primarily German with some English."
      ]
    },
    {
      "heading": "2.3 Ground Truth",
      "text": [
        "The ground truth for training and evaluating our regression models is formed by voting intention polls from YouGov (UK) and a collection of Austrian pollsters2 ?",
        "as none performed high frequency polling ?",
        "for the Austrian case study.",
        "We focused on the three major parties in the UK, namely Conservatives (CON), Labour (LAB) and Liberal Democrats (LBD) and the four major parties in Austria, namely the Social Democratic Party (SPO?",
        "), People's Party (O?VP), Freedom Party (FPO?)",
        "and the Green Alternative Party (GRU?).",
        "Matching with the time spans of the data sets described in the previous sections, we have acquired 240 unique polls for the UK and 65 polls for Austria.",
        "The latter have been expanded to 98 polls by replicating the poll of day i for day",
        "i ?",
        "1 where possible.",
        "There exists some interesting variability towards the end for the UK polls (Fig.",
        "1a), whereas for the Austrian case, the main changing point is between the second and the third party (Fig.",
        "1b)."
      ]
    },
    {
      "heading": "3 Methods",
      "text": [
        "The textual content posted on Social Media platforms unarguably contains valuable information, but quite often it is hidden under vast amounts of unstructured user generated input.",
        "In this section, we propose a set of methods that build on one another, which aim to filter the non desirable noise and extract the most informative features not only based on word frequencies, but also by incorporating users in this process."
      ]
    },
    {
      "heading": "3.1 The bilinear model",
      "text": [
        "There exist a number of different possibilities for incorporating user information into a regression model.",
        "A simple approach is to expand the feature set, such that each user's effect on the response variable can be modelled separately.",
        "Although flexible, this approach would be doomed to failure due to the sheer size of the resulting feature set, and the propensity to overfit all but the largest of training sets.",
        "One solution is to group users into different types, such as journalist, politician, activist, etc., but this presupposes a method for classification or clustering of users which is a non-trivial undertaking.",
        "Besides, these na?",
        "?ve approaches fail to account for the fact that most users use similar words to express their opinions, by separately parameterising the model for different users or user groups.",
        "We propose to account for individual users while restricting all users to share the same vocabulary.",
        "This is formulated as a bilinear predictive model,",
        "where X is an m ?",
        "p matrix of user-word frequencies and u and w are the model parameters.",
        "Let Q ?",
        "Rn?m?p be a tensor which captures our training inputs, where n, m and p denote the considered number of samples (each sample usually refers to a day), terms and users respectively; Q can simply be interpreted as n versions of X (denoted by Qi in the remainder of the script), a different one for each day, put together.",
        "Each element 3This has been carried out to ensure an adequate number of training points in the experimental process.",
        "Qijk holds the frequency of term j for user k during the day i in our sample.",
        "If a user k has posted ci?k tweets during day i, and cijk ?",
        "ci?k of them contain a term j, then the frequency of j for this day and user is defined as Qijk = cijkci?k .Aiming to learn sparse sets of users and terms that are representative of the voting intention signal, we formulate our optimisation task as follows:",
        "(2) where y ?",
        "Rn is the response variable (voting intention), w ?",
        "Rm and u ?",
        "Rp denote the term and user weights respectively, uTQiw expresses the bilinear term, ?",
        "?",
        "R is a bias term and ?(?)",
        "is a regularisation function with parameters ?1 or ?2.",
        "The first term in Eq.",
        "2 is the standard regularisation loss function, namely the sum squared error over the training instances.4 In the main formulation of our bilinear model, as the regularisation function ?(?)",
        "we use the elastic net (Zou and Hastie, 2005), an extension of the well-studied `1-norm regulariser, known as the LASSO (Tibshirani, 1996).",
        "The `1-norm regularisation has found many applications in several scientific fields as it encourages sparse solutions which reduce the possibility of overfitting and enhance the interpretability of the inferred model (Hastie et al., 2009).",
        "The elastic net applies an extra penalty on the `2-norm of the weight vector, and can resolve instability issues of LASSO which arise when correlated predictors exist in the input data (Zhao and Yu, 2006).",
        "Its regularisation function ?el(?)",
        "is defined by:",
        "?",
        "to its extremes transforms elastic net to ridge regression (?",
        "= 0) or vanilla LASSO (?",
        "= 1).",
        "Eq.",
        "2 can be treated as a biconvex learning task (Al-Khayyal and Falk, 1983), by observing that for a fixed w, learning u is a convex problem and vice versa.",
        "Biconvex functions and possible applications have been well studied in the optimisation literature (Quesada and Grossmann, 1995; 4Note that other loss functions could be used here, such as logistic loss for classification, or more generally bilinear variations of Generalised Linear Models (Nelder and Wed-derburn, 1972).",
        "Pirsiavash et al., 2009).",
        "Their main advantage is the ability to solve efficiently non-convex problems by a repeated application of two convex processes, i.e., a form of coordinate ascent.",
        "In our case, the bilinear technique makes it possible to explore both word and user spaces, while maintaining a modest training complexity.",
        "Therefore, in our bilinear approach we divide learning in two phases, where we learn word and user weights respectively.",
        "For the first phase we produce the term-scores matrix V ?",
        "Rn?m with elements given by:",
        "V contains weighted sums of term frequencies over all users for the considered set of days.",
        "The weights are held in u and are representative of each user.",
        "The initial optimisation task is formulated as:",
        "where we aim to learn a sparse but consistent set of weights w?",
        "for the terms of our vocabulary.",
        "In the second phase, we are using w?",
        "to form the user-scores matrix D ?",
        "Rn?p:",
        "which now contains weighted sums over all terms for the same set of days.",
        "The optimisation task becomes:",
        "This process continues iteratively by inserting the weights of the second phase back to phase one, and so on until convergence.",
        "We cannot claim that a global optimum will be reached, but biconvexity guarantees that our global objective (Eq.",
        "2) will decrease in each step of this iterative process.",
        "In the remainder of this paper, we refer to the method described above as Bilinear Elastic Net (BEN)."
      ]
    },
    {
      "heading": "3.2 Exploiting term-target or user-target",
      "text": [
        "relationships The previous model assumes that the response variable y holds information about a single inference target.",
        "However, the task that we are addressing in this paper usually implies the existence of several targets, i.e., different political parties or politicians.",
        "An important property, therefore, is the ability to perform multiple output regression.",
        "A simple way of adapting the model to the multiple output scenario is by framing a separate learning problem for each output, but tying together some of the parameters.",
        "Here we consider tying together the user weights u, to enforce that the same set of users are relevant to all tasks, while learning different term weights.",
        "Note that the converse situation, where w's are tied and u's are independent, can be formulated in an equivalent manner.",
        "Suppose that our target variable y ?",
        "R?n refers now to ?",
        "political entities, y = [yT1yT2 ...yT?",
        "]T; in this formation the top n elements of y match to the first political entity, the next n elements to the second and so on.",
        "In the first phase of the bilinear model, we would have to solve the following optimisation task:",
        "where V is given by Eq.",
        "4 and w?",
        "?",
        "R?m denotes the vector of weights which can be sliced into ?",
        "sub-vectors {w?1, ...,w??}",
        "each one representing a political entity.",
        "In the second phase, sub-vectorsw?i are used to form the input matrices Di, i ?",
        "{1, ..., ?}",
        "with elements given by Eq.",
        "6.",
        "The input matrix D?",
        "is formed by the vertical concatenation of all Di user score matrices, i.e.,",
        "]T, and the optimisation target is equivalent to the one expressed in Eq.",
        "7.",
        "Since D?",
        "?",
        "R?n?p, the user weight vector u?",
        "?",
        "Rp and thus, we are learning a single weight per user and not one per political party as in the previous step.",
        "The method described above allows learning different term weights per response variable and then binds them under a shared set of user weights.",
        "As mentioned before, one could also try the opposite (i.e., start by expanding the user space); both those models can also be optimised in an iterative process.",
        "However, our experiments revealed that those approaches did not improve on the performance of BEN.",
        "Still, this behaviour could be problem-specific, i.e., learning different words",
        "from a shared set of users (and the opposite) may not be a good modelling practice for the domain of politics.",
        "Nevertheless, this observation served as a motivation for the method described in the next section, where we extract a consistent set of words and users that are weighted differently among the considered political entities."
      ]
    },
    {
      "heading": "3.3 Multi-task learning with the `1/`2 regulariser",
      "text": [
        "All previous models ?",
        "even when combining all inference targets ?",
        "were not able to explore relationships across the different task domains; in our case, a task domain is defined by a specific political label or party.",
        "Ideally, we would like to make a sparse selection of words and users but with a regulariser that promotes intertask sharing of structure, so that many features may have a positive influence towards one or more parties, but negative towards the remaining one(s).",
        "It is possible to achieve this multi-task learning property by introducing a different set of regularisation constraints in the optimisation function.",
        "We perform multi-task learning using an extension of group LASSO (Yuan and Lin, 2006), a method known as `1 /` 2 regularisation (Argyriou et al., 2008; Liu et al., 2009).",
        "Group LASSO exploits a predefined group structure on the feature space and tries to achieve sparsity in the group-level, i.e., it does not perform feature selection (unlike the elastic net), but group selection.",
        "The `1/`2 regulariser extends this notion for a ?",
        "-dimensional response variable.",
        "The global optimisation target is now formulated as:",
        "where the input matrix Qi is defined in the same way as earlier, W = [w1 ... w? ]",
        "is the term weight matrix (each wt refers to the t-th political entity or task), equivalently U = [u1 ... u?",
        "], Wj and Uj denote the j-throws of weight matrices W and U respectively, and vector ?",
        "?",
        "R?",
        "holds the bias terms per task.",
        "In this optimisation process, we aim to enforce sparsity in the feature space but in a structured manner.",
        "Notice that we are now regularising the `2,1 mixed norm ofW and U , which is defined as the sum of the row `2-norms for those matrices.",
        "As a result, we expect to encourage the activation of a sparse set of features (corresponding to the rows of W and U ), but with nonzero weights across the ?",
        "tasks (Argyriou et al., 2008).",
        "Consequently, we are performing filtering (many users and words will have zero weights) and, at the same time, assign weights of different magnitude and sign on the selected features, something that suits a political opinion mining application, where pro-A often means anti-B.",
        "Eq.",
        "9 can be broken into two convex tasks (following the same notion as in Eqs.",
        "5 and 7), where we individually learn {W,?}",
        "and then {U,?",
        "}; each step of the process is a standard linear regression problem with an `1/`2 regulariser.",
        "Again, we are able iterate this bilinear process and in each step convexity is guaranteed.",
        "We refer to this method as Bilinear Group `1/`2 (BGL)."
      ]
    },
    {
      "heading": "4 Experiments",
      "text": [
        "The proposed models are evaluated on Cuk and Cau which have been introduced in Section 2.",
        "We measure predictive performance, compare it to the performance of several competitive baselines, and provide a qualitative analysis of the parameters learned by the models."
      ]
    },
    {
      "heading": "4.1 Data preprocessing",
      "text": [
        "Basic preprocessing has been applied on the vocabulary index of Cuk and Cau aiming to filter out some of the word features and partially reduce the dimensionality of the problem.",
        "Stop words and web links were removed in both sets, together with character sequences of length <4 and <3 for Cuk and Cau respectively.5 As the vocabulary size of Cuk was significantly larger, for this data set we have additionally merged Twitter hashtags (i.e., words starting with ?#?)",
        "with their exact non topic word match, where possible (by dropping the ?#?",
        "when the word existed in the index).",
        "After performing the preprocessing routines described above, the vocabulary sizes for Cuk and Cau were set to 80,976 and 22,917 respectively."
      ]
    },
    {
      "heading": "4.2 Predictive accuracy",
      "text": [
        "To evaluate the predictive accuracy of our methods, we have chosen to emulate a real-life scenario 5Most of the times those character sequences were not valid words.",
        "This pattern was different in each language and thus, a different filtering threshold was applied in each data set.",
        "a validation set for BEN in 15 iterations (30 steps) of the model.",
        "of voting intention prediction.",
        "The evaluation process starts by using a fixed set of polls matching to consecutive time points in the past for training and validating the parameters of each model.",
        "Testing is performed on the following ?",
        "(unseen) polls of the data set.",
        "In the next step of the evaluation process, the training/validation set is increased by merging it with the previously used test set (?",
        "polls), and testing is now performed on the next ?",
        "unseen polls.",
        "In our experiments, the number of steps in this evaluation process is set to 10 and in each step the size of the test set is set to ?",
        "= 5 polls.",
        "Hence, each model is tested on 50 unseen and consecutive in time samples.",
        "The loss function in our evaluation is the standard Mean Square Error (MSE), but to allow a better interpretation of the results, we display its root (RMSE) in tables and figures.",
        "The parameters of each model (?i for BEN and ?i for BEN and BGL, i ?",
        "{1, 2}) are optimised using a held-out validation set by performing grid search.",
        "Note that it may be tempting to adapt the regularisation parameters in each phase of the iterative training loop, however this would change the global objective (see Eqs.",
        "2 and 9) and thus convergence will not be guaranteed.",
        "A key question is how many iterations of training are required to reach convergence.",
        "Figure 2 illustrates how the BEN global objective function (Eq.",
        "2) converges during this iterative process and the model's performance on an unseen validation set.",
        "Notice that there is a large performance improvement after the first step (which alone is a linear solver), but overfitting occurs after step 11.",
        "Based on this result, for subsequent experiments we run the training process for two iterations (4 steps), and take the",
        "resenting the error of the inferred voting intention percentage for the 10-step validation process; ?",
        "denotes the mean RMSE across the three political parties for each baseline or inference method.",
        "for the 10-step validation process.",
        "best performing model on the held-out validation set.",
        "We compare the performance of our methods with three baselines.",
        "The first makes a constant prediction of the mean value of the response variable y in the training set (B?",
        "); the second predicts the last value of y (Blast); and the third baseline (LEN) is a linear regression over the terms using elastic net regularisation.",
        "Recalling that each test set is made of 5 polls, Blast should be considered as a hard baseline to beat7 given that voting intentions tend to have a smooth behaviour.",
        "Moreover, improving on LEN partly justifies the usefulness of a bilinear approach compared to a linear one.",
        "Performance results comparing inferred voting intention percentages and polls for Cuk and Cau are presented in Tables 1 and 2 respectively.",
        "For the UK case study, both BEN and BGL are able to beat all baselines in average performance across all parties.",
        "However in the Austrian case study, LEN performs better that BEN, something that could be justified by the fact that the users in Cau were selected by domain experts, and consequently there was not much gain to be had by filtering them further.",
        "Nevertheless, the difference in performance was rather small (approx.",
        "0.26% error) and the in",
        "ture in the model, and would likely improve predictive performance.",
        "ence results (50 polls, 3 parties).",
        "Sub-figure 3a is a plot of ground truth as presented in voting intention polls (Fig.",
        "1a).",
        "ferences of LEN and BEN followed a very similar pattern (??",
        "= .94 with p < 10?10).8 Multi-task learning (BGL) delivered the best inference performance in both case studies, which was on average smaller than 1.48% (RMSE).",
        "Inferences for both BEN and BGL have been plotted on Figures 3 and 4.",
        "They are presented as continuous lines of 50 inferred points (per party) which are created by concatenating the inferences 8Pearson's linear correlation averaged across the four",
        "intention polls (Fig.",
        "1b).",
        "on all test sets.9 For the UK case study, one may observe that BEN (Fig.",
        "3b) cannot register any change ?",
        "with the exception of one test point ?",
        "in the leading party fight (CON versus LAB); BGL (Fig.",
        "3c) performs much better in that aspect.",
        "In the Austrian case study this characteristic becomes more obvious.",
        "BEN (Fig.",
        "4b) consistently predicts the wrong ranking of O?VP and FPO?, whereas BGL (Fig.",
        "4c) does much better.",
        "Most importantly, a",
        "kann das buch ?res publica?",
        "von johannes #voggenhuber wirklich empfehlen!",
        "so zum nachdenken und so... #europa #demokratie Translation: can really recommend the book ?res publica?",
        "by johannes #voggenhuber!",
        "Food for thought and so on #europe #democracy",
        "and the total number of selected features.",
        "general observation is that BEN's predictions are smooth and do not vary significantly with time.",
        "This might be a result of overfitting the model to a single response variable which usually has a smooth behaviour.",
        "On the contrary, the multi-task learning property of BGL reduces this type of overfitting providing more statistical evidence for the terms and users and thus, yielding not only a better inference performance, but also a more accurate model."
      ]
    },
    {
      "heading": "4.3 Qualitative Analysis",
      "text": [
        "In this section, we refer to features that have been selected and weighted as significant by our bilinear learning functions.",
        "Based on the weights for the word and the user spaces that we retrieve after the application of BGL in the last step of the evaluation process (see the previous section), we compute a score (weighted sum) for each tweet in our training data sets for both Cuk and Cau.",
        "Table 3 shows examples of interesting tweets amongst the top weighted ones (positively as well as negatively) per party.",
        "Together with their text (anonymised for privacy reasons) and scores, we also provide an attribute for the author (if present).",
        "In the displayed tweets for the UK study, the only possible outlier is the ?Art Fanzine?",
        "; still, it seems to register a consistent behaviour (positive towards",
        "LAB, negative towards LBD) and, of course, hidden, indirect relationships may exist between political opinion and art.",
        "The Austrian case study revealed even more interesting tweets since training was conducted on data from a very active pre-election period (we made an effort to translate those tweets in English language as well).",
        "For a better interpretation of the presented tweets, it may be useful to know that ?Johannes Voggen-huber?",
        "(who receives a positive comment for his book) and ?Peter Pilz?",
        "(whose comment is questioned) are members of GRU?, ?Krone?",
        "(or Kronen Zeitung) is the major newspaper in Austria10 and that FPO?",
        "is labelled as a far right party, something that may cause various reactions from ?Human Rights?",
        "organisations."
      ]
    },
    {
      "heading": "5 Related Work",
      "text": [
        "The topic of political opinion mining from Social Media has been the focus of various recent research works.",
        "Several papers have presented methods that aim to predict the result of an election (Tumasjan et al., 2010; Bermingham and Smeaton, 2011) or to model voting intention and other kinds of socio-political polls (O?Connor et al., 2010; Lampos, 2012).",
        "Their common feature is a methodology based on a meta-analysis of word frequencies using off-the-shelf sentiment tools such as LIWC (Pennebaker et al., 2007) or Senti-WordNet (Esuli and Sebastiani, 2006).",
        "Moreover, the proposed techniques tend to incorporate posting volume figures as well as hand-crafted lists of words relevant to the task (e.g., names of politicians or parties) in order to filter the content successfully.",
        "Such papers have been criticised as their methods do not generalise when applied on different data sets.",
        "According to the work in (Gayo-Avello et al., 2011), the methods presented in (Tumasjan et al., 2010) and (O?Connor et al., 2010) failed to predict the result of US congressional elections in 2009.",
        "We disagree with the arguments supporting the statement ?you cannot predict elections with Twitter?",
        "(Gayo-Avello, 2012), as many times in the past actual voting intention polls have also failed to predict election outcomes, but we agree that most methods that have been proposed so far were not entirely generic.",
        "It is a fact that the 10?Accused of abusing its near monopoly to manipulate public opinion in Austria?, Wikipedia, 19/02/2013, http: //en.wikipedia.org/wiki/Kronen_Zeitung.",
        "majority of sentiment analysis tools are English-specific (or even American English) and, most importantly, political word lists (or ontologies) change in time, per country and per party; hence, generalisable methods should make an effort to limit reliance from such tools.",
        "Furthermore, our work ?",
        "indirectly ?",
        "meets the guidelines proposed in (Metaxas et al., 2011) as we have developed a framework of ?well-defined?",
        "algorithms that are ?Social Web aware?",
        "(since the bilinear approach aims to improve noise filtering) and that have been tested on two evaluation scenarios with distinct characteristics."
      ]
    },
    {
      "heading": "6 Conclusions and Future Work",
      "text": [
        "We have presented a novel method for text regression that exploits both word and user spaces by solving a bilinear optimisation task, and an extension that applies multi-task learning for multi-output inference.",
        "Our approach performs feature selection ?",
        "hence, noise filtering ?",
        "on large-scale user-generated inputs automatically, generalises across two languages without manual adaptations and delivers some significant improvements over strong performance baselines (< 1.5% error when predicting polls).",
        "The application domain in this paper was politics, though the presented methods are generic and could be easily applied on various other domains, such as health or finance.",
        "Future work may investigate further modelling improvements achieved by applying different regularisation functions as well as the adaptation of the presented models to classification problems.",
        "Finally, in the application level, we aim at an in-depth analysis of patterns and characteristics in the extracted sets of features by collaborating with domain experts (e.g., political analysts)."
      ]
    },
    {
      "heading": "Acknowledgments",
      "text": [
        "This work was funded by the TrendMiner project (EU-FP7-ICT n.287863).",
        "All authors would like to thank the political analysts (and especially Paul Ringler) from SORA11 for their useful insights on politics in Austria.",
        "11SORA ?",
        "Institute for Social Research and Consulting, http://www.sora.at."
      ]
    }
  ]
}
