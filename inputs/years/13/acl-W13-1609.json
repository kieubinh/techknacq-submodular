{
  "info": {
    "authors": [
      "Ivan Habernal",
      "Tomáš Ptáček",
      "Josef Steinberger"
    ],
    "book": "WASSA",
    "id": "acl-W13-1609",
    "title": "Sentiment Analysis in Czech Social Media Using Supervised Machine Learning",
    "url": "https://aclweb.org/anthology/W13-1609",
    "year": 2013
  },
  "references": [
    "acl-J11-2001",
    "acl-P10-1141",
    "acl-P11-2008",
    "acl-W02-1011",
    "acl-W11-0705",
    "acl-W11-1704",
    "acl-W12-3703"
  ],
  "sections": [
    {
      "heading": "Abstract",
      "text": [
        "This article provides an in-depth research of machine learning methods for sentiment analysis of Czech social media.",
        "Whereas in English, Chinese, or Spanish this field has a long history and evaluation datasets for various domains are widely available, in case of Czech language there has not yet been any systematical research conducted.",
        "We tackle this issue and establish a common ground for further research by providing a large human-annotated Czech social media corpus.",
        "Furthermore, we evaluate state-of-the-art supervised machine learning methods for sentiment analysis.",
        "We explore different preprocessing techniques and employ various features and classifiers.",
        "Moreover, in addition to our newly created social media dataset, we also report results on other widely popular domains, such as movie and product reviews.",
        "We believe that this article will not only extend the current sentiment analysis research to another family of languages, but will also encourage competition which potentially leads to the production of high-end commercial solutions."
      ]
    },
    {
      "heading": "1 Introduction",
      "text": [
        "Sentiment analysis has become a mainstream research field in the past decade.",
        "Its impact can be seen in many practical applications, ranging from analyzing product reviews (Stepanov and Riccardi, 2011) to predicting sales and stock markets using social media monitoring (Yu et al., 2013).",
        "The users?",
        "opinions are mostly extracted either on a certain polarity scale, or binary (positive, negative); various levels of granularity are also taken into account, e.g., document-level, sentence-level, or aspect-based sentiment (Hajmohammadi et al., 2012).",
        "Most of the research in automatic sentiment analysis of social media has been performed in English and Chinese, as shown by several recent surveys, i.e., (Liu and Zhang, 2012; Tsytsarau and Palpanas, 2012).",
        "For Czech language, there have been very few attempts, although the importance of sentiment analysis of social media became apparent, i.e., during the recent presidential elections 1.",
        "Many Czech companies also discovered a huge potential in social media marketing and started launching campaigns, contests, and even customer support on Facebook?",
        "the dominant social network of the Czech online community with approximately 3.5 million users.2 However, one aspect still eludes many of them: automatic analysis of customer sentiment of products, services, or even a brand or a company name.",
        "In many cases, sentiment is still labeled manually, according to our information from one of the leading Czech companies for social media monitoring.",
        "Automatic sentiment analysis in the Czech environment has not yet been thoroughly targeted by the research community.",
        "Therefore it is necessary to create a publicly available labeled dataset as well as to evaluate the current state of the art for two reasons.",
        "First, many NLP methods must deal with high flection and rich syntax when processing the Czech language.",
        "Facing these issues may lead to novel",
        "approaches to sentiment analysis as well.",
        "Second, freely accessible and well-documented datasets, as known from many shared NLP tasks, may stimulate competition which usually leads to the production of cutting-edge solutions.3 This article focuses on document-level sentiment analysis performed on three different Czech datasets using supervised machine learning.",
        "As the first dataset, we created a Facebook corpus consisting of 10,000 posts.",
        "The dataset was manually labeled by two annotators.",
        "The other two datasets come from online databases of movie and product reviews, whose sentiment labels were derived from the accompanying star ratings from users of the databases.",
        "We provide all these labeled datasets under Creative Commons BY-NC-SA licence4 at http://liks.fav.zcu.cz/sentiment , together with the sources for all the presented experiments.",
        "The rest of this article is organized as follows.",
        "Section 2 examines the related work with a focus on the Czech research and social media.",
        "Section 3 thoroughly describes the datasets and the annotation process.",
        "In section 4, we list the employed features and describe our approach to classification.",
        "Finally, section 5 contains the results with a thorough discussion."
      ]
    },
    {
      "heading": "2 Related work",
      "text": [
        "There are two basic approaches to sentiment analysis: dictionary-based and machine learning-based.",
        "While dictionary-based methods usually depend on a sentiment dictionary (or a polarity lexicon) and a set of handcrafted rules (Taboada et al., 2011), machine learning-based methods require labeled training data that are later represented as features and fed into a classifier.",
        "Recent attempts have also investigated semi-supervised methods that incorporate auxiliary unlabeled data (Zhang et al., 2012).",
        "3E.g., named entity recognition based on Conditional Random Fields emerged from CoNLL-2003 named entity recognition shared task."
      ]
    },
    {
      "heading": "analysis",
      "text": [
        "The key point of using machine learning for sentiment analysis lies in engineering a representative set of features.",
        "Pang et al. (2002) experimented with unigrams (presence of a certain word, frequencies of words), bigrams, part-of-speech (POS) tags, and adjectives on a Movie Review dataset.",
        "Martineau and Finin (2009) tested various weighting schemes for unigrams based on TFIDF model (Manning et al., 2008) and proposed delta weighting for a binary scenario (positive, negative).",
        "Their approach was later extended by Paltoglou and Thelwall (2010) who proposed further improvement in delta TFIDF weighting.",
        "The focus of the current sentiment analysis research is shifting towards social media, mainly targeting Twitter (Kouloumpis et al., 2011; Pak and Paroubek, 2010) and Facebook (Go et al., 2009; Ahkter and Soria, 2010; Zhang et al., 2011; Lo?pez et al., 2012).",
        "Analyzing media with very informal language benefits from involving novel features, such as emoticons (Pak and Paroubek, 2010; Montejo-Ra?ez et al., 2012), character n-grams (Blamey et al., 2012), POS and POS ratio (Ahkter and Soria, 2010; Kouloumpis et al., 2011), or word shape (Go et al., 2009; Agarwal et al., 2011).",
        "In many cases, the gold data for training and testing the classifiers are created semi-automatically, as in, e.g., (Kouloumpis et al., 2011; Go et al., 2009; Pak and Paroubek, 2010).",
        "In the first step, random samples from a large dataset are drawn according to presence of emoticons (usually positive and negative) and are then filtered manually.",
        "Although large high-quality collections can be created very quickly using this approach, it makes a strong assumption that every positive or negative post must contain an emoticon.",
        "Balahur and Tanev (2012) performed experiments with Twitter posts as part of the CLEF 2012 Re-pLab5.",
        "They classified English and Spanish tweets by a small but precise lexicon, which contained also slang, combined with a set of rules that capture the manner in which sentiment is expressed in social media.",
        "Since the limited space of this paper does not allow us to present detailed evaluation from the related work, we recommend an in-depth survey by Tsytsarau and Palpanas (2012) for actual results obtained from the abovementioned methods."
      ]
    },
    {
      "heading": "2.2 Sentiment analysis in Czech environment",
      "text": [
        "Veselovska?",
        "et al (2012) presented an initial research on Czech sentiment analysis.",
        "They created a corpus which contains polarity categories of 410 news sentences.",
        "They used the Naive Bayes classifier and a classifier based on a lexicon generated from annotated data.",
        "The corpus is not publicly available, moreover, due to the small size of the corpus no strong conclusions can be drawn.",
        "Steinberger et al. (2012) proposed a semi-automatic ?triangulation?",
        "approach to creating sentiment dictionaries in many languages, including Czech.",
        "They first produced high-level gold-standard sentiment dictionaries for two languages and then translated them automatically into the third language by a state-of-the-art machine translation service.",
        "Finally, the resulting sentiment dictionaries were merged by taking overlap from the two automatic translations.",
        "A multilingual parallel news corpus annotated with opinions towards entities was presented in (Steinberger et al., 2011).",
        "Sentiment annotations were projected from one language to several others, which saved annotation time and guaranteed comparability of opinion mining evaluation results across languages.",
        "The corpus contains 1,274 news sentences where an entity (the target of the sentiment analysis) occurs.",
        "It contains 7 languages including Czech.",
        "Their research targets fundamentally different objectives from our research as they focus on news media and aspect-based sentiment analysis."
      ]
    },
    {
      "heading": "3 Datasets",
      "text": []
    },
    {
      "heading": "3.1 Social media dataset",
      "text": [
        "The initial selection of Facebook brand pages for our dataset was based on the ?top?",
        "Czech pages, according to the statistics from SocialBakers.6 We focused on pages with a large Czech fan base and a sufficient number of Czech posts.",
        "Using Facebook Graph API",
        "and Java Language Detector7 we acquired 10,000 random posts in the Czech language from nine different Facebook pages.",
        "The posts were then completely anonymized as we kept only their textual contents.",
        "Sentiment analysis of posts at Facebook brand pages usually serves as a marketing feedback of user opinions about brands, services, products, or current campaigns.",
        "Thus we consider the sentiment target to be the given product, brand, etc.",
        "Typically, users?",
        "complaints hold negative sentiment, whereas joy or happiness about the brand is taken as positive.",
        "We also added another class called bipolar which represents both positive and negative sentiment in one post.8 In some cases, the user's opinion, although being somehow positive, does not relate to the given page.",
        "Therefore the sentiment is treated as neutral in these cases, according to our above-mentioned assumption.",
        "The complete 10k dataset was independently annotated by two annotators.",
        "The inter-annotator agreement (Cohen's ?)",
        "between these two annotators reaches 0.66 which represents a substantial agreement level (Pustejovsky and Stubbs, 2013), therefore the task can be considered as well-defined.",
        "The gold data were created based on the agreement of the two annotators.",
        "They disagreed in 2,216 cases.",
        "To solve these conflicts, we involved a third super-annotator to assign the final sentiment label.",
        "However, even after the third annotator's la-beling, there was still no agreement for 308 labels.",
        "These cases were later solved by a fourth annotator.",
        "We discovered that most of these conflicting cases were classified as either neutral or bipolar.",
        "These posts were often difficult to label because the author used irony, sarcasm or the context or previous posts.",
        "These issues remain open.",
        "The Facebook dataset contains of 2,587 positive, 5,174 neutral, 1,991 negative, and 248 bipolar posts, respectively.",
        "We ignore the bipolar class later in all experiments.",
        "The sentiment distribution among the",
        "these posts are mostly positive (or funny, at least) but are irrelevant for the desired task.",
        "source pages is shown in Figure 1.",
        "The statistics reveal negative opinions towards cell phone operators and positive opinions towards, e.g., perfumes"
      ]
    },
    {
      "heading": "3.2 Movie review dataset",
      "text": [
        "Movie reviews as a corpus for sentiment analysis has been used in research since the pioneering research conducted by Pang et al. (2002).",
        "Therefore we covered the same domain in our experiments as well.",
        "We downloaded 91,381 movie reviews from the Czech Movie Database10 and split them into 3 categories according to their star rating (0?2 stars as negative, 3?4 stars as neutral, 5?6 stars as positive).",
        "The dataset contains of 30,897 positive, 30,768 neutral, and 29,716 negative reviews, respectively."
      ]
    },
    {
      "heading": "3.3 Product review dataset",
      "text": [
        "Another very popular domain for sentiment analysis deals with product reviews (Hu and Liu, 2004).",
        "We crawled all user reviews from a large Czech e-shop Mall.cz11 which offers a wide range of products.",
        "The product reviews are accompanied with star ratings on the scale 0?5.",
        "We took a different strategy for assigning sentiment labels.",
        "Whereas in the movie dataset the distribution of stars was rather uniform, in the product review domain the ratings were skewed towards the higher values.",
        "After a manual inspection we discovered that 4-star ratings mostly correspond to neutral opinions and 3 or less stars denote mostly negative comments.",
        "Thus we split the",
        "dataset into three categories according to this observation.",
        "The final dataset consists of 145,307 posts (102,977 positive, 31,943 neutral, and 10,387 negative)."
      ]
    },
    {
      "heading": "4 Classification",
      "text": []
    },
    {
      "heading": "4.1 Preprocessing",
      "text": [
        "As pointed out by Laboreiro et al. (2010), tokenization significantly affects sentiment analysis, especially in case of social media.",
        "Although Ark-tweet-nlp tool (Gimpel et al., 2011) was developed and tested in English, it yields satisfactory results in Czech as well, according to our initial experiments on the Facebook corpus.",
        "Its significant feature is proper handling of emoticons and other special character sequences that are typical for social media.",
        "Furthermore, we remove stopwords using the stop-word list from Apache Lucene project.12 In many NLP applications, a very popular preprocessing technique is stemming.",
        "We tested Czech light stemmer (Dolamic and Savoy, 2009) and High Precision Stemmer13.",
        "Another widely-used method for reducing the vocabulary size, and thus the feature space, is lemmatization.",
        "For Czech language the only currently available lemmatizer is shipped with Prague Dependency Treebank (PDT) toolkit (Hajic?",
        "et al, 2006).",
        "However, we use our in-house Java HMM-based implementation using the PDT training data as we need a better control over each preprocessing step.",
        "Part-of-speech tagging is done using our in-house Java solution that exploits Prague Dependency Treebank (PDT) data as well.",
        "However, since PDT is trained on news corpora, we doubt it is suitable for tagging social media that are written in very informal language (consult, i.e., (Gimpel et al., 2011) where similar issues were tackled in English).",
        "Since the Facebook dataset contains a huge number of grammar mistakes and misspellings (typically ?i/y?,?e?/je/ie?, and others), we incorporated phonetic transcription to International Phonetic Alphabet (IPA) in order to reduce the effect of these mistakes.",
        "We rely on eSpeak14 implementation.",
        "An",
        "other preprocessing step might involve removing diacritics, as many Czech users type only using unaccented characters.",
        "However, posts without diacritics represent only about 8% of our datasets, thus we decided to keep diacritics unaffected.",
        "The complete preprocessing diagram and its variants is depicted in Table 1.",
        "Overall, there are 10 possible preprocessing ?pipe?",
        "configurations."
      ]
    },
    {
      "heading": "4.2 Features",
      "text": [
        "N-gram features We use presence of unigrams and bigrams as binary features.",
        "The feature space is pruned by minimum n-gram occurrence which was empirically set to 5.",
        "Note that this is the baseline feature in most of the related work.",
        "Character n-gram features Similarly to the word n-gram features, we added character n-gram features, as proposed by, e.g., (Blamey et al., 2012).",
        "We set the minimum occurrence of a particular character n-gram to 5, in order to prune the feature space.",
        "Our feature set contains 3-grams to 6-grams.",
        "POS-related features Direct usage of part-of-speech n-grams that would cover sentiment patterns has not shown any significant improvement in the related work.",
        "Still, POS tags provide certain characteristics of a particular post.",
        "We implemented various POS features that include, e.g., the number of nouns, verbs, and adjectives (Ahkter and Soria, 2010), the ratio of nouns to adjectives and verbs to adverbs (Kouloumpis et al., 2011), and number of negative verbs.",
        "Emoticons We adapted the two lists of emoticons that were considered as positive and negative from (Montejo-Ra?ez et al., 2012).",
        "The feature captures number of occurrences of each class of emoticons within the text.",
        "Delta TFIDF variants for binary scenarios Although simple binary word features (presence of a certain word) reach surprisingly good performance, they have been surpassed by various TFIDF-based weighting, such as Delta TFIDF (Martineau and Finin, 2009), or Delta BM25 TFIDF (Paltoglou and Thelwall, 2010).",
        "Delta-TFIDF still uses traditional TFIDF word weighting but treats positive and negative documents differently.",
        "However, all the existing related works which use this kind of features deal only with binary decisions (positive/negative), thus we filtered out neutral documents from the datasets.15 We implemented the most promising weighting schemes from (Paltoglou and Thelwall, 2010), namely Augmented TF, LogAve TF, BM25 TF, Delta Smoothed IDF, Delta Prob.",
        "IDF, Delta Smoothed Prob.",
        "IDF, and Delta BM25 IDF."
      ]
    },
    {
      "heading": "4.3 Classifiers",
      "text": [
        "All evaluation tests were performed using two classifiers, Maximum Entropy (MaxEnt) and Support Vector Machines (SVM).",
        "Although Naive Bayes classifier is also widely used in the related work, we did not include it as it usually performs worse than SVM or MaxEnt.",
        "We used a pure Java framework for machine learning16 with default settings (linear kernel for SVM)."
      ]
    },
    {
      "heading": "5 Results",
      "text": [
        "For each combination from the preprocessing pipeline (refer to Table 1) we assembled various sets of features and employed two classifiers.",
        "In the first",
        "scenario, we classify into all three classes (positive, negative, and neutral).17 In the second scenario, we follow a strand of related research, e.g., (Martineau and Finin, 2009; Celikyilmaz et al., 2010), that deals only with positive and negative classes.",
        "For these purposes we filtered out all the neutral documents from the datasets.",
        "Furthermore, in this scenario we evaluate only features based on weighted delta-TFIDF, as, e.g., in (Paltoglou and Thelwall, 2010).",
        "We also involved only MaxEnt classifier into the second scenario.",
        "All tests were conducted in the 10-fold cross validation manner.",
        "We report macro F-measure, as it allows comparing classifier results on different datasets.",
        "Moreover, we do not report micro F-measure (accuracy) as it tends to prefer performance on dominant classes in highly unbalanced datasets (Manning et al., 2008), which is, e.g., the case of our Product Review dataset where most of the labels are positive."
      ]
    },
    {
      "heading": "5.1 Social media",
      "text": [
        "Table 2 shows the results for the 3-class classification scenario on the Facebook dataset.",
        "The row labels denote the preprocessing configuration according to Table 1.",
        "In most cases, maximum entropy classifier significantly outperforms SVM.",
        "The combination of all features (the last column) yields the best results regardless to the preprocessing steps.",
        "The reason might be that the involved character n-gram feature captures subtle sequences which represent subjective punctuation or emoticons, that were not covered by the emoticon feature.",
        "On average, the best results were obtained when HPS stemmer and lowercasing or phonetic transcription were involved (lines ShCl and ShPe).",
        "This configuration significantly outperforms other preprocessing techniques for token-based features (see column Unigr",
        "In the second scenario we evaluated various TFIDF weighting schemes for binary sentiment classification.",
        "The results are shown in Table 3.",
        "The three-character notation consists of term frequency, inverse document frequency, and normalization.",
        "Due to a large number of possible combinations, we report only the most successful ones, 17We ignore the bipolar posts in the current research.",
        "namely Augmented?a and LogAve?L term frequency, followed by Delta Smoothed??(t?",
        "), Delta Smoothed Prob.??(p?",
        "), and Delta BM25??",
        "(k) inverse document frequency; normalization was not involved.",
        "We can see that the baseline (the first column bnn) is usually outperformed by any weighted TFIDF technique.",
        "Moreover, using any kind of stemming (the row entitled various*) significantly improves the results.",
        "For the exact formulas of the delta TFIDF variants please refer to (Paltoglou and Thelwall, 2010).",
        "We also tested the impact of TFIDF word features when added to other features from the first scenario (refer to Table 2).",
        "Column FS1 in Table 3 displays results for a feature set with the simple binary presence-of-the-word feature (binary unigrams).",
        "In the last column FS2 we replaced this binary feature with TFIDF weighted feature a?(t?)n.",
        "It turned out that the weighed form of word feature does not improve the performance, when compared with simple binary unigram feature.",
        "Furthermore, a set of different features (words, bigrams, POS, emoticons, character n-grams) significantly outperforms a single TFIDF weighted feature.",
        "We also report the effect of the dataset size on the performance.",
        "We randomly sampled 10 subsets from the dataset (1k, 2k, etc.)",
        "and tested the performance; still using 10-fold cross validation.",
        "We took the most promising preprocessing configuration (ShCl) and MaxEnt classifier.",
        "As can be seen in Figure 2, while the dataset grows to approx 6k?7k items, the performance rises for most combinations of features.",
        "At 7k-items dataset, the performance begins to reach its limits for most combinations of features and hence adding more data does not lead to a significant improvement.",
        "5.1.1 Upper limits of automatic sentiment analysis To see the upper limits of the task itself, we also evaluate the annotator's judgments.",
        "Although the gold labels were chosen after a consensus of at least two people, there were many conflicting cases that must have been solved by a third or even a fourth person.",
        "Thus even the original annotators do not achieve 1.00 F-measure on the gold data.",
        "We present ?performance?",
        "results of both annotators and of the best system as well (MaxEnt classi",
        "measure, 95% confidence interval = ?0.01.",
        "Underlined numbers show the best results for TFIDF-weighted features.",
        "Bold numbers denote the best overall results.",
        "fier, all features, ShCl preprocessing).",
        "Table 4 shows the results as confusion matrices.",
        "For each class (p?positive, n?negative, 0?neutral) we also report precision, recall, and F-measure.",
        "The row headings denote gold labels, the column headings represent values assigned by the annotators or the system.18 The annotators?",
        "results show what can be expected from a ?perfect?",
        "system that would solve the task the way a human would.",
        "In general, both annotators judge all three classes with very similar F-measure.",
        "By contrast, the system's F-measure is very low for negative posts (0.54 vs. ?",
        "0.75 for neutral and positive).",
        "We offer the following explanation.",
        "First, many of the negative posts surprisingly contain happy emoticons, which 18Even though the task has three classes, the annotators also used ?b?",
        "for ?bipolar and ???",
        "for ?cannot decide?.",
        "?Best system?",
        "configuration: all features (unigram, bi-gram, POS, emoticons, character n-grams), ShCl preprocessing, and MaxEnt classifier.",
        "95% confidence interval = ?0.01.",
        "could be a misleading feature for the classifier.",
        "Second, the language of the negative posts in not as explicit as for the positive ones in many cases; the negativity is ?hidden?",
        "in irony, or in a larger context (i.e., ?Now I'm sooo satisfied with your competitor :))?).",
        "This remains an open issue for the future research."
      ]
    },
    {
      "heading": "5.2 Product and movie reviews",
      "text": [
        "For the other two datasets, the product reviews and movie reviews, we slightly changed the configuration.",
        "First, we removed the character n-grams from the feature sets, otherwise the feature space would become too large for feasible computing.",
        "Second, we abandoned SVM as it became computationally infeasible for such a large datasets.",
        "Table 5 (left-hand part) presents results on the product reviews.",
        "The combination of unigrams and bigrams works best, almost regardless of the preprocessing.",
        "By contrast, POS features rapidly decrease the performance.",
        "We suspect that POS features do not carry any useful information in this case and by introducing a lot of ?noise?",
        "they cause that the optimization function in the MaxEnt classifier fails to find a global minimum.",
        "In the right-hand part of Table 5 we can see the results on the movie reviews.",
        "Again, the bigram feature performs best, paired with combination of HPS stemmer and phonetic transcription (ShPe).",
        "Adding POS-related features causes a large drop in performance.",
        "We can conclude that for larger texts, the bigram-based feature outperforms unigram features and, in some cases, a proper preprocessing may further significantly improve the results."
      ]
    },
    {
      "heading": "6 Conclusion",
      "text": [
        "This article presented an in-depth research of supervised machine learning methods for sentiment analysis of Czech social media.",
        "We created a large Facebook dataset containing 10,000 posts, accompanied by human annotation with substantial agreement (Cohen's ?",
        "0.66).",
        "The dataset is freely available for non-commercial purposes.19 We thoroughly evaluated various state-of-the-art features and classifiers as well as different language-specific preprocessing techniques.",
        "We significantly outperformed the baseline (unigram feature without preprocessing) in three-class classification and achieved F-measure 0.69 using a combination of features (unigrams, bigrams, POS features, emoticons, character n-grams) and preprocessing techniques (unsupervised stemming and phonetic transcription).",
        "In addition, we reported results in two other domains (movie and product reviews) with a significant improvement over the baseline.",
        "To the best of our knowledge, this article is the only of its kind that deals with sentiment analysis in Czech social media in such a thorough manner.",
        "Not only it uses a dataset that is magnitudes larger than any from the related work, but also incorporates state-of-the-art features and classifiers.",
        "We believe that the outcomes of this article will not only help to set the common ground for sentiment analysis for the Czech language but also help to extend the research outside the mainstream languages in this research field."
      ]
    },
    {
      "heading": "Acknowledgement",
      "text": [
        "This work was supported by grant no.",
        "SGS-2013-029 Advanced computing and information 19We encourage other researchers to download our dataset for their research in the sentiment analysis field.",
        "sets.",
        "FS1 = Unigrams; FS2 = Uni + bigrams; FS3 = Uni + big + POS features; FS4 = Uni + big + POS + emot.",
        "Macro F-measure, 95% confidence interval ?0.002 (products), ?0.003 (movies).",
        "Bold numbers denote the best results.",
        "systems and by the European Regional Development Fund (ERDF), project ?NTIS - New Technologies for Information Society?, European Center of Excellence, CZ.1.05/1.1.00/02.0090.",
        "The access to computing and storage facilities owned by parties and projects contributing to the National Grid Infrastructure MetaCentrum, provided under the programme ?Projects of Large Infrastructure for Research, Development, and Innovations?",
        "(LM2010005) is highly acknowledged."
      ]
    }
  ]
}
