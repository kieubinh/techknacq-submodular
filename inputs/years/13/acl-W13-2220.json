{
  "info": {
    "authors": [
      "Antonio Valerio Miceli Barone",
      "Giuseppe Attardi"
    ],
    "book": "Workshop on Statistical Machine Translation",
    "id": "acl-W13-2220",
    "title": "Pre-Reordering for Machine Translation Using Transition-Based Walks on Dependency Parse Trees",
    "url": "https://aclweb.org/anthology/W13-2220",
    "year": 2013
  },
  "references": [
    "acl-C04-1010",
    "acl-C10-1043",
    "acl-D08-1078",
    "acl-D08-1089",
    "acl-D09-1105",
    "acl-D11-1045",
    "acl-N07-1049",
    "acl-N09-1028",
    "acl-P00-1056",
    "acl-P05-1012",
    "acl-P06-1067",
    "acl-P07-2045",
    "acl-W02-1001",
    "acl-W06-2922",
    "acl-W10-1736"
  ],
  "sections": [
    {
      "text": [
        "Proceedings of the Eighth Workshop on Statistical Machine Translation, pages 164?169, Sofia, Bulgaria, August 8-9, 2013 c?2013 Association for Computational Linguistics Pre-reordering for machine translation using transition-based walks on dependency parse trees"
      ]
    },
    {
      "heading": "Abstract",
      "text": [
        "We propose a pre-reordering scheme to improve the quality of machine translation by permuting the words of a source sentence to a target-like order.",
        "This is accomplished as a transition-based system that walks on the dependency parse tree of the sentence and emits words in target-like order, driven by a classifier trained on a parallel corpus.",
        "Our system is capable of generating arbitrary permutations up to flexible constraints determined by the choice of the classifier algorithm and input features."
      ]
    },
    {
      "heading": "1 Introduction",
      "text": [
        "The dominant paradigm in statistical machine translation consists mainly of phrase-based system such as Moses (Koehn et.al.,2007).",
        "Different languages, however, often express the same concepts in different idiomatic word orders, and while phrase-based system can deal to some extent with short-distance word swaps that are captured by short segments, they typically perform poorly on long-distance (more than four or five words apart) reordering.",
        "In fact, according to (Birch et.al., 2008), the amount of reordering between two languages is the most predictive feature of phrase-based translation accuracy.",
        "A number of approaches to deal with long-distance reordering have been proposed.",
        "Since an extuasive search of the permutation space is un-feasible, these approaches typically constrain the search space by leveraging syntactical structure of natural languages.",
        "In this work we consider approaches which involve reordering the words of a source sentence in a target-like order as a preprocessing step, before feeding it to a phrase-based decoder which has itself been trained with a reordered training set.",
        "These methods also try to leverage syntax, typically by applying hand-coded or automatically induced reordering rules to a constituency or dependency parse of the source sentence.",
        "(Galley and Manning, 2008; Xu et.al., 2009; Genzel, 2010; Isozaki et.al., 2010) or by treating reordering as a global optimization problem (Tromble and Eisner, 2009; Visweswariah et.al., 2011).",
        "In order to keep the training and execution processes tractable, these methods impose hard constrains on the class of permutations they can generate.",
        "We propose a pre-reordering method based on a walk on the dependency parse tree of the source sentence driven by a classifier trained on a parallel corpus.",
        "In principle, our system is capable of generating arbitrary permutations of the source sentence.",
        "Practical implementations will necessarily limit the available permutations, but these constraints are not intrinsic to the model, rather they depend on the specific choice of the classifier algorithm, its hyper-parameters and input features.",
        "2 Reordering as a walk on a dependency tree"
      ]
    },
    {
      "heading": "2.1 Dependency parse trees",
      "text": [
        "Let a sentence be a list of words s ?",
        "(w1, w2, .",
        ".",
        ".",
        ", wn) and its dependency parse tree be a rooted tree whose nodes are the words of the sentence.",
        "An edge of the tree represents a syntactical dependency relation between a head (parent) word and a modifier (child) word.",
        "Typical dependency relations include verb-subject, verb-object, noun-adjective, and so on.",
        "We assume that in addition to its head hi and dependency relation type di each word is also annotated with a part-of-speech pi and optionally a lemma li and a morphology mi (e.g. grammatical case, gender, number, tense).",
        "Some definitions require dependency parse trees to be projective, meaning that any complete",
        "subtree must correspond to a contiguous span of words in the sentence, however, we don't place such a requirement.",
        "In practice, languages with a substantially strict word ordering like English typically have largely projective dependencies, while languages with a more free word ordering like Czech can have substantial non-projectivity."
      ]
    },
    {
      "heading": "2.2 Reordering model",
      "text": [
        "Given a sentence s ?",
        "S with its dependency parse tree and additional annotations, we incrementally construct a reordered sentence s?",
        "by emitting its words in a sequence of steps.",
        "We model the reordering process as a non-deterministic transition system which traverses the parse tree: Let the state of the system be a tuple x ?",
        "(i, r, a, , .",
        ".",
        ". )",
        "containing at least the index of the current node i (initialized at the root), the list of emitted nodes r (initialized as empty) and the last transition action a (initialized as null).",
        "Additional information can be included in the state x, such as the list of the last K nodes that have been visited, the last K actions and a visit count for each node.",
        "At each step we choose one of the following actions:",
        "j) contains nodes that have not been emittedyet.",
        "hj = i, a 6= UP, ?k ?",
        "subtree(i) : k /?",
        "r (i, r, a, , .",
        ".",
        ". )",
        "DOWNj?",
        "(j, r, DOWNj , , .",
        ".",
        ". )",
        "The preconditions on the UP and DOWN actions prevent them from canceling each other, ensuring that progress is made at each step.",
        "The additional precondition on DOWN actions ensures that the process always halts at a final state where all the nodes have been emitted.",
        "Let T (s) be the set of legal traces of the transition system for sentence s. Each trace ?",
        "?",
        "T (s) defines a permutation s?",
        "of s as the list of emitted nodes r of its final state.",
        "We define the reordering problem as finding the trace ??",
        "that maximizes a scoring function ?",
        "Note that since the parse tree is connected, in principle any arbitrary permutation can be generated for a suitable choice of ?, though the maximization problem (1) is NP-hard and APX-complete in the general case, by trivial reduction from the traveling salesman problem.",
        "The intuition behind this model is to leverage the syntactical information provided by the dependency parse tree, as successfully done by (Xu et.al., 2009; Genzel, 2010; Isozaki et.al., 2010) without being strictly constrained by a specific type reordering rules."
      ]
    },
    {
      "heading": "2.3 Trace scores",
      "text": [
        "We wish to design a scoring function ?",
        "that captures good reorderings for machine translation and admits an efficient optimization scheme.",
        "We chose a function that additively decomposes into local scoring functions, each depending only on a single state of the trace and the following transition action",
        "(2) We further restrict our choice to a function which is linear w.r.t.",
        "a set of elementary local feature functions {fk}",
        "where {vk} ?",
        "R|F |is a vector of parameters derived from a training procedure.",
        "While in principle each feature function could depend on the whole sentence and the whole sequence of nodes emitted so far, in practice we restrict the dependence to a fixed neighborhood of the current node and the last few emitted nodes.",
        "This reduces the space of possible permutations."
      ]
    },
    {
      "heading": "2.4 Classifier-driven action selection",
      "text": [
        "Even when the permutation space has been restricted by an appropriate choice of the feature functions, computing an exact solution of the optimization problem (1) remains non-trivial, because",
        "at each step of the reordering generation process, the set of enabled actions depends in general on nodes emitted at any previous step, and this prevents us from applying typical dynamic programming techniques.",
        "Therefore, we need to apply an heuristic procedure.",
        "In our experiments, we apply a simple greedy procedure: at each step we choose an action according to the output a two-stage classifier:",
        "1.",
        "A three-class one-vs-all logistic classifier chooses an action among EMIT, UP or DOWN based on a vector of features extracted from a fixed neighborhood of the current node i, the last emitted nodes and additional content of the state.",
        "2.",
        "If a DOWN action was chosen, then a one",
        "vs-one voting scheme is used to choose which child to descend to: For each pair (j, j?)",
        ": j < j?",
        "of children of i, a binary logistic classifier assigns a vote either to j or j?.",
        "The child that receives most votes is chosen.",
        "This is similar to the max-wins approach used in packages such as LIBSVM (Chang and Lin, 2011) to construct a M class classifier from M (M ?",
        "1) /2 binary classifiers, except that we use a single binary classifier acting on a vector of features extracted from the pair of children (j, j?)",
        "and the node i, with their respective neighborhoods.",
        "We also experimented with different classification schemes, but we found that this one yields the best performance.",
        "Note that we are not strictly maximizing a global linear scoring function as as defined by equations (2) and (3), although this approach is closely related to that framework.",
        "This approach is related to transition-based dependency parsing such as (Nivre and Scholz, 2004; Attardi, 2006) or dependency tree revi-sion(Attardi and Ciaramita, 2007)."
      ]
    },
    {
      "heading": "3 Training",
      "text": []
    },
    {
      "heading": "3.1 Dataset preparation",
      "text": [
        "Following (Al-Onaizan and Papineni, 2006; Tromble and Eisner, 2009; Visweswariah et.al., 2011), we generate a source-side reference reordering of a parallel training corpus.",
        "For each sentence pair, we generate a bidirectional word alignment using GIZA++ (Och and Ney, 2000) and the ?grow-diag-final-and?",
        "heuristic implemented in Moses (Koehn et.al.,2007), then we assign to each source-side word a integer index corresponding to the position of the leftmost target-side word it is aligned to (attaching unaligned words to the following aligned word) and finally we perform a stable sort of source-side words according to this index.",
        "On language pairs where GIZA++ produces substantially accurate alignments (generally all European languages) this scheme generates a target-like reference reordering of the corpus.",
        "In order to tune the parameters of the downstream phrase-based translation system and to test the overall translation accuracy, we need two additional small parallel corpora.",
        "We don't need a reference reordering for the tuning corpus since it is not used for training the reordering system, however we generate a reference reordering for the test corpus in order to evaluate the accuracy of the reordering system in isolation.",
        "We obtain an alignment of this corpus by appending it to the training corpus, and processing it with GIZA++ and the heuristic described above."
      ]
    },
    {
      "heading": "3.2 Reference traces generation and classifier",
      "text": [
        "training For each source sentence s in the training set and its reference reordering s?, we generate a minimum-length trace ?",
        "of the reordering transition system, and for each state and action pair in it we generate the following training examples: ?",
        "For the first-stage classifier we generate a single training examples mapping the local features to an EMIT, UP or DOWN action label ?",
        "For the second-stage classifier, if the action is DOWNj , for each pair of children (k, k?)",
        ": k < k?",
        "of the current node i, we generate a positive example if j = k or a negative example if j = k?.",
        "Both classifiers are trained with the LIBLIN-EAR package (Fan et.al., 2008), using the L2-regularized logistic regression method.",
        "The regularization parameter C is chosen by twofold cross-validation.",
        "In practice, subsampling of the training set might be required in order to keep memory usage and training time manageable."
      ]
    },
    {
      "heading": "3.3 Translation system training and testing",
      "text": [
        "Once the classifiers have been trained, we run the reordering system on the source side of the",
        "whole (non-subsampled) training corpus and the tuning corpus.",
        "For instance, if the parallel corpora are German-to-English, after the reordering step we obtain German?-to-English corpora, where German?",
        "is German in an English-like word order.",
        "These reordered corpora are used to train a standard phrase-based translation system.",
        "Finally, the reordering system is applied to source side of the test corpus, which is then translated with the downstream phrase-based system and the resulting translation is compared to the reference translation in order to obtain an accuracy measure.",
        "We also evaluate the ?monolingual?",
        "reordering accuracy of upstream reordering system by comparing its output on the source side of the test corpus to the reference reordering obtained from the alignment."
      ]
    },
    {
      "heading": "4 Experiments",
      "text": [
        "We performed German-to-English and Italian-to-English reordering and translation experiments."
      ]
    },
    {
      "heading": "4.1 Data",
      "text": [
        "The German-to-English corpus is Europarl v7 (Koehn, 2005).",
        "We split it in a 1,881,531 sentence pairs training set, a 2,000 sentence pairs development set (used for tuning) and a 2,000 sentence pairs test set.",
        "We also used a 3,000 sentence pairs ?challenge?",
        "set of newspaper articles provided by the WMT 2013 translation task organizers.",
        "The Italian-to-English corpus has been assembled by merging Europarl v7, JRC-ACQUIS v2.2 (Steinberger et.al., 2006) and bilingual newspaper articles crawled from news websites such as Cor-riere.it and Asianews.it.",
        "It consists of a 3,075,777 sentence pairs training set, a 3,923 sentence pairs development set and a 2,000 sentence pairs test set.",
        "The source sides of these corpora have been parsed with Desr (Attardi, 2006).",
        "For both language pairs, we trained a baseline Moses phrase-based translation system with the default configuration (including lexicalized reordering).",
        "In order to keep the memory requirements and duration of classifier training manageable, we subsampled each training set to 40,000 sentences, while both the baseline and reordered Moses system are trained on the full training sets."
      ]
    },
    {
      "heading": "4.2 Features",
      "text": [
        "After various experiments with feature selection, we settled for the following configuration for both German-to-English and Italian-to-English: ?",
        "First stage classifier: current node i state-ful features (emitted?, left/right subtree emitted?, visit count), curent node lexical and syntactical features (surface form wi, lemma li, POS pi, morphology mi, DEPREL di, and pairwise combinations between lemma, POS and DEPREL), last two actions, last two visited nodes POS, DEPREL and visit count, last two emitted nodes POS and DEPREL, bi-gram and syntactical trigram features for the last two emitted nodes and the current node, all lexical, syntactical and stateful features for the neighborhood of the current node (left, right, parent, parent-left, parent-right, grandparent, left-child, right-child) and pairwise combination between syntactical features of these nodes.",
        "?",
        "Second stage classifier: stateful features for the current node i and the the children pair (j, j?",
        "), lexical and syntactical features for each of the children and pairwise combinations of these features, visit count differences and signed distances between the two children and the current node, syntactical trigram features between all combinations of the two children, the current node, the parent hi and the two last emitted nodes and the two last visited nodes, lexical and syntactical features for the two children left and right neighbors.",
        "All features are encoded as binary one-of-n indicator functions."
      ]
    },
    {
      "heading": "4.3 Results",
      "text": [
        "For both German-to-English and Italian-to-English experiments, we prepared the data as described above and we trained the classifiers on their subsampled training sets.",
        "In order to evaluate the classifiers accuracy in isolation from the rest of the system, we performed twofold cross validation on the same training sets, which revealed an high accuracy: The first stage classifier obtains approximately 92% accuracy on both German and Italian, while the second stage classifier obtains approximately 89% accuracy on German and 92% on Italian.",
        "We applied the reordering preprocessing system to the source side of the corpora and evaluated the monolingual BLEU and NIST score of the test sets (extracted from Europarl) against their reference reordering computed from the alignment To evaluate translation performance, we trained a Moses phrase-based system on the reordered training and tuning corpora, and evaluated the BLEU and NIST of the (Europarl) test sets.",
        "As a baseline, we also trained and evaluated Moses system on the original unreordered corpora.",
        "We also applied our baseline and reordered German-to-English systems to the WMT2013 translation task dataset."
      ]
    },
    {
      "heading": "5 Discussion",
      "text": [
        "Unfortunately we were generally unable to improve the translation scores over the baseline, even though our monolingual BLEU for German-to-English reordering is higher than the score reported by (Tromble and Eisner, 2009) for a comparable dataset.",
        "Accuracy on the WMT 2013 set is very low.",
        "We attribute this to the fact that it comes form a different domain than the training set.",
        "Since classifier training set cross-validation accuracy is high, we speculate that the main problem lies with the training example generation process: training examples are generated only from optimal reordering traces.",
        "This means that once the classifiers produce an error and the system strays away from an optimal trace, it may enter in a feature space that is not well-represented in the training set, and thus suffer from unrecoverable performance degradation.",
        "Moreover, errors occurring on nodes high in the parse tree may cause incorrect placement of whole spans of words, yielding a poor BLEU score (although a cursory examination of the reordered sentences doesn't reveal this problem to be prevalent).",
        "Both these issues could be possibly addressed by switching from a classifier-based system to a structured prediction system, such as averaged structured perceptron (Collins, 2002) or MIRA (Crammer, 2003; McDonald et.al., 2005).",
        "Another possible cause of error is the purely greedy action selection policy.",
        "This could be addressed using a search approach such as beam search.",
        "We reserve to investigate these approaches in future work."
      ]
    }
  ]
}
