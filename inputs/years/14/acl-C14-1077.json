{
  "info": {
    "authors": [
      "Kenji Imamura",
      "Ryuichiro Higashinaka",
      "Tomoko Izumi"
    ],
    "book": "COLING",
    "id": "acl-C14-1077",
    "title": "Predicate-Argument Structure Analysis with Zero-Anaphora Resolution for Dialogue Systems",
    "url": "https://aclweb.org/anthology/C14-1077",
    "year": 2014
  },
  "references": [
    "acl-C02-1122",
    "acl-C08-1097",
    "acl-C14-1088",
    "acl-D08-1055",
    "acl-D13-1121",
    "acl-J02-3001",
    "acl-J05-1004",
    "acl-J08-2006",
    "acl-J12-4003",
    "acl-N06-2015",
    "acl-P07-1033",
    "acl-P09-2022",
    "acl-P13-1116",
    "acl-W02-2016",
    "acl-W04-2412",
    "acl-W04-3230",
    "acl-W05-0620",
    "acl-W06-1617",
    "acl-W07-1522"
  ],
  "sections": [
    {
      "text": [
        "Abstract",
        "This paper presents predicate-argument structure analysis (PASA) for dialogue systems in Japanese.",
        "Conventional PASA and semantic role labeling have been applied to newspaper articles.",
        "Because pronominalization and ellipses frequently appear in dialogues, we base our PASA on a strategy that simultaneously resolves zero-anaphora and adapt it to dialogues.",
        "By incorporating parameter adaptation and automatically acquiring knowledge from large text corpora, we achieve a PASA specialized to dialogues that has higher accuracy than that for newspaper articles."
      ]
    },
    {
      "heading": "1 Introduction",
      "text": [
        "Semantic role labeling (SRL) and predicate-argument structure analysis (PASA) are important analysis techniques for acquiring ?who did what to whom?",
        "from sentences 1 .",
        "These analyses have been applied to written texts because most annotated corpora comprise newspaper articles (Carreras and M`arquez, 2004; Carreras and M`arquez, 2005; Matsubayashi et al., 2014).",
        "Recently, systems for speech dialogue between humans and computers (e.g., Siri of Apple Inc. and Shabette Concier of NTT DoCoMo) have become familiar with the popularization of smart phones.",
        "A man-machine dialogue system has to interpret human utterances to associate them with system utterances.",
        "The predicate-argument structure could be an effective data structure for dialogue management.",
        "However, it is unclear whether we can apply the SRL/PASA for newspaper articles to dialogues because there are many differences between them, such as the number of speakers, written or spoken language, and context processing.",
        "For example, the following dialogue naturally includes pronouns, and thus anaphora resolution is necessary for semantic role labeling.",
        "A: [I] ARG0 want [an iPad Air] ARG1 .",
        "B: [When] ARGM will [you] ARG0 buy [it(=an iPad Air)] ARG1 ?",
        "Similar phenomena exist in Japanese dialogues.",
        "However, most pronouns are omitted (called zero-pronouns), and zero-anaphora resolution is necessary for Japanese PASA.",
        "A: [iPad Air] NOM -ga hoshii-na.",
        "iPad Air NOM.",
        "want ??",
        "want an iPad Air.?",
        "B: itsu ?",
        "NOM ?",
        "ACC kau-no?",
        "when buy?",
        "?When will ?",
        "buy ???",
        "1 Recent SRL systems assign labels of predicates and their arguments as semantic roles.",
        "Consequently, SRL and PASA are very similar tasks.",
        "We use the term predicate-argument structure analysis in this paper because most Japanese analyzers use this term.",
        "806 This paper presents predicate-argument structure analysis with zero-anaphora resolution for Japanese chat dialogues.",
        "Here, we regard the task of constructing PASA for dialogues as a kind of domain adaptation from newspaper articles to dialogues.",
        "M`arquez et al. (2008) and Pradhan et al. (2008) indicated that the tuning of parameter distribution and reducing the out-of-vocabulary are important for the domain adaptation of SRL.",
        "We also focus on parameter distribution and out-of-vocabulary to construct a PASA adapted to dialogues.",
        "To the best of our knowledge, this is the first paper to describe a PASA for dialogues that include many zero-pronouns.",
        "The paper is organized as follows.",
        "Section 2 briefly reviews SRL/PASA in English and Japanese.",
        "Section 3 discusses characteristics of chat dialogues by comparing two annotated corpora, newspaper articles and dialogues.",
        "Section 4 describes the basic strategy of our PASA, and Section 5 shows how it was adapted for dialogues.",
        "Experiments are presented in Section 6, and Section 7 concludes the paper.",
        "2 Related Work 2.1 Semantic Role Labeling in English The advent of the supervised method proposed by Gildea and Jurafsky (2002) has led to the creation of annotated corpora for semantic role labeling.",
        "In the CoNLL-2004 and 2005 shared task (Carreras and M`arquez, 2004; Carreras and M`arquez, 2005), evaluations were carried out using the Proposition Bank (Palmer et al., 2005).",
        "Because the Proposition Bank was annotated to the Penn Treebank (i.e., the source texts were from the Wall Street Journal), the shared tasks were evaluated on newspaper articles.",
        "M`arquez et al. (2008) provides a review of SRL.",
        "OntoNotes Corpus (Hovy et al., 2006) contains multiple genres such as newswire, broadcast news, broadcast conversation.",
        "The annotation to OntoNotes includes semantic role labels compliant with the Proposition Bank.",
        "It is currently used for coreference resolution (Pradhan et al., 2012), and is expected to be applied to dialogue analysis.",
        "A few SRL studies have focused on not only verbal predicates (e.g., ?decide?)",
        "but also nominal predicates (e.g., ?decision?)",
        "(Jiang and Ng, 2006; Gerber and Chai, 2012; Laparra and Rigau, 2013).",
        "Because the subject and object of nominal predicates are frequently omitted (e.g., the object in the phrase ?the decision?",
        "is omitted), problems similar to the Japanese zero-pronouns have to be resolved in the SRL of nominal predicates.",
        "2.2 Predicate-Argument Structure Analyses in Japanese Japanese material includes the NAIST Text Corpus (Iida et al., 2007) 2 , which is an annotated corpus of predicate-argument structures and coreference information for newspaper articles.",
        "Argument noun phrases of the nominative, accusative, and dative cases are assigned to each predicate.",
        "The predicate and the noun phrases are not limited to the same sentence.",
        "If arguments of the predicate are represented as zero-pronouns, the antecedent noun phrases in other sentences are assigned as the arguments.",
        "Many PASA methods have been studied on the NAIST Text Corpus (Komachi et al., 2007; Taira et al., 2008; Imamura et al., 2009; Yoshikawa et al., 2011).",
        "In Japanese, some of them simultaneously resolve the zero-anaphora caused by zero-pronouns.",
        "Most English SRL and Japanese PASA currently target newspaper articles, and it is unclear whether the methods for newspapers can be applied to dialogue conversations.",
        "3 Characteristics of Chat Dialogues We first collected chat dialogues of two speakers and annotated them with the predicate-argument structure.",
        "The participants chatted via keyboard input.",
        "Therefore, fillers and repetitions, which are frequent in speech dialogues, were rare.",
        "The theme was one of 20 topics, such as meals, travel, hobbies, and TV/radio programs.",
        "Annotation of the predicate-argument structure complied with the NAIST Text Corpus.",
        "Figure 1 shows a chat dialogue example and its predicate-argument structure annotation.",
        "2 http://cl.naist.jp/nldata/corpus/.",
        "We use version 1.5 with our own preprocessing in this paper.",
        "NAIST is an acronym of ?Nara Institute of Science and Technology.?",
        "807 A: natsu-wa (exo2) NOM (exog) DAT dekake-tari-shimashi-ta-ka?",
        "?Did (you) NOM go (anywhere) DAT in this summer??",
        "B: 8-gatsu-wa Ito-no [hanabi-taikai] DAT -ni (exo1) NOM yuki-mashi-ta.",
        "?",
        "(I) NOM went to [ the fireworks ?1 ] DAT at Ito in August.?",
        "A: [ hanabi ?2 ] ACC , [ watashi ?3 ] NOM -mo mi-takatta-desu.",
        "?",
        "[ Fireworks ?2 ] ACC , [ I ?3 ] NOM also wanted to see (it).?",
        "A: demo, kotoshi-wa (exo1) NOM isogashiku-te (exo1) NOM ( * 2) ACC mi-ni ( * 2) DAT ike-masen-deshita.",
        "?But (I) NOM couldn't go (?2) DAT to see (it=*2) ACC this year because (I) NOM was busy.?",
        "Figure 1: Chat Dialogue Example and Its Predicate-Argument Structure Annotation Lower lines denote glosses of the upper lines.",
        "The bold words denote predicates, the square brackets [] denote intra-sentential arguments, and the round brackets () denote inter-sentential or exophoric arguments.",
        "# of Articles # of Sentences # of Words # of Predicates Corpus Set /Dialogues /Utterances (per Sentence) (per Sentence) NAIST Text Corpus Training 1,751 24,283 664,898 (27.4) 68,602 (2.83) Development 480 4,833 136,585 (28.3) 13,852 (2.87) Test 696 9,284 255,624 (27.5) 26,309 (2.83) Chat Dialog Corpus Training 184 6,960 61,872 (8.9) 7,470 (1.07) Test 101 4,056 38,099 (9.4) 5,333 (1.31) Table 1: Sizes of Corpora Zero-Zero- Exophora Case Corpus # of Arguments Dep Intra Inter exo1 exo2 exog Nominative NAIST 68,598 54.5% 17.3% 11.4% 2.0% 0.0% 14.7% Dialogue 7,467 31.8% 7.4% 12.6% 23.9% 5.6% 18.8% Accusative NAIST 27,986 89.2% 6.9% 3.4% 0.0% 0.0% 0.4% Dialogue 1,901 46.6% 12.8% 27.5% 0.8% 0.1% 12.2% Datative NAIST 6,893 84.7% 10.2% 4.3% 0.0% 0.0% 0.8% Dialogue 2,089 37.6% 7.8% 15.0% 2.5% 1.1% 36.1% Table 2: Distribution of Arguments in Training Corpora Table 1 shows the statistics of the NAIST Text Corpus and the Chat Dialogue Corpus we created 3 .",
        "The size of the Dialogue Corpus is about 10% of the NAIST Corpus.",
        "The NAIST Corpus is divided into three parts: training, development, and test.",
        "The Dialogue Corpus is divided into training and test.",
        "Table 2 shows distributions of arguments in the training sets of the NAIST/Dialogue corpora.",
        "We classified the arguments into the following six categories because each argument presents different difficulties for analysis by its position and syntactic relation.",
        "The first two categories (Dep and Zero-Intra) are the ones that in which the predicate and the argument occupy the same sentence.",
        "?",
        "Dep: The argument directly depends on the predicate and vice versa on the parse tree.",
        "?",
        "Zero-Intra: Intra-sentential zero-pronoun.",
        "The predicate and the argument are in the same sentence, but there is no direct dependency.",
        "?",
        "Zero-Inter: Inter-sentential zero-pronoun.",
        "The predicate and the argument are in different sentences.",
        "?",
        "exo1/exo2/exog: These are exophoric and denote zero-pronouns of the first person, second per-son, and the others (general), respectively.",
        "By Table 2, we can see that the ratios of Dep in all cases decreased in the Dialogue Corpus.",
        "In the other categories, the tendencies between the nominative case and the accusative/dative cases were different.",
        "In the nominative case, the Zero-Intra also decreased in the Dialogue Corpus, and the declines were 3 We regard a dialogue and an utterance as an article and a sentence, respectively.",
        "808 exo1 exo2 exogNULL Phrase 1 Phrase 2 Phrase 3 Phrase 4 ?",
        "Special Noun Phrases Candidate Argumentsin Past Sentences Candidate Argumentsin Current Sentence Candidate Arguments SelectorNominativeModel SelectorAccusativeModel SelectorDativeModel exo1exophoric(first person) zero-anaphoric(inter-sentential) Phrase 2 NULLno argument Figure 2: Structure of Argument Identification and Classification assigned to exo1 and exo2.",
        "Namely, the arguments in a sentence were reduced, and zero-pronouns increased compared with the newspaper articles.",
        "Note that many antecedents were the first or second person.",
        "On the other hand, in the accusative and dative cases, the declines of the Dep were assigned to the Zero-Inter or the exog in the Dialogue Corpus.",
        "Namely, anaphora resolution across multiple sentences is important to dialogue analysis.",
        "In contrast, most arguments and the predicate appear in the same sentence in the accusative/dative cases of newspapers.",
        "4 Basic Strategy for Predicate-Argument Structure Analysis and Zero-Anaphora Resolution 4.1 Architecture We use Imamura et al. (2009)'s method developed for newspaper articles as the base PASA in this paper.",
        "It can simultaneously identify arguments of a predicate in the sentence, those in other sentences, and exophoric arguments.",
        "The analyzer receives the entire article (dialogue) and performs the following steps for each sentence (utterance).",
        "1.",
        "The input sentences are tagged and parsed.",
        "During parsing, the base phrases and their headwords are also identified.",
        "At this time, the part-of-speech tags and the parse trees of the Dialogue Corpus are supplied by applying the morphological analyzer MeCab (Kudo et al., 2004) and the dependency parser CaboCha (Kudo and Matsumoto, 2002).",
        "The NAIST Corpus version 1.5 already includes the part-of-speech tags and the parse trees.",
        "2.",
        "Predicate phrases are identified from the sentences.",
        "We use the correct predicates in the corpora for the evaluation.",
        "When we build dialogue systems on PASA, predicate phrases will be identified using part-of-speech patterns that include verbs, adjectives, and copular verbs.",
        "3.",
        "For each predicate, candidate arguments are acquired from the sentence that includes the predicate (called the current sentence) and the past sentences.",
        "Concretely, the following base phrases are regarded as candidates.",
        "?",
        "All noun phrases in the current sentence are extracted as intra-sentential candidates regardless of syntactic relations.",
        "?",
        "From the past sentences, noun phrases are contextually extracted as inter-sentential candidates.",
        "Details are described in Section 4.4. ?",
        "Exophoric labels (exo1, exo2, and exog) and the NULL (the argument is not required) are added as special noun phrases.",
        "809 4.",
        "The features are generated from the predicate phrase, candidate arguments, and their relations.",
        "The best candidate for each case is independently selected (Figure 2).",
        "4.2 Models The models for the selector are based on maximum entropy classification.",
        "The selector identifies the best noun phrase n?",
        "that satisfies the following equations from the candidate argument set N. n?",
        "= argmax n j ?N P (d(n j ) = 1|X j ;M c ) (1) P (d(n j ) = 1|X j ;M c ) = 1 Z c (X) exp ?",
        "k {?",
        "ck f k (d(n j ) = 1, X j )} (2) Z c (X) = ?",
        "n j ?N exp ?",
        "k {?",
        "ck f k (d(n j ) = 1, X j )} (3) X j = ?n j , v, A?",
        "(4) where n denotes a candidate argument, N denotes a set of candidate arguments of predicate v, d(n) is a function that returns 1 iff candidate n becomes the argument, and M c denotes the model of case c. In addition, f k (d(n j ) = 1, X j ) is a feature function, ?",
        "ck denotes a weight parameter of the feature function, and A denotes the article from which all sentences are parsed.",
        "Training phase optimizes the weight parameters in order to maximize the difference in posterior probabilities among the correct noun phrase and the other candidates.",
        "Specifically, the model of case M c is learnt by minimizing the following loss function ` c .",
        "` c = ?",
        "?",
        "i logP (d(n i ) = 1|X i ;M c ) + 1 2C ?",
        "k ||?",
        "ck || 2 (5) where n i denotes the correct noun phrase of the i-th predicate in the training set, X i denotes the i-th tuple of the correct noun phrase, the predicate, and the article ?n i , v i , A i ?.",
        "Since the posterior probability is normalized for each set of candidate arguments of a predicate by Equation (3), the probability of the correct noun phrase approaches closer to 1.0, and the probabilities of the other candidates approach closer to 0.0 in Equation (5).",
        "4.3 Features Similar to other studies (e.g., (Gildea and Jurafsky, 2002)), we use three types of features: 1) predicate features, 2) noun phrase (NP) features, and 3) the relationship between predicates and noun phrases (Table 3).",
        "We also introduce combined features of the ?Noun?",
        "with all other binary features because the features aim to select the best noun phrase.",
        "The special features in this paper are the dependency language models (three types) and the obligatory case information (?Frame?",
        "feature), which are automatically acquired from large text corpora.",
        "We discuss them in Section 5.2.",
        "4.4 Context Processing Contexts of dialogues and newspaper articles are different.",
        "We should employ context processing specialized for the dialogues.",
        "However, contexts, including system and user utterances, should be managed collectively by the dialogue manager from the viewpoint of dialogue systems.",
        "Thus, this study uses the same context processing for the newspaper articles and dialogues.",
        "Note that the method in this paper controls the context by selecting the inter-sentential candidates.",
        "We can easily alter context management by providing candidate arguments from an external manager.",
        "Context processing in this paper is as follows.",
        "?",
        "From the current sentence, trace back to the past, and find a sentence that contains the other predicate (we call this the prior sentence).",
        "This process aims to ignore utterances that do not contain predicates.",
        "810 Type Name Value Remark Predicate Pred Binary Lemma of the predicate.",
        "PType Binary Type of predicate.",
        "One of ?verb?, ?adjective?, and ?copular verb?.",
        "Voice Binary Declarative or not.",
        "If not, the passive/causative auxiliary verb is assigned.",
        "Suffix Binary Sequence of the functional words of the main clause.",
        "This feature aims to reflect the speech act of the utterance.",
        "Frame Binary Obligatory case information.",
        "The case requires argument (1) or not (0).",
        "Noun Phrase Noun Binary Headword of the NP Particle Binary Case particle of the base phrase.",
        "If the NP is a special noun phrase, this is NULL.",
        "NType Binary If the substance of the NP is in the article, this is ?NP?",
        "; otherwise the same value of the ?Noun?",
        "feature.",
        "Surround Binary POS tags of the surrounding words of the NP.",
        "The window size is ?2.",
        "Relation between Predicate and NP PhPosit Binary Distance between the predicate and the NP.",
        "If they are in different sentences, or the NP is an exophora, this is NULL.",
        "Syn Binary Dependency path between the predicate and the NP.",
        "If they are in different sen-tences, or the NP is an exophora, this is NULL.",
        "Speaker Binary Whether the speakers of the predicate and the NP are the same (SAME) or not (OTHER).",
        "Dependency Language Models log P (n|c, v) Real Generation probability of NP n given predicate v and case c. log P (v|c, n) Real Generation probability of predicate v given NP n and case c. log P (c|n) Real Generation probability of case c given NP n. Table 3: List of Features ?",
        "All noun phrases that lie between the prior to the current sentence are added to the candidate arguments.",
        "In addition, noun phrases that are used as arguments of any predicates are also added (called argument recycling (Imamura et al., 2009)).",
        "Argument recycling covers wide contexts because it can employ distant noun phrases if the past predicates have inter-sentential arguments.",
        "5 Adaptation to Chat Dialogues The method described in the previous section is common to dialogues and newspaper articles.",
        "This section describes the adaptation made to target dialogues.",
        "5.1 Adaptation of Model Parameters In order to tune the difference in the argument distribution, model parameters of the selectors are adapted to the dialogue domain.",
        "We use the feature augmentation method (Daum?e, 2007) as the domain adaptation technique; it has the same effect as regarding the source domain to be prior knowledge, and the parameters are optimized to the target domain.",
        "Concretely, the models of the selectors are learnt and applied as follows.",
        "1.",
        "First, the feature space is segmented into three parts: common, source, and target.",
        "2.",
        "The NAIST Corpus and the Dialogue Corpus are regarded as the source and the target domains, respectively.",
        "The features from the NAIST Corpus are deployed to the common and the source spaces, and those from the Dialogue Corpus are deployed to the common and the target spaces.",
        "3.",
        "The parameters are estimated in the usual way on the above feature space.",
        "The weights of the common features are emphasized if the features are consistent between the source and target.",
        "With regard to domain-dependent features, the weights in the respective space, source or target, are emphasized.",
        "4.",
        "When the argument is identified, the selectors use only the features in the common and target spaces.",
        "The parameters in the spaces are optimized to the target domain, plus we can utilize the features that appear only in the source domain data.",
        "5.2 Weak Knowledge Acquisition from Very Large Resources In this paper, we use two types of knowledge to reduce the harmful effect of out-of-vocabulary in the training corpus.",
        "Both types are constructed by automatically analyzing, summing up, and filtering large 811 text corpora (Kawahara and Kurohashi, 2002; Sasano et al., 2008; Sasano et al., 2013).",
        "They provide information about unknown words with some confidence but they do contain some errors.",
        "We use them as the features of the models, and parameters are optimized by the discriminative learning of the selectors.",
        "5.2.1 Obligatory Case Information (Frame Feature) Case frames are important clues for SRL and PASA.",
        "The obligatory case information (OCI) comprises subsets of the case frames that only clarify whether the cases of each predicate are necessary or not.",
        "The OCI dictionary is automatically constructed from large text corpora as follows.",
        "The process assumes that 1) most of the cases match the case markers if the noun phrase directly depends on the predicate, and 2) if the case is obligatory, the occurrence rate on a specific predicate is higher than the average rate of all predicates.",
        "1.",
        "Similar to PASA in this paper (c.f., Section 4.1), predicates and base phrases are identified by tagging and parsing raw texts.",
        "2.",
        "Noun phrases that directly depend on the predicate and accompany a case marker are extracted.",
        "We sum up the frequency of the predicate and cases.",
        "3.",
        "Highly frequent predicates are selected according to the final dictionary size.",
        "Obligation of the cases is determined so as to satisfy the following two conditions.",
        "?",
        "Co-occurrence of the predicate and the case ?v, c?",
        "are higher than the significance level (p ?",
        "0.001; LLR ?",
        "10.83) by the log-likelihood-ratio test.",
        "?",
        "The case of the predicate appears at least 10% more frequently than the average of all predicates.",
        "We constructed two OCI dictionaries.",
        "The Blog dictionary contains about 480k predicates from one year of blogs (about 2.3G sentences,).",
        "The News dictionary contains about 200k predicates from 12 years of newspaper articles (about 7.7M sentences).",
        "The coverage of predicates in the training set of the Dialogue Corpus was 98.5% by the Blog dictionary and 96.4% by the News dictionary.",
        "5.2.2 Dependency Language Models Dependency language models (LMs) represent semantic/pragmatic collocations among predicate v, case c, and noun phrase n. The generation probabilities of v, c, and n are computed by n-gram models.",
        "More concretely, the following real values are computed.",
        "The purpose of the biases (probabilities involved <unk>) is to correct the values to be positive.",
        "?",
        "logP (n|c, v) ?",
        "logP (<unk>|c, v) ?",
        "logP (v|c, n) ?",
        "logP (v|c,<unk>) ?",
        "logP (c|n) ?",
        "logP (c|<unk>) Each dependency LM is constructed from the tuples of ?v, c, n?",
        "extracted in Section 5.2.1 using the SRILM (Stolcke et al., 2011).",
        "Note that since the obligatory case information corresponds to the generation probability of the case (P (c|v)), we exclude it from the dependency LMs.",
        "Similar to the OCI dictionaries, we constructed two sets of dependency language models from the Blog and the News sentences.",
        "The coverage of triples ?v, c, n?",
        "appeared in the training set of the Dialogue Corpus was 76.4% by the Blog LMs and 38.3% by the News LMs.",
        "The Blog LMs cover the Dialogue Corpus more comprehensively than the News LMs.",
        "6 Experiments We evaluate the accuracies of the proposed PASA on the Dialogue Corpus (Table 1) from the perspectives of parameter adaptation and the effect of the automatically acquired knowledge.",
        "The evaluation metric is F-measure of each case (includes exophora identification).",
        "812 a) Adaptation b) NAIST?",
        "c) Dialogue?",
        "d) Adaptation e) Adaptation # of OCI:Blog OCI:Blog OCI:Blog OCI:News?",
        "OCI:Blog Case Type Args.",
        "LMs:Blog LMs:Blog LMs:Blog LMs:Blog LMs:News?",
        "Nominative Dep 1,811 83.3%??",
        "77.6% 82.7% 83.0% 82.7% Zero-Intra 511 37.4% 43.7%?",
        "36.6% 36.5% 38.1% Zero-Inter 767 8.6% ?",
        "9.1% 9.0% 8.3% 4.5% exo1 1,193 70.2%?",
        "13.5% 69.9% 70.1% 70.3% exo2 281 46.8%??",
        "0.0% 43.1% 47.2% 46.8% exog 767 46.8%?",
        "32.5% 27.9% 47.2% 47.7%?",
        "Total 5,330 61.5%?",
        "44.4% 61.1% 61.4% 61.4% Accusative Dep 614 84.2%??",
        "?",
        "78.6% 81.5% 84.2% 82.4% Zero-Intra 149 42.9%?",
        "??",
        "27.1% 45.0% 38.9% 34.3% Zero-Inter 399 30.4%?",
        "?",
        "0.5% 30.9% 29.4% 24.3% exo1 19 0.0% 0.0% 0.0% 9.5% 10.0% exo2 7 0.0% 0.0% 0.0% 0.0% 0.0% exog 98 25.6%?",
        "0.0% 27.9% 25.2% 25.6% Total 1,286 59.0%?",
        "?",
        "51.6% 58.9% 58.4% 56.0% Dative Dep 566 80.5%??",
        "54.0% 79.0% 80.1% 80.7% Zero-Intra 70 20.7%?",
        "?",
        "0.0% 20.0% 20.7% 11.8% Zero-Inter 169 14.6%?",
        "0.0% 14.8% 14.4% 13.4% exo1 32 0.0% 0.0% 0.0% 0.0% 0.0% exo2 4 0.0% 0.0% 0.0% 0.0% 0.0% exog 265 45.4%??",
        "0.0% 43.1% 44.0% 44.9% Total 1,106 58.6%??",
        "32.2% 57.2% 58.2% 58.4% Table 4: F-measures among Methods/OCI dictionary/Dependency LMs on Dialogue Test Set The bold values denote the highest F-measures among all methods.",
        "The marks ?, ?, ?, ?",
        "denote significantly better methods by comparing a) with b), c), d), and e), respectively.",
        "We used the bootstrap resampling method (1,000 iterations) as the significance test, in which the significance level was 0.05.",
        "6.1 Experiment 1: Effect of Parameter Adaptation We compared three methods in order to evaluate parameter adaptation: a) The feature augmentation is applied to the training (Adaptation).",
        "b) Only the NAIST Corpus is used for training (NAIST Training).",
        "c) Only the Dialogue Corpus is used (Dialogue Training).",
        "The NAIST Training corresponds to a conventional PASA for newspaper articles.",
        "The results on the Dialogue test set are shown in the 4th, 5th, and 6th columns in Table 4.",
        "First, comparing methods a) Adaptation and b) NAIST training, Adaptation was better than the NAIST training for most types (The ?",
        "mark denotes ?significantly better?).",
        "In particular, the total F-measures of all cases were significantly better than NAIST training.",
        "Focusing on the types of arguments, the most characteristic results were exophoras of the first/second persons (exo1 and exo2) of the nominative case.",
        "These two types dominate of the nominative case (about 28%), and exo1 (70.2%) and exo2 (46.8%) became analyzable.",
        "Other types such as the Zero-Inter and the exog of the accusative and dative cases, which could not be analyzed by NAIST training, became analyzable.",
        "Comparing methods a) Adaptation and c) Dialogue training (c.f., ?",
        "), the F-measures of Dialogue training approached those of Adaptation even though the size of the Dialogue Corpus was small.",
        "Only the F-measure of the dative case of Adaptation was significantly better than Dialogue training in total.",
        "This does not imply that the corpus size is sufficient.",
        "Rather, we suppose that the Adaptation strategy could not adequately utilize the advantages of the NAIST Corpus.",
        "Adding more dialogue data would further improve the accuracies on the Dialogue test set.",
        "6.2 Experiment 2: Differences among Automatically Acquired Knowledge The columns a), d), and e) in Table 4 show the results for the proposed method (Adaptation).",
        "Note that the combination of the OCI dictionary and the dependency language models were changed to a) ?Blog, Blog?, d) ?News, Blog?, and e) ?Blog, News?.",
        "When the OCI dictionary was changed from a) Blog to d) News (c.f., ?",
        "), there were no significant differences in almost all types except for the Zero-Intra of the accusative case.",
        "We suppose that this 813 is because the coverage of the Blog and News dictionaries were almost the same, and obligatory cases of predicates are general information regardless of the domain.",
        "On the contrary, when the dependency LMs were changed from a) Blog to e) News (c.f., ?",
        "), the F-measures of some types significantly dropped, especially the Zero-Intra and Zero-Inter types, which are strongly influenced by semantic relation.",
        "For example, the Zero-Inter type of the accusative case was changed from 30.4% to 24.3%, and the F-measure consequently decreased by 3.0 points in total in the accusative case.",
        "Zero-anaphora resolution cannot rely on syntax, and the dependency LMs that measure semantic collocation become relatively important.",
        "The Blog LMs yielded greater coverage than the News LMs in this experiment.",
        "We can conclude that high-coverage LMs are better for improving the zero-anaphora resolution.",
        "7 Conclusion This paper presented predicate-argument structure analysis with zero-anaphora resolution for dialogues.",
        "We regarded this task as a kind of domain adaptation from newspaper articles, which are conventionally studied, to dialogues.",
        "The model parameters were adapted to the dialogues by using a domain adaptation technique.",
        "In order to address the out-of-vocabulary issue, the obligatory case information and the dependency language models were constructed from large text corpora and applied to the selectors.",
        "As a result, arguments that could not be analyzed by PASA for newspaper articles (e.g., zero-pronouns of the first and second persons in the nominative case) became analyzable by adding only a small number of dialogues.",
        "The parameter adaptation achieved some improvement.",
        "Moreover, we confirmed that high-coverage dependency LMs contribute to improving zero-anaphora resolution and the overall accuracy.",
        "Although we focused on parameter distribution and out-of-vocabulary in this paper, there are the other differences between dialogues and newspaper articles.",
        "For example, we did not discuss the exchange of turns, which is a special phenomenon of dialogues.",
        "To consider further phenomena is our future work.",
        "We are also evaluating the effectiveness of our PASA by incorporating it into a dialogue system (Higashinaka et al., 2014).",
        "References"
      ]
    }
  ]
}
