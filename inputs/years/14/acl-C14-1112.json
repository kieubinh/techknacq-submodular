{
  "info": {
    "authors": [
      "Kazushi Yoshida",
      "Tomohiro Ohno",
      "Yoshihide Kato",
      "Shigeki Matsubara"
    ],
    "book": "COLING",
    "id": "acl-C14-1112",
    "title": "Japanese Word Reordering Integrated with Dependency Parsing",
    "url": "https://aclweb.org/anthology/C14-1112",
    "year": 2014
  },
  "references": [
    "acl-C00-2109",
    "acl-C00-2126",
    "acl-C04-1097",
    "acl-C08-1027",
    "acl-E99-1026",
    "acl-J03-1005",
    "acl-N10-1127",
    "acl-P07-1041",
    "acl-P12-2061",
    "acl-P99-1018",
    "acl-W01-0810",
    "acl-W02-2016",
    "acl-W06-1402"
  ],
  "sections": [
    {
      "text": [
        "Japanese Word Reordering Integrated with Dependency Parsing Kazushi Yoshida 1,a) Tomohiro Ohno 2,b) Yoshihide Kato 3,c) Shigeki Matsubara 1,d) 1 Graduate School of Information Science, Nagoya University, Japan 2 Information Technology Center, Nagoya University, Japan 3 Information & Communications, Nagoya University, Japan a) yoshida@db.ss.is.nagoya-u.ac.jp b) ohno@nagoya-u.jp c) yoshihide@icts.nagoya-u.ac.jp d) matubara@nagoya-u.jp",
        "Abstract",
        "Although Japanese has relatively free word order, Japanese word order is not completely arbitrary and has some sort of preference.",
        "Since such preference is incompletely understood, even native Japanese writers often write Japanese sentences which are grammatically well-formed but not easy to read.",
        "This paper proposes a method for reordering words in a Japanese sentence so that the sentence becomes more readable.",
        "Our method can identify more suitable word order than conventional word reordering methods by concurrently performing dependency parsing and word reordering instead of sequentially performing the two processing steps.",
        "As the result of an experiment on word reordering using newspaper articles, we confirmed the effectiveness of our method."
      ]
    },
    {
      "heading": "1 Introduction",
      "text": [
        "Japanese has relatively free word order, and thus Japanese sentences which make sense can be written without having a strong awareness of word order.",
        "However, Japanese word order is not completely arbitrary and has some sort of preference.",
        "Since such preference is incompletely understood, even native Japanese writers often write Japanese sentences which are grammatically well-formed but not easy to read.",
        "The word reordering of such sentences enables the readability to be improved.",
        "There have been proposed some methods for reordering words in a Japanese sentence so that the sentence becomes easier to read (Uchimoto et al., 2000; Yokobayashi et al., 2004).",
        "In addition, there exist a lot of researches for estimating appropriate word order in various languages (Filippova and Strube, 2007; Harbusch et al., 2006; Kruijff et al., 2001; Ringger et al., 2004; Shaw and Hatzivassiloglou, 1999).",
        "Although most of these previous researches used syntactic information, the sentences they used there were what had been previously parsed.",
        "It is a problem that word reordering suffers the influence of parsing errors.",
        "Furthermore, as the related works, there are various researches on word reordering for improving the performance of statistical machine translation (Goto et al., 2012; Elming, 2008; Ge, 2010; Christoph and Hermann, 2003; Nizar, 2007).",
        "These researches consider information as to both a source language and a target language to handle word order differences between them.",
        "Therefore, their problem setting is different from that for improving the readability of a single language.",
        "This paper proposes a method for reordering words in a Japanese sentence so that the sentence becomes easier to read for revision support.",
        "Our proposed method concurrently performs dependency parsing and word reordering for an input sentence of which the dependency structure is still unknown.",
        "Our method can identify more suitable word order than conventional word reordering methods because it can concurrently consider the preference of both word order and dependency.",
        "An experiment using newspaper articles showed the effectiveness of our method.",
        "2 Word Order and Dependency in Japanese Sentences There have been a lot of researches on Japanese word order in linguistics (for example, Nihongo Kijutsu Bunpo Kenkyukai, 2009; Saeki, 1998), which have marshalled fundamental contributing factors which This work is licenced under a Creative Commons Attribution 4.0 International License.",
        "1186 naganen(for years) sekaiju-no(all over the world) hitobito-ga(people) torikun-de-ki-ta(have tackled) kare-ga(He) mondai-wo(theproblem) tsuini(finally) S1 (inappropriate word order) kaiketsu-shi-ta(resolved) ?He finally resolved the problem that people all over the world have tackled for years.?",
        "S2 (appropriate word order) naganen(for years) sekaiju-no(all over the world) hitobito-ga(people) torikun-de-ki-ta(have tackled) kare-ga(He) mondai-wo(theproblem) tsuini(finally) kaiketsu-shi-ta(resolved) Figure 1: Example of inappropriate/appropriate word order decide the appropriate word order in detail.",
        "In a Japanese sentence, a predicate of the main clause is fundamentally placed in last position, and thus, case elements, adverbial elements, or subordinate clauses are located before it.",
        "In addition, case elements are basically placed in the order of a nominative, a dative and an accusative.",
        "However, the basic order of case elements is often changed by being influenced from grammatical and discourse factors.",
        "For example, it is pointed out that a long case element has strong preference to be located at the beginning of a sentence even if the element is not nominative, as shown in Figure 1.",
        "In Figure 1, a box and an arrow express a bunsetsu 1 and a dependency relation respectively.",
        "Both the sentences S1 and S2 have the same meaning which is translated as ?He finally resolved the problem that people all over the world have tackled for years?",
        "in English.",
        "The difference between S1 and S2 is just in their word orders in Japanese.",
        "The word order of S1 is more difficult to read than that of S2 because the distance between the bunsetsu ?kare-ga (He)?",
        "and its modified bunsetsu ?kaiketsu-shi-ta (resolved)?",
        "is large and thus the loads on working memory become large.",
        "This example suggests that if the dependency structure of S1 is iden-tified, that information is useful to reorder the word order of S1 to that of S2 so that it becomes easier to read.",
        "In fact, most of the conventional word reordering methods have reordered words using the previously parsed dependency structure.",
        "However, the word order of S1 is thought to be more difficult to parse than that of S2 because dependency parsers are usually trained on syntactically annotated corpora in which sentences have the appropriate word order such as that in S2.",
        "This is why it is highly possible that dependency parsing can achieve a higher accuracy by changing the word order of S1 to that of S2 in advance.",
        "The above observations indicate that word reordering and dependency parsing depend on each other.",
        "Therefore, we consider it is more desirable to concurrently perform the two processings than to sequentially perform them.",
        "3 Word Reordering Method In our method, a sentence, on which morphological analysis and bunsetsu segmentation have been per-formed, is considered as the input 2 .",
        "We assume that the input sentence might have unsuitable word order, 1 Bunsetsu is a linguistic unit in Japanese that roughly corresponds to a basic phrase in English.",
        "A bunsetsu consists of one independent word and zero or more ancillary words.",
        "A dependency relation in Japanese is a modification relation in which a modifier bunsetsu depends on a modified bunsetsu.",
        "That is, the modifier bunsetsu and the modified bunsetsu work as modifier and modifyee, respectively.",
        "2 In order to focus attention on the comparison between our method and the conventional method, we assumed the input on which the lower layer processings than dependency parsing have been performed.",
        "Even if morphological analysis and bunsetsu segmentation are automatically performed on input sentences which have unsuitable word order, we can expect the accuracies 1187 which is not easy to read but grammatically well-formed.",
        "Our method identifies the suitable word order which is easy to read by concurrently performing dependency parsing.",
        "The simultaneous performing of dependency parsing and word reordering is realized by searching for the maximum-likelihood pattern of word order and dependency structure for the input sentence.",
        "Note our method reorders bunsetsus in a sentence without paraphrasing and does not reorder morphemes within a bunsetsu.",
        "3.1 Probabilistic Model for Word Reordering When a sequence of bunsetsus in an input sentence B = b 1 ?",
        "?",
        "?b n is provided, our method identifies the structure S which maximizes P (S|B).",
        "The structure S is defined as a tuple S = ?O,D?",
        "where O = {o 1,2 , o 1,3 , ?",
        "?",
        "?",
        ", o 1,n , ?",
        "?",
        "?",
        ", o i,j , ?",
        "?",
        "?",
        ", o n?2,n?1 , o n?2,n , o n?1,n } is the word order pattern after reordering and D = {d 1 , ?",
        "?",
        "?",
        ", d n?1 } is dependency structure.",
        "Here, o i,j (1 ?",
        "i < j ?",
        "n) expresses the order between b i and b j after reordering.",
        "o i,j is 1 if b i is located before b j , and is 0 otherwise.",
        "In addition, d i expresses the dependency relation whose modifier bunsetsu is b i .",
        "P (S|B) for a S = ?O,D?",
        "is calculated as follows.",
        "P (S|B) = P (O,D|B) = ?",
        "P (O|B) ?",
        "P (D|O,B) ?",
        "P (D|B) ?",
        "P (O|D,B) (1) Formula (1) is obtained for the product of the following two formulas.",
        "According to the probability theory, the calculated result of Formula (1) is equal to those of Formulas (2) and (3).",
        "However, in practice, since each factor in the formulas is estimated based on the corpus used for training, the calculated results of these formulas are different from each other.",
        "We use Formula (1) to estimate P (S|B) by using both values of P (D|O,B) and P (O|D,B).",
        "In fact, we pre-experimentally confirmed that the calculated result of Formula (1) was better than those of the others.",
        "P (O,D|B) = P (O|B) ?",
        "P (D|O,B) (2) P (O,D|B) = P (D|B) ?",
        "P (O|D,B) (3) Assuming that order o i,j between two bunsetsus is independent of that between other two bunsetsus and that each dependency relation d i is independent of the others, each factor in Formula (1) can be approximated as follows: P (O|B) ?",
        "= n?1 ?",
        "i=1 n ?",
        "j=i+1 P (o i,j |B) (4) P (D|O,B) ?",
        "= n?1 ?",
        "i=1 P (d i |O,B) (5) P (D|B) ?",
        "= n?1 ?",
        "i=1 P (d i |B) (6) P (O|D,B) ?",
        "= n?1 ?",
        "i=1 n ?",
        "j=i+1 P (o i,j |D,B) (7) where P (o i,j |B) is the probability that the order between b i and b j is o i,j whenB is provided, P (d i |O,B) is the probability that the dependency relation whose modifier bunsetsu is b i is d i when the sentence generated by reordering B according to O is provided, P (d i |B) is the probability that the dependency relation whose modifier bunsetsu is b i is d i when B is provided, and P (o i,j |D,B) is the probability that the order between b i and b j is o i,j when B where the dependency relation is D is provided.",
        "These probabilities are estimated by the maximum entropy method.",
        "remain comparatively high.",
        "This is because their processings use mainly local information.",
        "1188 To estimate P (d i |O,B), we used the features used in Uchimoto et al. (1999) except when eliminating features about Japanese commas (called toten, which is a kind of punctuation) and quotation marks.",
        "To estimate P (d i |B), we used the features which can be obtained without information about the order of input bunsetsus among the features used in estimating P (d i |O,B).",
        "To estimate P (o i,j |D,B), if b i and b j modifies the same bunsetsu, we used the features used in Uchimoto et al. (2000), except when eliminating features about parallel relations and semantic features.",
        "Otherwise, we used the features left after eliminating features about modified bunsetsus from those used in the above-mentioned case.",
        "To estimate P (o i,j |B), we used the features which can be obtained without dependency information among the features used to estimate P (O i,j |D,B).",
        "3.2 Search Algorithm Since there are a huge number of the structures S = ?O,D?",
        "which are theoretically possible for an input sentence B, an efficient algorithm is desired.",
        "However, since O and D are dependent on each other, it is difficult to find the optimal structure efficiently.",
        "In our research, we extend CYK algorithm used in conventional dependency parsing to efficiently find the suboptimal S = ?O,D?",
        "which maximizes P (S|B) efficiently.",
        "Our research assumes that an input sentence, which is grammatically well-formed, is reordered without changing the meaning so that the sentence becomes much easier to read.",
        "From this assumption, we can use following conditions for efficient search: 1.",
        "The dependency structure of an input sentence should satisfy the following Japanese syntactic constraints under the input word order: ?",
        "No dependency is directed from right to left.",
        "?",
        "Dependencies don't cross each other.",
        "?",
        "Each bunsetsu, except the last one, depends on only one bunsetsu.",
        "2.",
        "Even after the words are reordered, the dependency structure should satisfy the above-mentioned Japanese syntactic constraints under the changed word order.",
        "3.",
        "The dependency structures of a sentence before and after reordering should be identical.",
        "Using the condition 1 and the condition 3, we can narrow down the search space of D to dependency structures that satisfy Japanese syntactic constraints under the input word order.",
        "Furthermore, the search space of O can be narrowed down to the word order patterns derived from the above narrowed dependency structures based on the conditions 2 and 3.",
        "That is, after dependency structures possible for an input sentence are narrowed down, we just have to find the word order patterns after reordering so that each of the dependency structures is maintained and satisfies the Japanese syntactic constraints even under the changed word order.",
        "On the other hand, it is well known that CYK algorithm can efficiently find the optimal dependency structure which satisfies Japanese syntactic constraints.",
        "Therefore, in our research, we have extended the CYK algorithm for the conventional dependency parsing so that it can find the suboptimal D and O from among the dependency structures and word order patterns which satisfy the conditions 1, 2 and 3.",
        "3.2.1 Word Reordering Algorithm Algorithm 1 shows our word reordering algorithm.",
        "In our algorithm, the n?n triangular matrixM i,j (1 ?",
        "i ?",
        "j ?",
        "n) such as the left-side figure in Figure 2 is prepared for an input sentence consisting of n numbers of bunsetsus.",
        "M i,j , the element of the triangular matrix M in the i-th row and j-th column, is filled by argmax S i,j P (S i,j |B i,j ), which is the maximum-likelihood structure for an input subsequence B i,j = b i ?",
        "?",
        "?",
        "b j .",
        "In this section, for convenience of explanation, we represent S i,j as a sequence of dependency relations d x (i ?",
        "x ?",
        "j).",
        "For example, S i,j = d i d i+1 ?",
        "?",
        "?",
        "d 0 j means that the first bunsetsu is b i , the second is b i+1 , ?",
        "?",
        "?",
        ", the last is b j , and the dependency structure is {d i , d i+1 , ?",
        "?",
        "?",
        ", d j?1 }.",
        "Here, if we need to clearly specify the modified bunsetsu, we represent the dependency relation that bunsetsu 1189 Algorithm 1 word reordering algorithm 1: input B 1,n = b 1 ?",
        "?",
        "?",
        "b n // input sentence 2: set M i,j (1 ?",
        "i ?",
        "j ?",
        "n) // triangular matrix 3: set C i,j (1 ?",
        "i ?",
        "j ?",
        "n) // set of structure candidates 4: for i = 1 to n do 5: M i,i = d 0 i 6: end for 7: for d = 1 to n?",
        "1 do 8: for i = 1 to n?",
        "d do 9: j = i+ d 10: for k = i to j ?",
        "1 do 11: C i,j = C i,j ?",
        "ConcatReorder(M i,k ,M k+1,j ) 12: end for 13: M i,j = argmax S i,j ?C i,j P (S i,j |B i,j ) 14: end for 15: end for 16: return M 1,n \u0001Candidates generated by ?By the concatenating process ?By the reordering process M1,1= M1,2= M1,3= M1,4 M2,2= M2,3= M2,4 M3,3= M3,4= M4,4= 2 2 3 3 4 4 \u0001Candidates generated by ?By the concatenating process 2 3 4 23 4 ?",
        "By the reordering process 2 3 4 is filled by the structure which maximizes among the following candidates.",
        "Candidate 1: Candidate 3: Candidate 2: ?",
        "means that is located before and depends on .",
        "For example, i j -- is filled by the maximum-likelihood structure for a subsequence from to .",
        "3 1 1 2 2 31 No candidate is generated because has no child in .2 31 means .",
        "by moving after , which is the first child of in Figure 2: Execution example of our search algorithm b x modifies b y as d y x .",
        "In addition, d 0 j means that the last bunsetsu of the subsequence don't modify any bunsetsu.",
        "First, the statements of the lines 4 to 6 fill each of diagonal elements M i,i (1 ?",
        "i ?",
        "n) with d 0 i .",
        "Next, the statements of the lines 7 to 15 fill M i,j in turn toward the upper right M 1,n along the diagonal line, starting from the diagonal elements M i,i .",
        "The maximum-likelihood structure which should fill an M i,j is found as follows: The statements of the lines 10 to 12 repeat the process of generating candidates of the maximum-likelihood structure from M i,k and M k+1,j by the function ConcatReorder, and adding them to the set of structure candidates C i,j .",
        "The function ConcatReorder takes two arguments ofM i,k andM k+1,j and returns the set of candidates of the maximum-likelihood structure which should fill M i,j .",
        "The function ConcatReorder is composed of two processes: concatenating process and reordering process.",
        "First, the concatenating process generates a candidate by simply concatenating M i,k and M k+1,j in turn about the word order and connecting M i,k and M k+1,j by the dependency relation between the last bunsetsus of them about the dependency structure, without changing the internal structure of each of them.",
        "For example, whenM i,k = d i d i+1 ?",
        "?",
        "?",
        "d k?1 d 0 k andM k+1,j = d k+1 d k+2 ?",
        "?",
        "?",
        "d j?1 d 0 j are given as the argument, the concatenating process generates ?d i d i+1 ?",
        "?",
        "?",
        "d k?1 d j k d k+1 d k+2 ?",
        "?",
        "?",
        "d j?1 d 0 j .?",
        "1190 Second, the reordering process generates candidates by reordering words in the candidate generated by the concatenating process.",
        "The reordering is executed on the following conditions.",
        "The first condition is that the dependency structure is maintained and satisfies the Japanese syntactic constraints even under the changed word order.",
        "The second condition is that the order of any two words within each of M i,k and M k+1,j is maintained.",
        "Concretely, the first reordered candidate is generated by moving M i,k after the first (leftmost) child 3 of the last bunsetsu of M k+1,j among the children in M k+1,j .",
        "Then, the second reordered candidate is generated by moving M i,k after the second child.",
        "The reordering process is continued until the last reordered candidate is generated by moving M i,k after the last child.",
        "That is, the number of candidates generated by the reordering process is equal to the number of children of the last bunsetsu in M k+1,j .",
        "For example, when M i,k = d i d i+1 ?",
        "?",
        "?",
        "d k?1 d 0 k and M k+1,j = d j k+1 d j k+2 ?",
        "?",
        "?",
        "d j j?1 d 0 j , which means all bunsetsus except the last one depend on the last one, are given, the reordering process generates the following j ?",
        "k?",
        "1 candidates: ?d j k+1 d i d i+1 ?",
        "?",
        "?",
        "d k?1 d j k d j k+2 d j k+3 ?",
        "?",
        "?",
        "d j j?1 d 0 j ,?",
        "?d j k+1 d j k+2 d i d i+1 ?",
        "?",
        "?",
        "d k?1 d j k d j k+3 d j k+4 ?",
        "?",
        "?",
        "d j j?1 d 0 j ,?",
        ".",
        ".",
        "., and ?d j k+1 d j k+2 ?",
        "?",
        "?",
        "d j j?1 d i d i+1 ?",
        "?",
        "?",
        "d k?1 d j k d 0 j .?",
        "Therefore, in this case, the function ConcatReorder finally returns the set of candidates of which size is j?k, which includes the candidates generated by the reordering process and a candidate generated by the concatenating process.",
        "Next, in the line 13, our algorithm fills in argmax S i,j ?C i,j P (S i,j |B i,j ) which is the maximum-likelihood structure for a subsequence B i,j on M i,j .",
        "Finally, our algorithm outputs M 1,n as the maximum-likelihood structure of word order and dependency structure for the input sentence.",
        "Note that if the function ConcatReorder is changed to the function Concat in the line 11, our algorithm becomes the same as CYK algorithm used in the conventional dependency parsing.",
        "The functionConcat takes two arguments of M i,k and M k+1,j and generates a candidate of the maximum-likelihood structure which should fill M i,j by the same way as the concatenating process in the function ConcatReorder.",
        "Then, the function Concat returns the set which has the generated candidate as a element, of which size is 1.",
        "3.2.2 Execution Example of Word Reordering Algorithm Figure 2 represents an example of execution of our word reordering algorithm in n = 4.",
        "The left side of Figure 2 represents the triangle diagram which has 4 ?",
        "4 dimensions.",
        "The elements of the triangle diagram M 1,1 ,M 2,2 ,M 3,3 ,M 4,4 ,M 1,2 ,M 2,3 ,M 3,4 , and M 1,3 have already been filled in turn, and M 2,4 is being filled.",
        "The right side of Figure 2 shows the process of calculating the maximum-likelihood structure which should fill M 2,4 .",
        "First, in the loop from the line 10 to the line 12 in Algorithm 1, two structure candidates are generated by ConcatReorder(M 2,2 ,M 3,4 ).",
        "The candidate 1 is generated by the concatenating process, that is, by simply concatenating M 2,2 and M 3,4 and connecting the last bunsetsu of M 2,2 and that of M 3,4 .",
        "The candidate 2 is generated by the reordering process, that is, by moving M 2,2 after b 3 , which is the first child of b 4 in M 3,4 .",
        "Second, the candidate 3 is generated by the concatenating process in ConcatReorder(M 2,3 ,M 4,4 ).",
        "On the other hand, the reordering process in ConcatReorder(M 2,3 ,M 4,4 ) generates no candidates because b 4 has no child inM 4,4 .",
        "Among the three structures generated in the above way, the structure which maximizes P (S 2,4 |B) = P (O 2,4 , D 2,4 |B 2,4 ) fills M 2,4 .",
        "4 Experiment To evaluate the effectiveness of our method, we conducted an experiment on word reordering by using Japanese newspaper articles.",
        "4.1 Outline of Experiment In the experiment, as the test data, we used sentences generated by only changing the word order of newspaper article sentences in Kyoto Text Corpus (Kurohashi and Nagao, 1998), maintaining the dependency structure.",
        "That is, we artificially generated sentences which made sense but were not easy to read, 3 When b i depends on b j , we call b i as a child of b j .",
        "Furthermore, if b j has more than or equal to one child, the children are numbered from left to right based on their positions.",
        "1191 kokkai-wo(the Diet) toot-ta (passed) ato-demo(Even after) seron-chosa-de-wa(according to opinion polls) shohi-ze-zoze-ga(the consumption tax hike bill) zoze-hantai-ga(opposing views to the bill) Original sentence in newspaper articles (correct word order) taise-da(are in majority) ?Even after the Diet passed the consumption tax hike bill,according to opinion polls opposing views to the bill are in majority.?",
        "Test data (input sentence) test data generation kokkai-wo(the Diet) toot-ta (passed) ato-demo(Even after) seron-chosa-de-wa(according to opinion polls) shohi-ze-zoze-ga(the consumption tax hike bill) zoze-hantai-ga(opposing views to the bill) taise-da(are in majority) Figure 3: Example of test data generation in order to focus solely on problems caused by unsuitable word order.",
        "Figure 3 shows an example of the test data generation.",
        "The generation procedure is as follows: 1.",
        "Find a bunsetsu modified by multiple bunsetsus from the sentence end.",
        "2.",
        "Change randomly the order of the sub-trees which modify such bunsetsu.",
        "3.",
        "Iterate 1 and 2 until reaching the beginning of the sentence.",
        "In Figure 3, the bunsetsus ?taise-da (are in the majority)?",
        "and ?toot-ta (passed)?",
        "are found as bunsetsus modified by multiple bunsetsus.",
        "For example, when ?toot-ta (passed)?",
        "is found, the order of ?shohi- ze-zoze-ga (the consumption tax hike bill)?",
        "and ?kokkai-wo (the Diet)?",
        "is randomly changed.",
        "In this experiment, all Japanese commas (toten) in a sentence, and sentences which have quotation marks were removed.",
        "In this way, we artificially generated 865 sentences (7,620 bunsetsus) from newspaper articles of Jan. 9 in Kyoto Text Corpus and used them as the test data.",
        "As the training data, we used 7,976 sentences in 7 days?",
        "newspaper articles (Jan. 1, 3-8).",
        "Here, we used the maximum entropy method tool (Zhang, 2008) with the default options except ?-i 1000.?",
        "In the evaluation of word reordering, we obtained the following two measurements, which are defined by Uchimoto et al. (2000): ?",
        "complete agreement: the percentage of the sentences in which all words?",
        "order completely agrees with that of the original sentence.",
        "?",
        "pair agreement: the percentage of the pairs of bunsetsus whose word order agrees with that in the original sentence.",
        "(For example, in Figure 3, if the word order of the input sentence is not changed after reordering, the pair agreement is 52.4% (= 11/ 7 C 2 ) because the 11 pairs out of the 7 C 2 pairs are the same as those in the original sentence.)",
        "In the evaluation of dependency parsing, we obtained the dependency accuracy (the percentage of correctly analyzed dependencies out of all dependencies) and sentence accuracy (the percentage of the sentences in which all the dependencies are analyzed correctly), which are defined by Sekine et al. (2000).",
        "For comparison, we established two baselines.",
        "Both of the baselines execute the dependency parsing primarily, and then, perform the word reordering by using the conventional word reordering method 1192 Table 1: Experimental results (word reordering) pair agreement complete agreement our method 77.3% (30,190/38,838) 25.7% (222/865) baseline 1 75.4% (29,279/38,838) * 23.8% (206/865) baseline 2 74.8% (29,067/38,838) * 23.5% (203/865) no reordering 61.5% (23,886/38,838) * 8.0% (69/865) * Note that the agreements followed by * differ significantly from those of our method (p < 0.05).",
        "Table 2: Experimental results (dependency parsing) dependency accuracy sentence accuracy our method 78.4% (5,293/6,755) 35.3% (305/865) baseline 1 79.2% (5,350/6,755) 31.6% (273/865) * baseline 2 81.2% (5,487/6,755) * 32.1% (278/865) * Note that the accuracies followed by * differ significantly from those of our method (p < 0.05).",
        "(Uchimoto et al., 1999).",
        "The difference between the two is the method of dependency parsing.",
        "The baselines 1 and 2 use the dependency parsing method proposed by Uchimoto et al. (2000) and the dependency parsing tool CaboCha (Kudo and Matsumoto, 2002), respectively.",
        "The features used for the word reordering in both the baselines are the same as those used to estimate P (o i,j |D,B) in our method.",
        "Additionally, the features used for the dependency parsing in the baseline 1 are the same as those used to estimate P (d i |O,B) in our method.",
        "4.2 Experimental Results Table 1 shows the experimental results on word reordering of our method and the baselines.",
        "Here, the last row shows the agreements measured by comparing the input word order with the correct word order.",
        "The agreements mean the values which can be achieved with no reordering 4 .",
        "The pair and complete agreements of our method were highest among all.",
        "The pair agreement of our method is significantly different from those of both the baselines (p < 0.05) although there is no significant difference between the complete agreements of them.",
        "Next, Table 2 shows the experimental results on dependency parsing.",
        "The sentence accuracy of our method is significantly higher than those of both the baselines (p < 0.05).",
        "On the other hand, the dependency accuracy of our method is significantly lower than that of the baseline 2 although there is no significant difference between the dependency accuracies of our method and the baseline 1 (p > 0.05).",
        "Here, if the input sentences had the correct word order, the dependency accuracies of the baselines 1 and 2 were 86.4% (5,835/6,755) and 88.1% (5,950/6,755), respectively.",
        "We can see that the unsuitable word order caused a large decrease of the accuracies of the conventional dependency parsing methods.",
        "This is why the word order agreements of the baselines were decreased.",
        "Figure 4 shows an example of sentences of which all bunsetsus were correctly reordered and the dependency structure was correctly parsed only by our method.",
        "We can see that our method can achieve the complicated word reordering.",
        "On the other hand, Figure 5 shows an example of sentences incorrectly reordered and parsed by our method.",
        "In this example, our method could not identify the correct modified bunsetsu and the appropriate position of the bunsetsu ?arikata-wo (whole concept).?",
        "This is because the dependency probability between the bunsetsu ?arikata-wo (whole concept)?",
        "and the bunsetsu ?fukume 4 Some input sentences were in complete agreement with the original ordering.",
        "There were some cases that the randomly reordered sentences accidentally have the same word order as the original ones.",
        "In addition, there were some sentences in which all bunsetsus except the last one depend on the next bunsetsu.",
        "The word order of such sentences is not changed by the test data generation procedure because the procedure is executed on condition of maintaining the dependency structure.",
        "1193 Input sentence(inappropriate word order) ?Although I myself do not have an experience with a war, I think any generation should not glorify war.?",
        "Output sentence(correct word order and dependency structure) itsu-no(any) sedai-mo(generation) bika-su-beki-de-nai-to(should not glorify) senso-wo(with a war) senso-wo(war) taiken-shi-ta(have an experience) koto-wa(?)",
        "watashi-jishin(I myself) omou (think) itsu-no(any) sedai-mo (generation) bika-su-beki-de-nai-to(should not glorify) senso-wo(with a war) senso-wo(war) taiken-shi-ta(have an experience) koto-wa(?)",
        "watashi-jishin(I myself) nai-ga (although do not) omou (think) nai-ga (although do not) : shows an alignment of a bunsetsu before and after reordering.",
        ": shows a correct dependency relation.?",
        ": means there is no English word corresponding to the Japanese word.",
        "Figure 4: Example of sentences correctly reordered and parsed by our method ?Whole concept of the examination of rice should be fundamentally revised including the transfer of control to a private sector or prefectural and city governments.?",
        "Input sentence(inappropriate word order) Output sentence(incorrect word order and dependency structure) kensa-no(of the exami-nation) arikata-wo(whole concept) todofuken-ya(or prefectural and city governments) minkan-e-no(to a private sector) kome-no(of rice) ikan-mo(the transferof control) fukume (including) konpon-teki-ni(fundamen-tally) minaosu-beki-daro(should be revised) Original sentence(correct word order and dependency structure) kensa-no(of the exami-nation) arikata-wo(whole concept) todofuken-ya(or prefectural and city governments) minkan-e-no(to a private sector) kome-no(of rice) ikan-mo(the transferof control) fukume (including) konpon-teki-ni(fundamen-tally) minaosu-beki-daro(should be revised) kensa-no(of the exami-nation) arikata-wo(whole concept) todofuken-ya(or prefectural and city governments) minkan-e-no(to a private sector) kome-no(of rice) ikan-mo(the transferof control) fukume (including) konpon-teki-ni(fundamen-tally) minaosu-beki-daro(should be revised) : shows an alignment of a bunsetsu before and after reordering.",
        ": shows a correct dependency relation.",
        ": shows an incorrect dependency relation.",
        "Figure 5: Example of sentences incorrectly reordered and parsed by our method (including)?",
        "is higher than the one between the bunsetsu ?arikata-wo (whole concept)?",
        "and the bunsetsu ?minaosu-beki-daro (should be revised)?, and the probability that the bunsetsu ?arikata-wo (whole con-cept)?",
        "is located at the left side of ?fukume (including)?",
        "is higher than that of the right side.",
        "Since the word order of the output sentence has a strong probability of causing a wrong interpretation like ?The transfer of control to a private sector or prefectural and city governments should be fundamentally revised including whole concept of the examination of rice.",
        "?, this reordering has a harmful influence on the comprehension.",
        "We need to study techniques for avoiding the word order which causes the change of meanings in an input sentence.",
        "From the above, we confirmed the effectiveness of our method on word reordering and dependency parsing of a sentence of which the word order is not easy to read.",
        "5 Conclusion This paper proposed the method for reordering bunsetsus in a Japanese sentence.",
        "Our method can identify suitable word order by concurrently performing word reordering and dependency parsing.",
        "Based on the 1194 idea of limiting the search space using the Japanese syntactic constraints, we made the search algorithm by extending the CYK algorithm used in the conventional dependency parsing, and found the optimal structure efficiently.",
        "The result of the experiment using newspaper articles showed the effectiveness of our method.",
        "In our future works, we would like to collect sentences written by Japanese subjects who do not have much writing skills, to conduct an experiment using those sentences.",
        "In addition, we would like to conduct a subjective evaluation to investigate whether the output sentences are indeed more readable than the input ones.",
        "Acknowledgments This research was partially supported by the Grant-in-Aid for Young Scientists (B) (No.25730134) and Challenging Exploratory Research (No.24650066) of JSPS.",
        "References"
      ]
    }
  ]
}
