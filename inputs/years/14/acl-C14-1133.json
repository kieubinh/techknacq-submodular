{
  "info": {
    "authors": [
      "Miguel Ballesteros",
      "Bernd Bohnet",
      "Simon Mille",
      "Leo Wanner"
    ],
    "book": "COLING",
    "id": "acl-C14-1133",
    "title": "Deep-Syntactic Parsing",
    "url": "https://aclweb.org/anthology/C14-1133",
    "year": 2014
  },
  "references": [
    "acl-D07-1096",
    "acl-D12-1133",
    "acl-E12-2012",
    "acl-J05-1004",
    "acl-J07-4004",
    "acl-J08-1003",
    "acl-L08-1222",
    "acl-P01-1033",
    "acl-P03-1046",
    "acl-P08-1101",
    "acl-P13-2017",
    "acl-P86-1038",
    "acl-W06-2920",
    "acl-W08-2121",
    "acl-W08-2123",
    "acl-W09-1201",
    "acl-W09-1205",
    "acl-W09-1207"
  ],
  "sections": [
    {
      "text": [
        "Abstract",
        "?Deep-syntactic?",
        "dependency structures that capture the argumentative, attributive and coordinative relations between full words of a sentence have a great potential for a number of NLP-applications.",
        "The abstraction degree of these structures is in-between the output of a syntactic dependency parser (connected trees defined over all words of a sentence and language-specific grammatical functions) and the output of a semantic parser (forests of trees defined over individual lexemes or phrasal chunks and abstract semantic role labels which capture the argument structure of predicative elements, dropping all attributive and coordinative dependencies).",
        "We propose a parser that delivers deep syntactic structures as output."
      ]
    },
    {
      "heading": "1 Introduction",
      "text": [
        "Surface-syntactic structures (SSyntSs) as produced by data-driven syntactic dependency parsers are per force idiosyncratic in that they contain governed prepositions, determiners, support verb constructions and language-specific grammatical functions such as, e.g., SBJ, OBJ, PRD, PMOD, etc.",
        "(Johansson and Nugues, 2007).",
        "For many NLP-applications, including machine translation, paraphrasing, text simpli-fication, etc., such a high idiosyncrasy is obstructive because of the recurrent divergence between the source and the target structures.",
        "Therefore, the use of more abstract ?syntactico-semantic?",
        "structures seems more appropriate.",
        "Following Mel?",
        "?cuk (1988), we call these structures deep-syntactic structures (DSyntSs).",
        "DSyntSs are situated between SSyntSs and PropBank-(Palmer et al., 2005) or Semantic Frame-like structures (Fillmore et al., 2002).",
        "Compared to SSyntSs, they have the advantage to abstract from language-specific grammatical idiosyncrasies.",
        "Compared to PropBank and Semantic Frame stuctures, they have the advantage to be connected and complete, i.e., capture all argumentative, attributive and coordinative dependencies between the meaningful lexical items of a sentence, while PropBank and Semantic Frame structures are not always connected, may contain either individual lexical items or phrasal chunks as nodes, and discard attributive and coordinative relations (be they within the chunks or sentential).",
        "In other words, they constitute incomplete structures that drop not only idiosyncratic, functional but also meaningful elements of a given sentence and often contain dependencies between chunks rather than individual tokens.",
        "Therefore, we propose to put on the research agenda the task of deep-syntactic parsing and show how a DSyntS is obtained from a SSynt dependency parse using data-driven tree transduction in a pipeline with a syntactic parser.",
        "1 In Section 2, we introduce SSyntSs and DSyntSs and discuss the fundamentals of SSyntS?DSyntS transduction.",
        "Section 3 describes the experiments that we carried out on Spanish material, and Section 4 discusses their outcome.",
        "Section 5 summarizes the related work, before in Section 6 some conclusions and plans for future work are presented.",
        "2 Fundamentals of SSyntS?DSyntS transduction Before we set out to discuss the principles of the SSyntS?DSynt transduction, we must specify the DSyntSs and SSyntSs as used in our experiments.",
        "1 The term ?tree transduction?",
        "is used in this paper in the sense of Rounds (1970) and Thatcher (1970) to denote an extension of finite state transduction (Aho, 1972) to trees.",
        "1402 2.1 Defining SSyntS and DSyntS SSyntSs and DSyntSs are directed, node- and edge-labeled dependency trees with standard feature-value structures (Kasper and Rounds, 1986) as node labels and dependency relations as edge labels.",
        "The features of the node labels in SSyntSs are lex ssynt , and ?syntactic grammemes?",
        "of the value of lex ssynt , i.e., number, gender, case, definiteness, person for nouns and tense, aspect, mood and voice for verbs.",
        "The value of lex ssynt can be any (either full or functional) lexical item; in graphical representations of SSyntSs, usually only the value of lex ssynt is shown.",
        "The edge labels of a SSyntS are grammatical functions ?subj?, ?dobj?, ?det?, ?modif?, etc.",
        "In other words, SSyntSs are syntactic structures of the kind as encountered in the standard dependency treebanks; cf., e.g., dependency version of the Penn TreeBank (Johansson and Nugues, 2007) for English, Prague Dependency Treebank for Czech (Haji?c et al., 2006), Ancora for Spanish (Taul?e et al., 2008), Copenhagen Dependency Treebank for Danish (Buch-Kromann, 2003), etc.",
        "In formal terms that we need for the outline of the transduction below, a SSyntS is defined as follows: Definition 1 (SSyntS) An SSyntS of a language L is a quintuple T SS = ?N,A, ?",
        "l s ?n , ?",
        "r s ?a , ?",
        "n?g ?",
        "defined over all lexical items L of L, the set of syntactic grammemes G synt , and the set of grammatical functions R gr , where ?",
        "the set N of nodes and the set A of directed arcs form a connected tree, ?",
        "?",
        "l s ?n assigns to each n ?",
        "N an l s ?",
        "L, ?",
        "?",
        "r s ?a assigns to each a ?",
        "A an r ?",
        "R gr , and ?",
        "?",
        "n?g assigns to each ?",
        "l s ?n (n) a set of grammemes G t ?",
        "G synt .",
        "The features of the node labels in DSyntSs as worked with in this paper are lex dsynt and ?seman- tic grammemes?",
        "of the value of lex dsynt , i.e., number and determination for nouns and tense, aspect, mood and voice for verbs.",
        "2 In contrast to lex ssynt in SSyntS, DSyntS's lex dsynt can be any full, but not a functional lexeme.",
        "In accordance with this restriction, in the case of look after a person, AFTER will not appear in the corresponding DSyntS; it is a functional (or governed) preposition (so are TO or BY, in Figure 1).",
        "3 In contrast, AFTER in leave after the meeting is a full lexeme; it will remain in the DSyntS because there it has its own meaning of ?succession in time?.",
        "The edge labels of a DSyntS are language-independent ?deep-syntactic?",
        "relations I,.",
        ".",
        ".",
        ",VI, ATTR, COORD, APPEND.",
        "?I?,.",
        ".",
        ".",
        ",?VI?",
        "are argument relations, analogous to A0, A1, etc.",
        "in the PropBank annotation.",
        "?ATTR?",
        "subsumes all (cir- cumstantial) ARGM-x PropBank relations as well as the modifier relations not captured by the PropBank and FrameNet annotations.",
        "?COORD?",
        "is the coordinative relation as in: John-COORD?and-II?Mary, publish-COORD?or-II?perish, and so on.",
        "APPEND subsumes all parentheticals, interjections, direct addresses, etc., as, e.g., in Listen, John!",
        ": listen-APPEND?John.",
        "DSyntSs thus show a strong similarity with PropBank structures, with four important differences: (i) their lexical labels are not disambiguated; (ii) instead of circumstantial thematic roles of the kind ARGM-LOC, ARGM-DIR, etc.",
        "they use a unique ATTR relation; (iii) they capture all existing dependencies between meaningful lexical nodes; and (iv) they are connected.",
        "4 A number of other annotations have resemblance with DSyntSs; cf. (Ivanova et al., 2012) for an overview of deep dependency structures.",
        "Formally, a DSyntS is defined as follows: Definition 2 (DSyntS) An DSyntS of a language L is a quintuple T DS = ?N,A, ?",
        "l s ?n , ?",
        "r s ?a , ?",
        "n?g ?",
        "defined over the full lexical items L d of L, the set of semantic grammemes G sem , and the set of deep-syntactic relations R dsynt , where ?",
        "the set N of nodes and the set A of directed arcs form a connected tree, ?",
        "?",
        "l s ?n assigns to each n ?",
        "N an l s ?",
        "L d , ?",
        "?",
        "r s ?a assigns to each a ?",
        "A an r ?",
        "R dsynt , and ?",
        "?",
        "n?g assigns to each ?",
        "l s ?n (n) a set of grammemes G t ?",
        "G sem .",
        "Consider in Figure 1 an example for an SSyntS and its corresponding DSyntS.",
        "2 Most of the grammemes have a semantic and a surface interpretation; see (Mel?",
        "?cuk, 2013).",
        "3 Functional lexemes also include auxiliaries (e.g. HAVE, or BE when it is not a copula), and definite and indefinite determiners (THE, A); see Figure 1).",
        "4 Our DSyntSs are thus DSyntSs as used in the Meaning-Text Theory (Mel?",
        "?cuk, 1988), only that our DSyntSs do not disambiguate lexical items and do not use lexical functions (Mel?",
        "?cuk, 1996).",
        "1403 (a) almost 1.2 million jobs have been created by the state thanks to their endeavours restr quant quant subj analyt perf analyt pass agent adv prepos det obl obj prepos det (b) almost 1.2 million job create state thanks their endeavour ATTR ATTR ATTR II I ATTR II I Figure 1: An SSyntS (a) and its corresponding DSyntS (b) 2.2 Fleshing out the SSyntS?DSyntS transduction It is clear that the SSyntS and DSyntS of the same sentence are not isomorphic.",
        "The following correspondences between the SSyntS S ss and DSyntS S ds of a sentence need to be taken into account during SSyntS?DSyntS transduction: (i) a node in S ss is a node in S ds ; (ii) a relation in S ss corresponds to a relation in S ds ; (iii) a fragment of the S ss tree corresponds to a single node in S ds ; (iv) a relation with a dependent node in S ss is a grammeme in S ds ; (v) a grammeme in S ss is a grammeme in S ds ; (vi) a node in S ss is conflated with another node in S ds ; and (vii) a node in S ds has no correspondence in S ss .",
        "The grammeme correspondences (iv) and (v) and the ?pseudo?",
        "correspondences in (vi) and (vii) 5 are few or idiosyncratic and are best handled in a rule-based post-processing stage.",
        "The main task of the SSyntS?DSyntS transducer is thus to cope with the correspondences (i)?(iii).",
        "For this purpose, we can view both SSyntS and DSyntS as vectors indexed in terms of two-dimensional matrices I = N ?N (N being the set of nodes of a given tree 1, .",
        ".",
        ".",
        ",m), with I(i, j) = ?",
        "(n i , n j ), if n i , n j ?",
        "N and (n i , n j ) ?",
        "A and I(i, j) = 0 otherwise (where ??",
        "(n i , n j )?",
        "is the function that assigns to an edge a relation label and i, j = 1, .",
        ".",
        ".",
        ",m; i 6= j are nodes of the tree).",
        "That is, for a given SSyntS, the matrix I(i, j) contains in the cells (i, j), i, j = 1, .",
        ".",
        ".",
        ",m, the names of the SSynt-relations between the nodes n i and n j , and ?0?",
        "otherwise, while for a given DSyntS, the cells of its matrix I D contain DSyntS-relations.",
        "Starting from the matrix I S of a given SSyntS, the task is therefore to obtain the matrix I D of the corresponding DSyntS, that is, to identify correspondences between i/j, (i, j) and groups of (i, j) of I S with i ?",
        "/j ?",
        "and (i ?",
        ", j ? )",
        "of I D ; see (i)?",
        "(iii) above.",
        "In other words, the task consists in identifying and removing all functional lexemes, and attach correctly the remaining nodes between them.",
        "6 As a ?token chain?surface-syntactic tree?",
        "projection, this task can be viewed as a classification task.",
        "However, while the former is isomorphic, we know that the SSyntS?DSyntS projection is not.",
        "In order to approach the task to an isomorphic projection (and thus simplify its modelling), it is convenient to interpret SSyntS and the targeted DSyntS as collections of hypernodes: Definition 3 (Hypernode) Given a SSyntS S s with its index matrix I S (a DSyntS S d with its index matrix I D ), a node partition p (with |p |?",
        "1) of I S (I D ) is a hypernode h s i (h d i ) iff p corresponds to a partition p ?",
        "(with |p ?",
        "|?",
        "1) of S d (S s ).",
        "In this way, the SSyntS?DSyntS correspondence boils down to a correspondence between individual hypernodes and between individual arcs, and the transduction embraces the following three (classifica- tion) subtasks: 1.",
        "Hypernode identification, 2.",
        "DSynt tree construction, and 3.",
        "DSynt arc labeling, which are completed by a post-processing stage.",
        "5 (vi) covers, e.g., reflexive verb particles such as se in Spanish, which are conflated in the DSyntS with the verb: se?aux refl dir-conocer vs. CONOCERSE ?know each other?",
        "; (vii) covers, e.g., the zero subject in pro-drop languages (which is absent in the SSyntS and present in the DSyntS).",
        "6 What is particularly challenging is the identification of functional prepositions: based on the information found in the corpus only, our system must decide if a given preposition is a full or a functional lexeme.",
        "That is, we do not resort to any external lexical resources.",
        "1404 1.",
        "Hypernode identification.",
        "The hypernode identification consists of a binary classification of the nodes of a given SSyntS as nodes that form a hypernode of cardinality 1 (i.e., nodes that have a one-to-one correspondence to a node in the DSyntS) vs. nodes that form part of a hypernode of cardinality > 1.",
        "In practice, hypernodes of type one will be formed by: 1) noun nodes that do not govern determiner or functional preposition nodes, 2) full verb nodes that are not governed by any auxiliary verb nodes and that do not govern any functional preposition node, adjective nodes, adverbial nodes, and semantic preposition nodes.",
        "Hypernodes of type two will be formed by: 1) noun nodes + determiner / functional preposition nodes they govern, 2) verb nodes + auxiliary nodes they are governed by + functional preposition nodes they govern.",
        "2.",
        "DSynt tree reconstruction.",
        "The outcome of the hypernode identification stage is thus the set H s = H s |p|=1 ?H s |p|>1 of hypernodes of two types.",
        "With this set at hand, we can define an isomorphy function ?",
        ": H s ?",
        "H d |p|=1 (with h d ?",
        "H d |p|=1 consisting of n d ?",
        "N ds , i.e., the set of nodes of the target DSyntS).",
        "?",
        "is the identity function for h s ?",
        "H s |p|=1 .",
        "For h s ?",
        "H s |p|>1 , ?",
        "maps the functional nodes in h s onto grammemes (attribute-value pairs) of the lexically meaningful node in h d and identifies the lexically meaningful node as head.",
        "Some of the dependencies of the obtained nodes n d ?",
        "N ds can be recovered from the dependencies of their sources.",
        "Due to the projection of functional nodes to grammemes (which can be also seen as node removal), some dependencies will be also missing and must be introduced.",
        "Algorithm 1 recalculates the dependencies for the target DSyntS S d , starting from the index matrix I S of SSyntS S s to obtain a connected tree.",
        "Algorithm 1: DSyntS tree reconstruction for ?n i ?",
        "N d do if ?n j : (n j , n i ) ?",
        "S s ?",
        "?",
        "(n j ) ?",
        "N d then (n j , n i )?",
        "S d // the equivalent of the head node of n i is included in DSyntS else if ?n j , n a : (n j , n i ) ?",
        "S s ?",
        "?",
        "(n j ) 6?",
        "N d ?",
        "?",
        "(n a ) ?",
        "N d then //n a is the first ancestor of n j that has an equivalent in DSyntS //the equivalent of the head node of n i is not included in DSyntS, but the ancestor n a is (n a , n i )?",
        "S d else //the equivalent of the head node of n i is not included in DSyntS, but several ancestors of it are n b := BestHead(n i , S s , S d ) (n b , n i )?",
        "S d endfor BestHead recursively ascends S s from a given node n i until it encounters one or several head nodes n d ?",
        "N ds .",
        "In case of several encountered head nodes, the one which governs the highest frequency dependency is returned.",
        "3.",
        "Label Classification.",
        "The tree reconstruction stage produces a ?hybrid?",
        "connected dependency tree S s?d with DSynt nodes N ds , and arcs A s labelled by SSynt relation labels, i.e., an index matrix we can denote as I ?",
        ", whose cells (i, j) contain SSynt labels for all n i , n j ?",
        "N ds : (n i , n j ) ?",
        "A s and ?0?",
        "otherwise.",
        "The next and last stage of SSynt-to-DSyntS transduction is thus the projection of SSynt relation labels of S s?d to their corresponding DSynt labels, or, in other words, the mapping of I ?",
        "to I D of the target DSyntS.",
        "4.",
        "Postprocessing.",
        "As mentioned in Section 2, there is a limited number of idiosyncratic correspondences between elements of SSyntS and DSyntS (the correspondences (iv?vii) which can be straightforwardly handled by a rule-based postprocessor because (a) they are non-ambiguous, i.e., a ?",
        "b, c ?",
        "d ?",
        "a = b ?",
        "c = d, and (b) they are few.",
        "Thus, only determiners and auxiliaries in SSyntS map onto a grammeme in DSyntS, both SSyntS and DSyntS count with less than a dozen grammemes, etc.",
        "3 Experiments In order to validate the outlined SSyntS?DSyntS transduction and to assess its performance in combination with a surface dependency parser, i.e., starting from plain sentences, we carried out a number of 1405 experiments in which we implemented the transducer and integrated it into a pipeline shown in Figure 2.",
        "JointPoS TaggerSSynt parser SSynt?DSyntTransducerPlainSentences DSyntTreebankSSyntTreebank SSyntS DSynS Figure 2: Setup of a deep-syntactic parser For our experiments, we use the AnCora-UPF SSyntS and DSyntS treebanks of Spanish (Mille et al., 2013) in CoNLL format, adjusted for our needs.",
        "In particular, we removed from the 79-tag SSyntS treebank the semantically and information structure influenced relation tags to obtain an annotation granularity closer to the ones used for previous parsing experiments (55 relation tags, see (Mille et al., 2012)).",
        "Our development set consisted of 219 sentences (3271 tokens in the DSyntS treebank and 4953 tokens in the SSyntS treebank), the training set of 3036 sentences (57665 tokens in the DSyntS treebank and 86984 tokens in the SSyntS treebank), and the test set held-out for evaluation of 258 sentences (5641 tokens in the DSyntS treebank and 8955 tokens in the SSyntS treebank).",
        "To obtain the SSyntS, we use Bohnet and Nivre (2012)'s transition-based parser, which combines lemmatization, PoS tagging, and syntactic dependency parsing?tuned and trained on the respective sets of the SSyntS treebank.",
        "Cf. Table 1 for the performance of the parser on the development set.",
        "POS LEMMA LAS UAS 96.14 91.10 78.64 86.49 Table 1: Results of Bohnet and Nivre's surface-syntactic parser on the development set In what follows, we first present the realization of the SSyntS?DSyntS transducer and then the realization of the baseline.",
        "3.1 SSyntS?DSyntS transducer As outlined in Section 2.2, the SSyntS?DSyntS transducer is composed of three submodules and a postprocessing stage: 1.",
        "Hypernode identification.",
        "For the hypernode identification, we trained a binary polynomial (degree 2) SVM from LIBSVM (Chang and Lin, 2001).",
        "The SVM allows both features related to the processed node and higher-order features, which can be related to the head node of the processed node or to its sibling nodes.",
        "After several feature selection trials, we chose the following features for each node n: ?",
        "lemma or stem of the label of n, ?",
        "label of the relation between n and its head, ?",
        "surface PoS of n's label (the SSynt and DSyntS treebanks distinguish between surface and deep PoS), ?",
        "label of the relation between n's head to its own head, ?",
        "surface PoS of the label of n's head node.",
        "After an optimization round of the parameters available in the SVM implementation, the hypernode identification achieved over the gold development set 99.78% precision and 99.02% recall (and thus 99.4% F1).",
        "That is, only very few hypernodes are not identified correctly.",
        "The main error source are governed prepositions: the classifier has to learn when to assign a preposition an own hypernode (i.e., when it is lexically meaningful) and when it should be included into the hypernode of the governor (i.e., when it is functional).",
        "Our interpretation is that the features we use for this task are appropriate, but that the training data set is too small.",
        "As a result, some prepositions are erroneously left out from or introduced into the DSyntS.",
        "1406 2.",
        "Tree reconstruction.",
        "The implementation of the tree reconstruction module shows an unlabelled dependency attachment precision of 98.18% and an unlabelled dependency attachment recall of 97.43% over the gold development set.",
        "Most of the errors produced by this module have their origin in the previous module, i.e., hypernode identification.",
        "When a node has been incorrectly removed, the module errs in the attachment because it cannot use the node in question as the destination or the origin of a dependency, as it is the case in the gold-standard annotation: Gold-standard: ser como e?ne be like letter-n II II Predicted: ser e?ne II When a node has erroneously not been removed, no dependencies between its governor and its dependent can be established since DSyntS must remain a tree (which gives the same LAS and UAS errors as when a node has been erroneously removed): Gold-standard: y Michael Jackson II Predicted: y a Michael Jackson and to Michael Jackson II II 3.",
        "Relation label classification.",
        "For relation label classification, we use a multiclass linear SVM.",
        "The label classification depends on the concrete annotation schemata of the SSyntS and DSyntS treebanks on which the parser is trained.",
        "Depending on the schemata, some DSynt relation labels may be easier to derive from the original SSyntS relation labels than others.",
        "Table 2 lists all SSynt relation labels that have a straightforward mapping to DSyntS relation labels in the used treebanks, i.e., neither their dependent nor their governor are removed, and the SSyntS label always maps to the same DSynt label.",
        "SSynt DSynt abbrev ATTR abs pred ATTR adv ATTR adv mod ATTR agent I appos ATTR attr ATTR aux phras ?",
        "aux refl dir II SSynt DSynt aux refl indir III bin junct ATTR compl1 II compl2 III compl adnom ATTR coord COORD copul II copul clitic II copul quot II SSynt DSynt dobj clitic II dobj quot II elect ATTR juxtapos APPEND modal II modif ATTR num junct COORD obj copred ATTR prepos II SSynt DSynt prepos quot II prolep APPEND quant ATTR quasi coord COORD quasi subj I relat ATTR restr ATTR sequent ATTR subj I subj copred ATTR Table 2: Straightforward SSynt to DSyntS mappings Table 3 shows SSyntS relation?DSyntS relation label correspondences that are not straightforward.",
        "SSynt DepRel A Mapping to DSynt analyt fut remove Gov and Dep; add tense=FUT analyt pass remove Gov; invert I and II; add voice=PASS analyt perf remove Gov; add tense=PAST analyt progr remove Gov; add tem constituency=PROGR aux refl lex remove Dep; add se at the end of Gov's lemma aux refl pass remove Dep; invert I and II; add voice=PASS compar remove Dep if conjunction compar /coord /sub conj remove Dep if governed preposition det IF Dep=el?un THEN remove Dep; add definiteness=DEF/INDEF IF Dep=possessive THEN DepRel ATTR?I?II?III IF Dep=other THEN DepRel ATTR dobj remove Dep if governed preposition iobj remove Dep if governed preposition; DepRel II?III?IV?V?VI iobj clitic DepRel II?III?IV?V?VI obl compl remove Dep if governed preposition; DepRel I?II?III?IV?V?VI obl obj remove Dep if governed preposition; DepRel II?III?IV?V?VI punc ?",
        "punc init ?",
        "Table 3: Complex SSynt to DSynt mappings 1407 The final set of features selected for label classification includes: (i) lemma of the dependent node, (ii) dependency relation to the head of the dependent node, (iii) dependency relation label of the head node to its own head, (iv) dependency relation to the head of the sibling nodes of the dependent node, if any.",
        "After an optimization round of the parameter set of the SVM-model, relation labelling achieved 94.00% label precision and 93.28% label recall on the development set.",
        "The recall is calculated considering all the nodes that are included in the gold standard.",
        "The error sources for relation labelling were mostly the dependencies that involved possessives and the various types of objects (see Table 3) due to their differing valency.",
        "For instance, the relation det in su?det?coche ?his/her car?",
        "and su?det?llamada ?his/her phone call?",
        "have different correspondences in DSyntS: su?ATTR?coche vs. su?I?llamada.",
        "That is, the DSyntS relation depends on the lexical properties of the governor.",
        "7 Once again, more training data is needed in order to classify better those cases.",
        "4.",
        "Postprocessing In the postprocessing stage for Spanish, the following rules capture non-ambiguous correspondences between elements of the SSynt-index matrix I S = N s ?N s and DSyntS index matrix I D = N d ?N d , with n s ?",
        "N s and n d ?",
        "N d , and n s and n d corresponding to each other (we do not list here identity correspondences such as between the number grammemes of n s and n d ): ?",
        "if n s is dependent of analyt pass or analyt refl pass relation, then the voice grammeme in n d is PASS; ?",
        "if n s is dependent of analyt progr, then the voice grammeme in n d is PROGR; ?",
        "if n s is dependent of analyt refl lex, then add the particle -SE as suffix of node label (word) of d d ; ?",
        "if any of the children of n s is labelled by one of the tokens UN ?a masc ?, UNA ?a fem ?, UNOS ?some masc ?",
        "or UNAS ?some fem ?, then the definiteness grammeme in n d INDEF, otherwise it is DEF; ?",
        "if the n s label is a finite verb and n s does not govern a subject relation, then add to I ?",
        "the relation n d ?",
        "I?n ?",
        "d , with n ?",
        "d being a newly introduced node.",
        "3.2 Baseline As point of reference for the evaluation of the performance of our SSyntS?DSyntS transducer, we use a rule-based baseline that carries out the most direct transformations extracted from Tables 2 and 3.",
        "The baseline detects hypernodes by directly removing all the nodes that we are sure need to be removed, i.e. punctuation and auxiliaries.",
        "The nodes that are only potentially to be removed, i.e., all dependents of DepRels that have a possibly governed preposition or conjunction in Table 3, are left in the DSyntS.",
        "The new relation labels in the DSyntS are obtained by selecting the label that is most likely to substitute the SSyntS relation label according to classical grammar studies.",
        "The rules of the rule-based baseline look as follows: 1 if (deprel==abbrev) then deep deprel=ATTR 2 if (deprel==obl obj) then deep deprel=II .",
        ".",
        ".",
        "n if (deprel==punc) then remove(current node) 4 Results and Discussion Let us look in this section at the performance figures of the SSyntS parser, the SSyntS?DSyntS trans-ducer, and the sentence?DSyntS pipeline obtained in the experiments.",
        "4.1 SSyntS?DSyntS transducer results In Table 4, the performance of the subtasks of the SSyntS?DSyntS transducer is contrasted to the performance of the baselines; the evaluation of the postprocessing subtask is not included because the one-to-one projection of SSyntS elements to DSyntS guarantees an accuracy of 100% of the operations performed.",
        "The transducer has been applied to the gold standard test set, which is the held-out test set, with gold standard PoS tags, lemmas and dependency trees.",
        "It outputs in total 5610 nodes; the rule-based baseline outputs 8653 nodes.",
        "As mentioned in Section 3, our gold standard includes 5641 nodes.",
        "7 Note that lexemes are not generalized: a verb and its corresponding noun (e.g., construct/construction) are considered distinct lexemes.",
        "1408 Hyper-Node Detection Measure Rule-based Baseline Tree Transducer p 64.31 (5565/8653) 99.79 (5598/5610) r 98.65 (5565/5641) 99.24 (5598/5641) F1 77.86 99.51 Attachment and Labelling Measure Rule-based Baseline Tree Transducer LAP 50.02 (4328/8653) 91.07 (5109/5610) UAP 53.05 (4590/8653) 98.32 (5516/5610) LA-P 57.66 (4989/8653) 92.37 (5182/5610) LAR 76.72 (4328/5641) 90.57 (5109/5641) UAR 81.37 (4590/5641) 97.78 (5516/5641) LA-R 88.44 (4989/5641) 91.86 (5182/5641) Table 4: Performance of the SSyntS?DSyntS transducer and of the rule-based baseline over the gold-standard held-out test set (LAP: labelled attachment precision, UAP: unlabelled attachment precision, LA-P: label assignment precision, LAR: labelled attachment recall, UAR: Unlabelled attachment recall and LA-R: Label assignment recall) Our data-driven SSyntS?DSyntS transducer is much better than the baseline with respect to all evaluation measures.",
        "8 The transducer relies on distributional patterns identified in the training data set, and makes thus use of information that is not available for the rule-based baseline, which studies one node at a time.",
        "However, the rule-based baseline results also show that transduction that would remove a few nodes would provide results close to a 100% recall for the hypernode detection because a DSynt tree is a subtree of the SSynt tree (if we ignore the nodes introduced by post-processing).",
        "This is also evidenced by the labeled and attachment recall scores.",
        "The results of the transducer on the test and development sets are quite comparable.",
        "The hypernode detection is even better on the test set.",
        "The label accuracy suffers most from using unseen data during the development of the system.",
        "The attachment figures are approximately equivalent on both sets.",
        "4.2 Results of deep-syntactic parsing Let us consider now the performance of the complete DSynt parsing pipeline (PoS-tagger+surface- dependency parser?",
        "SSyntS?DSyntS transducer) on the held-out test set.",
        "Table 5 displays the figures of the Bohnet and Nivre parser.",
        "The figures are in line with the performance of state-of-the-art parsers for Spanish (Mille et al., 2012).",
        "POS LEMMA LAS UAS 96.05 92.10 81.45 88.09 Table 5: Performance of Bohnet and Nivre's joint PoS-tagger+dependency parser trained on Ancora-UPF Table 6 shows the performance of the pipeline when we feed the output of the syntactic parser to the rule-based baseline SSyntS?DSyntS module and the tree transducer.",
        "We observe a clear error propagation from the dependency parser (which provides 81.45% LAS) to the SSyntS?DSyntS transducer, which loses in tree quality more than 18%.",
        "Hyper-Node Detection Measure Baseline Tree Transducer p 63.87 (5528/8655) 97.07 (5391/5554) r 98.00 (5528/5641) 95.57 (5391/5641) F1 77.33 96.31 Labelling and Attachment Measure Baseline Tree Transducer LAP 38.75 (3354/8655) 68.31 (3794/5554) UAP 44.69 (3868/8655) 77.31 (4294/5554) LA-P 49.66 (4298/8655) 80.47 (4469/5554) LAR 59.46 (3354/5641) 67.26 (3794/5641) UAR 68.57 (3868/5641) 76.12 (4294/5641) LA-R 76.19 (4298/5641) 79.22 (4469/5641) Table 6: Performance of the deep-syntactic parsing pipeline 5 Related Work To the best of our knowledge, data-driven deep-syntactic parsing as proposed in this paper is novel.",
        "As semantic role labeling and frame-semantic analysis, it has the goal to obtain more semantically oriented structures than those delivered by state-of-the-art syntactic parsing.",
        "Semantic role labeling received considerable attention in the CoNLL shared tasks for syntactic dependency parsing in 2006 and 2007 8 We also ran MaltParser by training it on the DSynt-treebank to parse the SSynt-test set; however, the outcome was too weak to be used as baseline.",
        "1409 (Buchholz and Marsi, 2006; Nivre et al., 2007), the CoNLL shared task for joint parsing of syntactic and semantic dependencies in 2008 (Surdeanu et al., 2008) and the shared task in 2009 (Haji?c et al., 2009).",
        "The top ranked systems were pipelines that started with a syntactic analysis (as we do) and continued with predicate identification, argument identification, argument labeling, and word sense disambigua-tion; cf. (Johansson and Nugues, 2008; Che et al., 2009).",
        "At the end, a re-ranker that considers jointly all arguments to select the best combination was applied.",
        "Some of the systems were based on integrated syntactic and semantic dependency analysis; cf., e.g., (Gesmundo et al., 2009); see also (Llu?",
        "'s et al., 2013) for a more recent proposal along similar lines.",
        "However, all of them lack the ability to perform structural changes?as, e.g., introduction of nodes or removal of nodes necessary to obtain a DSyntS.",
        "Klime's (2006)'s parser removes nodes (producing tectogrammatical structures as in the Prague Dependency Treebank), but is based on rules instead of classifiers, as in our case.",
        "The same applies to earlier works in the TAG-framework, as, e.g., in (Rambow and Joshi, 1997).",
        "However, this is not to say that the idea of the surface?surface syntax?deep syntax pipeline is new.",
        "It goes back at least to Curry (1961) and is implemented in a number of more recent works; see, e.g., (de Groote, 2001; Klime?s, 2006; Bojar et al., 2008).",
        "6 Conclusions and Future Work We have presented a deep-syntactic parsing pipeline which consists of a state-of-the-art dependency parser and a novel SSyntS?DSyntS transducer.",
        "The obtained DSyntSs can be used in different applications since they abstract from language-specific grammatical idiosyncrasies of the SSynt structures as produced by state-of-the art dependency parsers, but still avoid the complexities of genuine semantic analysis.",
        "9 DSyntS-treebanks needed for data-driven applications can be bootstrapped by the pipeline.",
        "If required, a SSyntS?DSyntS structure pair can be also mapped to a pure predicate-argument graph such as the DELPH-IN structure (Oepen, 2002) or to an approximation thereof (as the Enju conversion (Miyao, 2006), which keeps functional nodes), to an DRS (Kamp and Reyle, 1993), or to a PropBank structure.",
        "On the other hand, DSyntS-treebanks can be used for automatic extraction of deep grammars.",
        "As shown by Cahill et al. (2008), automatically obtained resources can be of an even better quality than manually-crafted resources.",
        "In this context, especially research in the context of CCGs (Hockenmeier, 2003; Clark and Curran, 2007) and TAGs (Xia, 1999) should be also mentioned.",
        "To validate our approach with languages other than Spanish, we carried out an experiment on a Chinese SSyntS-DSyntS Treebank (training the DSynt-transducer on the outcome of the SSynt-parser).",
        "The results over predicted input showed an accuracy of about 75%, i.e., an accuracy comparable to the accuracy achieved for Spanish.",
        "We are also investigating multilingual approaches, such as the one proposed by McDonald et al. (2013).",
        "In the future, we will carry out further in-depth feature engineering for the task of DSynt-parsing.",
        "It proved to be crucial in semantic role labelling and dependency parsing (Che et al., 2009; Ballesteros and Nivre, 2012); we expect it be essential for our task as well.",
        "Furthermore, we will join surface syntactic and deep-syntactic parsing we kept so far separate; see, e.g., (Zhang and Clark, 2008; Llu?",
        "'s et al., 2013; Bohnet and Nivre, 2012) for analogous proposals.",
        "Further research is required here since although joint models avoid error propagation from the first stage to the second, overall, pipelined models still proved to be competitive; cf. the outcome of CoNLL shared tasks.",
        "The deep-syntactic parser described in this paper is available for downloading at https://code.",
        "google.com/p/deepsyntacticparsing/.",
        "Acknowledgements This work has been supported by the European Commission under the contract number FP7-ICT-610411.",
        "Many thanks to the three anonymous COLING reviewers for their very helpful comments and suggestions.",
        "9 The motivation to work with DSyntS instead of SSyntS is thus similiar to the motivation of the authors of the",
        "Abstract",
        "Meaning Representation (AMR) for Machine Translation (Banarescu et al., 2013), only that AMRs are considerably more semantic than DSyntSs.",
        "1410 References"
      ]
    }
  ]
}
