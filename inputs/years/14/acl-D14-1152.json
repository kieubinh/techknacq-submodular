{
  "info": {
    "authors": [
      "Ming-Feng Tsai",
      "Chuan-Ju Wang"
    ],
    "book": "EMNLP",
    "id": "acl-D14-1152",
    "title": "Financial Keyword Expansion via Continuous Word Vector Representations",
    "url": "https://aclweb.org/anthology/D14-1152",
    "year": 2014
  },
  "references": [
    "acl-N09-1031"
  ],
  "sections": [
    {
      "text": [
        "Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 1453?1458, October 25-29, 2014, Doha, Qatar.",
        "Abstract",
        "This paper proposes to apply the continuous vector representations of words for discovering keywords from a financial sentiment lexicon.",
        "In order to capture more keywords, we also incorporate syntactic information into the Continuous Bag-of-Words (CBOW) model.",
        "Experimental results on a task of financial risk prediction using the discovered keywords demonstrate that the proposed approach is good at predicting financial risk."
      ]
    },
    {
      "heading": "1 Introduction",
      "text": [
        "In the present environment with a great deal of information, how to discover useful insights for decision making is becoming increasingly important.",
        "In finance, there are typically two kinds of information (Petersen, 2004): soft information usually refers to text, including opinions, ideas, and market commentary, whereas hard information is recorded as numbers, such as financial measures and historical prices.",
        "Most financial studies related to risk analysis are based on hard information, especially on time series modeling (Christoffersen and Diebold, 2000; Lee and Tong, 2011; Wu et al., 2014; Y?uml?u et al., 2005).",
        "Despite of using only hard information, some literature incorporates soft textual information to predict financial risk (Ko- gan et al., 2009; Leidner and Schilder, 2010; Tsai and Wang, 2013).",
        "Moreover, sentiment analysis, a technique to make an assessment of the sentiments expressed in various information, has also been applied to analyze the soft textual information in financial news, reports, and social media data (De- vitt and Ahmad, 2007; Loughran and McDonald, 2011; Wang et al., 2013).",
        "Continuous vector space models (Bengio et al., 2003; Schwenk, 2007; Mikolov et al., 2010) are neural network language models, in which words are represented as high dimensional real valued vectors.",
        "These representations have recently demonstrated promising results across variety of tasks (Schwenk, 2007; Collobert and Weston, 2008; Glorot et al., 2011; Socher et al., 2011; Weston et al., 2011), because of their superiority of capturing syntactic and semantic regularities in language.",
        "In this paper, we apply the Continuous Bag-of-Words (CBOW) model (Mikolov et al., 2013) on the soft textual information in financial reports for discovering keywords via financial sentiments.",
        "In spe-cific, we use the continuous vector representations of words to find out similar terms based on their contexts.",
        "Additionally, we propose a straightforward approach to incorporate syntactic information into the CBOW model for better locating similarly meaningful or highly correlated words.",
        "To the best of our knowledge, this is the first work to incorporate more syntactic information by adding Part-Of-Speech (POS) tags to the words before training the CBOW model.",
        "In our experiments, the corpora are the annual SEC 1 -mandated financial reports, and there are 3,911 financial sentiment keywords for expansion.",
        "In order to verify the effectiveness of the expanded keywords, we then conduct two prediction tasks, including regression and ranking.",
        "Observed from our experimental results, for the regression and ranking tasks, the models trained on the expanded keywords are consistently better than those trained the original sentiment keywords only.",
        "In addition, for comparison, we conduct experiments with random keyword expansion as baselines.",
        "According to the experimental results, the expansion either with or without syntactic information outperforms the baselines.",
        "The results suggest that the CBOW model is effective at expanding keywords for financial risk prediction.",
        "1 Securities and Exchange Commission 1453 2 Keyword Expansion via Financial Sentiment Lexicon 2.1 Financial Sentiment Lexicon A sentiment lexicon is the most important resource for sentiment analysis.",
        "Loughran and McDonald (2011) states that a general purpose sentiment lexicon (e.g., the Harvard Psychosociological Dic-tionary) might misclassify common words in financial texts.",
        "Therefore, in this paper, we use a finance-specific lexicon that consists of the 6 word lists provided by (Loughran and McDonald, 2011) as seeds to expand keywords.",
        "The six lists are negative (Fin-Neg), positive (Fin-Pos), uncertainty (Fin- Unc), litigious (Fin-Lit), strong modal words (MW- Strong), and weak modal words (MW-Weak).",
        "2 2.2 Simple Keyword Expansion With the financial sentiment lexicon, we first use a collection of financial reports as the training texts to learn continuous vector representations of words.",
        "Then, each word in the sentiment lexicon is used as a seed to obtain the words with the highest n cosine distances (called the top-n words for the word) via the learned word vector representations.",
        "Finally, we construct an expanded keyword list from the top-n words for each word.",
        "2.3 Keyword Expansion with Syntactic Information For the expansion considering syntactic informa-tion, we attach the POS tag to each word in the training texts first.",
        "Then, the words in the sentiment lexicon with 4 major POS tags (i.e., JJ, NN, VB, RB) are used as seeds to expand.",
        "The rest of steps is similar to that in Section 2.2.",
        "The reason of considering POS tags for expansion is that, in general, a word with different POS tags may result in different lists of top-n words.",
        "Table 1 shows the top-5 words for the word ?default?",
        "with different POS tags (noun and adjective).",
        "Note that none of the words in the two lists overlaps.",
        "3 Financial Risk Prediction 3.1 The Risk Measure: Volatility Volatility is a measure for variation of prices of a stock over a period of time.",
        "Let S t be the price of a stock at time t. Holding the stock from time t?",
        "1 to time t would lead to a simple return: R t = 2 http://www.nd.edu/ ?",
        "mcdonald/Word_ Lists.html.",
        "default (NN) default (JJ) Cosine Cosine Word Distance Word Distance default (v.) 0.63665 nonconform (v.) 0.63462 unwaiv (v.) 0.63466 subprim (v.) 0.62404 uncur (v.) 0.62285 chattel (n.) 0.61510 trigger (n.) 0.60080 foreclos (adj.)",
        "0.61397 unmatur (v.) 0.58208 unguarante (v.) 0.60559 Table 1: Top-5 Words for the word ?default.?",
        "S t /S t?1 ?",
        "1 (Tsay, 2005).",
        "The volatility of returns for a stock from time t?",
        "n to t can thus be defined as follows: v [t?n,t] = ?",
        "?",
        "t i=t?n (R i ?",
        "?",
        "R) 2 n , (1) where ?",
        "R = ?",
        "t i=t?n R i /(n + 1).",
        "3.2 Regression Task Given a collection of financial reports D = {d 1 ,d 2 , .",
        ".",
        ".",
        ",d n }, in which each d i ?",
        "R p and is associated with a company c i , we aim to predict the future risk of each company c i (which is characterized by its volatility v i ).",
        "This prediction problem can be defined as follows: v?",
        "i = f(d i ;w).",
        "(2) The goal is to learn a p-dimensional vector w from the training data T = {(d i , v i )|d i ?",
        "R p , v i ?",
        "R}.",
        "In this paper, we adopt the Support Vector Regression (SVR) (Drucker et al., 1997) for training such a regression model.",
        "More details about SVR can be found in (Sch?olkopf and Smola, 2001).",
        "3.3 Ranking Task Instead of predicting the volatility of each company in the regression task, the ranking task aims to rank companies according to their risk via the textual information in their financial reports.",
        "We first split the volatilities of company stock returns within a year into different risk levels by the mechanism provided in (Tsai and Wang, 2013).",
        "The risk levels can be considered as the relative difference of risk among the companies.",
        "After obtaining the relative risk levels of the companies, the ranking task can be defined as fol-lows: Given a collection of financial reports D, we aim to rank the companies via a ranking model f : R p ?",
        "R such that the rank order of the set of companies is specified by the real value that the 1454 model f takes.",
        "Specifically, f(d i ) > f(d j ) means that the model asserts that c i c j , where c i c j means that c i is ranked higher than c j ; that is, the company c i is more risky than c j .",
        "For this task, this paper adopts Ranking SVM (Joachims, 2006).",
        "4 Experiments 4.1 Dataset and Preprocessings In the experiments, we use the 10-K corpus (Ko- gan et al., 2009) to conduct our financial risk prediction tasks.",
        "All documents and the 6 financial sentiment word lists are stemmed by the Porter stemmer (Porter, 1980), and some stop words are also removed.",
        "For financial risk prediction, the ground truth, the twelve months after the report volatility for each company, v +(12) , (which measures the future risk for each company) can be calculated by Equation (1), where the stock prices can be obtained from the Center for Research in Security Prices (CRSP) US Stocks Database.",
        "In addition, to obtain the relative risks among companies used in the ranking task, we follow (Tsai and Wang, 2013) to split the companies of each year into 5 risk levels.",
        "4.2 Keyword Expansion In our experiments, Section 7 (Management Discussion and Analysis) in 10-K corpus is used as training texts for the tool (word2vec 3 ) to learn the continuous vector representations of words.",
        "For the simple expansion (denoted as EXP-SIM hereafter), we use the total 1,667 stemmed sentiment words as seeds to obtain the expanded keywords via the learned word vector representations.",
        "For the expansion considering syntactic information (denoted as EXP-SYN), NLTK 4 is applied to attach the POS tag 5 to each word in the training texts; we attach the POS tag to a word with an underscore notation (e.g., default VB).",
        "For simplicity, we combine some POS tags to one tag via the tag replacement; for example, the tags JJR (adjective, comparative) and JJS (adjective, superlative) are replaced to JJ (adjective).",
        "The detailed replacement rules are tabulated in Table 2.",
        "Words from the sentiment lexicon with the four types of POS tags (i.e., JJ, NN, VB, RB) are consider as the seeds to expand the keywords.",
        "For both EXP-SIM and 3 https://code.google.com/p/word2vec/ 4 http://www.nltk.org/ 5 The most common POS tag scheme, the Penn Treebank POS Tags, is adopt in the paper.",
        "After Replacement Before Replacement JJ JJ, JJR, JJS NN NN, NNS, NNP, NNPS PRP PRP, PRP$ RB RB, RBR, RBS VB VB, VBD, VBG, VBN, VBP, VBZ WP WP, WP$ Table 2: Tag Replacement Rules.",
        "Word Cosine Distance Word Cosine Distance uncur 0.569498 event 0.466834 indentur 0.565450 lender 0.459995 waiv 0.563656 forbear 0.456556 trigger 0.559936 represent 0.450631 cure 0.539999 breach 0.446851 nonpay 0.538445 noncompli 0.431490 unmatur 0.525251 gecc 0.430712 unwaiv 0.510359 customari 0.424447 insolv 0.488534 waiver 0.419338 occurr 0.471123 prepay 0.418969 Table 3: Top-20 (Stemmed) Words for the Word ?default.?",
        "EXP-SYN, we use the top-20 expanded words for each word (e.g., Table 3) to construct expanded keyword lists.",
        "In total, for EXP-SIM, the expanded list contains 9,282 unique words and for EXP-SYN, the list has 13,534 unique words.",
        "4.3 Word Features In the experiments, the bag-of-words model is adopted and three word features are used to represent the 10-K reports in the experiments.",
        "Given a document d, three word features (i.e., TF, TFIDF and LOG1P) are calculated as follows: ?",
        "TF(t,d) = TC(t,d)/|d|, ?",
        "TFIDF(t,d) = TF(t,d) ?",
        "IDF(t,d) = TC(t,d)/|d| ?",
        "log(|D|/|d ?",
        "D : t ?",
        "d|), ?",
        "LOG1P = log(1 + TC(t,d)), where TC(t,d) denotes the term count of t in d, |d| is the length of document d, and D denotes the set of all documents in each year.",
        "4.4 Experimental Results Tables 4 and 5 tabulate the experimental results of regression and ranking, respectively, in which the training data is composed of the financial reports in a five-year period, and the following year is the test data.",
        "For example, the reports from year 1996 to 2000 constitute a training data, and the learned model is tested on the reports of year 2001.",
        "1455 [TFIDF] (Baseline) (Baseline) Year SEN EXP-RAN EXP-SIM EXP-SYN SEN EXP-RAN EXP-SIM EXP-SYN Kendall's Tau (Kendall, 1938).",
        "Spearman's Rho (Myers et al., 2003) 2001 0.4384 0.4574 0.4952 0.5049 0.4701 0.4889 0.5266 0.5375 2002 0.4421 0.4706 0.4881 0.4944 0.4719 0.5007 0.5187 0.5256 2003 0.4414 0.4706 0.5105 0.5006 0.4716 0.5015 0.5418 0.5318 2004 0.4051 0.4551 0.4750 0.4961 0.4335 0.4842 0.5043 0.5255 2005 0.3856 0.4482 0.5126 0.5294 0.4117 0.4757 0.5418 0.5579 2006 0.3784 0.4385 0.4588 0.4867 0.4029 0.4641 0.4847 0.5129 Table 5: Performance of Ranking.",
        "[LOGP] (Baseline) Year SEN EXP-RAN EXP-SIM EXP-SYN Mean Squared Error 2001 0.2526 0.2360 0.2195 0.2148 2002 0.2858 0.2649 0.2433 0.2381 2003 0.2667 0.2512 0.2320 0.2350 2004 0.2345 0.2140 0.1902 0.1872 2005 0.2241 0.2014 0.1754 0.1682 2006 0.2256 0.2072 0.1889 0.1825 Table 4: Performance of Regression In the tables, SEN denotes the experiments trained on the words from the original financial sentiment lexicon.",
        "Despite of the experiments trained on EXP-SIM and EXP-SYN, we also conduct experiments with random keyword expansion (called EXP-RAN); for the comparison purpose, we keep the number of words in the randomly expanded word list the same as that in EXP-SYN.",
        "Note that the randomly expanded list contains all sentiment words and the rest of words are randomly chosen from the vocabulary of the dataset.",
        "The columns with label EXP-RAN denote the results averaged from 20 randomly expanded word lists.",
        "The bold face numbers denote the best performance among the four word lists.",
        "As shown in Tables 4 and 5, for both regression and ranking tasks, the models trained on expanded keywords (i.e., EXP-* ) are consistently better than those trained on the original sentiment keywords only.",
        "6 Additionally, we treat the experiments with randomly expanded word list (EXP-RAN) as the baselines.",
        "7 From the two tables, we observe that the expansion either with or without syntactic information outperforms the baselines.",
        "Note that, for the EXP-SIM, the number of words used for train-6 Due to the page limits, only the results trained on features LOGP for regression and TFIDF for ranking are reported, but the performance for models trained on features TF, TFIFG, and LOGP is very consistent.",
        "7 The results for EXP-SYN are all significant better than the baseline with p < 0.05. ing the regression and ranking models is even less than that of EXP-RAN.",
        "The results suggest that the CBOW model is effective at expanding keywords for financial risk prediction.",
        "Furthermore, incorporating syntactic information into the CBOW model can even enhance the performance for the tasks of financial risk prediction.",
        "4.5 Discussions Below we provide the original texts from 10-K reports that contain the top 1 expanded word, ?uncur?",
        "(stemmed), for ?default?",
        "in Table 3.",
        "Two pieces of sentences are listed as follows (the company Investment Technology Group, 1997): ?",
        "?",
        "?",
        "terminate the agreement upon certain events of bankruptcy or insolvency or upon an uncured breach by the Company of certain covenants ?",
        "?",
        "?",
        "?",
        "?",
        "?",
        "any termination of the license agreement resulting from an uncured default would have a material adverse effect on the Company's results of operations.",
        "From the above examples, the expanded word ?un- cur?",
        "has similar meaning to ?default,?",
        "which confirms the capability of our method of capturing similarly meaningful or highly correlated words.",
        "5 Conclusions This paper applies the continuous bag-of-words model on the textual information in financial reports for expanding keywords from a financial sentiment lexicon.",
        "Additionally, we propose a simple but novel approach to incorporate syntactic information into the continuous bag-of-words model for capturing more similarly meaningful or highly correlated keywords.",
        "The experimental results for the risk prediction problem show that the expansion either with or without syntactic information outperforms the baselines.",
        "As a direction for further 1456 research, it is interesting and important to provide more analysis on the expanded words via the continuous vector representations of words.",
        "Acknowledgments This research was partially supported by the National Science Council of Taiwan under the grants NSC 102-2420-H-004-052-MY2, 102-2221-E-004- 006, and 102-2221-E-845-002-MY3.",
        "References"
      ]
    }
  ]
}
