{
  "info": {
    "authors": [
      "Teemu Ruokolainen",
      "Oskar Kohonen",
      "Sami Virpioja",
      "mikko kurimo"
    ],
    "book": "EACL",
    "id": "acl-E14-4017",
    "title": "Painless Semi-Supervised Morphological Segmentation using Conditional Random Fields",
    "url": "https://aclweb.org/anthology/E14-4017",
    "year": 2014
  },
  "references": [
    "acl-D11-1090",
    "acl-P06-1027",
    "acl-P08-1099",
    "acl-P10-1040",
    "acl-W02-0603",
    "acl-W02-1001",
    "acl-W10-2210"
  ],
  "sections": [
    {
      "text": [
        "Proceedings of the 14th Conference of the European Chapter of the Association for Computational Linguistics, pages 84?89, Gothenburg, Sweden, April 26-30 2014. c?2014 Association for Computational Linguistics Painless Semi-Supervised Morphological Segmentation using Conditional Random Fields Teemu Ruokolainen a Oskar Kohonen b Sami Virpioja b Mikko Kurimo a a Department of Signal Processing and Acoustics, Aalto University b Department of Information and Computer Science, Aalto University firstname.lastname@aalto.fi",
        "Abstract",
        "We discuss data-driven morphological segmentation, in which word forms are segmented into morphs, that is the surface forms of morphemes.",
        "We extend a recent segmentation approach based on conditional random fields from purely supervised to semi-supervised learning by exploiting available unsupervised segmentation techniques.",
        "We integrate the unsupervised techniques into the conditional random field model via feature set augmentation.",
        "Experiments on three diverse languages show that this straightforward semi-supervised extension greatly improves the segmentation accuracy of the purely supervised CRFs in a computationally efficient manner."
      ]
    },
    {
      "heading": "1 Introduction",
      "text": [
        "We discuss data-driven morphological segmenta-tion, in which word forms are segmented into morphs, the surface forms of morphemes.",
        "This type of morphological analysis can be useful for alleviating language model sparsity inherent to morphologically rich languages (Hirsim?ki et al., 2006; Creutz et al., 2007; Turunen and Kurimo, 2011; Luong et al., 2013).",
        "Particularly, we focus on a low-resource learning setting, in which only a small amount of annotated word forms are available for model training, while unannotated word forms are available in abundance.",
        "We study morphological segmentation using conditional random fields (CRFs), a discriminative model for sequential tagging and segmentation (Lafferty et al., 2001).",
        "Recently, Ruokolainen et al. (2013) showed that the CRFs can yield competitive segmentation accuracy compared to more complex, previous state-of-the-art techniques.",
        "While CRFs yielded generally the highest accuracy compared to their reference methods (Poon et al., 2009; Kohonen et al., 2010), on the smallest considered annotated data sets of 100 word forms, they were outperformed by the semi-supervised Morfessor algorithm (Kohonen et al., 2010).",
        "However, Ruokolainen et al. (2013) trained the CRFs solely on the annotated data, without any use of the available unannotated data.",
        "In this work, we extend the CRF-based approach to leverage unannotated data in a straightforward and computationally efficient manner via feature set augmentation, utilizing predictions of unsupervised segmentation algorithms.",
        "Experiments on three diverse languages show that the semi-supervised extension substantially improves the segmentation accuracy of the CRFs.",
        "The extension also provides higher accuracies on all the considered data set sizes and languages compared to the semi-supervised Morfessor (Kohonen et al., 2010).",
        "In addition to feature set augmentation, there exists numerous approaches for semi-supervised CRF model estimation, exemplified by minimum entropy regularization (Jiao et al., 2006), generalized expectations criteria (Mann and McCal-lum, 2008), and posterior regularization (He et al., 2013).",
        "In this work, we employ the feature-based approach due to its simplicity and the availability of useful unsupervised segmentation methods.",
        "Varying feature set augmentation approaches have been successfully applied in several related tasks, such as Chinese word segmentation (Wang et al., 2011; Sun and Xu, 2011) and chunking (Turian et al., 2010).",
        "The paper is organized as follows.",
        "In Section 2, we describe the CRF-based morphological segmentation approach following (Ruokolainen et al., 2013), and then show how to extend this approach to leverage unannotated data in an efficient manner.",
        "Our experimental setup and results are discussed in Sections 3 and 4, respectively.",
        "Finally, 84 we present conclusions on the work in Section 5.",
        "2 Methods 2.1 Supervised Morphological Segmentation using CRFs We present the morphological segmentation task as a sequential labeling problem by assigning each character to one of three classes, namely {be- ginning of a multi-character morph (B), middle of a multi-character morph (M), single character morph (S)}.",
        "We then perform the sequential labeling using linear-chain CRFs (Lafferty et al., 2001).",
        "Formally, the linear-chain CRF model distribution for label sequence y = (y 1 , y 2 , .",
        ".",
        ".",
        ", y T ) and a word form x = (x 1 , x 2 , .",
        ".",
        ".",
        ", x T ) is written as a conditional probability p (y |x;w) ?",
        "T ?",
        "t=2 exp ( w ?",
        "?",
        "(y t?1 , y t , x, t) ) , (1) where t indexes the character positions,w denotes the model parameter vector, and ?",
        "the vector-valued feature extracting function.",
        "The model parameters w are estimated discrimatively based on a training set of exemplar input-output pairs (x, y) using, for example, the averaged perceptron algorithm (Collins, 2002).",
        "Subsequent to estimation, the CRF model segments test word forms using the Viterbi algorithm (Lafferty et al., 2001).",
        "We next describe the feature set {?",
        "i (y t?1 , y t , x, t)} |?| i=1 by defining emission and transition features.",
        "Denoting the label set {B, M, S} as Y , the emission feature set is defined as {?",
        "m (x, t)1(y t = y ?",
        "t ) |m ?",
        "1..M ,?y ?",
        "t ?",
        "Y} , (2) where the indicator function 1(y t = y ?",
        "t ) returns one if and only if y t = y ?",
        "t and zero otherwise, that is 1(y t = y ?",
        "t ) = { 1 if y t = y ?",
        "t 0 otherwise , (3) and {?",
        "m (x, t)} M m=1 is the set of functions describing the character position t. Following Ruokolainen et al. (2013), we employ binary functions that describe the position t of word x using all left and right substrings up to a maximum length ?.",
        "The maximum substring length ?",
        "max is considered a hyper-parameter to be adjusted using a development set.",
        "While the emission features associate the input to labels, the transition feature set {1(y t?1 = y ?",
        "t?1 )1(y t = y ?",
        "t ) | y ?",
        "t , y ?",
        "t?1 ?",
        "Y} (4) captures the dependencies between adjacent labels as irrespective of the input x.",
        "2.2 Leveraging Unannotated Data In order to utilize unannotated data, we explore a straightforward approach based on feature set augmentation.",
        "We exploit predictions of unsupervised segmentation algorithms by defining variants of the features described in Section 2.1.",
        "The idea is to compensate the weaknesses of the CRF model trained on the small annotated data set using the strengths of the unsupervised methods that learn from large amounts of unannotated data.",
        "For example, consider utilizing predictions of the unsupervised Morfessor algorithm (Creutz and Lagus, 2007) in the CRF model.",
        "In order to accomplish this, we first learn the Morfessor model from the unannotated training data, and then apply the learned model on the word forms in the annotated training set.",
        "Assuming the annotated training data includes the English word drivers, the Morfessor algorithm might, for instance, return a (partially correct) segmentation driv + ers.",
        "We present this segmentation by defining a function ?",
        "(t), which returns 0 or 1, if the position t is in the middle of a segment or in the beginning of a segment, respectively, as in t 1 2 3 4 5 6 7 x t d r i v e r s ?",
        "(t) 1 0 0 0 1 0 0 Now, given a set of U functions {?",
        "u (t)} U u=1 , we define variants of the emission features in (2) as {?",
        "u (x, t)?",
        "m (x, t)1(y t = y ?",
        "t ) | ?u ?",
        "1..U ,?m ?",
        "1..M ,?y ?",
        "t ?",
        "Y} .",
        "(5) By adding the expanded features of form (5), the CRF model learns to associate the output of the unsupervised algorithms in relation to the surrounding substring context.",
        "Similarly, an expanded transition feature is written as {?",
        "u (x, t)1(y t?1 = y ?",
        "t?1 )1(y t = y ?",
        "t ) | ?u ?",
        "1..U ,?y ?",
        "t , y ?",
        "t?1 ?",
        "Y} .",
        "(6) After defining the augmented feature set, the CRF model parameters can be estimated in a standard manner on the small, annotated training data set.",
        "Subsequent to CRF training, the Morfessor model is applied on the test instances in order to allow the feature set augmentation and standard decoding with the estimated CRF model.",
        "We expect the Morfessor features to specifically improve 85 segmentation of compound words (for example, brain+storm), which are modeled with high accuracy by the unsupervised Morfessor algorithm (Creutz and Lagus, 2007), but can not be learned from the small number of annotated examples available for the supervised CRF training.",
        "As another example of a means to augment the feature set, we make use of the fact that the output of the unsupervised algorithms does not have to be binary (zeros and ones).",
        "To this end, we employ the classic letter successor variety (LSV) scores presented originally by (Harris, 1955).",
        "1 The LSV scores utilize the insight that the predictability of successive letters should be high within morph segments, and low at the boundaries.",
        "Conse-quently, a high variety of letters following a prefix indicates a high probability of a boundary.",
        "We use a variant of the LSV values presented by ?",
        "?ltekin (2010), in which we first normalize the scores by the average score at each position t, and subse-qently logarithmize the normalized value.",
        "While LSV score tracks predictability given prefixes, the same idea can be utilized for suffixes, providing the letter predecessor variety (LPV).",
        "Subsequent to augmenting the feature set using the functions LSV (t) and LPV (t), the CRF model learns to associate high successor and predecessor values (low predictability) to high probability of a segment boundary.",
        "Appealingly, the Harris features can be obtained in a computationally inexpensive manner, as they merely require counting statistics from the unannotated data.",
        "The feature set augmentation approach described above is computationally efficient, if the computational overhead from the unsupervised methods is small.",
        "This is because the CRF parameter estimation is still based on the small amount of labeled examples as described in Section 2.1, while the number of features incorporated in the CRF model (equal to the number of parameters) grows linearly in the number of exploited unsupervised algorithms.",
        "3 Experimental Setup 3.1 Data We perform the experiments on the Morpho Challenge 2009/2010 data set (Kurimo et al., 2009; Ku-1 We also experimented on modifying the output of the Morfessor algorithm from binary to probabilistic, but these soft cues provided no consistent advantage over the standard binary output.",
        "English Finnish Turkish Train (unann.)",
        "384,903 2,206,719 617,298 Train (ann.)",
        "1,000 1,000 1,000 Devel.",
        "694 835 763 Test 10,000 10,000 10,000 Table 1: Number of word types in the Morpho Challenge data set.",
        "rimo et al., 2010) consisting of manually prepared morphological segmentations in English, Finnish and Turkish.",
        "We follow the experiment setup, including data partitions and evaluation metrics, described by Ruokolainen et al. (2013).",
        "Table 1 shows the total number of instances available for model estimation and testing.",
        "3.2 CRF Feature Extraction and Training The substring features included in the CRF model are described in Section 2.1.",
        "We include all substrings which occur in the training data.",
        "The Morfessor and Harris (successor and predecessor va-riety) features employed by the semi-supervised extension are described in Section 2.2.",
        "We experimented on two variants of the Morfessor al-gorithm, namely, the Morfessor Baseline (Creutz and Lagus, 2002) and Morfessor Categories-MAP (Creutz and Lagus, 2005), CatMAP for short.",
        "The Baseline models were trained on word types and the perplexity thresholds of the CatMAP models were set equivalently to the reference runs in Morpho Challenge 2010 (English: 450, Finnish: 250, Turkish: 100); otherwise the default parameters were used.",
        "The Harris features do not require any hyper-parameters.",
        "The CRF model (supervised and semi-supervised) is trained using the averaged perceptron algorithm (Collins, 2002).",
        "The number of passes over the training set made by the perceptron algorithm, and the maximum length of substring features are optimized on the held-out development sets.",
        "The experiments are run on a standard desktop computer using a Python-based single-threaded CRF implementation.",
        "For Morfessor Baseline, we use the recently published implementation by Virpioja et al. (2013).",
        "For Morfessor CatMAP, we used the Perl implementation by Creutz and Lagus (2005).",
        "86 3.3 Reference Methods We compare our method's performance with the fully supervised CRF model and the semi-supervised Morfessor algorithm (Kohonen et al., 2010).",
        "For semi-supervised Morfessor, we use the Python implementation by Virpioja et al. (2013).",
        "4 Results Segmentation accuracies for all languages are presented in Table 2.",
        "The columns titled Train (ann.)",
        "and Train (unann.)",
        "denote the number of annotated and unannotated training instances utilized by the method, respectively.",
        "To summarize, the semi-supervised CRF extension greatly improved the segmentation accuracy of the purely supervised CRFs, and also provided higher accuracies compared to the semi-supervised Morfessor algorithm 2 .",
        "Appealingly, the semi-supervised CRF extension already provided consistent improvement over the supervised CRFs, when utilizing the computationally inexpensive Harris features.",
        "Additional gains were then obtained using the Morfessor features.",
        "On all languages, highest accuracies were obtained using a combination of Harris and CatMAP features.",
        "Running the CRF parameter estimation (includ- ing hyper-parameters) consumed typically up to a few minutes.",
        "Computing statistics for the Harris features also took up roughly a few minutes on all languages.",
        "Learning the unsupervised Morfessor algorithm consumed 3, 47, and 20 minutes for English, Finnish, and Turkish, respectively.",
        "Meanwhile, CatMAP model estimation was considerably slower, consuming roughly 10, 50, and 7 hours for English, Finnish and Turkish, respectively.",
        "Training and decoding with semi-supervised Morfessor took 21, 111, and 47 hours for English, Finnish and Turkish, respectively.",
        "5 Conclusions We extended a recent morphological segmentation approach based on CRFs from purely supervised to semi-supervised learning.",
        "We accomplished this in an efficient manner using feature set augmentation and available unsupervised segmentation techniques.",
        "Experiments on three diverse 2 The improvements over the supervised CRFs and semi-supervised Morfessor were statistically significant (confi- dence level 0.95) according to the standard 1-sided Wilcoxon signed-rank test performed on 10 randomly divided, non-overlapping subsets of the complete test sets.",
        "Method Train (ann.)",
        "Train (unann.)",
        "F1 English CRF 100 0 78.8 S-MORF.",
        "100 384,903 83.7 CRF (Harris) 100 384,903 80.9 CRF (BL+Harris) 100 384,903 82.6 CRF (CM+Harris) 100 384,903 84.4 CRF 1,000 0 85.9 S-MORF.",
        "1,000 384,903 84.3 CRF (Harris) 1,000 384,903 87.6 CRF (BL+Harris) 1,000 384,903 87.9 CRF (CM+Harris) 1,000 384,903 88.4 Finnish CRF 100 0 65.5 S-MORF.",
        "100 2,206,719 70.4 CRF (Harris) 100 2,206,719 78.9 CRF (BL+Harris) 100 2,206,719 79.3 CRF (CM+Harris) 100 2,206,719 82.0 CRF 1,000 0 83.8 S-MORF.",
        "1,000 2,206,719 76.4 CRF (Harris) 1,000 2,206,719 88.3 CRF (BL+Harris) 1,000 2,206,719 88.9 CRF (CM+Harris) 1,000 2,206,719 89.4 Turkish CRF 100 0 77.7 S-MORF.",
        "100 617,298 78.2 CRF (Harris) 100 617,298 82.6 CRF (BL+Harris) 100 617,298 84.9 CRF (CM+Harris) 100 617,298 85.5 CRF 1,000 0 88.6 S-MORF.",
        "1,000 617,298 87.0 CRF (Harris) 1,000 617,298 90.1 CRF (BL+Harris) 1,000 617,298 91.7 CRF (CM+Harris) 1,000 617,298 91.8 Table 2: Results on test data.",
        "CRF (BL+Harris) denotes semi-supervised CRF extension using Morfessor Baseline and Harris features, while CRF (CM+Harris) denotes CRF extension employing Morfessor CatMAP and Harris features.",
        "languages showed that this straightforward semi-supervised extension greatly improves the segmentation accuracy of the supervised CRFs, while being computationally efficient.",
        "The extension also outperformed the semi-supervised Morfessor algorithm on all data set sizes and languages.",
        "Acknowledgements This work was financially supported by Langnet (Finnish doctoral programme in language studies) and the Academy of Finland under the Finnish Centre of Excellence Program 2012?2017 (grant no.",
        "251170), project Multimodally grounded language technology (no.",
        "254104), and LASTU Programme (nos.",
        "256887 and 259934).",
        "87 References"
      ]
    }
  ]
}
