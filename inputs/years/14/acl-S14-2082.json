{
  "info": {
    "authors": [
      "AndrÃ© F. T. Martins",
      "Mariana S. C. Almeida"
    ],
    "book": "*SEM",
    "id": "acl-S14-2082",
    "title": "Priberam: A Turbo Semantic Parser with Second Order Features",
    "url": "https://aclweb.org/anthology/S14-2082",
    "year": 2014
  },
  "references": [
    "acl-D07-1101",
    "acl-D08-1016",
    "acl-D10-1001",
    "acl-D10-1004",
    "acl-D10-1125",
    "acl-D11-1022",
    "acl-D12-1133",
    "acl-P05-1012",
    "acl-P05-1073",
    "acl-P09-1039",
    "acl-P10-1001",
    "acl-P13-2109",
    "acl-P14-1134",
    "acl-P96-1023",
    "acl-S12-1029",
    "acl-W06-2932",
    "acl-W08-2123"
  ],
  "sections": [
    {
      "text": [
        "Priberam: A Turbo Semantic Parser with Second Order Features Andr ?",
        "e F. T. Martins ??",
        "Mariana S. C. Almeida ??",
        "?",
        "Priberam Labs, Alameda D. Afonso Henriques, 41, 2 o , 1000-123 Lisboa, Portugal ?",
        "Instituto de Telecomunicac?",
        "?oes, Instituto Superior T?ecnico, 1049-001 Lisboa, Portugal {atm,mla}@priberam.pt",
        "Abstract",
        "This paper presents our contribution to the SemEval-2014 shared task on Broad-Coverage Semantic Dependency Parsing.",
        "We employ a feature-rich linear model, including scores for first and second-order dependencies (arcs, siblings, grandparents and co-parents).",
        "Decoding is performed in a global manner by solving a linear relaxation with alternating directions dual decomposition (AD 3 ).",
        "Our system achieved the top score in the open challenge, and the second highest score in the closed track."
      ]
    },
    {
      "heading": "1 Introduction",
      "text": [
        "The last decade saw a considerable progress in statistical modeling for dependency syntactic parsing (K?ubler et al., 2009).",
        "Models that incorporate rich global features are typically more accurate, even if pruning is necessary or decoding needs to be approximate (McDonald et al., 2006; Koo and Collins, 2010; Bohnet and Nivre, 2012; Martins et al., 2009, 2013).",
        "This paper applies the same rationale to semantic dependency parsing, in which the output variable is a semantic graph, rather than a syntactic tree.",
        "We extend a recently proposed dependency parser, TurboParser (Martins et al., 2010, 2013), to be able to perform semantic parsing using any of the three formalisms considered in this shared task (DM, PAS, and PCEDT).",
        "The result is TurboSemanticParser, which we release as open-source software.",
        "1 We describe here a second order model for semantic parsing (?2).",
        "We follow prior work in semantic role labeling (Toutanova et al., 2005; Jo-This work is licensed under a Creative Commons Attribution 4.0 International Licence.",
        "1 http://labs.priberam.com/Resources/ TurboSemanticParser Figure 1: Example of a semantic graph in the DM formalism (sentence #22006003).",
        "We treat top nodes as a special semantic role TOP whose predicate is a dummy root symbol.",
        "hansson and Nugues, 2008; Das et al., 2012; Flanigan et al., 2014), by adding constraints and modeling interactions among arguments within the same frame; however, we go beyond such sibling interactions to consider more complex grandparent and co-parent structures, effectively correlating different predicates.",
        "We formulate parsing as a global optimization problem and solve a relaxation through AD 3 , a fast dual decomposition algorithm in which several simple local subproblems are solved iteratively (?3).",
        "Through a rich set of features (?4), we arrive at top accuracies at parsing speeds around 1,000 tokens per second, as described in the experimental section (?5).",
        "2 A Second Order Model for Parsing Figure 1 depicts a sentence and its semantic graph.",
        "We cast semantic parsing as a structured prediction problem.",
        "Let x be a sentence and Y(x) the set of possible dependency graphs.",
        "We assume each candidate graph y ?",
        "Y(x) can be represented as a set of substructures (called parts) in an underlying set S (e.g., predicates, arcs, pairs of adjacent arcs).",
        "We design a score function f which decomposes as a sum over these substruc-tures, f(x, y) := ?",
        "s?S f s (x, y s ).",
        "We parametrize this function using a weight vector w, and write each atomic function as f s (x, y s ) := w??",
        "s (x, y s ), where ?",
        "s (x, y s ) is a vector of local features.",
        "The decoding problem consists in obtaining the best-471 Algorithm 1 Decoding in an Arc-Factored Model 1: input: Predicate scores ?",
        "P (p), arc scores ?",
        "A (p ?",
        "a), labeled arc scores ?",
        "LA (p r ?",
        "a).",
        "2: Initialize semantic graph G?",
        "?",
        "3: for p = 0 to L do 4: Initialize ?",
        "?",
        "?",
        "P (p), frame A(p)?",
        "?",
        "5: for a = 1 to L do 6: Set r ?",
        "?",
        "argmax r ?",
        "LA (p r ?",
        "a) 7: if ?",
        "A (p?",
        "a) + ?",
        "LA (p r ?",
        "?",
        "a) > 0 then 8: A(p)?",
        "A(p) ?",
        "{?p, a, r ?",
        "?}",
        "9: ?",
        "?",
        "?",
        "+ ?",
        "A (p?",
        "a) + ?",
        "LA (p r ?",
        "?",
        "a) 10: end if 11: end for 12: if ?",
        "> 0 then set G?",
        "G ?",
        "{?p,A(p)?}",
        "13: end for 14: output: semantic graph G. scored semantic graph y?",
        "given a sentence x: y?",
        "= arg max y?Y(x) f(x, y).",
        "(1) Our choice of parts is given in Figure 2.",
        "The second order parts are inspired by prior work in syntactic parsing, modeling interactions for pairs of (unlabeled) dependency arcs, such as grandparents (Carreras, 2007) and siblings (Smith and Eis-ner, 2008; Martins et al., 2009).",
        "The main novelty is co-parent parts, which, to the best of our knowl-edge, were never considered before, as they only make sense when multiple parents are allowed.",
        "If all parts were basic, decoding could be done independently for each predicate p, as illustrated in Algorithm 1.",
        "The total runtime, for a sentence with L words, is O(L 2 |R|), where R is the set of semantic roles.",
        "Adding consecutive siblings still permits independent decoding for each pred-icate, but dynamic programming is necessary to decode the best argument frame, increasing the runtime to O(L 3 |R|).",
        "The addition of consecutive co-parents, grandparents, and arbitrary siblings and co-parents breaks this independency and sets a demand for approximate decoding.",
        "Even without second-order parts, the inclusion of hard constraints (such as requiring some roles to be unique, see ?3) also makes the problem harder.",
        "2 Rather than looking for a model in which exact decoding is tractable, which could be even more stringent for parsing semantic graphs than for dependency trees, we embrace approximate decoding strategies.",
        "Namely, our approach is based on 2 Albeit the dynamic program could still incorporate constraints for unique roles (by appending a bit-string to the state to mark semantic roles that have been filled), runtime becomes exponential in the number of unique roles, only being feasible when this number is small.",
        "Figure 2: Parts considered in this paper.",
        "The top row illustrate the basic parts, representing the event that a word is a predicate, or the existence of an arc between a predicate and an argument, eventually labeled with a semantic role.",
        "Our second-order model looks at some pairs of arcs: arcs bearing a grandparent relationship, arguments of the same predicate, predicates sharing the same argu-ment, and consecutive versions of these two.",
        "dual decomposition, a class of optimization techniques that tackle the dual of combinatorial problems in a modular and extensible manner (Ko- modakis et al., 2007; Rush et al., 2010).",
        "We employ alternating directions dual decomposition (AD 3 ; Martins et al., 2011).",
        "Like the subgradi-ent algorithm of Rush et al. (2010), AD 3 splits the original problem into local subproblems, and seeks an agreement on the overlapping variables.",
        "The difference is that the AD 3 subproblems have an additional quadratic term to accelerate con-sensus, achieving a faster convergence rate both in theory and in practice (Martins et al., 2012, 2013).",
        "For several factors (such as logic factors representing AND, OR and XOR constraints, budget constraints, and binary pairwise factors), these quadratic subproblems can be solved efficiently.",
        "For dense or structured factors, the quadratic subproblems can be solved as a sequence of local Viterbi decoding steps, via an active set method (Martins, 2014); this local decoding operation is the same that needs to be performed in the subgra-dient algorithm.",
        "We describe these subproblems in detail in the next section.",
        "3 Solving the Subproblems Predicate and Arc-Factored Parts.",
        "We capture all the basic parts with a single component.",
        "As stated in ?2, local decoding in this component has a runtime of O(L 2 |R|), by using Algorithm 1.",
        "Unique Roles.",
        "We assume some roles are unique, i.e., they can occur at most once for the 472 same predicate.",
        "3 To cope with unique roles, we add hard constraints of the kind ?",
        "a I(p r ?",
        "a ?",
        "y) ?",
        "1, ?p,?r ?",
        "R uniq , (2) where R uniq is the set of unique roles.",
        "This set is obtained from the training data by looking at the roles that never occur multiple times in the gold argument frames.",
        "4 The constraint above corresponds to a ATMOSTONE factor, which is built-in in AD 3 and can be decoded in linear time (ren- dering the runtime O(L 2 |R uniq |) when aggregating all such factors).",
        "These have also been used by Das et al. (2012) in frame-semantic parsing.",
        "Grandparents, Arbitrary Siblings and Co-parents.",
        "The second-order parts in the middle row of Figure 2 all involve the simultaneous inclusion of a pair of arcs, without further dependency on the remaining arcs.",
        "We handle each of these parts using a simple pairwise factor (called PAIR in the AD 3 toolkit).",
        "The total runtime to locally decode these factors is O(L 3 ).",
        "Predicate Automata.",
        "To handle consecutive siblings, we adapt the simple head automaton model (Alshawi, 1996; Smith and Eisner, 2008; Koo et al., 2010) to semantic parsing.",
        "We introduce one automaton for each predicate p and attachment direction (left or right).",
        "We describe right-side predicate automata; their left-side counterparts are analogous.",
        "Let ?a 0 , a 1 , .",
        ".",
        ".",
        ", a k+1 ?",
        "be the sequence of right modifiers of p, with a 0 = START and a k+1 = END.",
        "Then, we have the following component capturing consecutive siblings: f CSIB p,?",
        "(p?",
        "a 1 , .",
        ".",
        ".",
        ", p?",
        "a k ) = ?",
        "k+1 j=1 ?",
        "CSIB (p, a j?1 , a j ).",
        "(3) Maximizing f CSIB p,?",
        "via dynamic programming has a cost of O(L 2 ), yielding O(L 3 ) total runtime.",
        "Argument Automata.",
        "For consecutive co-parents, we introduce another automaton which is analogous to the predicate automaton, but where arrows are reversed.",
        "Let ?p 0 , p 1 , .",
        ".",
        ".",
        ", p k+1 ?",
        "be the sequence of right predicates that take a as argument (the left-side case is analagous), with p 0 = START and p k+1 = END.",
        "We define: f CCP a,?",
        "(a?",
        "p 1 , .",
        ".",
        ".",
        ", a?",
        "p k ) = ?",
        "k+1 j=1 ?",
        "CCP (a, p j?1 , p j ).",
        "(4) 3 Such roles have been called ?deterministic?",
        "by Flanigan et al. (2014).",
        "4 For PAS, all 43 roles were found unique; for DM, this number is 40 out of 52, and for PCEDT only 3 out of 69.",
        "The total runtime is also O(L 3 ).",
        "4 Features We define binary features for each part represented in Figure 2.",
        "Most of the features are taken from TurboParser (Martins et al., 2013), while others are inspired by the semantic parser of Johansson and Nugues (2008).",
        "Those features marked with ?",
        "require information from the dependency syntactic parser, and are only used in the open track.",
        "5 Predicate Features.",
        "Our predicate features are: ?",
        "PREDWORD, PREDLEMMA, PREDPOS.",
        "Lexical form, lemma, and POS tag of the predicate.",
        "?",
        "PREDREL.",
        "?",
        "Syntactic dependency relation between the predicate and its head.",
        "?",
        "PREDHEADWORD/POS.",
        "?",
        "Form and POS tag of the predicate syntactic head, conjoined with the predicate word and POS tag.",
        "?",
        "PREDMODWORD/POS/REL.",
        "?",
        "Form, POS tag, and dependency relation of the predicate syntactic dependents, conjoined with the predicate word and POS tag.",
        "Arc Features.",
        "All features above, plus the following (conjoined with arc direction and label): ?",
        "ARGWORD, ARGLEMMA, ARGPOS.",
        "The lexical form, lemma, and POS tag of the argument.",
        "?",
        "ARGREL.",
        "?",
        "Syntactic dependency relation between the argument and its head.",
        "?",
        "LEFTWORD/POS, ?",
        "RIGHTWORD/POS.",
        "?",
        "Form/POS tag of the leftmost/rightmost dependent of the argument, conjoined with the predicate word and POS tag.",
        "?",
        "LEFTSIBWORD/POS, ?",
        "RIGHTSIBWORD/POS.",
        "?",
        "Form/POS tag of the left/right sibling of the argument, conjoined with the predicate tag.",
        "?",
        "PREDCONTEXTWORD, PREDCONTEXTPOS, PREDCONTEXTLEMMA.",
        "Word, POS, and lemma on the left and right context of the predicate (context size is 2).",
        "?",
        "PREDCONTEXTPOSBIGRAM/TRIGRAM.",
        "Bi-gram and trigram of POS tags on the left and right side of the predicate.",
        "?",
        "PREDVOICE.",
        "?",
        "Predicate voice: active, passive, or none.",
        "Determined from the syntactic dependency tree as in Johansson and Nugues (2008).",
        "5 For the open track, the only external information used by our system were the provided automatic dependency trees.",
        "473 ?",
        "PREDWORDARGWORD, PREDWORDARG-POS, PREDPOSARGWORD, PREDPOSARG-POS.",
        "Predicate word/tag conjoined with argument word/tag.",
        "?",
        "PREDARGPOSCONTEXT.",
        "Several features conjoining the POS of words surrounding the predicate and argument (similar to the contextual features in McDonald et al. (2005)).",
        "?",
        "EXACTARCLENGTH, BINNEDARCLENGTH.",
        "Exact and binned arc length (distance between predicate and argument), conjoined with the predicate and argument POS tags.",
        "?",
        "POSINBETWEEN, WORDINBETWEEN.",
        "POS and forms between the predicate and argument, conjoined with their own POS tags and forms.",
        "?",
        "RELPATH, ?",
        "POSPATH.",
        "?",
        "Path in the syntactic dependency tree between the predicate and the argument.",
        "The path is formed either by dependency relations or by POS tags.",
        "Second Order Features.",
        "These involve a pred-icate, an argument, and a ?companion word?",
        "(which can be a second argument, in the case of siblings, a second predicate, for co-parents, or the argument of another argument, for grandparents).",
        "In all cases, features are of the following kind: ?",
        "POSTRIPLET.",
        "POS tags of the predicate, the argument, and the companion word.",
        "?",
        "UNILEXICAL.",
        "One word form (for the predi-cate/argument/companion) and two POS tags.",
        "?",
        "BILEXICAL.",
        "One POS tag (for the predi-cate/argument/companion) and two word forms.",
        "?",
        "PAIRWISE.",
        "Backed-off pair features for the companion word form/POS tag and the word form/POS of the predicate/argument.",
        "5 Experimental Results All models were trained by running 10 epochs of max-loss MIRA with C = 0.01 (Crammer et al., 2006).",
        "The cost function takes into account mismatches between predicted and gold dependen-cies, with a cost c P on labeled arcs incorrectly predicted (false positives) and a cost c R on gold labeled arcs that were missed (false negatives).",
        "These values were set through cross-validation in the dev set, yielding c P = 0.4 and c R = 0.6 in all runs, except for the DM and PCEDT datasets in the closed track, for which c P = 0.3 and c R = 0.7.",
        "To speed up decoding, we discard arcs whose posterior probability is below 10 ?4 , according to a probabilistic unlabeled first-order pruner.",
        "Table 1 shows a significant reduction of the search space with a very small drop in recall.",
        "Table 2 shows our final results in the test set, for a model trained in the train and development partitions.",
        "Our system achieved the best score in the open track (an LF score of 86.27%, averaged over DM, PAS, and PCEDT), and the second best in the closed track, after the Peking team.",
        "Overall, we observe that the precision and recall in PCEDT are far below the other two formalisms, but this difference is much smaller when looking at unlabeled scores.",
        "Comparing the results in the closed and open tracks, we observe a consistent improvement in the three formalisms of around 1% in F 1 from using syntactic information.",
        "While this confirms previous findings that syntactic features are important in semantic role labeling (Toutanova et al., 2005; Johansson and Nugues, 2008), these improvements are less striking than expected.",
        "We conjecture this is due to the fact that our model in the closed track already incorporates a variety of contextual features which are nearly as informative as those extracted from the dependency trees.",
        "Finally, to assess the importance of the second order features, Table 3 reports experiments in the dev-set that progressively add several groups of features, along with runtimes.",
        "We can see that siblings, co-parents, and grandparents all provide valuable information that improves the final scores (with the exception of the PCEDT labeled scores, where the difference is negligible).",
        "This comes at only a small cost in terms of runtime, which is around 1,000 tokens per second for the full models.",
        "UR # UA/tok LR # LA/tok DM 99.33 3.5 (13.4%) 99.22 34.4 (2.5%) PAS 99.53 3.3 (12.5%) 99.49 20.8 (1.9%) PCEDT 99.03 2.1 (8.2%) 98.77 54.5 (3.0%) Table 1: Pruner statistics in the dev-set, for the open track.",
        "Shown are oracle recall scores, considering both unlabeled (UR) and labeled arcs (LR); and the averaged number of unlabeled and labeled arcs per token that remained after the pruning stage (# UA/tok and # LA/tok).",
        "In brackets, we show the fraction of unlabeled/labeled arcs that survived the pruning.",
        "474 UP UR UF LP LR LF DM, closed 90.14 88.65 89.39 88.82 87.35 88.08 PAS, closed 93.18 91.12 92.14 91.95 89.92 90.93 PCEDT, closed 90.21 85.51 87.80 78.80 74.70 76.70 average, closed ?",
        "?",
        "89.77 ?",
        "?",
        "85.24 DM, open 91.41 89.26 90.32 90.23 88.11 89.16 PAS, open 93.62 92.01 92.81 92.56 90.97 91.76 PCEDT, open 91.58 86.61 89.03 80.14 75.79 77.90 average, open ?",
        "?",
        "90.72 ?",
        "?",
        "86.27 Table 2: Submitted results for the closed and open tracks.",
        "For comparison, the best-performing system in the closed track (Peking) obtained averaged UF and LF scores of 91.03% and 85.91%, respectively.",
        "UF LF Tok/sec DM, arc-factored 89.90 88.96 1,681 DM, arc-factored, pruned 89.85 88.90 2,642 +siblings 90.34 89.34 1,838 +co-parents 90.80 89.76 1,073 +grandparent (full) 90.95 89.90 955 PAS, arc-factored 92.34 91.40 1,927 PAS, arc-factored, pruned 92.35 91.40 2,914 +siblings 92.45 91.45 2,106 +co-parents 92.71 91.71 1,104 +grandparent (full) 92.87 91.87 1,043 PCEDT, arc-factored 87.90 79.90 1,558 PCEDT, arc-factored, pruned 87.74 79.83 2,906 +siblings 88.46 79.98 2,066 +co-parents 90.17 79.90 1,531 +grandparent (full) 90.18 80.03 1,371 Table 3: Results in the dev-set for the open track, progressively adding several groups of features, until the full model is obtained.",
        "We report un-labeled/labeled F 1 and parsing speeds in tokens per second.",
        "Our speeds include the time necessary for pruning, evaluating features, and decoding, as measured on a Intel Core i7 processor @3.4 GHz.",
        "6 Conclusions We have described a system for broad-coverage semantic dependency parsing.",
        "Our system, which is inspired by prior work in syntactic parsing, implements a linear model with second-order fea-tures, being able to model interactions between siblings, grandparents and co-parents.",
        "We have shown empirically that second-order features have an impact in the final scores.",
        "Approximate decoding was performed via alternating directions dual decomposition (AD 3 ), yielding fast runtimes of around 1,000 tokens per second.",
        "Acknowledgements We would like to thank the reviewers for their helpful comments.",
        "This work was partially supported by the EU/FEDER programme, QREN/POR Lisboa (Portugal), under the Intelligo project (contract 2012/24803) and by a FCT grant PTDC/EEI-SII/2312/2012.",
        "References"
      ]
    }
  ]
}
