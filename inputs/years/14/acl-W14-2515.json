{
  "info": {
    "authors": [
      "Charley Beller",
      "Craig Harman",
      "Benjamin Van Durme"
    ],
    "book": "LTCSS",
    "id": "acl-W14-2515",
    "title": "Predicting Fine-grained Social Roles with Selectional Preferences",
    "url": "https://aclweb.org/anthology/W14-2515",
    "year": 2014
  },
  "references": [
    "acl-D11-1120",
    "acl-J02-2003",
    "acl-J90-1003",
    "acl-J98-2002",
    "acl-N07-1071",
    "acl-P07-1028",
    "acl-P09-1080",
    "acl-P10-1044",
    "acl-P11-1016",
    "acl-P99-1014",
    "acl-W97-0209"
  ],
  "sections": [
    {
      "text": [
        "Abstract",
        "Selectional preferences, the tendencies of predicates to select for certain semantic classes of arguments, have been successfully applied to a number of tasks in computational linguistics including word sense disambiguation, semantic role label-ing, relation extraction, and textual inference.",
        "Here we leverage the information encoded in selectional preferences to the task of predicting fine-grained categories of authors on the social media platform Twitter.",
        "First person uses of verbs that select for a given social role as subject (e.g.",
        "I teach ... for teacher) are used to quickly build up binary classifiers for that role."
      ]
    },
    {
      "heading": "1 Introduction",
      "text": [
        "It has long been recognized that linguistic predicates preferentially select arguments that meet certain semantic criteria (Katz and Fodor, 1963; Chomsky, 1965).",
        "The verb eat for example selects for an animate subject and a comestible object.",
        "While the information encoded by selectional preferences can and has been used to support natural language processing tasks such as word sense disambiguation (Resnik, 1997), syntactic disambiguation (Li and Abe, 1998) and semantic role labeling (Gildea and Jurafsky, 2002), much of the work on the topic revolves around developing methods to induce selectional preferences from data.",
        "In this setting, end-tasks can be used for evaluation of the resulting collection.",
        "Ritter et al. (2010) gave a recent overview of this work, breaking it down into class-based approaches (Resnik, 1996; Li and Abe, 1998; Clark and Weir, 2002; Pantel et al., 2007), similarity-based approaches (Dagan et al., 1999; Erk, 2007), and approaches using discriminative (Bergsma et al., 2008) or generative probabilistic models (Rooth et al., 1999) like their own.",
        "One of our contributions here is to show that the literature on selectional preferences relates to the analysis of the first person content transmitted through social media.",
        "We make use of a ?quick and dirty?",
        "method for inducing selectional preferences and apply the resulting collections to the task of predicting fine-grained latent author attributes on Twitter.",
        "Our method for inducing selectional preferences is most similar to class-based approaches, though unlike approaches such as by Resnik (1996) we do not require a WordNet-like ontology.",
        "The vast quantity of informal, first-person text data made available by the rise of social media platforms has encouraged researchers to develop models that predict broad user categories like age, gender, and political preference (Garera and Yarowsky, 2009; Rao et al., 2010; Burger et al., 2011; Van Durme, 2012b; Zamal et al., 2012).",
        "Such information is useful for large scale demographic research that can fuel computational social science advertising.",
        "Similarly to Beller et al. (2014), we are interested in classification that is finer-grained than gender or political affiliation, seeking instead to predict social roles like smoker, student, and artist.",
        "We make use of a light-weight, unsupervised method to identify selectional preferences and use the resulting information to rapidly bootstrap classification models.",
        "2 Inducing Selectional Preferences Consider the task of predicting social roles in more detail: For a given role, e.g. artist, we want a way to distinguish role-bearing from non-role-bearing users.",
        "We can view each social role as being a fine-grained version of a semantic class of the sort required by class-based approaches to selectional preferences (e.g. the work by Resnik (1996) and those reviewed by Light and Greiff (2002)).",
        "The goal then is to identify a set of verbs that preferen-50 tially select that particular class as argument.",
        "Once we have a set of verbs for a given role, simple pattern matches against first person subject templates like I can be used to identify authors that bear that social role.",
        "In order to identify verbs that select for a given role r as subject we use an unsupervised method inspired by Bergsma and Van Durme (2013) that extracts features from third-person content (i.e. newswire) to build classifiers on first-person content (i.e. tweets).",
        "For example, if we read in a news article that an artist drew ..., we can take a tweet saying I drew ... as potential evidence that the author bears the artist social role.",
        "We first count all verbs v that appear with role r as subject in the web-scale, part-of-speech tagged n-gram corpus, Google V2 (Lin et al., 2010).",
        "The resulting collection of verbs is then ranked by computing their pointwise mutual information (Church and Hanks, 1990) with the subject role r. The PMI of a given role r and a verb v that takes r as subject is given as: PMI(r, v) = log P (r, v) P (r)P (v) Probabilities are estimated from counts of the role-verb pairs along with counts matching the generic subject patterns he and she which serve as general background cases.",
        "This gives us a set of verbs that preferentially select for the subset of persons filling the given role.",
        "The output of the PMI ranking is a high-recall list of verbs that preferentially select the given social role as subject over a background population.",
        "Each such list then underwent a manual filtering step to rapidly remove non-discriminative verbs and corpus artifacts.",
        "One such artifact from our corpus was the term wannabe which was spuriously elevated in the PMI ranking based on the relative frequency of the bigram artist wannabe as compared to she wannabe.",
        "Note that in the first case wannabe is best analyzed as a noun, while in the second case a verbal analysis is more plausible.",
        "The filtering was performed by one of the authors and generally took less than two minutes per list.",
        "The rapidity of the filtering step is in line with findings such as by Jacoby et al. (1979) that relevance based filtering involves less cognitive effort than generation.",
        "After filtering the lists contained fewer than 40 verbs selecting each social role.",
        "In part because of the pivot from third-to first-person text we performed a precision test on the remaining verbs to identify which of them are likely to be useful in classifying twitter users.",
        "For each remaining verb we extracted all tweets that contained the first person subject pattern I from a small corpus of tweets drawn from the free public 1% sample of the Twitter Firehose over a single month in 2013.",
        "Verbs that had no matches which appeared to be composed by a member of the associated social role were discarded.",
        "Using this smaller high-precision set of verbs, we collected tweets from a much larger corpus drawn from 1% sample over the period 2011-2013.",
        "One notable feature of the written English in social media is that sentence subjects can be optionally omitted.",
        "Subject-drop is a recognized feature of other informal spoken and written registers of English, particularly ?diary dialects?",
        "(Thrasher, 1977; Napoli, 1982; Haegeman and Ihsane, 2001; Weir, 2012; Haegeman, 2013; Scott, 2013).",
        "Because of the prevalence of subjectless cases we collected two sets of tweets: those matching the first person subject pattern I and those where the verb was tweet initial.",
        "Example tweets for each of our social roles can be seen in Table 2.",
        "3 Classification via selectional preferences We conducted a set of experiments to gauge the strength of the selectional preference indicators for each social role.",
        "For each experiment we used balanced datasets for training and testing with half of the users taken from a random background sample and half from a collection of users identified as belonging to the social role.",
        "Base accuracy was thus 50%.",
        "To curate the collections of positively identified users we crowdsourced a manual verification procedure.",
        "We use the popular crowdsourcing platform Mechanical Turk 1 to judge whether, for a tweet containing a given verb, the author held the role that verb prefers as subject.",
        "Each tweet was judged using 5-way redundancy.",
        "Mechanical Turk judges (?Turkers?)",
        "were presented with a tweet and the prompt: Based on this tweet, would you think this person is a ARTIST?",
        "along with four response options: Yes, Maybe, Hard to tell, and No.",
        "An example is shown in Figure 1.",
        "We piloted this labeling task with a goal of 20 tweets per verb over a variety of social roles.",
        "1 https://www.mturk.com/mturk/ 51 Artist draw Yeaa this a be the first time I draw my shit onn Athlete play @[user] @[user] i have got the night off tonight because I played last night and I am going out for dinner so won't be able to come?",
        "Blogger blogged @[user] I decided not to renew.",
        "I blogged about it on the fan club.",
        "a bit shocked no neg comments back to me Cheerleader cheer I really dont wanna cheer for this game I have soo much to do Christian thank Had my bday yesterday 3011 nd had a good night with my friends.",
        "I thank God 4 His blessings in my life nd praise Him 4 adding another year.",
        "DJ spin Quick cut session before I spin tonight Filmmaker film @[user] apparently there was no audio on the volleyball game I filmed so...there will be no ?NAT sound?",
        "cause I have no audio at all Media Host interview Oh.",
        "I interviewed her on the @[user] .",
        "You should listen to the interview.",
        "Its awesome!",
        "@[user] @[user] @[user] Performer perform I perform the flute... kareem shocked... Producer produce RT @[user]: Wow 2 films in Urban-world this year-1 I produced ... [URL] Smoker smoke I smoke , i drank .. was my shit bra !",
        "Stoner puff I?m a cigarello fiend smokin weed like its oxygen Puff pass, nigga I puff grass till I pass out Student finish I finish school in March and my friend birthday in March ...",
        "Teacher teach @[user] home schooled I really wanna find out wat it's like n making new friends but home schooling is cool I teach myself mums ill Table 1: Example verbs and sample tweets collected using them in the first person subject pattern (I ).",
        "Each answer was associated with a score (Yes = 1, Maybe = .5, Hard to tell = No = 0) and aggregated across the five judges, leading to a range of possible scores from 0.0 to 5.0 per tweet.",
        "We found in development that an aggregate score of 4.0 led to an acceptable agreement rate between the Turkers and the experimenters, when the tweets were randomly sampled and judged internally.",
        "Verbs were discarded for being either insufficiently accurate or insufficiently prevalent in the corpus.",
        "From the remaining verbs, we identified users with tweets scoring 4.0 or better as the positive examples of the associated social roles.",
        "These positively identified user's tweets were scraped using the Twitter API in order to construct user-specific corpora of positive examples for each role.",
        "Figure 1: Mechanical Turk presentation 0.5 0.6 0.7 0.8 Art ist Ath lete Blo gge r Che erle ade r Chr istia n DJ Film mak er Ho st Per form er Pro duc er Sm oke r Sto ner Stu den t Tea che r Acc ura cy Figure 2: Accuracy of classifier trained and tested on balanced set contrasting agreed upon Twitter users of a given role, against users pulled at random from the 1% stream.",
        "3.1 General Classification The positively annotated examples were balanced with data from a background set of Twitter users to produce training and test sets.",
        "These test sets were usually of size 40 (20 positive, 20 back-ground), with a few classes being sparser (the smallest test set had only 28 instances).",
        "We used the Jerboa (Van Durme, 2012a) platform to convert our data to binary feature vectors over a uni-gram vocabulary filtered such that the minimum frequency was 5 (across unique users).",
        "Training and testing was done with a log-linear model via LibLinear (Fan et al., 2008).",
        "Results are shown in Figure 2.",
        "As can be seen, a variety of classes in this balanced setup can be predicted with accuracies in the range of 80%.",
        "This shows that the information encoded in selectional preferences contains discriminating signal for a variety of these social roles.",
        "3.2 Conditional Classification How accurately can we predict membership in a given class when a Twitter user sends a tweet matching one of the collected verbs?",
        "For exam-ple, if one sends a tweet saying I race ..., then how likely is it that the author is an athlete?",
        "52 0.5 0.6 0.7 0.8 Art ist : dra w Ath lete : ra ce Ath lete : ru n Blo gge r : b log ged Che erle ade r : c hee r Chr istia n : pra y Chr istia n : serv e Chr istia n : than k DJ : sp in Film mak er : fil m Ho st : inte rvie w Per form er : per form Pro duc er : pro duc e Sm oke r : sm oke Sto ner : p uff Sto ner : sp ark Stu den t : e nro ll Stu den t : f inis h Tea che r : t eac h Acc ura cy Figure 3: Results of positive vs negative by verb.",
        "Given that a user writes a tweet containing I interview .",
        ".",
        ".",
        "or Interviewing .",
        ".",
        ".",
        "we are about 75% accurate in identifying whether or not the user is a Radio/Podcast Host.",
        "# Users # labeled # Pos # Neg Attribute 199022 516 63 238 Artist-draw 45162 566 40 284 Athlete-race 1074289 1000 54 731 Athlete-run 9960 15 14 0 Blogger-blog 2204 140 57 18 College Student-enroll 247231 1000 85 564 College Student-finish 60486 845 61 524 Cheerleader-cheer 448738 561 133 95 Christian-pray 92223 286 59 180 Christian-serve 428337 307 78 135 Christian-thank 17408 246 17 151 DJ-spin 153793 621 53 332 Filmmaker-film 36991 554 42 223 Radio Host-interview 43997 297 81 97 Performer-perform 69463 315 71 100 Producer-produce 513096 144 74 8 Smoker-smoke 5542 124 49 15 Stoner-puff 5526 229 59 51 Stoner-spark 149244 495 133 208 Teacher-teach Table 2: Numbers of positively and negatively identified users by indicative verb.",
        "Using the same collection as the previous ex-periment, we trained classifiers conditioned on a given verb term.",
        "Positive instances were taken to be those with a score of 4.0 or higher, with negative instances taken to be those with scores of 1.0 or lower (strong agreement by judges that the original tweet did not provide evidence of the given role).",
        "Classification results are shown in figure 3.",
        "Note that for a number of verb terms these thresholds left very sparse collections of users.",
        "There were only 8 users, for example, that tweeted the phrase I smoke ... but were labeled as negative instances of Smokers.",
        "Counts are given in Table 2.",
        "Despite the sparsity of some of these classes, many of the features learned by our classifiers make intuitive sense.",
        "Highlights of the most highly weighted unigrams from the classification Verb Feature ( Rank) draw drawing, art, book 4 , sketch 14 , paper 19 race race, hard, winter, won 11 , training 16 , run 17 run awesome, nike 6 , fast 9 , marathon 20 blog notes, boom, hacked 4 , perspective 9 cheer cheer, pictures, omg, text, literally pray through, jesus 3 , prayers 7 , lord 14 , thank 17 serve lord, jesus, church, blessed, pray, grace thank [ ], blessed, lord, trust 11 , pray 12 enroll fall, fat, carry, job, spend, fail 15 finish hey, wrong, may 8 , move 9 , officially 14 spin show, dj, music, dude, ladies, posted, listen film please, wow, youtube, send, music 8 perform [ ], stuck, act, song, tickets 7 , support 16 produce follow, video 8 , listen 10 , single 11 , studio 13 , interview fan, latest, awesome, seems smoke weakness, runs, ti, simply puff bout, $ 7 , smh 9 , weed 10 spark dont, fat 5 , blunt 6 , smoke 11 teach forward, amazing, students, great, teacher 7 Table 3: Most-highly indicative features that a user holds the associated role given that they used the phrase I VERB along with select features within the top 20. experiments are shown in Table 3.",
        "Taken together these features suggest that several of our roles can be distinguished from the background population by focussing on typical language use.",
        "The use of terms like, e.g., sketch by artists, training by ath-letes, jesus by Chrisitians, and students by teachers conforms to expected pattern of language use.",
        "4 Conclusion We have shown that verb-argument selectional preferences relates to the content-based classification strategy for latent author attributes.",
        "In particu-lar, we have presented initial studies showing that mining selectional preferences from third-person content, such as newswire, can be used to inform latent author attribute prediction based on first-person content, such as that appearing in social media services like Twitter.",
        "Future work should consider the question of priors.",
        "Our study here relied on balanced class experiments, but the more fine-grained the social role, the smaller the subset of the population we might expect will possess that role.",
        "Estimating these priors is thus an important point for future work, especially if we wish to couple such demographic predictions within a larger automatic sys-tem, such as the aggregate prediction of targeted sentiment (Jiang et al., 2011).",
        "Acknowledgements This material is partially based on research sponsored by the NSF under grant IIS-1249516 and by DARPA under agreement number FA8750-13-2-0017 (DEFT).",
        "53 References"
      ]
    }
  ]
}
