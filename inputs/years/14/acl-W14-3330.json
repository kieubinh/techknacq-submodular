{
  "info": {
    "authors": [
      "Nicolas Pécheux",
      "Li Gong",
      "Quoc Khanh Do",
      "Benjamin Marie",
      "Yulia Ivanishcheva",
      "Alexander Allauzen",
      "Thomas Lavergne",
      "Jan Niehues",
      "Aurélien Max",
      "François Yvon"
    ],
    "book": "Workshop on Statistical Machine Translation",
    "id": "acl-W14-3330",
    "title": "LIMSI $ WMT’14 Medical Translation Task",
    "url": "https://aclweb.org/anthology/W14-3330",
    "year": 2014
  },
  "references": [
    "acl-C08-1064",
    "acl-D11-1125",
    "acl-J04-2004",
    "acl-J06-4004",
    "acl-N12-1005",
    "acl-N12-1047",
    "acl-P02-1040",
    "acl-P03-1021",
    "acl-P05-1032",
    "acl-P06-2093",
    "acl-P07-2045",
    "acl-P11-2031",
    "acl-P96-1041",
    "acl-W11-2123"
  ],
  "sections": [
    {
      "text": [
        "Proceedings of the Ninth Workshop on Statistical Machine Translation, pages 246?253, Baltimore, Maryland USA, June 26?27, 2014. c?2014 Association for Computational Linguistics LIMSI @ WMT?14 Medical Translation Task Nicolas P ?",
        "echeux 1,2 , Li Gong 1,2 , Quoc Khanh Do 1,2 , Benjamin Marie 2,3 , Yulia Ivanishcheva 2,4 , Alexandre Allauzen 1,2 , Thomas Lavergne 1,2 , Jan Niehues 2 , Aur ?",
        "elien Max 1,2 , Franc?ois Yvon 2 Univ.",
        "Paris-Sud 1 , LIMSI-CNRS 2 B.P.",
        "133, 91403 Orsay, France Lingua et Machina 3 , Centre Cochrane franc?ais 4 {firstname.lastname}@limsi.fr",
        "Abstract",
        "This paper describes LIMSI's submission to the first medical translation task at WMT?14.",
        "We report results for English-French on the subtask of sentence translation from summaries of medical articles.",
        "Our main submission uses a combination of NCODE (n-gram-based) and MOSES (phrase-based) output and continuous-space language models used in a post-processing step for each system.",
        "Other characteristics of our submission in-clude: the use of sampling for building MOSES?",
        "phrase table; the implementation of the vector space model proposed by Chen et al. (2013); adaptation of the POS-tagger used by NCODE to the medical do-main; and a report of error analysis based on the typology of Vilar et al. (2006)."
      ]
    },
    {
      "heading": "1 Introduction",
      "text": [
        "This paper describes LIMSI's submission to the first medical translation task at WMT?14.",
        "This task is characterized by high-quality input text and the availability of large amounts of training data from the same domain, yielding unusually high translation performance.",
        "This prompted us to experiment with two systems exploring different translation spaces, the n-gram-based NCODE (?2.1) and an on-the-fly variant of the phrase-based MOSES (?2.2), and to later combine their output.",
        "Further attempts at improving translation quality were made by resorting to continuous language model rescoring (?2.4), vector space sub-corpus adaptation (?2.3), and POS-tagging adaptation to the medical domain (?3.3).",
        "We also performed a small-scale error analysis of the outputs of some of our systems (?5).",
        "2 System Overview 2.1 NCODE NCODE implements the bilingual n-gram approach to SMT (Casacuberta and Vidal, 2004; Mari?no et al., 2006; Crego and Mari?no, 2006) that is closely related to the standard phrase-based approach (Zens et al., 2002).",
        "In this framework, the translation is divided into two steps.",
        "To translate a source sentence f into a target sentence e, the source sentence is first reordered according to a set of rewriting rules so as to reproduce the target word order.",
        "This generates a word lattice containing the most promising source permutations, which is then translated.",
        "Since the translation step is monotonic, the peculiarity of this approach is to rely on the n-gram assumption to decompose the joint probability of a sentence pair in a sequence of bilingual units called tuples.",
        "The best translation is selected by maximizing a linear combination of feature functions using the following inference rule: e ?",
        "= argmax e,a K ?",
        "k=1 ?",
        "k f k (f , e,a) (1) where K feature functions (f k ) are weighted by a set of coefficients (?",
        "k ) and a denotes the set of hidden variables corresponding to the reordering and segmentation of the source sentence.",
        "Along with the n-gram translation models and target n-gram language models, 13 conventional features are combined: 4 lexicon models similar to the ones used in standard phrase-based systems; 6 lexical-ized reordering models (Tillmann, 2004; Crego et al., 2011) aimed at predicting the orientation of the next translation unit; a ?weak?",
        "distance-based distortion model; and finally a word-bonus model and a tuple-bonus model which compensate for the system preference for short translations.",
        "Features are estimated during the training phase.",
        "Training source sentences are first reordered so as to match 246 the target word order by unfolding the word alignments (Crego and Mari?no, 2006).",
        "Tuples are then extracted in such a way that a unique segmentation of the bilingual corpus is achieved (Mari?no et al., 2006) and n-gram translation models are then estimated over the training corpus composed of tuple sequences made of surface forms or POS tags.",
        "Reordering rules are automatically learned during the unfolding procedure and are built using part-of-speech (POS), rather than surface word forms, to increase their generalization power (Crego and Mari?no, 2006).",
        "2.2 On-the-fly System (OTF) We develop an alternative approach implementing an on-the-fly estimation of the parameter of a standard phrase-based model as in (Le et al., 2012b), also adding an inverse translation model.",
        "Given an input source file, it is possible to compute only those statistics which are required to translate the phrases it contains.",
        "As in previous works on on-the-fly model estimation for SMT (Callison- Burch et al., 2005; Lopez, 2008), we first build a suffix array for the source corpus.",
        "Only a limited number of translation examples, selected by deterministic random sampling, are then used by traversing the suffix array appropriately.",
        "A coherent translation probability (Lopez, 2008) (which also takes into account examples where translation extraction failed) is then estimated.",
        "As we cannot compute exactly an inverse translation probability (because sampling is performed independently for each source phrase), we resort to the following ap-proximation: p( ?",
        "f |e?)",
        "= min ( 1.0, p(e?| ?",
        "f)?",
        "freq( ?",
        "f) freq(e?)",
        ") (2) where the freq(?)",
        "is the number of occurrences of the given phrase in the whole corpus, and the numerator p(e?| ?",
        "f)?freq( ?",
        "f) represents the predicted joint count of ?",
        "f and e?.",
        "The other models in this system are the same as in the default configuration of MOSES.",
        "2.3 Vector Space Model (VSM) We used the vector space model (VSM) of Chen et al. (2013) to perform domain adaptation.",
        "In this approach, each phrase pair ( ?",
        "f, e?)",
        "present in the phrase table is represented by a C-dimensional vector of TF-IDF scores, one for each sub-corpus, where C represents the number of sub-corpora (see Table 1).",
        "Each component w c ( ?",
        "f, e?)",
        "is a standard TF-IDF weight of each phrase pair for the c th sub-corpus.",
        "TF( ?",
        "f, e?)",
        "is the raw joint count of ( ?",
        "f, e?)",
        "in the sub-corpus; the IDF( ?",
        "f, e?)",
        "is the inverse document frequency across all sub-corpora.",
        "A similar C-dimensional representation of the development set is computed as follows: we first perform word alignment and phrase pairs extraction.",
        "For each extracted phrase pair, we compute its TF-IDF vector and finally combine all vectors to obtain the vector for the develompent set: w dev c = J ?",
        "j=0 K ?",
        "k=0 count dev ( ?",
        "f j , e?",
        "k )w c ( ?",
        "f j , e?",
        "k ) (3) where J and K are the total numbers of source and target phrases extracted from the development data, respectively, and count dev ( ?",
        "f j , e?",
        "k ) is the joint count of phrase pairs ( ?",
        "f j , e?",
        "k ) found in the development set.",
        "The similarity score between each phrase pair's vector and the development set vector is added into the phrase table as a VSM feature.",
        "We also replace the joint count with the marginal count of the source/target phrase to compute an alternative average representation for the development set, thus adding two VSM additional features.",
        "2.4 SOUL Neural networks, working on top of conventional n-gram back-off language models, have been introduced in (Bengio et al., 2003; Schwenk et al., 2006) as a potential means to improve discrete language models.",
        "As for our submitted translation systems to WMT?12 and WMT?13 (Le et al., 2012b; Allauzen et al., 2013), we take advantage of the recent proposal of (Le et al., 2011).",
        "Using a specific neural network architecture, the Structured OUtput Layer (SOUL), it becomes possible to estimate n-gram models that use large vocab-ulary, thereby making the training of large neural network language models feasible both for target language models and translation models (Le et al., 2012a).",
        "Moreover, the peculiar parameterization of continuous models allows us to consider longer dependencies than the one used by conventional n-gram models (e.g. n = 10 instead of n = 4).",
        "Additionally, continuous models can also be easily and efficiently adapted as in (Lavergne et al., 2011).",
        "Starting from a previously trained SOUL model, only a few more training epochs are 247 Corpus Sentences Tokens (en-fr) Description wrd-lm pos-lm in-domain COPPA 454 246 10-12M -3 -15 EMEA 324 189 6-7M 26 -1 PATTR-ABSTRACTS 634 616 20-24M 22 21 PATTR-CLAIMS 888 725 32-36M 6 2 PATTR-TITLES 385 829 3-4M 4 -17 UMLS 2 166 612 8-8M term dictionary -7 -22 WIKIPEDIA 8 421 17-18k short titles -5 -13 out-of-domain NEWSCOMMENTARY 171 277 4-5M 6 16 EUROPARL 1 982 937 54-60M -7 -33 GIGA 9 625 480 260-319M 27 52 all parallel all 17M 397-475M concatenation 33 69 target-lm medical-data -146M 69 - wmt13-data -2 536M 49 - devel/test DEVEL 500 10-12k khresmoi-summary LMTEST 3 000 61-69k see Section 3.4 NEWSTEST12 3 003 73-82k from WMT?12 TEST 1 000 21-26k khresmoi-summary Table 1: Parallel corpora used in this work, along with the number of sentences and the number of English and French tokens, respectively.",
        "Weights (?",
        "k ) from our best NCODE configuration are indicated for each sub-corpora's bilingual word language model (wrd-lm) and POS factor language model (pos-lm).",
        "needed on a new corpus in order to adapt the parameters to the new domain.",
        "3 Data and Systems Preparation 3.1 Corpora We use all the available (constrained) medical data extracted using the scripts provided by the organizers.",
        "This resulted in 7 sub-corpora from the medical domain with distinctive features.",
        "As out-of-domain data, we reuse the data processed for WMT?13 (Allauzen et al., 2013).",
        "For pre-processing of medical data, we closely followed (Allauzen et al., 2013) so as to be able to directly integrate existing translation and language models, using in-house text processing tools for tokenization and detokenization steps (D?echelotte et al., 2008).",
        "All systems are built using a ?true case?",
        "scheme, but sentences fully capitalized (plentiful especially in PATTR-TITLES) are previously lowercased.",
        "Duplicate sentence pairs are removed, yielding a sentence reduction up to 70% for EMEA.",
        "Table 1 summarizes the data used along with some statistics after the cleaning and pre-processing steps.",
        "3.2 Language Models A medical-domain 4-gram language model is built by concatenating the target side of the parallel data and all the available monolingual data 1 , with modified Kneser-Ney smoothing (Kneser and Ney, 1995; Chen and Goodman, 1996), using the SRILM (Stolcke, 2002) and KENLM (Heafield, 2011) toolkits.",
        "Although more similar to term-to-term dictionaries, UMLS and WIKIPEDIA proved better to be included in the language model.",
        "The large out-of-domain language model used for WMT?13 (Allauzen et al., 2013) is additionaly used (see Table 1).",
        "3.3 Part-of-Speech Tagging Medical data exhibit many peculiarities, including different syntactic constructions and a specific vocabulary.",
        "As standard POS-taggers are known not to perform very well for this type of texts, we use a specific model trained on the Penn Treebank and on medical data from the MedPost project (Smith et al., 2004).",
        "We use Wapiti (Lavergne et al., 2010), a state-of-the-art CRF implementa-tion, with a standard feature set.",
        "Adaptation is performed as in (Chelba and Acero, 2004) using the out-of-domain model as a prior when training the in-domain model on medical data.",
        "On a medical test set, this adaptation leads to a 8 point reduction of the error rate.",
        "A standard model is used for WMT?13 data.",
        "For the French side, due to the lack of annotaded data for the medical domain, corpora are tagged using the TreeTagger (Schmid, 1994).",
        "1 Attempting include one language model per sub-corpora yielded a significant drop in performance.",
        "248 3.4 Proxy Test Set For this first edition of a Medical Translation Task, only a very small development set was made available (DEVEL in Table 1).",
        "This made both system design and tuning challenging.",
        "In fact, with such a small development set, conventional tuning methods are known to be very unstable and prone to overfitting, and it would be suboptimal to select a configuration based on results on the development set only.",
        "2 To circumvent this, we artificially created our own internal test set by randomly selecting 3 000 sentences out from the 30 000 sentences from PATTR-ABSTRACTS having the lowest perplexity according to 3-gram language models trained on both sides of the DEVEL set.",
        "This test set, denoted by LMTEST, is however highly biaised, especially because of the high redundancy in PATTR-ABSTRACTS, and should be used with great care when tuning or comparing systems.",
        "3.5 Systems NCODE We use NCODE with default settings, 3- gram bilingual translation models on words and 4- gram bilingual translation factor models on POS, for each included corpora (see Table 1) and for the concatenation of them all.",
        "OTF When using our OTF system, all in-domain and out-of-domain data are concatenated, respectively.",
        "For both corpora, we use a maximum random sampling size of 1 000 examples and a maximum phrase length of 15.",
        "However, all sub-corpora but GIGA 3 are used to compute the vectors for VSM features.",
        "Decoding is done with MOSES 4 (Koehn et al., 2007).",
        "SOUL Given the computational cost of computing n-gram probabilities with neural network models, we resort to a reranking approach.",
        "In the following experiments, we use 10-gram SOUL models to rescore 1 000-best lists.",
        "SOUL models provide five new features: a target language model score and four translation scores (Le et al., 2012a).",
        "We reused the SOUL models trained for our participation to WMT?12 (Le et al., 2012b).",
        "More-over, target language models are adapted by running 6 more epochs on the new medical data.",
        "2 This issue is traditionally solved in Machine Learning by folded cross-validation, an approach that would be too prohibitive to use here.",
        "3 The GIGA corpus is actually very varied in content.",
        "4 http://www.statmt.org/moses/ System Combination As NCODE and OTF differ in many aspects and make different errors, we use system combination techniques to take advantage of their complementarity.",
        "This is done by reranking the concatenation of the 1 000-best lists of both systems.",
        "For each hypothesis within this list, we use two global features, corresponding either to the score computed by the corresponding system or 0 otherwise.",
        "We then learn reranking weights using Minimum Error Rate Training (MERT) (Och, 2003) on the development set for this combined list, using only these two features (SysComb-2).",
        "In an alternative configuration, we use the two systems without the SOUL rescoring, and add instead the five SOUL scores as features in the system combination reranking (SysComb-7).",
        "Evaluation Metrics All BLEU scores (Pap- ineni et al., 2002) are computed using cased multi-bleu with our internal tokenization.",
        "Reported results correspond to the average and standard deviation across 3 optimization runs to better account for the optimizer variance (Clark et al., 2011).",
        "4 Experiments 4.1 Tuning Optimization Method MERT is usually used to optimize Equation 1.",
        "However, with up to 42 features when using SOUL, this method is known to become very sensitive to local minima.",
        "Table 2 compares MERT, a batch variant of the Margin Infused Relaxation Algorithm (MIRA) (Cherry and Foster, 2012) and PRO (Hopkins and May, 2011) when tuning an NCODE system.",
        "MIRA slightly outperforms PRO on DEVEL, but seems prone to overfitting.",
        "However this was not possible to detect before the release of the test set (TEST), and so we use MIRA in all our experiments.",
        "DEVEL TEST MERT 47.0?",
        "0.4 44.1?",
        "0.8 MIRA 47.9?",
        "0.0 44.8?",
        "0.1 PRO 47.1?",
        "0.1 45.1?",
        "0.1 Table 2: Impact of the optimization method during the tuning process on BLEU score, for a baseline NCODE system.",
        "249 4.2 Importance of the Data Sources Table 3 shows that using the out-of-domain data from WMT?13 yields better scores than only using the provided medical data only.",
        "Moreover, combining both data sources drastically boosts performance.",
        "Table 1 displays the weights (?",
        "k ) given by NCODE to the different sub-corpora bilingual language models.",
        "Three corpora seems particulary useful: EMEA, PATTR-ABSTRACTS and GIGA.",
        "Note that several models are given a negative weight, but removing them from the model surprisingly results in a drop of performance.",
        "DEVEL TEST medical 42.2?",
        "0.1 39.6?",
        "0.1 WMT?13 43.0?",
        "0.1 41.0?",
        "0.0 both 48.3?",
        "0.1 45.4?",
        "0.0 Table 3: BLEU scores obtained by NCODE trained on medical data only, WMT?13 data only, or both.",
        "4.3 Part-of-Speech Tagging Using the specialized POS-tagging models for medical data described in Section 3.3 instead of a standart POS-tagger, a 0.5 BLEU points increase is observed.",
        "Table 4 suggests that a better POS tagging quality is mainly beneficial to the reordering mechanism in NCODE, in contrast with the POS-POS factor models included as features.",
        "Reordering Factor model DEVEL TEST std std 47.9?",
        "0.0 44.8?",
        "0.1 std spec 47.9?",
        "0.1 45.0?",
        "0.1 spec std 48.4?",
        "0.1 45.3?",
        "0.1 spec spec 48.3?",
        "0.1 45.4?",
        "0.0 Table 4: BLEU results when using a standard POS tagging (std) or our medical adapted specialized method (spec), either for the reordering rule mechanism (Reordering) or for the POS-POS bilingual language models features (Factor model).",
        "4.4 Development and Proxy Test Sets In Table 5, we assess the importance of domain adaptation via tuning on the development set used and investigate the benefits of our internal test set.",
        "Best scores are obtained when using the provided development set in the tuning process.",
        "Us-DEVEL LMTEST NEWSTEST12 TEST 48.3?",
        "0.1 46.8?",
        "0.1 26.2?",
        "0.1 45.4?",
        "0.0 41.8?",
        "0.2 48.9?",
        "0.1 18.5?",
        "0.1 40.1?",
        "0.1 39.8?",
        "0.1 37.4?",
        "0.2 29.0?",
        "0.1 39.0?",
        "0.3 Table 5: Influence of the choice of the development set when using our baseline NCODE system.",
        "Each row corresponds to the choice of a development set used in the tuning process, indicated by a surrounded BLEU score.",
        "Table 6: Contrast of our two main systems and their combination, when adding SOUL language (LM) and translation (TM) models.",
        "Stars indicate an adapted LM.",
        "BLEU results for the best run on the development set are reported.",
        "DEVEL TEST NCODE 48.5 45.2 + SOUL LM 49.4 45.7 + SOUL LM ?",
        "49.8 45.9 + SOUL LM + TM 50.1 47.0 + SOUL LM ?",
        "+ TM 50.1 47.0 OTF 46.6 42.5 + VSM 46.9 42.8 + SOUL LM 48.6 44.0 + SOUL LM ?",
        "48.4 44.2 + SOUL LM + TM 49.6 44.8 + SOUL LM ?",
        "+ TM 49.7 44.9 SysComb-2 50.5 46.6 SysComb-7 50.7 46.5 ing NEWSTEST12 as development set unsurprisingly leads to poor results, as no domain adaptation is carried out.",
        "However, using LMTEST does not result in much better TEST score.",
        "We also note a positive correlation between DEVEL and TEST.",
        "From the first three columns, we decided to use the DEVEL data set as development set for our sub-mission, which is a posteriori the right choice.",
        "4.5 NCODE vs. OTF Table 6 contrasts our different approaches.",
        "Preliminary experiments suggest that OTF is a comparable but cheaper alternative to a full MOSES system.",
        "5 We find a large difference in performance, 5 A control experiment for a full MOSES system (using a single phrase table) yielded a BLEU score of 45.9 on DEVEL and 43.2 on TEST, and took 3 more days to complete.",
        "250 extra missing incorrect unknown word content filler disamb.",
        "form style term order word term all syscomb 4 13 20 47 62 8 18 21 1 11 205 OTF+VSM+SOUL 4 4 31 44 82 6 20 42 3 12 248 Table 7: Results for manual error analysis following (Vilar et al., 2006) for the first 100 test sentences.",
        "NCODE outperforming OTF by 2.8 BLEU points on the TEST set.",
        "VSM does not yield any significant improvement, contrarily to the work of Chen et al. (2013); it may be the case all individual sub-corpus are equally good (or bad) at approximating the stylistic preferences of the TEST set.",
        "4.6 Integrating SOUL Table 6 shows the substantial impact of adding SOUL models for both baseline systems.",
        "With only the SOUL LM, improvements on the test set range from 0.5 BLEU points for NCODE system to 1.2 points for the OTF system.",
        "The adaptation of SOUL LM with the medical data brings an additional improvement of about 0.2 BLEU points.",
        "Adding all SOUL translation models yield an improvement of 1.8 BLEU points for NCODE and of 2.4 BLEU points with the OTF system using VSM models.",
        "However, the SOUL adaptation step has then only a modest impact.",
        "In future work, we plan to also adapt the translation models in order to increase the benefit of using in-domain data.",
        "4.7 System Combination Table 6 shows that performing the system combination allows a gain up to 0.6 BLEU points on the DEVEL set.",
        "However this gain does not transfer to the TEST set, where instead a drop of 0.5 BLEU is observed.",
        "The system combination using SOUL scores showed the best result over all of our other systems on the DEVEL set, so we chose this (a posteriori sub-obtimal) configuration as our main system submission.",
        "Our system combination strategy chose for DEVEL about 50% hypotheses among those produced by NCODE and 25% hypotheses from OTF, the remainder been common to both systems.",
        "As ex-pected, the system combination prefers hypotheses coming from the best system.",
        "We can observe nearly the same distribution for TEST.",
        "5 Error Analysis The high level of scores for automatic metrics encouraged us to perform a detailed, small-scale analysis of our system output, using the error types proposed by Vilar et al. (2006).",
        "A single annotator analyzed the output of our main submission, as well as our OTF variant.",
        "Results are in Table 7.",
        "Looking at the most important types of errors, assuming the translation hypotheses were to be used for rapid assimilation of the text content, we find a moderate number of unknown terms and incorrectly translated terms.",
        "The most frequent error types include missing fillers, incorrect disam-biguation, form and order, which all have some significant impact on automatic metrics.",
        "Comparing more specifically the two systems used in this small-scale study, we find that our combination (which reused more than 70% of hypotheses from NCODE) mostly improves over the OTF variant on the choice of correct word form and word order.",
        "We may attribute this in part to a more efficient reordering strategy that better exploits POS tags.",
        "6 Conclusion In this paper, we have demonstrated a successful approach that makes use of two flexible translation systems, an n-gram system and an on-the-fly phrase-based model, in a new medical translation task, through various approaches to perform domain adaptation.",
        "When combined with continuous language models, which yield additional gains of up to 2 BLEU points, moderate to high-quality translations are obtained, as confirmed by a fine-grained error analysis.",
        "The most challenging part of the task was undoubtedly the lack on an internal test to guide system development.",
        "Another interesting negative result lies in the absence of success for our configuration of the vector space model of Chen et al. (2013) for adaptation.",
        "Lastly, a more careful integration of medical terminology, as provided by the UMLS, proved necessary.",
        "7 Acknowledgements We would like to thank Guillaume Wisniewski and the anonymous reviewers for their helpful comments and suggestions.",
        "251 References"
      ]
    }
  ]
}
