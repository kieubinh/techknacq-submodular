{
  "info": {
    "authors": [
      "Miloš Stanojević",
      "Khalil Sima'an"
    ],
    "book": "SSST",
    "id": "acl-W14-4017",
    "title": "Evaluating Word Order Recursively over Permutation-Forests",
    "url": "https://aclweb.org/anthology/W14-4017",
    "year": 2014
  },
  "references": [
    "acl-C08-1136",
    "acl-D10-1092",
    "acl-J97-3002",
    "acl-P02-1040",
    "acl-W07-0404",
    "acl-W10-1749",
    "acl-W11-2107"
  ],
  "sections": [
    {
      "text": [
        "Proceedings of SSST-8, Eighth Workshop on Syntax, Semantics and Structure in Statistical Translation, pages 138?147, October 25, 2014, Doha, Qatar.",
        "c ?2014 Association for Computational Linguistics Evaluating Word Order Recursively over Permutation-Forests Milo ?",
        "s Stanojevi ?",
        "c and Khalil Sima?an Institute for Logic, Language and Computation University of Amsterdam Science Park 107, 1098 XG Amsterdam, The Netherlands {m.stanojevic,k.simaan}@uva.nl",
        "Abstract",
        "Automatically evaluating word order of MT system output at the sentence-level is challenging.",
        "At the sentence-level, ngram counts are rather sparse which makes it difficult to measure word order quality effectively using lexicalized units.",
        "Recent approaches abstract away from lexicalization by assigning a score to the permutation representing how word positions in system output move around relative to a reference translation.",
        "Metrics over permutations exist (e.g., Kendal tau or Spearman Rho) and have been shown to be useful in earlier work.",
        "However, none of the existing metrics over permutations groups word positions recursively into larger phrase-like blocks, which makes it difficult to account for long-distance reordering phenomena.",
        "In this paper we explore novel metrics computed over Permutation Forests (PEFs), packed charts of Permutation Trees (PETs), which are tree decompositions of a permutation into primitive ordering units.",
        "We empirically compare PEFs metric against five known reordering metrics on WMT13 data for ten language pairs.",
        "The PEFs metric shows better correlation with human ranking than the other metrics almost on all language pairs.",
        "None of the other metrics exhibits as stable behavior across language pairs."
      ]
    },
    {
      "heading": "1 Introduction",
      "text": [
        "Evaluating word order (also reordering) in MT is one of the main ingredients in automatic MT eval-uation, e.g., (Papineni et al., 2002; Denkowski and Lavie, 2011).",
        "To monitor progress on evaluating reordering, recent work explores dedicated reordering evaluation metrics, cf. (Birch and Os-borne, 2011; Isozaki et al., 2010; Talbot et al., 2011).",
        "Existing work computes the correlation between the ranking of the outputs of different systems by an evaluation metric to human ranking, on e.g., the WMT evaluation data.",
        "For evaluating reordering, it is necessary to word align system output with the corresponding reference translation.",
        "For convenience, a 1:1 alignment (a permutation) is induced between the words on both sides (Birch and Osborne, 2011), possibly leaving words unaligned on either side.",
        "Existing work then concentrates on defining measures of reordering over permutations, cf. (Lap- ata, 2006; Birch and Osborne, 2011; Isozaki et al., 2010; Talbot et al., 2011).",
        "Popular metrics over permutations are: Kendall's tau, Spearman, Hamming distance, Ulam and Fuzzy score.",
        "These metrics treat a permutation as a flat sequence of integers or blocks, disregarding the possibility of hierarchical grouping into phrase-like units, making it difficult to measure long-range order divergence.",
        "Next we will show by example that permutations also contain latent atomic units that govern the recursive reordering of phrase-like units.",
        "Accounting for these latent reorderings could actually be far simpler than the flat view of a permutation.",
        "Isozaki et al. (2010) argue that the conventional metrics cannot measure well the long distance reordering between an English reference sentence ?A because B?",
        "and a Japanese-English hypothesis translation ?B because A?, where A and B are blocks of any length with internal monotonic alignments.",
        "In this paper we explore the idea of factorizing permutations into permutation-trees (PETs) (Gildea et al., 2006) and defining new 138 ?2,4,1,3?",
        "2 ?1,2?",
        "4 ?1,2?",
        "5 6 1 3 Figure 1: A permutation tree for ?2, 4, 5, 6, 1, 3?",
        "tree-based reordering metrics which aims at dealing with this type of long range reorderings.",
        "For the Isozaki et al. (2010) Japanese-English example, there are two PETs (when leaving A and B as encapsulated blocks): ?2,1?",
        "A ?2,1?",
        "because B ?2,1?",
        "?2,1?",
        "A because B Our PET-based metrics interpolate the scores over the two inversion operators ?2, 1?",
        "with the internal scores for A and B, incorporating a weight for subtree height.",
        "If both A and B are large blocks, internally monotonically (also known as straight) aligned, then our measure will not count every single reordering of a word in A or B, but will consider this case as block reordering.",
        "From a PET perspective, the distance of the reordering is far smaller than when looking at a flat permutation.",
        "But does this hierarchical view of reordering cohere better with human judgement than string-based metrics?",
        "The example above also shows that a permutation may factorize into different PETs, each corresponding to a different segmentation of a sentence pair into phrase-pairs.",
        "In this paper we introduce permutation forests (PEFs); a PEF is a hypergraph that compactly packs the set of PETs that factorize a permutation.",
        "There is yet a more profoud reasoning behind PETs than only accounting for long-range reorder-ings.",
        "The example in Figure 1 gives the flavor of PETs.",
        "Observe how every internal node in this PET dominates a subtree whose fringe 1 is itself a permutation over an integer sub-range of the original permutation.",
        "Every node is decorated with a permutation over the child positions (called oper-ator).",
        "For example ?4, 5, 6?",
        "constitutes a contiguous range of integers (corresponding to a phrase pair), and hence will be grouped into a subtree; 1 Ordered sequence of leaf nodes.",
        "which in turn can be internally re-grouped into a binary branching subtree.",
        "Every node in a PET is minimum branching, i.e., the permutation factorizes into a minimum number of adjacent permutations over integer sub-ranges (Albert and Atkin-son, 2005).",
        "The node operators in a PET are known to be the atomic building blocks of all permutations (called primal permutations).",
        "Because these are building atomic units of reordering, it makes sense to want to measure reordering as a function of the individual cost of these operators.",
        "In this work we propose to compute new reordering measures that aggregate over the individual node-permutations in these PETs.",
        "While PETs where exploited rather recently for extracting features used in the BEER metric system description (Stanojevi?c and Sima?an, 2014) in the official WMT 2014 competition, this work is the first to propose integral recursive metrics over PETs and PEFs solely for measuring reordering (as opposed to individual non-recursive features in a full metric that measures at the same time both fluency and adequacy).",
        "We empirically show that a PEF-based evaluation measure correlates better with human rankings than the string-based measures on eight of the ten language pairs in WMT13 data.",
        "For the 9 th language pair it is close to best, and for the 10 th (English-Czech) we find a likely explanation in the Findings of the 2013 WMT (Bo- jar et al., 2013).",
        "Crucially, the PEF-based measure shows more stable ranking across language pairs than any of the other measures.",
        "The metric is available online as free software 2 .",
        "2 Measures on permutations: Baselines In (Birch and Osborne, 2010; Birch and Osborne, 2011) Kendall's tau and Hamming distance are combined with unigram BLEU (BLEU-1) leading to LRscore showing better correlation with human judgment than BLEU-4.",
        "Birch et al. (2010) additionally tests Ulam distance (longest common subsequence ?",
        "LCS ?",
        "normalized by the permutation length) and the square root of Kendall's tau.",
        "Isozaki et al. (2010) presents a similar approach to (Birch and Osborne, 2011) additionally testing Spearman rho as a distance measure.",
        "Talbot et al. (2011) extracts a reordering measure from METEOR (Denkowski and Lavie, 2011) dubbed Fuzzy Reordering Score and evaluates it on MT reordering quality.",
        "2 https://github.com/stanojevic/beer 139 For an evaluation metric we need a function which would have the standard behaviour of evaluation metrics the higher the score the better.",
        "Bellow we define the baseline metrics that were used in our experiments.",
        "Baselines A permutation over [1..n] (subrange of the positive integers where n > 1) is a bijective function from [1..n] to itself.",
        "To represent permutations we will use angle brackets as in ?2, 4, 3, 1?.",
        "Given a permutation pi over [1..n], the notation pi i (1 ?",
        "i ?",
        "n) stands for the integer in the i th position in pi; pi(i) stands for the index of the position in pi where integer i appears; and pi j i stands for the (contiguous) sub-sequence of integers pi i , .",
        ".",
        ".",
        "pi j .",
        "The definitions of five commonly used metrics over permutations are shown in Figure 2.",
        "In these definitions, we use LCS to stand for Longest Common Subsequence, and Kronecker ?",
        "[a] which is 1 if (a == true) else zero, and A n 1 = ?1, ?",
        "?",
        "?",
        ", n?",
        "which is the identity permutation over [1..n].",
        "We note that all existing metrics kendall(pi) = ?",
        "n?1 i=1 ?",
        "n j=i+1 ?",
        "[pi(i) < pi(j)] (n 2 ?",
        "n)/2 hamming(pi) = ?",
        "n i=1 ?",
        "[pi i == i] n spearman(pi) = 1?",
        "3 ?",
        "n i=1 (pi i ?",
        "i) 2 n(n 2 ?",
        "1) ulam(pi) = LCS(pi,A n 1 )?",
        "1 n?",
        "1 fuzzy(pi) = 1?",
        "c?",
        "1 n?",
        "1 where c is # of monotone sub-permutations Figure 2: Five commonly used metrics over permutations are defined directly over flat string-level permutations.",
        "In the next section we present an alternative view of permutations are compositional, recursive tree structures.",
        "3 Measures on Permutation Forests Existing work, e.g., (Gildea et al., 2006), shows how to factorize any permutation pi over [1..n] into a canonical permutation tree (PET).",
        "Here we will summarize the relevant aspects and extend PETs to permutation forests (PEFs).",
        "A non-empty sub-sequence pi j i of a permutation pi is isomorphic with a permutation over [1..(j ?",
        "i + 1)] iff the set {pi i , .",
        ".",
        ".",
        ", pi j } is a contiguous range of positive integers.",
        "We will use the term a sub-permutation of pi to refer to a subsequence of pi that is isomorphic with a permutation.",
        "Note that not every subsequence of a permutation pi is necessarily isomorphic with a permutation, e.g., the subsequence ?3, 5?",
        "of ?1, 2, 3, 5, 4?",
        "is not a sub-permutation.",
        "One sub-permutation pi 1 of pi is smaller than another sub-permutation pi 2 of pi iff every integer in pi 1 is smaller than all integers in pi 2 .",
        "In this sense we can put a full order on non-overlapping sub-permutations of pi and rank them from the smallest to the largest.",
        "For every permutation pi there is a minimum number of adjacent sub-permutations it can be factorized into (see e.g., (Gildea et al., 2006)).",
        "We will call this minimum number the arity of pi and denote it with a(pi) (or simply a when pi is understood from the context).",
        "For example, the arity of pi = ?5, 7, 4, 6, 3, 1, 2?",
        "is a = 2 because it can be split into a minimum of two sub-permutations (Figure 3), e.g. ?5, 7, 4, 6, 3?",
        "and ?1, 2?",
        "(but alternatively also ?5, 7, 4, 6?",
        "and ?3, 1, 2?).",
        "In contrast, pi = ?2, 4, 1, 3?",
        "(also known as the Wu (1997) per-mutation) cannot be split into less than four sub-permutations, i.e., a = 4.",
        "Factorization can be applied recursively to the sub-permutations of pi, resulting in a tree structure (see Figure 3) called a permutation tree (PET) (Gildea et al., 2006; Zhang and Gildea, 2007; Maillette de Buy Wenniger and Sima?an, 2011).",
        "Some permutations factorize into multiple alternative PETs.",
        "For pi = ?4, 3, 2, 1?",
        "there are five PETs shown in Figure 3.",
        "The alternative PETs can be packed into an O(n 2 ) permutation forest (PEF).",
        "For many computational purposes, a single canonical PET is sufficient, cf. (Gildea et al., 2006).",
        "However, while different PETs of pi exhibit the same reordering pattern, their different binary branching structures might indicate important differences as we show in our experiments.",
        "A permutation forest (akin to a parse forest) F for pi (over [1..n]) is a data structure consisting of a subset of {[[i, j, I j i , O j i ]] | 0 ?",
        "i ?",
        "j ?",
        "n}, where I j i is a (possibly empty) set of inferences (sets of split points) for pi j i+1 and O j i is an operator shared by all inferences of pi j i+1 .",
        "If pi j i+1 is a sub-permutation and it has arity a ?",
        "(j ?",
        "(i + 140 ?2,1?",
        "?2,1?",
        "?2,4,1,3?",
        "5 7 4 6 3 ?1,2?",
        "1 2 ?2,1?",
        "4 ?2,1?",
        "3 ?2,1?",
        "2 1 ?2,1?",
        "4 ?2,1?",
        "?2,1?",
        "3 2 1 ?2,1?",
        "?2,1?",
        "4 3 ?2,1?",
        "2 1 ?2,1?",
        "?2,1?",
        "?2,1?",
        "4 3 2 1 ?2,1?",
        "?2,1?",
        "4 ?2,1?",
        "3 2 1 Figure 3: A PET for pi = ?5, 7, 4, 6, 3, 1, 2?.",
        "And five different PETs for pi = ?4, 3, 2, 1?.",
        "1)), then each inference consists of a a ?",
        "1-tuple [l 1 , .",
        ".",
        ".",
        ", l a?1 ], where for each 1 ?",
        "x ?",
        "(a?",
        "1), l x is a ?split point?",
        "which is given by the index of the last integer in the x th sub-permutation in pi.",
        "The permutation of the a sub-permutations (?children?",
        "of pi j i+1 ) is stored in O j i and it is the same for all inferences of that span (Zhang et al., 2008).",
        "?2,1?",
        "4 3 2 1 ?2,1?",
        "4 3 2 1 ?2,1?",
        "4 3 2 1 Figure 4: The factorizations of pi = ?4, 3, 2, 1?.",
        "Let us exemplify the inferences on pi = ?4, 3, 2, 1?",
        "(see Figure 4) which factorizes into pairs of sub-permutations (a = 2): a split point can be at positions with index l 1 ?",
        "{1, 2, 3}.",
        "Each of these split points (factorizations) of pi will be represented as an inference for the same root node which covers the whole of pi (placed in entry [0, 4]); the operator of the inference here consists of the permutation ?2, 1?",
        "(swapping the two ranges covered by the children sub-permutations) and inference consists of a?",
        "1 indexes l 1 , .",
        ".",
        ".",
        ", l a?1 signifying the split points of pi into sub-permutations: since a = 2 for pi, then a single index l 1 ?",
        "{1, 2, 3} is stored with every inference.",
        "For the factorization ((4, 3), (2, 1)) the index l 1 = 2 signifying that the second position is a split point into ?4, 3?",
        "(stored in entry [0, 2]) and ?2, 1?",
        "(stored in entry [2, 4]).",
        "For the other factorizations of pi similar inferences are stored in the permutation forest.",
        "Figure 5 shows a simple top-down factorization algorithm which starts out by computing the arity a using function a(pi).",
        "If a = 1, a single leaf node is stored with an empty set of inferences.",
        "If a > 1 then the algorithm computes all possible factorizations of pi into a sub-permutations (a sequence of a?",
        "1 split points) and stores their inferences together as I j i and their operator O j i associated with a node in entry [[i, j, I j i , O j i ]].",
        "Subse-quently, the algorithm applies recursively to each sub-permutation.",
        "Efficiency is a topic beyond the scope of this paper, but this naive algorithm has worst case time complexity O(n 3 ), and when computing only a single canonical PET this can be O(n) (see e.g., (Zhang and Gildea, 2007)).",
        "Function PEF (i, j, pi,F); # Args: sub-perm.",
        "pi over [i..j] and forest F Output: Parse-Forest F(pi) for pi; begin if ([[i, j, ?]]",
        "?",
        "F) then return F ; #memoization a := a(pi); if a = 1 return F := F ?",
        "{[[i, j, ?",
        "]]}; For each set of split points {l 1 , .",
        ".",
        ".",
        ", l a?1 } do O j i := RankListOf(pi l 1 (l 0 +1) , pi l 2 (l 1 +1) , .",
        ".",
        ".",
        ", pi l a (l a?1 +1) ); I j i := I j i ?",
        "[l 1 , .",
        ".",
        ".",
        ", l a?1 ]; For each pi v ?",
        "{pi l 1 l 0 +1 , pi l 2 (l 1 +1) , .",
        ".",
        ".",
        ", pi l a (l a?1 +1) } do F := F ?",
        "PermForest(pi v ); F := F ?",
        "{[[i, j, I j i , O j i ]]}; Return F ; end; Figure 5: Pseudo-code of permutation-forest factorization algorithm.",
        "Function a(pi) returns the arity of pi.",
        "Function RankListOf(r 1 , .",
        ".",
        ".",
        ", r m ) returns the list of rank positions (i.e., a permutation) of sub-permutations r 1 , .",
        ".",
        ".",
        ", r m after sorting them smallest first.",
        "The top-level call to this algorithm uses pi, i = 0, j = n and F = ?.",
        "Our measure (PEFscore) uses a function opScore(p) which assigns a score to a given oper-ator, which can be instantiated to any of the existing scoring measures listed in Section 2, but in this case we opted for a very simple function which gives score 1 to monotone permutation and score 0 to any other permutation.",
        "Given an inference l ?",
        "I j i where l = [l 1 , .",
        ".",
        ".",
        ", l a?1 ], we will use the notation l x to refer to split point l x in l where 1 ?",
        "x ?",
        "(a ?",
        "1), with the convenient boundary assumption that l 0 = i and l a = j.",
        "141 PEFscore(pi) = ?",
        "node (0, n, PEF (pi)) ?",
        "node (i, j,F) = ?",
        "?",
        "?",
        "?",
        "?",
        "?",
        "?",
        "?",
        "?",
        "?",
        "?",
        "?",
        "?",
        "?",
        "?",
        "if (I j i == ?)",
        "then 1 else if (a(pi j i+1 ) = j ?",
        "i) then opScore(O j i ) else ?",
        "?",
        "opScore(O j i ) + (1?",
        "?)?",
        "?",
        "l?I j i ?",
        "inf (l,F ,a(pi j i+1 )) |I j i | ?",
        "??",
        "?",
        "Avg.",
        "inference score over I j i ?",
        "inf (l,F , a) = ?",
        "a x=1 ?",
        "[l x ?l x?1 >1]??",
        "node (l (x?1) ,l x ,F) ?",
        "a x=1 ?",
        "[l x ?l (x?1) >1] ?",
        "??",
        "?",
        "Avg.",
        "score for non-terminal children opScore(p) = { if (p == ?1, 2?)",
        "then 1 else 0 Figure 6: The PEF Score The PEF-score, PEFscore(pi) in Figure 6, computes a score for the single root node [[0, n, I n 0 , O n 0 ]]) in the permutation forest.",
        "This score is the average inference score ?",
        "inf over all inferences of this node.",
        "The score of an inference ?",
        "inf interpolates (?)",
        "between the opScore of the operator in the current span and (1?",
        "?)",
        "the scores of each child node.",
        "The interpolation parameter ?",
        "can be tuned on a development set.",
        "The PET-score (single PET) is a simplification of the PEF-score where the summation over all inferences of a node ?",
        "l?I j i in ?",
        "node is replaced by ?Select a canonical l ?",
        "I j i ?.",
        "4 Experimental setting Data The data that was used for experiments are human rankings of translations from WMT13 (Bo- jar et al., 2013).",
        "The data covers 10 language pairs with a diverse set of systems used for translation.",
        "Each human evaluator was presented with 5 different translations, source sentence and a reference translation and asked to rank system translations by their quality (ties were allowed).",
        "3 Meta-evaluation The standard way for doing meta-evaluation on the sentence level is with Kendall's tau correlation coefficient (Callison- Burch et al., 2012) computed on the number of times an evaluation metric and a human evaluator agree (and disagree) on the rankings of pairs of 3 We would like to extend our work also to English-Japanese but we do not have access to such data at the moment.",
        "In any case, the WMT13 data is the largest publicly available data of this kind.",
        "translations.",
        "We extract pairs of translations from human evaluated data and compute their scores with all metrics.",
        "If the ranking assigned by a metric is the same as the ranking assigned by a human evaluator then that pair is considered concor-dant, otherwise it is a discordant pair.",
        "All pairs which have the same score by the metric or are judged as ties by human evaluators are not used in meta-evaluation.",
        "The formula that was used for computing Kendall's tau correlation coefficient is shown in Equation 1.",
        "Note that the formula for Kendall tau rank correlation coefficient that is used in meta-evaluation is different from the Kendall tau similarity function used for evaluating permutations.",
        "The values that it returns are in the range [?1, 1], where ?1 means that order is always opposite from the human judgment while the value 1 means that metric ranks the system translations in the same way as humans do.",
        "?",
        "= #concordant pairs?#discordant pairs #concordant pairs+#discordant pairs (1) Evaluating reordering Since system translations do not differ only in the word order but also in lexical choice, we follow Birch and Osborne (2010) and interpolate the score given by each reordering metric with the same lexical score.",
        "For lexical scoring we use unigram BLEU.",
        "The parameter that balances the weights for these two metrics ?",
        "is chosen to be 0.5 so it would not underestimate the lexical differences between translations (?",
        "0.5) but also would not turn the whole metric into unigram BLEU (?",
        "0.5).",
        "The equation 142 for this interpolation is shown in Equation 2.",
        "4 FullMetric(ref, sys) = ?",
        "lexical(ref, sys) + (1?",
        "?)?",
        "bp(|ref |, |pi|)?",
        "ordering(pi) (2) Where pi(ref, sys) is the permutation representing the word alignment from sys to ref .",
        "The effect of ?",
        "on the German-English evaluation is visible on Figure 7.",
        "The PET and PEF measures have an extra parameter ?",
        "that gives importance to the long distance errors that also needs to be tuned.",
        "On Figure 8 we can see the effect of ?",
        "on German-English for ?",
        "= 0.5.",
        "For all language pairs for ?",
        "= 0.6 both PETs and PEFs get good results so we picked that as value for ?",
        "in our experiments.",
        "Figure 7: Effect of ?",
        "on German-English evaluation for ?",
        "= 0.6 Choice of word alignments The issue we did not discuss so far is how to find a permutation from system and reference translations.",
        "One way is to first get alignments between the source sentence and the system translation (from a decoder or by automatically aligning sentences), and also alignments between the source sentence and the reference translation (manually or automatically aligned).",
        "Subsequently we must make those alignments 1-to-1 and merge them into a permutation.",
        "That is the approach that was followed in previous work (Birch and Osborne, 2011; Talbot et al., 4 Note that for reordering evaluation it does not make sense to tune ?",
        "because that would blur the individual contributions of reordering and adequacy during meta evaluation, which is confirmed by Figure 7 showing that ?",
        "0.5 leads to similar performance for all metrics.",
        "Figure 8: Effect of ?",
        "on German-English evaluation for ?",
        "= 0.5 2011).",
        "Alternatively, we may align system and reference translations directly.",
        "One of the simplest ways to do that is by finding exact matches between words and bigrams between system and reference translation as done in (Isozaki et al., 2010).",
        "The way we align system and reference translations is by using the aligner supplied with METEOR (Denkowski and Lavie, 2011) for finding 1-to-1 alignments which are later converted to a permutation.",
        "The advantage of this method is that it can do non-exact matching by stemming or using additional sources for semantic similarity such as WordNets and paraphrase tables.",
        "Since we will not have a perfect permutation as input, because many words in the reference or system translations might not be aligned, we introduce a brevity penalty (bp(?, ?)",
        "in Equation 2) for the ordering component as in (Isozaki et al., 2010).",
        "The brevity penalty is the same as in BLEU with the small difference that instead of taking the length of system and reference translation as its parameters, it takes the length of the system permutation and the length of the reference.",
        "5 Empirical results The results are shown in Table 1 and Table 2.",
        "These scores could be much higher if we used some more sophisticated measure than unigram BLEU for the lexical part (for example recall is very useful in evaluation of the system translations (Lavie et al., 2004)).",
        "However, this is not the issue here since our goal is merely to compare different ways to evaluate word order.",
        "All metrics that we tested have the same lexical component, get the same permutation as their input and have the same value for ?.",
        "143 E n g l i s h C z e c h E n g l i s h S p a n i s h E n g l i s h G e r m a n E n g l i s h R u s s i a n E n g l i s h F r e n c h Kendall 0.16 0.170 0.183 0.193 0.218 Spearman 0.157 0.170 0.181 0.192 0.215 Hamming 0.150 0.163 0.168 0.187 0.196 FuzzyScore 0.155 0.166 0.178 0.189 0.215 Ulam 0.159 0.170 0.181 0.189 0.221 PEFs 0.156 0.173 0.185 0.196 0.219 PETs 0.157 0.165 0.182 0.195 0.216 Table 1: Sentence level Kendall tau scores for translation out of English with ?",
        "= 0.5 and ?",
        "= 0.6 C z e c h E n g l i s h S p a n i s h E n g l i s h G e r m a n E n g l i s h R u s s i a n E n g l i s h F r e n c h E n g l i s h Kendall 0.196 0.265 0.235 0.173 0.223 Spearman 0.199 0.265 0.236 0.173 0.222 Hamming 0.172 0.239 0.215 0.157 0.206 FuzzyScore 0.184 0.263 0.228 0.169 0.216 Ulam 0.188 0.264 0.232 0.171 0.221 PEFs 0.201 0.265 0.237 0.181 0.228 PETs 0.200 0.264 0.234 0.174 0.221 Table 2: Sentence level Kendall tau scores for translation into English with ?",
        "= 0.5 and ?",
        "= 0.6 5.1 Does hierarchical structure improve evaluation?",
        "The results in Tables 1, 2 and 3 suggest that the PEFscore which uses hierarchy over permutations outperforms the string based permutation metrics in the majority of the language pairs.",
        "The main exception is the English-Czech language pair in which both PETs and PEFs based metric do not give good results compared to some other metrics.",
        "For discussion about English-Czech look at the section 6.1.",
        "5.2 Do PEFs help over one canonical PET?",
        "From Figures 9 and 10 it is clear that using all permutation trees instead of only canonical ones makes the metric more stable in all language pairs.",
        "Not only that it makes results more stable but it metric avg rank avg Kendall PEFs 1.6 0.2041 Kendall 2.65 0.2016 Spearman 3.4 0.201 PETs 3.55 0.2008 Ulam 4 0.1996 FuzzyScore 5.8 0.1963 Hamming 7 0.1853 Table 3: Average ranks and average Kendall scores for each tested metrics over all language pairs Figure 9: Plot of scaled Kendall tau correlation for translation from English also improves them in all cases except in English-Czech where both PETs and PEFs perform badly.",
        "The main reason why PEFs outperform PETs is that they encode all possible phrase segmentations of monotone and inverted sub-permutations.",
        "By giving the score that considers all segmentations, PEFs also include the right segmentation (the one perceived by human evaluators as the right seg-mentation), while PETs get the right segmentation only if the right segmentation is the canonical one.",
        "5.3 Is improvement consistent over language pairs?",
        "Table 3 shows average rank (metric's position after sorting all metrics by their correlation for each language pair) and average Kendall tau correlation coefficient over the ten language pairs.",
        "The table shows clearly that the PEFs metric outperforms all other metrics.",
        "To make it more visible how metrics perform on the different language pairs, Figures 9 and 10 show Kendall tau correlation coefficient scaled between the best scoring metric for the given language (in most cases PEFs) and 144 Figure 10: Plot of scaled Kendall tau correlation for translation into English the worst scoring metric (in all cases Hamming score).",
        "We can see that, except in English-Czech, PEFs are consistently the best or second best (only in English-French) metric in all language pairs.",
        "PETs are not stable and do not give equally good results in all language pairs.",
        "Hamming distance is without exception the worst metric for evaluation since it is very strict about positioning of the words (it does not take relative ordering between words into account).",
        "Kendall tau is the only string based metric that gives relatively good scores in all language pairs and in one (English-Czech) it is the best scoring one.",
        "6 Further experiments and analysis So far we have shown that PEFs outperform the existing metrics over the majority of language pairs.",
        "There are two pending issues to discuss.",
        "Why is English-Czech seemingly so difficult?",
        "And does preferring inversion over non-binary branching correlate better with human judgement.",
        "6.1 The results on English-Czech The English-Czech language pair turned out to be the hardest one to evaluate for all metrics.",
        "All metrics that were used in the meta-evaluation that we conducted give much lower Kendall tau correlation coefficient compared to the other language pairs.",
        "The experiments conducted by other researchers on the same dataset (Mach?a?cek and Bojar, 2013), using full evaluation metrics, also get far lower Kendall tau correlation coefficient for English-Czech than for other language pairs.",
        "In the description of WMT13 data that we used (Bojar et al., 2013), it is shown that annotator-agreement for English-Czech is a few times lower than for other languages.",
        "English-Russian, which is linguistically similar to English-Czech, does not show low numbers in these categories, and is one of the language pairs where our metrics perform the best.",
        "The alignment ratio is equally high between English-Czech and English-Russian (but that does not rule out the possibility that the alignments are of different quality).",
        "One seemingly unlikely explanation is that English-Czech might be a harder task in general, and might require a more sophisticated measure.",
        "However, the more plausible explanation is that the WMT13 data for English-Czech is not of the same quality as other language pairs.",
        "It could be that data filtering, for example by taking only judgments for which many evaluators agree, could give more trustworthy results.",
        "6.2 Is inversion preferred over non-binary branching?",
        "Since our original version of the scoring function for PETs and PEFs on the operator level does not discriminate between kinds of non-monotone operators (all non-monotone get zero as a score) we also tested whether discriminating between inversion (binary) and non-binary operators make any difference.",
        "E n g l i s h C z e c h E n g l i s h S p a n i s h E n g l i s h G e r m a n E n g l i s h R u s s i a n E n g l i s h F r e n c h PEFs ?",
        "= 0.0 0.156 0.173 0.185 0.196 0.219 PEFs ?",
        "= 0.5 0.157 0.175 0.183 0.195 0.219 PETs ?",
        "= 0.0 0.157 0.165 0.182 0.195 0.216 PETs ?",
        "= 0.5 0.158 0.165 0.183 0.195 0.217 Table 4: Sentence level Kendall tau score for translation out of English different ?",
        "with ?",
        "= 0.5 and ?",
        "= 0.6 Intuitively, we might expect that inverted binary operators are preferred by human evaluators over non-binary ones.",
        "So instead of assigning zero as a score to inverted nodes we give them 0.5, while for non-binary nodes we remain with zero.",
        "The experiments with the inverted operator scored with 0.5 (i.e., ?",
        "= 0.5) are shown in Tables 4 and 5.",
        "The results show that there is no clear improvement by distinguishing between the two kinds of 145 C z e c h E n g l i s h S p a n i s h E n g l i s h G e r m a n E n g l i s h R u s s i a n E n g l i s h F r e n c h E n g l i s h PEFs ?",
        "= 0.0 0.201 0.265 0.237 0.181 0.228 PEFs ?",
        "= 0.5 0.201 0.264 0.235 0.179 0.227 PETs ?",
        "= 0.0 0.200 0.264 0.234 0.174 0.221 PETs ?",
        "= 0.5 0.202 0.263 0.235 0.176 0.224 Table 5: Sentence level Kendall tau score for translation into English for different ?",
        "with ?",
        "= 0.5 and ?",
        "= 0.6 non-monotone operators on the nodes.",
        "7 Conclusions Representing order differences as compact permutation forests provides a good basis for developing evaluation measures of word order differences.",
        "These hierarchical representations of permutations bring together two crucial elements (1) grouping words into blocks, and (2) factorizing reordering phenomena recursively over these groupings.",
        "Earlier work on MT evaluation metrics has often stressed the importance of the first ingredient (grouping into blocks) but employed it merely in a flat (non-recursive) fashion.",
        "In this work we presented novel metrics based on permutation trees and forests (the PETscore and PEFscore) where the second ingredient (factorizing reordering phenomena recursively) plays a major role.",
        "Permutation forests compactly represent all possible block groupings for a given permutation, whereas permutation trees select a single canonical grouping.",
        "Our experiments with WMT13 data show that our PEFscore metric outperforms the existing string-based metrics on the large majority of language pairs, and in the minority of cases where it is not ranked first, it ranks high.",
        "Crucially, the PEFscore is by far the most stable reordering score over ten language pairs, and works well also for language pairs with long range reordering phenomena (English-German, German-English, English-Russian and Russian-English).",
        "Acknowledgments This work is supported by STW grant nr.",
        "12271 and NWO VICI grant nr.",
        "277-89-002.",
        "We thank TAUS and the other DatAptor project User Board members.",
        "We also thank Ivan Titov for helpful comments on the ideas presented in this paper.",
        "References"
      ]
    }
  ]
}
