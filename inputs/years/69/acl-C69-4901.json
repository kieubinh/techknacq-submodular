{
  "info": {
    "authors": [
      "David Sankofl"
    ],
    "book": "International Conference on Computational Linguistics",
    "id": "acl-C69-4901",
    "title": "Simulation of Word-Meaning Stochastic Processes",
    "url": "https://aclweb.org/anthology/C69-4901",
    "year": 1969
  },
  "references": [],
  "sections": [
    {
      "heading": "PART ONE - LELICOSTATISTICS",
      "text": [
        "The Swadesh theory of lexicostatistics (1950, 1952, 1955) provided the first quantitative comparison of related languages based on a well-defined model of language change.",
        "The stochastic nature of this model was poorly understood by linguists, in the main, and many have rejected the theory in the course of a protracted and confused controversy.",
        "Meanwhile field linguists, especially those working with language groups of unknown history, have accepted lexicostatistics and have found it to be an efficient, valid and reliable technique."
      ]
    },
    {
      "heading": "The Swadesh theory",
      "text": [
        "There are serious oversimplifications of reality implicit in lexicostatistics, and it is these, rather than the stochastic aspects, which are limitations of the theory.",
        "Swadesh hypothesized, in effect, that",
        "(i) it is possible to discover a set of basic, universal and non-cultural meanings, and he constructed a list of about 200 such meanings; (ii) in every natural language, at a given tine, there is a unique lexical representation (word) corresponding to each of these meanings; but (iii) over short time intervals, the word representing any meaning runs a small but constant risk of being replaced by a different (non-cognate) word; and (iv) the replacement, or non-replacement, of the lexical",
        "representation of a meaning occurs independently of that of any other meaning, and independently over different periods of time.",
        "To formalize (i) and (ii), we must postulate the existence, for each natural language, at all points t in time, of a lexicon, represented by a finite abstract set Lt. A well-defined equivalence relation corresponding to covnation partitions the elements of Lt (T a real interval) into equivalence teT classes.",
        "If kELs, 1ELt (t,sE T) are cognate, we write 45(k,l) = 1.",
        "Otherwise S (k,1 ) = 0.",
        "Further, we must postulate the existence of a finite abstract set M (corresponding to the universal set of meaning`), and a procedure for defining, for any t, and any Lt, a unique map from M into Lt.",
        "This map, written M t--\"-o-Lt, specifies that for each mEM there is a 1E.",
        "Lt such that m---.1.•1 (1 means m).",
        "Hypotheses (iii) and (iv) imply that the changes over time in the image of the map M – Lo-Lt have a certain stochastic aspect.",
        "This can be modelled by the probability statement P[ S(k,l) =13 = 1 A(t - s) + h , >► a universal constant, tN.s, and h/t-s -O.",
        "0 as t-.s; and two independence conditions; let mi for i = 1,2,...,IMI ((4 the number of elements in M),",
        "si m ti for (si,ti), i = 1,2,...,N, a finite number of disjoint intervals, then g(hilji)9 S.(h29j2)9 .",
        "• • , g(hN,jN) are independent random variables.",
        "This model has a number of immediate properties which form the central thesis of the Swadesh theory.",
        "These are presented here as Theorems 1, 2 and 3.",
        "For simplicity we will assume that at any time t, at most one word in Ltcan belong to a cognation equivalence class.",
        "This simplifies notation and proofs, although the assumption may be relaxed without substantively affecting this development.",
        "One further type of assumption is required to ensure a degree of randomness in the choice of replacing word during lexical replacement.",
        "To prove Theorem 1 as stated below, we require",
        "Let N(t-s) be the number of changes (with respect to the cognation relation) of the mapping m-Lto-1 in the interval (s,t).",
        "Then N(t-s) = 0 is just the event that a Poisson process remains at zero on the interval (s,t) (see, e.g. Parzen, 1960, p.252), and",
        "which are independent dauditer languages of the same parent language (which are said to split attime s) if",
        "By transitivity of the equivalence relation represented by S , the first term on the right is",
        "Since we have fixed m-24- k",
        "The summation contains at most max (1 Ltj, I Ltl ) terms which are not annihilated by S (1%1\") and so the total is",
        "This completes the proof of the first statement of the theorem.",
        "The proof of the second parallels the analogous result in the previous theorem.",
        "In natural languages, ILtI is several thousands and 1 tLtj is negligible compared to the exponential term, except for very high values of t (where the theory has little applicability).",
        "In the next theorem, the results of Theorems 1 and 2 are utilized, neglecting the error terms of the form O(ILt!",
        ").",
        "Under certain, more specific restrictions on"
      ]
    },
    {
      "heading": "s 1",
      "text": [
        ", Brainerd (n. d.) solved for the exact form of the error term attached to the exponential laws (here formulated as Theorems 1 and 2).",
        "Theorem l Insofar as we may approximate the results of Theorems 1 and 2"
      ]
    },
    {
      "heading": "1}11-4 EE S(k,i) e-X(t-s)",
      "text": [
        "and",
        "is the maximum likelihood estimator (BLE) of A in the first formula above, and if A is known, - log 1141-1 is the NLE of t-s.",
        "In the case of two independent daughter languages (Thm.",
        "2),",
        "It suffices to find the MLE of A, the other cases being analogous.",
        "AT e - Consider binomial trials with parameter p = S(k,l) = 1 is the equivalent of a success in one such trial.",
        "= r is the equivalent of r successes in IN trials.",
        "miX The likelihood function of A in such a case is",
        "d log L(#) = -Tr Te 1T 1-e--Ar d At the MU, , this derivative should be zero,",
        "as follows.",
        "He first selected his list of meanings which he considered basic to all languages.",
        "He then compared Old English with Modern English (t-s 74:1000 years), i.e. he compared the words in each language corresponding to the basic meanings.",
        "The etymology of words in these languages being fairly well known, he was able to decide when a pair of words corresponding to the same meaning were cognate (i.e. one was historically derived from the other, or both were derived from a common root, by a series of phonological alterations, each.of which affected only a part of the word in question).",
        "This immediately led to nf, 2X 10-4.",
        "Using the estimate which he obtained as a constant, he dated the relative times of separation or \"split\" of various Salish (western North•American Indian) common parent with the estimator t-s .",
        "After was considered to be a universal constant, absolute dates of split, and t-s could date a collection of texts from a dead language."
      ]
    },
    {
      "heading": "Criticisms of the theory",
      "text": [
        "Criticisms of lexicostatistics fall into two classes.",
        "In the first class are protests based on or resulting from the stochastic nature of the model and/or the stochastic nature of the phenomena of lexical loss and replacement.",
        "The second class of criticisms refer to particular assumptions in the model , and I will discuss these in the next section.",
        "Bergsland and Vogt (1962) presented four cases where ,■/ t-s (or t-s ) are not accurate (three too low and one too high), and rejected the Swadesh theory on this basis.",
        "In statistical terms, the authors constructed a sample consisting entirely of outliers and rejected an hypothesis without even considering the distribution of the test statistic.",
        "Fodor (1962) took the same approach to \"disprove\" lexicostatistics.",
        "Chretien (1962) calculated and published pages of ordinary binomial functions to prove, in essence, that t-s is a random variable and hence not \"an acceptable mathematical formulation\" of the Swadesh theory.",
        "This basic misunderstanding of the nature of statistical estimation is characteristic not only of critics of lexicostatistics, but also of many of its practitioners.",
        "A more important criticism has been expounded, at great length, by Fodor (1965) and, more clearly, by Teeter (1963).",
        "Quoting from the latter; \"Lexical similarities and dissimilarities do not coma about in any one simple way, and any mechanical method of counting lexical similarities cannot separate those due to chance, universals, diffusion, and common origin.",
        "Lexical change is the result of many factors, and all are scrambled together in the final result.\"",
        "(p.641) This diversity of causes of lexical and semantic change has received detailed study by linguists and semanticists; see, for example, Bloomfield (1933) P.392 ff., Ullman (1957) p.183 ff.",
        "Quoting from Lees (1953): \" The reasons for morpheme decay, i.e. for changes in•vocabulary, have been classified by many authors; they include .such processes as word tabu, phonemic confusion of etymologically distinct items close in meaning, change in material culture with loss of obsolete terms, rise of witty terms or slang, adoption of prestige forms from a superstratum language, and various gradual semantic shifts, such as specialization, generalization, and peroration.\"",
        "(p.114) And it is just this diversity and the difficulty of \"unscrambling\" which, contrary to Teeter and to Fodor, justifies a stochastic model incorporating retention parameters.",
        "Consider, for comparison, the problem of constructing a model for the behaviour of gases.",
        "We have an enclosed volume containing a large number of particles of finite dimension, undergoing rapid motion.",
        "We can assume everything is perfectly deterministic, all the particles obeying Newton's three laws of motion, and all collisions perfectly elastic.",
        "The position of any particle at any time can, theoretically, be calculated precisely if we know the initial state of the system and the time elapsed.",
        "Practically speaking, of course, this would be impossibly tedious, boring and pointless, there being so many particles, any two of which may collide, plus the walls, plus gravitational or electrical charge attractions and repulsions to consider.",
        "What is possible, interesting, and of great value (witness the fields of kinetic theory and statistical mechanics, dating from the work of men such as Maxwell, Holtzman, and Einstein) is to consider the nature of each particle as a random process involving appropriate parameters and to consider the statistical behaviour of the model thus constructed.",
        "It is complexity and great difficulty of prediction which make a statistical model workable.",
        "In the same way, Fodor and others have inadvertently justified the proposition that some sort of stochastic process might be an appropriate model for lexical change phenomena.",
        "The question remains, what process?",
        "The Swadesh theory provides at least a first approximation to the correct answer."
      ]
    },
    {
      "heading": "Problems with Swadosh's model",
      "text": [
        "Before discussing details of the model, it is appropriate to present the results of an early (1953) lexicostatistic investigation of R. Lees.",
        "He chose thirteen language pairs, each pair consisting of an historio language and a modern descendant.",
        "The",
        "particular choice of pairs presumably stemmed from wrailability and not from any sampling technique.",
        "He translated each word in Swadesh's 215-word list (1950) into the 26 languages.",
        "After counting the number, r, of cognates between each language pair, he used (in effect), - log (r/IMI) -t-s where Ik4 215 according to the number of indeterminate cognations and uncertainties of translation.",
        "To get an estimate of a \"universal\" he combined the individual estimates in",
        "which should be approximately the square of a standard normal random variable, if the assumptions of the theory are true.",
        "Since an estimate of A is used in calculating p, the sum of the squared variables should be 1(1-distributed.",
        "But As1=29.5, significant at the 1% level, suggesting rejection of the theory.",
        "Lees, however, suggested four reasons for not rejecting on the basis of the )2 test; the large values for IMIand r, uncertainty in t, possible inappropriateness of the )(2 test, and the error in estimating A.",
        "The first and third of these are not valid",
        "statistically, and the fourth is a source of very little of the excess x2.",
        "The variability in the time parameter can be incorporated into the ';2 calculation.",
        "This only reduces x2 to 25.9 - 27.5 depending on the variation assumed in t. Lees' results, then, indicate strongly that the theory is an inadequate model for the phenomena.",
        "We turn now to the second class of criticisms of the Swadesh model, those that involve objections, evaluations or improvements related to the generalizations and simplification of reality inherent in lexicostatistio theory.",
        "The listing of assumptions earlier in this chapter will serve as a framework for classifying this latter class of criticisms.",
        "(i) There are no universal sets of meanings, it being difficult to specify most meanings without recourse to particular natural languages.",
        "No list of meanings yet devised is completely satisfactory for sufficiently diverse languages; Hoijer (1956), O'Grady (1960), Cohen (1964), Levin (1964), Trager (1966).",
        "(ii) The existence of synonymy proves the non-uniqueness of the meaning map M-4.",
        "L; and no known methods of eliciting words for given meanings are completely and reliably reproducible, from speaker to speaker or even from occasion to occasion for a single speaker; Gudschinsky (1960).",
        "The existence of general and specific terms for a single entity provides a further complication.",
        "(iii) If the parameter A can be said to exist at all, it is constant neither from language to language; Bergsland and Vogt (1962),"
      ]
    },
    {
      "heading": "15",
      "text": [
        "Fodor (1962), from meaning to meaning; Swadesh (1955), Andreyev (1962), Ellegard (1962), and especially Dyen (1964), van der Xerwe (1966), Dyen, James and Cole (1967), nor even from time interval to time interval for the same meaning; Swadesh (1962).",
        "Judgements about cognation are unreliable, especially with respect to languages which are separated by large t-s and whose history is mostly unknown; Fairbanks (1955), Teeter (1963), Lunt (1964).",
        "An analysis of this latter problem is beyond the scope of this stucky.",
        "(iv) Lexical loss and replacement do not occur independently for different meanings, neither are current and future trends entirely independent of what has happened in the past, especially in languages which have possessed an orthography for some time.",
        "This has been noted especially in connection with the independence assumption of Theorem 2, as in the interval immediately after a split we might expect parallel (to some extent, at least) evolution of the two daughter languages; Lees (1953), Hymes (1960), Teeter (1963).",
        "Also in this connection, independence of evolution does not strictly hold where borrowings, loan-translations and imitations of other types are frequent occurrences."
      ]
    },
    {
      "heading": "Towards a new theory",
      "text": [
        "A number of authors have attempted to deal with one or more of these problems.",
        "Swadesh (1952) discarded more than half of the meanings in his original list.",
        "For choosing among synonyms, Gudschinsky (1956) proposed a random selection, Hymes (1960) suggested a procedure which would select cognate forms whenever they were 16 available, Satterthwaite (1960) and Dyen (1960) pointed out that it would be more reasonable to choose the word which is most frequently used for the meaning in question.",
        "Little could be done about the central postulate or result of the theory; that >I is a constant, until the work of Dyen became well known.",
        "Dyen, on the basis of comparisons of a large number of Malayopolynesian languages was able to segregate meanings into groups on the basis of their individual ?I ts.",
        "A discussion of the ) mathematical implications of this ( p=e-Ai(t-s for meaning mi leads to D(rfi /41) =e(t-s) ) was published by van der Merwe (1966).",
        "= Meanwhile, Dyeni (1964) had statistically demonstrated that meanings with high A in the Malayopolynesian languages tend to have high in the Indoeuropean languages and 35122 versa This was the first new type of lexicostatistic result since the work of Lees.",
        "Later (1967) this work was refined so that Dyen al.",
        "al were able to estimate a separate A for each meaning on a 196-word list of the Swadesh type.",
        "On the problem of independence, Swadesh pointed out that interaotion between languages because of contact would bias estimates of t-s downward.",
        "Hattori (1953) suggested and Hymes (1960) discussed the formula Ariimp sw4.41(t-s) as a way of taking into account parallel evolution and the effect of those meanings with lower than the rest of the list.",
        "The latter effect is, however, properly described by using a sum of exponentials and, for the former, it is unreasonable to expect a constant 17 multiplier (1.4) to express the dependence of two languages over all time.",
        "It is clear that the multiplier of -A(t-s) should be near zero when t is close to s and to approach 2 as t gets very large.",
        "This was noted by Gleason (1960) who rightly suggested that for all sufficiently large t, estimates of t-s could be corrected by adding a small positive constant.",
        "One further suggestion that has been made by many authors and implemented by some, e.g. Hirsch (1954), Hattori (1957), is to attempt to construct a larger set M to provide a better (i.e. lower variance) estimate of time intervals.",
        "The primary purpose of this paper will be to develop a formal theory of word-meaning relationship, applicable to lexical and semantic change, which incorporates most of the criticisms levelled against the Swadesh theory.",
        "Relatiopshin to linguistic theories This theory is unique in that it provides a link between two previously unrelated linguistic theories, that of generative grammar, and the conventional descriptive semantics.",
        "Elsewhere (1969) we show how stochastic models, like our theory of word meaning behaviour, and Labov's (1967,1968) frequency approach to optional grammatical rules, can be derived by imposing probabilistic structure on formal grammars.",
        "On the other hand, the major phenomena and problems of descriptive and historical semantics can be elegantly formalized in terms of this same model."
      ]
    },
    {
      "heading": "PART TWO - WORD-MEANING PROCESSES",
      "text": [
        "The problems of the Swadesh theory stem from its assumptions about the nature of meaning, and its oversimplified mechanism of lexical replacement.",
        "I propose a model of word-meaning relationship in which lexical replacement is a consequence of a more basic stochastic phenomenon - fluctuations in probabilities of word usage.",
        "The only aspect of a \"meaning\" which is relevant to this model is its representability by one or more words.",
        "I make no assumption as to the psychological or cultural nature of meaning.",
        "In fact, Thm.",
        "4 below shows that the set of meanings as defined here can be considered a purely analytical construct.",
        "This set is completely determined by comparing word usage probabilities in certain contexts.",
        "For a natural language there is the possibility of constructing the set of meanings by empirical means (from word usage frequency data).",
        "Whether the entities I refer to as meanings correspond well to aspects of the intuitive (or the semanticists') concept of meaning depends on whether they have important properties in common and whether they behave similarly over time.",
        "It is my thesis that these entities model the processes of historical semantics at least as closely as, say, the \"meanings\" of Osgood et al. (1957) model psychological aspects of meaning or the \"meanings\" of Katz and Postal (1964) model the grammatical function of meaning."
      ]
    },
    {
      "heading": "The word-meaning relationship",
      "text": [
        "The mapping type of relationship in the Swadesh theory can be represented by a bipartite graph as in Fig.1 .",
        "The first generalization to be made is to allow a many-to-one (in both directions) relation, as in Fig. 2.",
        "Fig.",
        "Unrestricted word-meaning relationship.",
        ".",
        "s. .• • ' .. • s.. • I .",
        "• S. m IMI 1 ILI The next important refinement of the model is the introduction of probability distributions on words and meanings.",
        "The frequency with which a word takes on a meaning in M has, as cited in PART 1, been recognized as important to lexicostatistics.",
        "Dyen's (1960) essay contains a clear description of how fluctuations",
        "in these frequencies underlie the phenomena of lexical replacement.",
        "In what follows, L can be understood as in PART 1, but M is completely reinterpreted.",
        "Definition Let L and M be finite sets.",
        "Let p(•,•) be a bivariate probability distribution on MXL.",
        "Let Sm =fli:Lip(m,l) > 01 If Sm for all mGM, and if for distinct m,n6M) Sm A Sn , then M is a set of peanines, on L, with respect to the distribution p, and each non-zero p(m,l) represents a word-meaning relationship between 1 and m. p(m,l) should be understood as the probability that the word 1 will be used, and that meaning m will be intended (when no information is given about the context).",
        "The definition incorporates two restrictions on abstract meaninps, neither of which is overly restrictive when considered as properties of meanings in the intuitive sense.",
        "First, if a meaning is expressible by some word or other in the lexicon, that word must have a non-zero probability of expressing it (in some context which has a non-zero probability of occurring).",
        "Second, if two meanings are to be distinct, on our level of analysis, at least one of them must be expressible by at least one word which the other is not.",
        "Fig.",
        "3 illustrates these conditions.",
        "The latter principle, lexical distinguishability of meanings, might seem to place too much emphasis on marginal or threshold word-meaning relationships (those with very low p(.,.",
        "))."
      ]
    },
    {
      "heading": "Fig.3 Part of word-meaning system. A line joins m and 1",
      "text": [
        "iff p(m,1).",
        "), 0.",
        "Such objections will be seen to have little importance, however, after Theorem 9 below, where M is embedded in a metric space.",
        "Here all meanings which do not differ greatly in their usage probabilities will cluster together in the metric space, and any comparisons between meanings will be in terms of the metric.",
        "Assuming lexical distinguishability facilitates the particular line of development followed here, but relaxing it (e.g. in favour of a more quantitative distinction between meanings, or in favour of a definition of meaning grouping closely related lexically distinguished entities) is not likely to radically affect the behaviour of meanings in the metrio space.",
        "An important consequence of the definition of a set of meanings is",
        "•",
        "Theorem 4 Let 4(L) be the set of subsets of L, and let M be a set of meanings on L with respect to p. If Sm =fie Lip(m,l) > 01, then Sm is a one-one map from M onto a subset of 9(L).",
        "but this is just the condition of lexical distinguishability in the definition.",
        "Theorem 4 tells us that, for analytical or computational purposes, we can treat meanings as sets of words.",
        "Two meanings are distinguished by the words they do not share and are related by those they have in common.",
        "Note that the case p(m,l) = 0 can arise in two ways.",
        "Either p(m,l) = 0, for all 1, in which case Sm = and m is not a meaning, or m is a meaning but 1 k Sm.",
        "From now on, no distinction will be drawn between the meaning m and the set Sm, and tl,e latter notation will be discarded.",
        "Sometimes, an entity whose status as a meaning or not is under study, will be labelled m. If m is not a meaning, p(m,l) = 0, for all 1; mlq.",
        "M;",
        "etc., and every attempt will be made to keep this usage unambiguous.",
        "Interpretation of the marginal distributions With the usage probability interpretation of p(.,•),",
        "is the overall probability that 1 is used.",
        "The probability function g(1) underlies word-frequency distributions, e.g. those of Zipf (1945), Josselson (1953), and Juilland (1965a,19656).",
        "is the overall probability that m is used.",
        "This is related (at least conceptually) to the \"semantic frequency lists\" of Eaton (1940).",
        "Since these are probability distribution functions,",
        "and, of course, p(m,1);: 0 Recapitulating, a word-meaning relationship exists between m and 1, or a line is drawn between m and 1 on a word-meaning graph like Fig.2 or 3 , iff 1 can take on meaning m, which occurs iff p(m,1):› 0.",
        "(I.e., we require that if a word can take on a meaning, there is a non-zero probability that it will do so.)",
        "The statement f(m) = 0 is equivalent to saying that m is not lexically representable by elements of L, and mk M."
      ]
    },
    {
      "heading": "Precision of sneech",
      "text": [
        "In constructing a model involving the grouping of words and the distinction between meanings, provision should be made for some degree of variation to correspond to the variation which occurs in reality, from person to person and, more especially, from situation to situation.",
        "This variation is a complex effect, but 24 a good deal of it maybe interpreted as alternation between precise and loose speech.",
        "In certain situations, and for certain topics, effective communication requires unambiguous usages, specific rather than generic terms, and other manifestations of precision which are, on the other hand, inefficient, uneconomical or just too difficult to sustain in everyday speech.",
        "This alternation may occur independently in different parts of the lexicon in a natural language, but for our model we will use a single precision parameter Or.",
        "Each value of 0C will specify a set Mai of meanings on L. In the next few sections, the probability distributions and other entities dependent on QC will be so subscripted (e.g. pm(m,1), Mo).",
        "In what manner should the system depend on 0(7 In natural languages, as a speaker becomes more precise he draws more distinctions between words and he groups two words of similar meaning less frequently (i.e. with smaller probabilities).",
        "One measurement which is sensitive to this process in the model is the average size of the meanings",
        "where ITO = ISml, the number of words connected to, representing, or simply in, a meaning.",
        "This measurement would be too crude, by itself, to serve as a precision parameter, since it does not distinguish between overall precision in the system and extreme precision in one part of the system but little precision in the rest.",
        "Instead, a condition should be placed on the system so that if C( increases, then lava, 2gEIRE'the system , this increase would coincide with an increase in the probability weight on small meanings (i.e. /m) is small) and a decrease in oe would coincide with an increase on large meanings.",
        "Such a restriction may be formalized as follows.",
        "Let 6[0,1].",
        "Let DC e(L) be any set of subsets of L, meanings or not, such that m E D, nC m m nE D Then it is required that",
        "is monotonic and non-decreasing with 0(.",
        "Another way of looking at this is in terms of the lattice of subsets of L. If we choose any points in the lattice or even draw a line right across it, the probability assigned to all sets below these points, or below the line, must increase .",
        "(or at least not decrease) as O!, the precision, increases.",
        "A simple example ion illustrate this.",
        "Let L fl1,12,133 .",
        "Fig.11, depicts the lattice of subsets of L.",
        "The example suggests the next theorem, which confirms that the precision requirement is strong enough to imply monotonicity of the average meaning size.",
        "since a(s) and b(.)",
        "are the probability distributions of the values of fmI."
      ]
    },
    {
      "heading": "Regularity conditions",
      "text": [
        "We have imposed a condition on the pm(m,l) so that the probability weight must flow down the lattice of subsets of L as C( increases.",
        "It would be desirable, from the viewpoints of model realism and analytical convenience, to have this \"flow\" behave in as continuous a manner as possible.",
        "It would be most convenient if the pjm,l) were required to be continuous functions of M , but there are good reasons to relax this somewhat.",
        "Again trying to model natural languages, it would be realistic to require that the following process may occur in the system.",
        "Suppose a meaning m'EM0 is connected to k,11,12,...,lrE L. (In our earlier notation, Sm!= [k,11,12,...,1), in our current notation m' = , po(mi,k) 0, po(mi,li)> 0, d liErd).",
        "As c( increases, the values of all the pix(M,1i) fluctuate but , remain greater than some positive value, except for pa(m,k) which gradually drops to zero at cVo.",
        "In terms of speech behaviour, the words k, 11,12,...,1r are used interchangeably (in certain",
        "contexts) to mean it when precision is low.",
        "As precision increases, 11,12,...,lr continue to be interchangeable but k is seldom usable in this sense and, at 00O3 never.",
        "It is most important in what ensues to underetand that the set m' = tk,11,12,...,lri ceases to be a moaning when the precision is 0(0,",
        "It is, however, most natural that m = be a meaning at 0(0, since the interchangeability of these words is not necessarily dependent on the behaviour of k. Hence, if any psychological interpretation is to be attached to the set of abstract meanings in our model, it must be realized that as precision changes, the abstract label attached to a psychological or cognitive entity may suddenly change as lexical representability of that entity changes.",
        "If this seems strange behaviour for a symbolic system, it should seem less so later, when the Maitre embedded in a metric space and the relative position of meanings in this space becomes more important than the letters that identify them.",
        "Returning to quantitative considerations, since m' ceases to be a meaning at and m suddenly takes over its role, it is necessary that pix(m\",11),..., p(,m°,1r) drop discontinuously to zero at M:0 and po(m,11), pot(m,lr) jump to compensate.",
        "We must, therefore, accept certain discontinuities of this sort in the model.",
        "For simplicity°s sake, we restrict 30 occurrences such as this so that only ono pa(m,l) may drop continuously to zero at any particular value of 010 (pcx(m ,k) in the example above).",
        "This is in fact a weak restriction, in that we can approximate situations where N of the pa(m,l) go to zero at am by having them do this one at a time, at elm, oto + E , + 2E , , 0(0 + (N-1)E for arbitrarily small E .",
        "An appropriate continuity-discontinuity condition may be most economically phrased as in condition (iii) in the next section.",
        "Summary of development thus far We assume that there exists a finite set L (the set of words) and for each cite [0,13 a finite set Met(a set of meanings on L) and.",
        "a bivariate probability distribution p on Mm X L such that p,m(M41) = mE14., 14EL The elements of M, are in one-one correspondence with certain non-empty subsets of L. m Sm 44 po, (m,l) 0, XilE This correspondence enables us to unambiguously identify Sm with m, and we may rewrite the above condition",
        "As 0( varies between zero and 1, the following conditions must hold: (ii) If D C e(L) such that mE D, ncM =0 n ED, then zElp,x(m,l) is monotone non-decreasing with 0f, mED lem (iii).",
        "The poi(m,l) are continuous functions of a only where 244 is fixed.",
        "244x changes at 0(0 only as a result of discontinuities occurring, for unique m, and unique k4 m, to all of",
        "Before.",
        "enunciating the continuity and discontinuity condition (iii), we described the desired behaviour of some of the functions p(.,.)",
        "at a point where the condition is relevant.",
        "We can prove that this condition implies this behaviour.",
        "Theorem 6 In the system as described above, if cCo is a point where Mot changes, then p1(m + fki,k) (as in condition (iii) above) is continuous at ao, and if it goes to zero at *Co it is the only such function.",
        "Now if any other px(n,1') goes to zero at oto, n ceases to be a meaning and Mck changes as a result.",
        "This contradicts condition (iii) unless n = m or m +{ki, in which case discontinuities are prescribed by the same condition.",
        "Existence and local behaviour The next theorem gives assurance that the conditions on the components of a word-meaning system, as developed so far, are not contradictory.",
        "The proof consists of a construction of a particular system (which is otherwise uninteresting) and is presented as Appendix 3 in Sankoff (1969).",
        "Theorem 7 Word-meanings systems exist.",
        "Specifically, it is possible to construct a word-meaning system using any finite set",
        "The regularity conditions are strong enough, however, so that aside from continuous variation in the pee(•,•, only certain types of change in.M.e are possible.",
        "Theorem 8 Suppose M4 changes at oco.",
        "Let M\" , Mf be the state of Met in small enough intervals to the left and right of oleo, respectively.",
        "Then one of A, B or C must hold.",
        "A.",
        "For a unique m, and unique 14m, as in condition (iii),",
        "imply either pot(m,l)PZ 0 or p (m + Ck],i)F 0 near *cc>, and hence have no discontinuity.",
        "In (4,e; ) and (4 sit ;4E4), Poc(m,l) and pac(m + {lc},1) \"jump\" in the same direction, hence their sum could not be continuous, (4 ef.E (4,4 ;E,E) and (6,e;d4 ) violate condition (ii).",
        "There remain only the three possibilities,",
        "N.B.",
        "right continuity instead of left continuity would be equally possible here.",
        ".0.......... .",
        ".",
        "(m + {ICI ,l) ....,>4..s.- (m,l) %,.. .......\\ (a + ki,k) \"'ON.",
        "....., Fig. 5 4; Possibility C, Tbs.",
        "8 Meanings as points in a metric space The idea of distances between meanings is not new, and there have been a number of attempts to operationalize this concept.",
        "We shall examine a very natural way of defining such a distance for the meanings in a word-meaning system in terms of the functions pei(m,1).",
        "Definition Let m e n€ M8",
        "defines a metric on MD,.",
        "a at Proof The norm ZI.1 defines a metric on probability distributions p (m,l) defines a probability distribution on L. It remains to prove that two such meMaL do not define the same distribution.",
        "But this follows from the fact that each mEMA defines a unique subset of L such that pic(m,1)).",
        "0.",
        "Remark If as, increases beyond 0( , 138(m,1) changes, d„,im,m) will have a minimum value at, = 04 and will increase for iron either side of ec In a neighbourhood of , clo(m,m) for fixed",
        "m, then, measures distance from et .",
        "This relevance of d to the parameter as well as to the meanings will become important in later sections.",
        "This follows from the continuity of the p, on such intervals and from the fact that d is a continuous function of such pm As a changes, the points in Mwmove continuously.",
        "When MoLchanges, two (at most) points experience a sudden shift in position with respect to the rest of the points.",
        "This may involve the creation or annihilation of these points.",
        "When is close to 1, there will be few words in common between two meanings, on the average, and hence the distance between them will be close to 1.",
        "When oC is close to zero, on the other hand, the reverse is true, and distances will tend toward zero.",
        "This rather succinct comparison of precise versus loose usage accords well with more intuitive notions of precision of speech.",
        "Fig.",
        "6 and Table 4 present, as illustrations, the distances in the metric spaces defined by the 3-word system described earlier in this chapter."
      ]
    },
    {
      "heading": "Diachronic word-meaning systems",
      "text": [
        "We have developed, in some detail, a synchronic (i.e. at a fixed point in time) theory of words and meanings.",
        "It remains to show what relevance this has to historical linguistics and lexicostatistics.",
        "As Ullman (1957) remarks: \"The two [semantic relationship, simple or multiple, and semantic change.]",
        "are interdependent, one being the projection of the other on a different plane.",
        "The functional analysis of meaning will entail therefore a definition of semantic change along similar lines.",
        "If a meaning is conceived as a reciprocal relation obtaining between name and sense [word and meaning) , then a semantic change will occur whenever a new name becomes attached to a sense and/or a new sense to a name.\"",
        "(p.171) and, as he points out, word-meaning phenomena at a fixed time have parallels in processes of change over time.",
        "In our particular model, changes in the system as the precision parameter changes will provide the prototype for change with time.",
        "Definition A word-meaning system history is a word-meaning system with oi40,1) replaced by teb,T) (time parameter) and with condition (ii) relaxed entirely.",
        "Condition (iii) is changed so that if k and m are given as before, and m + 4k!, is a new meaning or if m disannears starting at to, there are discontinuities in pt(m + Ckj,k) and pt(m + 1411) t pt(m,l) for one lem, but pt(m + {14,10 + pt(m + (4,1) + pt(m,l) is continuous.",
        "Although an adjustment to the construction necessary for Thm.8 could adapt the existence proof of word-meaning systems to that of word-meaning system histories, it will be simpler to leave existence to be implicit in the constructions carried out later.",
        "Suppose Mt changes at to.",
        "Let M-, Mf be as in Thm.",
        "8.",
        "Then one of A, B, C, A', B', C' holds.",
        "A, B and C were the three possibilities admitted in Thm.",
        "8.",
        "The only new restriction applies when m + kk/ appears or m disappears at to, and therefore applies to none of the three.",
        "A', B' and C' were discarded in Thm.",
        "8 because they violated condition (ii).",
        "The new condition (iii) applies to all of these cases.",
        "In A' and C', m + ikl appears so pt(m + {k},k) must jump from zero at to.",
        "The cases A, B and C are still represented by Fig. 5A, 5B and5C, with of replaced by t. Cases A', B' and C' would be represented by mirror images of these three figures, except that pt(m + ikl,k) must exhibit a discontinuity at to, and one of the pt(m + (4,1) must compensate for this.",
        "itaraLt The asymmetry with respect to time of the conditions for changes in Mt .may be interpreted as follows, The probability that a word may be used for a meaning may drop to zero continuously, but it may not increase from zero continuously.",
        "Instead, it must at some time jump to some finite value.",
        "This distinction is not too important to the overall characteristics of word-meaning system 40 histories, but we note it because the particular type of histories we shall study have this property.",
        "The development of the metric d in the previous section carries over completely when the time parameter replaces the precision.",
        "parameter, except, of course, that there is no longer any necessary trend in the average distance between meanings as t increases.",
        "Anticipating some of our later discussion, consider the case where all meanings consist of exactly one word, as in the Swadesh model.",
        "In this case, letting s and t be time as in Thm.",
        "1, ds,t(m,n) = 1 -1,(k,l) where m = n = (ligfit.",
        "d then, is in a certain sense a generalization of the cognation indicator $ ."
      ]
    },
    {
      "heading": "Word-meaning processes",
      "text": [
        "So far, changes in M4 or Mt have been deterministic as the value of the parameter changes.",
        "(Even though the p, or pt are p2.21:.",
        "abilityfunctions, we have not studied further properties of the random variables which are distributed according to these functions, and we will not do so.",
        "In linguistic terms, we are still dealing with angue and not parole,) To generalize the Swadesh theory, and to provide a realistic model, we must take into account unpredictability of lexical and semantic change.",
        "In probability theoretical terms, we must impose a probability measure, on the set of all possible histories.",
        "We shall not do this explicitly.",
        "Rather we shall assume it is possible, and assume that the examples we construct by specifying local behaviour are well-behaved in terms of an underlying probability measure space.",
        "Definition A word-meaning process is a set of word-meaning system histories indexed by WE St where (SI P) is a probability measure space.",
        "This means that any event or combination of events in which we may be interested is represented by a set, A, of histories (WEA ) where A is a member of the 01-algebra and where P(A) is well-defined for all AE.).",
        "A word-meaninz process based on Brownian motion To construct the word-meaning process which is the best model for natural languages would require the operationalizing of definitions, collection of much data and its statistical analysis.",
        "At present, we shall attempt only an heuristic investigation.",
        "In PART 1, we emphasized the basic unpredictability of change in the word-meaning relationship.",
        "In terms of our model, (and considering only small intervals of time) this means that for t> s,",
        "Furthermore, it should not be possible to-predict the future behaviour of individual pt(m,l) from trends established in the pasts for any t' s1> sz> .",
        ".",
        "sr ript(1141)1 ps(m,1), ps2(m,1), .",
        ".",
        ".,Par(st,1 i 11Pt( m,l)lp , the Markov condition.",
        "si But these two conditions and the continuity conditions on pt indicate that the local behaviour of pt(m,l) should resemble a",
        "diffusion process, with zero drift.",
        "The simplest such process is the well-known Brownian motion, whose behaviour characteristics change neither with time, t, nor with position, x.",
        "We proceed to construct a word-meaning process satisfying these properties.",
        "Let (L, pai•,•)) be a word-meaning system for a fixed oC .",
        "For t = 0, let pt(m,l) = pm(m,1), Mt = Let no = qm44/41 .",
        "no is the number of word-meaning relationships in the system.",
        "Let x1(t), x2(t), .",
        ".",
        ".11cno(t) z t 3 0 be no sample paths of a no Brownian motion process, chosen independently, and R(t) =1.",
        ";E,xi(t).",
        "where i = i(m,l) is determined beforehand.",
        "Then pt is continuous in C 0,T) with probability 1.",
        "We must engure that pt(.,.)",
        "is a probability.",
        "distribution.",
        "It is not necessarily true, however, that pt(m,l) 0, since yi(t) may be negative.",
        "To adjust for this, let",
        "In other words, all the pt(m,l) are positive before r Then with probability 1, there is a unique m't Mo, ke m', such that lim pt(m',k) = pl(m1,k) = 0 But this is reminiscent of case A or C in Thm.",
        "11 (see Fig.5), where one word in a meaning loses its ability to be grouped with the others.",
        "Then all the pt(m',1) should drop to zero and all the p (m1-[ki,l) jump to compensate.",
        "According to whether m' ik3e Mo or not, we have case A or case C respectively.",
        "Then it is a simple matter to determine Mt.",
        "Now, change the definition of all the pt(m,l) for t >t-, by calculating",
        "and starting over as Tor t = 0.",
        "Continuing this way until t = T, we ensure that no pt(m,l) ever drops below zero.",
        "We now have a word-meaning process, but not a very healthy one, in that IM+J decreases monotonically with t.",
        "To counteract this, we superimpose another process on our construction.",
        "We select points in [0,T] at random as follows: The probability of no points being selected in an interval [t,t+ Alt] is",
        "where h/Lit-0 0 as At-00).",
        "At each point 'r selected, randomly ohoose mg' M2.",
        "and keL, kin:.",
        "If fr(m + 114 ))0, the system undergoes a change as in case B' of Thm.",
        "11 If ft. -(m + fla) = 0, the system undergoes an A'-type change with probability , and a C'-type change with probability 1 In each of these cases an element ld m must be selected at random so that pt(m (id,k) + pt(m +f0,1) and pt(m,l) are discontinuous but their sum is continuous.",
        "The size of the discontinuity is uniformly distributed between 0 and pt(m,1).",
        "In case A', we assume that after this latter step is done, each element in m loses a random (but fixed) proportion of its probability weight to the corresponding element in m + ikl.",
        "This ends the construction.",
        "Note that case B of Thm.11 does not occur in this-example.",
        "Had we not insisted on the extra discontinuities (in pt(m + fkl,k)) in the definition of a word-meaning system history, we would not have been able to use the Brownian motion.",
        "If p (m + ikl,k) = 0, and if we add a Brownian motion yi(t), nrit(m + (4,k) will be zero again for arbitrarily small t. Hence we must start p (m + (k),k) at a finite value, i.e. discontinuouslY.",
        "Stability The first thing we would like to know about our system is whether or not it is degenerate.",
        "Does it tend to degenerate into a single word-meaning relationship with pe(1/,l) = 1 ?",
        "Does the number of meanings IMItIor word-meaning relationships nt tend to grow without bounds as T and ILI increase?",
        "By increasingpu to a high enough value, we can increase the rate at which new word-meaning relationships are created, and hence reduce the time during which nt is at low values.",
        "At the same time, nt cannot increase without bound, since as the number of word-meaning relationships increases, the probability weight attached to each must decrease, on the average.",
        "Hence a higher proportion of relationships tends to be annihilated per unit time, as in cases A and C of Theoremil A rigorous proof that nt is neither too large nor too small most of the time does not seem easy to achieve, simply because of the complication of the model and the importance of the initial conditions.",
        "In any case, such a result would be rather weak.",
        "It seems likely, and we will present evidence from sampling experiments to support this, that as t---> , nt tends to vary about an equilibrium mean value according to an equilibrium distribution, depending only on the system parameters it4 and 'T",
        "Regularity of change in (Mt, dto?",
        "For each o' , a word-meaning system (relatively complicated) was associated with a relatively simple metric space (Ma,d,01 The meanings corresponded to points in the metric space and the distance between meanings varied continuously almost everywhere with respect to oC.",
        "The same remarks hold true, of course, for the analogous metric spaces (Mt,dtt).",
        "As t increases each meaning moves continuously except at certain points where it can split into two or merge with another meaning.",
        "At such times there are discontinuities in dt,t,but these are not usually very large.",
        "This regularity of motion ensures that we have some sort of correspondence between the sets of meanings at two distinct times.",
        "In the Swadesh model, a well defined correspondence is assumed, in terms of the universal set of meanings.",
        "If we do not postulate anything of this nature, since it must necessarily refer to cultural universals, not linguistic universals, it becomes more difficult to make word-meaning comparisons at two points in time.",
        "Indeed, if after a point in time, s, a meaning loses a lexical representation (as in case C in Thm.",
        "11), it ceases to exist, in our technical sense, and others close to it take up its semantic load - and we must, at the very least, assume some rule for choosing a related or close meaning, for all later points in time, if we are to make lexical comparisons.",
        "The intuitive use of the term \"close\" gives a clue as to the appropriate choice - the",
        "meaning n which minimizes dst(m,n) .",
        ", This has one important desirable property for such a rule.",
        "For t very close to s, in most cases n will, of course, be m itself.",
        "of quantities approximately proportional to Brownian motion (see definition of d ) and hence will, on the average (or in expectation) increase monotonically.",
        "1 - ds monotonically.",
        "t(m,m) will decrease notonically.",
        ", After a discontinuity 1 - minds t(m,n) will continue to decrease.",
        "nEMt ' Since it is the processes of lexical loss and lexical replacement which are responsible for this decrease, 1 2 (1 - min ds,t(mn))"
      ]
    },
    {
      "heading": "1Ms1 mEMs",
      "text": [
        "is a likely candidate to replace Swadesh's 1 ZS(k,l) as a TT mei lexicostatistic indicator.",
        "We will so use it, keeping in mind that it does not involve any pan-cultural or pan-linguistic method of selecting universal meanings to compare.",
        "If such a method existed (and it does, approximately speaking, e.g. the Swadesh list) our indicator must necessarily provide an upper bound for any indicator of the form 1 - ds,t'"
      ]
    },
    {
      "heading": "Simulating word-meaning processes",
      "text": [
        "A complete, purely mathematical treatment of the Brownian-based word-meaning system would be difficult, and no results analogous to Theorems 1 – 3 are yet available.",
        "On the other hand, by choosing a set of po(m,l) = po(0(m,l) from a word-meaning system,",
        "and fixing AA, and Tr it is possible to simulate the behaviour of the bivariate functions pt(m,l).",
        "A sample from a number of simulated histories might produce some hint of what the corresponding theorems might be.",
        "The remainder of this chapter consists of an account of such an experiment.",
        "A simulation 'program A computer program (see Fig. 7) was written to provide word-meaning histories sampled from the Brownian-based process (actually an approximation of this process).",
        "The program accepts as initial data T (the length of the simulation), parameters I (from which /64 can be calculated), •;), and 0 ; and two matrices N(i,j) and P(i,j) with iNj rows and 20 columns.",
        "The row index i identifies the meaning being considered, and the non-zero N(i,j) identify the words connected to that meaning (up to 20).",
        "P(i,j) then, represents po(mi,lk) of the system where N(i,j) = lk.",
        "(It is more economical to store two X 20 matrices than one IN X 114 matrix if (Li> 40.)",
        "To approximate the Brownian motion from time t=0 to t=I, one part of the program adds a normal random variable to each of the non-zero P(i,j).",
        "These variables have mean zero and variance I and their sum is zero, as specified in the model.",
        "Each of these P(i,j) is then examined to see whether it has dropped to zero or below.",
        "If it has, the rest of the non-zero P(i,k) are set to zero as in cases A and C of Thm.il and P(h,g) are increased by compensating amounts where h and g are the appropriate meanings and words for the cases.",
        "Another part of the program picks an integer according to a Poisson random variable, with mean 10, and this variable represents the number of cases A', B' and C' which have occurred during the time increment I.",
        "Hence dkc a: 10/I.",
        "For each of these occurrences the program then allows a choice of whether the word (see Thm11 ) is to be a new word (borrowing) or a word that is already used for another meaning (this choice is made at random with probabilities B ,i-e ).",
        "The meaning m and the word 16 in (again as in Thing.)",
        "are chosen at random.",
        "If necessary (not in case B') a random choice is made between A° and C' according to parameter nr , and if necessary (case A\") the allocation of probabilities between m and m + (ic) is decided by choosing a random number (uniformly distributed between 0 and p(m,1)).",
        "The program then provides for the examination of the system to calculate the resulting values of IMI, 114, N(.,.)",
        ", P(.,-) and tit and it prints these out.",
        "From this point it returns'to the Brownian motion section and sets t a 21 and adds another batch of normal variables with variance I, etc.",
        "The above is only a summary of the program.",
        "Other routines relabel words or meanings so that they may be stored and examined economically, and others allocate any \"negative probability\" from Brownian paths going below zero during a time increment (when in theory they are only allowed to go as far as zero) among the other word-meaning relationships of the meaning involved.",
        "Finally, in the versionrepresentedinFig7there is a routine which compares the word-meaning system at time t with the initial word-meaning system (at",
        "time t=0) according to our lexicostatistic indicator F(t) = 1 - min do t(m,n)) .",
        "ncMt '"
      ]
    },
    {
      "heading": "Results of a simulation experiment",
      "text": [
        "To illustrate the properties of a Brownian-based process, we will present the results on 12 sample histories of a simulated process with the parameters fixed.",
        "These histories were obtained as follows.",
        "For the first, the initial system was represented as in Fig.B.",
        "whore each line between an m and an 1 represents po(m,l) = .01 Here m20, tf..-20, n0=100.",
        "[0,T) was divided into 100 increments, and details of the system were extracted at time T",
        "52 and these were used to provide the initial system for the second history.",
        "This general procedure was followed thereafter with the final status of some of the systems serving as the initial systems for others.",
        "Stability and equilibrium distributions As we conjectured earlier, the system moves rather quickly to equilibrium and we can trace this in the first history.",
        "Fig.",
        "9 shows how IM.tijiLtland nt tend to approach and then oscillate around an equilibrium value.",
        "The \"equilibrium\" distributions in Fig.10 are calculated from all the values of the system characteristics, at all points in time, of the last 11 histories(since the first history started with a non-equilibrium state"
      ]
    },
    {
      "heading": "Zinf's Law",
      "text": [
        "It is a property of natural languages that, aside from the few most frequent words, the frequency of occurrence of a word 0(1) and the rank order of this frequency, H(1), are related approximately as",
        "where C and IC are constants.",
        "Our word-meaning systems do not have as many words as natural languages.",
        "Nevertheless, it is possible to calculate the probabilities (not frequencies) g(1) from",
        "This was carried out for eight of the terminal word-meaning systems of our simulation and the g(1) were then ordered to give H(1).",
        "Plotting these (Fig.",
        "11), it is clear that a Zipf's law can be stated which holds for the majority of the words in the system, excepting the first few and the last few.",
        "The \"tailing off\" effect can perhaps be ascribed to the homogeneity of the Brownian process - any word, whose total probability fluctuates close to zero, is very likely to hit zero and be absorbed.",
        "By introducing an inhomogeneous diffusion, where the variance o: the displacement of p(m,l) after time 4it is an increasing function of pt(m,1), this effect could be removed, and the total number of words and meanings could increase as well.",
        "One interesting comparison can be made between the g(1) vs. H(1) curves for the initial and the terminal states of the first history (see Pig.8 ).",
        "In the initial, non-equilibrium state all words have equal probability g(1) =.05 The terminal state has shifted to a typical Zipf's law."
      ]
    },
    {
      "heading": "Lexicostatistics",
      "text": [
        "Finally, we present the results of the lexicostatistic survey of the 11 equilibrium system histories.",
        "These are displayed in Fig.12 and the mean behaviour is extracted and is displayed in Fig. 13 These diagrams speak for themselves after an initial sharp drop, the index",
        "TO what extent the initial drop is a property of the particular metric being used and to what extent it is an inevitable consequence of the Brownian motion, must await further study.",
        "In any case, it does not seem to be a simple consequence of a Zipf's law distribution of word probabilities or the analogous effect for meaning, since it also occurs for very symmetrical initial systems such as the one in Fig.8.",
        "Without coming to any specific conclusions, it is appropriate to end this chapter by pointing out that both Swadesh's relatively simple model of lexical lass, using a universal meaning set to compare language stages; and our more complicated model, in which comparisons between stages of languages are made in terms of internal properties of the lexicon; concur in the very similar behaviour of their lexicostatistio indexes."
      ]
    }
  ]
}
