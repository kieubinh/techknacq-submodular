{
  "info": {
    "authors": [
      "Charles J. Rieger III"
    ],
    "book": "ACL Microfiche Series 1-83, Including Computational Linguistics",
    "id": "acl-J79-1013",
    "title": "Understanding by Conceptual Inference",
    "url": "https://aclweb.org/anthology/J79-1013",
    "year": 1979
  },
  "references": [],
  "sections": [
    {
      "heading": "ABSTRACT",
      "text": [
        "Any theory of languaga must also be a theory of inference and memory.",
        "It does not appear to be possible to \"understand\" even tae simplest of utterances in a contextually meaningful way in a system in which language fails to interact with a language free memory and belief system, or in a system which, lacks a spontaneous inference reflex.",
        "People apply a tremendous amount of cognitive effort to understanding the meaning content of language in context.",
        "Most of this effort is of the form of spontaneous conceptual inferences which occur in a language-independent meaning environment.",
        "I have developed a theory of how humans process the meaning content of utterances in context.",
        "The theory is called Conceptual Memory, and has been implemented by a computer program whicn is designed to accept as input analyzed Cnnceptual Dependency (Schank et a..) meaning graphs, to generate many conceptual inferences as automatic responses, then to identify points of contact among those inferences in \"infefence space\".",
        "Points of contact establish new patnways through existing memory structures, and hence \"knit\" each utterance in witn its surrounding context.",
        "Sixteen classes of conceptual inference have been identified and implemented, at least at the prototype level.",
        "Tnese classes appear to be essential to all higher-level language comprehension processes.",
        "Among them are causative/resultative (those which predict cause and effect relations), motivational (those which predict and describe actors' intentions), enablement (those which predict the surrounding context of actions), state-duration (those which predict the fuzzy duration of various states in the world) normative (those which assess the \"normality\" of a piece of information - how unusual it is), and specification (those which predict and fill .in missing conceptual information in a languagccommunicated meaning graph).",
        "Interactions of conceptual inference with the language processes of (1) word sense promotion in context, and (2) ident.)",
        "ification of referents to memory tokens are discussed.",
        "A theoretically important inference-reference \"relaxation cycle\" is identified.",
        "and its solution discussed.",
        "The theory provides the basis of a computationally effective model of language comprehension at a deep conceptual level, and should therefore be of interest to computational linguists, psychologists and computer scientists alike."
      ]
    },
    {
      "heading": "TABLE OF CONTENTS",
      "text": [
        "1.",
        "The Need for a Theory of Conceptual Memory and Inference 5 2.",
        "A Simple Example 7 3.",
        "Background 10 4.",
        "A Brief Overview of the Conceptual Memory's Inference Control Structure 15 5.",
        "The Sixteen Theoretical Classes of Conceptual Inference 20 5.1.",
        "CLASS 1: Specification Inferences 21 5.2.",
        "CLASSES 2 and 3: Resultative and Causative Inferences 25 5.3.",
        "CLASS 4: Motivational Inferences 26 5.4.",
        "CLASS 5: Enabling Inferences 27 5.5.",
        "CLASS 6: Action Prediction Inferences28 5.6.",
        "CLASS 7: Enablement Prediction",
        "6.",
        "Summary of the Inference Component 43 7.",
        "The Inference-Reference Relaxation Cycle in Conceptual Memory 44 8.",
        "Word Sense Promotions and Implicit Concept Activation in the Conceptual Memory 48 9.",
        "Conclusion 51 APPENDIX A. Causal Chain Expansion",
        "Research in natural language over the past twenty years has been focussed primarily on processes relating to the analysis of individual sentences (parsing).",
        "Most of the early work was devoted to syntax.",
        "Recently, however, there has been a considerable thrust in the areas of semantic, and importantly, conceptual analysis (see (R2), (M1), (Si) and (Cl) for example).",
        "Whereas a syntactic analysis elucidates a sentence's surface syntactic structure, typically by producing some type of phrase-structure parse tree, conceptual analysis elucidates a sentence's meaning (the \"oicture\" it produces), typically via production of an interconnected network of concepts which specifies the interrelationships among the cohcepts referenced by the words of the sentence.",
        "On the one hand, syntactic sentence analysis can more often than not be performed \"locally\" that is, on single sentences, disregarding any sort of global context; and it is reasonably clear that syntax has generally very little to do with the meaning of the thoughts it expresses.",
        "Hence, although syntax is an important link in the understanding chain, it is little more than an abstract system of encoding which does not for the most part relate in any meaningful way to the information it encodes.",
        "On the other hand, conceptual sentence analysis, by its very definition, is forced into, the realm of geneLai WOLJU knowledge; a conceptual analyzer's \"syntax\" is the set of rules which can produce the range of all \"reasonable\" events that might occur in the real world.",
        "Hence, in order to parse conceptually, the conceptual, analyzer must interact with a repository of world knowledge and world knowledge handlers (inferential processes).",
        "This need for such an analyzer-accessible world knowledge repository has provided part Df the motivation for the development of the following theory of conceptual inference and memory however, the production of a conceptual network from an isolated sentence is only the first step in the understanding 5, process.",
        "After this first step, the real question is: what happens to this conceptual network after it has been produced by the analyzer?",
        "That is, if we regard the conceptual analyzer as a specialized component of a larger memory, then the allocation of memory resources in reaction to each sentence follows the pattern: (phase 1) get the sentence into a form which is understandable, then (phase 2) understand it It is a desire to characterize phase 2 which has served as the primary motivation for developing this theory of memory and inference.",
        "In this sense, he theory is intended to be a charting-out of the kinds of processes which must surely occur each time a sentence's conceptual network enters the system.",
        "Although it is not intended to be an adequate or verifiable model of how these processes might actually occur in humans, the theory described in this paper has nevertheless been implemented as a computer model under PDP-10 Stanford 1.6 LISP.",
        "While the implementation follows as best it can an intuitively correct approach to the various processes described, the main intent of the underlying theory is to propose a set of memory processes which, taken together, could behave in a manner similar to the way a human behaves when he \"understands language\"."
      ]
    },
    {
      "heading": "2. A Simple Example",
      "text": [
        "The attentive human mind is a volatile processor.",
        "My conjecture is that information simply cannot be put into it in a passive way; there are very primitive inference reflexes in its logical architecture which each input meaning stimulus triggers.",
        "I will call these primitive inference reflexes \"conceptual inferences\", and regard them as one class of subconscious memory process.",
        "I say \"subconscious\" because the concern is with a relatively low level stratum of \"higher-level cognition\", particularly insofar as a human applies it to the understanding of language-communicated information.",
        "The eventual goal is to synthesize in an artificial system the rOugh flow of information which occurs in any normal adult response to a meaningfully-connected sequence of natural language utterances.",
        "This of course is a rather ambitious project.",
        "In this paper I will discuss some important classes of conceptual inference and their relation to a specific formalism I have developed (R1).",
        "Let me first attempt, by a fairly ludicrous example, to convince you (1) that your mind is more than a simple receptacle for data, and (2) that you often have little control over the thoughts that pop up in response to something you perceive.",
        "Read the following sentence, pretending you were in the midst of an absorbing novel:"
      ]
    },
    {
      "heading": "EARLIER THAT EVENING, MARY SAID SHE HAD KILLED HERSELF. One of two things probably occurred: either you chose as referent",
      "text": [
        "of \"herself\" some person other than Mary (in which ease everything works out fine), or (as many people seem to do) you first identified \"herself\" as a reference to Mary.",
        "In this case, something undoubtedly seemed awry: you realized either that your choice of referent was erroneous, that the, sentence was part of some unspecified \"weird\" context, or that there was simply an out-and-out contradiction.",
        "Of course, all three interpretations are unusual in some sense because of a \"patently obvious\" contradiction in the picture this utterance elicits.",
        "The sentence is syntactically arid semantically impeccable; only when we \"think about it\" does the big fog horn upstairs alert:us to the implicit contradiction:"
      ]
    },
    {
      "heading": "MARY SPEAK AT TIME T",
      "text": []
    },
    {
      "heading": "MARY KILLS HERSELF AT TIME T-d",
      "text": [
        "Here is the argument: before reading the sentence, you probably had no suspicion that what you were about to read contained an implicit contradiction.",
        "Yet you probably discovered that contradiction effortlessly: Could there have been any a priori \"goal direction\" to the three simple inferences above?",
        "My conclusion is that there could not have been.",
        "If we view tne mind as a multidimensional \"inference space\", then each incoming thought produces a spherical burst of activity about the point where it lands in this space (the place where the conceptual network representing it is stored).",
        "The horizon of this sphere consists of an advancing wavefront of inferences - spontaneous probes Which are sent out from the point.",
        "Most will lose momentum and eventually atrophy; but a few will conjoin with inferences on the horizons of other points' spheres.",
        "The sum of these \"points of contact represents tne integration of the thought into the existing fabric of the memory in that each point of contact establishes a new pathway between the new thought and existing knowledge (or perhaps among several existing pieces of knowledge).",
        "This to me is a pleasing memory paradigm, and there is a tempting analogy to be drawn with neurons and actual physical wavefronts as proposed years ago by researchers such as John Eccles (El).",
        "The drawing of this analogy is, however, left for the pleasure of you, the reader.",
        "This killing example was of course more pedagogical than serious, since it is a loaded atterance involving rather black and white, almost trivial interences.",
        "But it suggests a powerful low-level mechanics for general language comprehension.",
        "Later, I will refer you to an example which shows how the implemented model, called MEMORY and described in (R1), reacts to the more interesting example MARY KISSED JOHN BECAUSE HE HIT BILL, which is,perceived in a particular context.",
        "It does so in a way that integrates the thought into the frameWork of that context and which results in a \"causal chain expansion\" involving six probanilistic inferences."
      ]
    },
    {
      "heading": "3. Background",
      "text": [
        "Central to this theory are sixteen classes of spontaneous conceptual inferences.",
        "These classes are abstract enough to be divorced from any particular meaning representation formalism.",
        "However, since they were developed concurrently with a larger model of conceptual memory (R1) which is functionally a part of a language comprehension system involving a conceptual analyzer and generator (MARGIE (S3)), it will help make the following presentation more concrete if we first have a brief look at the operation and goals of the conceptual memory in the context of the complete language comprehension system.",
        "The memory adopts Schank et al.",
        "'s theory (S1,S2) of Conceptual Dependency (CD) as its basis for representation.",
        "CD is a theory of meaning representation which posits the existence of a small number of primitive actions (eleven are used by the conceptual memory), a number of primitive states, and a small set of connectives (links) which can join the actions and states together into conceptual graphs (networks).",
        "Typical-of the links are: tne ACTOR-ACTION \"main\" link the ACTON-OBJECT link the CAUSAL link lit the DIRECTIVE link<-12C and the STATECHANGE link Each primitive action has a case framework which defines conceptual slots which must be filled whenever the act appears in a conceptual graph.",
        "There are in addition TIME, LOCation and INSTrumental links, and these, as are all conceptual cases, are obligatory, even if they must be inferentially filled in by the conceptual memory (CM).",
        "Figure 1 illustrates the CD representation of the",
        "sentence MARY XISSED JOHN BECAUSE HE (JOHN) HIT BILL.",
        "That conceptual graph is read as follows: John propelled some unspecified object X from himself toward Bill, causing X to come into physical contact with Bill, and this entire event cause Mary to do something which resulted in her lips being in physical contact with John!",
        "Furthermore, the entire event occurred sometime in the past.",
        "Chapter 2 of (R1) contains a fairly complete overview of the CD representation.",
        "Assuming the conceptual analyzer (see (R2)) has constructed, in consultation with the CM, a conceptual graph of the sort typified by 'Figure 1, the first step for the CM is to begin \"integrating\" it into some internal memory structure which is more amenable to the kinds of active infernce Manipulations the CM wants to perform.",
        "This initial integration occurs in three stages.",
        "First is an initial attempt to replace the symbols (JOHN, MARY, BILL, X, etc.)",
        "by pointers to actual memory concelots and tokens of concepts.",
        "Each concept and token in the CM is represented by a unique LISP atom (such as CO347) which itself bears no intrinsic meaning.",
        "Instead, the essence of the concept or token is captured in a set of features associated with the symbol.",
        "Thus, for instance, an internal memory token with no features is simply \"something\" if it must be expressed by language, whereas the token illustrated in Figure 2 would represent part of our knowledge about Bill's friend Mary Smith, a female human who owns, a red Edsel, lives at 222 Avenue St., is 26 years old, and so forth.",
        "This set of features is called 00948's occurrence set, and is in the implementation merely a set of pointers to all other memory structures in which C0948 occurs.",
        "The process of referent identification will attempt to isolate one token, or second best, a set af candidate tokens for each concept symbol in the incoming graph by means of a feature-intersedting algorithm described in (R1).",
        "Reference identification is the first stage of the initial integration of the graph into internal memory structures.",
        "The",
        "second and third seages are (2) the isolation of subgraphs which will form the beginning inference,queue (input to tne spontaneous inference component), and (3) the storage of the graph dependency links themselves as pointers in the memory.Just as for simple concepts and tokens, composite structures (ctiQns and states) are stored under a unique internal symbol, and this symbol may also have an occurrence set.",
        "In addition, there are several other properties associated with each composite structure S: the recency of S's activation by explicit reference (RECENCY), the recency of S's activation by implicit (inferential) reference (TOUCHED), the degree to which S is held to be true (STRENGTH), a list of other composite structures fnom which S arose in the memory - its inferential antecedants-(REASONS), and a list of other composite structures in whose generation Splayed a role as antecedant (OFFSPRING).",
        "RECENCY and TOUCHED are also properties of concepts and tokens, and are used in the referent identification process.",
        "Figure 3 shows the memory structures which result from the conceptual graph of Figure 1 after the initial integration.",
        "The net result of the initial integration is a set of starting memory structures,(actuallv, a list of pointers to their symbols, such as (C2496 C2301 C2207)).",
        "Each of these structures references memory concepts tokens and other composite structures.",
        "Regarding the referent identification process, for those concepts.",
        "and tokens which could not.be uhiquely identified, new temporary tokens will have beeh created, each having as its initial occurrence set a list of what is khown about the entity so far.",
        "After the initial integration, the inference component is applied simultaneously to each memory structure (\"point in inference space\") on the starting inference queue."
      ]
    },
    {
      "heading": "4. A Brief Overview ot the Conce.tual Memor 's Inference Control Structure.",
      "text": [
        "The control structure which implements the CM inference reflex is a breadth-first monitor whose queue at any moment is a list of pointers to dependehcy structures which have arisen by inference from the beginning structures isolated during the initial integration.",
        "It is the inference monitor's task to examine each dependency structure on the queue in turn, isolate its predicate, prepare its arguments in a standard format, collect several time aspdcts from the structure's occurrence set, then call the inference molecule associated with the predicate, passing along the arguments and time information.",
        "All inferential knowledge in the CM is contained in inference molecules, which lie in one-one correspondence with conceptual predicates.",
        "An inference molecule is a structured LISP program which can perform arbitrary discrimination testis on a relevant dependency structure's features and features of all involved concepts and tokens, and which-can call on specialist programs to carry out standard test information retrieval functions.",
        "(\"CAUSER\" is an example of such :4 specialist.",
        "It will scan back causal sequences from structure S until it locates a volitional actiOn, then it returns the actor of that action as the primary causing agent of S ) Inference molecules are hence multiple-response discrimination Petworks whose responses are conceptual inferences (of the various theoretical types to be described) which can be made from the depndency structure.",
        "Each potentidl inference within the inference molecule is called an inference atom.",
        "The contribution of an inference atom which has been found applicable to the dependency structure reports eight pieces of information to a component of the monitor called the structure generator, whose job it is to embody each new inference in a memory structure.",
        "These.eight pieces of information are the following:",
        "1. a unique mnemonic which indicates to *hich of the 16 theoretical classes the new inference belongs (this mnemonic is associated with the new structure only temporarily on the inference queue for subsequent control purposes) 2. the \"reference name\" of the generating inference atom",
        "(each atom has a unique name which is associated with the new memory structure for control purposes) 3, the dependency structure (a predicate which binds together several pointers to concepts, tokens and other structures), which is the substance of the new inference 4, a detault \"significance factor\" which is a rough, ad hoc measure of the inference's probable relative significance (this is used only if a more sophisticated process, to be described, fails) 5, a REASONS list, which is a list of all other sttuctures in the CM which were tested.",
        "by the discrimination net leading up to this inference atom.",
        "tvery dependency structure has a REASONS list recording how the structure arose, and the REASONS list plays a vital role in the generation of certain types of inference 6. a \"propagation strength factor\" which, when multiplied by the STRENGTIls (degree of belief) of all structures on the REASONS list, produces the STRENGTH of the new inference.",
        "Mere is a need for better heuristics here incidentally -- see (Z1) for instance.)",
        "7 a list of modifying structures (typicarly time aspects) which become the new inferred structure's initial occurrence set",
        "8, propagation and strength factors for each modifying struc tute Figure 4 illustrates the small implemented.",
        "NEGCHANGL (something undergoes a negative change on some scale) inference molecule.",
        "It is included to communicate the gestalt rather than correct specifics at this early stage of development.",
        "The two other main components of the inference monitor are the evaluator and the structure merger.",
        "It is the function of the evaluator to detect exact and fuzzy contradictions and confirmations (points of contact) between eacn new inference as it arises and existing memory dependency structures.",
        "Because \"fuzziness\" in the matching process iliTplieF, access to a vast number of heuristics (to illuStrate: would it be more like our friend.",
        "the",
        "lawyer or our friend the carpenter to own a radial arm saw?",
        "), the evaluators delegates most of the matching responsibility to programs - again organized by conceptual predicates - called normality molecules (\"N-molecules\").",
        "N-molecules, which will be discussed more later, can apply detailed heuristics to ferret out fuzzy confirmations and contradictions.",
        "As I will describe, N-molecules also implement one class of conceptual inference Confirmations' and contradictions discovered by the evaluator are noted on special lists which serve as sources for possible subsequent responses by the CM.",
        "In addition, confirmations lead.",
        "to invocation of the structure merger, which physically replaces the two matching structures by one new aggregate structure, and thereby knits together two lines of inference.",
        "1s events go, this is one of the most exciting in the CM.",
        "Inference cutoff occurs when the product of .an inference's STRENGTH (likelihood) and its significance factor falls below a threshold (0.25).",
        "This ultimately restricts the raoius of each sphere in the inference space, and in the current model, the threshold is set low to allow considerable expansion.",
        "Figure 5 depicts the overall strategy of the inference monitor.",
        "(R1) contains a fuller account of the inference control structure, whose description will be terminated at this point.",
        "Enter... sixteen theoretical classes of conceptual inference whichLfuel this inference reflex.",
        "The inference monitor."
      ]
    },
    {
      "heading": "5. The Sixteen Theoretical Classes of Cohceptual Inference.",
      "text": [
        "It is phenomenological that most of the human language experience focuses on actions, their intended and/or resulting states, and the causality and enabling states which surround them.",
        "'There seems 'to be an inescapable core of notions related to actions, causation and enablement which almost anyone who introspects long enough' will independently discover.",
        "In his \"Cold Warrior\" model; Abelson (LA1) Was perhaps the first to attempt a computationally formal systematization of this fundamental core of Meaning relations.",
        "It is of the utmost primacy in his system,.",
        "which models the political ideologies and behavior patterns of a rabid right-winger, to discover and relate the underlying purposes, enablement and causality surrounding events in some hypothetical international scenerio or crisis.",
        "Again, in Schank t al's CD theory, the same emphasis arose more or less independently in a system of meaning representation for everyday utterances: causality, actions, state-changes and enablement were recurringsthemes.",
        "Not surprisingly the same notions have emerged as central in my analysis of the inference reflex: over half of the-16 classes telate to this \"action-intention-causalityenablement-knowledgen complex.",
        "In the following descriptions of these 16 classes, keep in mind that all types of inference are applicable to every subcomponent of every utterance, and that the CM is essentially a parallel simulation.",
        "Also bear in mind that the inference evaluator is constantly performing matching operations on each new inference in order to detect interesting' interactions between inference spheres.",
        "It should also be emphasized.",
        "that conceptual inferences are probabilistic and predictive in nature, and that by making them in apparently wasteful quantities, the CM is not seeking one.",
        "result or truth.",
        "Rather, inferential expansion.is an endeavor which broadens'each piece of information into its surrounding spectrum to fill out the information-rich situation to which the information-lean utterance might refer.",
        "The CM's.gropings will resemble more closely the solution of a jigsaw puzzle than the mare goal directed solution of a crossword puzzle.",
        "The following discussions can only sketch the main ideas behind each inference class.",
        "See (R1) for a more comprehensive.",
        "treatment.",
        "5.1 CLASS 1: SPECIFICATION XNFERENCES PRINCIPLE:The CM must be able to identify and attempt.to fill in each missing slot of an incoming conceptual graph.",
        "EXAMPLES:\"Johmwas driving home from work.",
        "He hit Bill's cat.",
        "(inference) It was a car which John propelled into the cat.",
        "**John bought a chalk line.",
        "(inference) It was probably from a hardware store that John bought the chalk line."
      ]
    },
    {
      "heading": "DISCUSSION:",
      "text": [
        "Our use of language presupposes a tremendous underlying kffowledge about the world.",
        "Because of this, even in, say, the most explicit technLal lutting, certain assumptions are made by the writur (speaker) about the comprehender's knowledge -- that he can fill in the plethora of .detail surrounding each thought.",
        "In the CM, this corresponds to filling in all the missing conceptual slots in a graph.",
        "The utility of such a process is twofold'.",
        "first, CM failures to specify a missing concept can serve as a source of requests, for more information (or goals to seek out that information by CM actions if.",
        "CM is controlling a robot).",
        "Second, by predictively completing the graph by application of genetal pattern knowledge of the modeled world, novel relations among specific concepts and tokens will arise, and these can lead to potentially significant discoveries by other inferences.",
        "To illustrate, a very common missing slot is the instrumental case.",
        "We generally leave it to the imaginative powers of the hearer to surmise the probable instrumental action by which some action occurred: (husband to wife) I went to SEARS today.",
        "(wife to husband), How?",
        "I had the car all day!",
        "Here, wife fills in the instrumental slot as: \"Husband drove a car to SEARS\" (clearly relying_on some specific heuristics,,such as the distaAce from their",
        "home to SEARS, etc.",
        "), and this led to her di\"scovery of a contradiction.",
        "That she may have been premature in the specification (and'shad later to undo it) is of secondary importance to the phenomenon that she did so spontaneously.",
        "In the CM.specification inferences, as all inferences, are implemented in the form of structured programs which realize discrimination nets whose terminal nodes are concepts and tokens rather-than inferences, as in general inference molecules.",
        "These specification procedures are called specifier molecules (\"S-molecules\"), and are quite similar to inference molecules.",
        "Fig.",
        "6 shows a small prototype of the PROPEL specifier molecule Which can predictively fill in the missing object of a PROPEL.attion, as in \"John hit Pete.\" That particular \"specifier atom\" is sensitive to context along one simple dimension if the actor is known to be grasping an object (this prototype doesn't care wnetner it's a wet noodle or a bludgeon), at the time of the action, the molecule will infer that it was the grasped object which was propelled, as in \"John picked up the flower pot.",
        "He hit Pete.\" Otherwise, the molecule will assume \"hand of the actor\".",
        "This is ridiculously oversimplified, tut it repreents a certain philoSophy I will digress a moment to reveal.",
        "I, as many other people (see Wl, H1, Cl, for unstance), have come to believe that passive data structures ,are fundamentally awkward for representing knowledge in any detail, partitularly for the purposes typified by",
        "see if anythjng is located in Xl.",
        "If sonething is found, it is bound to X2, and the LOC structure which expresses this information is.",
        "bound to X3.",
        "If nothin9 s located in the actor's hand, has hand itself (X1) is inferred.",
        "The (LIST X3) in the first SP Call is the list of REASONS (just.one here) lustifying the specificatibn of the bbject the actor was 'holding as the object of the PROPEL.",
        "FIGURE 6 The PROPEL specifier molecule.",
        "this simple PROPEL example.",
        "The needs for \"special.case heuristics\" in even such a inodest pperation as this quickly overtaRe one's prowess at devising \"declarative\" memory, structures.",
        "Programs, on the other hand., are quick and to the point, quite flexible, and have_as much \"aesthetic potentialnas eyen the most elegant declarative structures.",
        "A life-size procedure for this very narrow process of specifying the missing object-of a PROPEL action would obviously reqUire-many more tests for related contexts (\"John was racing down.",
        "the hill on his bilce.",
        "He hit Bill.\") But independent of the fidelity with which any given g-molecule executes its task, there is a very important claim buried both here and in the other inferential procedures in the 01.",
        "It is that there are certain central tasks in which the decision process must seek out the context, rather than context seeking out the appropriate decision process.",
        "In other words, much ofinference capability requires specialists who Rmow a priori exactly what dimensions of context could possibly affect the generation of every potential inference, and these specialists carry out active probes to search, for those dimensions before any inference is generated.",
        "I can imagine no \"uniform context mechanism\" which accounts for the human's diverse ability to attend to the relevant and ignore the superfluous.>-conjecture i5 that the mechanism for contextual guidance of inference is highly distributed throughout the memory rather than.centralized as a component of the, memory's control structure."
      ]
    },
    {
      "heading": "5.2 CLASSES 2 and 3: RUULTATIVE and CAUSATIVE INFERENCES",
      "text": [
        "PRINCIPLE!If an action is perceived, its probable resulting states should be inferred (RESULTATIVE).",
        "If u state is perceived, the general nature of its probable causing action (or a specific action, if possible) should be inferred (CAUSATIVE).",
        "EXAMPLES:**11.Jary hit Pete with a rock.",
        "(inference) Pete probably became hurt.",
        "(RESULTATIVE) **Bill was angry at Mary.",
        "(inference) Mary'may have done something to Bill.",
        "(CAUSATIVE) DISCUSSION.",
        ": These two classes Of inference embody the CH's ability to relate actions arid states in causal sequences relative to the Ws models of causality.",
        "In addition to serving as the basis for MOTIVATIONAI, inferences and contributing to the general expansjon process, CAUSATIVE and RESULTATIVE inferences often achieve the rather exotic form of understanding I have termed \"causal chain expansion.\" It is this process which makes explicit the oft-abbreviated statements of causality: language communicated predications ot causality must always (if only subconsciously) be explained in terts of the comprehender's models of causality, and failures to do so signal a lack of understanding and form another source of CM queries for more information.",
        "CaUsal expansion successes on the other hand result in important intervening actions and states which draw out (\"touch\") surtounding context and serve as the basis for inferences in other categories.",
        "Appendix A contains the computer printout from MEMOM , tracing a causal expansion for \"Mary kissed John because he hit Bill\" in a particular context M-lidh makes the explanation plausible.",
        "5 .",
        "3 CLASS 4: MOTIVATIONAL .INF ERENC ES 1RINCIPLEThe desires (intentions) of an actor can frequently be inferred by analyzing the states (AESULTATIVE inferences) which result from an action he executes.",
        "These WANT-STATE patterns are essential to understanding and should be made in abundance.",
        "EXAMPLES:**John pointed out to Mary that she hadn-t done her chores.",
        "(inference) Mary may have felt guilty.",
        "(RESULTATIVE) (inference) John may have wanted Mary to feel guilty.",
        "(MOTIVATIONAL) **Andy blew on the hot 'meat.",
        "(inference) Andy may have wanted the meat to .decrease in temperature.",
        "DISCUSSION: Language is a dual system of communication in that it usually communicates both the actual, and, either explicitly or by inference, the intentional; Where the intentions of actors (the set of stat?s.they desire) are not explicitly communicated, they must be inferred as the immediate causality of the.",
        "action.",
        "In the CM candidates for MOTIVATIONAL infereneesareneRESULTATIVEinfer'encesMthe CM can produce from",
        "anactionA:foreachRESULTATIVEinferenceR.which the CM could make from A , it conjectures that perhaps the actor of A desired R. Since the generation of MOTIVATIONAL inference is dependent upon the results of another class of inference (in general, the actor could have desired things causally removed by several inferences from the immediate resultg of his action), the MOTIVATIONAL inference process is implemented by a special proceuu-re POSTSCAN which is invok.ed between \"passes\" of the main breadth-first monitor.",
        "These passes will be discussed more later.",
        "Once generated, each MOTIVATIONAL inference will generally lead backward, via CAUSATIVE inferences, into an entire causal chain which lead up to the action.",
        "This chain will frequently connect in interesting ways with chains working forward from other actions.",
        "5 .",
        "4 CLASSENABLING.",
        "IN4ERENCES PRINCIPLE:Every action has a set of enabling conditions -- conditions which must be met for the action to begin or proceed.",
        "The CM needs a rich knowledge of these conditions (state), and should infer suitable ones to surround each perceived action.",
        "EXANPLES:**John saw Mary yesterday.",
        "(inference) John and -Iary were in the same general location sometime 'yesterday.",
        "**Mary told Pete that John was at the store (inference) Mary knew that John was at the store."
      ]
    },
    {
      "heading": "DISCUSSION:",
      "text": [
        "The example at the beginning of the paper contained a contradiction which could be discovered only.by.making a very simple enabling inference about the action of speaking (any action for that matter), namely that the actor was alive at the time!",
        "Enabling inferences can fruitfully lead from the known action through the enabling states to predications about other actions the actor Might have performed in order to set up the enabling states for the primary action.",
        "This Idea is closely related to the next class of inference.",
        "5.",
        "5 MAU 6: ACTION PREDICTION INFERENCES Whenever some WANT STATE of a potential actor is known, predictions about possible actions the actor might perform to achieve the state should be attempted.",
        "These predictions will provide potent potential points of contact for subsequently perceived actions.",
        "EXAMPLES:**John'Wants some nails.",
        "(inference) John might attempt to acquire some nails.",
        "**Mary is furious at Rita.",
        "(inference) Mary might do something to hurt Rita.",
        "DISCUSSION: Action prediction inferences serve the inverse role of MOTIVATIONAL inferences, in that they work forward from a known WANT STATE pattern into predictions about future actions which could produce the desired state.",
        "Just as a MOTIVATIONAL inference relies upon RESULTATIVE inferences, an ACTION PREDICTION inference relies upon CAUSATIVE Inferences which can be generated from the state the potential actor desires.",
        "Because it is often impossible to anticipate the specific causing action, ACTION PREDICTION inferences typically will be 'more general expectancies for a class of possible actions.",
        "In the nails example above, the general expentandy is, simply that John may do something which normally causes a PTRANS-(in CD terminology, a change of location of some object) of some nails from somewhere to himself.",
        "Often the nature of the desired state is such that some specific action can be predicted (\"John is hungry... John will ingest food.\") By making specific action predictions, a new crop of enabling inferences can be predicted (\"John must be near food.\", etc.",
        "),.and those conditions which cannot be assumed to be already satisfied can.serve as new WANT-STATEs of the actor.",
        "Thus it is through MOTIVATIONAL, ACTION PREDICTION and ENABLING inferences that the CM can model (predict) the problem-solving behavior of each actor.",
        "Predicted actions which match up with subsequently perceived conceptual input serve as a very real measure of the CM's success at piecing together connected discourse and stories.",
        "I suspect in addition that ACTION PREDICTION inferences will play a key role in the eventual solutions of the \"contextual guidance of inference\" problem.",
        "Levy DI) ha S some interesting beginning thoughts on this topic.",
        "What the action prediction inference process tries to doe' A.E.",
        "is enabling state j 1 3 for action.i."
      ]
    },
    {
      "heading": "FIGURE 7'",
      "text": [
        "The action synalaiction'inferefire pr.ocess.",
        "5 .",
        "6 CLASS 7: ENABLEMENT PREDICTION IItERENC ES .",
        "PRINCIPLE:If ,a potential actor desires-a state which is a commbn enabling condition for some specific action, then it can be inferred that the %tor migiIt wish to execute that action.",
        "EXAMPLES:**Mary asked John to tarn on the light.",
        "(inference) Mary probably wants to see something.. **Andr wants the meat to be cool.",
        "(inference) Nndy migfit want to eat the meat.",
        ")ISCUSSION: Inferences in this class arc, in a sense, the inverse of ENABLING inferences, because they attempt to predict an action from an enabling state known to be desired by a would-be actor.",
        "Whereas an ACTION PREDICTION infereRcepredicts.a.possible future action_to fulfill the desired state, enablement prediction draws out thn motivation of the desire for the state by identifying a probable action the state 1%ould enable.",
        "Although (as with ACTION PREDICTION inference) it will frequently happen that no specific action can be anticipated (since most states could enable infinitely many specific actions), it i5 nevertheless possible to' form general predictions about the nature of (-restrictions on) the enabled 'action.",
        "If, for example, John walks over to Mary, then a RESULTATIVE inference is that he is near Mary, and a MOTIVATIONAL inference is that he wants to be.",
        "near qARY At this point an ENABLEMENT PREDICTION inference can be made to represent the general class of interactions John might have in mind.",
        "This will be of'particular significance if, for instance, the CM knows already that John had something to tell her, since then the inferred action pattern would match quite well the action of verbal communication in which.the state of spatial proximity plays a key enabling role."
      ]
    },
    {
      "heading": "5 . 7 CLASS 8: FUNCTION INFERENCES",
      "text": [
        "PRINCIPLL:Control over some physical obj.ect P is usually desired by a potential actor becauSe jle is engaged.",
        "in an algorithm in which P plays a role.",
        "The CM should attempt to infer a probable action from its knowledge of P's normal function.",
        "EXAMPLES: **Mary wants the book.",
        "(inference) Mary probably wftnts to read the book.",
        "**John wants a knife., (inferencej- John -prObably wants to cut something with the knife.",
        "**Bill Tikes to pour sundaes down girls' dresses.",
        "Bill asked Pete to .hand him the sundae...",
        "DISCUSSION: Function inferences form a very diverse, rather colorful subclass of ENABLEMENT PREDICTION inference.",
        "The underlyihg principle is that desire of`immediate control over an object is usually tantamount to a desire .to use that objept in the norma,1 function of objects of that type, or in some function vitith is peculiar to the object-and/or actor (third example above).",
        "In the CM, normal functions of objects are stored as (NKT X Y) patterns, as ip Fig. 8 for things that are printed matter.",
        "Before applying NFCT patterns, the el firSt checks for unusual relations involving the specific actor and specific objectexcluding paths which include.",
        "the normal ISA relations between, say sundae and food).",
        "Thus, that Bill is known to require sundaes for slightly different algorithms from most people will be discovered and used'in the prediction.",
        "The result of a FUNCTION inference is always some predicted action, assumed to be part of some.al2orithvin which the actor is engaged,"
      ]
    },
    {
      "heading": "INTERVENTION INFERENCES",
      "text": [
        "PRINCIPLE:If a would-be actor is known to have been unsuccessful in achieving some action, it is often possible to infer the absence of one of the action's enabling states CMISSING BIABLEMENT).",
        "If a potential actor is known to desire that some action cease, it'can be predicted that he will attempt VD remove one or more enabling states of the action (INTERVENTION).",
        "EXAMPLES:**Mary couldn't see the horses finish.",
        "(inference) Something bloc_ked Mary's view.",
        "(MISSING ENABLEMENT) She.",
        "cursed the man in front of her... **Mary saw that Baby Billy was running out into the street.",
        "(inference) Mary will pick Billy off the ground (INTERVENTION) She ran after him...",
        "DISCUSSION: Closely related to the other enabling inferences, these forms attempt to apply lmowledge about enablement relations to infer the cause of an action's failure (in the case of MUSSING ENABLEMENT), or to predict a WANT NOT-STATE which can lead by action prediction inference to possible actions of intervention on the part of the WANTer.",
        "In the second example above; Mary (and the CM' first Must realize (via RESULTATIVE inferences) the potentially undesirable consequences of Billy's running attion (i.e., possible NEGCHANGE for Billy) From this, the CM can retrace, loaate the running action which could lead to such a NEGCHANGE, collect its enabling states-, then coniecture that Mary might desire to annul one or more of them.",
        "Among them tor instance would be that Billy's feet be jn intermittent PINSCONT with the ground.",
        "From the (WANT (NOT myscomr FEET GROUND))) structure, a subsequent ACTION PREDICTION inference can arise, predicting that Mary 'might put an end to (PHYSCONT FEET GROUND).",
        "This _pill in turn requilea her to be located near Billy, and that prediction will matCh the RESULTATIVE inference made from her directed running (the next utterance input), knifing the two thoughts together.",
        "5.9 CLASS 11: KNOWLEDGE PROPAGATION INFERENCES PRINCIPLE:Based on what the CM knows an actor to know, it can often infer other knowledge which must also be available to the actor.",
        "Since most conceptual inferences involve the intentions .of actors, this modeling of ,knowledge is crucial.",
        "EXAMPLES:**John saw Mary beating Pete with a baseball bat.",
        "(inherence) Joh4 probably knew that Pete was getting'hUrt.",
        "**Betty asked Bill for the aspitin.",
        "(inference) Bill probably surmised that Betty wasnit feeling well."
      ]
    },
    {
      "heading": "DISCUSSION:",
      "text": [
        "Modeling the knowledge of potential actors is fundamentally difficult.",
        "Yet it is essential, since most all intention/prediction-related inferences must be based in part on guesses about what knowledge each actor has available to him at various times.",
        "The CM currently models others' knowledge by \"introspecting\" on its on assuming another person P has access to_ the same kinds of information as the CM, P might be expected, to make some of the same inferences the CM does.",
        "Since the CM presertcs a logical conneetlyity among all its inferred structures (by the REASONS and OFFSPRIY( properties of each structure), after inferences of othef types have arisen from some unit of information U, the CM can return, determine who knew the original fact U, locate U's OFFSPRING (those other memory structures which arose by inference from U)., then infer that p may also be aware of each of the offspring.",
        "As with MOTIVATIONAL inferences (Which rely on the RESULTATIVEinferonces from a structure), KNOWLEDGE PROPAGATION inferences are implemented in the procedure POSTSCAN- which runs after the initial breadth-first inference expansion by the monitor.",
        "Modeling others' knowledge demands a rich knowledge of what is normal in the world.. (\"dOes John Smith know that kissing is a sign.of affection?\").",
        "In fact, all inferences must rely upon default assumptiont;.",
        "about normality, since most of the EMPs .knowledge' (and presumably a. Luman's) exists in the form of general patterns, rather than specific relations among specific concepts and tokens.",
        "The next olass of .inference implements my belief that patterns, just as inferences, should be realized in 'the CM by active programs rathbr than by passive declarative data structures.",
        "5, 10 CLASS 12 : NORMATIVE INFERENCES PRINCIPLE:The QM must make heavy reliance, upon programs whIcaencoue commonsense pattern informatiOn about the modeled world.",
        "When the retrieval of a sought-after unit of inforfttion fails, the relevant normality program should be executed on (pattern applied to) that information to assess its likelihood in the absence of explicit inforMation.. LXAMPLES:'**Does John Smith own a book?",
        "(inference) Probably so; middle'-class business executives normally own books.",
        "**Was John Likely to have been asleep at 3 pm yesterdav2 (inference) Most likely.not, since he has a normal daytime job, and yesterday was avorkday.",
        "DISCUSSION: There are several low-level information retrieval procedures in the CM which search for explicit information units as directed by specific inference molecules.",
        "Such searches are on the basis of form alone, and successes-result in precise matches, while failures are total.",
        "If there were no recourse for such failures, the CM would quickly grind to a halt, being unable to make intelligent assumptions, There must be some more Positive and flexible mechanism to.ameliorate\"syntactid\",lookup failures.",
        "the CM, this ability To Rake intelligent assumptions is implemented by having the low-level loaup procedures defer control to the appropriate normality molecule (N-molecule) which will perform systemmatic tests organized in single-response discrimination nets, to the unlocatable information.",
        "The goal is to arrive at-a terminal node in the.",
        "net where a real number between C and 1 is located.",
        "ii some sequence of tests leads to spch a number, the N-molecule return.it as the assessed likelihood (\"compatibility\".fuzzy logic tetminology (Z1)] f X being true.",
        "Although the test in the N-molecules are themselves discrete, they result in the fuzzy.",
        "compatibility.",
        "The point of course is that the tests can encode quite diverse and very specific heuristics peculiar to each small domain of patterns; For instance, based on known (or N-molecule inferrable.-- one N-molecule can Gall upon' others in its testing process!)",
        "features of either Jobn or the hammer, we would suspect the compatibllity of each of the following four Conjectures.",
        "to form a decreasing sequence:",
        "1.",
        "John Smith owns something.",
        "(very likely, but 'dependent on his age, society in which he lives, etc.)",
        "2 John Smith owns a hammer.",
        "(probably, 'nit potentially related to featuressof John, such as his profession) 3.",
        "John Smith owns a claw hammer with a wooden handle.",
        "(maybe, but again dependent on features of John and models of hammers in general -- i.e., how likely is any given,hammer to hare a claw and wooden handle?)",
        "4.",
        "John Smith owns a 16 oz.",
        "Stanley claw hammer with a steel-reinforced wooden handle and a. tack puller on the claw.",
        "(likelihood is quite low unless the N-molecuie can locate some specific hints, such as that",
        "John usuallbuys good e'quipment', etc.)",
        "A successful N-molecule assessment results in the.",
        "creation of the assessed information as a permanent, explicit memory struture whose STRENGT1i is the assessed compatibility..",
        "This structure is the normative inference.",
        "One is quickly awed by his own ability to rate (wsually quite accurately) commonsense conjecture such as these, and.thc-process seems usually to be quite sensitive to features of the entities involvedthe conjecture.",
        "It is my feeling that important insight& can be gained via a ffiore thorough investigation of the \"normative inference\" process in humans.",
        "Another role of N-molecules is' mentioned in (R1) with respect to the inference-reference cycle I will describe shortly.",
        "Fig.",
        "9 shows the substance of a prototype N-molecule for assessihg dependency structures of the form (0*; P X).",
        "(perl-Ion P owns object X ).",
        "s P a member.",
        "of a pure communal society, or is it an infant?",
        "if so, very unlikely that P 9wns,X otherwise, does X have any distinctlYe conceptual features?",
        "if so).assess each one, form the product.of likelihoods, arid call it M. M will be used at the end to mitigate the likelihood which would normally.be assigned.",
        "is.X living?",
        "if so, is Xperson?",
        "is Pa slave owner: and does X possess characteristics of a slave?",
        "if .so, likelihood is low but non-zero otherwise likelihood is zero otherwise, is X a non-human animal Or a plant?",
        "if so, is X domestic-in P's culture?",
        "if so, does P have a fear of X's or is P allergic to X's of this type?",
        "if so, likelihood i$ low otherwise, liketihood is-moderate otherwise, is X related to actions P. does in any special way?",
        "if so, likeliho,od is 1'ow, but non-zero otherwise, likelihood is near-zero otherwise, does X have a normal function?",
        "if so, does P do actions like this normal function?",
        "(Note here that we nould want tok.at P's profession, and actions commonlu associated with that profession.)",
        "if so, IWelihood is oderately high otherwise, is X a common personal item?-if so, is it s value within P'megns if so, likelihood is high if not, likelihood is low, but non zero otherwise, is X a common household .item?",
        "if so, is P a homeowner?",
        "if so, is X within P's means?",
        "if so, likelihood'is high otherwise, likelihood is moderate otherwise,.",
        "likelihood is-low, but non-zero and so on ... Row we tnigh,tgy.aZoiding whether person P i;405-11 FIGURE 9 The normality-molecule disctimination'network for the pattern (OWNS'P X)."
      ]
    },
    {
      "heading": "5.11 CLASS 13: STATE DURATION INFERENCES",
      "text": [
        "PRINCIPLE:Most interesting states in the world.are transient.",
        "The CM must have the ability to make specific predictions about the-expected (fuzzy) duration of an arbitrary state so that information in the CM can be kept up to date.",
        "EXAMPLES:**John handed Mary the orange peel.",
        "ttomorroW I Mary still holding the orange peel?",
        "(inference) Almost certainly not.",
        "**Rita ate lunch a half hour ago Is she hungry yet?",
        "(inference) Unlikely.",
        "DISCUSSION: Time features of states relate in critical ways to the likelihood those states will be true at some given time.",
        "The thought of a scenario wherein the CM is informed that Mhry is holding an orange peel, then,50 years -later, uses that information in the generation of some other inference is a bit unsettling!",
        "The CM must Simply posess a low-level function whose job it is to predictmOrmal durations of states based on the particulars of the states, and to use that information in marking as \"terminated\" those states whose likelihood has diminished below some threshold.",
        "My conjecture is that a human notices and updates the temporal truth of a ;tate only when he is about to use it in some cognitive activity that most of the transient knowledge in ourheads is out of date Until we again attempt to use it in; say,.some inference.",
        "Accordingly, before using any state information, the CM first filters it.through the STATE DURATION inference process to arrive at In updated estimate of the state's likelihood as a function of its known starting time (its TS feature,.in CD notation-).",
        "iti The implementation of this process in the CM is as follows: an (OUR S ?)",
        "structure is constructed felr the state S whose duration is to be predicted, and this is passed to the NDUR specifir molecule: The NDUR S-molecule applies discrimination tests on features of the objects involved in S. Terminal nodes in we net are duration concepts (typically fuzzy ones), such as #ORDERHOUR, #ORDERYEAR.",
        "If a terminal node can be success fully reached, thus locating such a concept D, the property CHARF (Characteristic time .function) is retrieved from D's property list.CHARF is a step function of STRENGTH vs. the amount of time some state has been i existence (Fig.",
        "10).",
        "From this function a STRENGTH is computed for S and btacomes S's'predicted likelihood.",
        "If the STRENGTH turns out to be mfficiently low, a (TF S now) structure is predictively generated to make S's low likelihood elicit.",
        "The STATE,DURATJON inference thus acts as a cleansing filter on state information which is fed to various other inference processes.",
        "or learned associations, rather than upon-\"logical\" relations such as causation., motivation, and so forth.",
        "In a rough way, we can compare these inferences to the phenomenon of visual imagery which constructs a \"picture\" EXMPLES,:.",
        "of a thdught's surrounding environment.",
        "should be made in abundance.",
        "**Andy's diaper is wet.",
        "5.13 CLASS 16- UTTERANCE INTENT INFERENCES PRINCIPLE:Base4 on the way a thought is communicated (especially the often telling presence or absence of information), inferences can be made about the speaker's reasons for speaking.",
        "EXAMPLES:**Don't eat green gronks.",
        "(inference) Other kinds of gronks are probably edible **Mary threw out the rotten part of the fig.",
        "(inference) She threw it out because it was rotten.",
        "**John was unable to get an aspirin.",
        "(inference) John wanted to get.",
        "an aspirin.",
        "**Rita like the,chair, but it was green.",
        "(Inference) The clasis color is a negative .feature to Rita (or the speaker).",
        "DISCUSSION: I have included this class only to represent the largely unexplored domain ot interences dtawnefrom the way a thought is phrased.",
        "The CM will eventually need an explicit model of conversation, and this model will ,incorporate inferences from this class.",
        "Typical of such inferences are those, which translate the inclusion of referentially superfluous features of an object into an implied causality relation (the fig example), those which infer desire froM failure (the aspirin example) those which infer features of an oxdinary X from features of special kinds of X.",
        "(the gronk example), and so forth.",
        "These issues will lead to a more goal directed-modl than I am currently exploring.",
        "G. Summary of the inference Component I have now sketched 16 inference classes which, I conjecture, lie at the core of the human interence reflex.",
        "The central hypothesis is tnat a Inmuul language comprehender performs more subGonscious computation.",
        "on ileaning structures than any other theory of language compmhension has yet acknowledged.",
        "When the current CM is turned loose, it will often generate ui-wards of 100 inferences from a fairly banal stimulus such as \"John avc'4ar?",
        "the book.\" While most are irrefutible, they.",
        "are for the most part mundane and \"uninterestinr to a.criti'cal human observer, and are, after the fact, \"Iasteful.\" But change the.",
        "context and the hula' becomes salient -- even crucial while the crucial can become irrelevant!",
        "I. can sec no other Liecnanisn.",
        "for exilaining contextual.interhction of information than this sl-ontaneous, -subtionscious groping.",
        "I .sLoul..1 perhaps briefly address the adequacy and applicability of the inference classes in the current model.",
        "There is undouhtedly a number .1.3, 32, 04?)",
        "of eklually interesting inforence crasscs I have ignored or ovei-locked.",
        "but I feel the number is not large, and that other classes will sul:-It to the sain.",
        "sorts of systematization as described nere.",
        "While the ;iecerk.il examples I have used to illustrate the various inferences were not dTawn from any coherent domain such as a \"blocks harld\" (1'1) -- and this is a :ezikness -- I believe the net result (these inference .classes and their control structure) fdll prove central to any restricted domain which involves volitional actors..",
        "It is a current challenge to find such a restricted, yet interestir, domain to which these ideas can he transrlanted and applied in nore 1.-,oal-c!irbcted envirornents.",
        "I .,ant to describe now how two other _important language cok,onents reference and inplicit concept activation -- aid an0 abet the inference reflex. 7.",
        "The Inferenee-Reference Relaxation cycle in Conceptual Memory.",
        "A %.A.A1111.C.allaP.AA;1 1 liv4uLlmly inLopoulu ul 111:-,LanLanvu11sly lucilLiumg the referent (concept or token in memory) of a langua0.construction (noun group, rronoun, etc.).",
        "Yet an attentive listener seldom fmil..; eventually to identify tile intended 'referent, and he will seldom lose information because of the reference delay.",
        "Furthermore, incorrect reference decisions are em:irically few and fill between.",
        "I believe that these .phenomena' are intimately related to the inference reflex.",
        "In the Cl, initial reference attempts are made for concepts and toens from descriptive sets.---cOilections of 'conceptual features Ocancd From an utterance by RiesUeck s conceptual analy.zer (R2).",
        "lig.",
        "11 illustrates the descriptive set for the \"th'e big red Jog who ate the bird.\" Potential memory concepts and token referents arc identified by an intersection scarCh procedure which locates memory objects Whose features satisfy nil the features-of the descriptive set.",
        "Such a searcb hill result in either (a) a unique identification of some memory entity,.",
        "(h) a failure to locate any satisfactory entitle, dr (c) a set of'candidates,,one of which is the probable referent.",
        "Case (a) requires no-decision, but (b) end (c) do In either case, a nol%, possibly temporary token T is created aid, for case (b), T receives as its initial occurrenCe set the descriptive set identic.-ally.",
        "In case (c), where a set of candidates can be locattd, T receives the set of features lying in the intersection of all candidates' occurfenCe sets '(this will be at least the descriptive set).",
        "In either case, the CM then has an internal token, to ,work hith, allowing the conceptual graph in hhi.ch referenCes to it occur to be tentatively integrated into memory.s.-tructures.",
        "Tbe inference reflex I have described then.geherate,s all the vdrious inferences, and eventualliy returns to its quiescent state.",
        "One byprOduct of the inferencing is that-the occurrence set of each memory object involve:2 in the original structures hill emerge hith a possible enhanced-occurren66 set which may contain inferred information sufficient either (1) to identify the temporary token of category (b) above, or (2) to narroh the set df candidate associated with the temporary token of category (c) (hope4",
        "41.1 example of a desoriptive set.",
        "fully to exactly one).",
        "Thus, when the inference reflex has ceased, the CM reapplies the reference intersection algorithms to each unidentified mleri.",
        "to seek out any inference-tldrUied references.",
        "Successful identification& at this point result in the mergill (by the samo structure merger mentioned earlier)' of the temporary token's occurrence set with the identified tokPn's occurrence set, thus preserving all information collected to that point about the temporary token.",
        "(Implicit in the merge operation is the substitution of of all references to the, temporary token by references to.the identified one.)",
        "If, on the other land, the results of inferencing serve only to nacrow the candidate set of case (c.), the occurrence sets of the remaiRing candidates are re-intersected, and if this increases the size of the set) the set is reattached to the temporary toRnv In either case progress has been made.",
        "Now .comes a key point.",
        "It any referents were in fact identified on this second attempt Ouaking.their entire occurrence sets accessible), or if any candidate set decreases.",
        "caused new features to be associated Aith the temporary token, then there is the possibiiity that more inferences (which can make use.of the riewly-accessible.features) cah.be made.",
        "lne (72!",
        "thus reapplies the inference reflex' to all memory structures which were produced on the first pass.",
        "(The monitor is conditioned not to duplicate work already done on the first pass.)",
        "But a potential bnwoduct of the-second pass is further feature generation wnicn can again restrict candidate sets or produce positive identifications.",
        "This inference-reference interaction can proceed tintil no new narrowings or Identifications' occur; hence.the'term \"relaxation cycle.\" fig. 12 illustrates two examples'of this phenomenon which are handled by the current CM, arid Appendix E contains the computer trace of the second example.",
        "more new information, but this time a6out #PETE17 *.)",
        "8.",
        "Word Sense.",
        "Promotion end Implicit Concept Activation in the Conceatual Memory Another Jyproduct of the generation of an abundance of probabilistic conceptual patterns from each input is that many related concepts and tokens implicitly inVolved.in the situation are activated, or \"touched.\" This can be put to use in two ways.",
        "First, implicitly touched concepts can clarify what might otherwise be an utterly opaque Subsequent teference.",
        "If, for instance, someone says (outside of a particular context): \"The nurses were nice\", you will probably inquire \"What nurses?\" If, on the other hana, someone says: \"John was run over by a milk truck.",
        "When he woke up.",
        "the nurses were nice\" you will experience neither doubt about the referents of \"the nurses\", nor surprise at their mention.",
        "I presume that a-subconscious filling-out of the situation \"John was run over by .a milk trucW implicitly activates an entire set of coneptually relevant concepts, \"precharging\" ideas of hospitals and their relation to patients.",
        "Other theories founded more on concept associationism than conceptual inference have suggested that such activation occurs through word-word or concept-concept free associations (see (A2) and (1Q1) for instance).",
        "While these more direct associations play an undoubted role in many language functions, it is my belief that these straight associative phenomena are not fundamentally powerful enough to explain the Rind of language behavio/ underlying the nurse example.",
        "It is more often than not the \"gestalt\" meaning context of an utterance which restricts the kinds of meaningful associations a human makes.",
        "In contrast to the nurse example above, most people would agree that the reference to \"the nurses\" in the folrowing situation is a bit peculiar: In the dark of the night, John had wallowed through the knee-deep mud to the north wall of the deserted animal hospital.",
        "The nurses were nice.",
        "A simple hospital-nurses association model cannot account tor this.",
        "on the other hand, those concepts tduched by the more.",
        "restrictive conceptual inference patterns would presumably be quite distant from the medical staff of a hospital in this example, thus explaining the incongruity.",
        "Related to this idea of concept activation through conceptual inference Structures is another mechanism which, I presume, underlies a camprehenders' ability to select (almost unerringly) the proper senses of words in context dpring the linguistic analysis of each utterance.",
        "This mechanism is frequently called word sense prombtion, and its exact nature is one of the major conundrums of language analysis.",
        "It underlies our ability to avoid -- almost totally -- backing up to reinterpret words.",
        "It is as though at each moment during our comprehension we possess a dynamically shifting predisposition toward a unique sense of just about any word we are likely to hear next.",
        "Fig.",
        "13 cdntaans some illustrations of this phenomenon.",
        "I have only a thought (which I plan to develop) on this issue.",
        "At each instant in the CM, there is a powerful inference momentum which is the product of conceptual inferences.",
        "-Obviously, these concepts which the inference patterns touch ulll correspond to senses of words.",
        "These senses can be \"promoted\" in the same way implicit activation promotes certain referents.",
        "This is a partial explanation or word sense promotion.",
        "Suppose, however; that in additiop the CM had an independent parallel process whirl, took each inference as it arose and.",
        "mapped it back into a near language \"proto-sentence\", a linear sequence of concepts which is almost a sentence of the language, except that the actual word realizates of each concept have not yet been chosen.",
        "In other words, a generation process (see (Cl) for example) would be applied to each inference, but would be stopped short of the final lexical substitutions of word senses.",
        "By precnarging all the senses of the various words which could be substituted in such a proto-sentence, the CM would, have a word sense \"set\" which would be a function of the kind of restrictive inferential context which I feel is so vital to the process of analysis.",
        "This.",
        ".idea is obviously computationally exorbitant, but it might model a very real mechanism.",
        "We often catch ourselves subvocalizing what we expect to hear next (especially while listening to an annoyingly slow speaker), and this is tantalizing evidence that something like a proto-sentence generator is thrashing about upstairs.",
        "versus (CONTEXT) John was looking forward to getting high (SENSE) The grass smellea good.",
        "EXAMPLE 3: (Riesbeck's example (R2)) John went on a hunting trip.shot two bucks.",
        "It was all he had: FIGURE 13a Examples of word sense promotion.",
        "pro;to-sentencesconcep tua I which are the various Ways each inference might be expressedstructures by languageA These involve many alternative word senses-.back into prb to-sentences Mapping inferences back into proto-sentences, activating many word senses.",
        "FIGURE 13b Mapping inferences back into proto-sentences, activating many word senses.",
        "worA 'senses are prefered by ttle analyzer the partial generator runs independently from the memoru"
      ]
    },
    {
      "heading": "PARTIAL CONCEPTUAL GENERATOR :ND",
      "text": []
    },
    {
      "heading": "9. Conclusion",
      "text": [
        "Any theory of.Ianguage must also be a theory of inference and memory.",
        "It does not appear to be possible to \"understand': even the simplest of utterances in a contextually meaningful way in a system in which language fails to interact with a language-free belief system, or in a system which lacks a spontaneous inference reflex.",
        "One very important theoretical issue concerns exactly how much \"infereace energy\" is expended.before the fact (prediction, expectation) versus how much is expepded after the fact to clear up specific problems of how the utterance fits the context.",
        "My belief is that there is a great deal of exployatory, essentially undirected inferencing which is frequently overlooked and which cannot be repressed because it is the language-related manifestation of the much broader motivational structure of the brain.",
        "Rather than argue at an unsubstantiatable neurophysiological level, I have compiled evidence for this hypothesis within the domain of language.",
        "I believe, however, that spontaneity of inference pervades all other modes of perception as well, and that quantity as much as quality -- of spontaneous inference is a necessary requirement for general intelligence."
      ]
    },
    {
      "heading": "5 1 APPENDIX A: CAUSAL _CHAIN EXPANSION d'OMPUTER EXAMPLE",
      "text": [
        "WORKING.",
        "\"FORWARD\", GENERATING RESULTAIIVE INFERENCES FROM THE PROPEL UNDERLYINn \"HIT\":(CONTEKI) Bill swiped Mary' S book.",
        "(CAUSAL) Mary kissed JOhn because he hit Bill.",
        "*John propelled his hand toward Bill resultative 1 *John's hand came into physical contact with Bill resultative i *Because it was.propelled, the physical contact was probably resultative 1forceful *Bill probably suffered a negative change in physical state resu I tat i ve i *Because Bill suffered a negative.change., and Mary felt resul_tative Ia negative emotion toward Bill at tke time, Mary might 'have exper'renced a positive change in joy",
        "This is the'partially integrated memory structure, alter references have been established.",
        "No reference ambiguity is asunied.to exist for this example.",
        "C0035 is the resuj Ong me'mory.structure for this utterancp.",
        "We suppress all but this strUcture on the starting inference queue.",
        "(-We wi'l be seeing 'about one, fpurth of the original trace output fgp this example) Here, the CAUSE inference molecu.le Is injecting the two subconceptuallz?tions, A and B in Fig, 1into the.",
        "inference stream."
      ]
    },
    {
      "heading": "STARTING INFERENCE QUEUE: ((X 1.0 C0035).) ABOUT TO APPLY oLAubti lu.00035 C0035: (CAUSE (CAUSE (*PROREL* #JOHN1",
      "text": [
        "The causal structure of this conceptual 'zatid'n indicated that a path should.be found relatina strgcture C to structure 0 in Fig. 1 This is noted.. C0024 corresponds to C, Leo32 to O.",
        "Here, the causative inference that Mary's kissing was probably caused by her feeling a 'positive emotion toward-John As made.",
        "Because the PHYSCONT of John' hand and.",
        "Bill was caused by a PROPEL, MEMORY' here makes the inference that it was a forceful contact.",
        "Here, because nary was feeling a negative emotion toward Bill at the time, when Bill underwent a small NEGCHANGE; the prediction can be made that Meru mau%have experienced a degree of joy.",
        "Looking back the causal path which lead to Mary's likely change in joy, the FOSCHANGE inference molecule.",
        "discovers that it.was an action on John's part which was most directly respontible for her joy.",
        "The'inference that Mary might have started feeling a positive emotion toward John is made.",
        "As this last inference is pada, the inference evaluator notices that the same information exists elsewhere in the memory.",
        "This is a point of contact in inference space.",
        "It dis furthermore noticed that the two MFEEL structures join a causal path bdtween two.strucures which have been related causally-by language.",
        "The two MFEEL structures are merged into one, and this event i. noted as a causal chain eXpansion.",
        "To the left, .C868 and C0033 are the contact points, C0024riand C0032 are the two structures which have now been causally related."
      ]
    },
    {
      "heading": "CAUSAL EXPANSION ACHIEVED:",
      "text": [
        "Inference proceeds, and fjnally stops.",
        "At that point, we took a look at the structures lyin9 along this explained causal path.",
        "C0024 is the original PROPEL structure, C0032 is the PHYbCONT-lips str:ucture.",
        "The service function-CAUSAL_PATH will track down the causaJ linkage for %us.",
        "The causal chain consists of .the six structures to the left.",
        "This is the original PROPEL.",
        "Ouring the process, but not shown, C0048 was detected as unspecified: and filled ih:as John's hand.",
        "Notice on.",
        "the REASONS and OFFSPRING sels the results uP other inferencing which was not discussed above."
      ]
    },
    {
      "heading": "OFFSPRING:",
      "text": [
        "Here is the FOKECONT which was inferred from the PROPEL.",
        "This is Bill's likely (smalr) change in PSTATE which resulted frOm'the FORCECONT.",
        "This is ihe imp3rtant inference that Bill's NEGCHANGE may have cause a small I degree of happiness n.Mary.",
        "Notice that one .of the REASONS was assumed to be the case beforehand-(10137).",
        "Here, Mary is feeling a positive.",
        "emotion toward John, whose action indirectly caused her joy.",
        "This structure is the point of contact, and is the structure which resulted from the merge.",
        "Nptice that its STRENGTH has assumed the higher.STRENGTH of the two structures which were merged.",
        "This is the original PHYSCONT-lips structure which lead, Via a causative inference to the prediction that Mary may have felt a positive emotion toward John.",
        "This WANT is a prediction that one reason Mary my have kissed John is so that he would know she felt .a positive emotion toward him.",
        "This MLOC represents the inference that John probably now knows that Mary MFEELS a Positive emotion toward him."
      ]
    },
    {
      "heading": "APPENDIX B INFERENCEREFERENCE RELAXATION CYCLE. COMPUTER EXAMPLE",
      "text": [
        "This computer example illustrates reference-inference, reference-inference interaction (two inference passes).",
        "Hearing the input \"Bill saw John kiss Jenny.\", MEMORY is unable to decide upon the referent of \"Jenny\": it could be Jenny Jones or Jenny Smith.",
        "MEMORY therefore creates a temporary token having as features all the common features of Jenny Jones and Jenny Smith.",
        "By inference, MEMORY is able to decide upon Jenny Jones.",
        "At that point, the temporary token is merged int0 the concept for Jenny Jones, and a second pass at inferencing is initiated.",
        "However, on the second pass a new inference arises: because Bill loves Jenny Jones, and he saw John kiss her, he (probably) became angry at John.",
        "This inference was not triggered on the first inference pass because being loved by Bill was not a common feature of both Jennys, and hence not accessible then (ie.",
        "it had not been copied to the temporary token's occurrence set).",
        "The example begins with a few lines to set the scene for MEMORY.",
        "lnferencing on these setup lines (which is normally spontaneous) has been suppressed for the sake of simplicity in this example."
      ]
    },
    {
      "heading": "JOHN WAS IN PALO ALTO YESTERDAY ((IOC* (#JOHN1) (PPALOALTO)) (TIME(C0001) ) ) COM JENNY JONES WAS IN PALO ALTO YESTERDAY ((*LOC* (gJEWIY2) (#PALOALTO))",
      "text": []
    },
    {
      "heading": "CONS",
      "text": [
        "This example illustrates referenceinference, reference-inference,, interaction.",
        "That is, MEMORY is unable to establish a reference, so it creates a temporary token, and proceeds.",
        "with.",
        "inference; Inferencing generates new information.",
        "which solves the 'reference, so more inferencing can be undertaken.",
        "However, because features of the referent are accessible.on the second inference Pass.",
        "ne.LJ inferences are possible.",
        "To the left, MEMORY is reading in some",
        "information whiqth is relevant to this demonstration.",
        "Each of these inputs would normally produce inferences as it is processed, but inferenOng has been suppressed for the first four' sentences of thiS eAample.",
        "The four sentences are shown with their partial integrations and final structures.",
        ": C0002, C0005, C0008, C001-The synopsis of this short plot is as follows: There are, two Jennys: Jenny Jones and Jenny Smith.",
        "Bill loves Jenny Jones, John and Jenny Jones were in Palo Alto yestIday, Jenny Smith was in France yesterday.",
        "The .",
        "limax.comes when Bill sees John kiss Jenng.",
        "It is MEMORY's job to figure out which Jenny.",
        "MEMORY wirl decide upon Jenny Jones, then re-inference and infer that Bill probably got, angry at John something which wouldn't have.happqned if Bill had seen John kiss Jenny Smith.'",
        "To the left, the climax line is in the process of being read and internalized.",
        "Its final structure is C0031.",
        "Notice that C0015 was created to stand for some .Jenny, and that all common 'features of the two Jenny candidates were cooled to it.",
        "We interrupt MEMORY el, this point to have allot* at 'the two,Jennys and C0015, the token representing one of these Jennys.",
        "This is the person named Jenny who Bigi sai., yesterday, and who John kissed.",
        "C0012 is the token representing John's lips, which were in *PHYSCONT* with this person named Jenny (C0015) at time C0011.",
        "#JENNY1: STARTING.",
        "INFERENCE QUEUE: ((X 1.0 C0031) (X 1.0 D0017)",
        "a person, 'and that ',As name is Jenny.",
        "these wiJI not be of use in this example.",
        "All other subpropositrons have been suppressed from the starting inference queue for' this example, One inference from Bill's seeing this event is that he knows that the event occurred.",
        "That )s, the event went from his eyes to his conscious processor, C0021.",
        "To the left, the inference that Bill knows about John's kissing Jenny is being generated: information in Bill's CP (C0021) will also enter his LTM, C0040.",
        "This fact 011 'be of use during .th second pass of'inferenci.ng (after MEMORY decides that C0015 is Jenny Jonei).",
        "Another inference arises from John's lips being in PHYSCONT with C0015: that John feels a positive emotion toward C0015.",
        "The structure representing this inference is C0049.",
        "Another inference from John's kissing action is that C0015 knows that John feels 6,positive emotion toward C0016, C0051 is C0015's LTM.",
        "This inference will be of no direct conseouenCe in this example.",
        "MEMORY also infers from John'.s kissing C0015 that John and C0016.had the same location at the event time, C0011 (yesterday).",
        "Since MEMORY knows that John was in Palo Alto, and has no informatioh concerning C0015's location yesterday, MEMORY infers that C0015 was also in Palo Alto,yesterday.",
        "This information wilt,.",
        "solve the reference ambigu4ty.",
        "During the,postscan interencing, the fact that Bill saw JOhn kiss C0015 leads to the inference that.",
        "Bill knows that John feels a positive emotion toward 10015.",
        "This inference type implements the pr'i3Ociple that if a.perton knows X, he also is.likely also to know the inferences which .can.be drawn from X.",
        "That is, MEMORY assumes that other people possess the same inference powers.MEMORY does."
      ]
    },
    {
      "heading": "APPLYING 1NPOMOLECULE *PHYSCOW* TO C0026: (*PHYSCONT* C0012 C0015) ABOUT TO APPLY oPHYSCONT1 TO C0026 INFERRING: (*MFEEL* #JOHN1 #POSEMOTION.",
      "text": [
        "yesterday (C0011).",
        "0076 reprgeents Bill's knoUledge of C0015's location yesterday (but has no direct relevance to.",
        "this 'example).",
        "Notice that the reasons for MEMORY believing that C0015 was in.PaLo Alto at time C0011 are twofold: that John was in Palo Alto at that time,' and that a body part of John was In PHYSCONT.with C0015 then.",
        "We also examine the structure which represents the inference that Bill knbws.",
        "that John feels a positive emotion toward C0015.",
        "This information will come into play after C0015's identity is solved (on the second inference pass).",
        "1.0087 indicates when Bill started knowing this fact (C0040 is his LTM).",
        "The first pass of inferencing is now finished.",
        "We allow MEMORY to proceed.",
        "It notices that areference decision is pending, and attempts to decide between #JENNY1 and #JENNY2 as the referent of MIS bu using newly-inferred information aaut C0015 (from the fir$t pass).",
        "It sUcceeds,.",
        "because #JENNY2 was known to be in Palo Alto yesterday, and this matches new C0015 information, C01356.",
        "MEMORY merges C0015 into #JENNY2, purging old inforpation which is not used to augment #JENNY2.",
        "Recall that the merge replaces occurrence set pointers, so.that every.",
        "MEMORY structure which referenced C0015 now references #JENNY2.",
        "We have another look at #JENNY2 before the second inference pass begins.",
        "MEMORY,begins the second, pass of inferencing.",
        "This conststs.gf subjecting each infere6ce which arose from the first pass to iMerence again.",
        "The,ISEEN prOperty prevents duplication Of inferences during second and subsequent passes.",
        "One new inference which was not possible on the first'pass is That Bill probably became angry at John'.",
        "This inference arises from Bill's knowing that John feels a positive emotion toward #JENNY2, someone.Bill loves.",
        "C0119 ii the structure representing Bill's Incipient anger toward John.",
        "The crucial pojnt is that this inference became possible only after,#JENNY2's features became avatlable.after a'reference decision, which was in'turn'made possible through first pass inferencir,g.",
        "RE-INFERRING...",
        "Finally, we have a look at this second pass inferenqe.",
        "C0121 represents the cause of Bill's anger as being C0086, his knowing about the kissing event.",
        "C0049.",
        "Notice the reasons MEMORY believes that Bill became angru at John:.",
        "he knew John kissed #JENNY2 (this' structure is C0049), and he loves #JENNY2."
      ]
    },
    {
      "heading": "REFERENCES",
      "text": []
    }
  ]
}
