{
  "info": {
    "authors": [
      "Peter F. Brown",
      "John Cocke",
      "Stephen A. Della Pietra",
      "Vincent J. Della Pietra",
      "Frederick Jelinek",
      "Robert L. Mercer",
      "Paul S. Roossin"
    ],
    "book": "International Conference on Computational Linguistics",
    "id": "acl-C88-1016",
    "title": "A Statistical Approach to Language Translation",
    "url": "https://aclweb.org/anthology/C88-1016",
    "year": 1988
  },
  "references": [
    "acl-C86-1033"
  ],
  "sections": [
    {
      "heading": "ABSTRACT",
      "text": [
        "An approach to automatic translation is outlined that utilizes techniques of statistical information extraction from large data bases.",
        "The method is based on the availability of pairs of large corresponding texts that are translations of each other.",
        "In our case, the texts are in English and French.",
        "Fundamental to the technique is a complex glossary of correspondence of fixed locutions, 'the steps of the proposed translation process are: (1) Partition the source text into a set of fixed locutions.",
        "(2) Use the glossary plus contextual information to select the corresponding set of fixed locutions into a sequence forming the target sentence.",
        "(3) Arrange the words of the tat get fixed locutions into a sequence forming the target sentence.",
        "We have developed statistical techniques facilitating both the automatac creation of the glossary, and the performance of the three translation steps, all on the basis of an alignment of corresponding sentences in the two texts.",
        "While we are not yet able to provide examples of French / English translation, we present some encouraging intermediate results concerning glossary creation and the arrangement of target word seq itences."
      ]
    },
    {
      "heading": "1. INTRODUCTION",
      "text": [
        "In this paper we will outline an approach to automatic translation that utilizes techniques of statistical information extraction from large data bases.",
        "These self-organizing techniques have proven successful in the field of automatic speech recognition [1,2,3].",
        "Statistical approaches have also been used recently in lexicography Wand natural language processing [3,5,6].",
        "The idea of autontatic translation by statistical (information theoretic) methods was proposed many years ago by Warren Weaver 171.",
        "As will be seen in the body of the paper, the suggested technique is based on the availability of pairs of large corresponding texts that are translations of each other.",
        "In particular, we have chosen to work with the English and French languages because we were able to obtain the bilingual Hansard corpus of proceedings of the Canadian parliament containing 30 million words of text [8].",
        "We also prefer to apply our ideas initially to two languages whose word order is similar, a condition that French and English satisfy.",
        "Our approach eschews the use of an intermediate mechanism (language) that would encode the \"meaning\" of the source text.",
        "The proposal will seem especially radical since very little will be said about employment of conventional grammars.",
        "This omission, however, is not essential, and may only reflect our relative lack of tools as well as our uncertainty about the degree of grammar sophistication required.",
        "We are keeping an open mind!",
        "In what follows we will not be able to give actual results of French / English translation: our less than a year old project is not far enough along.",
        "Rather, we will outline our current thinking, sketch certain techniques, and substantiate our optimism by presenting some intermediate quantitative data.",
        "We wrote this somewhat speculative paper hoping to stimulate interest in applications of statistics to translation and to seek cooperation in achieving this difficult task."
      ]
    },
    {
      "heading": "2. A HEURISTIC OUTLINE, OF THE BASIC PHILOSOPHY",
      "text": [
        "Figure I juxtaposes a rather typical pair of corresponding English and French sentences, as they appear in the Hansard corpus.",
        "They are arranged graphically so as to make evident that (a) the literal word order is on the whole preserved, (b) the clausal (and perhaps phrasal) structure is preserved, and (c) the sentence pairs contain stretches of essentially literal correspondence interrupted by fixed locutions.",
        "In the latter category are I I rise on jc souleve 'affecting = a propos], and Ione which reflects o n = pour mettre en dome].",
        "It can thus he argued that translation ought to be based on a complex glossary of correspondence of fixed locutions.",
        "Included would he single words as well as phrases consisting of contiguous or non-contiguous words.",
        "E.g., sword = mot [word = propose.",
        "[not = ne ... pas no = ne past [seat belt = cei inure I ate = a mange] and even (perhaps) lone which reflects on = pour mettre en doute), etc.",
        "( ) Partition the source text into a set of fixed locutions,",
        "(2) Use the glossary plus contextual information to select the corresponding set of fixed locutions in the target language.",
        "(3) Arrange the words of the target fixed locutions into a sequence that forms the target sentence.",
        "This naive approach forms the basis of our work.",
        "In fact, we have developed statistical techniques facilitating the creation of the glossary, and the performance of the three translation steps.",
        "While the only way to refute the many weighty objections to our ideas would be to construct a machine that actually carries out satisfactory translation, some mitigating comments are in order.",
        "We do not hope to partition uniquely the source sentence into locutions.",
        "In most cases, many partitions will be possible, each having a probability attached to it.",
        "Whether \"affecting\" is to be translated as \"a propos\" or \"coneernant,\" or, as our dictionary has it, \"touchant\" or \"emouvant,\" or in a variety of other ways, depends on the rest of the sentence.",
        "However, a statistical indication may be obtained from the presence or absence of particular guide words in that sentence.",
        "The statistical technique of decision trees [9] can he used to determine the guide word set, and to estimate the probability to be attached to each possible translate.",
        "The sequential arrangement of target words obtained from the glossary may depend on an analysis of the source sentence.",
        "For instance, clause correspondence may he insisted upon, in which case only permutations of words which originate in the same source clause would be possible.",
        "Furthermore, the character of the source clause may affect the probability of use of certain function words in the target clause.",
        "There is, of course, nothing to prevent the use of more detailed information about the structure of the parse of the source sentence.",
        "However, preliminary experiments presented below indicate that only a very crude grammar may be needed (see Section 6).",
        "the words of the corresponding English sentence, each of its words being equally likely.",
        "Step 2 of the above algorithm then must be changed to 2'.",
        "Find the Jth occurrence of the word./ in the French text.",
        "Let it take place in the Kth sentence, and let the Kth English sentence consist of words e,,, ey Then increment the counters C(e„, f ), C(e,„ f ), f) by the fraction 1 /n.",
        "This second approach is based on the faith that in a large corpus, the frequency of occurrence of true translates of f in corresponding English sentences would overwhelm that of other candidates whose appearance in those sentences is accidental.",
        "This belief is obviously flawed.",
        "In particular, the article \"the\" would get the highest count since it would appear multiply in practically every English sentence, and similar problems would exist with other function words as well.",
        "What needs to be done is to introduce some sort of normalization that would appropriately discount for the expected frequency of occurrence of words.",
        "Let P(e,) denote the probability (based on the above procedure) that the word e, is a translate of a randomly chosen French-word.",
        "P(e) is given by"
      ]
    },
    {
      "heading": "3. CREATING THE GLOSSARY,'FIRST ATTEMPT",
      "text": [
        "We have already indicated in the previous section why creating a glossary is not just a matter of copying some currently available dictionary into the computer.",
        "In fact, in the paired sentences of Figure I, \"affecting\" was translated as \"a propos,\" a correspondence that is not ordinarily available.",
        "Laying aside for the time being the desirability of (idiomatic) word cluster - to word cluster translation, what we are'after at first is to find for each word f in the (French) source language the list of words fe,, e2, e,i of the (English) target language into which f can translate, and the probability P(e, f) that such a translation takes place.",
        "A first approach to a solution that takes advantage of a large data base of paired sentences (referred to as 'training text') may be as follows.",
        "Suppose for a moment that in every French / English sentence pair each French word f translates into one and only one English word e , and that this word is somehow revealed to the computer.. Then we could proceed by:' I .",
        "Establish a counter C(e„ f) for each word e, of the English vocabulary.",
        "Initially set C(e„ f) = 0 for words e,.",
        "Set J = I.",
        "2.",
        "Find the Jth occurrence of the word fin the French text.",
        "Let it take place in the Kth sentence, and let its translate be the qth word in the Kth English sentence E = An.",
        "Then increment by 1 the counter C(e,,,, f ).",
        "3.",
        "Increase J by 1 and repeat steps 2 and 3.",
        "Setting M(f) ) equal to the sum of all the counters C(e„ f) at the conclusion of the above operation (in fact, it is easy to see that M(f) ) is the number of occurrences of f in the total French text), we could then estimate the probability P(e, f) of translating the word f by the word e, by the fraction C(e, f )/ M(f ).",
        "The problem with the above approach is that it relies on correct identification of the translates of French words, i.e., on the solution of a significant part of the translation problem.",
        "In the absence of such identification, the obvious recourse is to profess complete ignorance, beyond knowing that the translate is one of where M is the total length of the French text, and M(P) is the number of occurrences of f in that text (as before).",
        "The fraction P(e, f) / P(e,) is an indicator of the strength of association of e, with f, since P(e,I f) is normalized by the frequency P(e,) of associating e, with an average word.",
        "Thus it is reasonable to consider e, a likely translate off if P(e, I f) is sufficiently large.",
        "The above normalization may seem arbitrary, but it has a sound underpinning from the field of Information Theory [10].",
        "In fact, the quantity",
        "is the mutual information between the French word f and the English word e,.",
        "Unfortunately, while normalization yields ordered lists of likely English word translates of French words, it does not provide us with the desired probability values.",
        "Furthermore, we get no guidance as to the size of a threshold T such that e, would be a candidate translate of f if and only if",
        "Various ad hoc modifications exist to circumvent the two problems.",
        "One might, for instance, find the pair e„ f with the highest mutual information, eliminate e, and f from all corresponding sentences in which they occur (i.e. decide once and for all that in those sentences e, is the translate of f !",
        "), then recompute all the quantities over the shortened texts, determine the new maximizing pair e,', f and continue the process until some arbitrary stopping rule is invoked.",
        "Before the next section introduces a better approach that yields probabilities, we present in Figure 2 a list of high mutual (3.2)",
        "information English words for some selected French words.",
        "'The reader will agree that even the flawed technique is quite powerful."
      ]
    },
    {
      "heading": "A SIMPLE GLOSSARY BASED ON A MODEL OF \"THE TRANSLATION PROCESS",
      "text": [
        "We will now revert to our original ambition of deriving probabilities of translation, P(e, I f ).",
        "Let us start by observing that the algorithm of the previous section has the following flaw: Should it be \"decided\" that the qth word, e, , of the English sentence is the translate of the rth word, 4, of the French sentence, that process makes no provision for removing e, from consideration as a candidate translate of any of the remaining French words (those not in the rth position)!",
        "We need to find a method to decide (probabilistically !)",
        "which English word was general ed by which French one, and then estimate P(e,.",
        "f) by the relative frequency with which f gave rise to e, as \"observed\" in the texts of paired French / English sentence translates.",
        "Our procedure will be based on a model (an admittedly crude one) of how English words arc generated from their French counterparts.",
        "With a slight additional refinement to be specified in the next section (see the discussion on position distortion), the following model will do the trick.",
        "Augment the English vocabulary by the word eo that leaves no trace in the English text.",
        "Then each French word f will produce exactly one 'primary' English word (which may be, however, invisible).",
        "Furthermore, primary English words can produce a number of secondary ones.",
        "'the provisions for the null word and for the production of secondary words will account for the unequal length of corresponding French and English sentences.",
        "It would be expected that some (but not all) French function words would be killed by producing null words, and that English ones would be created by secondary production.",
        "In particular, in the example of Figure 1, one would expect that \"reflects\" would generate both \"which\" and \"on\" by secondary production, and \"rise\" would similarly generate \"on.\" On the other hand, the article \"I\"' of \"I'Oratkur\" and the preposition \"a\" of \"a propos\" would both be expected to generate a null word in the primary process.",
        "This model of generation of English words from French ones then requires the specification of the following quantities: .",
        "The probabilities P(e, I f) that the ith word of the English dictionary was generated by the French word f.",
        "2.",
        "The probabilities Wei I e,) that the jth English word is generated from the ith one in a secondary generation process.",
        "3.",
        "The probabilities R (k I e) that the ith English word generates exactly k other words in the secondary process.",
        "By convention, we set R(0 I e0) = 1 to assure that the null word does not generate • any other words.",
        "The model probability that the word !",
        "generates e, in the primary process, and in the secondary one, is equal to the product P(eil II) R(k – 1 I eid Q(ei2 I eid Q(e,3 I eid Q(e,,, I eii) (4.1) Given a pair of English and French sentences E and F, by the term generation pattern $ we understand the specification of which English words were generated from which French ones, and which`secondary words from which primary ones.",
        "Therefore, the probability P(E,$ I F) of generating the words of E in a pattern $ from those of F is given simply by a product of factors like (4.1), one for each French word.",
        "We can then think of estimating the probabilities P(e, I f ), R(k I e), and Q(e, I e) by the following algorithm at the start of which all counters are set to 0:",
        "1.",
        "For a sentence pair E,F of the texts, find that pattern $ that gives the maximal value of P(E,$ F), and then make the (somewhat impulsive) decision that that pattern $ actually took place.",
        "2.",
        "If in the pattern $, f 'gave rise to e„ augment counter CP(e„ f) by 1; if e, gave rise to k secondary English words, augment counter CR(k, e) by 1; if e, is any (secondary) word that was given rise to by e„ augment counter CQ(ei, e,) by 1.",
        "3.",
        "Carry out steps I and 2 for all sentence pairs of the training text.",
        "4.",
        "Estimate the model probabilities by normalizing the corresponding counters, i.e.,",
        "The problem with the above algorithm is that it is circular: in order to evaluate P(E,$ I F) one needs to know the probabilities P(e,I f ), R(k I e,), and Q(e, I e) in the first place!",
        "Fortunately, the difficulty can be alleviated by use of iterative re-estimation, which is a technique that starts out by guessing the values of unknown quantities and gradually readjusts them so as to account better and better for given data [11].",
        "More precisely, given any specification of the probabilities P(e, I f ), R(k I e), and Weil e,) , we compute the probabilities P(E,$ I F) needed in step I, and after carrying out step 4, we use the freshly obtained probabilities P(e,I f ), R(k I e), and Q(e, I e,) to repeat the process from step I again, etc.",
        "We halt the computation when the obtained estimates stop changing from iteration to iteration.",
        "While it can be shown that the probability estimates obtained in the above process will converge 111,121, it cannot be proven that the values obtained will be the desired ones.",
        "A heuristic argument can be formulated making it plausible that a more complex but computationally excessive version [13] will succeed.",
        "Its truncated modification leads to a glossary that seems a very satisfactory one.",
        "We present some interesting examples of its P(e, I f) entries in Figure 3.",
        "Two important aspects of this process have not yet been dealt with: the initial selection of values of P(e; I f ), R(k I e,) , and Q(e, I e), and a method of finding the pattern $ maximizing p(E,S I F).",
        "A good starting point is as follows: A.",
        "Make Q(ei I e,) = 1/K, where K is the size of the English vocabulary.",
        "B.",
        "Let R (1 1 e,) = 0.8 , R(01 e;) = 0.1, R (210 = R(310 = R(4 1 e,) = R(51 e,) = 0.025 for all words e, except the null word e0.",
        "Let R(01e0) = 1.0.",
        "C. To determine the initial distribution P(e; l f ) proceed as follows: (i) Estimate first P(e, 1 f) by the algorithm of Section 3.",
        "(ii) Compute the mutual information values 1(e,; f) by formula (3.2), and for each f find the 20 words e, for which 1(e,; f) is largest.",
        "(iii) Let \"(elf) = P(e, If ) = ( I /21) - E for all words e, on the list obtained in (ii), where e is some small positive number, Distribute the remaining probability r uniformly over all the ['Audis's words not on the list.",
        "l•inding the maximizing pattern for a given sentence pair E, F well-studied technical problem with a variety of Computationally feasible solutions that are suboptimal in some practically unimportant respects 1141.",
        "Not to interrupt the Bow id intuitive ideas, we omit the discussion of the corresponding lgorit Inns."
      ]
    },
    {
      "heading": "5. TOWARD A COMPLEX GLOSSARY",
      "text": [
        "In the previous section we have introduced a technique that &rives a word - to - word translation glossary.",
        "We will now refine the model to make the probabilities a better reflection of reality, and then outline an approach for including in the glossary the fixed locutions discussed in Section 2.",
        "It should be noted that while English / French translation is quite local (as illustrated by the alignment of Figure 1), the model leading to (4.1) did not take advantage of this affinity of the two languages: the relative position of the word translate pairs in their respective sentences was not taken into account.",
        "If m and n denote the respective lengths of corresponding French and English sentences, then the probability that e, (the kth word in the English sentence) is a primary translate off (the hth word in the Trench sentence) should more accurately be given by the probability P(e,, k I fh, h,m,n) that depends both on word positions and sentence lengths.",
        "To keep the formulation as simple as possible, we can restrict ourselves to the functional form",
        "In (5.1) we make the 'distortion' distribution PD(k I h,m,n) independent of the identity of the words whose positional discrepancy it describes.",
        "- As far as secondary generation is concerned, it is first clear that the production of preceding words differs from that of those that follow.",
        "So the R and Q probabilities should be split into left and right probabilities RI, and QL, and RR and QR.",
        "Furthermore, we should provide the Q probabilities with their own distortion components that would depend on the distance of the secondary word from its primary 'parent'.",
        "As a result of these considerations, the probability that f,, generates (for instance) the primary words and preceding and following secondary words e, would be given by",
        "Obviously, other distortion formulations are possible.",
        "The purpose of any is to sharpen the derivation process by restricting the choice of translates to the positionally likely candidates in the corresponding sentence.",
        "To find fixed locutions in English, we can use the final probabilities QL and QR obtained by the method of the previous section to compute tnutual informations between primary and secondary word pairs,",
        "where P(e') C(e')/ N is the relative frequency of occurrence of the secondary word e in the English text (C(e') denotes the number of occurrences of e' in the text of size N), and QR and QL are the average secondary generation probabilities, and",
        "We cats then establish an experimentally appropriate threshold T, and include in the glossary all pairs (e, e') and (e , e) whose mutual information exceeds T. While the process above results in two-word fixed locutions, longer locutions can he obtained iteratively in the next round after the two-word variety had been included in the glossary and in the formulation of its creation.",
        "To obtain French locutions, one must simply reverse the direction of the translation process, making English and French the source and target languages, respectively.",
        "With two-word locutions present in both the English and French parts of the glossary, it is necessary to reformulate the generation process (4.1).",
        "The change would be minimal if we could decide to treat the words of a locution (f, f') as a single word f* = (f, f') rather than as two separate words f and f' whenever both are found in a sentence.",
        "In such a case nothing more than a recoding of the French text would be required.",
        "However, such a radical step would almost certainly be wrong: it could well connect auxiliaries and participles that were not part of a single past construction.",
        "Clearly then, the choice between separateness and unity should be statistical, with probabilities estimated in the overall glossary construction process and initialized according to the frequencies with which elements of the pair f, f' were associated or not by secondary generation when they appeared in the same sentence.",
        "Since the approach of this section was not yet used to obtain any results, we will leave its complete mathematical specification to a future report."
      ]
    },
    {
      "heading": "6. GENERATION OF TRANSLATED TEXT",
      "text": [
        "We have pointed out in Section 2 that translation can be somewhat ,taively regarded as a three stage process: ( ) Partition the source text into a set of fixed locutions.",
        "(2) Use the glossary plus contextual information to select the corresponding set of fixed locutions in the target language.",
        "(3) Arrange the words of the target fixed locutions into a sequence forming the target sentence.",
        "We, have just finished arguing in Section 5 that the partitioning of source next into locutions is somewhat complex, and that it must be approached statistically.",
        "The basic idea of using contextual information to select the correct 'sense' of a locution is to consti net a contextual glossary based on a probability of the form P(e f, 41-PI ) where e and f are English and French locutions, and ,p111 denotes a 'lexical' equivalence class of the sentence '1'he test of class membership would typically depend on the pi' m;ence of some combination of words in F. The choice of an appropriate equivalence classification scheme would, of course, be subject of research based on yet another statistical formulation, The estimate of P(e I ) would be derived from counts of locution alignments in sentence translate pairs, the alignments being estimated based on non-contextual glossary probabilities of the form (5.2).",
        "The last step in our translation scheme is the rearrangement of the words of the generated English locutions into an appropriate sequence.",
        "To see whether this can be done statistically, we explored what would happen in the impossibly optimistic case where the words generated in (2) were exactly those of the English sentence (only their order would be unknown): From a large English corpus we derived estimates of trigram probabilities, P(e, I et, e2), that the word ei follows immediately the sequence pair e,, e2.",
        "A model of English sentence production based on a trigram estimate would conclude that a sentence e,, e,, e„ is generated with probability"
      ]
    },
    {
      "heading": "REFERENCES",
      "text": [
        "P(ei, e2) P(e3 I el, 02) P(e4 I e2, 03) P(0,I 1) (6.1) 1131 L.E.",
        "Baum: An inequality and associated maximization technique in statistical estimation of probabilistic functions or a Markov process, Inequalities, 3:1-8, 1972.",
        "We then look other English sentences (not included in the training corpus) and determined which of the n !",
        "different arrangements of their n words was most likely, using the formula (6.1).",
        "We found that in 63% of sentences of 10 words or less, the most likely arrangement was the original English sentence.",
        "Furthermore, the most likely arrangement preserved the meaning of the original sentence in 79% of the cases.",
        "Figure 4 shows examples of synonymous and non-synonymous re-arrangernents.",
        "We realize that very little hope exists of the glossary yielding the words and only the words of an English sentence translating the original French one, and that, furthermore, English sentences arc typically longer than 10 words.",
        "Nevertheless, we feel that the above result is a hopeful one for future statistical translation methods incorporating the use of appropriate syntactic structure information.",
        "affecting the rights and prerogatives of parliamentary committees apropos des droits et des prerogatives des comites parlememaires and one which reflects on the word of two ministers et pour mettre en thane les propos de deux ministres of the Crown.",
        "de la Couronne."
      ]
    },
    {
      "heading": "FIGURE 1 ALIGNMENT OF A FRENCII AND ENGLISH SENTENCE PAIR",
      "text": []
    },
    {
      "heading": "EXAMPLES OF RECONSTRUCTION THAT PRESERVE MEANING:",
      "text": [
        "would I report directly to you?",
        "I would report directly to you?",
        "now let me mention some of the disadvantages.",
        "let me mention some of the disadvantages now.",
        "he did this several hours later.",
        "this he did several hours later."
      ]
    },
    {
      "heading": "EXAMPLES OF RECONSTRUCTION THAT DO NOT PRESERVE MEANING",
      "text": [
        "these people have a fairly large rate of turnover.",
        "of these people have a fairly large turnover rate.",
        "in our organization research has two missions.",
        "in our missions research organization has two.",
        "exactly how this might be done is not clear.",
        "clear is not exactly how this might be done."
      ]
    },
    {
      "heading": "FIGURE 4 STATISTICAL ARRANGEMENT OF WORDS BELONGING TO ENGLISH SENTENCES",
      "text": [
        "Note: *** denotes miscellaneous words not belonging to the lexicon."
      ]
    }
  ]
}
