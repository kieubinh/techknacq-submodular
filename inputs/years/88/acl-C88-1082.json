{
  "info": {
    "authors": [
      "Shoichi Matsunaga",
      "Masaki Kohda"
    ],
    "book": "International Conference on Computational Linguistics",
    "id": "acl-C88-1082",
    "title": "Linguistic Processing Using a Dependency Structure Grammar for Speech Recognition and Understanding",
    "url": "https://aclweb.org/anthology/C88-1082",
    "year": 1988
  },
  "references": [],
  "sections": [
    {
      "text": [
        "the i-th phrase recognition results, the following procedure is not carried out.Table 1.",
        "Parsing algorithm <2> The rules whose left term is scanned are such as (Xij)->(x+i ,k)(Xkil j ) After the leftmost derivation is repeated to detect hypotheses for phrase speech recognition, x.1 is detected in the following form.",
        "(Xi4-1,j)->(xii-1)(4+2,h)----(Xk+1,j) Generally, there is more than one (Xill,j), so xi+1 is a set of phrases.",
        "<3> The phrase recognition is carried out for the i1-1-th phrase utterance whose hypotheses are elements of the set <4> If the reliable phrase recognition result was detected in operation <3>, the rules which derived elements of are scanned again and hypotheses for the next utterance are derived using same procedure as <2>.",
        "<5> Theso operations, namely hypotheses derivation and its phonetic verification, are carried out until xj is detected.",
        "<6> The detected phrase sequence Xi,j and its dependency structure Yi,j is passed to the parser.",
        "Durinp, these operations, if the phrase recognition results are unreliable in operation <3>, the detection process of Xi,j is halted and phrase recognition for all hypotheses is carried out.",
        "Although Japanese is a phrase-order-free language, there are some relatively fixed phrase-order parts in a sentence.",
        "These rules are applied to these parts.",
        "The number of hypotheses and the amount of acoustic processing can thus be reduced, maintaining the above characteristics of the dependency structure grammar.",
        "By linking the predictor to the parser, parsing can be accomplished using the dependency structures detected in operation <6> of the prediction procedure.",
        "This linkage method greatly increases parsing speed.",
        "{I} Loop for the end phrase of the partial sequence DO {2} to {5} for j {2} Loop for the candidate DO {3} to {5} for p 1,2,---,Mi {3} Setting the initial value SET S(11x1,p,1) or D(j,xj,p,1) (Eqs.",
        "(7),(8)) If j = 1, go back to {2}.",
        "{4} Loop for the beginning phrase of the partial sequence DO {5} for i = j-1,j-2,---,1 {5} Calculation of reccurence relation < Loop for the end phrase of the former sequence > {5-1} DO {5-2} to {5-4} for k = (5-2) DO {5-3} to {5-4} for q = 1,2,---,Mk < Loop for the beam width > {5-3} DO 15-41 for rl = 1,2,--,L {5-4} DO for r2 = 1,2,---,L *Evaluation of S(1,x1,p,r) or D(j,xj,p,r) taking account of IP i top or Y(Eqs.",
        "(5' ),(6')) *Store of WI Acquisition of the parsing results * Detection of value p maximizing Eq.",
        "(9) * Acquisition of the phrase sequence and its dependency structure using 171,N,p 3.",
        "Speech recognition experiments 3.",
        "1 Speech recognition system",
        "The speech recognition and understanding system is shown in Fig. 7.",
        "The system is composed of acoustic and linguistic processing stages.",
        "The acoustic processing stage consists of a feature extraction part and a phoneme recognition part[101].",
        "The linguistic processing stage consists of a phrase recognition part[11], a parsing part (a dependency relationship analysis part), and a phrase prediction part.",
        "The linguistic processing stage uses a word dictionary, word connection rules for intraphrase syntax, dependency relationships rules and phrase prediction rules.",
        "The word dictionary is composed of pronunciation expressions, parts of speech and case structures.",
        "Dependency relationship rules produce negative evaluation values that are set to the dependency relationAips contrary to case structure discipline.",
        "predictor.",
        "The pre-selection is also carried out using bottom-up phoneme recognition results[12].",
        "Next, top-down phoneme verification is carried out and phrase recognition results are generated.",
        "Phrase recognition results are represented in the form of score matrix with phonetic recognition scores averaged for each hypothesized phrase.",
        "When the end of a sentence is detected, the parser extracts the phrases with the best sentence likelihood by scanning this matrix, and determines the dependency structure of the extracted phrases.",
        "3.",
        "3 Performance The effectiveness of the proposed linguistic processor was tested in speech recognition experiments.",
        "The experiments were carried out using 20 sentences containing 320 phrases uttered by 2 male speakers.",
        "These results are shown in Table 2."
      ]
    },
    {
      "heading": "Abstract",
      "text": [
        "This paper proposes an efficient linguistic processing strategy for speech recognition and understanding using a dependency structure grammar.",
        "The strategy includes parsing and phrase prediction algorithms.",
        "After speech processing and phrase recognition based on phoneme recognition, the parser extracts the sentence with the best likelihood taking account of the phonetic likelihood of phrase candidates and the linguistic likelihood of the semantic inter-phrase dependency relationships.",
        "A fast parsing algorithm using breadth-first search is also proposed.",
        "The predictor preselects the phrase candidates using transition rules combined with a dependency structure to reduce the amount of phonetic processing.",
        "The proposed linguistic processor has been tested through speech recognition experiments.",
        "The experimental results show that it greatly increases the accuracy of speech recognitions, and the breadth-first parsing algorithm and predictor increase processing speed."
      ]
    },
    {
      "heading": "1. Introduction",
      "text": [
        "In conventional continuous speech recognition and understanding systems[ 1 -4] , linguistic rules for sentences composed of phrase sequences are usually expressed by a phrase structure grammar such as a transition network or context free grammar.",
        "In such methods, however, phoneme recognition errors and rejections result in incorrect transition states because of the strong syntactical constraints.",
        "These erroneous transitions cause the following candidates to be incorrectly chosen or the processing system to halt.",
        "Therefore, these errors and rejections can be fatal to speech understanding.",
        "Furthermore, a complete set of these grammatical rules for speech understanding is very difficult to provide.",
        "To address these problems, this paper proposes a new linguistic processor based on a dependency structure grammar, which integrates a bottom-tip sentence parser and a top-down phrase predictor.",
        "This grammar is more semantic and less syntactic than phrase structure grammar, and, therefore, syntactic positional constraint in a sentence rarely occurs with this parser.",
        "This effectively prevents extreme degradation in speech recognition from errors and rejections in phoneme recognition and greatly increases the accuracy of speech processing.",
        "This grammar only has two syntactic rules, so this parser is free of many cumbersome grammatical rules that are indispensable to other grammars.",
        "This grammar particularly suits phrase-order-free languages such as Japanese.",
        "For the parser of this grammar, a depth-first parsing algorithm with backtracking which guarantees the optimal solution was devised[5].",
        "However, parsing long sentences composed of many phrases with this algorithm can be time-consuming because of combinatorial explosion, since the amount of computation is exponential order with respect to the number of phrases.",
        "Therefore, a fast parsing algorithm using breadth-first search and beam search was developed.",
        "This algorithm is based on fundamental algorithms[6,7] which only take account of the dependency relationships of the modifier and modificant phrases, and it handles higher linguistic or semantic processing such as case structure.",
        "The processing ability of this breadth-first algorithm is equivalent to that of the depth-first algorithm.",
        "To effectively recognize speech, the amount of phonetic processing must be reduced through top-down prediction of hypotheses.",
        "However, top-down control using the principal dependency structure is impossible.",
        "To solve this problem, this novel phrase predictor was devised.",
        "This predictor preselects hypotheses for phoneme recognition using prediction rules, and then it reduces the amount of phonetic processing.",
        "Prediction rules are created by integrating connection rules and phrase dependency structures.",
        "The effectiveness of this linguistic processing was ascertained through speech recognition experiments.",
        "2.",
        "Linguistic processor 2.",
        "1 Dependency structure grammar",
        "The proposed parser using the depth-first parsing algorithm increased phrase recognition rate by approximately 20% (from 57% without the parser to 77% with the parser).",
        "This result shows the effectiveness of a parser using a dependency structure grammar.",
        "The processing time with the breadth-first algorithm was reduced to approximately 1% of that with the depth-first algorithm for sentence parsing, while keeping the same level of speech recognition rate as with the depth-first algorithm.",
        "This result shows the great effectiveness of the breadth-first parsing algorithm.",
        "This result is shown in Fig. 8 for each speaker when M is 3 and L is 8.",
        "Next, using 26 rules, the prediction was carried out for 33% of the total input phrases.",
        "It reduced acoustic processing time to 60% at these parts in a sentence, and it increased speech recognition speed.",
        "Finally, linking the predictor to the parser reduced",
        "dep2(Yi,j,p,xj,p) is not evaluated in Eq.",
        "(4).",
        "Using notation S and D, the recurrence relation among the objective functions are derived.",
        "This is shown in Fig. 4.",
        "The recurrence relation are transforms into the following equations using beam search.",
        "where i<k<j-1, Kq<M, and 1<r, r1, r2<L. Here, r, r1 and r2 indicate the rank of beam, L is the maximum number of beams, S(1,xj,p,r) and D(i,xj,p,r) are the r-th value of the element whose phrase sequence is and the dependency structure is Here, rth_max[ I is a function for deriving the r-th best value.",
        "When Eq.",
        "(5') or (6') is calculated, is stored for use in the later stage of evaluating dep2.",
        "Initial values are given as follows.",
        "After calculating the recurrence relation, the value of the objective functions is obtained,",
        "where 1<p<M. The best sentence and its dependency structure are given through Y 1,N,p where p maximizes Eq.",
        "(9).",
        "The parsing table is shown in Fig. 5 and the parsing algorithm is shown in Table 1.",
        "In Fig. 5, the first row corresponds to S, and others correspond to D. The phrase sequence for first to Nth phrase corresponds to the rightmost top cell.",
        "Each cell is composed of ML sub-cells.",
        "Arrows show the sequence of calculating the recurrence relation.",
        "The processing amount order for this algorithm is 0(N3M2L2).",
        "Comparing the theoretical amount of processing for these two parsing algorithms, the breadth-first parsing algorithm clearly requires much less processing than the depth-first parsing algorithm.",
        "The amount of processing for each parsing algorithm is shown in Fig. 6.",
        "2.",
        "3 Predictor To preselect the phrase hypotheses for the speech recognition, the predictor is devised[9], using prediction rules created by integrating connection rules and dependency structures of phrases.",
        "These rules are described with rewriting rules:",
        "regarded as a phrase sequence with a closeddependency-structure.",
        "These rules are described for the sequence, the i-th phrase to j-th phrase modified by the i-th phrase, as )->(xi) (Xj4.1 j ) The hypotheses are predicted as follows.",
        "<1> xi is detected as a reliable phrase recognition result.",
        "If there are no reliable phrase candidates in",
        "parsing time to less than 10% of the time for the depth-first parser, and to approximately 90% of the time for the breadth-first parser.",
        "This shows the usefulness of the linkage.",
        "4.",
        "Breadth-first parsing algorithm for sentence speech recognition The broadth-first parsing algorithm for the sentence speech or connected phrase speech is devised[13] by the same procedure as in section 2.",
        "2.",
        "Based on basic expansion algorithms[14,15] from phrase-wise to sentence speech, the speech recognition and understanding accuracy using the proposed algorithm is greatly increased compared to the accuracies using the basic algorithms.",
        "In the sentence speech, phrase recognition results after phonetic processing are represented in a score lattice form with phonetic recognition scores averaged.",
        "The parser extracts the best sentence composed of a phrase sequence by scanning this lattice.",
        "The processing order is 0(N5M2L2), which is practical amount of computation, where N is the number of detected phrase boundaries in the uttered sentence, M is the maximum number of phonetic recognition candidates for each phrase segment from one boundary to the next boundary, and L is the maximum number of beams.",
        "The effectiveness of this parser was tested through sentence speech recognition with one speaker uttering 10 sentences containing a total of 67 phrases.",
        "This parser increased phrase recognition performance in the sentences by approximately 49% (from 27% without the parser to 76% with the parser)."
      ]
    },
    {
      "heading": "5. Conclusion",
      "text": [
        "This paper proposed an efficient linguistic processing strategy for speech recognition and understanding using a dependency structure grammar.",
        "This grammar suits processing of phrase-order-free languages such as Japanese and processing the result of front-end speech recognition, which is usually erroneous This linguistic processing strategy includes bottom-up parsing and a top-down phrase hypotheses predictor.",
        "In particular, the bottom-up parser, taking account of the phonetic and linguistic likelihood, greatly increases the accuracy and speed of speech recognition.",
        "The predictor reduces the amount of phonetic processing by preselecting the phrase hypotheses.",
        "The effectiveness of this parser and predictor was shown in speech recognition experiments.",
        "Future development is include the statistical likelihood of dependency relationships, integration with the statistical phonetic method like Hidden Markey Models, and higher linguistic processing using the semantics and context knowledge."
      ]
    },
    {
      "heading": "Acknowledgment",
      "text": [
        "The authors would like to express their appreciation to Dr. Kiyoshi Sugiyama and Dr. Sadaoki Furui, for their invaluable guidance.",
        "The authors would also like to thank to Dr. Kiyohiro Shikano and Shigeki Sagayama for their useful suggestions."
      ]
    },
    {
      "heading": "References",
      "text": [
        "the other sentence is unacceptable because arcs cross in its dependency structures."
      ]
    },
    {
      "heading": "2. 2 Parser",
      "text": [
        "After phonetic phrase recognition, recognition results are represented in a phonetic score matrix form as hown in Fig. 2.",
        "When analyzing dependency relationships, the parser extracts the most likely sentence in this matrix by taking into account the phonetic likelihood of phrase candidates and the linguistic likelihood of semantic inter-phrase dependency relationships.",
        "The parser also obtains the dependency structure that corresponds to the semantic structure of the extracted sentence.",
        "2.",
        "2.",
        "1 Objective function This parsing is equivalent to solving the following objective function using the constraints of dependency structure grammar.",
        "For simplicity, the following linguistic formulation is described for speech uttered phrase by phrase.",
        "The process for sentence speech is described in section 4.",
        "where 1SjO, N is the number of input phrases, M is the maximum number of phonetic recognition candidates for each phrase, xj,p is a candidate of the j-th input phrase with the p-th best phonetic likelihood, and c(xj,p) is its phonetic likelihood (positive!",
        "value).",
        "Also, Xi is a phrase sequence with one phrase candidate for each i-th to j-th input phrase and whose last phrase is xj,p.",
        "Yi,j,p is one of the dependency structures of Xi,j,p, wi,j_i is the set of phrases that modify xj,p in the sequence X.",
        "Here dep(w,x1Y) is the linguistic likelihood (negative value) of dependency relationships between w and x taking Y into account.",
        "Namely, the first item of the term on the right in Eq.",
        "(1) is the summation of phonetic likelihoods of the hypothesized sentence composed of its phrase sequence, and the second item is the summation of linguistic likelihood.",
        "Maximizing Eq.",
        "(1) gives the sentence and the dependency structure of it as speech recognition and understanding results.",
        "Because dependency structure grammar is compatible with case grammar[8], the linguistic semantic likelihood(dep) of the dependency structure is easily provided using case structure.",
        "The following are examplee of items for evaluating dependency relationships: the disagreement between the semantic primitives of the modifier and that requested by the modificant, the lack of the obligatory case phrase requested by the modificant, and the existence of different phrases with the same case and modifying the same phrase.",
        "The likelihood values for these items are given heuristically.",
        "To solve equation (1), a fast parsing algorithm using breadth-first search and beam search was developed.",
        "This algorithm deals with higher linguistic or semantic processing such as the case structure.",
        "Although this algorithm offers suboptimal solutions, it is practical because it requires less processing than depth-first search.",
        "2.",
        "2.",
        "2 Oceadth-first parsing algorithm The breadth-first algorithm is formulated as order of candidates",
        "where depl is the likelihood associated with dependency relationships of only the modifier and modificant phrases, and dep2 is the likelihood associated with Yi,j,p.",
        "An example of dependency relationships is shown in Fig. 3.",
        "Eqs.",
        "(1) and (2) give the objective function's value S(1,xj,p) of a phrase sequence including the top phrase to xj,p in the sentence as:"
      ]
    }
  ]
}
