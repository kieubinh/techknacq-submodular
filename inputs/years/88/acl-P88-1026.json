{
  "info": {
    "authors": [
      "Andrew David Beale"
    ],
    "book": "Annual Meeting of the Association for Computational Linguistics",
    "id": "acl-P88-1026",
    "title": "Lexicon and Grammar in Probabilistic Tagging of Written English",
    "url": "https://aclweb.org/anthology/P88-1026",
    "year": 1988
  },
  "references": [
    "acl-P87-1027"
  ],
  "sections": [
    {
      "heading": "Abstract",
      "text": [
        "The paper describes the development of software for automatic grammatical analysis of unrestricted, unedited English text at the Unit for Computer Research on the English Language (UCREL) at the University of Lancaster.",
        "The work is currently funded by IBM and carried out in collaboration with colleagues at IBM UK (Winchester) and IBM Yorktown Heights.",
        "The paper will focus on the lexicon component of the word tagging system.",
        "the UCREL grammar, the databanks of parsed sentences, and the tools that have been written to support development of these components.",
        "This work has applications to speech technology, spelling correction, and other areas of natural language processing.",
        "Currently, our goal is to provide a language model using transition statistics to disambiguate alternative parses for a speech recognition device."
      ]
    },
    {
      "heading": "1. Text Corpora",
      "text": [
        "Historically, the use of text corpora to provide empirical data for testing grammatical theories has been regarded as important to varying degrees by philologists and linguists of differing persuasions.",
        "The use of corpus citations in grammars and dictionaries me-dates electronic data processing (Brown, 1984: 34).",
        "While most of the generative grammarians of the 60s and 70s ignored corpus data, the increased power of the new technology nevertheless points the way to new applications of computerized text corpora in dictionary making, style checking and speech recognition.",
        "Computer corpora present the computational linguist with the diversity and complexity of real language which is more challenging for testing language models than intuitively derived examples.",
        "Ultimately grammars must be judged by their ability to contend with the real facts of language and not just basic constructs extrapolated by grammarians."
      ]
    },
    {
      "heading": "2. Word Tagging",
      "text": [
        "The system devised for automatic word tagging or part of speech selection for processing running English text, known as the Constituent-Likelihood Automatic Word-tagging System (CLAWS) (Garside et aL, 1987) serves as the basis for the current woric.",
        "The word tagging system is an automated component of the probabilistic parsing system we are cunently working on.",
        "In word tagging, each of the running words in the corpus text to be processed is associated with a pie-terminal symbol, denoting word class.",
        "In essence.",
        "the CLAWS suite can be conceptually divided into two phases: tag assignment and tag selection.",
        "JB = attributive adjective; JJ = general adjective: NN1 = singular.common noun; NNS1 = noun of style or title; NP1 = singular proper noun; VVO = base form of lexical verb; VVD = past tense of lexical verb; VVG = -ing form of lexical verb; VVN = past participle of lexical verb; %, = probability markers; = word initial capital marker.",
        "cent of running words are correctly disambiguated in this way.)",
        "Exceptions are dealt with by invoking a look up procedure that searches through a limited list of groups of two or more words, or by automatically adjusting the probabilities of sequences of three tags in cases when the intermediate tag is misleading.",
        "The current version of the CLAWS system requires no pre-editing and attributes the correct word tag to over 96 per cent of the input naming words, leaving 3 to 4 per cent to be corrected by human post-editors."
      ]
    },
    {
      "heading": "3. Error Analysis",
      "text": [
        "Error analysis of CLAWS output has resulted, and condnues to result, in dive= improvements to the system, from the simple adjustment of probability weightings against tags in the lexicon to the inclusion of additional procedures, for instance to deal with the distinction between proper names and common nouns.",
        "Parts of the system can also be used to develop new parts.",
        "to extend existing pans, or to interface with other systems.",
        "For instance, in order to produce a lexicon sufficiently large and detailed enough for parsing, we needed to extend the original list of about 8,000 entries to over 20.000 (the new CLAWS lexicon contains about 26,500 entries).'",
        "In order to do this, a list of 15,000 words not already in the CLAWS lexicon was tagged using the CLAWS tag assignment program.",
        "(Since they were not already in the lexicon, the candidate tags for each new entry were assigned by suffudist lookup or default tag assignment.)",
        "The new list was then post-edited by interactive screen editing and merged with the old lexicon.",
        "Another example of 'self improvement' is in the production of a better set of one-step transition probabilities.",
        "The first CLAWS system used a matrix of tag transition probabilities derived from the tagged Brown corpus (Francis and KuEera, 1982).",
        "Some cells of this matrix were inaccurate because of incompatibility of the Brown tagset and the CLAWS tagset.",
        "To remedy this, a new matrix was created by a statistics-gathering program that processed the post-edited version of a corpus of one million words tagged by the original CLAWS suite of programs."
      ]
    },
    {
      "heading": "4. Subcategorization",
      "text": [
        "Apart from extending the vocabulary coverage of the CLAWS lexicon, we are also subcategorizing words belonging to the major word classes in order to reduce the over-generation of alternative panes of sentences of greater than trivial length.",
        "The task of subcategolization involves:",
        "(1) a linguist's specification of a schema or typology of lexical subcategories based on distributional and",
        "Tag assignment involves, for each input running word or punctuation mark, lexicon look-up, which provides one or more potential word tags for each input word or punctuation mark.",
        "The lexicon is a list of about 8.000 records containing fields for (1) the word form (2) the set of one or more candidate tags denoting the word's word class(es) with probability markers attached indicating three different levels of probability.",
        "Words not in the CLAWS lexicon are assigned potential tags either by suffixlist look-up, which attempts to match end characters of the input word with a suffix in the suffudist, or.",
        "if the input word does not have a word-ending to match one of these entries, default tags are assigned.",
        "The procedures ensure that rare words and neologisms not in the lexicon .sue",
        "Tag selection disambiguates the alternative tags that are assigned to some of the running words.",
        "Disambiguation is achieved by invoking one-step probabilities of tag pair likelihoods extracted from a previously tagged training corpus and upgrading or downgrading likelihoods according to the probability markers against word tags in the lexicon or suffixlist.",
        "In the majority of cases, this first order Markov model is sufficient to correctly select the most likely sequence of tags associated with the input running text.",
        "(Over 90 per"
      ]
    },
    {
      "heading": "3",
      "text": [
        "functional criteria.",
        "(2) a lexicographer's judgement in assigning one or more of the subcategory codes in the linguist's schema to the major lexical word forms (verbs, nouns, adjectives).",
        "The amount of detail demarcated by the subcategorization typology is dependent.",
        "in part, on the practical requirements of the system.",
        "Existing subcategorizarion systems, such as the one provided in the Longman Dictionary of Contemporary English (1978) or Sager's (1981) subcategories, need to be taken into account.",
        "But these are assessed critically rather than adopted wholesale (see for instance Akkaman et al.. 1985 and Boguraev et at.. 1987, for a discussion of the strengths and weaknesses of the LDOCE grammar codes).",
        "[1] intransitive verb : ache, age, allow, care, conflict, escape.",
        "fish, occur, reply, snow, stay, sun-bathe, swoon, talk, vanish.",
        "[2] transitive verb : abandon, abhor, allow, build, complete, contain, demand, exchange, get, give, house, keep, mail, master, oppose, pardon.",
        "spend, strengthen, warn.",
        "(3]copular verb : appear, become, feel, get, grow, remain, seem.",
        "[4] prepositional verb : abstract, aim, ask, belong, cater.",
        "consist, prey, pry, search, vote.",
        "[5] phrasal verb : blow, build, cry, chess, ease, farm, fin, hand, jazz, look, open, pop, share, wort.",
        "[6] verb followed by that-clause : accept, believe.",
        "demand, doubt, feel, guess, know, maintain, reckon, require, think.",
        "[7] verb followed by to-infinitive : ask, come, dare, demand, fail, hope, intend, need, prefer, propose, refuse, seem, try, wish.",
        "[8] verb followed by big construction : abhor, begin.",
        "continue, deny, dislike, enjoy, keep, recall, remember, risk, suggest.",
        "[9] arnbitransitive verb : accept, answer, close, compile, cook, develop, feed, fly, move, obey, practice, quit, sing, stop, teach.",
        "[A] verb habitually followed by an adverbial : appear, come, go, keep, lie, live, move, put, sit, stand, swim, veer.",
        "[W] verb followed by a wit-clause : ask, choose, doubt.",
        "imagine, know, matter, mind, wonder.",
        "We began subcategorization of the CLAWS lexicon by word-tagging the 3,000 most frequent words in the Brown corpus (Kutera and Francis, 1967).",
        "An initial system of eleven verb subcategories was proposed, and judgements about which subcategory(ies) each verb belonged to were empirically tested by looking up entries in the microfiche concordance of the tagged Lancaster/Oslo-Bergen corpus (Holland and Johansson.",
        "1982; Johansson et al.",
        "1986) which shows every occurrence of a tagged word in the corpus together with its context.",
        "About 2,500 verbs have been coded in this way, and we are now working on a more detailed system of about 80 different verb subcategories using the Lexicon Development Environment of Boguraev et al.",
        "(1987)."
      ]
    },
    {
      "heading": "5. Constituent Analysis",
      "text": [
        "The task of implementing a probabilistic parsing algorithm to provide a disambiguated constituent analysis of unrestricted English is more demanding than implementing the word tagging suite, not least because, in order to operate in a manner similar to the word-tagging model, the system requires",
        "(1) specification of an appropriate grammar of rules and symbols and (2) the construction of a sufficiently large databank of parsed",
        "sentences conforming to the (optimal) grammar specified in (1) to provide statistics of' the relative likelihoods of constituent tag transitions for constituent tag disambiguation.",
        "In order to meet these prior requirements, researchers have been employed on a full-time basis to assemble a corpus of parsed sentences."
      ]
    },
    {
      "heading": "6. Grammar Development and Parsed Subcorpora",
      "text": [
        "The databank of approximately 45,000 words of manually parsed sentences of the Lancaster/Oslo-Bergen corpus (Sampson, 1987: 83ff).",
        "was processed to .show the distinct types of production rules and their frequency of occurrence in the grammar associated with the Sampson neebank.",
        "Experience of the UCREL probabilistic system (Garside and Leech.",
        "1987: 66ff) and suggestions from other researchers prompting new rules resulted in a new context-free grammar of about 6,000 productions creating more steeply nested structures than those of the Sampson grammar.",
        "(It was anticipated that steeper nesting would reduce the size of the treebank required to obtain adequate frequency statistics.)",
        "The new grammar is defined descriptively in a Parser's Manual (Leech, 1987) and formalised as a set of context-free phrase-structure productions.",
        "Development of the grammar then proceeded in tandem with the construction of a second databank of parsed sentences, fitting, as closely as possible, the rules expressed by the grammar.",
        "The new databank comprises extracts from newspaper reports daring from 1979-80 in the Associated Press (AP) corpus.",
        "Any difficulties the grammarians had in parsing were resolved, where appropriate, by amending or adding rules to the grammar.",
        "This methodology resulted in the grammar",
        "- being modified and extended to nearly 10,000 context-free productions by December 1987.",
        "Ob = operator consisting of.",
        "or ending with, a form of be; Od se operator consisting of, or ending with, a form of do; Oh = operator constisting of, or ending with, a form of the verb have; V = main verb with complementation; V. = predicate; Vg an -ing verb phrase; Vn es a past participle phrase; 0= optional constituents; (/) 13 alternative constituents."
      ]
    },
    {
      "heading": "7. Constructing the Parsed Databank",
      "text": [
        "For convenience of screen editing and computer processing, the constituent structures are represented in a linear form, as strings of grammatical words with labelled bracketing.",
        "The grammarians are given printouts of post-edited output from the CLAWS suite.",
        "They then construct a constituent analysis for each sentence on the print-out, either in detail or in outline, according to the rules described in the Parser's Manual, and key in their structures using an input program that checks for well-formedress.",
        "The well-formedness constraints imposed by the program are:",
        "(1) that labels are legal non-terminal symbols (2) that labelled brackets balance",
        "(3) that the productions obtained by the input analysis are contained in the existing grammar.",
        "One sentence is presented at a time.",
        "Any errors found by the program are reported back to the screen, once the grammarian has sent what s/he considers to be the completed parse.",
        "Sentences which are not well formed can be re-edited or abandoned.",
        "A validity marker is appended to the reference for each sentence indicating whether the sentence has been abandoned with errors contained in it.",
        "AT = article; ATI = singular article; CC = coordinating conjunction:- IF = for as preposition; 11 = preposition; JO = of as preposition: MC = cardinal number, MD = ordinal number.",
        "NN2 = plural common noun; NNL2 = plural locative noun; NNT1 = temporal noun; NNU = unit of measurement RR = general adverb; VBR = are; = germanic genitive marker.",
        "8.",
        "Assessing the Parsed Databank and the Grammar We have written ancillary programs, to help in the development of the grammar and to check the validity of the parses in the databank.",
        "One program searches through the parsed databank for every occurrence of a constituent matching a specified constituent tag.",
        "Output is a list of all occurrences of the specified constituent together with frequencies.",
        "This facility allows selective searching through the databank, which is a useful tool for revising parts of the grammar."
      ]
    },
    {
      "heading": "9. Skeleton Parsing",
      "text": [
        "We are aiming to produce a million word corpus of parsed sentences by December 1988 so that we can implement a variant of the CYK algorithm (Hopcmft and Ullman.",
        "1979: 140) to obtain a set of parses for each sentence.",
        "Viterbi labrIling (Bahl et al.",
        "1983; Fomey, 1973) could be used to select the most probable parse from the output parse set.",
        "But problems associated with assembling a fully parsed databank are:",
        "(1) speed of production and (2) matching the parsed databank to an evolving grammar.",
        "In order to cimumvent these problems, a strategy of skeleton parsing has been introduced.",
        "In skeleton parsing, grammarians enter minimal labelled bracketing by insetting only those labelled brackets that are uncontroversial and, in sonic cases, by inserting brackets with no labels.",
        "The grammar validation routine is decoupled from the input program so that changes to the grammar can be made without disrupting the input parsing.",
        "The strategy also prevents extensive retrospective editing whenever the grammar is modified.",
        "Grammar development and parsed databank construction are not entirely independent however.",
        "A subset (10 per cent) of the skeleton pluses are extracted for comparison with the current grammar, while another subset (1 per cent) is checked by independan grammarians.",
        "Skeleton parsing will give us a partially parsed databank which should limit the alternative parses compatible with the final grammar.",
        "We can either assume each parse is equally likely and use the frequency weighted productions generated by the partially parsed databank to upgrade or downgrade alternative parses or we can use a 'restrained' outside/inside algorithm (Baker.",
        "1979) to find the optimal parse.",
        "D general determinative element Da = determinative element containing an article as the last or only word; G = genitive construction; Jm = adjective phrase; M = numeral phrase; N nominal; N' = noun phrase; N'& = first conjunct of coordinated noun phrase; N'+ = non-initial conjunct following a conjunction; Mr' .",
        "temporal noun phrase; p = prepositional phrase; Po = prepositional phrase; Q = qualifier; S' = sentence; Sd = declarative sentence.",
        "PPHS1 = he, she; PPHS2 = they: PP102 us; PP1S2 we; RT = nominal adverb of time; VM = modal auxiliary verb; hypertags: S = included sentence; S& = first coordinated main clause; S+ non-inital coordinated main clause following a conjunction; Si = interpolated or appended sentence."
      ]
    },
    {
      "heading": "10. Featurisation",
      "text": [
        "The development of the CLAWS tagset and UCREL grammar owes much to the work of Quirk a al.",
        "(1985) while the tags themselves have evolved from the Brown tagset (Francis and Kutera.",
        "1982).",
        "However, the rules and symbols chosen have been translated into a notation compatible with other theories of grammar.",
        "For instance, tags from the extended version of the CLAWS lexicon have been translated into a formalism compatible with the Winchester parser (Sharman.",
        "1988).",
        "A program has also been written to map all of the ten thousand productions of the current UCREL grammar into the notation used by the Grammar Development Environment (ODE) (Briscoe et al., 1987; Grover et aL, 1988; Carroll et al.. 1988).",
        "This is a preliminary step in the task of recasting the grammar into a feature-based unification formalism which will allow us to radically reduce the size of the rule set while preventing the grammar from overgenerating."
      ]
    },
    {
      "heading": "11. Summary",
      "text": [
        "In summary, we have a word tagging system that requires minimal post-editing, a steadily accumulating corpus of parsed sentences and a context-free grammar of about ten thousand productions which is currently being recast into a feature-based unification formalism.",
        "Additionally, we have programs for extracting statistical and collocational data from both word tagged and parsed text corpora."
      ]
    },
    {
      "heading": "12. Acknowledgements",
      "text": [
        "The author is a member of a group of researchers working at the Unit for Computer Research on the English Language at Lancaster University.",
        "The present members of UCREL are Geoffrey Leech, Roger Gar:tide (UCREL directors), Andrew Beale, Louise Denmark, Steve Elliott.",
        "Jean Forrest, Fanny Leech and Lila Taylor.",
        "The work is currently funded by IBM UK (research grant 823105) and carried out in collaboration with Claire Grover, Richard Sharman, Peter Alderson, Ezra Black and Frederick Jelinek of IBM."
      ]
    },
    {
      "heading": "13. References",
      "text": []
    }
  ]
}
