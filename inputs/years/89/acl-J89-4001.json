{
  "info": {
    "authors": [
      "Andrew R. Haas"
    ],
    "book": "Computational Linguistics",
    "id": "acl-J89-4001",
    "title": "A Parsing Algorithm for Unification Grammar",
    "url": "https://aclweb.org/anthology/J89-4001",
    "year": 1989
  },
  "references": [
    "acl-P85-1017",
    "acl-P85-1018",
    "acl-P86-1038"
  ],
  "sections": [
    {
      "text": [
        "We describe a table-driven parser for unification grammar that combines bottom-up construction of phrases with top-down filtering.",
        "This algorithm works on a class of grammars called depth-bounded grammars, and it is guaranteed to halt for any input string.",
        "Unlike many unification parsers, our algorithm works directly on a unification grammarit does not require that we divide the grammar into a context-free \"backbone\" and a set of feature agreement constraints.",
        "We give a detailed proof of correctness.",
        "For the case of a pure bottom-up parser, our proof does not rely on the details of unification it works for any pattern-matching technique that satisfies certain simple conditions."
      ]
    },
    {
      "heading": "1 INTRODUCTION",
      "text": [
        "Unrestricted unification grammars have the formal power of a Turing machine.",
        "Thus there is no algorithm that finds all parses of a given sentence in any unification grammar and always halts.",
        "Some unification grammar systems just live with this problem.",
        "Any general parsing method for definite clause grammar will enter an infinite loop in some cases, and it is the task of the grammar writer to avoid this.",
        "Generalized phrase structure grammar avoids the problem because it has only the formal power of context-free grammar (Gazdar et al.",
        "1985), but according to Shieber (1985a) this is not adequate for describing human language.",
        "Lexical functional grammar employs a better solution.",
        "A lexical functional grammar must include a finitely ambiguous context-free grammar, which we will call the context-free backbone (Barton 1987).",
        "A parser for lexical functional grammar first builds the finite set of context-free parses of the input and then eliminates those that don't meet the other requirements of the grammar.",
        "This method guarantees that the parser will halt.",
        "This solution may be adequate for lexical functional grammars, but for other unification grammars finding a finitely ambiguous context-free backbone is a problem.",
        "In a definite clause grammar, an obvious way to build a context-free backbone is to keep only the topmost function letters in each rule.",
        "Thus the rule s > np(P ,N) vp( P ,IV) becomes S > np vp (In this example we use the notation of Pereira and Warren 1980, except that we do not put square brackets around terminals, because this conflicts with standard notation for context-free grammars.)",
        "Suppose we use a simple X-bar theory.",
        "Let major-category (Type, Bar level) denote a phrase in a major category.",
        "A noun phrase may consist of a single noun, for instance, John.",
        "This suggests a rule like this: major-category (n,2) > major-category (n, I) In the context-free backbone this becomes major-category ---> major-category so the context-free backbone is infinitely ambiguous.",
        "One could devise more elaborate examples, but this one suffices to make the point: not every natural unification grammar has an obvious context-free backbone.",
        "Therefore it is useful to have a parser that does not require us to find a context-free backbone, but works directly on a unification grammar (Shieber 1985b).",
        "We propose to guarantee that the parsing problem is solvable by restricting ourselves to depth-bounded grammars.",
        "A unification grammar is depth-bounded if for every L > 0 there is a D > 0 such that every parse tree for a sentential form of L symbols has depth less than D. In other words, the depth of a tree is bounded by the length of the string it derives.",
        "A context-free grammar is depth-bounded if and only if every string of symbols is finitely ambiguous.",
        "We will generalize the notion of finite ambiguity to unification grammars and show that for unification grammars, depth-boundedness is a stronger property than finite ambiguity.",
        "Copyright 1989 by the Association for Computational Linguistics.",
        "Permission to copy without fee all or part of this material is granted provided that the copies are not made for direct commercial advantage and the CL reference and this copyright notice are included on the first page.",
        "To copy otherwise, or to republish, requires a fee and/or specific permission.",
        "0362-613X1 89 /010219-232$03.00 Computational Linguistics, Volume 15, Number 4, December 1989219 Andrew HaasA Parsing Algorithm for Unification Grammar Depth-bounded unification grammars have more formal power than context-free grammars.",
        "As an example we give a depth-bounded grammar for the language xx, which is not context-free.",
        "Suppose the terminal symbols are a through z.",
        "We introduce function letters a' through z' to represent the terminals.",
        "The rules of the grammar are as follows, with e denoting the empty string.",
        "s > x(L)x(L) x(cons(A,L)) > pre-terminal(A) x(L) x(nil) --> e pre-terminal(a') > a pre-terminal(z') z The reasoning behind the grammar should be clearx(cons(a' ,cons(13' ,ni1))) derives ab, and the first rule guarantees that every sentence has the form xx.",
        "The grammar is depth-bounded because the depth of a tree is a linear function of the length of the string it derives.",
        "A similar grammar can derive the crossed serial dependencies of Swiss German, which according to Shieber (1985a) no context-free grammar can derive.",
        "It is clear where the extra formal power comes from: a context free grammar has a finite set of nonterminals, but a unification grammar can build arbitrarily large nonterminal symbols.",
        "It remains to show that there is a parsing algorithm for depth-bounded unification grammars.",
        "We have developed such an algorithm, based on the context-free parser of Graham et al.",
        "1980, which is a table-driven parser.",
        "If we generalize the table-building algorithm to a unification grammar in an obvious way, we get an algorithm that is guaranteed to halt for all depth bounded grammars (not for all unification grammars).",
        "Given that the tables can be built, it is easy to show that the parser halts on every input.",
        "This is not a special property of our parsera straightforward bottom-up parser will also halt on all depth-bounded grammars, because it builds partial parse trees in order of their depth.",
        "Our contribution is to show that a simple algorithm will verify depth-boundedness when in fact it holds.",
        "If the grammar is not depth-bounded, the table building algorithm will enter an infinite loop, and it is up to the grammar writer to fix this.",
        "In practice we have not found this troublesome, but it is still an unpleasant property of our method.",
        "Section 7 will describe a possible solution for this problem.",
        "Sections 2 and 3 of this paper define the basic concepts of our formalism.",
        "Section 4 proves the soundness and completeness of our simplest parser, which is purely bottom-up and excludes rules with empty right-hand sides.",
        "Section 5 admits rules with empty right sides, and section 6 adds top-down filtering.",
        "Section 7 discusses the implementation and possible extensions.",
        "2 BASIC CONCEPTS The following definitions are from Gallier 1986.",
        "Let S be a finite, nonempty set of sorts.",
        "An S-ranked alphabet is a pair (I,r) consisting of a set I together with a function /S* x S assigning a rank (u,^) to each symbol f in I.",
        "The string u in S* is the arity off and s is the type of The S-ranked alphabets used in this paper have the following property.",
        "For every sort s E S there is a c:ountably infinite set Vs of symbols of sort s called variables.",
        "The rank of each variable in Vs is (e,^), where eis the empty string.",
        "Variables are written as strings beginning with capitalsfor instance X, Y, Z.",
        "Symbols that are not variables are called function letters, and function letters whose arity is e are called constants.",
        "There can be only a finite number of function letters in any sort.",
        "The set of terms is defined recursively as follows.",
        "For every symbol f of rank (u, ...un, s) and any terms ti...tn, with each t, of sort u,, f(t, ,...tn) is a term of sort s. Since every sort in S includes variables, whose arity is e, it is clear that there are terms of every sort.",
        "A term is called a ground term if it contains no variables.",
        "We make one further requirement on our ranked alphabets: that every sort contains a ground term.",
        "This can be guaranteed by just requiring at least one constant of every sort.",
        "It is not clear, however, that this solution is linguistically acceptablewe do not wish to include constants without linguistic significance just to make sure that every sort includes a ground term.",
        "Therefore, we give a simple algorithm for checking that every sort in S includes a ground term.",
        "Let T, be the set of sorts in S that include a constant.",
        "Let Ti I be the union of 'I', and the set of all s in S such that for some function letter f of sort s, the arity off is and the sorts ul,...,un are in Ti.",
        "Every sort in T, includes a ground term, and if every sort in T. a ground term then every sort in T, includes a ground term.",
        "Then for all n, every sort in Tn includes a ground term.",
        "The algorithm will compute Tn for successive values of n until it finds an N such that TN = TN (this N must exist, because S is finite).",
        "If TN = S, then every sort in S includes a ground term, otherwise not.",
        "As an illustration, let S = {phrase, person, numbed.",
        "Let the function letters of I be {np, vp, s, 1st, 2nd, 3rd, singular, plural}.",
        "Let ranks be assigned to the function letters as follows, omitting the variables.",
        "We have used the notation [a,b,c] for the string of a, b, and c. Typical terms of this ranked alphabet are np(lst, 220Computational Linguistics, Volume 15, Number 4, December 1989 Andrew HaasA Parsing Algorithm for Unification Grammar singular) and vp(2nd, plural).",
        "The reader can verify, using the above algorithm, that every sort includes a ground term.",
        "In this case, Ti = {person, number}, T2 = {person, number, phrase}, and T3 = T2.",
        "To summarize: we define ranked alphabets in a standard way, adding the requirements that every sort includes a countable infinity of variables, a finite number of function letters, and at least one ground term.",
        "We then define the set of terms in a standard way.",
        "All unification in this paper is unification of terms, as in Robinson 1965not graphs or other structures, as in much recent work (Shieber 1985b).",
        "A unification grammar is a five-tuple G = (S, (1,r) T, P, Z) where S is a set of sorts, (I,r) an S-ranked alphabet, T a finite set of terminal symbols, and Z a function letter of arity e in (2r).",
        "Z is called the start symbol of the grammar (the standard notation is S not Z, but by bad luck that conflicts with standard notation for the set of sorts).",
        "P is a finite set of rules; each rule has the form (A > a), where A is a term of the ranked alphabet and a is a sequence of terms of the ranked alphabet and symbols from T. We define substitution and substitution instances of terms in the standard way (Gallier 1986).",
        "We also define instances of rules: if s is a substitution and (A > B, ...B.)",
        "is a rule, then (s(A) --> s(B ).",
        "..s(B n)) is an instance of the rule (A ---> Bi...Bn).",
        "A ground instance of a term or rule is an instance that contains no variables.",
        "Here is an example, using the set of sorts S from the previous example.",
        "Let the variables of sort person be P1 P2,... and the variables of sort number be N, ,N2... etc.",
        "Then the rule (start > np(P, , NI) vp(P, , NI) has six ground instances, since there are three possible substitutions for the variable PI and two possible substitutions for N, .",
        "We come now to the key definition of this paper.",
        "Let G = (S, (14 T, P. Z) be a unification grammar.",
        "The ground grammar for G is the four-tuple (N, T, P', Z), where N is the set of all ground terms of (4, T is the set of terminals of G, P' is the set of all ground instances of rules in P, and Z is the start symbol of G. If N and P' are finite, the ground grammar is a context-free grammar.",
        "If N or P' is infinite, the ground grammar is not a context-free grammar, and it may generate a language that is not context-free.",
        "Nonetheless we can define derivation trees just as in a cfg.",
        "Following Hoperoft and Ullman (1969), we allow derivation trees with nonterminals at their leaves.",
        "Thus a derivation tree may represent a partial derivation.",
        "We differ from Hoperoft and Ullman by allowing nonterminals other than the start symbol to label the root of the tree.",
        "A derivation tree is an A-tree if the non-terminal A labels its root.",
        "The yield of a derivation tree is the string formed by reading the symbols at its leaves from left to right.",
        "As in a cfg, A a iff there is an A-tree with yield a.",
        "The language generated by a ground grammar is the set of terminal strings derived from the start symbol.",
        "The language generated by a unification grammar is the language generated by its ground grammar.",
        "The central idea of this approach is to regard a unification grammar as an abbreviation for its ground grammar.",
        "Ground grammars are not always cfgs, but they share many properties of cfgs.",
        "Therefore if we regard unification grammars as abbreviations for ground grammars, our understanding of cfgs will help us to understand unification grammars.",
        "This is of course inspired by Robinson's work on resolution, in which he showed how to \"lift\" a proof procedure for propositional logic up to a proof procedure for general first order logic (Robinson 1965).",
        "The case of a finite ground grammar is important, since it is adequate for describing many syntactic phenomena.",
        "A simple condition will guarantee that the ground grammar is finite.",
        "Suppose s1 and s2 are sorts, and there is a function letter of sort s, that has an argument of sort s2.",
        "Then we say that s > s2.",
        "Let >* be the transitive closure of this relation.",
        "If >* is irreflexive, and D is the number of sorts, every term of the ground grammar has depth D. To see this, think of a ground term as a labeled tree.",
        "A path from the root to a leaf generates a sequence of sorts: the sorts of the variables and functions letters encountered on that path.",
        "It is a strictly decreasing sequence according to >*.",
        "Therefore, no sort occurs twice; therefore, the length of the sequence is at most D. Since there are only a finite number of function letters in the ranked alphabet, each taking a fixed number of arguments, the number of possible ground terms of depth D is finite.",
        "Then the ground grammar is finite.",
        "A ground grammar G' is depth-bounded if for every integer n there exists an integer d such that every derivation tree in G' with a yield of length n has a depth less than d. In other words, a depth-bounded grammar cannot build an unbounded amount of tree structure from a bounded number of symbols.",
        "Remember that these symbols may be either terminals or nonterminals, because we allow nonterminals at the leaves of a derivation tree.",
        "A unification grammar G is depth bounded if its ground grammar is depth-bounded.",
        "We say that a unification grammar is finitely ambiguous if its ground grammar is finitely ambiguous.",
        "We can now prove the result claimed above: that a unification grammar can be finitely ambiguous but not depth bounded.",
        "In fact, the following grammar is completely unambiguous but still not depth-bounded.",
        "It has just one terminal symbol, b, and its start symbol is start.",
        "The function letter \"succ\" represents the successor function on the integers, and the terms 0, succ(0), succ(succ(0))... represent the integers 0, 1, 2... etc.",
        "For convenience, we identify these terms with the integers Computational Linguistics, Volume 15, Number 4, December 1989221 Andrew HaasA Parsing Algorithm for Unification Grammar they represent.",
        "A string of N occurrences of b has just one parse tree.",
        "In this tree the start symbol derives p(0), which derives p(IV) by N applications of the second rule.",
        "p(N) derives q(IV), which derives N occurrences of b by N applications of the fourth rule and one application of the last rule.",
        "The reader can verify that this derivation is the only possible one, so the grammar is unambiguous.",
        "Yet the start symbol derives p(N) by a tree of depth N, for every N. Thus trees whose frontier has only one symbol can still be arbitrarily deep.",
        "Then the grammar cannot be depth-bounded.",
        "We have defined the semantics of our grammar formalism without mentioning unification.",
        "This is deliberate; for us unification is a computational tool, not a part of the formalism.",
        "It might be better to call the formalism \"substitution grammar,\" but the other name is already established.",
        "Notation: The letters A, B, and C denote symbols of a ground grammar, including terminals and nonterminals.",
        "Lowercase Greek letters denote strings of symbols.",
        "a [i k] is the substring of a from space i to space k, where the space before the first symbol is space zero.",
        "e is always the empty string.",
        "We write x U y or U(x,y) for the union of sets x and y, and also (U i<j<k j(j)) for the union of the sets f(j) for all j such that i <j < k. If a is the yield of a tree t, then to every occurrence of a symbol A in a there corresponds a leaf of t labeled with A.",
        "To every node in t there corresponds an occurrence of a substring in athe substring dominated by that node.",
        "Here is a lemma about trees and their yields that will be useful when we consider top-down filtering.",
        "Lemma 2.1.",
        "Suppose t is a tree with yield apa' and n is the node of t corresponding to the occurrence of after a in apa'.",
        "Let A be the label of n. If t' is the tree formed by deleting all descendants of n from t, the yield of t' is aAa'.",
        "Proof: This is intuitively clear, but the careful reader may prove it by induction on the depth of t."
      ]
    },
    {
      "heading": "3 OPERATIONS ON SETS OF RULES AND TERMS",
      "text": [
        "The parser must find the set of ground terms that derive the input string and check whether the start symbol is one of them.",
        "We have taken the rules of a unification grammar as an abbreviation for the set of all their ground instances.",
        "In the same way, the parser will use sets of terms and rules containing variables as a representation for sets of ground terms and ground rules.",
        "In this section we show how various functions needed for parsing can be computed using this representation.",
        "A grammatical expression, or g-expression, is either a term of L, the special symbol nil, or a pair of g-expressions.",
        "The letters u, v, w, x, y, and z denote g-expressions, and X, Y, and Z denote sets of g expressions.",
        "We use the usual LISP functions and predicates to describe g-expressions.",
        "[x y] is another notation for cons (x,y).",
        "For any substitution s, s (cons (x,y)) = cons (s(x),s(y)) and s(Nil) = Nil.",
        "A selector is a function from g-expressions to g-expressions formed by composition from the functions car, cdr, and identity.",
        "Thus a selector picks out a subexpression from a g-expression.",
        "A constructor is a function that maps two g-expressions to a g-expression, formed by composition from the functions cons, car, cdr, nil, (A x y. x), and (A x y. y).",
        "A constructor builds a new g-expression from parts of two given g-expressions.",
        "A g-predicate is a function from g-expressions to Booleans formed by composition from the basic functions car, cdr, (A x. x), consP, and null.",
        "Let ground(X) be the set of ground instances of g expressions in X.",
        "If f is a selector function, let f(X) be the set of all fix) such that x E X.",
        "If p is a g-predicate, let separate (p,X) be the set of all x E X such that p(x).",
        "The following lemmas are easily established from the definition of s(x) for a g-expression x.",
        "These lemmas tell us that if we use sets X and Y of terms to represent the sets ground(X) and ground( Y) of ground terms, we can easily construct representations for .figround(X)), separate(p,ground (X)), and ground (X) U ground ( Y).",
        "Also we can decide whether a given ground term is contained in ground(X) and whether ground(X) is empty.",
        "All these operations will be needed in the parser.",
        "The parser requires one more type of operation, defined as follows.",
        "Definition.",
        "Let J., andf2 be selectors and g a constructor, and suppose g(x,y) is well defined whenever f1(x) and f2(y) are well defined.",
        "The symbolic product defined by J.; , f2, and g is the function",
        "The symbolic product matches every x in X against every y in Y.",
        "If f1(x) equals f2(y), it builds a new structure from x and y using the function g. As an example, suppose X and Y are sets of pairs of ground terms, and we need to find all pairs [A C] such that for some B, [A B] is in X and [B C] is in Y.",
        "We can do this by finding the symbolic product with f1 = cdr, f2 = car, and g = (A x y. cons(car(x), cdr(y))).",
        "To see that this is correct, notice that if [A B] is in X and [B C] is in Y, then 222Computational Linguistics, Volume 15, Number 4, December 1989 Andrew HaasA Parsing Algorithm for Unification Grammar f,([A B]) =f2 ([B C]), so the pair g ([A B],[B C]) = [A C] must be in the answer set.",
        "A second example: we can find the intersection of two sets of terms by using a symbolic product with fl = (A x .",
        "x), f2 = (A x .",
        "x), and g = (A x y. x).",
        "If X is a set of g-expressions and n an integer, rename(X,n) is an alphabetic variant of X.",
        "For all X, Y, m, and n, if m 0 n then rename(X,n) and rename( Y,m) have no variables in common.",
        "The following theorem tells us that if we use sets of terms X and Y to represent the sets ground(X) and ground( Y) of ground terms, we can use unification to compute any symbolic product of ground(X) and ground( Y).",
        "We assume the basic facts about unification as in Robinson (1965).",
        "Theorem 2.1.",
        "If h is the symbolic product defined by f,, f2 and g, and X and Y are sets of g-expressions, then h (ground(X),ground(Y)) = ground({s(g(u,v)) u E rename(X,1) A v E rename(Y,2) A s is the m.g.u.",
        "of f1(u) and f2(v)}.)",
        "Proof.",
        "The first step is to show that if Z and W share no variables",
        "Consider any element of the right side of equation (1).",
        "It must be a ground instance of s(g(u,v)), where u E Z, v E W, and s is the m.g.u.",
        "of f1(u) and f2(v).",
        "Any ground instance of s(g(u,v)) can be written as s'(s(g(u,v))), where s' is chosen so that s'(s(u)) and s'(s(v)) are ground terms.",
        "Then s'(s(g(u,v))) -=- g(s'(s(u)),s'(s(v))) and fi(s'(s(u))) = s'(s(fi(u))) = s'(s(f2 (v))) = f2(s'(s(v))).",
        "Therefore s'(s(g(u,v))) belongs to the set on the left side of equation (1).",
        "Next consider any element of the left side of (1).",
        "It must have the form g(z,w), where z E ground(Z), w E ground(W), and J., (z) = f2 (w).",
        "Then for some u E Z and V E W, Z is a ground instance of u and w is a ground instance of v. Since u and v share no variables, there is a substitution s' such that s'(u) = z and s'(v) = w. Then s'(f, (u)) = A (s'(u)) = f2 (si(v)) = s'(f2 (v)), so there exists a most general unifier s for J., (u) and f2 (v), and s' is the composition of s and some substitution s\".",
        "Then g(z,w) = g(s(s(u)) s(s(v))) = s(s(g(u,v))).",
        "g(z,w) is a ground term because z and w are ground terms, so g(z,w) is a ground instance of s(g(u,v)) and therefore belongs to the set on the right side of equation (1).",
        "We have proved that if Z and W share no variables, (2) h(ground(Z),ground(W)) = ground({s( g(u,v)) I u EZAvEWAs is the m.g.u.",
        "of fl(u) and f2(v)}) For any X and Y, rename(X,1) and rename( Y,2) share no variables.",
        "Then we can let Z = rename(X,1) and W = rename( Y,2) in formula (2).",
        "Since h(ground(X), ground(}')) = h(ground(rename(X,1)), ground(rename (Y,2))), the theorem follows by transitivity of equality.",
        "This completes the proof.0 As an example, suppose X = {[a(F) b(F)]} and Y = {[b(G) c(G)]}.",
        "Suppose the variables F and G belong to a sort s that includes just two ground terms, m and n. We wish to compute the symbolic product of ground(X) and ground( Y), using f, = cdr, f2 = car, and g = (A x y. cons(car(x), cdr(y))) (as in our previous example).",
        "ground(X) equals {[a(m) b(m)],[a(n) b(n)ll and ground( Y) equals {[b(m) c(m)],[b(n) c(n)ll, so the symbolic product is {[a(m) c(m)],[a(n) c(n)}}.",
        "We will verify that the unification method gets the same result.",
        "Since X and Y share no variables, we can skip the renaming step.",
        "Let x = [a(F) b(F)] and y = [b(G) c(G)].",
        "Thenf, (x) = b(F),f2 (Y) = b(G), and the most general unifier is the substitution s that replaces F with G. Then g(x,y) = [a(F) c(G)] and s(g(x,y)) = [A(G) C(G)].",
        "The set of ground instances of this g-expression is {[A(m) C(m)], [A(n)C(n)ll, as desired.",
        "Definition.",
        "Let f be a function from sets of g expressions to sets of g-expressions, and suppose that when X C X' and Y C Y', flX, Y) C f(X', Y').",
        "Then f is monotonic.",
        "All symbolic products are monotonic functions, as the reader can easily show from the definition of symbolic products.",
        "Indeed, every function in the parser that returns a set of g-expressions is monotonic."
      ]
    },
    {
      "heading": "4 THE PARSER WITHOUT EMPTY SYMBOLS",
      "text": [
        "Our first parser does not allow rules with empty right sides, since these create complications that obscure the main ideas.",
        "Therefore, throughout this section let G be a ground grammar in which no rule has an empty side.",
        "When we say that a derives [3 we mean that a derives [3 in G. Thus a e iff a = e. A dotted rule in G is a rule of G with the right side divided into two parts by a dot.",
        "The symbols to the left of the dot are said to be before the dot, those to the right are after the dot.",
        "DR is the set of all dotted rules in G. A dotted rule (A > a. f3) derives a string if a derives that string.",
        "To compute symbolic products on sets of rules or dotted rules, we must represent them as g-expressions.",
        "We represent the rule (A --> B C) as the list (A B C), and the dotted rule (A > B.C) as the pair [(A B C) (C)].",
        "We write A B if A derives B by a tree with more than one node.",
        "The parser relies on a chain tablea table of all pairs [A B] such that A B.",
        "Let Cd be the set of all [A B] such that A B by a derivation tree of depth d. Clearly CI is the set of all [A B] such that (A B) is a rule of G. If S, and S2 are sets of pairs of terms, define",
        "The terminal symbols [b c], [c d]}, C2= {[a empty.",
        "Definitions.",
        "ChainTable is the set of all [A B] such that A B.",
        "If S is a set of dotted pairs of symbols and S' a set of symbols, ChainUp(S,S') is the set of symbols A such that [A B] E S for some B E S'.",
        "\"ChainUp\" is clearly a symbolic product.",
        "If S is a set of symbols, close(S) is the union of S and ChainUp(ChainTable,S).",
        "By the definition of ChainTable, close(S) is the set of symbols that derive a symbol of S. In the example grammar, ChainTable is the union of C1, C2, and C3that is, the set {[ a b],[b c],[c d],[a c], [b d],[a d]}.",
        "ChainUp({ a}) = {}, but ChainUp({ d}) = fa,b,cl.",
        "close({ a}) = al, while close({ d}) = a,b,c,d}.",
        "Let a be an input string of length L > 0.",
        "For each a[i k] the parser will construct the set of dotted rules that derive a[i k].",
        "The start symbol appears on the left side of one of these rules iff a[i k] is a sentence of G. By lemma 2.5 this can be tested, so we have a recognizer for the language generated by G. With a small modification the algorithm can find the set of derivation trees of a.",
        "We omit details and speak of the algorithm as a parser when strictly speaking it is a recognizer only.",
        "The dotted rules that derive a[i k] can be partitioned into two sets: rules with many symbols before the dot and rules with exactly one.",
        "For each a[i k], the algorithm will carry out three steps.",
        "First it collects all dotted rules that derive a[i k] and have many symbols before the dot.",
        "From this set it constructs the set of all symbols that derive a[i k], and from these symbols it constructs the set of all dotted rules that derive a[i k] with one symbol before the dot.",
        "The union of the two sets of dotted rules is the set of all dotted rules that derive a[i k].",
        "Note that a dotted rule derives a[i k] with more than one symbol before the dot iff it can be written in the form (A 013.13') where 0 a[i j], B a[j k], and i <j < k (this follows because a nonempty string 0 can never derive the empty string in G).",
        "If (A B.",
        "C) derives a[i j] and B derives aU kl, then (A --> B C .)",
        "derives a[i k].",
        "This observation motivates the following.",
        "Definition.",
        "If S is a set of dotted rules and S' a set of symbols, AdvanceDot(S,S') is the set of rules (A > aB.f3) such that (A 0 a.Bp) E S and B E S'.",
        "Clearly AdvanceDot is a symbolic product.",
        "For example, AdvanceDot({( d--> k .f)},{a,f}) equals {( d > k f .)}.",
        "Suppose that for each proper substring of a[i k] we have already found the dotted rules and symbols that derive that substring.",
        "The following lemma tells us that we can then find the set of dotted rules that derive a[i k] with many symbols before the dot.",
        "A au j kplE1 As noted above, this is the set of dotted rules that derive a[i k] with more than one symbol before the dot.",
        "Definition.",
        "If S is a set of dotted rules, finished( S) = {A IA 0.)",
        "E 1.",
        "When the dot reaches the end of the right side of a rule, the parser has finished building the symbol on the left sidehence the name finished.",
        "For example, finished({( d > k f .",
        "),(a > .",
        "b)l) is the set { d}.",
        "The next lemma tells us that if we have the set of dotted rules that derive a[i k] with many symbols before the clot, we can construct the set of symbols that derive a[i k].",
        "In our example grammar, the set of dotted rules deriving a[0 2] = gh with more than one symbol before the dot is {(d ---> k f.)} finished({( d > k f.)} ) is { d}, and close({ dl ) = a,b,c,d1.",
        "It is easy to check that these are all the symbols that derive gh.1=1 Definitions.",
        "RuleTable is the set of dotted rules (A > .a) such that (A > a) is a rule of G. If S is a set of symbols, NewRules(S) is AdvanceDot(RuleTable, S).",
        "In our example grammar, NewRules (fkl) = f( d --> k Pl.",
        "Lemma 3.3.",
        "If S is the set of symbols that derive a, n until C is empty.",
        "Then the union of all the C's is the chain table.",
        "We give an example from a finite ground grammar.",
        "are are g and h .",
        "Then CI = f[a b], c],[b d]}, and C3 = {faC4 is 224Computational Linguistics, Volume 15, Number 4, December 1989 Andrew HaasA Parsing Algorithm for Unification Grammar the set of dotted rules that derive a with one symbol before the dot is NewRules(S).",
        "Proof.",
        "Expanding the definitions gives Advance Dot({( A.01(Af3)EP}, { C C= {(A c.0 (A > CB') EPAal.",
        "This is the set of dotted rules that derive a with one symbol before the dot.",
        "Let terminals(i,k) be the set of terminals that derive a[i k]; that is, if i + 1 = k then terminals(i,k) = {a[i and otherwise terminals(i,k) = 0.",
        "Let a be a string of length L > 0.",
        "For 0 i < k L, define",
        "dotted rules that derive a[i k].",
        "Proof.",
        "By induction on the length of a[i k].",
        "If the length is 1, then i + 1 = k. The algorithm returns NewRules(close({a[i i + 1]})).",
        "close({ a[i i + 1]} ) is the set of symbols that derive a[ ii + 1] (by the definition of ChainTable), and NewRules(close({aU i + 11})) is the set of dotted rules that derive a[i i + 1] with one symbol before the dot (by lemma 3.3).",
        "No rule can derive a[i i + 1] with many symbols before the dot, because a[i i + 1] has only one symbol.",
        "Then NewRules(close ({a[i k]})) is the set of all dotted rules that derive a[i k].",
        "Suppose a[i k] has a length greater than I.",
        "If i <j<k, dr(i,j) contains the dotted rules that derive a[i j] and dr(j,k) contains the dotted rules that derive a[j k], by induction hypothesis.",
        "Then finished(dr(j,k)) is the set of nonterminals that derive aU k], and terminals(j,k) is the set of terminals that derive a[j k], so the union of these two sets is the set of all symbols that derive a[j k].",
        "By lemma 3.1, rules, is the set of dotted rules that derive a[i k] with many symbols before the dot.",
        "By lemma 3.2, close(finished(rules,)) is the set of symbols that derive a[i k], so by lemma 3.3 rules2 is the set of dotted rules that derive a[i k] with one symbol before the dot.",
        "The union of rules, and rules2 is the set of dotted rules that derive a[i k], and this completes the proof.0 Suppose we are parsing the string gh with our example grammar.",
        "We have"
      ]
    },
    {
      "heading": "5 THE PARSER WITH EMPTY SYMBOLS",
      "text": [
        "Throughout this section, G is an arbitrary depth bounded unification grammar, which may contain rules whose right side is empty.",
        "If there are empty rules in the grammar, the parser will require a table of symbols that derive the empty string, which we also call the table of empty symbols.",
        "Let Ed be the set of symbols that derive the empty string by a derivation of depth d, and let E'd be the set of symbols that derive the empty string by a derivation of depth d or less.",
        "Since the grammar is depth-bounded, it suffices to construct Ed for successive values of d until a D > 0 is found such that ED is the empty set.",
        "E, is the set of symbols that immediately derive the empty string; that is, the set of all A such that (A > e) is a rule.",
        "A E Ed iff there is a rule (A --> Bi...Bn) such that for each i, B. e at depth di, and d is the maximum of the di's.",
        "In other words: A E Ed iff there is a rule (A ---> aBf3) such that B E Ed and every symbol of a and 0 is in E'd.",
        "Let DR be a set of dotted rules and S a set of symbols.",
        "Define",
        "SI is the set of dotted rules (A ---> a.po) such that every symbol of a is in E'd.",
        "S2 is then the set of dotted rules (A > aB.01) such that B E Ed and every symbol of a is in E'd.",
        "Therefore S3 is the set of dotted rules (A > aBp.p2) such that B E Ed and every symbol of a and is in E'd.",
        "Finally S4 is the set of symbols A such that for some rule (A > B/3), B E Ed and every symbol of a and 0 is in E'd.",
        "Then S4 is Ed + 1.",
        "In this way we can construct Ed for increasing values of d until the table of empty symbols is complete.",
        "Here is an example grammar with symbols that derive the empty string:",
        "The terminal symbols are r and s. In this grammar, E, = {a,b}, E2 = {C}, and E3 = 0.",
        "Definitions Let EmptyTable be the set of symbols that derive the empty string.",
        "If S is a set of dotted rules, let SkipEmpty(S) be AdvanceDot*(S, EmptyTable).",
        "Computational Linguistics, Volume 15, Number 4, December 1989225 Andrew HaasA Parsing Algorithm for Unification Grammar Note that SkipEmpty(S) is the set of dotted rules (A > ap1.132) such that (A > .0102) e S and pl e. SkipEmpty(S) contains every dotted rule that can be formed from a rule in S by moving the dot past zero or more symbols that derive the empty string.",
        "In the example grammar EmptyTable = {a,b,c}, so SkipEmpty({( k > .",
        "cfcgc)}) = {( k > .",
        "cfcgc), (k > c. fcgc)}.",
        "If the dotted rules in S all derive a, then the dotted rules in SkipEmpty(S) also derive a.",
        "Let Cd be the set of pairs [A B] such that A B by a derivation tree in which the unique leaf labelled B is at depth d (note: this does not imply that the tree is of depth d).",
        "C1 is the set of pairs [A B] such that (A > aBp) is a rule and every symbol of a and 0 derives the empty string.",
        "CI is easily computed using SkipEmpty.",
        "Also Cd + 1 = link(Cd,Ci), so we can construct the chain table as before.",
        "In the example grammar there are no A and B such that A B, but if we added the rule (k> cfc), we would have k f. Note that k derives fby a tree of depth 3, but the path from the root of this tree to the leaf labeled f is of length one.",
        "Therefore the pair [k f] is in C. The parser of Section 4 relied on the distinction between dotted rules with one and many symbols before the dot.",
        "If empty symbols are present, we need a slightly more complex distinction.",
        "We say that the string a derives p using one symbol if there is a derivation of p from a in which exactly one symbol of a derives a non-empty string.",
        "We say that a derives 0 using many symbols if there is a derivation of 0 from a in which more than one symbol of a derives a nonempty string.",
        "If a string a derives a string p, then a derives p using one symbol, or a derives p using many symbols, or both.",
        "In the example grammar, cfc derives r using one symbol, and cfcg derives rs using many symbols.",
        "We say that a dotted rule derives 0 using one (or many) symbols if the string before the dot derives f3 using one (or many) symbols.",
        "Note that a dotted rule derives a[i k] using many symbols iff it can be written as (A > 13B/3' .pi) where pa[ij], B alj k , e, and i <j < k. This is true because whenever a dotted rule derives a string using many symbols, there must be a last symbol before the dot that derives a nonempty string.",
        "Let B be that symbol; it is followed by a p' that derives the empty string, and preceded by a 0 that must contain at least one more symbol deriving a non-empty string.",
        "We prove lemmas analogous to 3.1, 3.2, and 3.3.",
        "Lemma 4.1.",
        "For i < j < k let S(i,j) be the set of dotted rules that derive a[ij] and Si(j,k) the set of symbols that derive aU k I.",
        "The set of dotted rules that derive a[i k] using many symbols is",
        "This is the set of rules that derive a[i k] using many symbols, as noted above.",
        "If we have a = rs, then the set of dotted rules that derive a[0 1] is r .",
        "),(k > cf. .",
        "cgc),(k > cfc .",
        "gc)).",
        "The set of symbols that derive a[1 2] is {g ,s}.",
        "The set of dotted rules that derive a[0 2] using many symbols is {(k > cfcg .",
        "c),(k > cfcgc .)}",
        "Lemma 4.1 tells us that to compute this set we must apply SkipEmpty to the output of AdvanceDot.",
        "If we failed to apply SkipEmpty we would omit the dotted rule (k > cfcgc .)",
        "from our answer.",
        "Lemma 4.2.",
        "Suppose length(a) > 1 and S is the set of dotted rules that derive a using many symbols.",
        "The set of symbols that derive a is close(finished(S)).",
        "Proof.",
        "By induction as in Lemma 3.2.",
        "Definitions.",
        "Let RuleTable' be SkipEmpty({( A > .a) (A * a) E Pl) = {( A > a.a') E DR J a e}.",
        "If S is a set of symbols let NewRules'(S) be SkipEmpty(Advance Dot(RuleTable',S)).",
        "RuleTable' is like the RuleTable defined in Section 4, except that we apply SkipEmpty.",
        "In the example gram mar, this means adding the following dotted rules: (c > a .",
        "b)",
        "The following lemma tells us that NewRules' will perform the task that NewRules performed in Section 4.",
        "Lemma 4.3.",
        "If S is the set of symbols that derive a, the set of dotted rules that derive a using one symbol is NevvRules'( S).",
        "Proof.",
        "Expanding definitions gives SkipEmpty(AdvanceDotg(A > 13.01) E DR Iel,",
        "Theorem 4.1. dr(i,k) is the set of dotted rules that derive a[i k].",
        "Proof.",
        "By induction on the length of a[i k] as in the proof of theorem 3.1, but with lemmas 4.1, 4.2, and 4.3 replacing 3.1, 3.2, and 3.3, respectively.0 If a = rs we find that"
      ]
    },
    {
      "heading": "6 THE PARSER WITH TOP-DOWN FILTERING",
      "text": [
        "We have described two parsers that set dr(i,k) to the set of dotted rules that derive a[i k].",
        "We now consider a parser that uses top-down filtering to eliminate some useless rules from dr(i, k).",
        "Let us say that A follows p if the start symbol derives a string beginning with f3A.",
        "A dotted rule (A > x) follows p if A follows p. The new algorithm will set dr(i,k) to the set of dotted rules that derive a[i k] and follow a[0 i].",
        "If A derives a string beginning with B, we say that A can begin with B.",
        "The new algorithm requires a prediction table, which contains all pairs [A B] such that A can begin with B.",
        "Let P, be the set of pairs [A B] such that (A > pP0') is a rule and p e. Let P I be Pn U Link(Pn, P1).",
        "Lemma 5.1.",
        "The set of pairs [A B] such that A can begin with B is the union of Pn for all n1.",
        "Proof.",
        "By induction on the tree by which A derives a string beginning with B.",
        "Details are left to the reader.0 Our problem is to construct a finite representation for the prediction table.",
        "To see why this is difficult, consider a grammar containing the rule",
        "Q, subsumes Q2, and Q, is already a finite representation of a weak prediction table.",
        "The following lemma Computational Linguistics, Volume 15, Number 4, December 1989227 Andrew HaasA Parsing Algorithm for Unification Grammar shows that in general, the Q1 defined above allows us to build a finite representation of a weak prediction table.",
        "Lemma 5.2.",
        "Let Q1 be a set of pairs of terms that contains no function letters of cyclic sorts, and let Q, be as defined above for all i > 1.",
        "Then for some D, QD subsumes LP(QD,Q1).",
        "Proof.",
        "Note first that since unification never introduces a function letter that did not occur in the input, Q, contains no function letters of cyclic sort for any i 1.",
        "Let C be the number of noncyclic sorts in the language.",
        "Then the maximum depth of a term that contains no function letters of cyclic sorts is C + 1.",
        "Consider a term as a labeled tree, and consider any path from the root of such a tree to one of its leaves.",
        "The path can contain at most one variable or function letter of each noncyclic sort, plus one variable of a cyclic sort.",
        "Then its length is at most C + 1.",
        "Consider the set S of all pairs of terms in L that contain no function letters of cyclic sorts.",
        "Let us partition this set into equivalence classes, counting two terms equivalent if they are alphabetic variants.",
        "We claim that the number of equivalence classes is finite.",
        "Since there is a finite bound on the depths of terms in S, and a finite bound on the number of arguments of a function letter in S, there is a finite bound V on the number of variables in any term of S. Let v,...vK be a list of variables containing V variables from each sort.",
        "Then there is a finite number of pairs in S that use only variables from v,...i/K; let S' be the set of all such pairs.",
        "Now each pair p in S is an alphabetic variant of a pair in 5', for we can replace the variables of p one-for-one with variables from v,...vK.",
        "Therefore the number of equivalence classes is no more than the number of elements in S'.",
        "We call this number E. We claim that QD subsumes LP(QD,Q1) for some D E. To see this, suppose that a does not subsume LP(Q1,Q1) for all i < E. If a does not subsume LP(Q,,Q1), then Q11 intersects more equivalence classes than Q, does.",
        "Since Q, intersects at least one equivalence class, QE intersects all the equivalence classes.",
        "Therefore QE subsumes LP(QE,Q1), which was to be proved.E] This lemma tells us that we can build a weak prediction table for any grammar by throwing away all sub terms of cyclic sort.",
        "In the worst case, such a table might be too weak to be useful, but our experience suggests that for natural grammars a prediction table of this kind is very effective in reducing the size of the dr(i,k) s. In the following discussion we will assume that we have a complete prediction table; at the end of this section we will once again consider weak prediction tables.",
        "Definitions.",
        "If S is a set of symbols, let first(S) = S U { B I (3 A E S. [A B] E PredTable 1.",
        "If PredTable is indeed a complete prediction table, first(S) is the set of symbols B such that some symbol in S can begin with B.",
        "If R is a set of dotted rules let next(R) = {B I (3 A,0,13' (A ---> P.BP') E R}.",
        "Consider the following example grammar:",
        "The terminal symbols are r and s. In this grammar first({ start}) = {start, a,r}, and next({( a > r. g)}) = { g}.)",
        "The following lemma shows that we can find the set of symbols that follow a[0 j] if we have a prediction table and the sets of dotted rules that derive a[ij] for all i <I. Lemma 5.3.",
        "Let j satisfy 0 j length(a).",
        "Suppose that for 0 5_ i < j, SW is the set of dotted rules that follow a[0 i] and derive a[i j] (if j = 0 this is vacuous).",
        "Let start be the start symbol of the grammar.",
        "Then the set of symbols that follow a[0 j] is",
        "_-s j Proof.",
        "We show first that every member of the given set follows a[0 j].",
        "If j 0, certainly every member of first({startp follows a[0 01 = e. If j> 0, suppose that C follows a[0 I], (C ---> f3BP') is a rule, and a[ij]; then clearly B follows a[0 j].",
        "Next we show that if A follows a[0 j], A is in the given set.",
        "We prove by induction on d that if start a[0 j]Aa' by a tree t, and the leaf corresponding to the occurrence of A after a[0 j] is at depth d in t, then A belongs to the given set.",
        "If d = 0, then A = start, and j = 0.",
        "We must prove that start E first(Istartp, which is obvious.",
        "If d> 0 there are two cases.",
        "Suppose first that the leaf n corresponding to the occurrence of A after a[0 j] has younger brothers dominating a nonempty string (younger brothers of n are children of the same father occurring to the left of n).",
        "Then the father of n is admitted by a rule of the form (C--> pito).",
        "c is the label of the father of n, and f3 consists of the labels of the younger brothers of n in order.",
        "Then 0 a[i j], where 0 i < j.",
        "Removing the descendants of n's father from t gives a tree t' whose yield is a[0 i]Ca'.",
        "Therefore C follows a[0 i].",
        "We have shown that (C --> pAp') is a rule, C follows a[0 i], and p a[i j].",
        "Then (C --> f3.AP') E S(i), A E next(S(i)), and A E (Ui <j next(S(i))).",
        "Finally suppose that the younger brothers of n dominate the empty string in t. Then if C is the label of n's father, C can begin with A.",
        "Removing the descendants of n's father from t gives a tree t' whose yield begins with a[0 j]C. Then C belongs to the given set by induction hypothesis.",
        "If C E first(X) and C can begin with A, then A E first(X).",
        "Therefore A belongs to the given set.",
        "This completes the proof.",
        "As an example, let a = rs.",
        "Then the set of dotted rules that derive a[0 1] and follow a[0 0] is {(a ---> r. g)}.",
        "The dotted rule (c --> r. h) derives a[0 1], but it does not follow a[0 0] because c is not an element of first({start}).",
        "228Computational Linguistics, Volume 15, Number 4, December 1989 Andrew HaasA Parsing Algorithm for Unification Grammar We are finally ready to present the analogs of lemmas 3.1, 3.2, and 3.3 for the parser with prediction.",
        "Where the earlier lemmas mentioned the set of symbols (or dotted rules) that derive a[i j], these lemmas mention the set of symbols (or dotted rules) that follow a[0 i] and derive a[i j].",
        "Lemma 5.4.",
        "Let a be a nonempty string.",
        "Suppose that for i <j < k, S(i,j) is the set of dotted rules that follow a[0 i] and derive a[i j], while S'(j,k) is the set of symbols that follow a[0 j] and derive a[j k].",
        "The set of dotted rules that follow a[0 i] and derive a[i k] using many symbols is SkipEmpty(i<Ui<k AdvanceDot(S(i j), S '(j ,k))) Proof.",
        "Expanding definitions and using the same argument as in lemma 3.1, we have SkipEmpty(i<Uj<k AdvanceDot({(B > 0.0,) E DR I B follows a[0 i] A 0a[i j]} {A I A follows a[0 j] A A au j kfl) = SkipEmpty({(B ----> f3A.P2) E DR I B follows a[0 i] A (3 j. i<j <k A 0 a[i j] A A follows a[0 j] A A a[j) If B follows a[0 i], (B > PA 132) is a rule, and IS a[i j], then A follows a[0 j].",
        "Therefore the statement that A follows a[0 j] is redundant and can be deleted, giving SkipEmpty({(B > /3A.P2) E DR I B follows a[0 i] A (3 j. i<j<k A p a[i j] A Aa[j k])})This in turn is equal to {(B > 0A/3'.03) E DR I B follows a[0 i] A (3 j. i<j<k A 13 a[i j] AA a[j k]) A f3' el This is the set of dotted rules that follow a[0 i] and derive a[i k] using many symbols .0 Lemma 5.5.",
        "Suppose length(aU j/) > 1, S is the set of symbols that follow a[0 i], and S' is the set of dotted rules that follow a[0 i] and derive a[i j] using many symbols.",
        "Then S fl close(finished(S')) is the set of symbols that follow a[0 i] and derive a[i j].",
        "Proof.",
        "S' is a subset of the set of dotted rules that derive a[i j], so by lemma 4.2 and monotonicity, close(finished(S')) is a subset of the set of symbols that derive a[i j].",
        "Therefore every symbol in S F1 close(finished(S1))) derives a[i j] and follows a[0 i].",
        "This proves inclusion in one direction.",
        "For the other direction, suppose A follows a[0 i] and derives a[i j].",
        "Then by lemma 4.2 there is a dotted rule (B > p.) such that a[i j] using many symbols and AB.",
        "Then B follows a[0 i], so B is in finished(S'), which means that A is in S Fl close(finished(S')).0 Definition.",
        "If S is a set of symbols and R a set of dotted rules, filter(S,R) is the set of rules in R whose left sides are in S. In other words, filter(S,R) = {( A --> 0.0') ERI AES}.",
        "Lemma 5.6.",
        "Suppose S is the set of symbols that follow a[0 i], and S' is the set of symbols that follow a[0 i] and derive a[i j].",
        "Then the set of rules that follow a[0 i] and derive a[i j] using one symbol is filter(S,NewRules'(S')).",
        "Proof: S' is a subset of the set of symbols that derive a[i j].",
        "By lemma 4.3 and monotonicity, we know that every dotted rule in NewRules'(S') derives a[i j] using one symbol.",
        "Therefore every dotted rule in filter(S,NewRules(S')) follows a[0 i] and derives aU j] using one symbol.",
        "This proves inclusion in one direction.",
        "For the other direction, consider any dotted rule that follows a[0 i] and derives a[ij] using one symbol; it can be written in the form (A > 0B0'.p1), where and /3' derive e, B derives a[i j], and A follows a[0 i].",
        "Since /3 e, B follows a[0 i].",
        "Therefore B E S' and (A ---> 0B0'.01) is in NewRules'(S').",
        "Since A follows a[0 i], (A -> .p,) is in filter(S,NewRules'(S')).",
        "Let a be a string of length L. For 0-i<k5_ L, define",
        "Note that the new version of dr(i,k) is exactly like the previous version except that we filter the output of close by intersecting it with pred(i), and we filter the output of NewRules' by applying the function filter.",
        "Theorem 5.6 For 0--sk:sL, pred(k) is the set of symbols that follow a[0 i], and if 0-i< k, dr(i,k) is the set of dotted rules that follow a[0 i] and derive a[i k].",
        "Proof.",
        "This proof is similar to the proof of theorem 3.4, but it is more involved because we must show that pred(k) has the desired values.",
        "Once more we argue by induction, but this time it is a double induction: an outer induction on k, and an inner induction on the length of strings that end at k. We show by induction on k that pred(k) has the desired value and for Oi<k, dr(i,k) has the desired value.",
        "If k = 0, lemma 5.3 tells us that pred(0) is the set of symbols that follow a[0 01, and the second part of the induction hypothesis is vacuously true.",
        "If k > 0, we first show by induction on the length of a[i k] that dr(i,k) has the desired value for 0 This part of the proof is much like the proof of 3.4.",
        "If a[i k] has length 1, then pred(i) is the set of symbols that follow a[0 i] by the hypothesis of the induction on k. Then pred(i) 11 close({a[i k]).)",
        "is the set of symbols that follow a[0 i] and derive a[i k] , so lemma 5.6 tells us that filter(pred (i),NewRules'(pred(i) n close(fa[i k]}))) is the set of dotted rules that follow a[0 i] and derive a[i k].",
        "If length(a[i k]) > 1, consider any j such that i<j<k. dr(i,j) and dr(j,k) have the desired values by induction Computational Linguistics, Volume 15, Number 4, December 1989229 Andrew HaasA Parsing Algorithm for Unification Grammar hypothesis.",
        "Then lemma 5.4 tells us that rules, is the set of dotted rules that follow a[0 i] and derive a[i k] using many symbols.",
        "pred(i) is the set of symbols that follow a[0 i], so pred(i) fl close(finished(rides1)) is the set of symbols that follow a[0 i] and derive a[i k], by lemma 5.5.",
        "Therefore rules2 is the set of dotted rules that follow a[0 i] and derive a[i k] using one symbol, by lemma 5.6.",
        "The union of rulesi and rules2 is the set of dotted rules that follow a[0 i] and derive a[i k], and this completes the inner induction.",
        "To complete the outer induction, we use lemma 5.3 to show that pred(k) is the set of symbols that follow a[0 k].",
        "This completes the proof.0 Corollary: Start E finished(dr(0,L)) iff a is a sentence of the language generated by G. Suppose we are parsing the string rs using the example grammar.",
        "Then we have",
        "We have proved the correctness of the parser when it uses an ideal prediction table.",
        "We must still consider what happens when the parser uses a weak prediction table.",
        "Theorem 5.7.",
        "If PredTable is a superset of the set of all [A B] such that A can begin with B, then start E finished(dr(0,L)) iff a is a sentence of the language generated by G. Proof.",
        "Note that the parser with filtering always builds a smaller dr(i,k) than the parser without filtering.",
        "Since all the operations of the parser are monotonic, this is an easy induction.",
        "So if the parser with filtering puts the start symbol in dr(0,L), the parser without filtering will do this also, implying that a is a sentence.",
        "Note also that the parser with filtering produces a larger dr(i,k) given a larger PredTable (again, this follows easily because all operations in the parser are monotonic).",
        "So if a is a sentence, the parser with the ideal prediction table includes Start in dr(0,L), and so does the parser with the weak prediction table.0"
      ]
    },
    {
      "heading": "7 DISCUSSION AND IMPLEMENTATION NOTES 7.1 RELATED WORK AND POSSIBLE EXTENSIONS",
      "text": [
        "The chief contribution of the present paper is to define a class of grammars on which bottom-up parsers always halt, and to give a semi-decision procedure for this class.",
        "This in turn makes it possible to prove a completeness theorem, which is impossible if one considers arbitrary unification grammars.",
        "One can obtain similar results for the class of grammars whose context-free backbone is finitely ambiguouswhat Pereira and Warren (1983) called the offline-parsable grammars.",
        "However, as Shieber (1985b) observed, this class of grammars excludes many linguistically interesting grammars that do not use atomic category symbols.",
        "The present parser (as opposed to the table-building algorithm) is much like those in the literature.",
        "Like nearly all parsers using term unification, it is a special case of Earley deduction (Pereira and Warren 1985).",
        "The tables are simply collections of theorems proved in advance and added to the program component of Earley deduction.",
        "Earley deduction is a framework for parsing rather than a parser.",
        "Among implemented parsers, BUP (Matsumota et al.",
        "1983) is particularly close to the present work.",
        "It is a bottom-up left-corner parser using term unification.",
        "It is written in Prolog and uses backtracking, but by recording its results as clauses in the Prolog database it avoids most backtracking, so that it is close to a chart parser.",
        "It also includes top-down filtering, although it uses only category symbols in filtering.",
        "The paper includes suggestions for handling rules with empty right sides as well.",
        "The main difference from the present work is that the authors do not describe the class of grammars on which their algorithm halts, and as a result they cannot prove completeness.",
        "The grammar formalism presented here is much simpler than many formalisms called \"unification grammars.\" There are no meta-rules, no default values of features, no general agreement principles (Gazdar et al.",
        "1986).",
        "We have found this formalism adequate to describe a substantial part of English syntaxat least, substantial by present-day standards.",
        "Our grammar currently contains about 300 syntactic rules, not counting simple rules that introduce single terminals.",
        "It includes a thorough treatment of verb subcategorization and less thorough treatments of noun and adjective subcategorization.",
        "It covers major construction types: raising, control, passive, subject-aux inversion, imperatives, wh-movement (both questions and relative clauses), determiners, and comparatives.",
        "It assigns parses to 85% of a corpus of 791 sentences.",
        "See Ayuso et al.",
        "1988 for a description of the grammar.",
        "It is clear that some generalizations are being missed.",
        "For example, to handle passive we enumerate by hand the rules that other formalisms would derive by meta rule.",
        "We are certainly missing a generalization here, but we have found this crude approach quite practicalour coverage is wide and our grammar is not hard to maintain.",
        "Nevertheless, we would like to add meta rules and probably some general feature-passing principles.. We hope to treat them as abbreviation mechanismswe would define the semantics of a general feature-passing principal by showing how a grammar using that principal can be translated into a grammar written in our original formalism.",
        "We also hope to add feature disjunction to our grammar (see Kasper 1987; Kasper and Rounds 1986).",
        "Though our formalism is limited, it has one property that is theoretically interesting: a sharp separation between the details of unification and the parsing mechanism.",
        "We proved in Section 3 that unification allows us to compute certain functions and predicates on sets of grammatical expressionssymbolic products, unions, 230Computational Linguistics, Volume 15, Number 4, December 1989 Andrew HaasA Parsing Algorithm for Unification Grammar and so forth.",
        "In Section 4 and 5 we assumed that these functions were available as primitives and used them to build bottom-up parsers.",
        "Nothing in Sections 4 and 5 depends on the details of unification.",
        "If we replace standard unification with another mechanism, we have only to reprove the results of Section 3 and the correctness theorems of Sections 4 and 5 follow at once.",
        "To see that this is not a trivial result, notice that we failed to maintain this separation in Section 6.",
        "To show that one can build a complete prediction table, we had to consider the details of unification: we mentioned terms like \"alphabetic variant\" and \"subsumption.\" We have presented a theory of bottom-up parsing that is general in the sense that it does not rely on a particular pattern-matching mechanismit applies to any mechanism for which the results of Section 3 hold.",
        "We claim that these results should hold for any reasonable pattern-matching mechanism; the reader must judge this claim by his or her own intuition.",
        "One drawback of this work is that depth-boundedness is undecidable.",
        "To prove this, show that any Turing machine can be represented as a unification grammar, and then show that an algorithm that decides depth-boundedness can also solve the halting problem.",
        "This result raises the question: is there a subset of the depth-bounded grammars that is strong enough to describe natural language, and for which membership is decidable?",
        "Recall the context-free backbone of a grammar, described in the Introduction.",
        "One can form a context free backbone for a unification grammar by keeping only the topmost function letters in each rule.",
        "There is an algorithm to decide whether this backbone is depth bounded, and if the backbone is depth-bounded, so is the original grammar (because the backbone admits every derivation tree that the original grammar admits).",
        "Unfortunately this class of grammars is too restricted it excludes rules like (major-category(n,2) > majorcategory(n,1)), which may well be needed in grammars for natural language.",
        "Erasing everything but the top function letter of each term is drastic.",
        "Instead, let us form a \"backbone\" by applying the transformation of Section 6, which eliminates cyclic function letters.",
        "We can call the resulting grammar the acyclic backbone of the original grammar.",
        "We showed in Section 6 that if we eliminate cyclic function letters, then the relation of alphabetic variance will partition the set of all terms into a finite number of equivalence classes.",
        "We used this fact to prove that the algorithm for building a weak prediction table always halts.",
        "By similar methods we can construct an algorithm that decides depth-boundedness for grammars without cyclic function letters.",
        "Then the grammars whose acyclic backbones are depth-bounded form a decidable subset of the depth-bounded grammars.",
        "One can prove that this class of grammars generates the same languages as the off-line parsable grammars.",
        "Unlike the off-line parsable grammars, they do not require atomic category symbols.",
        "A forthcoming paper will discuss these matters in detail."
      ]
    },
    {
      "heading": "7.2 THE IMPLEMENTATION",
      "text": [
        "Our implementation is a Common Lisp program on a Symbolics Lisp Machine.",
        "The algorithm as stated is recursive, but the implementation is a chart parser.",
        "It builds a matrix called \"rules\" and sets rules[i k] equal to dr(i,k), considering pairs [i k] in the same order used for the induction argument in the proof.",
        "It also builds a matrix \"symbols\" and sets symbols[i k] to the set of symbols that derive a[i k], and a matrix pred with pred[i] equal to the set of symbols that follow a[0 i].",
        "Currently the standard parser does not incorporate prediction.",
        "We have found that prediction reduces the size of the chart dramatically, but the cost of prediction is so great that a purely bottom-up parser runs faster.",
        "total time (in seconds)917220115381085 Table 1 presents the results of predicting different features on a sample of 11 sentences.",
        "It describes parsing without prediction, with prediction of categories only, with traces and categories, and finally with categories, traces, and verb form information.",
        "In each case it lists the total number of entries in the matrices \"rules\" and \"symbols\" for every sentence, and the total time to parse the 11 sentences.",
        "The reader should compare this table with the one in Shieber 1985.",
        "Shieber tried predicting subcategorization information along with categories.",
        "In our grammar there is a separate VP rule for each subcategorization frame, and this rule gives the categories of all arguments of the verb.",
        "Shieber eliminated these multiple VP rules by making the list of arguments a feature of the verb.",
        "Therefore by predicting categories alone, we get the same information that Shieber got by predicting subcategorization information.",
        "The table shows that for our grammar, prediction reduces the chart size drastically, but it is so costly that a straight bottom-up parser runs faster than any version of prediction.",
        "The parsing tables for the present grammar are quite tractable.",
        "The largest table is the table of chain rules, which has 2,270 entries and takes under ten minutes to build.",
        "A prediction table that predicts categories, traces, and verb forms has 1,510 entries and takes six minutes to build.",
        "Computational Linguistics, Volume 15, Number 4, December 1989231 Andrew HaasA Parsing Algorithm for Unification Grammar In the special case of a context-free grammar, our parsing program is essentially the same as the parser of Graham et al.",
        "(1980), in particular algorithm 2.2 of that paper.",
        "The only significant differences are that their chart includes entries for empty substrings, which we omit, and that we record symbols while they record only dotted rules.",
        "When running on a context-free grammar, the parser takes time proportional to the cube of the length n of the input stringbecause the number of symbolic products is proportional to n3, and the time for a symbolic product is independent of the input string.",
        "This result also holds for a grammar without cyclic function letters.",
        "If there are cyclic function letters, the size of the nonterminals built by the parser depends on the length of the input, so the time for unifications and symbolic products is no longer independent of the input, and the parsing time is not bounded by n3.",
        "To save storage we use a simplified version of structure-sharing (Boyer and Moore 1972).",
        "Following the suggestion of Pereira and Warren (1983), we use structure-sharing only for dotted rules with symbols remaining after the dot.",
        "When the dot reaches the end of the right side of a rule, we translate the left side of the rule back to standard representation.",
        "This method guarantees that in each resolution only one resolvent is in structure-sharing representation.",
        "Instead of general resolution we are doing what the theorem-proving literature calls input resolution.",
        "This allows us to represent a substitution as a simple association list, using the function assoc to retrieve the substitutions that have been made for variables.",
        "Pereira (1985) describes a more sophisticated version of structure-sharing.",
        "This method has two advantages over our version.",
        "First, the time to retrieve a substitution is 0(log n), where n is the length of the derivation, compared to 0(n) for Boyer-Moore.",
        "Second, only symbols that derive the empty string need to be translated from structure-sharing form to the standard representation, and this saves storage.",
        "The first advantage may not be important, for two reasons.",
        "By using a single assoc to retrieve a substitution, we reduce the constant factor in 0(n).",
        "Also by eliminating the structure sharing each time the dot reaches the end of a rule, we keep our derivations shortn is no more than the length of the right side of the longest rule.",
        "The second advantage of Pereira's method is more important, since our current parser uses a lot of storage.",
        "The other optimizations are fairly obvious.",
        "As usual we skip the occur check in our unifications (as long as there are no cyclic sorts, this is guaranteed to be safe).",
        "In each symbolic product, one set is indexed by the topmost function letter of the term to be matched, which saves a good number of failed unifications.",
        "These simple techniques gave us adequate performance for some time, but as the grammar grew the parser slowed down, and we decided to rewrite the program in C. This version, running on a Sun 4, is much more efficient.",
        "It parses a corpus of 790 sentences, with an average length of nine words, in half an hour."
      ]
    },
    {
      "heading": "ACKNOWLEDGEMENTS",
      "text": [
        "I wish to thank an anonymous referee, whose careful reading and detailed comments greatly improved this paper.",
        "This work was supported by the Defense Advanced Research Projects Agency under contract numbers N00014-87-C-0085 and N00014-85-C-0079."
      ]
    },
    {
      "heading": "REFERENCES",
      "text": []
    }
  ]
}
