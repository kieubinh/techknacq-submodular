{
  "info": {
    "authors": [
      "Kazuhiko Ozeki"
    ],
    "book": "International Conference on Computational Linguistics",
    "id": "acl-C90-2054",
    "title": "A Polynomial-Order Algorithm for Optimal Phrase Sequence Selection from a Phrase Lattice and Its Parallel Layered Implementation",
    "url": "https://aclweb.org/anthology/C90-2054",
    "year": 1990
  },
  "references": [
    "acl-C80-1003",
    "acl-C88-1082"
  ],
  "sections": [
    {
      "heading": "Abstract",
      "text": [
        "This paper deals with a problem of selecting an optimal phrase sequence from a phrase lattice, which is often encountered in language processing such as word processing and post-processing for speech recognition.",
        "The problem is formulated as one of combinatorial optimization, and a polynomial order algorithm is derived.",
        "This algorithm finds an optimal phrase sequence and its dependency structure simultaneously, and is therefore particularly suited for an interface between speech recognition and various language processing.",
        "What the algorithm does is numerical optimization rather than symbolic operation unlike conventional parsers.",
        "A parallel and layered structure to implement the algorithm is also presented.",
        "Although the language taken up here is Japanese, the algorithm can be extended to cover a wider family of languages."
      ]
    },
    {
      "heading": "1. Introduction",
      "text": [
        "In Japanese language processing related to speech recognition and word processing, we often encounter a problem of selecting a phrase sequence which constitutes the most acceptable sentence from a phrase lattice, that is, a set of phrases with various starting and ending positions, By solving this problem, linguistic ambiguities and/or uncertainties coming from the inaccuracy in speech recognition are expected to be resolved.",
        "This problem can be solved, in principle, by enumerating all the possible combinations of the phrases and measuring the syntactic and semantic acceptability of each phrase sequence as a sentence.",
        "Obviously, however, the amount of computation in this enumerative method grows exponentially with respect to the length of the sequence and becomes intractable even for a moderate problem size.",
        "In this paper we formulate this task as a combinatorial optimization problem and derive a set of recurrence equations, which leads to an algorithm of polynomial order in time and space.",
        "We utilize the idea of dependency grammar [Hays 64] for defining the acceptability of a phrase sequence as a Japanese sentence.",
        "With a review of recent theoretical development on this topic, a parallel and layered implementation of the algorithm is presented.",
        "2.",
        "Dependency Structure of Japanese",
        "In Japanese, words and morphemes are concatenated to form a linguistic unit called 'bunsetsn', which is referred to as simply 'phrase' here.",
        "A typical phrase consists of a content word followed by some functional morphemes.",
        "A Japanese sentence is a sequence of phrases with a structure which can be described by a diagram as in Fig.1 [Hashimoto 46].",
        "For a sequence of phrases xix2...xn to be a well-formed Japanese sentence, it must have a structure satisfying the following constraints [Yoshida 72]:",
        "(c1) For any i (1<i<n-1), there exists unique j (i<j<n) such that xi modifies xj in a wide sense.",
        "(c2) For any i,j,k,l (1<i<j<k<1<n), it never occurs that xi modifies xk and xj modifies x1.",
        "A structure satisfying these constraints is called a dependency structure here.",
        "More formally we define a dependency structure as follows [Ozeki 86a].",
        "Definition 1",
        "(1) If x0 is a phrase, then <x0> is a dependency structure.",
        "(2) If XI Xn are dependency structures and x0 is a phrase, then <X1...Xn x0> is a dependency structure.",
        "A dependency structure <X1.",
        ".",
        ".Xn x0> (Xi=<...xi>) implies that each xi, which is the last phrase in Xi, modifies x0.",
        "It is easily verified that a structure satisfying the constraints (c1) and (c2) is a dependency structure in the sense of Definition 1 and vice versa [Ozeki 86a].",
        "When a dependency structure X is composed of phrases xi,x2 xn we say that X is a dependency structure on x1x2...xn.",
        "The set of all the dependency structures on x1x2...xn is denoted as K(x1x2...xn): and for a sequence of phrase sets A1,A2 , An, we define KB(Ai,A2 , An) ={XIXEK(x1x2...xn), xieAi (1<i<n)}.",
        "A B D E Fig.l Example of dependency structure in Japanese.",
        "A,B,... are phrases.",
        "3.",
        "Acceptability of a Dependency Structure",
        "For a pair of phrases xl and x0, we can think of a penalty imposed on a modifier-modificant relation between xl and x0.",
        "This non-negative value is denoted as pen(xl:x0).",
        "The smaller value of pen(x1;x0) represents the more natural linguistic relation.",
        "Although it is very important to establish a way of computing pen(x1;x0), we will not go into that problem in this paper.",
        "Based on the 'local' penalty, a 'global' penalty P(X) of a dependency structure X is defined recursively as follows [Ozeki 86a].",
        "Definition 2",
        "(1) For X=<x>, P(X)=0.",
        "(2) For X=<X1...Xn xp, where Xi=<...xi> (1<i<n) is a dependency structure,",
        "Note that P(X) is the sum of the penalty of all the phrase pairs which are supposed to be in modifier-modificant relation in the dependency structure X.",
        "This function is invariant under permutation of Xi Xn in accordance with the characteristic of Japanese.",
        "4.",
        "Formulation of the Problem For simplicity, let us begin with a special type of phrase lattice composed of a sequence of phrase sets 131,B2 BN as shown in Fig.2, which we call phrase matrix.",
        "Suppose we are given a phrase matrix and a reliability function",
        "where R+ denotes the set of non-negative real numbers.",
        "The smaller value of s(x) represents the higher reliability of x.",
        "We encounter this special type of phrase lattice in isolated phrase speech recognition.",
        "In that case Bi is the set of output candidates for the ith utterance, and s(x) is the recognition score for a candidate phrase x."
      ]
    },
    {
      "heading": "For a dependency structure X on a phrase",
      "text": [
        "sequence x1x2...xN, the total reliability",
        "Combining the acceptability and the reliability, we define an objective function F(X) as",
        "Fig.2 Phrase matrix.",
        "B1 BN are phrase sets.",
        "Then the central problem here is formulated as the following combinatorial optimization problem Natsunaga 86, Ozeki 86a].",
        "Problem Find a dependency structure",
        "which minimizes the objective function F(X).",
        "By solving this problem, we can obtain the optimal phrase sequence and the optimal dependency structure on the sequence simultaneously.",
        "When I1311=1B21=...=IBNI= M. we have IKB(131,B2 , knuN BN)I= (2(N...1)C(N_I))/0,.",
        "where C denotes combination.",
        "This becomes a huge number even for a moderate problem size, rendering an enumerative method practically impossible.",
        "5.",
        "Recurrence equations and a resulting algorithm",
        "Combining two dependency structures X and Y=<Y1 , Ym,y>, a new dependency structure <X,Y1 , Ym,y> is obtained which is denoted as X ED Y. Conversely, any dependency structure Z with length greater than 1 can be decomposed as Z= X (D Y, where X is the top dependency structure in Z.",
        "Moreover, it is easily verified from the definition of the objective function that F(Z)= F(X) + F(Y) + pen(x;y), where x and y are the last phrases in X and Y. respectively.",
        "The following argument is based on this fact.",
        "We denote elements in B. as x. x.. ji, .",
        "For 1<i<j<N and 1<p<113.0, where IBjI denotes the number of elements in B. we define opt(i,j;p) =mintF(X)1XeKB(Bi,...,Bj_1(xjp))) and opts(i,j;p) =argminIF(X)1)(00(Bi Bj_1ixjp))1.",
        "Then the following recurrence equations hold for opt(i,j;p) and opts(i,j;p), respectively COzeki 86a].",
        "Proposition 1 For 1<i<j<N and 1<p<IBil.",
        "(1) if i=j, then opt(i,j;0=s(xjp), (2) and if i<j, then",
        "opt(i,j;p) =min{f(k,q)li<k<j-1,1<q<IBk1}, where f(k,q)=opt(i,k;q)+opt(k+1,j;p) +pen(xko;xin).",
        "Proposition 1' For 1<i<j<N and 1<y<IBJI.",
        "(1) if i=j, then opts(i,j;P)=<xjp>, (2) and if i<j, then",
        "opts(i,j;p) =opts(i,*k;*q)C)opts(*k+1,j;P).",
        "where *k is the best segmentation point and *q is the best phrase number in B*k: (*k,*q)=argmin(f(k,q)Ii<k<j-1,1<q<IBk1).",
        "According to Proposition 1, if the values of opt(i,k;q) and opt(k+1,j;p) are known for 1<k<j-1 and 1<q<IBkl, it is possible to calculate the value of opt(i,j;p) by searching the best segmentation point and the best phrase number at the segmentation point.",
        "This fact enables us to calculate the value",
        "of opt(1,N;p) recursively, starting with opt(i,i;q) (1<i0,1<q<IB11).",
        "This is the principle of dynamic programming [Bellman 57].",
        "Let *p= argmin(opt(1,N:p)I1<p<IBNI), then we have the final solution opt(1,N:*p)=min(F(X)IXEKB(B1 BN)) and",
        "The opts(1,N;*p) can be calculated recursively using Proposition 2.",
        "Fig.3 illustrates an algorithm translated from these recurrence equations [Ozeki 86a].",
        "This algorithm uses two tables, tableland table2, of upper triangular matrix form as shown in Fig.4.",
        "The (i,j) element of the matrixhasIB.I'pigeon-holes'.",
        "The value of opt(i,j;p) is stored in tableland the pair of the best segmentation point and the best phrase number is stored in table?.",
        "It should be noted that there is much freedom in the order of scanning i,j and p, which will be utilized when we discuss a parallel implementation of the algorithm.",
        "Optimal_Dependency_Structure; begin /* Analysis Phase */ for j:=1 to N do for i:=j downto 1 do for p:=1 to 113j) do if i=j then",
        "begin if i=j then opts:='<xjp>';",
        "else begin (*k,*q):=table2(i,j;p); opts:=opts(i,*k;*q) opts(*k+1,i;O: end; end.",
        "Fig.3 Algorithm to select an optimal dependency structure from a phrase matrix.",
        "Fig.5 Example of phrase lattice.",
        "When 11311----IBNI=M, the number of operations (additions and comparisons) necessary to fill tablel is 0(M2N3).",
        "These recurrence equations and algorithm can be easily extended so that they can handle a general phrase lattice.",
        "A Phrase lattice is a set of phrase sets, which looks like Fig.5.",
        "B(i,j) denotes the set of phrases beginning at character position i and ending at j.",
        "A phrase lattice is obtained, for example, as the output of a continuous speech recognition system, and also as the result of a morphological analysis of non-segmented Japanese text spelled in kana characters only.",
        "We denote the elements of B(i,j) as xiji,xij2,..., and in parallel with the definition of opt and opts, we define opt' and opts' as follows.",
        "For l<i<m<j<N and xmjp, opt'(i,j,m;p) =the minimum value of [P(X)+S(X)] as X runs over all the dependency structures on all the possible phrase sequences beginning at i and ending at j with the last phrase being fixed as xmjp, and opts'(i,j,m,p) =the dependency structure which gives the above minimum.",
        "Then recurrence equations similar to Proposition 1 and Proposition l' hold for opt' and opts'[Ozeki 86b]: Proposition 2 For 1<i<m<j<N and 1<p<IB(m,j)I,",
        "In this example, and IBI1=..AB71=3.",
        "(2) and if i<m, then opt'(i,j,m;p) =min{f(k.n.q)li<n<k<m-1,1<q<IB(n,k)H, where",
        "(2) and if i<m, then opts'(i,j,m;p) =opts'(i,*k,*n:*q)C)opts'(*k+1,j,m;p), where *k is the best segmentation point, *n is the top position of the best phrase at the segmentation point and *q is the best phrase number in B(*n,*k): (*k,*n,*q) =argmintf(k,n,q)li<n<k<m-1,1<q<IB(n,k)11.",
        "The minimum is searched on 3 variables in this case.",
        "It is a straight forward matter to translate these recurrence equations into an algorithm similar to Fig.3 [Ozeki 86b, Kohda 86].",
        "In this case, the order of amount of computation is 0(M2N5), where M=IB(i.j)1 and N is the number of starting and ending positions of phrases in the",
        "Also, we can modify the algorithm in such a way that up to kth optimal solutions are obtained.",
        "6.",
        "Parallel and Layered Implementation",
        "When only one processor is available, the amount of computation dominates the processing time.",
        "On the other hand, when there is no limit as to the number of processors, the processing time depends on how much of the computation can be executed in parallel.",
        "There exists a tidy parallel and layered structure to implement the above algorithm.",
        "For simplicity, let us confine ourselves to a phrase matrix case here.",
        "Furthermore, let us first consider the case where there is only one element xi in each of the phrase set Bi.",
        "If we define opt\"(i,j)=min(P(X)1X81((xi , xi)) then Proposition 1 is reduced to the following simpler form.",
        "Proposition 3 For 1<i<j<N,",
        "(1) if i=j, then opt\"(i,j)=0, (2) and if i<j, then",
        "It is easy to see that opt\"(i,j) and opt\"(i+m,j+m) (mt0) can be calculated independently of each other.",
        "This motivates us to devise a parallel and layered computation structure in which processing elements are arranged in a 2-dimensional array as shown in Fig.6.",
        "There are N(N+l)/2 processing elements in total.",
        "The node(i,j) has an internal structure as shown in Fig.7, and is connected with node(i,k) and node(k+1,j) (1<k<j-1) as in Fig.8.",
        "The bottom elements, node(i,i)'s (1<i<N), hold value 0 and do nothing else.",
        "The node(i,j) calculates the value of opt\"(i,j) and holds the result in memory 1 together with the optimal segmentation point in memory 2.",
        "Within a layer all the nodes work independently in parallel and the computation proceeds from the lower to upper layer.",
        "An upper node receives information about a longer subsequence than a lower node: an upper node processes more global information than a lower node.",
        "When",
        "the top element, node(1,N), finishes its job, each node holds information which is necessary to compose the optimal dependency trticture on xix2...xN.",
        "This computation structure, having many simple interrelated computing elements, might be reminiscent of A connectionist model or a neural network.",
        "This result can be easily extended, based on Proposition 1, to the case in which each phrase set has more than one elements.",
        "In this case processing elements are arranged in a 3-dimensional array as shown in Fig.9.",
        "The bottom elements, node(i,i;p)'s, hold the value of s(xip).",
        "The node(i,j;p) calculates the value of opt(i,j;p).",
        "The computation proceeds from the lower to upper layer just as in the previous simpler case.",
        "Further extension of this structure is also possible :() that it can handle a general phrase lattice."
      ]
    },
    {
      "heading": "Y. Related Works",
      "text": [
        "The problem of selecting an appropriate phrase sequence from a phrase lattice has been treated in the field of Japanese word processing, where a non-segmented Japanese Text spelled in kana character must be converted into an orthographic style spelled in kana and kanji.",
        "Several practical methods have been devised so far.",
        "Among them, the approach in [Oshima 86] is close in idea to the present one in that it utilizes the Japanese case grammar in order to disambiguate a phrase lattice.",
        "However, their method is enumeration-oriented and some kind of heuristic process is necessary to reduce the size of the phrase lattice before syntactic analysis is performed.",
        "In order to disambiguate the result of speech recognition, an application of dependency analysis was attempted [Matsunaga 86, Matsunaga 87].",
        "The algorithm used is a bottom-up, depth-first search, and it is reported that it takes considerable processing time.",
        "By introducing a beam search technique, computing time can be very much reduced [Nakagawa 87], but with loss of global optimality.",
        "Perhaps the most closely related algorithm will be (extended)CYK algorithm with probabilistic rewriting rules [Levinson 85, Ney 87, Nakagawa 87].",
        "In spite of the difference in the initial ideas and the formulations, both approaches lead to similar bottom-up, breadth-first algorithms based on the principle of dynamic programming.",
        "In Fig.2, if each phrase set has only one phrase, and the value of between-phrase penalty is 0 or 1, then the algorithm reduces to the conventional Japanese dependency analyzer [Hitaka 80].",
        "Thus, the algorithm presented here is a twofold extension of the conventional Japanese dependency analyzer: the value of between-phrase penalty can take an arbitrary real number and it can analyze not only a phrase sequence but a phrase matrix and a phrase lattice in polynomial time.",
        "We have considered a special type of dependency structure in this paper, in which a modificant never precedes the modifier as is normally the case in Japanese.",
        "It has been shown that the algorithm can be extended to cover a more general dependency structure [Katoh 89].",
        "The fundamental algorithm presented here has been modified and extended, and utilized for speech recognition [Matsunaga 88]."
      ]
    },
    {
      "heading": "8. Concluding Remarks",
      "text": [
        "In the method presented here, the linguistic data and the algorithm are completely separated.",
        "The linguistic data are condensed in the penalty function which measures the naturalness of modifier-modificant relation between two phrases.",
        "No heuristics has slipped into the algorithm.",
        "This makes the whole procedure very transparent.",
        "The essential part of the algorithm is execution of numerical optimization rather than symbolic matching unlike conventional parsers.",
        "Therefore it can be easily implemented on an arithmetic processor such as DSP (Digital Signal Processor).",
        "The parallel",
        "and layered structure will fit LSI implementation.",
        "An obvious limitation of this method is that it takes account of only pairwise relation between phrases.",
        "Because of this, the class of sentences which have a low penalty in the present criterion tends to be broader than the class of sentences which we normally consider acceptable.",
        "Nevertheless, this method is useful in reducing the number of candidates so that a more sophisticated linguistic analysis becomes possible within realistic computing time in a later stage.",
        "A reasonable way of computing the penalty for a phrase pair is yet to be established.",
        "There seems to be two approaches to this problem: a deterministic approach taking syntactic and semantic relation between two phrases into consideration, and a statistical one based on the frequency of co-occurence of two phrases."
      ]
    },
    {
      "heading": "Acknowledgement",
      "text": [
        "The author is grateful to the support of Hoso Bunka Foundation for this work."
      ]
    }
  ]
}
