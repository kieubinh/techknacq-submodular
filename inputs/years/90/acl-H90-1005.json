{
  "info": {
    "authors": [
      "Fernando Pereira"
    ],
    "book": "Workshop on Speech and Natural Language",
    "id": "acl-H90-1005",
    "title": "Finite-State Approximations of Grammars",
    "url": "https://aclweb.org/anthology/H90-1005",
    "year": 1990
  },
  "references": [
    "acl-J82-3004",
    "acl-P85-1018"
  ],
  "sections": [
    {
      "text": [
        "Grammars for spoken language systems are subject to the conflicting requirements of language modeling for recognition and of language analysis for sentence interpretation.",
        "Current recognition algorithms can most directly use finite-state acceptor (FSA) language models.",
        "However, these models are inadequate for language interpretation, since they cannot express the relevant syntactic and semantic regularities.",
        "Augmented phrase structure grammar (APSG) formalisms, such as unification grammars, can express many of those regularities, but they are computationally less suitable for language modeling, because of the inherent cost of computing state transitions in APSG parsers.",
        "The above problems might be circumvented by using separate grammars for language modeling and language interpretation.",
        "Ideally, the recognition grammar should not reject sentences acceptable by the interpretation grammar, but it should contain as much as possible of the constraints built into the interpretation grammar.",
        "However, if the two grammars are built independently, those constraints are difficult to maintain.",
        "For this reason, we have developed a method for constructng automatically a finite-state approximation for an APSG.",
        "Since the purpose of the approximation is to serve as a filter in a speech-recognition front-end to the real parser, the approximation language is a superset of the language accepted by the APSG.",
        "The term \"approximation\" will always be used in this sense in what follows.",
        "If no further constraints were placed on the closeness of the approximation, the trivial algorithm that assigns to any APSG over alphabet E the regular language E* would do.",
        "Clearly, this is not what is required.",
        "One possible criterion for \"goodness\" of approximation arises from the observation that many interesting phrase structure grammars have substantial parts that accept regular languages.",
        "That does not mean that the grammar rules are in the standard forms for defining regular languages (left-linear or right-linear), because syntactic and semantic considerations often require that strings in a regular set be assigned structural descriptions not definable by regular productions.",
        "A useful criterion is thus that if a grammar generates a regular language, the approximation algorithm yields an acceptor for that regular language.",
        "In other words, one would like the algorithm to be exact for APSGs yielding regular languages.",
        "We have not yet proved that our method satisfies the above exactness criterion, but some experiments have shown that the method is exact for a variety of interesting grammars.",
        "The Algorithm Our approximation method applies to any context-free grammar (CFG), or any unification grammar that can be fully expanded into a context-free grammar.",
        "The resulting FSA accepts a superset of the sentences accepted by the input grammar.",
        "The current implementation accepts as input a form of unification grammar in which features can take only atomic values drawn from a specified finite set.",
        "It is clear that such grammars can only generate context-free languages, since an equivalent CFG can be obtained by instantiating features in rules in all possible ways.",
        "The heart of our approximation method is an algorithm to convert the LR(0) characteristic machine M(G) (Aho and Ullman, 1977; Backhouse, 1979) of a CFG G into an FSA for a superset of the language L(G) defined by G. The characteristic machine for a CFG G is an FSA for the viable prefixes of G, which are just the possible stacks built by the standard shift-reduce recognizer for G when recognizing strings in L(G).",
        "This is not the place to review the characteristic machine construction in detail.",
        "However, to explain the approximation algorithm we will need to recall the main aspects of the construction.",
        "The states of M(G) are sets of dotted rules A a where A + afl is some rule of G. M(G) is the determinization by the standard subset construction (Aho and Ullman, 1977) of the FSA defined as follows: The initial state is the dotted rule S' > S. where S is the start symbol of G and S' is a new auxiliary start symbol.",
        "The final state is S'S.",
        "lUnification grammars not in this class must first be weakened using techniques such as Shieber's restrictor (Shieber, 1985).",
        "The other states are all the possible dotted rules of G. There is a transition labeled X, where X is a terminal or nonterminal symbol, from dotted rule A --+ a Xi3 to A 4, aX [3.",
        "There is an &transition from A a Bi3 to B-7, where B is a nonterminal symbol and B --+ 7 a rule in G. M(G) can be seen as a finite state control for a non deterministic shift-reduce pushdown recognizer for G. A state transition labeled by a terminal symbol x from state s to state s' licenses a shift move, pushing onto the stack of the recognizer the pair (s, tx).",
        "Arrival at a state containing a completed dotted rule A a licenses a reduction move.",
        "This pops from the stack as many pairs as the symbols in a, checking that the symbols in the pairs match the corresponding elements of a, and then takes the transition out of the last state popped s labeled by A, pushing (s, A) onto the stack.",
        "The basic ingredient of our approximation algorithm is the flattening of a shift-reduce recognizer for a grammar G into an FSA by eliminating the stack and turning reduce moves into &transitions.",
        "However, as we will see below, flattening the characteristic machine recognizer directly will lead to poor approximations in many interesting cases.",
        "Instead, the characteristic machine must be unfolded into a larger machine whose states carry information about the possible shift-reduce stacks at states of the characteristic machine.",
        "The quality of the approximation is crucially influenced by how much stack information is encoded in the states of the unfolded machine too little leads to coarse approximations, while too much leads to redundant automata needing very expensive optimization.",
        "The algorithm is best understood with a simple example.",
        "Consider the left-linear grammar G1",
        "activated the rule being reduced.",
        "Thus the corresponding &transition goes from state 4 to state 2.",
        "Adding all the transitions that arise in this way we obtain the FSA in Figure 2.",
        "From this point on, the arcs labeled with nonterminals can be deleted.",
        "Doing that and simplifying, we get finally the FSA in Figure 3. which is the minimal FSA for the input left-linear grammar.",
        "If flattening were applied to the LR(0) characteristic machine as in the example above, even simple grammars defining regular languages might be inexactly approximated by the algorithm.",
        "The reason for this is that in general the reduction at a given reducing state in the characteristic machine transfers to different states depending on stack contents.",
        "In other words, the reducing state might be reached by different routes which use the result of the reduction in different ways.",
        "Consider for example the grammar G2 S aXa I bXb X --+ c which accepts the two strings aca and bcb.",
        "Flattening M(G2) will produce an FSA that will also accept acb and bca, clearly an undesirable outcome.",
        "The reason for this is that the &transitions leaving the reducing state containing X + c do not distinguish between the different ways of reaching that state, which are encoded in the stack of the characteristic recognizer One way of solving the above problem is to unfold each state of the characteristic machine into a set of states corresponding to different stacks at that state, and flattening the unfolded acceptor rather than the original one.",
        "However, the set of possible stacks at a state is in general infinite.",
        "Therefore, it is necessary to do the unfolding not with respect to stacks, but with respect to a finite par-Figure"
      ]
    },
    {
      "heading": "3: Minimal Acceptor",
      "text": [
        "tition of the set of stacks possible at the state, induced by an appropriate equivalence relation.",
        "The relation we use currently makes two stacks equivalent if they can be made identical by collapsing loops, that is, removing portions of stack pushed between two arrivals at the same state in the finite-state control of the shift-reduce recognizer.",
        "The purpose of collapsing loops is to \"forget\" stack segments that may be arbitrarily repeated.'",
        "Clearly, each equivalence class is uniquely defined by the shortest stack in the class, and the classes can be constructed without having to consider all the (infinitely) many possible stacks.",
        "Soundness of the Algorithm We will show here that the approximation method described informally in the previous section is sound, in the sense that the approximating FSA will always accept a superset of the language accepted by the input CFG.",
        "In what follows, G is a fixed CFG with terminal vocabulary E, nonterminal vocabulary N and start symbol S. M is the characteristic machine for G, with state set Q, start state so, final states F, and transition function S : S x (E U N) + S. As usual, transition functions such as 6 are extended from input symbols to input strings by defining 6(s, e) = s and 6(s, a fl) = 6(6(s, ex), i3).",
        "The shift-reduce recognizer R. associated to M has the same states, start state and final states.",
        "Its configurations are triples (s, , w) of a state, a stack and an input string.",
        "The stack is a sequence of pairs (s, X) of a state and a terminal or nonterminal symbol.",
        "The transitions of the shift-reduce recognizer are given as follows: Shift: (s, a, xw) F (s', cr(s , x), w) if b(s, x) = s' Reduce: (s, or, w) F (s' ,cr(s\" , A), w) if 6(s\" , A) = s' and either (1) A is a completed dotted rule in s, s\" = s and r is empty, or (2) A + is a completed dotted rule in s,",
        "The initial configurations of R. are (so, c, w) for some input string w, and the final configurations are (s, (so, S) , e) for some state sE F. A derivation of a string w is a sequence of configurations co, ..., cm such that co = (so, c, w), Cm = (s, (so, S), e) for some final state p, and c8_1 F ci for 1 i n. Let s be a state.",
        "The set Stacks(s) contains each sequence (so, X0) (sk, Xk) such that Si = i k and s = 6(sk, Xk ).",
        "In addition, Stacks(so) contains the empty sequence c. By construction, it is clear that if (s, cr, w) is reachable from an initial configuration in 7Z,, then a E Stacks(s).",
        "A stack congruence on 7Z is a family of equivalence relations on Stacks(s) for each state s E S such that if aa' and 6(s, X) = s' then a (s, X)er(s, X).",
        "A 2Since possible stacks can be easily shown to form a regular language, loop collapsing has a direct connection to the pumping lemma for regular languages.",
        "stack congruence partitions each Stacks(s) into equivalence classes [a], of the stacks in Stacks(s) equivalent to a under Each stack congruence E on 12, induces a corresponding unfolded recognizer 1?..",
        "The states of the unfolded recognizer are pairs of a state and stack equivalence class at that state.",
        "The initial state is (so, [c],o), and the final states are all (s, [o]8) with s E F. The transition function bn of the unfolded recognizer is defined by",
        "That this is well-defined follows immediately from the definition of stack congruence.",
        "The definitions of dotted rules in states, configurations, shift and reduce transitions given above carry over immediately to unfolded recognizers.",
        "Also, the characteristic recognizer can also be seen as an unfolded recognizer for the trivial coarsest congruence.",
        "For any unfolded state p, let Pop(p) be the set of states reachable from p by a reduce transition.",
        "More precisely, Pop(p) contains any state p' such that there is a completed dotted rule A a in p and a state p\" such that b.",
        "(p\" , ct) = p and 6.",
        "(p\" , A) = p'.",
        "Then the flattening F= of 7Z= is a no deterministic FSA with the same state set, start state and final states as 7Z= and nondeterministic transition function cb= defined as follows: If 6,(p, x) = p' for some x E E, then p' E 0,(p, x) If p' E Pop(p) then p' E 95E (P, e) Let co,..., cm be a derivation of string w in R., and put ci = (gi, ai, wi), and pi = .",
        "By construction, if ci._1 F ci is a shift move on x (wi_1 = then b.",
        "(pi _1, x) = p, and thus pi E 0.",
        "(psi, x).",
        "Alternatively, assume the transition is a reduce move associated to the completed dotted rule A ---+ oz .",
        "We consider first the case a 0 c. Put a = Xi X.",
        "By definition of reduce move, there is a sequence of states ri, , rn and a stack a such that ai_i = (ri , Xi) (rn, Xn)",
        "where r1 = c and ri = (ri, Xi) ... (ri _1, Xi _1) for j > 1.",
        "Furthermore, again by definition of stack congruence we have 6-, ((ri, [c]ri), A) = pi.",
        "Therefore, pi E Pop(pi_i) and thus pi E 0.(pi_i,e).",
        "A similar but simpler argument allows us to reach the same conclusion for the case a = c. Finally, the definition of final state for R.= and .F= makes pm a final state.",
        "We have thus shown how to construct from a derivation of a string in 7Z, an accepting path for the same string in ..F=.",
        "This proves that every string in L(G) is accepted by .F=, that is, that our construction is sound.",
        "Finally, we should show that the stack collapsing equivalence informally described earlier is indeed a stack congruence.",
        "A stack 7 is a loop if r =",
        "unfolded and flattened FSA 3417 states and 4255 transitions, and the determinized and minimized final DFA 18 states and 67 transitions.",
        "The compilation time is 123.19 seconds on a Sun SparcStation 1, with the determinizer and minimizer written in C and the rest of the compiler in Quintus Prolog.",
        "Most of the time is spent in the unfolding and flattening phases (90.62 seconds unfolding and 17.33 flattening).",
        "It is hoped that recoding these phases in C using carefully tuned data structures will speed them up by between one and two orders of magnitude.",
        "Substantially larger grammars, with thousands of instantiated rules, have been developed for a speech-tospeech translation project.",
        "Compilation times range from the very reasonable (around 10 minutes) to the very high (10 hours).",
        "Very long compilations are caused by a combinatorial explosion in the unfolding of right recursions that will be discussed further in the next section."
      ]
    },
    {
      "heading": "Informal Analysis",
      "text": [
        "The present algorithm has not yet been analyzed sufficiently to determine the class of context-free grammars generating regular languages for which it is exact.",
        "However, it is exact for in a variety of interesting cases, including the examples of Church and Patil (Church and Patil, 1982), which illustrate how typical attachment ambiguities arise as structural ambiguities on regular string sets.",
        "For example, the left-linear grammar",
        "both of which generate the regular set a*b, are mapped by the algorithm into the FSA in Figure 3.",
        "The algorithm is also exact for some self-embedding grammars' of regular languages, such as S --+ aS I Sb I c defining the regular language cecb*.",
        "A more interesting example is the following simplified grammar for the structure of English noun phrases:",
        "As an example of inexact approximation, consider the the self-embedding CFG S + aSb I c for the nonregular language eV' ,n > 0.",
        "This grammar is mapped by the algorithm into an FSA accepting c I a+ b.",
        "The effect of the algorithm is thus to \"forget\" the pairing between a's and b's mediated by the stack in a pushdown acceptor for the CFG.",
        "As noted earlier, right recursion is rather bad for the present unfolding scheme.",
        "It is easy to see that the number of unfolded states for a grammar of the form is exponential in n. However, the problem can be circumvented by left factoring the grammar as follows:",
        "This kind of situation often arises indirectly in the expansion of an APSG when some features in the right-hand side of a rule are unconstrained and thus lead to many different instantiated rules."
      ]
    },
    {
      "heading": "Related Work and Conclusions",
      "text": [
        "Our work can be seen as an algorithmic realization of suggestions of Church and Patil (Church, 1980; Church and Patil, 1982) on algebraic simplifications of CFGs of regular languages.",
        "Other work on finite state approximations of phrase structure grammars has typically relied on arbitrary depth cutoffs in rule application.",
        "While this is reasonable for psycholinguistic modeling of performance restrictions on center embedding (Pulman, 1986), it does not seem appropriate for speeech recognition where the approximating FSA is intended to work as a filter and not reject inputs acceptable by the given grammar.",
        "For instance, depth cutoffs in the method described by Black (1989) lead to approximating FSAs whose language is neither a subset nor a superset of the language of the given phrase-structure grammar.",
        "In contrast, our method will produce an exact FSA for many interesting grammars generating regular languages, such as those arising from systematic attachment ambiguities (Church and Patil, 1982).",
        "It important to note, however, that even when the result FSA accepts the same language, the original grammar is still necessary because interpretation algorithms are generally expressed in terms of phrase structures described by that grammar, not in terms of the states of the FSA.",
        "The current algorithm can be combinatorially explosive in two places: the instantiation of unification grammar rules to derive an equivalent CFG, and the unfolding of the characteristic machine, in particular for right recursive rules.",
        "The former problem can be alleviated by avoiding full instantiation of unification grammar rules with respect to \"don't care\" features, that is, features that are not constrained by the rule.",
        "This can also help decrease the right-recursion unfolding explosion discussed earlier.",
        "As for the cost of unfolding, preliminary experiments suggest that dividing the grammar into nonmutually-recursive components and applying the LR(0) construction and unfolding separately to those components could lead to much smaller unfolded automata."
      ]
    },
    {
      "heading": "Acknowledgments",
      "text": [
        "Thanks are due to Mark Liberman for suggesting that finite-state approximations might be worth investigating to David Roe and Pedro Moreno for using the grammar compiler prototype and patiently putting up with its bugs and inefficiencies."
      ]
    }
  ]
}
