{
  "info": {
    "authors": [
      "Michael A. Covington"
    ],
    "book": "Computational Linguistics",
    "id": "acl-J90-4003",
    "title": "Technical Correspondence: Parsing Discontinuous Constituents in Dependency Grammar",
    "url": "https://aclweb.org/anthology/J90-4003",
    "year": 1990
  },
  "references": [
    "acl-C86-1028",
    "acl-C86-1046",
    "acl-C86-1109",
    "acl-P85-1015",
    "acl-P86-1010"
  ],
  "sections": [
    {
      "heading": "TECHNICAL CORRESPONDENCE PARSING DISCONTINUOUS CONSTITUENTS IN DEPENDENCY GRAMMAR",
      "text": [
        "Discontinuous constituents – for example, a noun and its modifying adjective separated by words unrelated to them-are common in variable-word-order languages; Figure 1 shows examples.",
        "But phrase structure grammars, including ID/LP grammars, require each constituent to be a contiguous series of words.",
        "Insofar as standard parsing algorithms are based on phrase structure rules, they are inadequate for parsing such languages.",
        "The algorithm presented here, however, does not require constituents to be continuous, but merely prefers them so.",
        "It can therefore parse languages in which conventional parsing techniques do not work.",
        "At the same time, because of its preference for nearby attachments, it prefers to make constituents continuous when more than one analysis is possible.",
        "The new algorithm has been used successfully to parse Russian and Latin (Covington 1988, 1990).",
        "This algorithm uses dependency grammar.",
        "That is, instead of breaking the sentence into phrases and subphrases, it establishes links between individual words.",
        "Each link connects a word (the \"head\") with one of its \"dependents\" (an argument or modifier).",
        "Figure 2 shows how this works.",
        "The arrows point from head to dependent; a head can have many dependents, but each dependent can have only one head.",
        "Of course the same word can be the head in one link and the dependent in another.2 Dependency grammar is equivalent to an X-bar theory with only one phrasal bar level (Figure 3) – the dependents of a word are the heads of its sisters.",
        "Thus dependency grammar captures the increasingly recognized importance of headship in syntax.",
        "At the same time, the absence of phrasal nodes from the dependency representation streamlines the search process during parsing.",
        "The parser presupposes a grammar that specifies which words can depend on which.",
        "In the prototype, the grammar consists of unification-based dependency rules (called D-rules) such as:",
        "This rule sanctions a dependency relation between any two words whose features unify with the structures shown – in this case, the verb and its subject in a language such as Russian or Latin.",
        "The arrow means \"can depend on\" and the word order is not specified.",
        "X and Y are variables.",
        "D-rules take the place of the phrase structure rules used by Shieber (1986) and others; semantic information can easily be added to them, and the whole power of unification-based grammar is available.",
        "The parser accepts words from the input string and keeps track of whether or not each word is \"independent\" (not yet known to depend on another word), indicated by + or – in Figure 4.",
        "On accepting a word W, the parser does the following:",
        "(1) Search the independent words (those marked +), most recent first, for words that can depend on W. If any are found, establish the dependencies and change the marking of the dependents from + to – .",
        "(2) Search all words so far seen, most recent first, for a word on which W can depend.",
        "If one is found, establish the dependency and mark Was – .",
        "Otherwise mark Was +.",
        "Figure 4 shows the process in action.",
        "The first three words, ultima Cumaei venit, are accepted without creating any links.",
        "Then the parser accepts iam and makes it depend on venit.",
        "Next the parser accepts carminis, on which Cumaei, already in the list, depends.",
        "Finally it accepts aetas, which becomes a dependent of venit and the head of ultima and carminis.",
        "The most-recent-first search order gives the parser its preference for continuous constituents.",
        "The search order is significant because it is assumed that the parser can backtrack, i.e., whenever there are alternatives it can back up and try them.",
        "This is necessary to avoid \"garden paths\" such as taking animalia (ambiguously nominative or accusative) to be the subject of animalia vident pueri \"boys see animals.\"",
        "With ordinary sentences, however, backtracking is relatively seldom necessary.",
        "Further, there appear to be other constraints on variable word order.",
        "Ades and Steedman (1982) propose that all discontinuities can be resolved by a pushdown stack.",
        "(For example, pick up ultima, then Cumaei, then put down Cumaei next to carminis, then put down ultima next to aetas.",
        "Crossing movements are not permitted.)",
        "Moreover, there appears to be an absolute constraint against mixing clauses together.3 If these hypotheses hold true, the parser can be modified to restrict the search process accordingly.",
        "Most dependency parsers have followed a \"principle of adjacency\" that requires every word plus all its direct and indirect dependents to form a contiguous substring (Hays and Ziehe 1960; Starosta and Nomura 1986; Fraser 1989; but not Hellwig 1986 and possibly not Jdppinen et al.",
        "1986).",
        "This is equivalent to requiring constituents to be continuous.",
        "This parser imposes no such requirement.",
        "To add the adjacency requirement, one would modify it as follows: ( ) When looking for potential dependents of W, never",
        "(2) When looking for the word on which W depends, consider only the previous word, that word's head, the head's head if any, and so on.",
        "With these requirements added, the algorithm would be the same as one implemented by Hudson (1989).",
        "Formal complexity analysis has not been carried out, but my algorithm is simpler, at least conceptually, than the variable-word-order parsers of Johnson (1985), Kashket (1986), and Abramson and Dahl (1989).",
        "Johnson's parser and Abramson and Dahl's parser use constituency trees with explicit discontinuity (\"tangled trees\"), with all their inherent unwieldiness.",
        "Kashket's parser, though based on GB theory, is effectively a dependency parser since it relies on case assignment and subcategorization rather than tree structure.",
        ", December 1990 235"
      ]
    },
    {
      "heading": "Technical Correspondence",
      "text": []
    }
  ]
}
