{
  "info": {
    "authors": [
      "Ezra W. Black",
      "Steven Abney",
      "Daniel P. Flickinger",
      "Claudia Gdaniec",
      "Ralph Grishman",
      "Philip Harrison",
      "Donald Hindle",
      "Robert J. P. Ingria",
      "Frederick Jelinek",
      "Judith L. Klavans",
      "Mark Y. Liberman",
      "Mitchell P. Marcus",
      "Salim Roukos",
      "Beatrice Santorini",
      "Tomek Strzalkowski"
    ],
    "book": "Workshop on Speech and Natural Language",
    "id": "acl-H91-1060",
    "title": "A Procedure for Quantitatively Comparing the Syntactic Coverage of English Grammars",
    "url": "https://aclweb.org/anthology/H91-1060",
    "year": 1991
  },
  "references": [],
  "sections": [
    {
      "heading": "IBM Research Division, Thomas J. Watson Research Center",
      "text": [
        "Yorktown Heights, NY 10598 other differences.",
        "Despite the seeming intractability of this problem, it appears to us that a solution to it is now at hand.",
        "We propose an evaluation procedure with these characteristics: it judges a parse based only on the constituent boundaries it stipulates (and not the names it assigns to these constituents); it compares the parse to a \"hand-parse\" of the same sentence from the University of Pennsylvania Tree bank; and it yields two principal measures for each parse submitted.",
        "The procedure has three steps.",
        "For each parse to be evaluated: (1) erase from the fully-parsed sentence all instances of: auxiliaries, \"not\", pre-infinitival \"to\", null categories, possessive endings ('s and '), and all word-external punctuation (e.g. \" .",
        ", ; ); (2) recursively erase all parenthesis pairs enclosing either a single constituent or word, or nothing at all; (3) compute goodness scores (Crossing Parentheses, and Recall) for the input parse, by comparing it to a similarly reduced version of the Penn Treebank parse of the same sentence.",
        "For example, for the Brown Corpus sentence: Miss Xydis was best when she did not need to be too probing.",
        "consider the candidate parse: (S(NP-s(PNP(PNP Miss) (PNP Xydis))) (VP(VPAST was) (ADJP(ADJ best))) (S(COMP(WHADVP(WHADV when))) (NP-s (PRO she)) (VP ((VPAST did) (NEG not) (V need)) (VP((X to) (V be)) (ADJP(ADV too) (ADJ probing)))))) (?",
        "(FIN .))",
        "After step-one erasures, this becomes: (S(NP-s(PNP(PNP Miss) (PNP Xydis))) (VP(VPAST was) (ADJP(ADJ best))) (S(COMP(WHADVP(WHADV when))) (NP-s (PRO she)) (VP((VPAST ) (NEC ) The problem of quantitatively comparing the performance of different broad-coverage grammars of English has to date resisted solution.",
        "Prima facie, known English grammars appear to disagree strongly with each other as to the elements of even the simplest sentences.",
        "For instance, the grammars of Steve Abney (Bellcore), Ezra Black (IBM), Dan Flickinger (Hewlett Packard), Claudia Gdaniec (Logos), Ralph Grishman and Tomek Strzalkowski (NYU), Phil Harrison (Boeing), Don: Hindle (AT&T), Bob Ingria (BBN), and Mitch Marcus (U. of Pennsylvania) recognize in common only the following constituents, when each grammarian provides the single parse which he/she would ideally want his/her grammar to specify for three sample Brown Corpus sentences: The famed Yankee Clipper, now retired, has been assisting (as (a batting coach)).",
        "One of those capital-gains ventures, in fact, has saddled him (with Gore Court).",
        "He said this constituted a (very serious) misuse (of the (Criminal court) processes).",
        "Specific differences among grammars which contribute to this apparent disparateness of analysis include the treatment of punctuation as independent tokens or, on the other hand, as parasites on the words to which they attach in writing; the recursive attachment of auxiliary elements to the right of Verb Phrase nodes, versus their incorporation there en bloc; the grouping of pre-infinitival \"to\" either with the main verb alone or with the entire Verb Phrase that it introduces; and the employment or non-employment of \"null nodes\" as a device in the grammar; as well as",
        "Step three consists of comparing the candidate parse to the treebank parse and deriving two scores: (1) The Crossing Parentheses score is the number of times the treebank has a parenthesization such as, say, (A (B C)) and the parse being evaluated has a parenthesization for the same input of ((A B) C)), i.e. there are parentheses which \"cross\".",
        "(2) The Recall score is the number of parenthesis pairs in the intersection of the candidate and treebank parses (T intersection C) divided by the number of parenthesis pairs in the treeba,nk parse T, viz. (T intersection C) / T. This score provides an additional measure of the degree of fit between the standard and the candidate parses; in theory a Recall of 1 certifies a candidate parse as including all constituent boundaries that are essential to the analysis of the input sentence.",
        "We applied this metric to 14 sentences selected from the Brown Corpus and analyzed by each of the grammarians named above in the manner that each wished his/her grammar to do.",
        "Instead of using the UPenn Treebank as a standard, we used the automatically computed \"majority parse\" of each sentence obtained from the set of candidate parses themselves.",
        "The average Crossing Parentheses rate over all our grammars was .4%, with a corresponding Recall score of 94%.",
        "We have agreed on three additional categories of systematic alteration to our input parses which we believe will significantly improve the correlation between our \"ideal parses\", i.e. our individual goals, and our standard.",
        "Even at the current level of fit, we feel comfortable allowing one of our number, the UPenn parse, to serve as the standard parse, since, crucially, it is produced by hand.",
        "Our intention is to apply the current metric to more Brown Corpus data \"ideally parsed\" by us, and then to employ it to measure the performance of our grammars, run automatically, on a benchmark set of sentences."
      ]
    },
    {
      "heading": "APPENDIX: EVALUATION PROCEDURE FOR COMPUTER ENGLISH GRAMMARS 0. Input format",
      "text": [
        "A parse for evaluation should consist initially of:",
        "(a) the input word string, tokenized as follows: (1) Any tokens containing punctuation marks are enclosed by vertical bars, e.g. 1D'Alberti 14,0001 (2) Contracted forms in which the abbreviated verb is used in the sentence under analysis as a main verb, as opposed to an auxiliary, are to be split: you've -> you I've' (In \"You've a good reason for that.\" but not in \"You've been here often.\") John's -> John l's1 (In \"John's (i.e. is) a good friend\" or \"John's (i.e. has) a good friend\" but not \"John's (i.e. is) leaving\" and not \"John's (i.e. has) been here\" (3) Hyphenated words, numbers and miscellaneous digital expressions are left as is (i.e. not split), i.e. Ico-signers1 (and not \"co II signers\"); 12,0001 (and not",
        "(b) the parse of the input word string with respect to the grammar under evaluation (1) Each grammatical constituent of the input is grouped using a pair of parentheses, e.g.",
        "(b) \"Not\" E.g. \"is not in here\" -> \"is in here\", \"Not precisely asleep, John sort of dozed\" ->\"precisely asleep, John sort of dozed\" (c) Pre-infinitival \"to\" E.g. \"she opted to retire\" -> \"she opted retire\", \"how to construe it\" -> \"how construe it\" (d) Null categories Example 1: (\"getting more pro letters than con\"):",
        "precede right parentheses, e.g.",
        "1.",
        "Erasures of Input Elements The first of the two steps necessary to prepare initial parsed input for evaluation consists of erasing the following types of word (token) strings from the parse: (a) Auxiliaries Examples are: \"would go there\" -> \"go there\", \"has been laughing\" -> \"laughing\", \"does sing it correctly\" -> \"sing it correctly\", but not: \"is a cup\", \"is blue\", \"has a dollar\", \"does the laundry\"",
        "2.",
        "Erasures of Constituent Delimiters, i.e. Parentheses The second of the two steps necessary to prepare initial parsed input for evaluation consists of erasing parenthesis pairs, proceeding recursively, from the most to the least deeply embedded portion of the parenthesization, whenever they enclose either a single constituent or word, or nothing at all.",
        "particles which occur constituent-finally.",
        "(a) Extraposition The treatment accepted at present attaches the extraposed clause to the topmost node of the host (sentential) clause.",
        "Example: If initial analysis is: (It (is (necessary (for us to leave)))) Then change to standard as follows: (It (is necessary) (for us to leave)) NOTE: The following is not an example of extraposition, and therefore not to be modified, although it seems to differ only minimally from a genuine extraposition sentence such as: \"It seemed like a good idea to begin early\": (It (seemed (like ((a good meeting) (to begin early)))))",
        "1.",
        "The prospect of cutting back spending 2. prospect of cutting back spending 3. of cutting back spending 4. cutting back spending 5. cutting back While both constituents 2 and 5 differ from the standard, only 2 qualifies as a \"crossing\" violation, as 5 is merely a substring of a constituent of the standard parse.",
        "So the \"Constituents Incompatible With Standard\" score for this sentence is 1.",
        "(b) \"Recall\" and \"Precision\" of Parse Being Evaluated",
        "As a preliminary to computing Recall:",
        "the total number of constituents in the standard parse, and in the candidate parse, are simply counted.",
        "Notice that \"Number of Standard-Parse Constituents in Candidate\" and \"Number of Candidate-Parse Constituents in Standard\" are merely different names for the same object--the intersection of the set of standard-parse constituents with the set of candidate-parse constituents.",
        "So the final count preliminary to the computation of Recall and Precision is the number of elements in that intersection.",
        "To return to the first example of the last subsection: Standard parse: ((The prospect) (of (cutting back spending))) Parse for evaluation: (The (prospect (of ((cutting back) spending)))) there are 4 standard-parse constituents, if the convention is adopted of excluding unary constituents; and 5 candidate-parse constituents, under the same convention.",
        "Three of these are common to both sets, i.e. the intersection here is 3.",
        "Computing Recall and Precision is accomplished for this parse as follows:"
      ]
    }
  ]
}
