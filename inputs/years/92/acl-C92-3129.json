{
  "info": {
    "authors": [
      "Eric Wehrli"
    ],
    "book": "International Conference on Computational Linguistics",
    "id": "acl-C92-3129",
    "title": "The IPS System",
    "url": "https://aclweb.org/anthology/C92-3129",
    "year": 1992
  },
  "references": [
    "acl-C88-2160",
    "acl-C90-1017",
    "acl-P84-1102"
  ],
  "sections": [
    {
      "heading": "Abstract",
      "text": [
        "The IPS system is a large-scale interactive GB-based parsing system (English, French) under development at the University of Geneva.",
        "This paper starts with an overview of the system, discussing some of its basic features as well as its general architecture.",
        "We then turn to a more detailed discussion of the \"right cor-ner\" parsing strategy developed for this project.",
        "Combining top down and bottom up features, this strategy is consistent with an incremental interpretation of sentences."
      ]
    },
    {
      "heading": "1 Overview of the IPS project",
      "text": [
        "The IPS (Interactive Parsing System) research project, at the Linguistics Departement of the University of Geneva, aims at developing a large, interactive, parsing model based on Chomsky's Government and Binding (henceforth GB) linguistic theory'.",
        "This project, which focuses both on English and French, has theoretical as well as practical goals, including the following:",
        "• to show the feasibility and the soundness of a GB-based approach to natural language parsing;",
        "'The research described in this paper has been supported in part by a grant from the Swiss national science foundation (grant no 11-25362.88).",
        "I am grateful to Robin Clark, Paola Merlo, Mira Ramluckun and Martin Kay for helpful comments and discussion on earlier drafts of this paper.",
        "Cf. Chomsky (1981, 1988) for a discussion of GB theory.",
        "Issues related to the use of GB theory in natural language parsing design are discussed in Berwick (1987), Berwick et al.",
        "(1991) and Wehrli (1988).",
        "• to demonstrate the advantages of an interactive approach to natural language processing; • to develop robust, large-scale parsers suitable for NLP applications (e.g. translation).",
        "The IPS parser is interactive in the sense that it can request on-line information from the user.",
        "Typically, interaction will be used to solve ambiguities that the parser cannot handle, for instance when the resolution of an ambiguity depends on contextual or extralinguistic knowledge'.",
        "The interactive feature is seen as a way to increase the reliability of the parser difficult decisions are left to the user – as well as a way to simplify the grammar, since many ad hoc features that would be necessary if the parser had to solve all problems by itself can now be dispensed with.",
        "In addition, the interactive capability is also useful as a development tool, in the sense that on-line user interaction can supplement modules which have not yet been developed (e.g. semantic and pragmatic components).",
        "Other important features of the IPS parser include:",
        "• Modular architecture, i.e. the parsing mechanism is decomposed into modules, which roughly correspond to some of the components of a standard GB grammar (e.g. X, chains, 0, etc.).",
        "• The parsing strategy is left-to-right, data driven, with parallel treatment of alterna",
        "tives.",
        "The non-determinism of the parser is 3 The X module restricted by a selection mechanism.",
        "• Use of structure-sharing techniques to cut down the number of explicit representations of alternatives."
      ]
    },
    {
      "heading": "2 Architecture",
      "text": [
        "The IPS parser tries to associate with an input sentence a set of syntactic structures.",
        "These structures correspond to GB S-structures, i.e. surface structures enriched with traces of moved elements and other empty categories.",
        "In our implementation, GB grammatical modules correspond to particular processes.",
        "While some of the modules function as generators (X, chain modules, coordination module) in the sense that they increase the set of structures hypothesized at a given point, others are used as filters (Case module, 0-module) in the sense that their action tends to reduce the set of structures.",
        "The modules apply as soon as possible at each step in the parsing process, triggered by particular data or by specific calls from other modules.",
        "Alternatives are considered concurrently (pseudo-parallelism), and a small number of heuristics are used to restrict the size of the hypothesis set.",
        "To give an example, one heuristic gives precedence to attachments satisfying formal selectional features over (cf. (3), (7)) other kinds of attachments.",
        "Thus, if an incoming verb form can be attached either as a complement to an auxiliary or as a main verb, preference will be given to the former'.",
        "User interaction –which is an optional feature in the IPS system– can be used to select alternatives, mostly in case of attachment ambiguities, but occasionally also for other types of ambiguity (lexical, thematic, etc).",
        "Alternatives are then displayed (in an abbreviated manner) and the user is asked to make a selection.",
        "'Notice that this heuristic might explain garden path sentences such as \"'Invite qu'il a dit des Polies\" (the guest he has told insanities), in which readers wrongly interpret dit as past participle selected by the auxiliary verb a.",
        "The central module of the IPS system is the X module, which acts as the main generator of the system, and determines the syntactic structures of constituents.",
        "We assume the X schema in (1):",
        "(1) XP Spec X X---■ X Compl",
        "where X is a lexical or a functional category, Spec and Compl are lists (possibly empty) of maximal projections (YP).",
        "As indicated in (1), maximal projections are of order 2 (XP) and lexical categories of order 0 (Y).",
        "For typographical reasons, categories of order 1 (X) are noted I' in the illustrations below.",
        "The set of lexical categories include N , V , and P, the set of functional categories includes D(eterminer), T(ense) et C(omplementizer).",
        "We also assume the DP hypothesis (cf. Abney 1987, Clark 1990a), and, as a consequence, the strong parallelism between DP and TP structures, as illustrated in (2):",
        "Lexical categories as well as functional categories can select other lexical or functional projections.",
        "Thus, a determiner can select a projection of category DP or NP, as in (3) and (4), respectively, corresponding to the structures (5) and (6)",
        "(3) [each, D, (+definite], (4D,[numeral(1\"`\"1 (4) [each, D, [1-definite), [__[N,[singular]]\"'\"] (5)m each five men.",
        "b.",
        "[op ID, each [DP 1D, five[Np [N, men]]]]]]",
        "Similarly, auxiliaries can select projections of type VP, and most prepositions projections of type DP.",
        "Some examples of selection features associated with auxiliary verbs are given in (7), with the corresponding structures in (8) and (9):",
        "The following is a summary of the fundamental properties of constituent structures :",
        "• Any lexical category X projects to a maximal projection XP.",
        "• Attachments are restricted to maximal projections (XP).",
        "• All constituents have the same architecture."
      ]
    },
    {
      "heading": "4 The IPS parsing strategy",
      "text": [
        "In our implementation of the X module, we distinguish three types of action: projection, attachment to the left (specifiers) and attachment to the right.",
        "The parsing strategy is left to right, parallel, combining a bottom up approach with top down filtering, as we shall see below.",
        "The motivation for this particular strategy is to maximize at each step the interpretation of constituents in order to facilitate the selection mechanism as well as user interaction discussed in section 2.",
        "Interestingly enough, this requirement seems to coincide with psycholinguistic evidence suggesting that sentence parsing proceeds in an incremental fashion, trying to integrate incoming items into maximally interpreted structurest.",
        "The basic idea is that the parser must be sensitive to incoming words.",
        "However, strictly bottom up strategies are known to have some undesirable features.",
        "In particular, they tend to generate numerous locally well-formed structures which turn out to be incompatible with the overall structure.",
        "Furthermore, they restrict attachment to complete constituents, which means that when applied to right branching languages such as French or English, assembling the final structure does not start much before the end of the sentence is reached.",
        "To illustrate these problems, consider the following examples : (10)a.",
        "Who could the children have invited ?",
        "b. John must have given the students several of his books.",
        "In sentence (10a), when the parser gets to the word have, it tries to combine it with the left context, say [ Dp the children], leading to the new constituent [ Tp the children have].",
        "Although this new constituent is perfectly well-formed locally, it is not compatible with the modal could.",
        "Sentence (10b) illustrates the second and more serious problem.",
        "If node attachment is limited to complete nodes, the combination of the subject John and the rest of the structure (the whole verb phrase, which is a T in our system) will not occur before the last word of the sentence is read.",
        "The use of a more sophisticated strategy, such as the left corner strategy, addresses the first problem quite successfully.",
        "However, it fails to solve the second problem, since attachments are limited to complete constituents in the standard left corner parser'.",
        "In an attempt to overcome this problem, and taking advantage of the clear",
        "bias for right branching structures in languages (12) John has bought some flowers.",
        "such as French or English (cf. structure (9b)), we developed a strategy dubbed \"right corner\", which is based on the following principles: When the parser reads the word some, the left context include, among many constituents, structure (13) :",
        "(11) \"Right corner\" strategy : • constituents can be attached as soon as they have been hypothesized; • attach incoming items to maximally expanded constituents in the left context; • constituents specify a list of active attachment sites on their right edge; • all attachments are considered in parallel;",
        "Notice that this strategy is clearly bottom-up (actions are triggered by incoming material).",
        "However, it differs from other bottom-up strategies in some important ways.",
        "First of all, the combination of a new item with its left context is not done through a sequence of \"reduce\" operations (as in a shift-reduce parser).",
        "More generally, the attachment of (most) incoming items is made directly to some subconstituent of the top node, i.e. to some attachment site specified in the active node list of a constituent in the left context.",
        "This is in sharp contrast with standard bottom-up parsers (including the left corner parser), for which reduction to the start symbol cannot occur before the end of the sentence is reached.",
        "Although the right corner strategy requires significantly more complex data structures (constituents must specify all their potential attachment sites7), it has the advantage of being computationally and psycholinguistically more adequate than other bottom up strategies.",
        "Regarding the latter point, the right corner strategy seems consistent with the (trivial) observations (i) that the analyzer is data driven but (ii) although still incomplete, left context constituents are maximally specified, as they would in a top-down parser.",
        "A detailed example will illustrate this strategy.",
        "Consider the following sentence : 'Attachment sites for a given constituent correspond to the list of X nodes on its right edge.",
        "For efficiency reasons, they are put together in a stack associated with the constituent.",
        "(13) [ John has [ bought]]"
      ]
    },
    {
      "heading": "TP VP",
      "text": [
        "The word some triggers a DP projection, with some as its head.",
        "Considering the left context, the parser finds structure (13), the stack of attachment sites of which contains the verb bought.",
        "The newly created DP projection combine with the TI' structure as a complement of the verb bought.",
        "We now have an updated TP constituent, as in (14), with an updated stack of active nodes, with at the top the DP constituent just attached.",
        "(14) II, John has bought some]",
        "The parser can now read the following word flowers, which can attach to the left context structure (14), as a complement of the determiner some.",
        "The right corner strategy takes care of attachments to the right.",
        "In the case of projections or of attachments to the left (specifiers), the usual bottom up procedure applies.",
        "Typically projection is triggered by inherent features (H-tense] verbs will trigger a T(ense) projection, proper nouns a DP projection, etc.).",
        "As for left attachment, it occurs when the current constituent can find a left context constituent which can function as a possible specifier.",
        "The attachment of the specifier to the current constituent determines a new constituent which may in turn find a specifier in its left context (iterative attachment) as it happens in the possessive construction (e.g. John's little brother's cat)."
      ]
    },
    {
      "heading": "5 Concluding remarks",
      "text": [
        "The right corner parsing strategy discussed in this paper has been developed to satisfy the particular needs of our on-line interactive parsing model.",
        "By (i) pursuing concurrently all the possible analyses and (ii) trying to integrate incoming items into fully developed constituents, AcrEs DE COLING-92, NANTEs, 23-28 mixt 1992 8 7 3 Proc.",
        "OF COL1NG-92, NAsrms, AUG. 23-28, 1992 this scheme, at each step in the parsing process, provides the filtering components, including user-interaction, with structures that are as much interpreted as possible.",
        "Not only does this make the selection process much more reliable, it is also consistent with psycholinguistic evidence for incremental sentence parsing.",
        "Although still under development, the IPS parser, which uses a lexical database exceeding 80,000 entries, has a fairly broad grammatical coverage including simple and complex sentences, complex determiners and possessives, yes/no and wh-interrogatives, relatives, passive, some comparatives as well as some cases of coordination (of same category).",
        "The French version also handles typical Romance constructions such as clitics and causatives."
      ]
    }
  ]
}
