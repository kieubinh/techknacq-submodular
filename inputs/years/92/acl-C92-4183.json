{
  "info": {
    "authors": [
      "Erik Aarts"
    ],
    "book": "International Conference on Computational Linguistics",
    "id": "acl-C92-4183",
    "title": "Uniform Recognition for Acyclic Context-Sensitive Grammars Is NP-Complete",
    "url": "https://aclweb.org/anthology/C92-4183",
    "year": 1992
  },
  "references": [],
  "sections": [
    {
      "heading": "Abstract",
      "text": [
        "Context-sensitive grammars in which each rule is of the form aZ/I ary,l3 are acyclic if the associated context-free grammar with the rules Z is acyclic.",
        "Tire problem whether an input string is in the language generated by an acyclic context-sensitive grammar is NP-complete."
      ]
    },
    {
      "heading": "Introduction",
      "text": [
        "One of the most well-known classifications of rewrite grammars is the Chomsky hierarchy.",
        "Grammars and languages are of type 3 (regular), type 2 (context-free), type 1 (context-sensitive) or of type 0 (unrestricted).",
        "It is easy to decide whether a string is in the language generated by a regular or context-free grammar.",
        "For context-free grammars input strings can be recognized in a time that is polynomial in the length of the input string as well as in the length of the grammar.",
        "Earley [1970] has shown a bound of 0(P2n3) where is the size of the grammar and n the length of the input string.",
        "Recognition for context-sensitive grammars is harder: it is PSPACE-complete [Carey and Johnson, 1979], referring to [Kuroda, 1964] and [Karp, 1972].",
        "Recognition of type 0 languages is undecidable (see e.g. Lewis and Papadinaitriou [1981]).",
        "The area between context-free grammars and context-sensitive grammars is interesting for two reasons.",
        "First, people have tried to describe natural languages with rewrite granunars.",
        "Context-free grammars do not seem powerfull enough to describe natural languages.",
        "Context-free grammars generate context-free languages.",
        "Natural 'The author was sponsored by project NF 102/62-356 ('Structural and Semantic Parallels in Natural Languages and Programming Languages'), funded by the Netherlands Organization for the Advancement of Research (NWO).",
        "languages are probably not context-free.",
        "The counterexamples of sentences that can not be described with a context-free grammar are always a bit artificial.",
        "Very big subparts of natural languages are context-free.",
        "A grammar for natural languages has to be only a bit stronger than context-free.",
        "That's why we are interested in grammars that are between context-free and context-sensitive.",
        "The second perspective is the one of efficient processability.",
        "hi it context-free model, sentences can be processed efficiently.",
        "In a context-sensitive one, they can not.",
        "It is very interesting to know where the border lies: in which models sentences can be processed efficiently and in which ones they can not?",
        "In the 60's and 70's, attempts have been made to put restrictions on context-sensitive grammars in order to generate context-free languages.",
        "Examples arc Book [1972], Hibbard [1974] and Ginsburg and Greibach [1966].",
        "Baker [1974] has shown that these methods come down to the same more or less.",
        "They all block the use of context to pass information through the string.",
        "Book [1973] gives an overview of attempts to generate context-free languages with non-context-free grammars.",
        "How to restrict permutative grammars in order to generate context-free languages is described in Makkinen [1985].",
        "Peters Jr. and Ritchie [1973] proposed a linguistically motivated change in the definition of the notion grammar.",
        "Subsequent replacements in a string are replaced by node admissibility constraints in the parse trees of sentences in a context-free grammar.",
        "However, tins formalism leads to generation of context-free languages too.",
        "The approach of restricting grammars such that they generate context-free languages does not seem interesting front the natural language perspective nor from the efficiency perspective.",
        "The only advantages of this kind of restrictions lie in the possibilty to describe a context-free language hi a different way, which may be easier for some purpose.",
        "Another argument against blocking information [Baker, 1974] is the problem of unbounded dependencies.",
        "Unbounded dependencies are dependencies over an unbounded distance.",
        "Wh-movement is an example of it.",
        "The number of unbounded dependencies in natural language is (almost) always restricted.",
        "Models that restrict the amount of information that can be sent seem to come closer to models of human language than models restrict the distance over which information can be sent.",
        "In the 70's and 80's attention has shifted to the perspective of efficient processing.",
        "Context-sensitive grammars have been restricted so that complexity of recognition lies somewhere between PSP ACE and P. Book [1978] has shown that for linear time context-sensitive grammars recognition is NP-complete even for (some) fixed grammars.",
        "Furthermore there is a result that recognition for growing context-sensitive grammars is polynomial for fixed grammars [Dahlhaus and Warmuth, 1986].",
        "This article also tries to define a border between nearly-efficient and just-efficient models.",
        "We can define the notions uniform (or universal) recognition and recognition for a fixed grammar as follows."
      ]
    },
    {
      "heading": "UNIFORM RECOGNITION",
      "text": [
        "INSTANCE: A grammar G and a string w. QUESTION: Is w in the language generated by G The grammar, as well as the input string are inputs for the problem (these two types of input are easily confused!).",
        "The uniform recognition problem is one problem.",
        "There are infinitely many other problems: Suppose we have a grammar G."
      ]
    },
    {
      "heading": "RECOGNITION FOR FIXED GRAMMAR. G",
      "text": [
        "INSTANCE: A string to.",
        "QUESTION: Is w in the language generated by C Things are getting even more difficult when we say things like: \"For every grammar G RECOGNITION FOR FIXED GRAMMAR G \".",
        "The difference between uniform recognition and recognition for all fixed G can be illustrated with an example from Barton Jr., Berwick and Ristad [1987].",
        "They show that uniform recognition for unordered context-free grammar (UCFG) can be done in time 0(21°63).",
        "It has not been shown that the uniform recognition problem is in P. For every C, however, the fixed recognition problem can be solved in time 0(n3) and all these problems are in P. Barton Jr., Berwick and Ristad [1987] show the problem to be polynomial for any fixed grammar by a compilation step, The UCFG is compiled into a big context-free grammar.",
        "They use this grammar and the Earley algorithm in order to prove a polynomial bound.",
        "Just forgetting about the grammar size (replacing ICI by a constant) gives a polynomial hound too.",
        "It is not clear why Barton Jr., Berwick and Ristad [1987] always associate the fixed grammar problem with compilation (cf. their pp.",
        "27-30, 64-79 and 202- 206).",
        "This article is about uniform recognition for one type of restricted context-sensitive grammars, the acyclic context sensitive grammars (ACSG's).",
        "We prove it to be NP-complete.",
        "This means they are as complex as the Agreement Grammars and the Unordered CFG's of Barton Jr., Berwick and Ristad [1987].",
        "ACSG's are the pure rewrite grammars in this group.",
        "They fit in the Chomsky hierarchy.",
        "One might ask when we can use acyclic context-sensitive grammars.",
        "One can use them everywhere where one wants to use context-sensitive grammars.",
        "But one has to be careful: cycles are not allowed.",
        "This property of acyclicity can be checked easily'.",
        "For most purposes one does not need cycles at all.",
        "One field where context-sensitive grammars can be used is e.g. morphology.",
        "Characters in a word are often changed when 'It is much easier than checking whether a CSG is a linear time CSG as defined by Book [19781.",
        "One has to reason about length of possible derivations.",
        "In ACSG, derivations are short as a result of their acyclicity.",
        "some suffix is added.",
        "These changes in a word are context-sensitive and can be described by a context-sensitive grammar.",
        "Once a character is changed, we normally do not want to change it back, the grammar we use is an acyclic one.",
        "The complexity of recognition for ACSG is lower than in the unrestricted case (CSG, with complexity PSPACE) because we restrict the amount of information that can he passed through the sentence.",
        "The number of messages that can be sent is limited (and we do not block the messages by barriers as in Baker [1974] !).",
        "In the unrestricted case we can send messages that leave no trace.",
        "E.g. after a message that changes 0's into l's we can send a message that does the reverse.",
        "In sending a message from one position in the sentence to another, the intermediate symbols are not changed.",
        "In fact they are changed twice: back and forth.",
        "With acyclic context-sensitive grammars, this is not possible.",
        "Every messages leaves a trace mid the amount of information that can be sent is restricted by the grammar."
      ]
    },
    {
      "heading": "Definitions",
      "text": [
        "A grammar is a 4-tuple, G = (V, r, It, S), where V is a set of symbols, E C V is the set of terminal symbols.",
        "R C V1 x V* is a relation defined on strings.",
        "Elements of R are called rules.",
        "SE V \\ E is the startsymbol.",
        "A grammar is context-sensitive if each rule is of the form ceZ tryil where Z C V \\E ; a,0,-y c V* ; y e. A grammar is context-free if each rule is of the form Z '7 where Z € V E ; 7 V*.",
        "Derivability (=>-) between strings is defined as follows: nay ufiv (u,v,a,0 E V`) if (a,13) E R. The transitive closure of is denoted by 4.",
        "The transitive reflexive closure of 4 is denoted by =.",
        "The language generated by C is defined as L(G) = fin E E* S r w}.",
        "A derivation of a string 6 is a sequence of strings xi, x2, , x„ with x1 = 8, for all i (1 < i < n) xi xi+1 and xy 6.",
        "A context-free grammar is acyclic if there is no Z E V\\ E such that Z 4 Z.",
        "This implies that there is no string a E V* such that a 4 a.",
        "We can map a context-sensitive grammar G onto its associated context-free grammar GI as follows: If G is (V, E, R, S) then GI is (V, E,R1,S) where for every rule ceZ cryP E R there is a rule Z R'.",
        "There are no other rules in R'.",
        "Note that the associated grammar does not contain empty productions.",
        "We call G acyclic iff the associated context-free grammar G' is acyclic.",
        "The notation we use for context-sensitive rules is as follows: the rule aZt3 cry0 is written as Z --s[al][a2] • • [ckki Vlii[02] • • .",
        "[[3d with",
        "An example of a context-sensitive grammar with the corresponding context-free rules is: context-sensitive rules context-free part",
        "This context-sensitive grammar is cyclic.",
        "It is able to permute 0's and l's.",
        "Recognition is NP-complete"
      ]
    },
    {
      "heading": "UNIFORM RECOGNITION FOR ACYCLIC CONTEXT-SENSITIVE GRAMMAR",
      "text": [
        "INSTANCE: An acyclic context-sensitive grammar G = (V, E, R, S) and a string w E E*.",
        "QUESTION: Is w in the language generated by G The proof can be found in Aarts [1991b[.",
        "To prove that it is in NP we have to prove that derivations in ACSG's are short (have polynomial length).",
        "This follows from the fact that derivations in context-free grammars have polynomial length.",
        "Derivations in an acyclic CSG are identical with derivations in the associated context-free grammar.",
        "The proof of NP-hardness is more complicated.",
        "The known NP-hard problem 3-SAT can be reduced to UNIFORM RECOGNITION for ACSG.",
        "Any 3-SAT formula can be translated in a grammar and an input for ACSG-recognition.",
        "Acres DE COLING-92, NANITS, 23-28 AOFIT 1992 5 9 PRoc.",
        "OF COLING-92, NANIES, Auc.",
        "23-28, 1992"
      ]
    },
    {
      "heading": "Recognizing Power",
      "text": [
        "Any context-free grammar can be transformed into an acyclic context-free grammar without loss of recognizing power.",
        "A cycle can be removed by introduction of a new symbol.",
        "This symbol rewrites to any member of the cycle.",
        "Any context-free grammar with empty productions can be changed into a context-free grammar without empty productions that recognizes the same language.",
        "There's one exception here: languages containing the empty string can not be generated.",
        "Any acyclic context-free grammar without empty productions is an acyclic context-sensitive grammar.",
        "Therefore, ACSG's recognize all context-free languages that do not contain the empty word.",
        "Furthermore, acyclic context-sensitive grammars recognize languages that are not context-free.",
        "One example is the language",
        "A derivation of \"AABBBBCC \": ACSG-recognition is not NP-hard for any fixed grammar.",
        "If this is not true, there would exist a grammar that recognizes all 3-SAT formulas.",
        "For this grammar the recognition problem would be NP-hard.",
        "In such a grammar, not every 3-SAT variable is encoded in a different symbol in the grammar.",
        "The variables are numbered and their numbers are encoded in sequences of 0's and l's e.g. .",
        "A grammar that recognizes all 3-SAT formula's must be able to compare such sequences.",
        "It must e.g. be able to recognize the language {am w E V*}.",
        "If w is a number, two numbers are compared.",
        "Context-sensitive grammars can recognize ww.",
        "Some can even recognize all 3-SAT formula's.",
        "ACSG's are not that strong.",
        "They can not even recognize ww.",
        "Any ACSG can compare only a fixed number of characters (only fixed amounts of information can be sent).",
        "Therefore my conjecture is that the recognition problem for any fixed grammar is not so hard: it's polynomial.",
        "Chart parsers for ACSG have been designed and implemented [Aarts, 1991].",
        "They recognize inputs for many hard grammars in polynomial time.",
        "It is hard to prove, however, that they run in polynomial time for every grammar.",
        "If it could be proved, complexity of ACSG-recognition is similar to complexity of UCFG-recognition: NP-complete for the uniform case and a known algorithm that runs in time something like 0(21G1n3)) (polynomial in n but not in G).",
        "SABBC:=-ABXCAXXC AXBBCCAABBBBCC aabbbbcc.",
        "With the pumping lemma one can prove that the language is not context-free."
      ]
    },
    {
      "heading": "Discussion",
      "text": [
        "We have proved that UNIFORM RECOGNITION FOR.",
        "ACYCLIC CONTEXT-SENSITIVE GRAMMAR is NP-complete.",
        "It turns out to be important for complexity of recognition with context-sensitive grammars whether sending information leaves a trace.",
        "We have reduced 3-SAT to the uniform recognition problem for acyclic context-sensitive grammars.",
        "Every 3-SAT formula results in a different grammar.",
        "Probably it is not possible to construct an acyclic context-sensitive grammar that recognizes all 3-SAT formulas.",
        "My conjecture is that The polynomial bound (which has not been proved yet) would be an explanation of the fact that humans can process language efficiently.",
        "Humans have a fixed grammar in mind which does not change.",
        "The complexity of recognition with a fixed grammar should be compared with the speed of human language processing.",
        "The arguments of Barton Jr., Berwick and Ristad [1987] against this are based on two kinds of arguments.",
        "The first has to do with compilation or preprocessing.",
        "We have polynomial bounds without compilation or preprocessing (just fix IGI).",
        "These arguments do not seem to hold.",
        "The other ones have to do with language acquisition.",
        "When a child is learning a language, the grammar she uses is changing.",
        "At every sentence utterance or understanding the grammar seems to be fixed.",
        "The difference between uniform recognition and recognition for any fixed grammar is that small that we can not draw conclusions about what kind of processing children perform when learning a language."
      ]
    },
    {
      "heading": "Acknowledgements",
      "text": [
        "I want to thank Peter van Einde Boas, Reinhard Muskens, Mart Trautwein and Theo Jansen for their comments on earlier versions of this paper."
      ]
    }
  ]
}
