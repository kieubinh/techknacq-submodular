{
  "info": {
    "authors": [
      "Julie Carson-Berndsen",
      "Dafydd Gibbon"
    ],
    "book": "International Conference on Computational Linguistics",
    "id": "acl-C92-4205",
    "title": "Event Relations At the Phonetics/Phonology Interface",
    "url": "https://aclweb.org/anthology/C92-4205",
    "year": 1992
  },
  "references": [
    "acl-C88-1023",
    "acl-C90-2011",
    "acl-C90-3004"
  ],
  "sections": [
    {
      "heading": "EVENT RELATIONS AT THE PHONETICS/PHONOLOGY INTERFACE JULIE CARSON-BERNI)SEN DAFYDD GIBBON",
      "text": []
    },
    {
      "heading": "Summary",
      "text": [
        "In this paper a procedure for the construction of event relations at the phonetics/phonology interface is presented.",
        "The approach goes further than previous formal interpretations of autosegmental phonology in that phonological relations are explicitly related to intervals in actual speech signals as required by a speech recognition system.",
        "An event structure containing the temporal relations of overlap, precedence and inclusion is automatically constructed on the basis of an event lattice with time annotations derived from the speech signal.",
        "The event structure can be interpreted linguistically as an autosegmental representation with assimilation, long components or coarticulation.",
        "The theoretical interest of this work lies in its contribution to the solution of the projection problem in speech recognition, since a rigid mapping to segments is not required."
      ]
    },
    {
      "heading": "1. Motivation",
      "text": [
        "In the processing of speech one of the major problems is the projection problem at the phonetics/phonology interface: sounds and words are realised with different degrees of coarticulation (overlap of properties) in different lexical, syntactic, and phonostylistic contexts and thus a segmentation into phonemes alone is too rigid in order to capture all variants.",
        "Furthermore, the set of possible words in natural languages, analogous to the set of sentences, is infinite.",
        "In fact, even subsets of these sets may be so large that a simple list is no longer tractable.",
        "This has so far proved to be an insuperable problem for the simple concatenative word models of current speech recognition systems, whether phoneme, disyllable, or word based.",
        "In this paper, a new approach to this problem is proposed, starting from recent well-motivated developments in phonology such as autosegmental phonology (Goldsmith, 1976,1990), articulatory phonology (Brownian & Goldstein, 1986,1989), underspecification theory (Archangeli,1988; Keating, 1988) and phonological events (Bird & Klein, 1990).",
        "The overall context for the work presented here is a further development of the PhoPa system (Carson, 1988; Carson-Berndsen, 1990) for phonological word parsing with a feature-based phonotactic net.",
        "The present approach goes beyond these studies in deriving phonological relations directly from speech data, and in providing detailed language-specific top-down phonotactic constraints.",
        "For phonological parsing a flexible notion of compositionality is utilised based on underspecified structures with 'autosegmental' tiers of parallel phonological events which avoid a rigid mapping from phonetic parameters to simple sequences of segments.",
        "The motivation for using an event-based phonological representation was to use phonological knowledge as represented in the phonotactic net (thus also maintaining the notion of underspecification and optimisation by the use of feature cooccurrence restrictions) while catering for those phenoinena arising in continuous speech which tio not correspond to the phonotactics of the language.",
        "An example of this kind of phenomenon found during the labelling of the EUROM-0 speech data in the SAM project (ESPRIT 2589 cf. Braun, 1991b) is the cluster Ism] in the German word [vE:RUNszste:m] as a pronunciation of /vE:RUNszYste:m/ Weihningssystem (see section 3).",
        "By using a phonotactic description based on an autosegmental representation of events and tire temporal relations which exist between them, a rigid segmentation at the phonetic level is no longer necessary.",
        "A further advantage of an event representation with temporal annotations at the phonetics-phonology interface concerns the exchange of differing types of information between the two levels.",
        "An event is interpreted as an interval with a particular property, and it is not necessary to confine the possible set of properties to conventional phonological features such as voice or nasal but acoustic properties of actual speech signals such as \"frication noise\" or \"syllable peak\" may be included."
      ]
    },
    {
      "heading": "2. Event Relations",
      "text": [
        "Three stages arc involved in the determination of signal-derived event relations at the phonetics/phonology interface.",
        "These are: (1) Event Detection, which will be discussed from the point of view of phonetic and phonological levels of representation in section 2.1., (2) Event Mapping where the relations between the individual events are constructed automatically, which is discussed in section 2.2 and (3) Event Structure Constraints, defining phonological structure, which are discussed in section 2.3.",
        "The work described here is concerned primarily with speech recognition rather than synthesis and in particular with its phonological parsing component as opposed to the acoustic front end.",
        "The event relations generated at the phonetics/phonology interface serve as input to a constraint-based phonological parser whose knowledge base is an event-based description of the phonotactics of the language.",
        "2.1.",
        "Phonetic and Phonological Events Assuming that the feature detectors at the acoustic level recognise events each consisting of a property and an interval together with a measure of confidence, it is possible to define a procedure which automatically constructs temporal relations of overlap, precedence and inclusion over intervals Bird & Klein (1990) have some reservations about the use of endpoints of intervals at the phonological level.",
        "However, absolute temporal annotations must indeed be provided at the phonetic level on the basis of threshold and confidence values for a particular acoustic event in a speech signal token, and the use of these in the calculation of temporal relations for a given signal within an actual speech recognition procedure is in fact necessary, not an option.",
        "At the phonological level, an event is simply a pair of a property and an interval <P, I>.",
        "At the phonetic level, an event is a quadruple <P, ts, to C>, providing information on event-type (property), start of interval, end of interval and confidence value.",
        "This serves as input to event mapping.",
        "The output of the mapping is a set of tuples <e,, R, ei> where e, and e; represent events and R is the temporal relation which exists between them (overlap, precedence or temporal inclusion).",
        "Using phonological constraints based on simplex and complex phonolological event structures, the phonologically relevant information is abstracted from this set of tuples.",
        "It is not the temporally annotated events themselves which are interesting for the phonological parser but the temporal relations which exist between these events (cf. section 2.3).",
        "2.2.",
        "Event Mapping In the speech recognition context there is a snapping of absolute phonetic events to abstract temporal relations between events is described.",
        "The algorithm for the automatic construction of event relations has the following properties: Each event pair is tested only once; there is no explicit statement of reflexivity.",
        "The reflexivity and symmetry of overlap are not reflected in the output, but can be inferred by Modus Ponens from the axioms at the phonological level.",
        "Inclusion is a special case of overlap; thus, when an event is temporally included in another these events also overlap, and the algorithm makes use of this fact.",
        "There are nine types of overlap, seven of which are instances of inclusion, and all are catered for by the algorithm.",
        "It was found that the relation of temporal inclusion played an important role in the constraints needed for phonological parsing (Carson-Berndsen, 1991).",
        "Simultaneity was not considered due to the fact that phonetic decisions are made on the basis of confidence values and thus the likelihood of true simultaneity is low.",
        "There is no difficulty, however, in augmenting the algorithm to cater for this if required since it is in fact a relationship of mutual temporal inclusion.",
        "The relations of overlap and precedence which hold between pairs of events are governed by a set of axioms; event structures are defined as a collection of events and constraints.",
        "These axioms can be regarded as having three different functions: inference, abbreviation and consistency checking.",
        "With respect to the abbreviation function of the axioms, this feature is not currently availed of in the algorithm as this would not reduce the search space.",
        "The consistency checking function of the axioms would be an extra step after the relations have been constructed.",
        "The output of the event mapping is an event lattice, analogous to the traditional disjunctive lattices of phoneme, syllable or word-based speech recognition, but not so far considered in previous work based on autosegmental structures.",
        "23.",
        "Event Structure Constraints There is clearly no direct correspondence between events as measured in a signal, and abstract phonological structures.",
        "These levels differ in five major ways: first, the signal-derived relations may be incomplete, owing to noisy input; second, the signal-derived event relations approximate to the transitive closure of the phonologically relevant minimal specification of the event structure, and must therefore be reduced by appropriate criteria; third, contextually conditioned phonetic reductions, assimilations and epentheses must be resolved; fourth, explicit complex phonological structures need to be defined; fifth, there may be no simple relation between event endpoints and nodes in parse chart structures.",
        "To complete the mapping from phonetic events to phonological event structures, constraints must be formulated which fulfil these tasks.",
        "The third type will be briefly discussed in section 3; the rest of the present section is mainly concerned with the fourth type.",
        "For the phonological component in the present system, a distinction is made between simplex and complex events.",
        "A simplex phonological event is defined as the basic unit of input from the phonetic component; at the phonetic level these events are in general a function of several parameters and arc therefore by no means 'simplex' at this level.",
        "A complex phonological event is constructed compositionally in terms of the precedence, overlap and inclusion relations at the phonological level.",
        "So for example the composition of the simplex events occlusion, transient and noise results in the complex event plosive.",
        "Complex events also refer to ACFES COLING-92, NAFIFES, 23-28 Aoiir 1992 12 7 0 PROC.",
        "Or COLING-92, NANT8s, AuG. 23-28, 1992 larger structures relevant at the phonological level such as syllable onset or reduced syllable.",
        "Using the constraint axiom set, further relations between these complex events are inferred.",
        "In the speech recognition context, absolute speech signal constants arc required to be assigned to the largest complex events in order to permit synchronisation at higher levels.",
        "The output of constraint application is thus a complex event lattice which is subsequently mapped to a linguistic parse chart (cf. Chien & al.",
        "1990)."
      ]
    },
    {
      "heading": "3. An Example",
      "text": [
        "In this section, an example of input and output in the system for generating the relations between phonetic events in a token of the English word palm /pa:m/ is discussed (cf. also Carson-Berndscn, 1991).",
        "The speech signal is shown in Figure 1; the phonemic annotations and display were produced with the SAMLAB speech signal labelling system (Braun, 1991a).",
        "The events used in this analysis are based on a feature set proposed by Fant (1973); although the features have labels which indicate articulatory features, they are in fact acoustically based.",
        "A diagrammatic representation of the detected events in an approximately 520 msec interval is shown in Figure 2.",
        "The temporally annotated events are passed to the phonological component of the speech recognition system in the interface format given in (3).",
        "Before the above algorithm is applied, the tuples are uniquely identified and translated into a variety of attribute-value notation as shown in (4) (note that confidence values arc not considered further here).",
        "(3) Temporal input from the phonetic level",
        "<voiceless, 0, 91.19, C> <voiced, 91.2, 517.5, C> <glide, 452.6, 498.2, C> <occlusive, 0, 35.4, C> <transient, 34.5, 60.6, C> <noise, 60.61, 91.16, C> <vowellike, 94.29, 392.6, C> <nasal, 402.9, 518.6, C> <bilabial, 20.45, 93.2, C> <tongue-retracted, 93.21, 392.6, C> <bilabial, 392.62, 518.2, C>",
        "(4) Event inventory",
        "VOI(voiceless, < 0,91.19 > ) e5: VOI(voiced, < 91.2,517.5 > ) e3: GLI(glide, < 452.6,498.2 > )",
        "Of particular interest to the phonological parser arc the precedence relations between those event properties of the same type and the overlap and temporal inclusion relations between event properties of differing types.",
        "Initially all relations between the individual events are generated automatically in (5).",
        "The temporal relations of overlap, precedence and inclusion are represented by the symbols ' <' and '{' respectively.",
        "One of the motivations for having chosen an event-based phonology for coping with the interface between phonetics and phonology was to be able to cater for phenomena which do not correspond to the phonotactics of the language.",
        "It may be the case, as given in the example WiihnIngssysten: in section 2, that the information on the centre portion of the signal, which is shown in (6) after the translation into attribute-value structure, is provided by the phonetic",
        "component.",
        "(6) Temporal annotations for [szst).",
        "cluster",
        "e,: FRICATION(fricative, <0, 301.3>) e2: VOICE(voiced, <79.9, 229.3>) C,: VOWELLIKE(vowellike, <128.5, 202.6>) c,: OCCLUSION(occlusive, <301.31, 334.6> ) There is not a full match between the output of the event mapping and any phonological representation, because FRICATION is continuous throughout and and thus overlaps VOWELLIKE rather than both preceding and following it.",
        "However, the phonological constraints include information on possible phonotactic structures; these will not he discussed here in detail (hut cf. Carson-Berndsen 1992).",
        "Positions in these structures are underspecified in terms of events, thus indirectly defining a priority between specified and non-specified event types at those positions.",
        "In this case, at the relevant VOWELLIKE interval FRICATION overlap is not specified, and thus a phonotactic match is permitted; VOICE is also not specified for initial sibilants.",
        "Note that vowel quality does not need to be specified in detail in the phonotactics.",
        "If an actual lexical item is more highly specified at these positions, it will match this part of the phonotactic structure, thus ultimately allowing the relevant portion of phonological representation of Walinings.system to be derived.",
        "(7) Constraints for fszstl cluster (foment).",
        "e, < e, (explicitly required by phonotactics) e2 < e, (explicitly required by phonotactics) e3 < e, (explicitly required by phonotactics) ° et (not specified by phonotactics) e, ° e, (not specified by phonotactics)",
        "(5) Output of Automatic Event Mapping"
      ]
    },
    {
      "heading": "4. Final Remarks",
      "text": [
        "In this paper a new solution to the projection problem in speech recognition is proposed in the form of a three-stage procedure for the automatic construction of event relations and phonological event structures, starting with an event lattice of simplex events in the form of temporal annotations provided by the acoustic phonetic component of a speech recognition system.",
        "In contrast to the purely concatenative solutions to word compositionality which are conventionally used, the present flexible approach using the three compositional relations of overlap, precedence and temporal inclusion promise a principled and effective solution to the projection problem at the phonetics/phonology interface."
      ]
    },
    {
      "heading": "5. Bibliography",
      "text": []
    }
  ]
}
