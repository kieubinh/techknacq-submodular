{
  "info": {
    "authors": [
      "K. Vijay-Shanker"
    ],
    "book": "Conference of the European Association for Computational Linguistics",
    "id": "acl-E93-1045",
    "title": "The Use of Shared Forests in Tree Adjoining Grammar Parsing",
    "url": "https://aclweb.org/anthology/E93-1045",
    "year": 1993
  },
  "references": [
    "acl-J93-4002",
    "acl-P85-1011",
    "acl-P88-1032",
    "acl-P89-1018"
  ],
  "sections": [
    {
      "heading": "Abstract",
      "text": [
        "We study parsing of tree adjoining grammars with particular emphasis on the use of shared forests to represent all the parse trees deriving a well-formed string.",
        "We show that there are two distinct ways of representing the parse forest one of which involves the use of linear indexed grammars and the other the use of context-free grammars.",
        "The work presented in this paper is intended to give a general framework for studying tag parsing.",
        "The schemes using hg and cfg to represent parses can be seen to underly most of the existing tag parsing algorithms."
      ]
    },
    {
      "heading": "1 Introduction",
      "text": [
        "We study parsing of tree adjoining grammars (tag) with particular emphasis on the use of shared forests to represent all the parse trees deriving a well formed string.",
        "Following Billot and Lang [1989] and Lang [1992] we use grammars as a means of recording all parses.",
        "Billot and Lang used context-free grammars (cfg) for representing all parses in a cfg parser demonstrating that a shared forest grammar can be viewed as a specialization of the grammar for the given input string.",
        "Lang [1992] extended this approach considering both the recognition problem as well as the representation of all parses and suggests how this can be applied to tag.",
        "This paper examines this approach to tag parsing in greater detail.",
        "In particular, we show that We are very grateful to Bernard Lang for helpful discussions.",
        "there are two distinct ways of representing the parse forest.",
        "One possibility is to use linear indexed grammars (hg), a formalism that is equivalent to tag [Vijay-Shanker and Weir, in pressa].",
        "The use of hg is not surprising in that we would expect to be able to represent parses of a formalism in an equivalent formalism.",
        "However, we also show that there is a second way of representing parses that makes use of a cfg.",
        "The work presented in this paper is intended to give a general framework for studying tag parsing.",
        "The schemes using hg and cfg to represent parses can be seen to underly most of the existing tag parsing algorithms.",
        "We begin with brief definitions of the tag and hg formalisms.",
        "This is followed by a discussion of the methods for cfg recognition and the representation of parses trees that were described in [Billot and Lang, 1989; Lang, 1992].",
        "In the remainder of the paper we examine how this approach can be applied to tag.",
        "We first consider the representation of parses using a cfg and give the space and time complexity of recognition and extraction of parses using this representation.",
        "We then consider the same issues where hg is used as the formalism for representing parses.",
        "We conclude by comparing these results with those for existing tag parsing algorithms."
      ]
    },
    {
      "heading": "2 Tree Adjoining Grammars",
      "text": [
        "Tag is a tree generating formalism introduced in [Joshi et al., 1975].",
        "A tag is defined by a finite set of elementary trees that are composed by means of the operations of tree adjunction and substitution.",
        "In this paper, we only consider the use of the adjunction operation.",
        "Definition 2.1A tag, G, is denoted G=(VN,VT,S,I,A) where VN is a finite set of nonterminals symbols, VT is a finite set of terminal symbols, S E VN is the start symbol, I is a finite set of initial trees, A is a finite set of auxiliary trees.",
        "An initial tree is a tree with root labeled by S and internal nodes and leaf nodes labeled by nonterminal and terminal symbols, respectively.",
        "An auxiliary tree is a tree that has a leaf node (the foot node) that is labeled by the same nonterminal that labels the root node.",
        "The remaining leaf nodes are labeled by terminal symbols and all internal nodes are labeled by nonterminals.",
        "The path from the root node to the foot node of an auxiliary tree is called the spine of the auxiliary tree.",
        "An elementary tree is either an initial tree or an auxiliary tree.",
        "We use a to refer to initial trees and /3 for auxiliary trees.",
        "A node of an elementary tree is called an elementary node and is named with an elementary node address.",
        "An elementary node address is a pair comprising of the name of the elementary tree to which the node belongs and the address of the node within that tree.",
        "We will assume the standard addressing scheme: the root node has an address e; if a node with address p has k children then the k children (in left to right order) have addresses p 1, .",
        ".",
        ".",
        ", p k. Thus, for each address p we have p E AP' where N is the set of natural numbers.",
        "In this section we use p to refer to addresses and 77 to refer to elementary node addresses.",
        "In general, we can write j =< 7, p > where 7 is an elementary tree and p E dom (-y) and dom (7) is the set of addresses of the nodes in 7.",
        "Let 7 be a tree with internal node labeled by a nonterminal A.",
        "Let )3 be an auxiliary tree with root and foot node labeled by the same nonterminal A.",
        "The tree, 7', that results from the adjunction of /3 at the node in 7 labeled A is formed by removing the subtree of 7 rooted at this node, inserting )3 in its place, and substituting it at the foot node of 3.",
        "Each elementary node is associated with a selective adjoining (SA) constraint that determines the set of auxiliary trees that can be adjoined at that node.",
        "In addition when adjunction is mandatory at a node it is said to have an obligatory adjoining (OA) constraint.",
        "Whether i3 can be adjoined at the node (labeled by A) in 7 is determined by the SA constraint of the node.",
        "In 7' the nodes contributed by )3 have the same constraints as those associated with the corresponding nodes in )3.",
        "The remaining nodes in 7' have the constraints of the corresponding nodes in 7.",
        "Given p E dom (7), by Ibl(-y, p) we refer to the label of the node addressed p in 7.",
        "Similarly, we will use sa(7, p) and oa(7, p) to refer to the SA and OA constraints of a node addressed p in a tree 7.",
        "Finally, we will use ft (/3) to refer to the address of the foot node of an auxiliary tree 13. adj (7, p, 13) denotes the tree that results from the adjunction of )3 at the node in 7 with address p. This is defined when f3 E sa(7, p).",
        "If adj (7, p, = 71 then the nodes in 7' are defined as follows.",
        "if p pi E dom (7') such that pi E dom (f3) then pi) =Pi),",
        "if p ft (fi) Pi E dom (71) such that p pa E dom (7) then 1b1(71, p ft (f3) pi) = 1b1(7, p pi), sa(71, p ft (j3) pi) = sa(7, p pi), a (7', P ft (/3) Pi) = oa(7, P Pi), In general, if p is the address of a node in 7 then <7, p > denotes the elementary node address of the node that contributes to its presence, and hence its label and constraints.",
        "The tree language, T(G), generated by a TAG, G, is the set of trees derived starting from an initial tree such that no node in the resulting tree has an OA constraint.",
        "The (string) language, L(G), generated by a TAG, G, is the set of strings that appear on the frontier of trees in T(G).",
        "Example 2.1 Figure 1 gives a TAG, G, which generates the language New I w E {a,b}*}.",
        "The constraints associated with the root and foot of 13 specify that no auxiliary trees can be adjoined at these nodes.",
        "This is indicated in Figure 1 by associating the empty set, 0, with these nodes.",
        "An example derivation of the strings aca and abcab is shown in Figure 2."
      ]
    },
    {
      "heading": "3 Linear Indexed Grammars",
      "text": [
        "An indexed grammar [Aho, 1968] can be viewed as a cfg in which objects are nonterminals with an associated stack of symbols.",
        "In addition to rewriting nonterminals, the rules of the grammar can have the effect of pushing or popping symbols on top of the stacks that are associated with each nonterminal.",
        "In [Gazdar, 1988] a restricted form of indexed grammars was discussed in which the stack associated with the nonterminal on the left of each production can only be associated with one of the occurrences of nonterminals on the right of the production.",
        "Stacks of bounded size are associated with other occurrences of nonterminals on the right of the production.",
        "We call this linear indexed grammars (hg).",
        "Lig generate the same class of languages as tag [Vijay-Shanker and Weir, in pressa].",
        "Definition 3.1A LIG, G, is denoted",
        "where VN is a finite set of nonterminals, VT is a finite set of terminals, V1 is a finite set of indices (stack symbols), S E VN is the start symbol, and P is a finite set of productions.",
        "Given a hg, G = (VN,VT)VItSIP), we define the set of objects of G as lic(G) ={A[ot] IA E VN and a E 1/1* } We use A[oo a] to denote the nonterminal A associated with an arbitrary stack with the string a on top and A[] to denote that an empty stack is associated with A.",
        "We use T to denote strings in (lic (G)UVT)*.",
        "The general form of a fig production is: A[oo a] ^ TB[oo air where A, B E VN a, a' E V/ and T, T' E (Ve(G) U VT)* Given a grammar, G = (VN , VTS, P), the derivation relation,v , is defined such that if A[oo a] TB[ooE P then for every )3 E VI and Ti T2 E (Vc(G)U VT)* T1A[fla]T2T1TI3PaTrT2 As a result of the linearity in the rules, the stack f3a associated with the object in the left-hand side of the derivation and the stack fia' associated with one of the objects in the right-hand side have the initial part # in common.",
        "In the derivation above, we say that the object B[flai] is the distinguished child of A[/3a].",
        "Given a derivation, the distinguished descendant relation is the reflexive, transitive closure of the distinguished child relation.",
        "The language generated by a fig, G is:",
        "wheredenotes the reflexive, transitive closure"
      ]
    },
    {
      "heading": "4 Parsing as Intersection with Regular Languages",
      "text": [
        "In the case of cfg parsing, [Billot and Lang, 1989; Lang, 19921 show that a cfg can be used to encode all of the parses for a given string.",
        "For example, let Go be a grammar and let the string w = al ... a, be in L(Go).",
        "All parses for the string w can be represented by the shared forest grammar G. The nonterminals in Gw are of the form (A, i, j) where A is a nonterminal of Go and 0 < i <i < n. The construction of G. is such that any derivation from (A, 1, j) encodes a derivation Aai+iai For instance, suppose ABC is a production in Go that is used in the first step of a derivation of the substring ...ai from A.",
        "Corresponding to this production, G., contains a production (A, i, j)(B, k)(C, k, j) for each 0 <i<k<j< n. This can be used to encode all parses of ai+i a from A where B...ak and Cakai In general, corresponding to a production AX1.. Xr in Go the grammar G., contains a production (A, it,--+ (Xi , it, ) (XI., ir for every it, hi , irE { 1,, n } such that for each 1 <k < r if Xk E VT then ik +1 = jk, otherwise ik+1 < ik.",
        "Additionally, G., includes the production (ak,k,k +1)ak for each 1 < k < n. Note that the number of nonterminals in the shared forest grammar, G.,, is 0(n2) and the number of productions is 0(nm+1) where twi = n and m is the maximum number of nonterminals in the right-hand-side of a production in G0.",
        "Therefore, if the object grammar were in Chomsky normal form, the number of productions is 0(n3).",
        "Lang [1992] extended this by showing that parsing a string w according to a grammar G can be viewed as intersecting the language L(G) with the regular language { w }.",
        "Suppose we have an object context free grammar Go and some deterministic finite state automaton M. For the sake of simplicity, let us assume that Go is in Chomsky normal form.",
        "The standard proof that context-free languages are closed under intersection with regular languages, constructs a context-free grammar for L(G0) fl L(M) with a production (A, p, q)(B , p,r)(C,r, q) for each production A BC of Go and states p, q, r of M. Also for each terminal a the production (a , p, q) a will be included if and only if b(p, a) = q where 5 is the transition function of M. Lang [1992] applied this to cfg recognition as follows.",
        "Given an input, w = al ... an, define the dfa Mu such that L(M)= {w}.",
        "The state set of M,, is { 0,1, ..., n }; the transition function b is such that b(i,ai+i) = + 1 for each 0 < i < n; 0 is the initial state; and n is the final state.",
        "The shared forest grammar G. is obtained when the standard intersection construction described above is applied to Go and M. Furthermore, since L(G) = L(G0) n L(Mw) and L(M) = {w}, we have w E L(Go) if and only if L(G) is not the empty set.",
        "That is, the original recognition problem can be turned into one of generating the shared forest grammar, Gw, and deciding whether the start nonterminal, (S, 0, n), of G. is an useful symbol, i.e., whether there is some terminal string x such that (S, 0, n) x Here S has been taken to be the start nonterminal of Go.",
        "Note that G., can be constructed in 0(n3) time and \"recognition\" can also be accomplished within this time bound.",
        "One advantage that arises from viewing parsing as intersection with regular languages is that exactly the same algorithm can be given a word net (a regular language that is not a singleton) rather than a single word as input.",
        "This could be useful if we wish to deal with ill-formed inputs."
      ]
    },
    {
      "heading": "5 Derivation versus Derived Trees in TAG",
      "text": [
        "For grammar formalisms involving the derivation of trees, a tree is called a derived tree with respect to a given grammar if it can be derived using the rewriting rules of the grammar.",
        "A derivation tree of the grammar, on the other hand, is a tree that encodes the sequence of rewritings used in deriving a derived tree.",
        "In the case of cfg, a tree that is derived contains all the information about its derivation and there is no need to distinguish between derivation trees and derived trees.",
        "This is not always the case.",
        "In particular, for a tree-rewriting system like tag we need to distinguish between derived and derivation trees.",
        "In fact there are at least two ways one can encode tag derivation trees.",
        "The first (see [Vijay-Shanker, 1987]) captures the fact that derivations in tag are context-free, i.e., the trees that can be adjoined at a node can be determined a priori and are not dependent on the derivation history.",
        "We capture this context-freeness by giving a cfg to represent the set of all possible derivation sequences in a tag.",
        "An alternate scheme uses a tag or a hg (see [Vijay-Shanker",
        "and Weir, in pressbp to represent the set of all possible derivations.",
        "We briefly consider the first scheme to show how given a tag, Go and a string, w, context-free grammar can be used to represent shared forests.",
        "In later sections we will study the second scheme using hg for shared forests.",
        "and a string w = al ...an we construct a context free grammar, G. such that L(G) (1) if and only if w E L(G.).",
        "Let My, be the dfa for w described in Section 4.",
        "Consider a tree 13' that has been derived from some auxiliary tree in A.",
        "Let the string on the frontier of f3 that is to the left of the foot node be u) and the string to the right of the foot node be ur Consider the tree that results from the adjunction of )3 at a node in with elementary node addressl n where v is the string on the frontier of the subtree rooted at n. After adjunction the strings u/ and u,.",
        "will appear to the left and right (respectively) of v. Suppose that in a derivation of the string w by the grammar Go the strings ut and hr form two continuous substrings w: i.e., ui = ai+1 ap and Ur = aq+1 ...aiforsome0<i<p<q<j<n. Thus, according to the definition of Mu, we would have 4i, ui) = p and b(g,ur) = j.",
        "Hence, we can use the four states i, j,p and g of Mt, to account for which parts of w are spanned by the frontier of )3.",
        "Since the string appearing at the subtree rooted at 17 is v then if b(p, v) = q we have b(i,uivur) = j and p and q identify the substring of w that is spanned by the subtree rooted at 7/.",
        "However, the node may be on the spine of some auxiliary tree, i.e., on the path from the root to the foot node.",
        "In that case we will have to view the frontier of the subtree rooted at 77 as comprising two substrings, say viand v,.",
        "to the left and right of the foot node, respectively.",
        "The two states p, q of Mu, are do not fully characterize the frontier of subtree rooted at ij.",
        "We need four states, say p, q, r, s, where b(p, vi) = r and b(s, yr) = s. Note that the four states in question only characterize the frontier of subtree rooted at ?I before the adjunction of /3 takes place.",
        "The four states i, j, r, s characterize the situation after adjunction of 3 since b(i, 14) = p, (5(p, vi) = r (therefore b(i, uivi) = p) and b(s, voir) = b(q,ur) = j.",
        "In the shared forest cfg G. the derivation of the Rather than repeatedly saying a node with an elementary node address Is, henceforth we simply refer to it as the node string at frontier of tree rooted at ri before adjunction will be captured by the use of a nonterminal of the form (1, q, p, q,r, s) and the situation after ad junction will be characterized by (T, j, r,^).",
        "We use the symbols T and 1 to capture the fact that consideration of a node involves two phases: (i) the T part where we consider adjunction at a node, and (ii) the 1 part where we consider the subtree rooted at this node.",
        "Note that the states r, s are only needed when ri is a node on the spine of an auxiliary tree.",
        "When this is not the case we let r = s = Since we have characterized the frontier of /3 (i.e., the subtree rooted at the roots, the root of f3) by the four states I, j, p, q, we can use the nonterminal (T, root, j,p, q) and can capture the derivation involving adjunction of /3 at y by a production of the form (T ,j, r, s)(T, rooto, j, p, q)(J..,qp, q, r, s) Without further discussion, we will give the productions of G. For each elementary node i do the following.",
        "Case 1: When 77 is a node that is labeled by a terminal a, add the production ) + a if and only if b(p, a) = q.",
        "Case 2a: Let 711 and 772 be the children of '1 and the left-child ni dominates the foot node then add the production (1, q, j,p, q)(T, qi,i, k , p, q) (T 072, k , j , , ) if neither children dominate the foot node then add the production",
        "If q is the root of an initial tree then add the production S > (T, o, n, ) where S is the start symbol of G. Note that (cases 2a and 2b) we are assuming binary branching merely to simplify the presentation.",
        "We can use a sequence of binary cfg productions to encode situations where q has more than two children.",
        "That is, even if the object-level grammar was not binary branching, the shared forest grammar can still be.",
        "Note that since the state set of M., is {0, , n}, the number of nonterminals in Go is 0(n4).",
        "Since there are at most three nonterminals in a production, there are at most six states involved in a production.",
        "Therefore, the number of productions is 0(n6) and construction of this grammar takes 0(n6) time.",
        "Although the derivations of G. encode derivations of the string w by Go the specific set of terminal strings that is generated by G. is not important.",
        "We do however have L(G) 0 0 if and only if w E L(G0) As before, we can determine whether L(G) 0 0 by checking whether the start nonterminal S is useful.",
        "Furthermore this can be detected in time and space linear to the size of the grammar.",
        "Since w E L(G0) if and only if L(G) 0 0, recognition can be done in 0(n6) time and space.",
        "Once we have found all the useful symbols in the grammar we can prune the grammar by retaining only those productions that have only useful symbols.",
        "Since G. is a cfg and since we can now guarantee that every nonterminal can derive a terminal string and therefore using any production will yield a terminal string eventually, the derivations of w in Go can be read off by simply reading off derivations in G. 7 Using LIG for Shared Forests We now present an alternate scheme to represent the derivations of a string w from a given object tag grammar G..",
        "In later sections show how it can be used for solving the recognition problem and how a single parse can be extracted.",
        "The scheme presented in Section 6 that produced a cfg shared forest grammar captured the context freeness of tag derivations.",
        "The approach that we now consider captures an alternative view of tag derivations in which a derivation is viewed as sensitive to the derivation history.",
        "In particular, the control of derivation can be captured with the use of additional stack machinery.",
        "This underlies the use of hg to represent the shared forests.",
        "In order to understand how a hg can be used to encode a tag derivation, consider a top-down derivation in the object grammar as follows.",
        "A tag derivation can be seen as a traversal over the elementary trees beginning at the root of one of the initial trees.",
        "Suppose we have reached some elementary node q.",
        "We must first consider adjunction at 9 and after that we must visit each of q's subtrees from left to right.",
        "When we first reach q we say that we are in the top phase of 9.",
        "The derivation 14 encodes this with the nonterminal T associated with a stack whose top element is n. After having considered adjunction at n we are in the bottom phase of n. The derivation 14 encodes this with the nonterminal 1 associated with a stack whose top element is n. When considering adjunction at q we may have a choice of either not adjoining at all or selecting some auxiliary tree to adjoin.",
        "If the former case we move directly to the bottom phase of n. In the latter case we move to (visit) the root of the auxiliary tree /3 that we have chosen to adjoin.",
        "Once we have finished visiting the nodes of /3 (i.e., we have reached the foot of /3) we must return to (the bottom phase of) q.",
        "Therefore, it is necessary, while visiting the nodes in i3 to store the adjunction node q.",
        "This can be done by pushing 9 onto the stack at the point that we move to the root of /3.",
        "Note that the stack may grow to unbounded length since we might adjoin at a node within 13, and so on.",
        "When we reach the bottom phase of foot node of /3 the stack is popped and we find the node at which /3 was adjoined at the top of the stack.",
        "/,From the above discussion it is clear that the 14 needs just two nonterminals, T and 1.",
        "At each step of a derivation in the 14 shared forest grammar the top of the stack will specify the node being currently being visited.",
        "Also, if the node I being visited belongs to an auxiliary tree and is on its spine we can expect the symbol below the top of the stack to give us the node where )3 is adjoined.",
        "If q is not on the spine of an auxiliary tree then it is the only symbol on the stack.",
        "We now show how the hg shared forest grammar can be constructed for a given string w = al an.",
        "Suppose we have a tag",
        "as defined in Section 4.",
        "We construct the 14 = (VIC,ITT, , P) that generates the intersection of L(G) and L(M).",
        "P includes the following set of productions for the start symbol S' IST (T ,qo,V)frn I qf E F and q is root of initial tree In addition, for each elementary node do the following.",
        "for each p, q E Q such that q E b(p, a).",
        "Case 2a: When ni and 712 are the children of a node such that the left sibling ni is on the spine or neither child is on the spine, P includes the production (1, p, q)[oo(T, p, r)[oo iii] (T, r, q)[712] for each p, q, r E Q.",
        "Note that the stack of adjunction points must be passed to the ancestor of the foot node all the way to the root.",
        "Case 2h: When ni and n2 are the children of a node 71 such that the right sibling n2 is on the spine P includes the production (1, p, q)[oo 77](T, p, r)[ni] (T, r, q)[oo n2] for each p, q, r E Q.",
        "Case 3: When ri is a nonterminal node that does not have an OA constraint P includes the production (T, p, q)[oo n] -.4 (1, p, q)[oo for each p,q E Q.",
        "This production is used when no adjunction takes place and we move directly between the top and bottom phases of n. Case 4a: When n is a node where # can be adjoined and n' is the root node of /3 P includes the production (T, p, q)[oo(T, p, q)[oo my] for each p,q E Q.",
        "Note that the adjunction node 77 has been pushed below the new node if on the stack.",
        "Case 4h: When n is a node where 71 can be adjoined and if is the foot node of /3 P includes the production (1, p, q)[oo nni] --+ (1, p, q)[oo for each p, q E Q.",
        "Note that the stack symbol that appeared below 77 will be the node at which # was adjoined.",
        "Since the state set of M. is {0,, n} there are 0(n2) nonterminals in the grammar.",
        "Since at most three states are used in the productions, M. has 0(n3) productions.",
        "The time taken to construct this grammar is also 0(n3).",
        "As in the cfg shared forest grammar constructed in Section 6 we have assumed that the tag is binary branching for sake of simplifying the presentation.",
        "The construction can be adapted to allow for any degree of branching through the use of additional (binary) hg productions.",
        "Furthermore, this would not increase the space complexity of the grammar.",
        "Finally, note that unlike the cfg shared forest grammar, in the hg shared forest grammar G., w is derived in Go if and only if w is derived in G. Of course in both cases L(G) = {w}f1L(G0) and hence the recognition problem can be solved by determining whether the shared forest grammar generates the empty set or not."
      ]
    },
    {
      "heading": "8 Removing Useless Symbols",
      "text": [
        "As in the case of the cfg shared forest grammar, to solve the original recognition problem we have to determine if L(G) 0.",
        "In particular, we have to determine whether S' [1 derives a terminal string.",
        "We solve this question by construcing an nfa, MG., from G. where the states of MG. correspond to the non terminal and terminal symbols of G. This transforms the question of determining whether a symbol is useful into a reachibility question on the graph of MG In particular, for any string of stack symbols 7, the object A[7] derives a string of terminals if and only if it is possible, in the nfa MG., to reach a final state from the state corresponding to A on the input 7.",
        "Thus, w E L(Go) if and only if S'n w if and only if in MG,, a final state is reachable from the state corresponding to S' on the empty string.",
        "Given a hg G. = (VN VT , P) we construct the nfa MG, = (Q, E, b, qo, F) as follows.",
        "Let the state set of M be the nonterminal and terminal alphabet of G,: i.e., Q = VN U VT.",
        "The initial state of MG. is the start symbol of G., i.e., qo = S'.",
        "The input alphabet of MG,, is the stack alphabet of G.: i.e., E = VI.",
        "Note that since G. is the hg shared forest the set VI is the set of the elementary node addresses of the object tag grammar Go.",
        "The set of final states, F, of MG,,, is the set VT.",
        "The transition function b of MG,,, is defined as follows.",
        "then if BEn) add B to 5(.91, c).",
        "Given that w = al ... an and that the nonterminals (and corresponding states in MG.) of Gw are of the form (T, j) or (_L, j) where 0 < i < j < n, there are 0(n2) nonterminals (states in M.) in the hg G. The size of MG. is 0(n4) since there are 0(n2) out-transitions from each state.",
        "We can use standard dynamic programming techniques to ensure that each production is considered only once.",
        "Given such an algorithm it is easy to check that the construction of MG, will take 0(0) time.",
        "The worst case corresponds to case 4a which will take 0(n4) for each production.",
        "However, there are only 0(n2) such productions (for which case 4a applies).",
        "Once the nfa has been constructed the recognition problem (i.e., whether w E L(G 0)) takes 0(n2) time.",
        "We have to check if there is an c-transition from the initial state to a final state and hence we will have to consider 0(n2) transitions.",
        "A straightforward algorithm can be used to remove the states for nonterminals that do not appear in any sentential form derived from S'.",
        "In other words, only keep states such that for some 7 there is a derivation S[]T1A[7]T2 for some Ti T2 E (Vc(Gw) U VT)* Note that the states to be removed are not those states that are not reachable from the initial state of MG..",
        "The set of states reachable from the initial state includes only the set of nonterminals in objects that are the distiguished descendent of the root node in some derivation.",
        "iFrom the construction of MG., it is that case that for each A E VN the set {v I a E7) for some a E F } is equal to the set {71.4[7]x for some x E Thus, if a final state is accessible from a state A then for some 7 (that witnesses the accessibility of a final state from A) A[7]x for some x E V2.",
        "Once the construction of MG,, is complete we only retain those productions in G. that involve nonterminals that remain in the state set of of MG..",
        "However, unlike the case of the cfg shared forest grammar, the extraction of individual parses for the input w does not simply involve reading off a derivation of G. This is due to the fact that although retaining the state A does mean that there is a derivation S[] T1A[7]T2 for some 7 and T1T2, we can not guarantee that A[7] will derive a string of terminals.",
        "The next section describes how to deal with this problem.",
        "9 Recovery of a Parse Let the hg G. with useless productions removed be G. = (VN, VTP) and let the nfa MG,, constructed in Section 8 with unnecessary states removed be MG. = (VN U VT1V 1)5, VT) Recovering a parse of the string w by the object grammar Go has now been converted into the problem of extracting one of the derivations of G. However, this is not entirely straightforward.",
        "The presence of a state Ain VNU VT indicates that for some 7 in Viand Ti, T2 in (Vc(Gw) U VT)* we have TiAMT2 Ow However, it is not necessarily the case that b(A, 7)n VT 0 0, i.e., it might not be possible to reach a final state of MG. from A with input 7.",
        "All we know is that there is some 7' E 17; (that could be distinct from 7) such that A[71] derives a terminal string, i.e., at least one final state is accessible from A on the string 7'.",
        "This means that in recovering a derivation of Gw by considering the top-down application of productions we must be careful about which production we choose at each stage.",
        "We cannot assume that any choice of production for an object, A[7] will eventually lead to a complete derivation.",
        "Even if the top of the stack 7 is compatible with the use of a production, this does not guarantee that A[7] derives a terminal string.",
        "We give an procedure recover that can be used to recover a derivation of G. by using the nfa MG..",
        "This procedure guarantees that when we reach a state A by traversing a path 7 from the initial state then on the same string 7 a final state can be reached from the state A.",
        "If recover(TI Tna) is invoked the following hold.",
        "then output p. Note there must be such a production Case 2a: If there is some production p = A1[00B[oo C[11] E P such that b(C , 1\") = b for some b E VT, and either n> 1 and A2 E 6(B, 1') (where T2 = (A2) 772)) or n = 1 and a E b(B, 1') then output p recover((B, 1')T2 .",
        ".",
        ".Tna) recover((C, 1\")b) Case 2b: If there is some production",
        "such that 6(C, 1\") = b for some b E VT and either n> 1 and A2 E b(B , 1') (where T2 = (A2,172)) or n= land a E 6(B ,P) then output p recover((B, 1')T2 .",
        ".",
        ".",
        "Tea) recover((C, 1\")b) Case 3: If there is some production p = Ai [oo 771]B[oo E P such that either n > 1 and A2 E 5(B, 1') (where",
        "such that C E b(B ,1') for some C E VN and A2 E d(C, no and either n> 1 and 7'2 = (Az, 712) or n = 1 and a E b(C, ni) then output p recover((B, /')(C, n1)7'2T, ,a) Case 4h: If there is a production p = Ai [oo n2ni] A2[00E P such that n> 1 and T2 = (A21712) then output p recover(T2 .",
        "Tn) Given the form of the nonterminals and productions of G. we can see that the complexity of extracting a parse as above is dominated by the complexity by Case 4a which takes 0(n4) time.",
        "If in G0 every elementary tree has at least one terminal symbol in its frontier (as in a lexicalized tag) then to derive a string of length n there can be at most n adjunctions.",
        "In that case, when we wish to recover a parse the derivation height (which gives recursion depth of the the invocation of the above procedure) is 0(n) and hence recovery of a parse will take 0(n5) time."
      ]
    },
    {
      "heading": "10 Conclusions",
      "text": [
        "We have shown that there are two distinct ways of representing the parses of a tag using hg and cfg.",
        "The cfg representation captures the fact that the choice of which trees to adjoin at each step of a derivation is context-free.",
        "In this approach the number of nonterminals is 0(124), the number of productions is 0(n6) and, hence, the recognition problem can be resolved in 0(n6) time with 0(n4) space.",
        "Note that now the problem of whether the input string can be derived in the tag grammar is equivalent to deciding whether the shared forest cfg obtained generates the empty language or not.",
        "Each derivation of the shared forest cfg represents a parse of the given input string by the tag.",
        "In the scheme that uses hg the number of non terminals is 0(n2) and the number of productions is 0(n3).",
        "While the space complexity of the shared forest is more compact in the case of hg, recovering a parse is less straightforward.",
        "In order to facilitate recovery of a parse as well as to solve the recognition problem (i.e., determine if the language generated by the shared forest grammar is nonempty) we use an augmented data structure (the nfa, MG.) With this structure the recognition problem can again be resolved in 0(n6) with 0(n4) space and the extraction of a parse has 0(n) time complexity.",
        "The work described here is intended to provide a general framework that can be used to study and compare existing tag parsing algorithms (for example [Vijay-Shanker and Joshi, 1985; Vijay-Shanker and Weir, in pressb; Schabes and Joshi, 1988]).",
        "If we factor out the particular dynamic programming algorithm used to determine the sequence in which these rules are considered then the productions of our cfg and hg shared forest grammars encapsulate the steps of all of these algorithms.",
        "In particular, the algorithm presented in [Vijay-Shanker and Joshi, 1985] can be seen to corresponds to the approach involving the use of cfg to encode derivations, whereas, the algorithm of [Vijay-Shanker and Weir, in pressb]",
        "uses hg in this role.",
        "Although the space complexity of the cited parsing algorithms is 0(724), the data structures used by them do not explicitly give the shared forest representation provided by our shared forest grammars.",
        "The data structures would have to be extended to record how each entry in the table gets added.",
        "With this kind of additional information the space requirements of these algorithms would become 0(n6).",
        "It is perhaps not surprising that the hg shared forest and cfg shared forest described here turn out to be closely related.",
        "In the nfa MG. (after useless symbols have been removed) we have (B, p, q) E b ((A, i, j), q) if and only if in the cfg shared forest (A, n, i, j, p, q) is not a useless symbol.",
        "In addition, there is a close correspondence between productions in the two shared forest grammars.",
        "This shows that the two schemes result in essentially the same algorithms that store essentially the same information in the tables that they build.",
        "We end by noting that Lang [1992] also considers tag parsing with shared forest grammars, however, he uses the tag formalism itself to encode the shared forest.",
        "This does not utilize the distinction between derivation and derived trees in a tag.",
        "The algorithms presented here specialize the derivation tree grammar to get shared forest whereas Lang [19921 specializes object grammar itself.",
        "As a result, in order to get 0(n6) time complexity Lang must assume the object grammar tree in a very restricted normal form."
      ]
    }
  ]
}
