{
  "info": {
    "authors": [
      "Chinatsu Aone",
      "Sharon Flank",
      "Douglas McKee",
      "Paul Krause"
    ],
    "book": "Message Understanding Conference",
    "id": "acl-M93-1018",
    "title": "SRA: Description of the SOLOMON System as Used for MUC-5",
    "url": "https://aclweb.org/anthology/M93-1018",
    "year": 1993
  },
  "references": [
    "acl-H91-1060",
    "acl-H93-1028",
    "acl-P93-1021",
    "acl-W93-0110"
  ],
  "sections": [
    {
      "heading": "BACKGROUND",
      "text": [
        "SRA used a language-independent, domain-independent, multipurpose text understanding system as the core of the M UC-5 system for extraction from English and Japanese joint venture texts.",
        "SRA's NLP core system, SOLOMON, has been under development since 1986.",
        "It has been used for a variety of domains, and was aimed from the start to be language-independent, domain-independent, and application-independent.",
        "More recently, SOLOMON has been extended to be multilingual, beginning with Spanish in 1990 and Japanese in 1991.",
        "The Spanish-Japanese text understanding system that uses SOLOMON was developed for a domain very different from the MUC-5 joint venture domain (cf. Aone, et al.",
        "[2]).",
        "SOLOMON's principal applications have been in data extraction, but it is also used in a prototype machine translation system (cf. Aone and McKee [5]).",
        "The domain areas in which SOLOMON applications have been developed are: financial, terrorism, medical, and the MUC-5 joint-venture domain.",
        "SRA has significantly enhanced its capability to add new domains and languages by developing new strategies for data acquisition using both statistical techniques and a variety of user-friendly tools."
      ]
    },
    {
      "heading": "MUC-5 SYSTEM ARCHITECTURE",
      "text": [
        "SOLOMON employs a modular, data-driven architecture to achieve its language and domain-independence.",
        "The M UC-5 system, which uses SOLOMON as a core engine, consists of seven processing modules and corresponding data modules, as shown in Figure 1, which will be described in the following sections."
      ]
    },
    {
      "heading": "Message Zoner",
      "text": [
        "The Message Zoner uploads the SGML-annotated text file into the data extraction system.",
        "Input files are assumed to have been proprocessed so that they contain only \"rigorous markup\" (cf. Goldfarb [8]) SGML tags and text; however, we do not require sentences or paragraphs to be tagged.",
        "Japanese text is assumed to be encoded in EUC, but tags must be ASCII.",
        "All input, including tags, is tokenized using a simple, language-independent, regular expression recognizer.",
        "The (multi-word) tokens are parsed into sentences, paragraphs, headers and documents using a simple operator-precendence grammar (cf. Aho, Sethi and Ullman [1]) operating on punctuation and tags.",
        "The tokenizer and parser are written entirely in lex.",
        "Sentence and paragraph boundries are inferred using a conservative algorithm and marked as inferred.",
        "Inference is not performed if sentences and paragraphs are rigorously marked.",
        "The output is piped to a post-processor, which does a fast lookup of each word in a btree gazetteer, and includes entry information in the tokens of place names."
      ]
    },
    {
      "heading": "Preprocessing",
      "text": [
        "Preprocessing consists of two processors, the morphological analyzer and the pattern matcher, and associated data in the form of morphological data, lexicons, and patterns for each language.",
        "Its input is a tokenized message, and its output is a series of lexical entries with syntactic and semantic attributes.",
        "Declarative morphological data for inflection-rich Japanese and Spanish is compiled into finite-state machines.",
        "The English domain lexicon was derived from development texts automatically, using a statistical technique (cf. McKee and Maloney [10]).",
        "This derived lexicon also contains automatically acquired domain-specific subcategorization frames and predicate-argument mapping rules called situation types (cf. Aone and McKee [3]), as shown in Figure 2.",
        "Pattern recognition handles a wide range of phenomena, including multi-words, numbers, acronyms, money, date, person names, locations, and organizations.",
        "We extended the Pattern matcher to handle multilevel pattern recognition.",
        "The pattern data are divided into ordered multiple groups called priority groups, and the patterns in each group are fired sequentially, avoiding recursive applications as much as possible.",
        "This extension speeded up the performance of Preprocessing significantly."
      ]
    },
    {
      "heading": "Syntactic Analysis",
      "text": [
        "The processor for Syntactic Analysis is a parser based on Tomita's algorithm (cf. Tomita [11]), with modifications for disambiguation during parsing.",
        "Syntactic Analysis data consist of X-bar based phrase structure grammars and preparse patterns for each of the three languages, English, Japanese, and Spanish.",
        "Syntactic Analysis outputs F-structures (grammatical relations), along the lines of Lexical-Functional Grammar (cf. Bresnan [7]), as shown in Figure 3.",
        "The Semantic Interpretation module is interleaved for disambiguation"
      ]
    },
    {
      "heading": "(OCCS 36) (PREDICATE CHAIGIIG-EVENT) (PROB 8.1 . 1) (SITUATION-TYPE ACTIVITY))) (TEAM ((CATEGORY . V) (IDIOSYNCRACIES (THEME (MAPPING (LITERAL WITH)))) (OCCS 31) (PREDICATE ANIMATE-OBJECT-ACTIVITY) (SITUATION-TYPE PROCESS _CAUSED-PROCESS))) (SWITCH ((CATEGORY . V) (IDIOSYNCRACIES (SOURCE (MAPPING (LITERAL FROM)))) (OCCS 161) (PREDICATE TURNKEY-CHANGE)",
      "text": [
        "of prepositional phrase attachment, conjunctions, and so on, by calling semantic functions, which are shared by all three languages, from inside the grammar.",
        "Preparsing takes the burden off of main parsing and increases accuracy, by recognizing structures such as sentential complements, appositives, certain PP's, etc.",
        "by pattern matching, and sending these to the parser as chunks.",
        "These preparse chunks are parsed prior to main parsing using the same grammars, and their output consists of F-structures as well.",
        "• Appositives: RARA-T-osMai \"industry's largest Tokyo Kaijou\" • Sentences with certain verb endings: KVA, it\"ItAXAT 11 -fvtit, Lt,: trifk,*\"\"Ct *MITSIZ .",
        "• PP's: start production [in january 1990] with production of 20,000 iron",
        "In order to test the progress of grammar development and pinpoint trouble spots, automatic evaluation of grammars was used.",
        "SRA adapted the community-wide program Parseval (cf. Black, et al.",
        "[6]) for use in Japanese in addition to English.",
        "Testing on Japanese was limited, since there are not many bracketed Japanese texts to use as answer keys."
      ]
    },
    {
      "heading": "Semantic Interpretation",
      "text": [
        "Semantic Interpretation uses a language-independent processing module, and its data are predicate-argument mapping rules for each verb, plus both core and domain knowledge bases.",
        "Semantic Interpretation works"
      ]
    },
    {
      "heading": "BRIDGESTONE SPORTS CO. SAID FRIDAY IT HAS SET UP A JOINT VENTURE IN TAIWAN WITH A LOCAL CONCERN AND A JAPANESE TRADING HOUSE ... [ST: <S> SUBJECT: [ST: <NP> HEAD: BRIDGESTONE-SPORTS-CO.] ADJUNCTS: ([ST: <NP> HEAD: FRIDAY]) PREDICATE: [ST: <VP> TENSE: PAST PREDICATE: (COMMUNICATE) ROOT: SAY SENT-COMP: [ST: <S> SUBJECT: [ST: <NP>",
      "text": [
        "HEAD: IT]"
      ]
    },
    {
      "heading": "PREDICATE: [ST: <VP> TENSE: PRESENT ASPECT: PERFECT PREDICATE: (CREATE) ROOT: SET VERB-PARTICLE: UP] OBJECT: [ST: <NP> HEAD: A-JOINT-VENTURE]",
      "text": []
    },
    {
      "heading": "MARKED: WITH HEAD: A-LOCAL-CONCERN-AND-A-JAPANESE-TRADING-HOUSED",
      "text": []
    },
    {
      "heading": "MARKED: IN HEAD: TAIWAN])]]]",
      "text": [
        "off of language-neutral F-structures in order to handle all the languages.",
        "It outputs semantic structures, i.e. predicate-argument and modification relations, as shown in Figure 4.",
        "The predicate-argument mapping rules (i.e. rules which map F-structures to semantic structures) are acquired automatically (cf. Aone and McKee [31).",
        "Domain knowledge bases, on the other hand, were acquired manually.",
        "However, a new rapid knowledge acquisition tool called KATool was used to link a lexical entry to its corresponding semantic concept in the knowledge bases (cf.",
        "Figure 5).",
        "If a full parse cannot be created, SOLOMON uses a fragment combination strategy.",
        "Debris Parsing and its subsequent process, Debris Semantics, work together to obtain the best interpretation from sentence fragments.",
        "They use as data the grammars and knowledge bases, and they output semantic structures just like when a full parse is created.",
        "Debris Parsing retrieves the largest and most preferred constituents from the parse stack.",
        "It then reparses the rest of the input, and creates debris F-structures with the best fragment constituents.",
        "Debris Semantics relies on the semantic interpreter to process each fragment, and then fits fragments together using semantic constraints on unfilled slots."
      ]
    },
    {
      "heading": "Discourse Analysis",
      "text": [
        "Discourse Analysis, which was redesigned and implemented this year (cf. Aone and McKee [zq), performs reference resolution.",
        "Discourse Analysis uses a data-driven architecture to achieve language-independence, domain-independence, and extensibility.",
        "It employs a single language-independent, domain-independent processor, and several discourse knowledge bases, some of which are shared among different languages.",
        "The mflimit of Discourse Analysis is a set of semantic structures with coreference links added, i.e.",
        "File Cards (cf. Heim [9]).",
        "Discourse plienomena handled for the joint venture domain include rulnie anaphora (e.g."
      ]
    },
    {
      "heading": "(COMPAIY-1146 (ISA (VALUE (COMPANY))) (QUANTITY (VALUE ((EXACT 1)))) (UNIT (VALUE (NATURAL-UNIT))) (NAMES (VALUE ((BRIDGESTONE SPORTS CO))))) (CREATE-1163 (ISA (VALUE (CREATE))) (LOCATION (VALUE (COUNTRY-ii))) (AGENT (VALUE (THING-1166))) (THEME (VALUE (TIE-UP-EVENT-1164))) (CO-THEME (VALUE (CONJOIIED-COLLECTIOI COMPANY)-1172)) (ASPECT (VALUE (PERFECT))) (TENSE (VALUE (PRESENT)))) ((CONJOINED-COLLECTION COMPANY) -1172 (ISA (VALUE ((AID CONJOINED-COLLECTION COMPANY)))) (HAS-MEMBERS (VALUE (COMPANY-1170 COMPAIY-1168)))) (COMPANY-1168 (ISA (VALUE (COMPANY))) (QUANTITY (VALUE ((EXACT 1)))) (UNIT (VALUE (NATURAL-UNIT))) (LOCATION (TYPE (AND T PHYSICAL-LOCATION)) (VALUE (LOCAL)))) (COMPANY-1170 (ISA (VALUE (COMPANY))) (QUANTITY (VALUE ((EXACT 1)))) (UNIT (VALUE (NATURAL-UNIT))) (NATIONALITY (VALUE (JAPAN)))) (COUNTRY-1144 (ISA (VALUE (COUNTRY))) (ENGLISH-GAX-STRING (VALUE (Taiwan (COUNTRY)))))",
      "text": [
        "\"BRIDGESTONE SPORTS\" for \"BRIDGESTONE SPORTS CO.\") and definite NP's such as \"THE NEW ('OM PA NY .",
        "The system traces for English and Japanese walkthrough examples are shown in Figure 6 and Figure 7.",
        "In the English example, the two instances of name anaphora for \"Bridgestone Sports Co.\" are recognized, while in the Japanese example, all the references to \"Tokyo Kaijou Kasai Hoken,\" including appositives, are resolved."
      ]
    },
    {
      "heading": "Pragmatic Inferencing",
      "text": [
        "Pragmatic lnferencing performs reasoning in order to derive implicit information from the text, using a forward chainer and inference rules.",
        "Pragmatic Inferencing outputs semantic structures, with inferred information added.",
        "It infers additional information from \"literal\" meanings as required for application domains.",
        "For instance, in the walkthrough example, in order to infer \"THE TAIWAN UNIT\" is a joint venture company from the phrase \"THE ESTABLISHMENT OF THE TAIWAN UNIT\" the following rule is used."
      ]
    },
    {
      "heading": "Extract",
      "text": [
        "The Extract module performs template generation, translating the domain-relevant portions of our language-independent semantic structures into database records.",
        "We maintain a strong distinction between processing and data even in template generation.",
        "Thus, we use the same processing module to output in different languages and to several database schemata, including to a flat template-style schema as in MUC-4 and to a more object-oriented schema as in MUC-5.",
        "To do the actual template filling, we rely on Extract data made up of kb-object/slot to db-table/field mapping rules and conversion functions for the individual values (e.g. set fills, string fills).",
        "For example, the #nationality slot of an #ORGANIZATION object in our knowledge base corresponds to the Nationality field of the Entity object in the MUC-5 template."
      ]
    },
    {
      "heading": "REUSABILITY OF THE SYSTEM",
      "text": [
        "SOLOMON is designed for reusability.",
        "Each processing module is data-driven and reusable in other languages and other domains, as well as in applications other than data extraction (e.g. machine translation, abstracting, summarization).",
        "A large portion of the data is also reusable in:",
        "• Other languages and domains – Core knowledge bases • Other domains – Morphological data – General lexicons General pattern data (e.g. date, location, personal name, organization name) Grammars Some of the discourse knowledge sources • Other languages – Domain knowledge bases",
        " – Some of the discourse knowledge sources – Inference rules – Extract (template generation) data",
        "The data acquisition tools and techniques are also reusable in other languages and domains.",
        "The statistical techniques used to derive lexical information can be reused for other domains.",
        "LEXTool, the lexicon acquisition tool, is multilingual and relies on system data files for category and morphological information.",
        "KBTool, the knowledge base acquisition tool, is language-independent just as the knowledge bases are language-independent.",
        "KATool, the knowledge acquisition tool that links lexicon entries with the appropriate knowledge base concepts, is entirely data-driven as well, and is therefore completely reusable.",
        "Figure 8 summarizes the reusability of SRA's MUC-5 system."
      ]
    },
    {
      "heading": "TEST RESULTS AND ANALYSIS",
      "text": [
        "Our MUC-5 results for the English and Japanese joint-venture domain task are shown in Table 1.",
        "We spent 10.55 person-months for this task, most of which were devoted to data development for both languages (see Table 2).",
        "The \"other\" category includes time spent on developing language-independent data such as a joint-venture domain knowledge base, pragmatic inference rules, and Extract data for template generation.",
        "We believe that the results do not indicate the potential of our system, since the system performance for both languages was still improving after five months of development.",
        "Much of the work we did resulted in long-term improvements to our overall text understanding capability, all of which will ensure a stronger base system for future applications.",
        "This implies that although the development cycle for data extraction system using a text understanding system may be slower in its current maturity stage, the potential for such a system is still unknown and represents a most promising avenue for development.",
        "We are particularly pleased with the success of our Japanese system: no other Japanese MUC-5 site is using the full understanding approach, but we did as well and our performance continues to improve.' Staff time was the major limiting factor.",
        "We needed more time to perform more testing and evaluation the 18-month Tipster evaluation, the highest JJV F-measure was about 40.",
        "using the scoring program, and to finely tune Extract (template generation) mapping rules.",
        "We discovered we were hampered by formatting errors, and in addition considerable information was \"understood\" by the system all the way through, but was not extracted by the template generator.",
        "Since the discourse module was new, it would have been helpful to have additional time to test and expand it.",
        "In addition, we needed more time to fill the OWNERSHIP, REVENUE, and TIME objects, which we simply did not output."
      ]
    },
    {
      "heading": "CONCLUSION",
      "text": [
        "Overall, the data-driven architecture in SOLOMON allowed for minimum work on processing modules when working on different languages and domains.",
        "We ported the system to Spanish in a week for the demonstration given, at the MUC-5 conference.",
        "Although we successfully acquired large amounts of domain data from domain texts in both languages, using both statistical methods and newly developed user-friendly knowledge acquisition tools, we recognize the need to move even more quickly to new domains and languages.",
        "We plan to continue our work on automatic acquisition of lexicons, knowledge bases, and links between them in multiple languages.",
        "Tuning performance of each module (e.g. parsing, discourse analysis) as well as the performance of the whole system to a particular task more rapidly is another research issue we identified.",
        "We believe that developing automatic evaluation and training algorithms for such automated module/system tuning is crucial to develop a data extraction system that produces optimal results."
      ]
    },
    {
      "heading": "ACKNOWLEDGEMENTS",
      "text": [
        "We are indebted to Rajeev Agarwal, Debbie Sanders, and Vera Zlatarski for their hard work and dedication in data development, module testing, and more.",
        "We also gratefully acknowledge the contributions of Scott Bennett, David Garfield, and Hatte Blejer to the MUC-5 process."
      ]
    },
    {
      "heading": "References",
      "text": [
        "[II Alfred V. Alio, Revi Sethi, and Jeffry D. Ullman.",
        "Compilers: Principles, Techiniques and Tools.",
        "Addison-Wesley, 1986.",
        "[2] Chinatsu Aone, Hatte Blejer, Sharon Flank, Douglas McKee, and Sandy Shinn.",
        "The Murasaki Project: Multilingual Natural Language Understanding.",
        "In Proceedings of the ARPA Human Language Technology Workshop, 1993.",
        "[3] Chinatsu Aone and Doug McKee.",
        "Acquiring Predicate-Argument Mapping Information from Multilingual Texts.",
        "In Acquisition of Lexical Knowledge from Text: Proceedings of a Workshop Sponsored by the Special Interest Group on the Lexicon of the Association for Computational Linguistics, 1993.",
        "[4] Chinatsu Aone and Doug McKee.",
        "Language-Independent Anaphora Resolution System for Understanding Multilingual Texts.",
        "In Proceedings of 31st Annual Meeting of the ACL, 1993.",
        "[5] Chinatsu Aone and Doug McKee.",
        "Three-Level Knowledge Representation of Predicate-Argument Mapping for Multilingual Lexicons.",
        "In AA AI Spring Symposium Working Notes on Building Lexicons for Machine Translation, 1993.",
        "[6] E. Black, S. Abney, D. Flickinger, C. Gdaniec, R. Grishman, P. Harrison, D. Hindle, R. Ingria, F. Jelinek, J. Klavans, M. Liberman, M. Marcus, S. Roukos, B. Santorini, and T. Strzalkowski.",
        "A Procedure for Quantitatively Comparing the Syntactic Coverage of English Grammars.",
        "In Proceedings of the Fourth DARPA Speech and Natural Language Workshop, 1991.",
        "[7] Joan Bresnan, editor.",
        "The Mental Representation of Grammatical Relations.",
        "MIT Press, 1982.",
        "[8] Charles F. Goldfarb.",
        "The SGML Handbook.",
        "Oxford, 1990.",
        "[9] Irene Heim.",
        "The Semantics of Definite and Indefinite Noun Phrases.",
        "PhD thesis, University of Massachusetts, 1982.",
        "[10] Doug McKee and John Maloney.",
        "Using Statistics Gained from Corpora in a Knowledge-Based NLP System.",
        "In Proceedings of The AAAI Workshop on Statistically-Based NLP Techniques, 1992.",
        "[II] Masaru Tornita.",
        "Efficient Parsing for Natural Language.",
        "Kluwer, Boston, 1986."
      ]
    },
    {
      "heading": "APPENDIX",
      "text": []
    },
    {
      "heading": "REL OF ENTITY2 TO ENTITY1: CHILD STATUS: CURRENT <ENTITY-0592-16> := NAME: Union Precision Casting CO ALIASES: \"Union Precision Casting\" TYPE: COMPANY ENTITY RELATIONSHIP: <ENTITY_RELATIONSHIP-0592-18> <ENTITY-0592-17> := NATIONALITY: Taiwan (COUNTRY) TYPE: COMPANY ENTITY RELATIONSHIP: <ENTITY_RELATIONSHIP-0592-18> <TIE_UP_RELATIONSHIP-0592-4> := TIE-UP STATUS: EXISTING ENTITY: <ENTITY-0592-22>",
      "text": [
        "<ENTITY-0592-21>"
      ]
    },
    {
      "heading": "ACTIVITY: <ACTIVITY-0592-9> <ENTITY-0592-21> := TYPE: COMPANY",
      "text": []
    }
  ]
}
