{
  "info": {
    "authors": [
      "Tsuneaki Kato"
    ],
    "book": "Applied Natural Language Processing Conference",
    "id": "acl-A94-1018",
    "title": "Yet Another Chart-Based Technique for Parsing Ill-Formed Input",
    "url": "https://aclweb.org/anthology/A94-1018",
    "year": 1994
  },
  "references": [
    "acl-C88-1075",
    "acl-C88-2118",
    "acl-J83-3001",
    "acl-J83-3003",
    "acl-P83-1019",
    "acl-P89-1013",
    "acl-P92-1006",
    "acl-P92-1008"
  ],
  "sections": [
    {
      "text": [
        "<C from S to E needs nothing> Cl --> ...Cs' C Cs2... where Csi is not empty (in the grammar) ------------------------------------- <C1 from * to E2 needs Cs!",
        "from * to S , Cs2 from E to E2> where if Cs2 is empty then E2 E else E2=*."
      ]
    },
    {
      "heading": "Fundamental rule:",
      "text": [
        "<C from S to E needs ... , [...Csl 1, Cl, Cs12...] from sl to e , ...> <C1 from S1 to El needs nothing> <C from S to E needs ... , Csi 1 from si to S1 ,Cs 12 from El to el,...> where si 5 S1 or si=*, El ei or e =*."
      ]
    },
    {
      "heading": "Simplification rule:",
      "text": [
        "<C from S to E needs from si_ 1 to s, [] from s to s, Csi+i from s to ei+1, •••> <C from S to E needs ..., Csi_i from si_1 to s, Csi+1 from s to , •••>",
        "The first phase of the process is invoked after the failure of left corner parsing.",
        "The bottom-up parsing leaves behind all complete constituents of every possible parse and unsatisfied active edges for all error points that are to the immediate right of sequences of constituents corresponding to the RHS.",
        "Since parsing proceeds left to right, an active edge is generated only when an error point exists to the right of the found constituents.",
        "In the first phase, bidirectional bottom-up parsing generates all generalized edges that represent unsatisfied expectations to the right and left of constituents.",
        "From some perspectives, the role this phase plays is similar to that of the covered bidirectional phase of the Picky parser (Magerman and Weir, 1992), though the method proposed herein does not employ stochastic information at all.",
        "This process can be described in three rules as shown in Figure 1.",
        "As can be seen, this is bidirectional bottom-up parsing that uses generalized edges as the data structure.",
        "For simplicity, the details for avoiding duplicated edge generation have been omitted.",
        "It is worth noting that after this process, the needs listed in each generalized edge indicate that the expected constituents did not exist, while, before this process, a need may exist just because an expectation has not been checked.",
        "The second phase finds out errors and corrects them.",
        "The location operation proceeds by refining a need into more precise one, and it starts from the global need that refers to the start symbol, S, from 0 to n, where n is the length of the given input.",
        "In the notion of generalized edges, that need can be represented as, <GOAL from 0 to n needs [S] from 0 to n> .",
        "The data structure reflecting global needs directly is used in this phase, so the left part of each generalized edge is redundant and can be omitted.",
        "In addition, two values, g and h, are introduced.",
        "g denotes how much cost has been expended for the recovery so far, and h is the estimation of how much cost will be needed to reach a solution.",
        "Cost involves solution plausibility; solutions with low plausibility have high costs.",
        "Thus, the data structure used in this phase is, <needs Cs!",
        "from s l to el, cs2 from s2 to e2, , can from sn to en, g, h> .",
        "Here, the number of errors corrected so far is taken as g, and the total number of categories in the needs is used as h. As mentioned above, since the needs listed indicate only the existence of errors as detected by the preceding process and to be refined, the value of h is always less than or equal to the number of the errors that must be corrected to get a solution.",
        "That is, the best first search using g+h as the cost functions is an admissible A* search (Rich and Knight, 1991).",
        "Needless to say, more sophisticated cost functions can also be used, in which, for example, the cost depends on the kind of error.",
        "The rules governing the second phase, which correspond to the search state transition operators in the context of search problems, are shown in Figure 2.",
        "The top-down rule and the refining rule locate errors and the other three rules are for correcting them.",
        "Most important is the refining rule, which tries to find out errors by using generalized edges in a top-down manner toward pre-terminals.",
        "This reduces the frequency of using the top-down rule and prevents an explosion in the number of alternatives.",
        "This process starts from <needs [S] from 0 to n, g: 0, h: 1> .",
        "To reach the following need means to get one solution.",
        "<needs nothing, g: h: 0>."
      ]
    },
    {
      "heading": "Top-down rule:",
      "text": [
        "<needs [Ci...Csl] from si to El, g: G, h: H> C1 ...RHS (in grammar) <needs [...RHS ...Csi] form si to El , g: G, h: H+(length of RHS)-l>"
      ]
    },
    {
      "heading": "Refining rule:",
      "text": [
        "<needs [...Csi 1, C1, Cs12...] from si to el , , g: G, h: H> <C1 from S to E needs Csi from S1 to El , , Csn from Sn to En > <needs Csii from si to S , Csi from Si to El , , Csn from Sn to En , Csi2 from E to el , g: G, h: H+E(length of Csn)-1> The result must be well-formed, that is sl S1 or sl–* or S1–* and so on."
      ]
    },
    {
      "heading": "Garbage rule:",
      "text": [
        "<needs [CI ...Csi] from si to ei , g: G, h: H> where C1 is a pre-terminal <Ci from S1 to Ei needs nothing> where sl 5 S1 <needs Csi from El to ei , g: G+(Si-s1), h: H-1>"
      ]
    },
    {
      "heading": "Unknown word rule:",
      "text": [
        "<needs [Ci...Csi] from si to ei , g: G, h: H> where Ci is a pre-terminal <needs Csi from si+1 to el, g: G+1, h: H-1> where the edge, <Ci from si to si+1 needs nothing> does not exist in the chart",
        "incidental.",
        "In reality, application of the top-down rule may be meaningful only when all the constituents listed in the RHS of a grammar rule contain errors.",
        "In every other case, generalized edges derived from that rule must have been generated already by the first phase.",
        "The application of the top-down rule can be restricted to cases involving unary rules, if one assumes at most one error may exist."
      ]
    },
    {
      "heading": "4 Preliminary Experiments",
      "text": [
        "In order to evaluate the technique described above, some preliminary experiments were conducted.",
        "The experiments employed the same framework as used by Mellish, and used a similar sized grammar, the small e-free CF-PSG for a fragment of English with 141 rules and 72 categories.",
        "Random sentences (10 for each length considered) were generated from the grammar, and then random occurrences of specific types of errors were introduced into these sentences.",
        "The errors considered were none, deletion of one word, adding one known or unknown word, and substituting one unknown or known word for one word of the sentence.",
        "The amount of work done by the parser was calculated using the concept of \"cycle\".",
        "The parser consumes one cycle for processing each edge.",
        "The results are shown in Table 1.",
        "The",
        "The need with the smallest value of g+h is processed first.",
        "If two needs have the same value of g+h, the one with the smaller h values dominates.",
        "This control strategy guarantees to find the solution with minimal cost first; that is, the solution with the minimum number of recoveries.",
        "Figure 3 shows an example of this technique in operation.",
        "(a) shows the sample grammar adopted, (b) shows the input to be processed, and (c) shows some of the edges left behind after the failure of the original bottom-up parsing.",
        "As shown in (d), the first phase generates several edges that indicate unsatisfied expectations to the left of found constituents.",
        "The second phase begins with need (e-1).",
        "Among the others, (e-2) and (e-3) are realized by applying the refining rule and the top-down rule, respectively.",
        "Since (e-2) has the smallest value of g+h , it takes precedence to be expanded.",
        "The refining rule processes (e-2) and generates (e-4) and (e-7), among others.",
        "The solution indicated by (e-6), which says that the fifth word of the input must be a preposition, is generated from (e-4).",
        "Another solution indicated by (e-9), which says that the fifth word of the input must be a conjunctive is derived from (e-7).",
        "That the top-down rule played no role in this example was not",
        "<needs nothing, g:1, h:0> ...(e-6) Unknown word rule, (e-5) The fifth word, \"an\", is hypothesized to be an unknown preposition (P) <needs [NP] from 3 to 7, g:0, h:1> ...(e-7) Refining rule, (e-2), (c-4) <needs [C] from 4 to 5, g:0, h:1> ...(e-8) Refining rule, (e-7), (d-2) <needs nothing, g:1, h:0> ...(e-9) Unknown word rule, (e-8) The fifth word, \"an\", hypothesized to be an unknown conjunctive (C) statistics in the table are described as follows.",
        "BU cycles is the number of cycles taken to exhaust the chart in the initial bottom-up parsing.",
        "BD cycles is the number of cycles required for bidirectional bottom-up parsing in the first phase.",
        "#solns is the number of different solutions and represents descriptions of possible errors.",
        "First/Last is the number of cycles required for error location and recovery to find the first / last solution.",
        "LR cycles is the number of cycles in the error locating and recovery phase required to exhaust all possibilities of sets of errors with the same penalty as the first solution.",
        "The preliminary results show that, for short sentences with one error, enumerating all possible minimum-penalty errors takes about 4 times as long as parsing the correct sentences.",
        "This is almost twice the speed of Mellish's strategy.",
        "As 75% of the process are occupied by the first bidirectional parsing operation, more cycles are needed to get the first solution with the proposed technique than with Mellish's strategy."
      ]
    },
    {
      "heading": "5 Discussion",
      "text": [
        "The second phase of the proposed technique is based on ordinary top-down parsing or tree search rather than chart parsing.",
        "As a consequence, some error location operations may be redundant, as Mellish pointed out.",
        "For example, suppose a new grammar rule, N ---> N PP is added to the grammar given in Figure 3.",
        "In that case, the following edge, located in the first phase, may cause a redundant error locating process, as the same search is triggered by (e-4).",
        "<N from 3 to * needs [PP] from 4 to *>.",
        "One way for avoiding such redundancies is to use a data structure that reflects just local needs.",
        "However, it is true that an effective error location process must take into account global needs.",
        "There is a tradeoff between simplicity and the avoidance of duplicated efforts.",
        "The technique proposed here employs a data structure that",
        "directly reflects the global needs.",
        "Mellish, on the other hand, utilized a structure that reflected just local needs and tried to put global needs into the heuristic function.",
        "The result, at least so far as confirmed by tests, was that pruning allowed the simple method to overcome the drawback of duplicated effort.",
        "Moreover, Mellish's dependency control mechanism, introduced to maintain the plausibility scores, means that edges are no longer local.",
        "In addition, it can be expected that a standard graph search strategy for avoiding duplicated search is applicable to the technique proposed.",
        "Theoretical investigation is needed to confirm how the number of grammar rules and the length of input will affect the amount of computation needed.",
        "Furthermore, the algorithm has to be extended in order to incorporate the high level knowledge that comes from semantics and pragmatics.",
        "Stochastic information such as statistics on category trigrams must be useful for effective control."
      ]
    }
  ]
}
