{
  "info": {
    "authors": [
      "Toru Hisamitsu",
      "Yoshihiko Nitta"
    ],
    "book": "International Conference on Computational Linguistics",
    "id": "acl-C94-1031",
    "title": "An Efficient Treatment of Japanese Verb Inflection for Morphological Analysis",
    "url": "https://aclweb.org/anthology/C94-1031",
    "year": 1994
  },
  "references": [],
  "sections": [
    {
      "heading": "AN EFFICIENT TREATMENT OF JAPANESE VERB INFLECTION FOR MORPHOLOGICAL ANALYSIS",
      "text": []
    },
    {
      "heading": "ABSTRACT",
      "text": [
        "Because of its simple appearance, Japanese verb inflection has never been treated seriously.",
        "In this paper we reconsider traditional lexical treatments of Japanese verb inflection, and propose a new treatment of verb inflection which uses newly-devised segmenting units.",
        "We show that our proposed treatment minimizes the number of lexical entries and avoids useless segmentation.",
        "It requires 20 to 40% less chart parsing computation and it is also suitable for error correction in optical character readers."
      ]
    },
    {
      "heading": "Introduction",
      "text": [
        "In this paper we focus on lexical entries for coping with Japanese verb inflection.",
        "The problem of treating verb inflection comes from the nature of written Japanese, in which word boundaries are not usually indicated explicitly.",
        "The morphological analyzer must therefore check for the existence of a verb and its inflection at each position in an input character string.",
        "As a consequence, an awkward treatment of verb inflection may result unacceptably low computational efficiency.",
        "Japanese verb inflection seems to be quite simple.",
        "Therefore, it has never been a central subject of natural language processing (NLP) studies.",
        "It is also because, in the early stages of Japanese NLP, the most time-consuming process of the Japanese morphological analysis (JMA) was found to be accessing the dictionary stored in a secondary memory.",
        "Therefore greater effort was put into designing the dictionary data structure and methods for quick access.",
        "The situation, however, has changed.",
        "Highly efficient data structures based on the TRIE structure seem to have finally solved the data structure problems (for instance, Morimoto and Aoe, 1993), and the access problem is also being resolved by the emergence of cheap main memory on which the dictionary can be stored directly, and a dictionary-accessing chip that can access the dictionary thousands of times faster (Fukushima, 1991).",
        "As a result, problem of treating Japanese verb inflection is becoming more important.",
        "Although phonological description of Japanese verb inflection is highly simple, it cannot be applied to JMA directly.",
        "Because each Japanese hiragana phonogram basically corresponds to a consonant-vowel pair, not to a phoneme.",
        "On the other hand, traditional school grammar gives a description based on the ordinary Japanese writing system, and has thus been widely used in JMA.",
        "However it is neither as rational as the phonological description nor is it the most efficient from a computational viewpoint.",
        "We reconsider lexical entries for verb inflection and propose a new method for segmenting verbal complexes.",
        "Though our method is based on the ordinary Japanese writing system, it has various advantages over existing ones: 1) it minimizes the number of lexical entries together with avoiding useless segmentation; 2) it requires 20 to 40% less chart parsing computation, where the parser is based on dynamic programming and suitable for robust analysis; 3) it is also suitable for error correction in OCRs; 4) it requires a smaller incident matrix than other treatments, making the morphological analyzer easier to construct and maintain.",
        "Section 1 overviews descriptions of Japanese verb inflection in terms of phonology and in terms of traditional school grammar; Section 2 reviews three different treatments of verb inflection in NLP, which are based on the two descriptions in section 1.",
        "Section 3 introduces our proposed treatment, and section 4 shows the advantages of our treatment from several aspects, including a quantitative comparison of the computational efficiency of a chart parser."
      ]
    },
    {
      "heading": "1 Descriptions of Japanese Verb Inflection",
      "text": [
        "Japanese verbs can be roughly classified into three groups as shown in Table 1.",
        "The number of regular verbs amounts to several thousand (our dictionary for JMA has about 3000 regular verbs).",
        "Regular verbs are classified into two groups: consonant-stem verbs whose stems end with consonants, and vowel-stem verbs whose stems end with vowels.",
        "Sateen-verbs are also classified into two groups: verbal nouns, whose stems can be used as nouns, and the others.",
        "This is the largest of the three groups (our dictionary has about 6000 verbs in class II).",
        "The number of irregular verbs is negligibly small.",
        "group Examples regular consonant tob-u (to fly), kak-u (to write), verbs stem verbs kes-u (to extinguish), ... vowel-stem mi-ru (to see), ki-ru (to wear), verbs sake-ru (to avoid), ... salien_ verbal nouns kenkyuu-suru (to study), verbs kopii-suru (to copy), .... others yuttari-suru (to relax), guttari-suru (to be exhausted),.. irregular verbs kuru (to come), sum (to do)"
      ]
    },
    {
      "heading": "Tablet Classification of Verbs",
      "text": [
        "In terms of inflection processing, Sahen-verbs are the easiest of the three: their stems precede the special verb \"s-uru\" (to do), and inflectional affixes are attached to its stern 's' .",
        "Thus their inflection can be reduced to the inflection of \"s-uru\" and we can treat them by registering all inflectional forms in the dictionary.",
        "From the same reason irregular verbs are also easy to treat.",
        "Thus the central problem is treating the inflection of regular verbs.",
        "In the following, we focus on the treatment of these verbs.",
        "First of all, we give two descriptions of the inflection of Japanese regular verbs.",
        "One is based on phonology, the other on the traditional school grammar."
      ]
    },
    {
      "heading": "1.1 Phonological Description",
      "text": [
        "In Japanese, morphemes which correspond to \"Past / Non-past\", \"Causative\", \"Passive\", and so on directly follow a verbal stem as inflectional affixes.",
        "The first study of phonological analysis of Japanese verb inflection was done by an American linguist B. Bloch (Bloch, 1946).",
        "Unlike traditional school grammar, phonological description is based purely on phonemes, not on Japanese phonograms.",
        "A standard phonological description of Japanese regular verbs is shown in"
      ]
    },
    {
      "heading": "Verb Inflection (Phonological Description)",
      "text": [
        "For example, the inflection of a verb l'Is-u\" (kes-u: to extinguish) is as follows:",
        "consonants { b, g, k, n, r, s, t, w} as their stem endings.",
        "According to phonological transformation, they are classified into six groups (b, m, n), (k), (g), {r, t), } and (s).",
        "For instance, if x E (b, m, n}, then the following transformation occurs:",
        "where '_x' stands for a verbal stem whose ending is 'x', 'vs' for the boundary of the verbal stem and for the boundary of the inflected verb respectively.",
        "This transformation is called Onbin.",
        "For example, yon + -ita ----> yonda.",
        "(to read) (Past)"
      ]
    },
    {
      "heading": "1.2 Traditional School Grammar",
      "text": [
        "As stated in the introduction, the phonological analysis of the previous subsection cannot be directly applied to JMA.",
        "Because each hiragana",
        "corresponds to a consonant-vowel pair, some phonological morphemes, such as 'and and ase' do not appear in character strings.",
        "For example, in the character string \"'ill (kesanai: not to extinguish), the stern 'kes' and the negative affix 'am' are glued together to form \"il'W\"s(kesana)\".",
        "This is why the school grammar \" description is a little bit complex.",
        "The school grammar considers the indicative non-past form of a verb to be the \"basic form\".",
        "Verbs arc \"transformed\" when inflectional affixes are attached.",
        "This transformation is called Katsuyou, and is illustrated in Table 3."
      ]
    },
    {
      "heading": "Verbal Inflection (School Grammar)",
      "text": [
        "This time the Katsuyou of \"Mt\" is described as follows:",
        "The underlined hiragana above are called Katsuyougobi (inflectional endings), and the inflected forms are called Katsuyoukei.",
        "Corresponding to the Onbin transformation stated in subsection 1.1, an additional transformation is needed.",
        "For example,",
        "transformation t'atr ----> ----> Although the description above lacks uniformity and seems to be far more complicated than phonological description, traditional JMAs have followed this description."
      ]
    },
    {
      "heading": "2 Existing Approaches",
      "text": [
        "In this section, we sketch some methods of inflection analysis based on the two descriptions stated in the previous section."
      ]
    },
    {
      "heading": "2.1 Phonological Method",
      "text": [
        "To use phonological description for verb inflection analysis, one first needs to convert the hiragana in an input character string into a string of Roman characters (romaji) corresponding to the Japanese phonemes.",
        "In this way, morphemes such as 'ana' and 'ase' become observable in the character string.",
        "Lexical entries for the inflection analysis of regular verbs are shown in Table 4."
      ]
    },
    {
      "heading": "Examples of Lexical Entries (Phonological Method)",
      "text": [
        "For example, 71 h, (kesanakatta: did not extinguish) is analyzed as follows: ---> nsanakatta ---> ills 1 ana 1 katta kes: to extinguish / ana: Neg.",
        "/ katta: Past We will refer to this method with the abbreviation PM in the rest of this paper.",
        "In the case of our dictionary, which includes 2807 regular verbs, an extra 1598 allomorphs (morpheme that are transformed from their basic form) are registered to cope with Onbin transformations of regular verbs.",
        "The disadvantage of PM is that the target character strings must be lengthened as they are analyzed.",
        "In particular, character sequences including no kanji, which must be treated in kana-kanji conversion, are doubly lengthened.",
        "To make matters worse, for all the vowels a, i, u,",
        "e, and o, there are lexical entries with a single vowel.",
        "These facts deteriorate the computational efficiency.",
        "Thus this framework is suitable for generation (Kamioka, Tsuchiya and Anzai, 1989) but not for JMA."
      ]
    },
    {
      "heading": "2.2 School Grammar Method",
      "text": [
        "Almost all existing systems employ inflectional analysis based on the school grammar.",
        "In this framework kana-to-romaji conversion is not necessary.",
        "There arc two different lexical treatments for allomorphs."
      ]
    },
    {
      "heading": "2.2.1 Allomorph Expansion",
      "text": [
        "The simplest method is to register all Katsuyoukeis as lexical entries (see Table 5).",
        "For example, allomorphs of \"illft(kes-u: to extinguish)\", '411 , 1, ) are all registered.",
        "Using these lexical entries, the example in subsection 2.1 is analyzed as follows: /,‘P t: (kesanakatta) kesa : to extinguish / nakat : Neg.",
        "/ to : Past This method is referred to as SG-I in the rest of this paper."
      ]
    },
    {
      "heading": "Examples of Lexical Entries (SG-1)",
      "text": [
        "If SG-I is employed, an additional 11652 allomorphs requires to be registered in our dictionary to cope with Katsuyou transformation of regular verbs.",
        "This number of allomorphs is far larger than the true number of verbs: and explains why this method is not usually used in existing systems, especially those developed when memories were much more expensive.",
        "'The most popular treatment of Katsuyou involves separating inflectional endings and registering them as lexical entries (see Table 6).",
        "Since the number of inflectional endings of regular verbs is 76, the number of lexical entries is far smaller than in PM or SG-I.",
        "For this reason, this method has been considered to be the best one.",
        "This time the same example is analyzed as follows:",
        "-1r.",
        "t: / •ts -/), o Itz kesanakatta ke[si: to extinguish / sa: [ainakat: Neg.",
        "/ Past",
        "We will refer this method as SG-II in the rest of this paper."
      ]
    },
    {
      "heading": "Examples of Lexical Entries (SG-II)",
      "text": [
        "However, analysis by SG-II requires one more segmentation than PM and SG-I.",
        "Worse still, the segment / N has no meaning, thus this segmentation is useless.",
        "Since memories have become much lower in price, this problem cannot be disregarded."
      ]
    },
    {
      "heading": "3 Proposed Lexical Treatment of Japanese Verb inflection",
      "text": [
        "In the previous section we described three different lexical treatments.",
        "Here we summarize their advantages and problems:",
        "1) PM is the simplest but is not directly applicable to ordinary written character strings.",
        "2) SG-I realizes the minimum segmentation but requires a large number of allomorphs amounting to several times the original number of regular verbs.",
        "3) SG-II requires the smallest number of lexical entries, but causes useless segmentations.",
        "Only our proposed lexical treatment can solve these problems.",
        "Let us explain our approach using the same example.",
        "In PM, the character string \" t.c o tc (kesanakatta)\" is analyzed as \"Mslanalkatta\" , where the ending consonant 's' of the stem \"Vis\" and the head vowel 'a of the affix 'and come from the phonogram ' t(sa)'.",
        "Here recall that neither 's' nor 'a' itself has a corresponding phonogram in the original character string.",
        "The school grammar description gives an observable lexical entry WS ' by concatenating the head vowel 'a' of 'and to the tail of 'ills'.",
        "It may be linguistically appropriate, but computationally not; there can be an alternative.",
        "We attach the consonant 's' to the head of anal and generate an entry ' (sana =s+ana)' as a kind of an allomorph of 'and.",
        "At the same time, the stem \"di' is marked as a morpheme which can only be followed by \"s-attached inflectional affixes\", that is, -Lctr (s+ase: Causative), (s+are: Passive), is (s+ana: Negative,....}.",
        "Other lexical entries are generated in the same manner (see Table 7)."
      ]
    },
    {
      "heading": "Examples of Lexical Entries (Proposed Method)",
      "text": [
        "This time the previous example is analyzed as follows:",
        "ke(s): to extinguish / sana: Neg.",
        "/ katta: Past It is obvious that this segmentation gives exactly the same semantic information as the other methods.",
        "This time the number of \"allomorphs\" is only 125, which is comparable to one of SG-II.",
        "On the other hand, the number of segments is as same as that of S G-I in this example.",
        "In the next section we discuss the advantages of our proposed method."
      ]
    },
    {
      "heading": "4 Advantages of Proposed Lexical Treatment",
      "text": []
    },
    {
      "heading": "4.1 The Number of Allomorphs",
      "text": [
        "As stated in the previous sections, SG-I and our proposed method require almost the same number of allomorphs, which is far smaller than that of the other methods."
      ]
    },
    {
      "heading": "4.2 Quantitative Comparison of Parsing Efficiency",
      "text": [
        "In order to compare the computational efficiency of each method, we used a chart parsing algorithm (Hisamitsu and Nitta, 1991) and three dictionaries based on SG-I, SG-II, and the proposed method.",
        "Here we only sketch the outline of the algorithm (See Fig.1).",
        "Here s denotes an input string a1 – an.",
        "A candidate-word lattice (N41, • • •, M } is used for recording candidate morphemes, where Mi records the morphemes extracted at position j.",
        "Partial path lists (T i,•••, Try } are used for recording the fragments of partial solutions, where T. contains fragments of partial solutions which reach the j-th position in s. An element in Tk (1 has the form (m, C, {<mi,Ci>, • • <mk, Ck>} ) where m is the last morpheme of partial solutions ap • ak, C is their common cost, and <mi, Ci> is the preceding morpheme of m at a.• (<m C ••• <In C >} is j, 1' 1 \" k' k regarded as a \"pointer\" for tracing solutions backward.",
        "The elements of Tk are calculated using Ti and Mi+i, where 1 n-1, and jSks n. Once the Partial path lists (T 1, • • •, T0) is constructed, the solutions are extracted by depth",
        "first backtracking to trace pointers backward.",
        "To enable a quantitative comparison, we use the following three measures, which reflect the efficiency of chart parsing and are independent of implementing variations:",
        "A) Total number of morphemes contained in morpheme lists {M Mn } .",
        "B) Total number of tests which check for the connectability between partial-solution fragments in Ti and morphemes in Mj+1.",
        "C) Total number of elements contained in partial path lists (T1,..., Tn } .",
        "Figure 2 compares the three methods.",
        "The comparison was made using 100 sentences taken from Nikkei Shinhun, which contain a total of 5286 characters.",
        "The dictionary contained about 60000 words.",
        "Our proposed method is far more efficient than the most popular method SG-II, and its efficiency is comparable to that of SG-I.",
        "4.3 Application to OCR Error Correction Recently, morphological analysis has been applied more extensively to various systems, especially to error correction in OCRs (optical character readers).",
        "In general, a character recognition module outputs a sequence of lists which include candidate characters at each position in the pattern sequence.",
        "Each candidate character is given a positive confidence ratio (see Fig.3).",
        "We call the sequence of lists \"candidate character lattice\".",
        "Note that the character string of the top candidate characters, which is the final output of a hare character recognizer, is not necessarily the correct sentence.",
        "To correct the errors, we use two main processes: 1) constructing a candidate words lattice by using the candidate character lattice and a dictionary; 2) extracting plausible word sequences from the candidate words lattice.",
        "Generally process 1) is time-consuming, because we need to find potential word candidates from the combination of candidate characters at each position.",
        "To avoid combinatorial explosion, a skillful method has been widely used in error correction (Takao and Nishio, 1989): at each position, first extract all words whose first character matches the top candidate character at the position, secondly compare those words with the candidate character lattice.",
        "Example of Candidate Character Lattice For this method to be effective, the lexical entries should be as long as possible, because a longer entry is easier to recover when one or two characters arc mis-recognized.",
        "There should also be as few entries as possible whose first characters coincide.",
        "In terms of the former requirement, our proposed method is obviously better than S G - II.",
        "Although SG I results in the longest lexical entries, it is the worst in terms of the latter requirement because each verb has basically six allomorphs in the dictionary, and the first characters of these words are inevitably the same.",
        "For this reason, our experiments have shown that error correction based on the SG-I dictionary is 3.6 times more time-consuming than error correction based on the proposed dictionary.",
        "Thus our proposed method is the most suitable for this purpose."
      ]
    },
    {
      "heading": "4.4 Other Advantages",
      "text": [
        "Compared with SG-I and SG-II, our proposed method reduces the size of the incident matrix, because, using our lexical entries makes it",
        "unnecessary to check for connection between a Katsuyougobi and various inflectional affixes.",
        "4.4.2 The Number of Free Parameters in"
      ]
    },
    {
      "heading": "Statistical Heuristics",
      "text": [
        "In obtaining a (simple) Markov model, one may notice a major difference between the proposed method and SG-I.",
        "Figure 4 (a) illustrates the linguistically possible incidence between our lexical entries including a verbal stem v. To construct a probabilistic likelihood function, one needs to estimate all of the free parameters pwv, where pwv denotes the transition probability from word w to v. Since a verbal stem can succeed almost all grammatical categories, the number of parameters {pwv} (= N(v)) is almost equal to the number of all categories.",
        "v: Stem of a Verb vi: Inflected Form of V",
        "With SG-I, the number of parameters {PWVJ' PWV2\"•} is about seven times as large as N(v), where 'vi' denotes a Katsuyoukei of the verb v (Fig.4 (b)).",
        "In other words, the number of free parameters is inevitably increased by using S G-I."
      ]
    },
    {
      "heading": "5 Further Study",
      "text": [
        "In subsection 4.2, we used a standard chart parser based on dynamic programming for the comparison.",
        "While the parser itself is robust and efficient, there are several kinds of parsing methods.",
        "For example, the longest matching method is popular.",
        "Actually, our lexical treatment is also effective for such a parsing strategy.",
        "We will also make an experimental comparison based on various parsing methods."
      ]
    },
    {
      "heading": "6 Conclusion",
      "text": [
        "In this paper we reconsidered lexical entries for verb inflection and proposed a new way of segmenting verbal complexes that has various advantages over existing methods: 1) it minimizes the number of lexical entries and avoids useless segmentation; 2) it requires 20 to 40% less computation than standard chart parsing; 3) it is suitable for error correction in OCRs; 4) it requires a smaller incident matrix than other treatments, thus making it easier to construct and maintain the morphological analyzer; 5) it is the most suitable for obtaining statistical heuristics because it can intrinsically reduce the number of free parameters."
      ]
    }
  ]
}
