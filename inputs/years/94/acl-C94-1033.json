{
  "info": {
    "authors": [
      "Hiroshi Maruyama"
    ],
    "book": "International Conference on Computational Linguistics",
    "id": "acl-C94-1033",
    "title": "Backtracking-Free Dictionary Access Method for Japanese Morphological Analysis",
    "url": "https://aclweb.org/anthology/C94-1033",
    "year": 1994
  },
  "references": [],
  "sections": [
    {
      "text": [
        "node accesses dominates the performance of the overall system.",
        "3 Constructing TRW with fail pointers A TRIE index with fail pointers is created in the following two steps: 1.",
        "Create a 'Inn.",
        "; index, and"
      ]
    },
    {
      "heading": "2.5 Other Cosiderations",
      "text": [
        "Theoretically there is a possibility of pruning dictionary lookup by using the state set at position n. For example, if no noun can follow any of the states in the current state set, there is no need to look up nouns.",
        "One way to do this pruning is to associate with each node a hit vector representing the set of all parts of speech of some word beyond this node.",
        "If the intersection of the expected set of parts of speeche and the possibilities beyond this node is empty, the expansion of this node can be pruned.",
        "In general, however, almost every character position predicts most of the parts of speech.",
        "Thus, it is common practice in Japanese morphological analysis to look up every possible prefix at every character position.",
        "Hidaka et al.",
        "(1984) used a modified I3-tree instead of a simple TiuE.",
        "Altough a 11-tree has much less nodes than a TRW and thus the number of secondary storage accesses can be significantly reduced, it still backtracks to the next character position and duplicate matching is inevitable.",
        "2.",
        "Calculate a fail pointer of each node in the TIUE.",
        "Since Step I is well known, we will describe only Step 2 here.",
        "For each node TL, Step 2 gives the value Jail(i).",
        "In the following algorithm, f orward(n,c) denotes the child node of the node in whose associated character is C. If there is no such node, we define f orward(n,c) = nil.",
        "Root is the root node of the TRIE.",
        "2-1 f ail(Root) 4 Root 2-2 for each node 71. of depth I, fail(n) 4 Root 2-3 for each depth d = I, 2, ..., 2-3-1 for each node in with depth d, 2-3- II for each child node no of T1 (where",
        "Since the Japanese language does not have explicit word boundaries, dictionary lookup should be done, in principle, for all possible sub strings in an input sentence.",
        "Thus, Japanese morphological analysis involves a large number of dictionary accesses.",
        "The standard technique for handling this problem is to use the TRIE structure to find all the words that begin at a given position in a sentence (Morimoto and Aoe 1993).",
        "This process is executed for every character position in the sentence; that is, after looking up all the words beginning at position n, the program looks up all the words beginning at position n + 1, and so on.",
        "Therefore, some characters may be scanned more than once for different starting positions.",
        "This paper describes an attempt to minimize this 'backtracking' by using an idea similar to one proposed by Aho and Corasick (Abe 1990) for multiple-keyword string matching.",
        "When used with a 70,491-word dictionary that we developed for Japanese morphological analysis, our method reduced the number of dictionary accesses by 25%.",
        "The next section briefly describes the problem and our basic idea for handling it.",
        "The detailed algorithm is given in Section 3 and Section 4, followed by the results of an experiment in Section 5."
      ]
    },
    {
      "heading": "2 JapaneseMorphological",
      "text": []
    },
    {
      "heading": "Analysis 2.1 Grammar",
      "text": [
        "A Japanese morphological analyzer (hereafter called the JMA) takes an input sentence and segments it into words and phrases, attaching a part-of-speech code to each word at the same time.",
        "Figure 1 shows a sample input and the output of our JMA.",
        "The grammaticality of a sequence of Japanese words is mainly determined by looking at two consecutive words at a time (that is, by looking at two-word windows).",
        "Therefore, Japanese morphological analysis is normally done by using a Regular Grammar (e.g., Maruyama and Ogino 1994).",
        "Our JMA grammar rules have the following general form: statel\"word\" [linguistic-features] state2 cost= cost.",
        "Each grammar rule has a heuristic cost, and the parse with the minimum cost will be selected as the most plausible morphological reading of the input sentence.",
        "A part of our actual gram208 If the node corresponds to the end of some word, we record the length I of the word in the node.",
        "For example, at the node that corresponds to the end of the word (mainframe)\", (mainframe)\", / 5 and I = 3 are recorded because it is the end of both of the words \"-A-m-i-not (mainframe, / = 5)\" and \"al'n-tt (computer, 1 -= 3).\" 3 Figure 6 shows the complete TRIE with the fail pointers."
      ]
    },
    {
      "heading": "4 Dictionary access",
      "text": [
        "The algorithm for consulting the dictionary is quite simple:",
        "where ci is the character at position i."
      ]
    },
    {
      "heading": "5 Experimental results",
      "text": [
        "We applied the TRIE with fail pointers to Our 70,491-word dictionary for Japanese morphological analysis (in which the average word length is 2.8 characters) and compared it with a conventional TR,TE-based system, using two sets of data: newspapers articles (44,113 characters) and computer manuals (235,104 characters).",
        "The results are shown in Table 1.",
        "The tables show both the number of node accesses and the actual CPU time.",
        "For the newspaper articles, our method (marked as TRIE w/ FP) had 25% fewer node accesses than than the 3 This information is redundant, because one can look up every possible word by following the fail pointer.",
        "However, if the nodes are in secondary storage, it is worth having the length information within the node to minimize the disk access.",
        "traditional TRW and was 27% faster in CPU time.",
        "The CPU time was measured with all the nodes in the main memory.",
        "For the computer manuals, the reduction rate was a little larger.",
        "This is attributable to the fact that computer manuals tend to contain longer, more technical terms than newspaper articles.",
        "Our method is more effective if there are a large number of long words in a text."
      ]
    },
    {
      "heading": "6 Conclusion",
      "text": [
        "We have proposed a new method of dictionary lookup for Japanese morphological analysis.",
        "The idea is quite simple and easy to implement with a very small amount of overhead (a fail pointer and an array of length 1 to each node).",
        "For large terminology dictionaries (medical, chemical, and so on), this method will greatly reduce the overhead related to dictionary access, which dominates the efficiency of practical Japanese morphological analyzers.",
        "Fast Japanese morphological analyzers will be crucial to the success of statistically-based language analysis in the near future (Maruyama et al.",
        "1993)."
      ]
    },
    {
      "heading": "References",
      "text": [
        "1.",
        "Aho, A. V., 1990: \"Algorithms for Finding Patterns in Strings,\" in Leeuwen, J.V.",
        "ed., Handbook of Theoretical Computer Science, Volume A - Algorithms and Complexity, pp.",
        "273-278, Elsevier.",
        "2.",
        "Ilidaka, T., Yoshida, S., and Inanaga, 1984: \"Extended 113-Tree and Its Applications to Japanese Word Dictionaries,\" (In Japanese) Trans.",
        "of HiliCE, Vol.",
        "J67-D, No.",
        "4.",
        "3.",
        "Hisamitsu, T. and Nitta, Y., 1991: \"A Uniform Treatment of Heuristic Methods for Morphological Analysis of Written",
        "mar is shown in Figure 2.",
        "Currently our grammar has about 4,300 rules and 400 nonterminal symbols."
      ]
    },
    {
      "heading": "2.2 Dictionary Lookup",
      "text": [
        "While the function words (particles, auxiliary verbs, and so on, totaling several hundred) are encoded in the grammar rules, the content words (nouns, verbs, and so on) are stored in a separate dictionary.",
        "Since content words may appear at any position in the input sentence, dictionary access is tried from all the positions n. For example, in the sentence fragment in Figure 3, M (large)\" and \"-)C NI a '17): (mainframe)\" are the results of dictionary access at position For simplicity, we assume that the dictionary contains only the following words: \"ik T. (large),\" \"--..k...fflana (mainframe),\" \"m-na (computer)\", \"m-natasm (computing facility),\" and \"tAll (facility).\" I"
      ]
    },
    {
      "heading": "2.3 Using TRIE",
      "text": [
        "The most common method for dictionary lookup is to use an index structure called TRW; (see Figure 4).",
        "The dictionary lookup begins with the root node.",
        "The hatched nodes represent the terminal nodes that correspond to dictionary entries.",
        "At position I in the sentence above, two words, \"MO.",
        "(large)\" and \" -.",
        ")(NIa'n1 (mainframe),\" are found.",
        "Then, the starting position is advanced to the second character in the text and the dictionary lookup is tried again.",
        "In this case, no word is found, because there are no words that begins 'Actual dictionaries also contain \"A (big)\" (type),\" -Kr (measure),\" In): (compute),\" \"t): (order),\" \"itt (machine),\" V. (establish),\" and \"Viii (prepare).\" with \"NI\" in the dictionary.",
        "The starting position is then set to 3 and tried again, and this time the words \"In-t1 (computer)\" and \" 1IR.V1i (computing facility)\" are obtained.",
        "2 The problem here is that, even though we know that there is \")C.N1aMilt (mainframe)\" at position I, we look up \"lit niii/ (computer)\" again.",
        "Since \"41-.1att (computer)\" is a substring of \"ikwraa (mainframe),\" we know that the word (computer)\" exists at position 3 as soon as we find \"KN.Iiii-na (mainframe)\" at position I.",
        "Therefore, going back to the root node at position 3 and trying matching all over again means duplicating our efforts unnecessarily."
      ]
    },
    {
      "heading": "2.4 Eliminating Backtracking",
      "text": []
    }
  ]
}
