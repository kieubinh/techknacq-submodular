{
  "info": {
    "authors": [
      "Mats Wiren"
    ],
    "book": "International Conference on Computational Linguistics",
    "id": "acl-C94-1076",
    "title": "Minimal Change and Bounded Incremental Parsing",
    "url": "https://aclweb.org/anthology/C94-1076",
    "year": 1994
  },
  "references": [
    "acl-E89-1033"
  ],
  "sections": [
    {
      "heading": "Abstract",
      "text": [
        "Ideally, the time that an incremental algorithm uses to process a change should be a function of the size of the change rather than, say, the size of the entire current input.",
        "Based on a formalization of \"the set of things changed\" by an incremental modification, this paper investigates how and to what extent it is possible to give such a guarantee for a chart-based parsing framework and discusses the general utility of a minimality notion in incremental processing.'"
      ]
    },
    {
      "heading": "1 Introduction",
      "text": []
    },
    {
      "heading": "1.1 Background",
      "text": [
        "Natural-language computing has traditionally been understood as a \"batch-mode\" or \"once-only\" process, in which a problem instance P (say, a text) is mapped as a whole to a solution S (such as an analysis of the text).",
        "However, in highly interactive and real-time applications – for example, grammar checking, structure editing and on-line translation – what is required is efficient processing of a sequence of small changes of a text.",
        "Exhaustive recomputation is then not a feasible alternative.",
        "Rather, to avoid as much recomputation as possible, each update cycle must reuse those parts of the previous solution that are still valid.",
        "We say that an algorithm is incremental if it uses information from an old solution in computing the new solution.",
        "The problem of incremental processing can be stated as follows, using a notation similar to that of Alpern et al.",
        "[1]: Assume given a problem instance P (a representation of the current input), a solution S (the current output), and a modification Ap to P.2 The modification results in a new problem instance P' P (11) A p , where ED is a composition operator.",
        "The task of an in-would like to thank Ralph Riinnquist as well as Gregor Erbach and other colleagues ill Saarbriicken for discussions on the material presented here, Peter Fri tzson for originally alerting my attention to Ramalingam and Reps' paper, and the anony-'nous referees.",
        "This research has been funded by the German Science Foundation (DFG) through the Sonderforsehungsbereich 314, project N3 (Bill)).",
        "2A terminological note: we use \"input change\" and \"modification\" as well as \"output change and \"update\" synonymously.",
        "crernental algorithm is then to produce an update As in the old solution such that S m As is a solution to PTA], (see figure 1).",
        "At this point, nothing is stipulated about the amount of information in S that should be reused in S'.",
        "To show properties such as correctness and complexity of incremental algorithms, it is necessary to establish a formal measure of \"the set of things changed\".",
        "This measure should capture the minimal change resulting from a modification and, moreover, should be independent of any particular algorithms for incremental update.",
        "One way of achieving this is to compare the results obtained by batch-mode processing of the inputs before and after the change, respectively (Wiriln and Riinnquist [15, 17]): By forming the \"difference\" between the batch-mode solutions S and S' obtained before and after a modification Al to P, we obtain a parameter which captures the minimal change in a way which is indeed independent of the incremental update.",
        "Given that As .in corresponds precisely to what any sound and complete incremental algorithm 11171Si do, it can be used as a basis for correctness proofs for such algorithms (given that the batch-mode algo-ritlini is correct).",
        "Furthermore, Asthin can be used as a basis of complexity analyses: Ideally, each update cycle of an incremental algorithm should expend an amount of work which is a polynomial function of the size of the change, rather than, say, the size of the entire current input.",
        "However, making this notion precise in a way which is independent of particular incremental algorithms is not As",
        "always straightforward.",
        "Two early approaches along these lines are Goodwin [3, 4] (reason maintenance) and Reps [11] (language-based editing).",
        "More recently, Alpern et al.",
        "[1] and Ramalingam and Reps [9, 10] have provided a framework for analysing incremental algorithms, in which the basic measure used is the sum of the sizes of the changes in the input and output.",
        "This framework assumes that the modification of the input can be carried out in 0(1Apl) time, where the generic notation IXl is used for the size of X.",
        "Furthermore, it assumes that IOSminI denotes the minimal lAsl such that S As solves P (I) Alpern et al.",
        "then define",
        "as the intrinsic size of a change.",
        "The choice of 6 is motivated as follows: I6,p I, the size of the modification, is in itself too crude a measure, since a small change in problem instance may cause a large change in solution or vice versa.",
        "lAs,„thi I is then chosen as a measure of the size of the change in the solution, since the time for updating the solution can be no less than this.",
        "The b measure thus makes it possible to capture how well a particular algorithm performs relative to the amount of work that must be performed in response to a change.",
        "An incremental algorithm is said to be hounded if it can process any change in time 0(f(6)), that is, in time depending only on b.",
        "Intuitively, this means that it only processes the \"region\" where the input or output changes.",
        "Algorithms of this kind can then be classified according to their respective degrees of boundedness (see Ramalingam and Reps [10, section 5]).",
        "For example, an algorithm which is linear in 6 is asymptotically optimal.",
        "Furthermore, an incremental algorithm is said to be unbounded if the time it takes to update the solution can be arbitrarily large for a given S. It might seem that what has been discussed so far has little relevance to natural-language processing, where incrementality is typically understood as the piecemeal assembly of an analysis during a single left-to-right,' pass through a text or a spoken utterance.",
        "In particular, incrementality is often used as a synonym for interleaved approaches, in which syntax and semantics work in parallel such that each word or phrase is given an interpretation immediately upon being recognized (see, for example, Mellish [7] and Haddock [5]).",
        "However, the two views are closely related: The \"leftto-right view\" is an idealized, psycholinguistically motivated special case, in which the only kind of change allowed is addition of new material at the end of the current input, resulting in piecemeal expansion of the analysis.",
        "Moreover, the interleaving is just a consequence of the fact that every piece of new input must, in some sense, be fully analysed in order to he integrated with the old analysis.",
        "To distinguish this special case from the general case, in which arbitrary changes are allowed, Wiren [15] refers to them as left-to-right WO incrementality and"
      ]
    },
    {
      "heading": "3 Strictly speaking front-to-back or beginning-to-end.",
      "text": [
        "full incrementality, respectively.",
        "The former case corresponds to on-line analysis – that each prefix of a string is parsed (interpreted) before any of the input beyond that prefix is read (Harrison [6, page 433]).",
        "The latter case has long been studied in interactive language-based programming environments (for example, Ghezzi and Mandrioli [2]), whereas the only previous such work that we are aware of in the context of natural-language processing is Wiren and ROnnquist [14, 15, 16, 17]."
      ]
    },
    {
      "heading": "1.2 The Problem",
      "text": [
        "The aim of this paper is to begin to adapt and apply the notion of bounded incremental computation to natural-language parsing, using a method for establishing minimal change previously introduced by Wiren and 116nnquist [15, 17].",
        "To this end, the paper shows how the 6 parameter can be defined in a fully incremental, chart-based parsing framework, briefly describes a previous, unbounded algorithm, and then shows how a polynomially bounded algorithm can be obtained."
      ]
    },
    {
      "heading": "2 Batch-Mode Chart Parsing",
      "text": [
        "An incremental problem can be defined by specifying its batch-mode version and the set of allowable modifications.",
        "We thus begin by specifying batch-mode chart parsing, restricting ourselves to a standard context-free grammar without cyclic or empty productions.",
        "Definition 1 (Chart) A chart is a directed graph C = (V, E) such that V is a finite, non-empty set of vertices and EC V x V x ft is a finite set of edges, where it is the set of dotted context-free rules obtained from the g,rammar•4 The vertices , .",
        "• ., vs+1 C V correspond to the linear positions between the tokens r ti • • • t„ of an n-token text.5 An edge e C /i; between vertices it; and vi carries information about a (partially) analysed constituent between the corresponding positions.",
        "The algorithm makes use of an agenda (see Thompson [12]).",
        "Agenda tasks are created in response to tokens being read and edges being added to the chart, and may be ordered according to their priorities.",
        "To define the agenda, we make use of the set of possible tokens ?Ins and the set of possible edges Edgs.",
        "Definition 2 (Agenda) We define the agenda as Agda C nits U Pdgs U (Edgs x Fdgs).",
        "We refer to the three types of tasks that it contains as scanning, prediction and combination tasks, respectively.",
        "4 For brevity, we omit a fourth edge component corresponding to the set of (partial) parse trees according to the grammar and lexicon (assuming that only the topmost portion of a tree corresponding to the dotted rule needs to be stored in an edge).",
        "5We shall Ilse T interchangeably to denote a sequence and a set of tokens.",
        "Each agenda task is executed by a step of the algorithm below.",
        "We specify two versions of batch-mode chart parsing – the basic bottom-up (strictly speaking, left-corner) and top-down (Earley-style) strategies assuming that the one or the other is chosen.",
        "Algorithm 1 (Batch-mode chart parsing) Input: A sequence of tokens r ti • • • 1„ Output: A chart.",
        "Initialization: If the top-down strategy is used, then add an agenda task corresponding to an initial top-down prediction (vi, v1, S .a) for each rule S a, where S is the start category of the grammar.",
        "Method: For each token, create a scanning task.",
        "While the agenda is not empty, remove the next task and execute the corresponding step below: Scan: Given a token t at position j, for each lexical entry of the form X add an edge (vi, vj.t.i, X '14.",
        "'1 Add resulting new tasks to the agenda.",
        "Predict 1 (Bottom-up): If the edge is of the form (vi, vk, X 4 a.",
        "), then, for each rule of the form Y X-y, add an edge (vi, vj, .X7) unless it already exists.",
        "Add resulting new tasks to the agenda.",
        "Predict 2 (Top-down): If the edge is of the form",
        "vj, X a.Yg), then, for each rule of the form n Y 7, add an edge (vj, vj, Y 4 .7) unless it already exists.",
        "Add resulting new tasks to the agenda.",
        "Combine: If the first edge is of the form (vi, vj, X -± a .Y 0) and the second is of the form (vj, vk, Y y.",
        "), then add an edge (vi, vk, X aY.m.",
        "Add resulting new tasks to the agenda."
      ]
    },
    {
      "heading": "3 Incremental Chart Parsing",
      "text": []
    },
    {
      "heading": "3.1 The Problem",
      "text": [
        "The overall incremental process can be thought of as a change-update loop, where each change of the input is immediately followed by a corresponding update of the output.",
        "To completely specify the state of this process, we shall make use of a configuration consisting of (a representation of) an input text r, a chart C and an edge-dependency relation 1) (to be defined in section 4).",
        "The problem of incremental chart parsing can then be specified abstractly as a mapping Mr, C, V), Ar) (r' ,C' from an old configuration and a modification AT to a new configuration.",
        "We shall allow two kinds of change, namely, insertion and deletion of m 7 I contiguous tmWe refer to the new edge as a !erica' 'edgc.",
        "tokens.",
        "We assume that a modification A, is given as a vertex pair vj, E V defining the update interval and, in the case of an insertion, a sequence of tokens r ti • • • We furthermore assume that either the bottom-up or top-down strategy is chosen throughout a change-update session, and, in the latter case, that the top-down initialization is made before the session is started."
      ]
    },
    {
      "heading": "3.2 A General Vertex Mapping",
      "text": [
        "How can the minimal change Astnin be defined in a chart-based framework?",
        "One way of doing this is to compare the charts C (V, E) and C' (V', E') that are obtained by belch-mode parsing of the texts before and after a change, respectively.",
        "We thereby obtain a measure which is independent of particular incremental update algorithms.",
        "Intuitively, only those edges that are in E but not in 5' must be reinoved, and only those edges that are in 5' but, not in E must be generated anew.",
        "if the change is small, then a large fraction of the edges are in E fl 5' (that is, are unchanged).",
        "However, to be able to compare the edge sets in the two charts, we must first establish a one-to-one mapping between their vertices.",
        "Let us consider the case in which a single token is deleted from an n-token text.",
        "The problem is that, because of the removed token, the two vertices viand vo.i would seem to correspond to a single vertex in V'.",
        "however, we can regard this single vertex as consisting of a \"left half\" and a \"right half\", which we assign different indices.",
        "In other words, after having increased each index of E V' by one, we \"split\" vertex and assign the index i+ I to its \"right half\".",
        "The incoming non-predicted edges as well as (looping) top-down predictions at the split vertex are then associated with its left half, and the outgoing non-predicted edges as well as (looping) bottom-up predictions are associated with its right half.?",
        "The reason for dividing the predicted edges in this way is that a top-down prediction is made at the ending vertex of the triggering edge (that is, from the left), whereas a bottom-up prediction is made at the starting vertex of the triggering edge (that is, from the right).",
        "The mapping can be generalized to the case in which 71I contiguous tokens are deleted.",
        "This is done by increasing the index of each vertex from the \"right half\" of the split vertex and onwards by m (instead of one).",
        "Furthermore, by using the same mapping but in the opposite direction, we can also cover insertion of rn contiguous tokens.",
        "To express this generalized mapping, assume that V is the set of vertices of time larger chart and V is that of the smaller chart.",
        "A deletion of rn contiguous tokens then involves a mapping from V to V and an insertion of m tokens involves a mapping from V to V. In terms of the indexing that holds before the vertices in V are renumbered, and assuming that V 'As mentioned above, we assume that only the one or the other strategy is used, so that it is known beforehand which kind of predictions the chart contains.",
        "has n+1 vertices, we obtain the following bidirectional mapping:",
        "• Vertices • ., E V correspond to vi, E V, respectively.",
        "• Vertex corresponds to the \"left half\" of vertex • Vertices i51+1, • • .,i3i+m-1 E V do not correspond to any vertices in V. • Vertex corresponds to the \"right half\" of vertex • Vertices correspond to vi+i ,•, v„+1_,,, respectively.",
        "The mapping is thus established with respect to insertion or deletion of an arbitrary number of contiguous tokens.8"
      ]
    },
    {
      "heading": "3.3 Minimal Change",
      "text": [
        "Assume that E and E' are the sets of edges of the charts C and C' obtained by batch-mode parsing of a text before and after a modification A'-, respectively.",
        "'Presumably, it is possible to generalize the mapping to more complex (non-contiguous) operations such as replacements or reversals.",
        "However, we do not pursue that here.",
        "We can then define the minimal output change on the basis of two edge sets as follows: Definition 3 (Minimal output change) We define the set of missing edges as the set difference M E\\E' and the sel of new edges as the set difference N = E' \\ E. We then define the minimal onipul change as M U N. Next, we can define the size of the minimal change as follows: Definition 4 (Size of minimal change) We define the size of the minimal change as 6 = 'ATI + the sum of the number of inserted or deleted tokens and the number of edges in Ac,„i„•"
      ]
    },
    {
      "heading": "3.4 An Example",
      "text": [
        "As an illustration, the chart in figure 2 is obtained under (batch-mode) bottom-up parsing, given the grammar in figure 4 and the sentence \"The old man the tall ships\".",
        "If the token \"tall\" is removed, the chart in figure 3 is obtained.",
        "Vertex v5 in figure 2 then corresponds to the left half of vertex v15 in figure 3, and vertex v6 corresponds to the right half of vertex v5.",
        "Furthermore, v7 corresponds to v16.",
        "Clearly, the input change A, consists of the token \"tall\".",
        "The output change Acmin consists of the missing set M, which contains the three edges A26, NP27 and NP34 in figure 2, and the new set N, which contains the single edge N1332 in figure 3.",
        "The size of the change is then 6 -= lAr Ac„,i„ = + 3 + 1 = 5.",
        "If instead \"tall\" is inserted before the last word in the sentence in figure 3, then the input change still consists of the token \"tall\".",
        "However, the two sets making up the output change are reversed: the missing set contains the single edge NP32 in figure 3 and the new set contains the three edges AM, NP27 and NP34 in figure 2.",
        "Thus, the size of the change is again 5."
      ]
    },
    {
      "heading": "4 An Unbounded Algorithm",
      "text": [
        "A key idea of the incremental chart-parsing algorithm put forward by Wirers [14, 15] is to use edge dependencies for keeping track of edges that have to be removed in response to a change.",
        "An edge e' is said to depend upon another edge or token e if it is formed (derived) directly on the basis of c. Furthermore, if e' is redundantly proposed by an edge f, then e' can be said to",
        "depend (also) on f. By e' being \"redundantly propo-sed\", we mean that the parser attempts to add an edge that is equivalent to e' to the chart, but that that edge is rejected by the standard redundancy test in chart parsing.",
        "In effect, f provides an additional \"justification\" for e'.",
        "Given a chart C = (V, E) and a set of tokens r, these conditions correspond to the following dependency relation on E and r: Definition 5 (Edge dependency) We define D as a binary relation on the set of chart edges and the set of tokens F U r such that D(s, d) holds if and only if d E E is formed, or is redundantly proposed, directly using s E EUr according to a chart-parsing algorithm.",
        "We say that d is a dependent (or derivative) edge of s, and that s is a source edge (token) of d. D can be illustrated by a graph.",
        "The dependency graph corresponding to the chart in figure 3 is shown in figure 5.",
        "On the basis of the dependency relation, Wiren and Riinnquist [15, 17] define different disturbance sets, given as functions from tokens to sets of edges, and containing edges that need to be removed from the chart in response to a token-level change.",
        "The simplest such set is D*(ti), the transitive closure of D(i).",
        "Wiren and ROnnquist [15, 17] discuss this and other alternatives and show completeness of D* with respect to the missing set.",
        "The algorithm performs an update essentially by removing the entire disturbance set and then generating all possible edges.",
        "The latter set includes not only the new edges, but also disturbed, non-missing edges, which have to be generated anew.",
        "The complexity analysis of the algorithm yields that it is unbounded incremental in both its bottom-up and top-down version (see Wiren [16]).",
        "The source of this is that the algorithm removes the entire disturbance set, whose size depends on n, the size of the entire input."
      ]
    },
    {
      "heading": "5 A Bounded Algorithm",
      "text": []
    },
    {
      "heading": "5.1 Intuitive Idea",
      "text": [
        "Intuitively, a bounded incremental algoridnn only processes the region where the input or output changes during an update cycle.",
        "In our case, the problem in achieving this is that the missing and new edges are not a priori known – when the incremental update begins, only a set of potentially missing edges (the disturbance set) is known.",
        "However, the update can be limited by using a change-propagation algorithm (compare Rarnalingarn and Reps [10, page 21]): By initially retaining the disturbance set, new and old edges can be compared during reparsing.",
        "If a new edge e1 is different from the corresponding old edge e (if tins exists), then the dependants of c are regarded as disturbed (potentially missing).",
        "If e' is equivalent to e in the sense of giving rise to the same derivative edges, then the dependants of c are known not to be missing, and hence the reparsing process does not have to proceed beyond tins point in the search space.",
        "In order to avoid extra computation, the disturbed edges should be visited in the order given by the dependency graph.",
        "Ilow can the points at which a change \"dies out\" he characterized?",
        "Since we are interested in characterizing the conditions under which two edges give rise to the same derivative edges, the contents part of an edge (that is, the right-hand side before the dot of the clotted rule) is irrelevant.",
        "For example, we want to say that the new edge N1'32 in figure 3 to be reparsing-equivalent with edge N1)34 in figure 2 although their dotted rules and parse trees are different: the dotted rule of the fernier is NP Del N .",
        "and that of the latter is NP Del A N .. We can summarize this in the following definition:"
      ]
    },
    {
      "heading": "Definition 6 (Reparsing-equivalent edges)",
      "text": [
        "Assume given a proposed edge e and a disturbed edge e' E C. We say that e = X –4a./3) and e' Y it.",
        "v) are equivalent from the point of view of reparsing if i = s, j i, X = Y and 0 Inactive (combined or lexical) edges and predicted edges are special cases under this definition.",
        "In the former case, ig and v are empty, and thus two inactive edges are reparsing-equivalent if i a, j = t and X = Y.",
        "In the latter case, a and it are empty, and thus two predicted edges e and c' are reparsing-equivalent if e e'."
      ]
    },
    {
      "heading": "5.2 The Algorithm",
      "text": [
        "We now specify a bounded incremental chart-parsing algorithm that handles one update cycle.'",
        "In comparison with the unbounded algorithm, the differences are in the reparse and remove steps."
      ]
    },
    {
      "heading": "Modify the problem instance:",
      "text": [
        "Insert or delete the modified tokens given by A, into or from r. Prepare the chart: Do one of the following steps in the case of insertion or deletion, respectively: Insertion: Renumber edges as follows: First, replace each edge (vj , vk, 1.)",
        "where j > i and k i with an edge vk, r).",
        "Secondly, replace each edge (vj , vk, r) where k > i with an edge (v5, vk+m, r).",
        "Looping edges at the \"modification vertex\", which have the form (vi, vi, r), are dealt with differently depending on where their sources are located, which in turn depends on Lhe prediction strategy:",
        "• Bottom-up case: If the looping edge depends on an outgoing, non-looping edge ((vi, vi , r) such that j > i), then the looping edge is replaced with an edge (vi4.„,, r) (in effect, it is moved).",
        "• Top-down case: If the looping edge depends on an incoming, possibly looping edge ((vi, vk, r) such that k < i), then do nothing.",
        "Finally, update the dependency relation V so that any edge (vi, r) such that j < i and k > i is made dependent on ti.",
        "Deletion: Renumber edges as follows: First, replace each edge (vi , vk, r) where j > i with an edge (v vk, r).",
        "Then replace each edge (vi, vk, r) where k > i with an edge (vi, vk m r) • Reparse: Do the following steps: In the case of insertion: create a scanning task for each new token; create a combination task for each active – inactive edge pair meeting at viand vi+,„,.",
        "In the case of deletion: create a combination task for each active – inactive edge pair meeting at vi.",
        "Reparse while visiting the disturbed edges in the order given by the dependency graph and treating the disturbed edges as \"sleeping\" (that is, they do not play any role in the parsing process as such).",
        "Whenever a new edge is proposed, check if an equivalent edge exists in the disturbance set according to definition 6.",
        "If so, install the new edge, update D by letting the new edge inherit the dependencies from the old edge.",
        "Do not add any agenda items for the new edge (thereby discontinuing reparsing along this path).",
        "Mark the new edge as recreated (with respect to a reparsing-equivalent one).",
        "Remove edges: Remove each edge that is in the disturbance set but not in the dependency set of any recreated edge."
      ]
    },
    {
      "heading": "5.3 Incremental Complexity",
      "text": [
        "For the purpose of analysing the incremental complexity of algorithm 2, we assume that adding or removing an edge takes unit time.",
        "We also assume that no edge has more than a constant number of sources or dependants and, hence, that the time required to install or examine the dependencies of k edges is 0(41° We first focus on the reparsing step.\"",
        "Consider the case of a deletion within a text.",
        "The set of new edges N are generated as a result of joining two subcharts, which we assume have length i and j and contain 0(i2) and 0(j2) edges, respectively (disregarding the grammar constant PD.",
        "The joined chart thus has length i j and consists of 0((i A') edges.",
        "The number of new edges resulting from joining the subcharts is then 0((i j)2) – (0(i2)+ 0(j2)) 0(i • j) edges.",
        "Since the algorithm generates these edges by invoking a 0(n3) reparsing algorithm, the new edges require O((i+ jr) – MO) 0(i3)) = 0(i *(i+ 1)) = 0(i2.",
        ":72) = 00N21) time.",
        "The insertion case can be obtained in a similar way and gives the same result.",
        "In the remove step, the missing edges are found by following dependency chains originating from tokens until a reparsing-equivalent edge is found or the chain ends.",
        "This step can therefore be executed in 0(IMI) time.",
        "The algorithm as a whole then requires 0(62) time."
      ]
    },
    {
      "heading": "6 Conclusions",
      "text": [
        "The boundedness criterion used here provides a guarantee that the next update state is never more than an amount of computation away from the current state that is limited by the size of the change.",
        "This criterion is very strong.",
        "It can be thought of as constituting one 10 This assumption is considered too strong in reason maintenance, where, in the worst case, all formulas can be directly connected (see Goodwin [4, page 110 f.[).",
        "However, it seems appropriate here, since under a context-free grammar of the kind used here only predicted edges may have multiple sources.",
        "Moreover, the number of these sources is limited because of the linearity of the problem instance (the text).",
        "II Since we take addition and removal of edges to be the primary tasks of incremental update, we disregard the chart-preparation step.",
        "Although a more thorough analysis might take this step into account both in the definition of 8 and in the complexity analysis, we do not believe that anything fundamental would be altered by this.",
        "extreme point of a continuum of ways in which to measure the complexity of incremental algorithms.",
        "At the other extreme, we have the option of using WI I IS' the cost of discarding the old solution and invoking a batch-mode algorithm on the modified problem instance.",
        "This measure might be used for showing that an algorithm with poor worst-case incremental behaviour is still practical: Poor incremental behaviour means that the algorithm does not respond quickly to (some) small changes.",
        "However, it may still perform better than discarding the old solution and invoking a batch-mode algorithm.",
        "In other words, even if the algorithm is unbounded in .5, it may have a lower time bound in ill +15.",
        "'1 than the batch-mode algorithm.",
        "The unbounded algorithm described in section 4 is an example of this: it is clearly more efficient than the batch-mode algorithm for the purpose of incremental update.",
        "Several interesting topics for further research present themselves: One is to generalize the notions of minimal change and bounded incrementality to other processing frameworks that make use of a table or a chart, for example, pseudo-parallel L13.",
        "parsing (Tomita [13]) or tabular generation (Neumann [8]).",
        "Another interesting topic is to translate the same notions to a unification-based grammar formalism.",
        "Defining minimal change then requires a definition of the difference between two feature structures.",
        "An immediate observation is that this is itself hardly a feature structure, but rather the set of (sub)structures that are not present in both feature structures (in analogy with our definition of the difference between two charts)."
      ]
    }
  ]
}
