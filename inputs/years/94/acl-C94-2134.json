{
  "info": {
    "authors": [
      "Masaki Kiyono",
      "Jun'ichi Tsujii"
    ],
    "book": "International Conference on Computational Linguistics",
    "id": "acl-C94-2134",
    "title": "Hypothesis Selection in Grammar Acquisition",
    "url": "https://aclweb.org/anthology/C94-2134",
    "year": 1994
  },
  "references": [
    "acl-C92-1022",
    "acl-C92-2072",
    "acl-E93-1027",
    "acl-P89-1013",
    "acl-P91-1027",
    "acl-P93-1032"
  ],
  "sections": [
    {
      "heading": "Abstract",
      "text": [
        "This paper presents some techniques for selecting linguistically adequate hypotheses of new grammatical knowledge to be used as resources of grammatical knowledge acquisition.",
        "In our framework of linguistic knowledge acquisition, a rule-based hypothesis generator is invoked in case of parsing failures and all the possible hypotheses of new grannnar rules or lexical entries are generated from partial parsing results.",
        "Although each hypothesis could recover the defects of the existing grammar, the greater part of hypotheses are linguistically unnatural.",
        "The techniques we propose here prevent such unnatural hypotheses from being generated without discarding plausible ones and make the following corpus-based acquisition process more efficient and niore reliable."
      ]
    },
    {
      "heading": "1 Introduction",
      "text": [
        "Reusability of existing linguistic knowledge is the most important requirement for the rapid development of practical natural language processing systems.",
        "In order to realize automatic customization of existing linguistic knowledge to each application domain, we proposed a new approach of linguistic knowledge acquisition, which is a combination of symbolic and statistical approaches [Kiyono and Tsujii, 1993].",
        "The framework of our approach is shown in Figure 1.",
        "The acquisition flow starts with executing the parse of each sentence in a corpus.",
        "If parsing failed, the 'Hypothesis Generator' produces the hypotheses of additional grananatical knowledge, each of which could recover the incompleteness of the existing grammar.",
        "After iterating this hypothesis generation process for all the sentences in the corpus, the hypotheses are passed to the statistical analysis process and finally plausible hypotheses are chosen as new knowledge by observing statistical properties of the hypotheses.",
        "Unlike robust parsing [Mellish, 1989; Goeser, 1992; Douglas and Dale, 1992] or non-statistical approach for granunar acquisition, our approach does not require a mechanism to detect the cause of the parsing failure in the sentential analysis phase and therefore the `Hypothesis Generator' may output all Hie possible hypotheses.",
        "However, the greater part of hypotheses generated by a simple deductive mechanism are unnatural revisions of the existing grammar.",
        "For example, even a rule winch derives 0 top node category S directly from the input string of words might be hypothesized.",
        "*also a staff member of Matsushita Electric Industrial Shinagawa, Thkyo, JAPAN.",
        "Linguistically unnatural hypotheses have harmful effects on the following corpus-based process, not only making the process inefficient but also interfering with statistical data as noise.",
        "In this paper, some techniques to remove such inadequate hypotheses are proposed and the results of experiments which show the effectiveness of the proposed techniques are also discussed."
      ]
    },
    {
      "heading": "2 Grammar Hypothesizing",
      "text": []
    },
    {
      "heading": "2.1 Grammar Formalism",
      "text": [
        "The grammar formalism we use is a conventional unification-based grammar.",
        "Each grammar rule is written in the form of a combination of a context-free rule and feature unification functions.",
        "This formalisin is not, specific to any linguistic theory, but we introduced a number of concepts widely accepted in linguistic theories, such as grammatical functions, o 11 b-categorization frames, and X-bar theory.",
        "The parsing systetn we introduced to apply our grammar formalism is a system called SAX [Mat-stunoto, 1986].",
        "SAX uses the concepts of active and inactive edges of Charl Parsing and analyses all input sentence with a bottom-up and parallel algorithm.",
        "As the grammar hypothesizing algorithm is supposed to refer partial parsing results of unsuccessfully parsed sentences, we slightly modified SAX so that it outputs inactive edges as partial parsing results."
      ]
    },
    {
      "heading": "2.2 Basic Algorithm",
      "text": [
        "When SAX fails to parse a sentence, no inactive edge of category S spanning the whole sentence exists in the parsing result.",
        "Grammar hypothesizing is a process to introduce this inactive edge by augmenting the current grammar.",
        "The basic part of the hypothesis generation algorithm is written as follows: [Algorithm] An inactive edge [ie(A) : xo,x„1 can be introduced from xo to x„, with label A, by each of the hypotheses generated by the following two steps.",
        "[Step 1] For each sequence of inactive edges, [ie(Bi) : xo,xd, , [2e(1 : :■:], spanning from xo to r,, generates a new rule.",
        "Feature Structures: A rule generated in [Step 1] could be a lexical entry when this top-down algorithm reaches the bottom.",
        "As we adopted a unification-based grammar formalism, we extended the algorithm so that it can hypothesize a feature structure of a lexical entry by observing surrounding successful categories.",
        "As the algorithm works even for a complex feature like a subcategorization frame, it can be used to acquire a subcategorization dictionary.",
        "While some previous works on subcategorization frame acquisition assumed very little prior knowledge concerning the classification of subcategorization frames [Brent, 1991; Manning, 1993], our approach assumes the existence of grammar rules specifying subcategorization frame assignment, which enables more accurate learning of subcategorization frames.",
        "Multiple Defects: In [Step 2] of the algorithm, it is supposed that each unsuccessfully parsed sentence has exactly one cause of failure but a sentence in actual texts often contains two or more causes of failure (for example, two unknown words).",
        "To solve this problem, we extended the algorithm so that it searches for a multiple hypothesis which is a set of rewriting rules and lexical entries."
      ]
    },
    {
      "heading": "3 Hypothesis Selection",
      "text": []
    },
    {
      "heading": "3.1 Basic Grammatical Constraints",
      "text": [
        "From a linguistic point of view, hypotheses generated by the algorithm given above might contain many unnatural hypotheses because the algorithm itself does not have any linguistic knowledge to judge the appropriateness of hypotheses.",
        "To remove unnatural hypotheses, we have introduced the following criteria [Kiyono and Tsujii, 1993].",
        "• The maximum number of adjacent unsuccessful categories is set to 2 in order not to decrease the efficiency of the algorithm.",
        "• The maximum number of daughter nodes is set to 3.",
        "• Supposing that the existing grammar contains all the category conversion rules, a unary rule which has only one daughter node is not generated.",
        "• Using generalizations embodied in the existing grammar, a hypothesis containing a sequence of subnodes which are collected into a larger category by existing grammar rules is not generated.",
        "• Distinguishing non-lexical categories from lexical categories, a hypothesis whose mother category is a lexical category is not, generated.",
        "• Assuming that the existing grammar has a complete set of functional words, a lexical hypothesis is restricted to the open lexical categories, such as noun, verb, adjective, and adverb."
      ]
    },
    {
      "heading": "3.2 Constraint based on Local Boundaries",
      "text": [
        "A new constraint on the violation of the boundary ondition given to phrases was introduced to avoid my collection of adjacent successful categories in rule iypothesizing.",
        "The boundary condition is given by nutting parentheses at both ends of a phrase, such is a noun phrase, a verb phrase, and a prepositional ihrase.",
        "This constraint filters out a hypothesis which rosses either end, not both ends, of a phrase.",
        "For xample, when parentheses are put like \"[The default docking factor] is [20 blocks]\" , a hypothesis `VP -=> VP, NP, V P.; B.E' covering \"blocking factor is\" is discarded because of the violation of the boundary con-lition of a noun phrase \"The default blocking factor\".",
        "This constraint requires the human task of putting parentheses before the hypothesis generator is invoked.",
        "n comparison with writing a constituent structure of he whole sentence, this work is notch easier because we have only to give parentheses to definite phrases.",
        "Moreover, instead of giving parentheses by hand, we an even obtain various tagged corpora.",
        "As this constraint is also applicable to other con-tituents of the input sentence, it might intprove the fliciency of the top-down hypothesizing algorithm."
      ]
    },
    {
      "heading": ".3 Constraint based on X-bar Theory",
      "text": [
        "Most of the criteria in 3.1 are based on linguis-ic category classification but none of them coin-nits itself to dealing with the relationship among the nother node and the daughter nodes.",
        "For example, upposing the existing grammar does not contain a ule for participial adjuncts in noun phrases, the by-othesizing program generates a new rewriting rule NP VP, N from the phrase \"blocking factor\" n the sentence `The default blocking factor is 20 locks\".",
        "However, the program also generates other alternative hypotheses from the same phrase, such as PI' VP, NP', VP, NP', and I'HAT_CLAUSh;VI', N P' , each of which derives post-positional adjunct for \"default\" by believing default\" is a bead noun of the noun phrase.",
        "Linguisti-ally, such combinations of mother nodes and daughter odes are not allowed.",
        "As a general principle for explaining phrase struc-rues, X-Inir theory is widely accepted.",
        "According to bar theory, a grammar rule is (or can be converted o) either of the following forms, where each prime() xpresses the projection level of a head X.",
        "The projec-on level increases as grammar rules are applied mid \" is called a maxima/ projection of that category.",
        "U nd W are adjuncts of N' and should be maximal pro-ctions of sonic categories.",
        "X\" .=> YX'Z => f/X.117 if the existing grammar is written in X.-bar theory, this constraint is drastically effective in reducing the number of hypotheses."
      ]
    },
    {
      "heading": "3.4 Plausibility of Hypotheses",
      "text": [
        "Among the hypotheses which passed through all the constraints, each one has a different plausibility as grammatical knowledge.",
        "Assuming that the existing grammar is reasonably comprehensive, lexical or idiosyncratic: knowledge should be more plausible than general rewriting rules.",
        "In order to eitiphasize this tendency, each hypothesis is given the following plausibility value.",
        "This value is related to the proportion of the size, or the product of the width and the height, of the subtree composed by the hypothesis in the whole structure of the sentence.",
        "The value ranges From 0 to I and gets bigger if the hypothesis covers a smaller part of the sentence.",
        "The width of the hypothesis, 14/(//yinO, is defined its the word count of the subtree and the height II(Ilypoi) is as the shortest path from lexical nodes to the top node of the suldree."
      ]
    },
    {
      "heading": "4 Experiments",
      "text": []
    },
    {
      "heading": "4.1 Corpus",
      "text": [
        "In order to check the effects of the hypothesis selection techniques, we carried out sonic experiments with the UNIX on-line manual.",
        "100 sentences were chosen as an experimental set, from the manual.",
        "The characteristics of this corpus are as follows.",
        "• Number of sentences: 100 O Length of sentences: 9.08 words (average) • Number of different words: 381 • li_ixittioplesi,",
        "There is no escape sequence that prints a double-quote.",
        "Ilse the next argument, as the blocking factor for tape records.",
        "The default, blocking factor is 20 blocks."
      ]
    },
    {
      "heading": "4.2 Given Grammatical Knowledge",
      "text": [
        "Two sets of grammar rules were prepared for the experiments, Crammer A, and Grammar II.",
        "(;rammar A contains 118 rewriting rules that, cover basic expressions of English.",
        "Grammar II is a subset, of Grammar A nand contains only 25 rewriting rules.",
        "The contents of Grammar A and Ciriunniar Ii are shown in Table 1.",
        "The dictionary we use is the PI)It.",
        "Knglish Dictionary containing 200,000 entries.",
        "\"Ile entries of this dictionary are not, written in the form of a feature struc-Lure but have the encoded information of the syntactic patterns, which we interpret as a feature structure.",
        "As the EDII.",
        "Dictionary was developed as a master nary for various applications, it, took in the information concerning all the appearances of each word without screening by Frequencies.",
        "This characteristic of the",
        "13)11. dictionary increases the ambiguity ()I' parsing.",
        "En fact, each word within the sample sentences from the UNIX manual has 1.49 parts of speech in the E)II.",
        "Dictionary while the same value is 1.41 according to the COPUNS (10 BUILD Dictionary."
      ]
    },
    {
      "heading": "4.3 Generated Hypotheses",
      "text": [
        "General Out conic: The experiments of generating hypotheses were carried out with ( kammar A under three different conditions, (a) using the basic grammatical constraints only, (h) adding the constraint with local phrasal boundaries given as parentheses, and (c) adding the constraint with X-bar theory.",
        "carry out experiments (b) and (c), within the target, sentences, parentheses were given to noun phrases, infinitive clauses, dean-clatwes, and subordinate clauses.",
        "A part of the result, of experiment, (a) is shown in Table 2, each column of which displays the number of hypotheses generated.",
        "'Flu) columns 'Single' and 'Multiple' show the numbers of single and multiple hypotheses respectively.",
        "'File results of the three experiments are summarized in Table 3.",
        "The parser failed to analyse Gt out, or 100 sentences and the grammar hypothesizing program was invoked for those sentences.",
        "While no hypotheses were generated from 20 or 30% of unsuccessfully parsed sentences because the current hypothesizing idgorit Ion does not allow vertical duplication of incompleteness and also because the parameters of the basic grammatical constraints do not, allow the existence of more than two adjacent incomplete nodes, the results on the hers of actual hypotheses made show that the stronger the constraint, we pose, the fewer hypotheses are generated.",
        "i'he average hypotheses per sentence, calculated by dividing the total hypothesis count of 1,301 in (a), 708 in (b), and 231 in (c), by the number of actual sentences from which hypotheses were generated, 50 in (a), 44 in (b), and 41 in (c), was reduced from 26.0 to 5.6.",
        "In some cases, all the hypotheses are removed by newly introduced constraints, G sentences by the local boundary constraint and 3 more sentences by the constraint of X-bar theory.",
        "Investigation of the initial set, of hypotheses generated from such sentences revealed that, no plausible hypothesis was included in it.. nere-fore, these sentences are not, critical to the hypothesis selection method we introduced.",
        "In the final set of hypotheses, 30 plausible hypothe",
        "The weighting function explained in 3.4 was not used for selecting hypotheses but the validity of it was proved by counting the order of each plausible hypothesis in the set of generated hypotheses.",
        "The row of `Rank of Plausible Hypotheses' in Table 3 indicates that plausible hypotheses stand much higher than the middle of the order.",
        "Examples: Thereafter, in order to show how hypotheses were selected by each constraint, we explain the results for seine typical examples.",
        "Ex.l) \"The default blocking factor is 20 blocks,\" As Grammar A does not contain a rule for participial adjuncts, the parser fails to analyse the noun phrase \"the default blocking factor\" and the grammar hypothesizing program is invoked.",
        "While this program generates 21 hypotheses in experiment (a), it filters out the following 12 hypotheses in experiment (b).",
        "While checking local boundary violation, the program retrieves those granunatically unnatural combinations of categories, though it does not use any linguistic knowledge.",
        "Moreover, the program filters out the following 4 hypothese with the constraint of X-bar theory.",
        "Finally, the following 5 hypotheses, among which the expected hypothesis 'NJ' VP, NP' still remains, are generated.",
        "Ex .2) \"The output device in use is not capable of backspacing.\"",
        "This sentence is also parsed unsuccessfully because the current version of the EDIT.",
        "Dictionary does not have information that \"capable\" subcategorizes a prepositional phrase.",
        "Among the initial set of 30 hypotheses, the following 8 hypotheses pass through",
        "the constraints of local boundaries and X-bar theory.",
        "The first hypothesis in the list is the plausible hypothesis obtained in search of the real cause of the feature disagreement between \"capable\" and \"of backspacing\".",
        "This lexical hypothesis for \"capable\" contains a modified version of its sub categorization franie so that it subcategorizes of-prepositional phrase."
      ]
    },
    {
      "heading": "4.4 Hypotheses from Smaller Knowledge",
      "text": [
        "Another experiment was performed with Grammar It under the basic grammatical constraints in order to compare the effects of the maturity of existing grammatical knowledge.",
        "The numbers of hypotheses generated from two grammar sets are shown in Table 4.",
        "The coverage of Grammar li is so limited that, 97 out of 100 sentences were parsed unsuccessfully and passed to the Hypothesis Generator However, as the immaturity of Grammar 11 also affects the number of gem-crated hypotheses, the iniuMer of plausible hypotheses among the 550 hypotheses (10.1) hypotheses per sentence) generated from 97 sentences was only 16.",
        "This result claims that, cyclic acquisition of grammatical knowledge is valid.",
        "Even the sentences from which no hypotheses are generated with a small grammar would be taken into consideration in a later acquisition cycle with a larger grammar."
      ]
    },
    {
      "heading": "5 Conclusion",
      "text": [
        "This paper proposed techniques for selecting appropriate hypotheses in the rule-based processing stage of grammar acquisition.",
        "The experiments to examine the effects of these techniques indicate that, they have several adVallt ages.",
        "e 'the newly introduced constraints reduce the number of hypotheses per sentence, front 26.0 to only 5.6, small enough to be treated in a corpus-based processing environment.",
        "Tins hypothesis selection is clone without discarding plausible hypotheses.",
        "Although, all the initial hypotheses may be, in certain cases, removed by the new constraints, this happens only if no plausible hypothesis is included in the initial set.",
        "• Even if no hypothesis is generated from an unsuccessfully parsed sentence (20 nut of 61 sentences in experiment (c)) or no plausible hypothesis is included in the initial hypothesis set (11 out of 41 sentences in experiment (c)), a plausible hypothesis will be generated in the later acquisition cycle after adding granmudical knowledge vital for the sentence, • Among the generated hypotheses, lexical hypotheses are more plausible than rule hypotheses (23 out of 30 plausible hypotheses were lexical in experiment (c)).",
        "This fact, means that the grammar used for the experiments has an almost sufficient set, of rewriting rules and that, after the grammar reaches such a mature situation during the acquisition cycle, only lexical or idiosyncratic knowledge has to be added.",
        "As our method has a facility to hypothesize a lexical entry with its feature structure including a subcategorization frame, we can set the target of acquisition only to lexical knowledge for a large dictionary.",
        "• The local boundary constraint was introduced for automatic hypothesis selection, but it, might also be used in an interactive debugging tool for grammar maintenance."
      ]
    }
  ]
}
