{
  "info": {
    "authors": [
      "Hans-Ulrich Krieger",
      "Ulrich Schäfer"
    ],
    "book": "International Conference on Computational Linguistics",
    "id": "acl-C94-2144",
    "title": "TDL - A Type Description Language for Constraint-Based Grammars",
    "url": "https://aclweb.org/anthology/C94-2144",
    "year": 1994
  },
  "references": [
    "acl-C94-1072",
    "acl-J91-1004",
    "acl-J92-2002",
    "acl-P87-1013",
    "acl-P91-1031"
  ],
  "sections": [
    {
      "text": [
        "fkrieger,schaeferlOdfki.uni–sb.de German Research Center for Artificial Intelligence (1)HK1) zenliattsweg :3, D-66123 Sintrbriicken, Germany Abstract 2 Motivation This paper presents TDE, a typed feature-based representation language and inference system.",
        "Type definitions in TOG consist of type and feature constraints over the Boolean connectives.",
        "TPC supports Open and closed-world reasoning over types and allows for partitions and incompatible types.",
        "Working with partially as well as with fully expanded types is possible.",
        "Efficient reasoning iu Tai.",
        "is accomplished through specialized modules.",
        "Topical Paper.",
        "Topic Area: software fin.",
        "NI,1', grammar formalism for typed feature structures."
      ]
    },
    {
      "heading": "Introduction",
      "text": [
        "Over the last few years, constraint-based gra/lunar formalisms have become the predominant paradigm in natural language processing and computational linguistics.",
        "Their success stems front the fact that they can be seen as a monotonic, high-level representation language for linguistic knowledge which can be given a precise mathematical semantics.",
        "'the main idea of representing as touch linguistic kitowledge as possible through a unique data type called feature structure, allows the integration or different description levels without taking care of interface problems.",
        "While the first approaches relied on annotated phrase structure rules (e.g., PATR-Ii), modern formalisms try to specify grammatical knowledge as well as lexicon entries entirely through feature structures.",
        "ill order to achieve this goal, one must enrich the expressive power of the first unification-based formalisms with different forms of disjunctive descriptions.",
        "Later, other operations came into play, e.g., (classical) negation.",
        "Other proposals consider the integration of functional/relational dependencies into the formalism which make them in general Turing-complete (e.g., ALE [i]).",
        "however the most important extension to formalisms consists of the incorporation of types, for instance in modern systems like ITS [l 5], CUT [ii], or TD., [7].",
        "Types are ordered hierarchically as it is known front object-oriented programming languages.",
        "This leads to multiple inheritance in the description of linguistic entities.",
        "finally, recursive types are necessary to describe at least phrase-structure recursion which is inherent in all grammar formalisms which are not provided with a context-free backbone.",
        "in the next section, we argue for the need and relevance of using types in CL and NIA'.",
        "After that, we give an overview of TVG and its specialized inference modules.",
        "Especially, we have a closer look on the novel features of TRC and present the techniques we have employed in implementing TPE.",
        "Modern typed unification-based grammar formalisms differ from early untyped systems in that they highlight time notion of a feature type.",
        "Types can be arranged hierarchically, where a subtype inherits monotonically all the information front its supertypes and unification plays the role of the primary information-combining operation.",
        "A type definition can be seen as an abbreviation for a complex expression, consisting of type constraints (concerning the sub-/supertype relationship) ruin feature constraints (stating the appropriate attributes and their values) over the connectives A, V, and - Types serve as abbreviations for lexicon entries, 11) rule schemata, and universal as well as language, specificprinciples as is familiar from 11P50.",
        "Besides using types as an abbreviation-al ineans as tellIplates are, there are other advantages as well which cannot be accomplished by templates:",
        "• STRUCTURING KNOW LEDGE",
        "Types together with the possibility to order thou hierarchically allow for a modular ;old clean way to represent linguistic knowledge adequately.",
        "Moreover, generalizations can be iuit at the appropriate levels of representation."
      ]
    },
    {
      "heading": "• EFFICIENT PROCESSING",
      "text": [
        "Certain type constraints can he compiled into efficient representations like bit vectors [E, where a 0E11 (greatest lower bound), LIMB (least upper bound), or a (type suhstimption) complitation reduces to low-level bit inanipulation; sec Section 3.2.",
        "Moreover, types release untyped unification from expensive computation through the possibility to declare them incompatible.",
        ":In addition, working wall type llatlleS may or with partially expanded types minimizes the costs of copying structures during processing.",
        "This can only be accomplished if the system makes it mechanism for type expansion available; see Section :1/1.",
        "• TYPE CHECK [NG",
        "Type definitions allow a grammarian to declare which attributes are appropriate for a given type and which types are appropriate for a given attribute, therefore disallowing one to write inconsistent, feature structures.",
        "Again, type expansion is necessary to determine the global consistency of a given description.",
        "• RECURSIVE TYPES",
        "Recursive types give a grammar writer the opportunity to !Orotund& certain functions or relations as recursive type specifications.",
        "Working iu the type deduction paradigm enforces a gratinnar writer to replace the context-free back",
        "bone through recursive types.",
        "Here, parameterized delayed type expansion is the ticket to the world of controlled linguistic deduction [13]; see Section 3.4."
      ]
    },
    {
      "heading": "3 TDC",
      "text": [
        "TD.0 is a unification-based grammar development environment and run time system supporting HPSGlike grammars.",
        "Work on TDL has started within the DISCO project of the DFKI [14] (this volume).",
        "The DISCO grammar currently consists of approx.",
        "900 type specifications written in TDE and is the largest HPSG grammar for German [9].",
        "The core engine of DISCO consists of TD,C and the feature constraint solver wok [3].",
        "1lDiAk itself is a powerful untyped unification machinery which allows the use of distributed disjunctions, general negation, and functional dependencies.",
        "The modules communicate through an interface, and this connection mirrors exactly the way an abstract typed unification algorithm works: two typed feature structures can only be unified if the attached types are definitely compatible.",
        "This is accomplished by the unifier in that //Da handles over two typed feature structures to TDE which gives back a simplified form (plus additional information; sec Fig. 1).",
        "The motivation for separating type and feature constraints and processing them in specialized modules (which again might consist of specialized components as is the case in TTIC) is twofold: (i) this strategy reduces the complexity of the whole system, thus making the architecture clear, and (ii) leads to a higher performance of the whole system because every module is designed to cover only a specialized task."
      ]
    },
    {
      "heading": "3.1 TDL; Language",
      "text": [
        "TD supports type definitions consisting of type constraints and feature constraints over the operators A, V, and el (xor).",
        "The operators are generalized in that they can connect feature descriptions, coreference tags (logical variables) as well as types.",
        "TDL distinguishes between avm types (open-world semantics), sort types (closed-world semantics), built-in types (being made available by the underlying COMMON LISP system), and atoms.",
        "Recursive types arc explicitly allowed and handled by a sophisticated lazy type expansion mechanism.",
        "In asking for the greatest lower bound of two avm types a and b which share no common subtype, TDE always returns a A b (open-world reasoning), and not 1.",
        "The reason for assuming this is manifold: (i) partiality of our linguistic knowledge, (ii) approach is in harmony with terminological (EL-ONE-like) languages which share a similar semantics, (iii) important during incremental grammar/lexicon construction (which has been shown useful in our project), and (iv) one must not write superfluous type definitions to guarantee successful type unifications during processing.",
        "The opposite case holds for the GLB of sort types (closed-world approach).",
        "Furthermore, sort types differ in another point from avm types in that they are not further structured, as is the case for atoms.",
        "Moreover, TDL; offers the possibility to declare partitions, a feature heavily used in HPSG.",
        "In addition, one can declare sets of types as incompatible, meaning that the conjunction of them yields 1, so that specific avm types can be closed.",
        "TX allows a grammarian to define and use parameterized templates (macros).",
        "There exists a special instance definition facility to ease the writing of lexicon entries winch differ from normal types in that they are not entered into the type hierarchy.",
        "Input given to TD.0 is parsed by a Zebu-generated LALR(1) parser [8] to allow for an intuitive, high-level input syntax and to abstract from uninteresting details imposed by the unifier and the underlying LISP system.",
        "The kernel of TDC (and of most other monotonic systems) can be given a set; theoretical semantics along the lines of [12].",
        "It is easy to translate TDL' statements into denotation-preserving expressions of Smolka's feature logic, thus viewing TDE only as syntactic sugar for a restricted (decidable) subset of first-order logic.",
        "Take for instance the following feature description o written as an attribute-value matrix:",
        "It is not hard to rewrite this two-dime isional description to a flat first-order formula, where attributes/features (e.g., AGR) are interpreted as binary relations and types (e.g., np) as unary predicates:",
        "The corresponding TDL' type definition of 0 looks as follows (actually St is used on the keyboard instead of A, I instead of V, instead of-i): := up A [AGE #x A agreement A [NUM sy, PERS 3rd], SUBJ #x]."
      ]
    },
    {
      "heading": "3.2 Type Hierarchy",
      "text": [
        "The type hierarchy is either called directly by the control machinery of TDE during the definition of a type (type classification) or indirectly via the simplifier both at definition and at run time (type unification).",
        "The implementation of the type hierarchy is based on Ait-Kaci's encoding technique for partial orders [1].",
        "Every type t is assigned a code 7(t) (represented via a bit vector) such that 7(t) reflects the reflexive transitive closure of the subsumption relation with respect to t. Decoding a code c is realized either by a lookup (iff 3t .",
        "7-1(c) = t) or by computing the \"maximal restriction\" of the set of types whose codes are less than c. Depending on the encoding method, the hierarchy occupies 0(n log n) (compact encoding) resp.",
        "0(n2) (transitive closure encoding) bits.",
        "Here, GLB/LUB operations directly correspond to bit-or/and instructions.",
        "GLB, LUB and computations have the nice property that they can be carried out in tins framework in 0(n), where n is the",
        "number of types.]",
        "Alit-Kaci's method has been extended in TD,C to cover the open-world nature of avin types in that potential G1,11/11,[1.13 candidates (calculated from their codes) must be verified.",
        "Why so?",
        "Take the following example to see why this is necessary:",
        "During processing, one can definitely substitute y Az through x, but rewriting y' A z' to x' is not correct, because differs froin y' A z' – • 'x' is more specific as a consequence of the feature constraint [a 1].",
        "So we make a distinction between the \"internal\" greatest lower bound G1,13_<, concerning only the type subsumption relation by using AIt-Kaci's method alone (which is however used for sort types) and the \"external\" one, GIBE, which takes the subsumption relation over feature structures into account.",
        "With M13< and GLI30 in mind, we can define a generalized.",
        "GUI operation informally by the following table.",
        "This GI,13 operation is actually used during type unification (le = feature constraint):",
        "avni2 see 1.",
        "1 _L see 2. sort 1 see 3. see 4.",
        "_L atm02 _L see 4. see 5, 1 fez see 2.",
        "1 1 see 6. where 'Actually, one can choose in 71)1. between the two encoding techniques and between bit vectors and bignums in COMMON LISP for the representation of the codes.",
        "In our Lisi.",
        "implementation, operations on bignums are a magnitude faster than on bit vectors.",
        "explicit incompatibility declaration avail A ainitp, otherwise (open world) avni.",
        "-(=>- expand(aina1,2) LI le2,1 1, otherwise",
        "_L, otherwise -s`• fci fifes I 1, otherwise 'the encoding algorithm is also extended towards the redefinition of types and the use of undefined types, an essential part of an incremental grant-mar/lexicon development system.",
        "iltedefilling a type means not only to make changes local to this type.",
        "instead, one has to redefine all dependents or this type – all subtypes in case of a conjunctive type definition and all disjunction alternatives for a disjunctive type specification plus, in both cases, all types which use these types in their definition.",
        "The dependent types of a type I can be characterized graph-theoretically via the strongly connected component of I with respect to the dependency relation.",
        "Conjunctive, e.g., x p A z and disjunctive type specifications, e.g., y' V z' are entered differently into the hierarchy: z inherits from its super-types y and z, whereas x' defines itself through its",
        "are introduced by TDC during the type definitions x := ttAv A [a 0] and y := wAvA 11 A [a 1].",
        "alternatives y' and z'.",
        "This distinction is represented through the use of different kinds of edges in the type graph (bold edges denote disjunction elements; see Fig. 3).",
        "But it is worth noting that both of them express subsumption (x y and x' y') and that the GLB/LUB operations must work properly over \"conjunctive\" as well as \"disjunctive\" subsumption links.",
        "TD,C decomposes complex definitions consisting of A, V, and -' by introducing intermediate types, so that the resulting expression is either a pure conjunction or a disjunction of type symbols.",
        "Intermediate type names are enclosed in vertical bars (cf. the intermediate types la A vl and la A v Awl in Fig. 2).",
        "The same technique is applied when using (i) (see Fig. 3).",
        "ED will be decomposed into A, V and plus additional intermediates.",
        "For each negated type TM introduces a new intermediate type symbol HI having the definition and declares it incompatible with t (see Section 3.2.3).",
        "In addition, if t is not already present, TDC will add t as a new type to the hierarchy (see types 1-41 and in Fig. 3).",
        "Let's consider the example a b EB c. The decomposition can be stated informally by the following steps (assuming that the user has chosen CNF):",
        "Incompatible types lead to the introduction of specialized bottom symbols (see Fig. 3 and 4) which however are identified in the underlying logic in that they denote the empty set.",
        "These bottom symbols must be propagated downwards by a mechanism called bottom propagation which takes place at definition time (see Fig. 4).",
        "Note that it is important to take not only subtypes of incompatible types into account but also disjunction elements as the following example shows:",
        "One might expect that incompatibility statements together with feature term unification no longer lead to a monotonic, set-theoretical semantics.",
        "But this is not the case.",
        "To preserve monotonicity, one must assume a 2-level interpretation of typed feature structures, where feature constraints and type constraints might denote different sets of objects and the global interpretation is determined by the intersection of the two sets.",
        "Take for instance the type definitions A [a 1] and 13 := [b 1], plus the user declaration",
        "= A A B, meaning that A and B are incompatible.",
        "Then A A B will simplify to 1 although the corresponding feature structures of A and B successfully unify to [a 1, b 1], thus the global interpretation is I."
      ]
    },
    {
      "heading": "3.3 Symbolic Simplifier",
      "text": [
        "The simplifier operates on arbitrary TDC expressions.",
        "Simplification is done at definition time and at run time when typed unification takes place (cf.",
        "Fig.",
        "1).",
        "The main issue of symbolic simplification is to avoid (i) unnecessary feature constraint unification and (ii) queries to the type hierarchy by simply applying \"syntactic\" reduction rules.",
        "Consider an expression",
        "detect 1 by simply applying reduction rules.",
        "The simplification schemata are well known from the propositional calculus.",
        "They are hard-wired in the implementation to speed up computation.",
        "Formally, type simplification in TDC can be characterized as a term rewriting system.",
        "A set of reduction rules is applied until a normal form is reached.",
        "Confluence and termination is guaranteed by imposing a total generalized lexicographic order on terms (see below).",
        "In addition, this order has the nice effects of neglecting commutativity (which is expensive and might lead to termination problems): there is only one representative for a given formula.",
        "Therefore, memoization is cheap and is employed in TUE to reuse precomputed results of simplified expressions (one must not cover all permutations of a formula).",
        "Additional reduction rules are applied at run time using \"semantic\" information of the type hierarchy (GLB, LUB, and ;-<).",
        "In order to reduce all arbitrary type expression 1,o a simpler expression, simplification rides roust be applied.",
        "So we have to define what it means for an expression to be \"simple\".",
        "One can either choose the conjunctive or disjunctive normal form, The ;idvan-tages of GNP/I/NE are:",
        "• UNIQUENESS",
        "Type expressions in normal form are unique modulo commutativity.",
        "Sorting type expressions according to a total lexicographic order will lead to a total uniqueness of type expressions (see Section 3.3.3).",
        "• LINEARITY",
        "Type expressions in normal form are linear.",
        "Arbitrary nested expressions can he transformed into flat, expressions.",
        "'rids may reduce the complexity of later simplifications, e.g., at run time.",
        "• COMPARABILITY",
        "This property is a consequence of the two other properties.",
        "Unique and linear expressions make it easy to find or to compare (sub)expressions.",
        "'Ibis is important for the metnoization technique described in Section 3.3.4.",
        "In order to reach a normal form, it would suffice to apply only the schemata for double negation, distributivity, and DeMorgan's laws.",
        "However, in the worst case, these three rules would blow up the length of the normal form to exponential size (compared with the number of literals in the original expression).",
        "To avoid thus, other rules are used intermediately: idempotence, identity, absorption, etc.",
        "If they can be applied, they always reduce the length of the expressions.",
        "Especially at run time, but also at definition time, it is useful to exploit information from the type hierarchy.",
        "Farther simplifications are possible by asking for the (MIL MI13, and",
        "To avoid the application of the commutativity rule, we introduce a total lexicographic order on type expressions.",
        "Together with 1)1\\IF/CNI.0, we obtain a unique sorted normal form for an arbitrary type expression.",
        "'rids guarantees fast comparability.",
        "We define the order <NJ' on nary normal fort us: type <NC, 7lay aied type <NI,' eon 11(14011 <Np dis-JUTICtiOn <NP symbol <Np, string <NI, number.",
        "For the comparison of atoms, strings, and type 11 alliCS, we use the lexicographical order on strings and for numbers the ordering < on natural numbers.",
        "'the memoization technique described in [10] has been adapted in order to reuse precomputed results of type simplification.",
        "'file lexicographically sorted normal form gottrantees fast access to precomputed type simplifications.",
        "Memoization results are also used by the recursive simplification algorithm to exploit, precomputed results for subexpressions.",
        "Some empirical results show the usefulness of mein-oization.",
        "'the current DISCO grammar for German consists of 880 types and 27 templates.",
        "After a full type expansion of a toy lexicon of 244 instances/entries, the niemoization table contains approx.",
        "3000 entries (literals are not ntemoized).",
        "1.8000 results have been reused at, least once (sonic up to 600 tunes) of which 90 (-Y(i, are proper simplifications (i.e., the simplified formulae tire really shorter than the unsimplified ones)."
      ]
    },
    {
      "heading": "3.4 Type Expansion and Control",
      "text": [
        "We noted earlier that types allow us to refer to complex constraints through the use of symbol names.",
        "Reconstructing the constraints which determine a type (represented as a feature structure) requires a complex operation called type eapansion.",
        "This is comparable to Carpenter's totally well-typedness [0]."
      ]
    },
    {
      "heading": "3.4.1 Motivation",
      "text": [
        "In -WE, the motivation for type expansion is manifold:",
        "• CONSISTENCY",
        "At definition thne, type expansion determines whether the set of type definitions (grammar and lexicon) is consistent,.",
        "At run time, type expansion is involved in checking the satisliability of the unification of two partially expanded typed feature structures, e.g., during parsing.",
        "• ECONOMY",
        "From the standpoint of efficiency, it does make sense to work only with small, partially expanded structures (if possible) to speed up feature term unification and to reduce the amount of copying.",
        "At the end of processing however, one has to make the result/constraints explicit.",
        "• RECURSION",
        "Recursive types are inherently present in modern constraint-based grammar theories like IIPSG which are not provided with a context-free backbone.",
        "Moreover, if the formalism does not allow functional or relational constraints, one roust specify certain functions/relations like append through recursive types.",
        "Take for instance Alt-Kaci's version of the append type which can be stated in TD.0 as follows:",
        "Parsing and generation can be seen in the light of type deduction as a uniform process, where ideally only the phonology (for parsing) or the semantics (for generation) must be given.",
        "Type expansion together with a sufficiently specified grammar then is responsible in both cases for constructing a fully specified feature structure which is maximal informative and compatible with the input.",
        "However, [15] has shown that type expansion without sophisticated control strategies is in many cases inefficient and moreover does not guarantee termination.",
        "Uszkoreit [13] introduced a new strategy for linguistic processing called controlled linguistic deduction.",
        "His approach permits the.",
        "specification of linguistic performance models without giving up the declarative basis of linguistic competence, especially monotonicity and completeness.",
        "The evaluation of both conjunctive and disjunctive constraints can be controlled in this framework.",
        "For conjunctive constraints, the one with the highest failure probability should be evaluated first.",
        "For disjunctive ones, a success measure is used instead: the alternative with the highest success probability is used until a unification fails, in which case one has to backtrack to the next best alternative.",
        "TD,C, and UDi.4 support this strategy in that every feature structure can be associated with its success/failure potential such that type expansion can be sensitive to these settings.",
        "Moreover, one can make other decisions as well during type expansion:",
        "• only regard structures which are subsumed by a given type resp.",
        "the opposite case (e.g., expand the type subcat-list always or never expand the type daughters) • take into account only structures under cer",
        "tain paths or again assume the opposite case (e.g., always expand the value under path SYNSEM I LOCI CAT; in addition, it is possible to employ path patterns in the sense of pattern matching) e set the depth of type expansion for a given type Note that we are not restricted to apply only one of these settings – they can be used in combination and can be changed dynamically during processing.",
        "It does make sense, for instance, to expand at certain well-defined points during parsing the (partial) information obtained so far.",
        "If this will not result in a failure, one can throw away (resp.",
        "store) this fully expanded feature structure, working on with the older (and smaller) one.",
        "However, if the information is inconsistent, we roust, backtrack to older stages in computation.",
        "Going this way which of course assumes heuristic knowledge (language as well as grammar-specific knowledge) results in faster processing and copying.",
        "Moreover, the inference engine must be able to handle possibly inconsistent knowledge, e.g., in case of a chart parser to allow for a third kind of edge (besides active and passive ones)."
      ]
    },
    {
      "heading": "3.4.3 Recursive Types, Inaplementational Issues, and Undecidability",
      "text": [
        "The set of all recursive types of a given grammar/lexicon can be precompiled by employing the dependency graph of this type system.",
        "This graph is updated every time a new type definition is added to the system.",
        "Thus detecting whether a given type is recursive or not reduces Lo a simple table lookup.",
        "However the expansion of a recursive type itself is a. little bit harder.",
        "hi TD,C, we are using a lazy expansion technique which only makes those constraints explicit which are really new.",
        "To put it in another way: if no (global or local) control information is specified to guide a specific expansion, a recursive type will be be expanded under all its paths (local plus inherited paths) until one reaches a point where the information is already given in a prefix path.",
        "We call such an expanded structure a resolved typed feature structure.",
        "Of course, there are infinitely many resolved feature structures, but this structure is the most general resolved one.",
        "Take for instance the append example from the previous section.",
        "append is of course a recursive type because one of its alternatives, viz., append].",
        "uses append under the PATCH attribute.",
        "Expanding append with no additional information supplied (especially no path leading inside append e.g., PATCH I PATCH I PATCH) yields a disjunctive feature structure where both append„ and append].",
        "are substituted by their definition.",
        "The expansion then stops if no other information enforce a further expansion.",
        "in practice, one has to keep track of the visited paths and visited typed feature structures to avoid unnecessary expansion.",
        "To make expansion more efficient, we mark structures whether they are fully expanded or not.",
        "A feature structure is then fully expanded if all of its substructures are fully expanded.",
        "This simple idea leads to a massive reduction of the search space when dealing with incremental expansion (e.g., during parsing).",
        "It is worth noting that the satisfiability of feature descriptions admitting recursive type equations/definitions is in general undecidable.",
        "Rounds and Manaster-Ramer [11] were the first having shown that a Kasper-Rounds logic enriched with recursive types allows one to encode a 'l'uring machine.",
        "lie-cause our logic is much more richer, we immediately get the same result for TDE.",
        "However, one can choose in TDE between a complete expansion algorithm which may not terniinate and a non-complete one to guarantee termination (see [2] and [5, Ch.",
        "15] for similar proposals).",
        "The latter case heavily depends on the notion of resolvedness (see above).",
        "In both cases, the depth of the search space can be restricted by specifying a maximal path length."
      ]
    },
    {
      "heading": "4 Comparison with other Systems",
      "text": [
        "TDE is unique in that it implements many novel features not found in other systems like ALE [1], LIFE [2], or TES [1.5].",
        "Of course, these systems provide other features which are not present in our formalism.",
        "What makes TDC unique in comparison to them is the distinction open vs. closed world, the availability of the full boolean connectives and distributed disjunctions (via LIDK:), as well as an iniplemented lazy type expansion mechanism for recursive types (as compared with LIFE).",
        "ALE, for instance, neither allows disjunctive nor recursive types and enforces the type hierarchy to be a BCE°.",
        "However, it makes recursion available through definite relations and incorporates special mechanisms for empty categories and lexical rules.",
        "TES comes up with a closed world, the unavailability of negative information (only implicitly present) and only a poor form of disjunctive information but performs parsing and generation entirely through type deduction (in fact, it was the first system).",
        "LIFT) conies closest to us but provides a semantics for types that is similar to TES.",
        "Moreover the lack of negative information and distributed disjunctions makes it again comparable with TES.",
        "LIFE as a whole can be seen as an extension of Firm-m(4 (as was the case for its predecessor LOGIN), where first-order terms are replaced by 0-terms.",
        "In this sense, LIFE is richer than our formalism in that it offers a full relational calculus."
      ]
    },
    {
      "heading": "5 Summary and Outlook",
      "text": [
        "In this paper, we have presented TD., a typed feature formalism that integrates a powerful feature constraint solver and type system.",
        "Both of them provide the boolean connectives A, V, and where a complex expression is decomposed by employing intermediate types.",
        "Moreover, recursive types are supported as well.",
        "In `MC, a grammar writer decides whether types live in an open or a closed world.",
        "This ef.-[(Jets GLB and L1113 computations.",
        "The type system itself consists of several inference components, each designed to cover efficiently a specific task: (i) a bit vector encoding of the hierarchy, (ii) a fast symbolic simplifier for complex type expressions, (iii) memoization to cache precomputed results, and (iv) a sophisticated type expansion mechanism.",
        "The system as described in this paper has been implemented in COMMON IdsP and integrated in the DISCO environment [14].",
        "The next major version of TD.0 will be integrated into a declarative specification language which allows linguists to define control knowledge that can be used during processing.",
        "In addition, certain forms of knowledge compilation will be made available in future versions of TDE, the automatic detection of syntactic incompatibilities between types, so that, a type computation can substitute an extensive feature term unification."
      ]
    }
  ]
}
