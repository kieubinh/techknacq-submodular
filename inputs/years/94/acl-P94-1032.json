{
  "info": {
    "authors": [
      "Kuang-Hua Chen",
      "Hsin-Hsi Chen"
    ],
    "book": "Annual Meeting of the Association for Computational Linguistics",
    "id": "acl-P94-1032",
    "title": "Extracting Noun Phrases from Large-Scale Texts: A Hybrid Approach and Its Automatic Evaluation",
    "url": "https://aclweb.org/anthology/P94-1032",
    "year": 1994
  },
  "references": [
    "acl-A88-1019",
    "acl-C92-3150",
    "acl-E85-1024",
    "acl-J93-1005",
    "acl-P90-1034",
    "acl-W93-0306"
  ],
  "sections": [
    {
      "heading": "Abstract",
      "text": [
        "To acquire noun phrases from running texts is useful for many applications, such as word grouping, terminology indexing, etc.",
        "The reported literatures adopt pure probabilistic approach, or pure rule-based noun phrases grammar to tackle this problem.",
        "In this paper, we apply a probabilistic chunker to deciding the implicit boundaries of constituents and utilize the linguistic knowledge to extract the noun phrases by a finite state mechanism.",
        "The test texts are SUSANNE Corpus and the results are evaluated by comparing the parse field of SUSANNE Corpus automatically.",
        "The results of this preliminary experiment are encouraging."
      ]
    },
    {
      "heading": "1. Introduction",
      "text": [
        "From the cognitive point of view, human being must recognize, learn and understand the entities or concepts (concrete or abstract) in the texts for natural language comprehension.",
        "These entities or concepts are usually described by noun phrases.",
        "The evidences from the language learning of children also show the belief (Snow and Ferguson, 1977).",
        "Therefore, if we can grasp the noun phases of the texts, we will understand the texts to some extent.",
        "This consideration is also captured by theories of discourse analysis, such as Discourse Representation Theory (Kamp, 1981).",
        "Traditionally, to make out the noun phrases in a text means to parse the text and to resolve the attachment relations among the constituents.",
        "However, parsing the text completely is very difficult, since various ambiguities cannot be resolved solely by syntactic or semantic information.",
        "Do we really need to fully parse the texts in every application?",
        "Some researchers apply shallow or partial parsers (Smadja, 1991; Hindle, 1990) to acquiring specific patterns from texts.",
        "These tell us that it is not necessary to completely parse the texts for some applications.",
        "This paper will propose a probabilistic partial parser and incorporate linguistic knowledge to extract noun phrases.",
        "The partial parser is motivated by an intuition (Abney, 1991): (1) When we read a sentence, we read it chunk by chunk.",
        "Abney uses two level grammar rules to implement the parser through pure LR parsing technique.",
        "The first level grammar rule takes care of the chunking process.",
        "The second level grammar rule tackles the attachment problems among chunks.",
        "Historically, our statistics-based partial parser is called chunker.",
        "The chunker receives tagged texts and outputs a linear chunk sequences.",
        "We assign a syntactic head and a semantic head to each chunk.",
        "Then, we extract the plausible maximal noun phrases according to the information of syntactic head and semantic head, and a finite state mechanism with only 8 states.",
        "Section 2 will give a brief review of the works for the acquisition of noun phrases.",
        "Section 3 will describe the language model for chunker.",
        "Section 4 will specify how to apply linguistic knowledge to assigning heads to each chunk.",
        "Section 5 will list the experimental results of chunker.",
        "Following Section 5, Section 6 will give the performance of our work on the retrieval of noun phrases.",
        "The possible extensions of the proposed work will be discussed in Section 7.",
        "Section 8 will conclude the remarks."
      ]
    },
    {
      "heading": "2. Previous Works",
      "text": [
        "Church (1988) proposes a part of speech tagger and a simple noun phrase extractor.",
        "His noun phrase extractor brackets the noun phrases of input tagged texts according to two probability matrices: one is starting noun phrase matrix; the other is ending noun phrase matrix.",
        "The methodology is a simple version of Garside and Leech's probabilistic parser (1985).",
        "Church lists a sample text in the Appendix of his paper to show the performance of his work.",
        "It demonstrates only 5 out of 248 noun phrases are omitted.",
        "Because the tested text is too small to assess the results, the experiment for large volume of texts is needed.",
        "Bourigault (1992) reports a tool, LEX7'ER, for extracting terminologies from texts.",
        "LEXTER triggers two-stage processing: 1) analysis (by identification of frontiers), which extracts the maximal-length noun phrase: 2) parsing (the maximal-length noun phrases), which, furthermore, acquires the terminology embedded in the noun phrases.",
        "Bourigault declares the LEXTER extracts 95% maximal-length noun phrases, that is, 43500 out of 46000 from test corpus.",
        "The result is validated by an expert.",
        "However, the precision is not reported in the Boruigault's paper.",
        "Voutilainen (1993) announces NProol for acquisition of maximal-length noun phrases.",
        "NPtool applies two finite state mechanisms (one is NP-hostile; the other is NP-friendly) to the task.",
        "The two mechanisms produce two NP sets and any NP candidate with at least one occurrence in both sets will be labeled as the \"ok\" NP.",
        "The reported recall is 98.5-100% and the precision is 95- 98% validated manually by some 20000 words.",
        "But from the sample text listed in Appendix of his paper, the recall is about 85% and we can find some inconsistencies among these extracted noun phrases."
      ]
    },
    {
      "heading": "3. Language Model",
      "text": [
        "Parsing can be viewed as optimizing.",
        "Suppose an n-word sentence, w1.",
        "v,.....w (including punctuation marks), the parsing task is to find a parsing tree T, such that P(71w 1, w.„ wn) has the maximal probability.",
        "We define T here to be a sequence of chunks, c1, c2, ...,Cm and each c, (0 < < in) contains one or more words wj (0 <j n).",
        "For example, the sentence \"parsing can be viewed as optimization.\"",
        "consists of 7 words.",
        "Its one possible parsing result under our demand is:",
        "(2) [parsing] [can be viewed] [as optimization] [.]",
        "Now, the parsing task is to find the best chunk sequence, C*, such that",
        "(3) C* = argmaxP(C, I w' )",
        "The Ci is one possible chunk sequence, cl, c2, cm‘, where in, is the number of chunks of the possible chunk sequence.",
        "To chunk raw text without other information is very difficult, since the word patterns are many millions.",
        "Therefore, we apply a tagger to preprocessing the raw texts and give each word a unique part of speech.",
        "That is, for an n-word sentence, w1, w2.",
        "....w,, (including punctuation marks), we assign part of speeches t1, t2, tn to the respective words.",
        "Now the real working model is: ( 4 ) C* = argniaxP(C, I t,\") Using bi-gram language model, we then reduce P(Cilti,",
        "where P1( • ) denotes the probability for the i'th chunk sequence and co denotes the beginning mark of a sentence.",
        "Following (5), formula (4) becomes",
        "In order to make the expression (6) match the intuition of human being, namely, 1) the scoring metrics are all positive, 2) large value means high score, and 3) the scores are between 0 and 1, we define a score function S(P( • )) shown as (7).",
        "(7) S(P( • ))= 0 when P( • )= 0;",
        "S(P( • ))= 1.0/(1.0+ABS(log(P( )))) o/w.",
        "We then rewrite (6) as (8).",
        "The final language model is to find a chunk sequence C*, which satisfies the expression (8).",
        "Dynamic programming shown in (9) is used to find the best chunk sequence.",
        "The score[i] denotes the score of position i.",
        "The words between position prep] and position i form the best chunk from the viewpoint of position i.",
        "The dscore(cf) is the score of the probability",
        "P(c1) and the cscore(clici-i) is the score of the probability /3(clicr-/).",
        "These scores are collected from the training corpus.",
        "SUSANNE corpus (Sampson, 1993; Sampson, 1994).",
        "The details will be touched on in Section 5.",
        "2. for (i = i<n+1; i++) do 3 and 4; 3. j*=maxarg(score[pre[j]l+dscore(ci)+cscore(cjicj-i)); where ci = ti;",
        "output the word Wpre[i]+1, Wi to form a chunk;"
      ]
    },
    {
      "heading": "4. Linguistic Knowledge",
      "text": [
        "In order to assign a head to each chunk, we first define priorities of POSes.",
        "X'-theory (Sells, 1985) has defined the X'-equivalences shown as Table 1.",
        "Table 1 defines five different phrasal structures and the hierarchical structures.",
        "The heads of these phrasal structures are the first level of X'-Equivalences, that is, X.",
        "The other grammatical constituents function as the specifiers or modifiers, that is, they are accompanying words not core words.",
        "Following this line, we define the primary priority of PUS listed in Table 1.",
        "(10) Primary POS priority' : V>N> A>P",
        "In order to extract the exact head, we further define Secondary POS priority among the 134 POSes defined in LOB corpus (Johansson, 1986).",
        "(11) Secondary PUS priority is a linear precedence relationship within the primary priorities for coarse POSes",
        "We do not consider the INFL.",
        "since our model will not touch on this structure.",
        "For example, LOB corpus defines four kinds of verbial words under the coarse PUS V: VB*, DO*, BE* and HV*2.",
        "The secondary priority within the coarse POS V is:",
        "(12) VB* > FiV* > DO* > BE*",
        "Furthermore, we define the semantic head and the syntactic head (Abney, 1991).",
        "(13) Semantic head is the head of a phrase according to the semantic usage; but syntactic head is the head based on the grammatical relations.",
        "Both the syntactic head and the semantic head are useful in extracting noun phrases.",
        "For example, if the semantic head of a chunk is the noun and the syntactic one is the preposition, it would be a prepositional phrase.",
        "Therefore, it can be connected to the previous noun chunk to form a new noun phrase.",
        "In some case, we will find some chunks contain only one word, called one-word chunks.",
        "They maybe contain a conjunction, e.g., that.",
        "Therefore, the syntactic head and the semantic head of one-word chunks are the word itself.",
        "Following these definitions, we extract the noun phrases by procedure (14):",
        "(14) (a) Tag the input sentences.",
        "(b) Partition the tagged sentences into chunks by using a probabilistic partial parser.",
        "(c) Decide the syntactic head and the",
        "semantic head of each chunk.",
        "(d) According to the syntactic and the semantic heads, extract noun phrase from these chunks and connect as many noun phrases as possible by a finite state mechanism.",
        "2 Asterisk * denotes wildcard.",
        "Therefore, VB* represents VB (verb, base form), VBD (verb, preterite), VBG (present participle), VBN (past participle) and VBZ (3rd singular form of verb).",
        "a chunker.",
        "The tag sets of LOB and SUSANNE are different.",
        "Since the tag set of SUSANNE corpus is subsumed by the tag set of LOB corpus, a TAG-MAPPER is used to map tags of SUSANNE corpus to those of LOB corpus.",
        "The chunker will output a sequence of chunks.",
        "Finally, a finite state NP-TRACTOR will extract NPs.",
        "Figure 2 shows the finite state mechanism used in our work.",
        "The symbols in Figure 2 are tags of LOB corpus.",
        "N* denotes nous; P* denotes pronouns; ,1* denotes adjectives; A* denotes quantifiers.",
        "qualifiers and determiners; IN denotes prepositions; CD* denotes cardinals; OD* denotes ordinals, and NR* denotes adverbial nouns.",
        "Asterisk * denotes a wildcard.",
        "For convenience, some constraints, such as syntactic and semantic head checking, are not shown in Figure 2."
      ]
    },
    {
      "heading": "5. First Stage of Experiments",
      "text": [
        "Following the procedures depicted in Figure 1, we should train a chunker firstly.",
        "This is done by using the SUSANNE Corpus (Sampson, 1993; Sampson, 1994) as the training texts.",
        "The SUSANNE Corpus is a modified and condensed version of Brown Corpus (Francis and Kucera, 1979).",
        "It only contains the 1/10 of Brown Corpus, but involves more information than Brown Corpus.",
        "The Corpus consists of four kinds of texts: 1) A: press reportage; 2) G: belles letters, biography, memoirs; 3) J: learned writing; and 4) N: adventure and Western fiction.",
        "The Categories of A, G. J and N are named from respective categories of the Brown Corpus.",
        "Each Category consists of 16 files and each file contains about 2000 words.",
        "The following shows a snapshot of SUSANNE Corpus.",
        "In order to avoid the errors introduced by tagger, the SUSANNE corpus is used as the training and testing texts.",
        "Note the tags of SUSANNE corpus are mapped to LOB corpus.",
        "The 3/4 of texts of each categories of SUSANNE Corpus are both for training the chunker and testing the chunker (inside test).",
        "The rest texts are only for testing (outside test).",
        "Every tree structure contained in the parse field is extracted to form a potential chunk grammar and the adjacent tree structures are also extracted to form a potential context chunk grammar.",
        "After the training process, total 10937 chunk grammar rules associated with different scores and 37198 context chunk grammar rules are extracted.",
        "These chunk grammar rules are used in the chunking process.",
        "Table 3 lists the time taken for processing SUSANNE corpus.",
        "This experiment is executed on the Sun Sparc 10, model 30 workstation.",
        "T denotes time, W word, C chunk, and S sentence.",
        "Therefore, T/W means the time taken to process a word on average.",
        "According to Table 3, to process a word needs 0.00291 seconds on average.",
        "To process all SUSANNE corpus needs about 436 seconds, or 7.27 minutes.",
        "In order to evaluate the performance of our chunker, we compare the results of our chunker with the denotation made by the SUSANNE Corpus.",
        "This comparison is based on the following criterion: (15) The content of each chunk should be dominated by one non-terminal node in SUSANNE parse field.",
        "This criterion is based on an observation that each non-terminal node has a chance to dominate a chunk.",
        "Table 4 is the experimental results of testing the SUSANNE Corpus according to the specified criterion.",
        "As usual, the symbol C denotes chunk and S denotes sentence.",
        "Table 4 shows the chunker has more than 98% chunk correct rate and 94% sentence correct rate in outside test, and 99% chunk correct rate and 97% sentence correct rate in inside test.",
        "Note that once a chunk is mischopped, the sentence is also mischopped.",
        "Therefore, sentence correct rate is always less than chunk correct rate.",
        "Figure 3 gives a direct view of the correct rate of this chunker."
      ]
    },
    {
      "heading": "6. Acquisition of Noun Phrases",
      "text": [
        "We employ the SUSANNE Corpus as test corpus.",
        "Since the SUSANNE Corpus is a parsed corpus, we may use it as criteria for evaluation.",
        "The volume of test texts is around 150,000 words including punctuation marks.",
        "The time needed from inputting texts of SUSANNE Corpus to outputting the extracted noun phrases is listed in Table 5.",
        "Comparing with Table 3, the time of combining chunks to form the candidate noun phrases is not significant.",
        "The evaluation is based on two metrics: precision and recall.",
        "Precision means the correct rate of what the system gets.",
        "Recall indicates the extent to which the real noun phrases retrieved from texts against the real noun phrases contained in the texts.",
        "Table 6 describes how to calculate these metrics.",
        "The rows of \"System\" indicate our NP-TRACTOR thinks the candidate as an NP or not an NP; the columns of \"SUSANNE\" indicate SUSANNE Corpus takes the candidate as an NP or not an NP.",
        "Following Table 6, we will calculate precision and recall shown as (16).",
        "To calculate the precision and the recall based on the parse field of SUSANNE Corpus is not so straightforward at the first glance.",
        "For example, (17)3 itself is a noun phrse but it contains four noun phrases.",
        "A tool for extracting noun phrases should output what kind of and how many noun phrases, when it processes the texts like (17).",
        "Three kinds of noun phrases (maximal noun phrases, minimal noun phrases and ordinary noun phrases) are defined first.",
        "Maximal noun phrases are those noun phrases which are not contained in other noun phrases.",
        "In contrast, minimal noun phrases do not contain any other noun phrases.",
        "Apparently, a noun phrase may be both a maximal noun phrase and a minimal noun phrase.",
        "Ordinary noun phrases are noun phrases with no restrictions.",
        "Take (17) as an example.",
        "It has three minimal noun phrases, one maximal noun phrases and five ordinary noun phrases.",
        "In general, a noun-phrase extractor forms the front end of other applications, e.g., acquisition of verb subcategorization frames.",
        "Under this consideration, it is not appropriate to taking (17) as a whole to form a noun phrase.",
        "Our system will extract two noun phrases from (17), \"a black badge of frayed respectability\" and \"his neck\".",
        "(17) [Ha black badge] of [frayed respectability]] that ought never to have left [his neck]] We calculate the numbers of maximal noun phrases, minimal noun phrases and ordinary noun phrases denoted in SUSANNE Corpus, respectively and compare these numbers with the number of noun phrases extracted by our system.",
        "Table 7 lists the number of ordinary noun phrases (NP), maximal noun phrases (MNP), minimal noun phrases (mNP) in SUSANNE Corpus.",
        "MmNP denotes the maximal noun phrases which are also the minimal noun phrases.",
        "On average, a maximal noun phrase subsumes 1.61 ordinary noun phrases and 1.09 minimal noun phrases.",
        "To calculate the precision.",
        "we examine the extracted noun phrases (ENP) and judge the correctness by the SUSANNE Corpus.",
        "The CNP denotes the correct ordinary noun phrases.",
        "CMNP the correct maximal noun phrases.",
        "CmNP correct minimal noun phrases and CMmNP the correct maximal noun phrases which are also the minimal noun phrases.",
        "The results are itemized in Table 8.",
        "The average precision is 95%.",
        "Here, the computation of recall is ambiguous to some extent.",
        "Comparing columns CMNP and CmNP in Table 8 with columns MNP and mNP in Table 7.",
        "70% of MNP and 72% of mNP in SUSANNE Corpus are extracted.",
        "In addition, 95% of MmNP is extracted by our system.",
        "It means the recall for extracting noun phrases that exist independently in SUSANNE Corpus is 95%.",
        "What types of noun phrases are extracted are heavily dependent on what applications we will follow.",
        "We will discuss this point in Section 7.",
        "Therefore, the real number of the applicable noun phrases in the Corpus is not known.",
        "The number should be between the number of NPs and that of MNPs.",
        "In the original design for NP-TRACTOR, a maximal noun phrase which contains clauses or prepositional phrases with prepositions other than \"of' is not considered as an extracted unit.",
        "As the result, the number of such kinds of applicable noun phrases (ANPs) form the basis to calculate recall.",
        "These numbers are listed in Table 9 and the corresponding recalls are also shown.",
        "The automatic validation of the experimenta results gives us an estimated recall.",
        "Appendix provides a sample text and the extracted noun phrases.",
        "Interested readers could examine the sample text and calculate recall and precision for a comparison."
      ]
    },
    {
      "heading": "7. Applications",
      "text": [
        "Identification of noun phrases in texts is useful for many applications.",
        "Anaphora resolution (Hirst, 1981) is to resolve the relationship of the noun phrases, namely, what the antecedent of a noun phrase is.",
        "The extracted noun phrases can form the set of possible candidates (or universal in the terminology of discourse representation theory).",
        "For acquisition of verb subcategorization frames, to bracket the noun phrases in the texts is indispensable.",
        "It can help us to find the boundary of the subject, the object and the prepositional phrase.",
        "We would use the acquired noun phrases for an application of adjective grouping.",
        "The extracted noun phrases may contain adjectives which pre-modify the head noun.",
        "We then utilize the similarity of head nouns to group the adjectives.",
        "In addition, we may give the head noun a semantic tag, such as Roget's Thesaurus provides, and then analyze the adjectives.",
        "To automatically produce the index of a book,",
        "we would extract the noun phrases contained in the book, calculate the inverse document frequency (IDF) and their term frequency (TF) (Salton, 1991), and screen out the implausible terms.",
        "These applications also have impacts on identifying noun phrases.",
        "For applications like anaphora resolution and acquisition of verb subcategorization frames, the maximal noun phrases are not suitable.",
        "For applications like grouping adjectives and automatic book indexing, some kinds of maximal noun phrases, such as noun phrases postmodified by \"of' prepositional phrases, are suitable: but some are not, e.g., noun phrases modified by relative clauses."
      ]
    },
    {
      "heading": "8. Concluding Remarks",
      "text": [
        "The difficulty of this work is how to extract the real maximal noun phrases.",
        "If we cannot decide the prepositional phrase \"over a husband eyes\" is licensed by the verb \"pull\", we will not know \"the wool\" and \"a husband eyes\" are two noun phrases or form a noun pharse combined by the preposition \"over\".",
        "(18) to pull the wool over a husband eyes to sell the books of my uncle In contrast, the noun phrase \"the books of my uncle\" is so called maximal noun phrase in current context.",
        "As the result, we conclude that if we do not resolve PP-attachment problem (Hindle and Rooth, 1993), to the expected extent, we will not extract the maximal noun phrases.",
        "In our work, the probabilistic chunker decides the implicit boundaries between words and the NP-TRACTOR connects the adjacent noun chunks.",
        "When a noun chunk is followed by a preposition chunk, we do not connect the two chunks except the preposition chunk is led by \"of' preposition.",
        "Comparing with other works, our results are evaluated by a parsed corpus automatically and show the high precision.",
        "Although we do not point out the exact recall, we provide estimated values.",
        "The testing scale is large enough (about 150,000 words).",
        "In contrast, Church (1988) tests a text and extracts the simple noun phrases only.",
        "Bourigault's work (1992) is evaluated manually, and dose not report the precision.",
        "Hence, the real performance is not known.",
        "The work executed by Voutilainen (1993) is more complex than our work.",
        "The input text first is morphologizied, then parsed by constraint grammar, analyzed by two different noun phrases grammar and finally extracted by the occurrences.",
        "Like other works, Voutilainen's work is also evaluated manually.",
        "In this paper, we propose a language model to chunk texts.",
        "The simple but effective chunker could be seen as a linear structure parser, and could be applied to many applications.",
        "A method is presented to extract the noun phrases.",
        "Most importantly, the relations of maximal noun phrases, minimal noun phrases, ordinary noun phrases and applicable noun phrases are distinguished in this work.",
        "Their impacts on the subsequent applications are also addressed.",
        "In addition, automatic evaluation provides a fair basis and does not involve human costs.",
        "The experimental results show that this parser is a useful tool for further research on large volume of real texts."
      ]
    },
    {
      "heading": "Acknowledgements",
      "text": [
        "We are grateful to Dr. Geoffrey Sampson for his kindly providing SUSANNE Corpus and the details of tag set to us."
      ]
    },
    {
      "heading": "References",
      "text": []
    },
    {
      "heading": "Appendix",
      "text": [
        "For demonstration, we list a sample text quoted from N I 8:0010a-N18 :0250e, SUSANNE Corpus.",
        "The extracted noun phrases are bracketed.",
        "We could compute the precision and the recall from the text as a reference and compare the gap with the experimental results itemized in Section 6.",
        "In actual, the result shows that the system has high precision and recall for the text."
      ]
    }
  ]
}
