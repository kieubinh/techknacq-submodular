{
  "info": {
    "authors": [
      "Timothy A. Cartwright",
      "Michael R. Brent"
    ],
    "book": "Workshop on Computational Phonology",
    "id": "acl-W94-0208",
    "title": "Segmenting Speech Without a Lexicon: The Roles of Phonotactics and Speech Source",
    "url": "https://aclweb.org/anthology/W94-0208",
    "year": 1994
  },
  "references": [],
  "sections": [
    {
      "heading": ".Abstract",
      "text": [
        "Infants face the difficult problem of segmenting continuous speech into words without the benefit of a fully developed lexicon.",
        "Several sources of information in speech might help infants solve this problem, inchiding prosody, semantic correlations and phonotactics.",
        "Research to date has focused on determining to which of these sources infants niight.",
        "be sensitive, but little work has been done to determine the potential usefulness of each source.",
        "The computer simulations reported here are a first attempt to tneasure the usefulness of distributional and phonotactic information in segmenting phoneme sequences.",
        "The algorithms hypothesize diffemtl.",
        "segmentations of the input into wiirds and select, the best.",
        "hypothesis according to the Minimum Description Length principle.",
        "Our results indicate that.",
        "while there is some useful int.",
        "(mnation in both phoneme distributions and phonottictic rules, the combination of both soil rces is most.",
        "useful."
      ]
    },
    {
      "heading": "INTRODUCTION",
      "text": [
        "infants must, leant to recognize certain sound sequences as being words; this is a difficult problem because normal speech contains no obvious acoustic divisions between words.",
        "l'wo sources ()I' information that might aid speech segmentation are: distribution the phoneme sequence in cut appears frequently in several contexts including litecat, c(tis and c(atutp, whereas the sequence in vain is rare and, appears in restricted contexts; and phonotactics eat is an acceptable syllable in English, whereas peat is nol..",
        "While evidence exists that infants are sensitive to these information sources, we know of no ineasuremeas of their usefulness.",
        "In this paper, we attempt to quantify the usefulness of distribution and phonotactics in segmenting speech.",
        "We found that.",
        "each source provided some useful information for speech segmentation, but the combination of sources provided substantial information.",
        "We also found that child-directed siteech was much easier to segment than adult-directed speech when using both sources.",
        "To date, psychologists have focused on two aspects of the speech segmentation problem.",
        "The first is the problem of parsing continuous speech into words given a developed lexicon to which incoming sounds can be matched; both psychologists (e.g., Cutler & Carter, 1987; Cutler & Butterfield, 1992) and designers of speech-recognition systems (e.g., Church, 1987) have examined this problem.",
        "However, the problem we examined is different – we want to know how infants segment speech before knowing which phonemic sequences form words.",
        "'rite second aspect psychologists have focused mu is the problem of determining the information sources to which infants are sensitive.",
        "Primarily, two sources have been examined: prosody and word stress.",
        "Results suggest.",
        "that, parents exaggerate prosody in child-directed speech to highlight important words (Fer-nald & Mazzie, 1991; Aslin, Woodward, LaMendola Bever, in press) and that infants are sensitive to prosody (e.g., Hirsh-Pasek et al., 1987).",
        "Word stress in English fairly accurately predicts the location of word beginnings (Cutler & Norris, 1988; Cutler & Butterfield, 1992); Jusczyk, Cutler and Redanz (1993) demonstrated that 9-month-olds (but not 6-month-olds) are sensitive to the common strong/weak word stress pattern in English.",
        "Sensitivity to native-language phonotactics in 9-month-olds was recently reported by Jusczyk, Friederici, Wessels, Svenkerud and Jusczyk (1993).",
        "These studies demonstrated infants' perceptive abilities without demonstrating the usefulness of in rants' perceptions.",
        "How do children combine the information they perceive front different sources?",
        "Aslin et al.",
        "speculate that.",
        "infants first learn words heard in isolation, then use distribution and prosody to refine and expand their vocabulary; however, Jusczyk (1993) suggests that sound sequences learned in isolation differ too greatly front those in context.",
        "to be useful.",
        "He goes on to say, \"just how far information in the sound structure of the input can",
        "pies, we see that Hypothesis 1 uses 48 characters arid Hypothesis 2 uses 75.",
        "However, this simplistic method is inefficient; for instmice, the length of lexical indices are arbitrary with respect to properties of the words themselves (e.g., in Hypothesis 2, there is no reason why /jul/ was assigned the index '10' – length two – instead of '9' – length one).",
        "Our system improves upon this simple size metric by computing sizes based on a compact, representation motivated by information theory.",
        "We imagine hypotheses represented as a string of ones and zeros.",
        "'['his binary string must, represent not only the lexical entries, their indices (called code words) and the coded sample, but also overhead information specifying the number of items coded and their arrangement in the string (information implicitly given by spacing and spatial placement in the introductory examples).",
        "Furthermore, the string and its components must be self-delimiting, so that a decoder could identify the endpoints of components by itself.",
        "The next section describes the binary representation and the length formulae derived from it in detail; readers satisfied with the intuitive descriptions presented so far should skip ahead to the Phonotactics subsection."
      ]
    },
    {
      "heading": "Representation and Length Formulw",
      "text": [
        "The representation scheme described below is based on information theory (for more examples of coding systems, see, e.g., Li XL Vitanyi, 1993 and Quinlan & Rivest, 1989).",
        "From this representation, we can derive a formula describing its length in bits.",
        "However, the discrete form of the formula would not work well in practice for our simulations.",
        "Instead, we use a continuous approximation of the discrete formula; this approximation typically involves dropping the ceiling function from length computations.",
        "For example, we sometimes use a self-delimiting representation for integers (as described in Li Sz Vitanyi, pp.",
        "74-75).",
        "In this representation, the number of bits needed to code an integer x is given by",
        "Using the discrete formula, the difference between (2)(126) and 62)(127) is zero, while the difference between .62)(127) and t(2)(128) is one bit; using the continuous formula, the difference between 62)(126) and £(2)(127) is 0.0156, while the difference between 02)(127) and e,(2)(128) is 0.0155.",
        "We found it easier to interpret the results using a con-tinuons function, so in the following discussion, we will only present the approximal.c formula!.",
        "The lexicon lists words (represented as phoneme sequences) paired With their code wordsl .",
        "For example;",
        "In the binary representation, the two columns are represented separately, one after the other; the first column is called the word inventory column; the second column is called the code word inventory column.",
        "In the word inventory column (see Figure I a for a schematic), the list of lexical items is represented as a continuous string of phonemes, without.",
        "separators between words (e.g., 6okoetkItisi... ).",
        "To mark the boundaries between lexical items, the phoneme string is preceded by a list, of integers representing the lengths (in phonemes) of each word.",
        "Each length is represented as a fixed-length, zero-padded binary number.",
        "Preceding this list, is a single integer denoting the length of each length field; this integer is represented in unary, so that its length need not be known in advance.",
        "Preceding the entire column is the number of lexical entries it coded as a self-delimiting integer.",
        "The length of the representation of the IIIi.eger n is given by the function",
        "We define 1 en(tvi) to be the number of phonemes in word IN.",
        "If there are p total unique phonemes used in the sample, then we represent.",
        "each phoneme as a fixed-length bit, string of length len(p) = log, p. So, the length of the representation of a word wi in the lexicon is the number of phonemes in the word times the length of a phoneme: len(p) • LON).",
        "The total length of all the words in the lexicon is the sum of this formula over all lexical items:",
        "As stated above, the length fields used to divide the phoneme string are fixed-length.",
        "field is an integer between one and the number of phonemes in the longest word.",
        "Since representing integers between one and x takes log, x bits, the length of each field is:",
        "ii %ode words are represented by square bradots, [11 means 'the code word corresponding to (I) I ootstrap the ac(pOsition of other levels [of linguistic organization] remains to be determined.\"",
        "In this paper, we measure the potential roles of distribution, phonotaetics and their combination using a computer-simulated learning algorithm; the simulation is based on a bootstrapping model in which phonotactic 'knowledge is used to constrain the distributional analysis of speech samples.",
        "While our work is in part motivated by the above research, other developmental research supports certain assuMptions we make.",
        "The input to our system is represented as a sequence of phonemes, so we implicitly assume that infants are able to t.mivert frot» acoustic input to phoneme sequences; research by Kuhl (e.g., (.rieser k, Kuhl, 1989) suggests that, this assumption is reasonable.",
        "Since sentence boundaries provide information about word boundaries (the end of a sentence is also the end of a word), our input contains sentence boundaries; several studies (Bernstein-Rattier, 1985; I lirsh-Pasek et al., 1987; Kemler No 1 lirsh-l'asek, Jusczyk ■kr, Wright Cassidy, 1989; Jusczyk el.",
        "at, 1992) have shown that infants can perceive sentence boundaries using prosodic cues.",
        "!however, Fishier and Tokura (in press) found no evidence that prosody can accurately predict word boundaries, So the task of finding words remains.",
        "Finally, one might question whether infants have the ability we are trying to model – that is, whether they can identify words embedded in sentences; Jusczyk and Aslin (submitted) found that 7 1/2-R1011th-olds can do so."
      ]
    },
    {
      "heading": "The Model",
      "text": [
        "To gain an intuitive understanding of our model, consider the following speech sample (transcription is in IPA): Orthography: Do you see the kitty?",
        "See the kitty?",
        "Do you like the kitty?",
        "Transcription: dujusiOokIti siOok1Li dujulatkOakiti There are many different ways to break this sample into putative Words (each particular segmentation is called a segmentation hypothesis).",
        "Two suck hypotheses are: Segmentation 1: du ju si o kiti si ela du ju hail( Oa kilti Segmentation 2: duj us i3 °k it i Si( ak iti dii jul ;IA Oak lti Listing the words used by each segmentation hypothesis yields the following two lexicons:",
        "Note that Segmentation 1, the correct hypothesis, yields a compact lexicon of frequent words whereas Segmentation 2 yields a much larger lexicon of infrequent words.",
        "Also note that a lexicon contains only the words used in the sample – no words are known to the system a priori, nor are any carried over froni one hypothesis to the next.. (liven a lexicon, the sample can be encoded by replacing words with their respective indices into the lexicon:",
        "Our simulation attempts to find the hypothesis that minimizes the combined sizes of the lexicon and encoded sample.",
        "This approach is called the Minimum Description Length (MDL) paradigm and has been used recently in other domains to analyze distributional information (Li & Vitanyi, 1993; Rissanen, 1978; Ellison, 1992, 1994; Brent, 1993).",
        "For reasons explained in the next section, the system converts these character-based representations to compact binary representations, using the number of bits in the binary string as a measure of size.",
        "Phonotactic rules can be used to restrict the segmentation hypothesis space by preventing word boundaries at certain places; for instance, ikal.spJz/ (\"(at's paws\") has six internal segmentation points (k wtspJz, 151 ):)z only two of which are phonotactically allowed (kwt sow and kwts pDz).",
        "To evaluate the usefulness of phonotactic knowledge', we compared results between phonotactically constrained and unconstrained simulations."
      ]
    },
    {
      "heading": "SIMULATION DETAILS",
      "text": [
        "To use the MDL principle, as introduced above, we search for the smallest-sized hypothesis.",
        "We must have some well-defined method of measuring hypothesis sizes for this method to work.",
        "A simple, intuitive way of rneasuing the size of a hypothesis is to count the number of characters used to represent it.",
        "For example, counting the characters (excluding spaces) in the introductory exam",
        "To be fully self-delimiting, the width of a field must be represented in a self-delimiting way; we use a unary representation – i.e., write an extra field consisting of only '1' bits followed by a terminating '0'.",
        "There are n fields (one for each word), plus the unary prefix, so the combined length of the fields plus prefix (plus terminating zero) is:",
        "The total length of the word inventory column representation is the sum of the terms in (1), (2) and (3).",
        "The code word inventory column of the lexicon (see Figure lb for a schematic) has a nearly identical representation as the previous column except that code words are listed instead of phonemic words – the length fields and unary prefix serve the same purpose of marking the divisions between code words.",
        "The sample can be represented most compactly by assigning short code words to frequent words, reserving longer code words for infrequent words.",
        "To satisfy this property, code words are assigned so that, their lengths are frequency-based; the length of the code word for a word of frequency f (w) will not be greater than:",
        "The total length of the code word list is the sum of the code word lengths over all lexical entries:",
        "As in the word inventory column (described above), the length of each code word is represented in a fixed-length field.",
        "Since the least frequent word will have the longest code word (a property of the formula for ten([wd)), the longest possible code word comes from a word of frequency one: log, T = log2 m Since the fields contains integers between one and this number, we define the length of a field to be: log„(log„ As above, we represent the width of a field in unary, so there are a total of n 1 elements of this size (n fields plus the unary representation of the field width).",
        "The combined length of the fields plus prefix (and terminating zero) is:",
        "The total length of the code word inventory column representation is the sum of the terms in (1) and (5).",
        "Finally, the sequence of words which form the sample (see Figure lc for a schematic) is represented as the number of words in the sample (70 followed by the list, of code words.",
        "Since code words are used as compact indices into the lexicon, the original sample could be reconstructed completely by looking up each code word in this list and replacing it with its phoneme sequence from the lexicon.",
        "The code words we assigned to lexical items are self-delimiting (once the set of codes is known), so there is no need to represent the boundaries between code words.",
        "The length of the representation of the integer Ul is given by the function",
        "The length of the representation of the sample is computed by summing the lengths of the code words used to represent the sample.",
        "We can simplify this description by noting that.",
        "the combined length of all occurrences of a particular code word [wi] is f(w) • /en({wd) since there are f (wi) occurrences of the code word in the sample.",
        "So, the length of the encoded sample is the sum of this formula over all words in the lexicon:",
        "The total length of the sample is given by adding the terms in (6) and (7).",
        "The total length of the representation of the entire hypothesis is the stun of the representation lengths of the word inventory column, the rode word inventory column and the sample.",
        "Each simulation was run on each sample, for a tu.",
        "tat of twelve 1)1sT runs.",
        "Finally, two other simulations were run on each sample to measure chance performance: .",
        "(1) RAND-FREE inserted random segmentation points and reported the resulting hypothesis, (2) RAND-PHONO inserted random segmentation points where permitted by the phonotactic constraints.",
        "Since the RAND simulations were given the number of segmentation points to add (equal to the number of segmentation points needed to produce the natural English segmentation), their performance is an upper bound on chance performance.",
        "In contrast, the DisT simulations must determine the number of segmentation points to add using M DI, evaluations.",
        "he results for each RAND simulation are averages over 1,000 trials on each input sample."
      ]
    },
    {
      "heading": "RESULTS",
      "text": [
        "Each simulation was scored for the number of correct segmentation points inserted, as compared to the natural English segmentation.",
        "From this scoring, two values were computed: recall, the percent of all correct segmentation points that were actually found; and accuracy, the percent of the hypothesized segmentation points that were actually correct.",
        "In terms of hits, false alarms and misses, we have:",
        "Results are given in Table 1.",
        "Note that there is a trade-off between recall and accuracy – if all possible segmentation points were added, recall would be 100% but accuracy would be low; likewise, if only one segmentation point was added between two words, accuracy would be 100% but recall would be low.",
        "Since our goal is to correctly segment speech, accuracy is more important than Ii nding every correct segmentation.",
        "For exa.mple, deciding littlekitty' is a word is less disastrous than deciding `Ii', 'tie', `ki' and `ty' are all words, because assigning meaning to littlekitty' is a reasonable first try at learning word-meaning pairs, whereas trying to assign separate meanings to 'IF and 'tie' is problematic.",
        "The performance of 1)isT-1)noNo on child-directe(I speech shows that this system goes a long way toward solving the segmentation problem.",
        "However, comparing the average performances of simulations is also useful.",
        "The effect of phonotactic information can be seen by comparing the average performances of RAND-FREE and RAND-FDONO, since the only difference between them is the addition of phonotactic constraints on seg-inetitations in the latter.",
        "Clearly phonotactic constraints are useful, as both recall and accuracy improve.",
        "A similar comparison between RAND-FREE and DIST-FREE shows that distributional information alone also improves performance.",
        "Note in all the results of DIST-FREE that using distributional information alone favors recall over accuracy; in fact, the segmentation hypotheses produced by DIST-FREE have most words broken into single phoneme units with only a handful of words remaining intact.",
        "Two comparisons are needed to show that the conibination of distributional and phonotactic in performs better Chilli either source alone: DIsT-PitoNo compared co RAND-PDONO, to see the effect of iulding distributional analysis to phonotactic constraints, and DIST-PlIONO compared to DIST-FREE, to see the effect of adding phonotactic constraints I.o distributional analysis.",
        "The former comparison shows that the sources combined are more useful than phonotactic information alone.",
        "The latter comparison is less obvious – the trade-off between recall and accuracy seems to have reversed, with no clear winner5.",
        "Data on discovered word types helps make this comparison: DIsT- FREE found 12% of the words with 30% accuracy and DIST-PHONO found 33% of the words with 50% accuracy.",
        "Whereas the segmentation point data are inconclusive, word type data demonstrate that combining information sources is more useful than using distributional information alone.",
        "There is no obvious difference in performance between child and adult-directed speech, except.",
        "in DisT-PtioNo (combined information sources) in which the difference is striking: accuracy remains high and recall rate more than triples for child-directed speech.",
        "This difference is again supported by word type data: 14% recall with :30% accuracy for adult-directed speech, 56% recall with 65% accuracy for child-directed speech."
      ]
    },
    {
      "heading": "DISCUSSION",
      "text": [
        "Our technique segments continuous speech into words using only distributional and phonotactic information more effectively than one might expect – up to 66% recall of segmentation points with 92% accuracy on one sample, which yields 58% recall of word types with 67% accuracy (the relatively low type accuracy is mitigated by the fact that most incorrect words are nieaninglnl concatenations of correct, words --e.g., 'thekitty').",
        "This finding confirms the idea that distribution mid phonotactics are useful sources of information that infants might use in discovering words (e.g., Jusczyk et al., 1993b).",
        "In fact, it helps explain in-fants' ability to k•arn words froni parental speech: these two sources alone are useful and infants have several others, like prosody and word stress patterns, available as well.",
        "It also suggests that semantics and isolated words need not play as central a role as one Might think (e.g., Jusczyk, 1993, downplayed the utility of words in isolation).",
        "It is difficult, if not impossible given currently available methods, to determine which sources of information are necessary: for infants to segment speech and learn words; only this sort of indirect evidence is available to us.",
        "The results show a difference between adult-and child-directed speech, in that the latter is easier to segment given both distribution and phonotactics.",
        "This let Is quantitative support, to research which suggests that motherese differs from normal adult speech in ways possibly useful to the language-learning infant (Aslin et al.).",
        "In fact, the factors making motherese more learnable might be elucidated using this technique: compare the results of several different models, each containing a different factor or combination of factors, looking for those in which a substantial performance difference exists between child and adult-directed SI wech.",
        "Our model uses phonotactic constraints as absolute requirements on the structure of it words; this implies that phonotactics have been learned prior to at at segrnentation.",
        "We must therefore show that phonotactics can indeed lw learned withoid.",
        "access to a lexicon –without such a demonstration, we are trapped in circular reasoning.",
        "Clafos and Brent (1994) demonstrate that phonotactics can be learned with high accuracy from the same unsegmented utterances we used in our simulations.",
        "In general, two methods exist for combining information sources in the M DI, paradigm: one is to have absolute requirements On plausible hypotheses (like our phonotactic constraints) these requirements must be independently learnable; the other method of combination is to include an information source in the internal representation of hypotheses (like our distributional inforrnation)----all components of the representation are learned simultaneously (see Ellison, 1992, for an example of multiple components in a representation).",
        "We would like to extend the system by using a more detailed transcription system.",
        "We expect that this would help the system find word boundaries for reasons detailed in Church (1987) – in brief, that allophonic variation may be quite useful in predicting word boundaries.",
        "Another simpler extension of this research will be to increase the length of the speelli samples used.",
        "Finally, we will try the current system on samples from other languages, to make sure this method generalizes appropriately.",
        "This research program will provide complementary evidence supporting hypotheses about the sources of information infants use in learning their native languages.",
        "Until now, research has focused on demonstrations of infants' sensitivity to various sources; we have begun to provide quantitative measures of the usefulness of those sources."
      ]
    }
  ]
}
