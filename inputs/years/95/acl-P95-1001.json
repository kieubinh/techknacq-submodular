{
  "info": {
    "authors": [
      "Gary Tajchman",
      "Daniel Jurafsky",
      "Eric Fosler-Lussier"
    ],
    "book": "Annual Meeting of the Association for Computational Linguistics",
    "id": "acl-P95-1001",
    "title": "Learning Phonological Rule Probabilities from Speech Corpora With Exploratory Computational Phonology",
    "url": "https://aclweb.org/anthology/P95-1001",
    "year": 1995
  },
  "references": [
    "acl-J94-3007"
  ],
  "sections": [
    {
      "heading": "Abstract",
      "text": [
        "This paper presents an algorithm for learning the probabilities of optional phonological rules from corpora.",
        "The algorithm is based on using a speech recognition system to discover the surface pronunciations of words in speech corpora; using an automatic system obviates expensive phonetic labeling by hand.",
        "We describe the details of our algorithm and show the probabilities the system has learned for ten common phonological rules which model reductions and coarticulation effects.",
        "These probabilities were derived from a corpus of 7203 sentences of read speech from the Wall Street Journal, and are shown to be a reasonably close match to probabilities from phonetically hand-transcribed data (TIMIT).",
        "Finally, we analyze the probability differences between rule use in male versus female speech, and suggest that the differences are caused by differing average rates of speech."
      ]
    },
    {
      "heading": "1 Introduction",
      "text": [
        "Phonological rules have formed the basis of phonological theory for decades, although their form and their coverage of the data has changed over the years.",
        "Until recently, however, it was difficult to determine the relationship between handwritten phonological rules and actual speech data.",
        "The current availability of large speech corpora and pronunciation dictionaries has allowed us to connect rules and speech in much tighter ways.",
        "For example, a number of algorithms have recently been proposed which automatically induce phonological rules from dictionaries or corpora (Gasser 1993; Ellison 1992; Daelemans et al.",
        "1994).",
        "While such algorithms have successfully induced syllabicity or harmony constraints, or simple oblig",
        "atory phonological rules, there has been much less work on non-obligatory (optional) rules.",
        "In part this is because optional rules like flapping, vowel reduction, and various coarticulation effects are postlexical and often products of fast speech, and hence have been considered less central to phonological theory.",
        "In part, however, this is because optional rules are inherently probabilistic.",
        "Where obligatory rules apply to every underlying form which meets the environmental conditions, producing a single surface form, optional rules may not apply, and hence the underlying form may appear as the surface form, unmodified by the rule.",
        "This makes the induction problem non-deterministic, and not solvable by the above algorithms.",
        "1 While optional rules have received less attention in linguistics because of their probabilistic nature, in speech recognition, by contrast, optional rules are commonly used to model pronunciation variation.",
        "In this paper, we employ techniques from speech recognition research to address the problem of assigning probabilities to these optional phonological rules.",
        "We introduce a completely automatic algorithm that explores the coverage of a set of phonological rules on a corpus of lexically transcribed speech using the computational resources of a speech recognition system.",
        "This algorithm belongs to the class of techniques we call Exploratory Computational Phonology, which use statistical pattern recognition tools to explore phonological spaces.",
        "We describe the details of our probability estimation algorithm and also present the probabilities the system has learned for ten common phonological rules which model reductions and coarticulation effects.",
        "Our probabilities are derived from a corpus of 7203 sentences of read speech from the Wall Street Journal (NIST 1993).",
        "We also benchmark the probabilities generated by our system against probabilities from phonetically hand-transcribed data, and show a relatively good fit.",
        "Finally, we analyze the probability differences between rule use in male ver",
        "sus female speech, and suggest that the differences erate phone sequences from word orthography as an are caused by differing average rates of speech.",
        "additional source of pronunciations."
      ]
    },
    {
      "heading": "2 The Algorithm",
      "text": [
        "In this section we describe our algorithm which assigns probabilities to hand-written, optional phonological rules like flapping.",
        "The algorithm takes a lexicon of underlying forms and applies phonological rules to produce a new lexicon of surface forms.",
        "Then we use a speech recognition system on a large corpus of recorded speech to check how many times each of these surface forms occurred in the corpus.",
        "Finally, by knowing which rules were used to generate each surface form, we can compute a count for each rule.",
        "By combining this with a count of the times a rule did not apply, the algorithm can compute a probability for each rule.",
        "The rest of this section will discuss each of the aspects of the algorithm in detail."
      ]
    },
    {
      "heading": "2.1 The Base Lexicon",
      "text": [
        "Our base lexicon is quite large; it is used to generate the lexicons for all of our speech recognition work at ICSI.",
        "It contains 160,000 entries (words) with 300,000 pronunciations.",
        "The lexicon contains underlying forms which are very shallow; thus they are post-lexical in the sense that there is no represented relationship between e.g. 'critic' and 'criticism' (where critic is pronounced kritik and criticism kritisizm).",
        "However, the entries do not represent flaps, vowel reductions, and other coarticulatory effects.",
        "In order to collect our 300,000 pronunciations, we combined seven different on-line pronunciation dictionaries, including the five shown in Table 12.",
        "We represent pronunciations with the set of 54 ARPAbet-like phones detailed in Table 2.",
        "All the lexicon sources except LIMSI use ARPABET-like phone sets'.",
        "CMU, BRITPRON, and PRONLEX phone sets include three levels of vowel stress.",
        "The pronunciations from all these sources were mapped into our phone set using a set of obligatory rules for stop closures [bcl, del, gcl, pd, tcl, kcl], and optional rules to introduce the syllabic consonants [el, em, en], reduced vowels [ax, ix, axr], voiced h [hv], and alveolar flap [dx]."
      ]
    },
    {
      "heading": "2.2 Applying Phonological Rules to Build a Surface Lexicon",
      "text": [
        "We next apply phonological rules to our base lexicon to produce the surface lexicon.",
        "Since the rules",
        "are optional, the surface lexicon must contain each underlying pronunciation unmodified, as well as the pronunciation resulting from the application of each relevant phonological rule.",
        "Table 3 gives the 10 phonological rules used in these experiments.",
        "One goal of our rule-application procedure was to build a tagged lexicon to avoid having to implement a phonological-rule parser to parse the surface pronunciations.",
        "In a tagged lexicon, each surface pronunciation is annotated with the names of the phonological rules that applied to produce it.",
        "Thus when the speech recognizer finds a particular pronunciation in the speech input, the list of rules which applied to produce it can simply be looked up in the tagged lexicon.",
        "The algorithm applies rules to pronunciations recursively; when a context matches the left hand side of a phonological rule \"RULE,\" two pronunciations are produced: one unchanged by the rule (marked -RULE), and one with the rule applied (marked +RULE).",
        "The procedure places the +RULE pronunciation on the queue for later recursive rule application, and continues trying to apply phonological rules to the RULE pronunciation.",
        "See Figure 1 for details of the algorithm.",
        "While our procedure is not guaranteed to terminate, in practice the phonological rules we apply have a finite recursive depth.",
        "The nondeterministic mapping produces a tagged equiprobable multiple pronunciation lexicon of 510,000 pronunciations for 160,000 words.",
        "For example, Table 4 gives our base forms for the word \"butter\": Source Pronunciation TTS b ah t axr BPU b ah tax BPU b ah t axr CMU b ah t er LIM b ah t axr PLX b ah t er",
        "The resulting tagged surface lexicon would have the entries in Table 5."
      ]
    },
    {
      "heading": "2.3 Filtering with forced-Viterbi",
      "text": [
        "Given a lexicon with tagged surface pronunciations, the next required step is to count how many times each of these pronunciations occurs in a speech corpus.",
        "The algorithm we use has two steps; PHONETIC LIKELIHOOD ESTIMATION and FORCED-VITERBI ALIGNMENT.",
        "In the first step, PHONETIC LIKELIHOOD ESTIMATION, we examine each 20ms frame of speech data, and probabilistically label each frame with the phones that were likely to produce the data.",
        "That is, for each of the 54 phones in our phone-set, we compute the probability that the slice of acoustic data was produced by that phone.",
        "The result of this labeling is a vector of phone-likelihoods for each acoustic frame.",
        "Our algorithm is based on a multilayer percep-tron (MLP) which is trained to compute the conditional probability of a phone given an acoustic feature vector for one frame, together with 80 ms of surrounding context.",
        "Hourlard & Morgan (1991)",
        "The second step of the algorithm, FORCED-VITERBI ALIGNMENT, takes this vector of likelihoods for each frame and produces the most likely phonetic string for the sentence.",
        "If each word had only a single pronunciation and if each phone had some fixed duration, the phonetic string would be completely determined by the word string.",
        "However, phones vary in length as a function of idiolect and rate of speech, and of course the very fact of optional phonological rules implies multiple possible pronunciations for each word.",
        "These pronunciations are encoded in a hidden Markov model (HMM) for each word.",
        "The Viterbi algorithm is a dynamic programming search, which works by computing for each phone at each frame the most likely string of phones ending in that phone.",
        "Consider a sentence whose first two words are \"of the\", and assume the simplified lexicon in Figure 3.",
        "Each pronunciation of the words 'of' and 'the' is represented by a path through the probabilistic automaton for the word.",
        "For expository simplicity, we have made the (incorrect) assumption that consonants have a duration of 1 frame, and vowel a duration of 2 or 3 frames.",
        "The algorithm analyzes the input frame by frame, keeping track of the best path of phones.",
        "Each path is ranked by its probability, which is computed by multiplying each of the transition probabilities and the phone probabilities for each frame.",
        "Figure 4 shows a schematic of the path computation.",
        "The size of each dot indicates the magnitude of the local phone likelihood.",
        "The maximum path at each point is extended; non-maximal paths are pruned.",
        "The result of the forced-Viterbi alignment on a single sentence is a phonetic labeling for the sentence (see Figure 5 for an example), from which we",
        "The probability P(q1x) produced by the MLP for each frame is first converted to the likelihood P(xlq) by dividing by the prior P(q), according to Bayes' rule; we ignore P(x) since it is constant here:",
        "paths in a dcl d ey can produce a phonetic pronunciation for each word.",
        "By running this algorithm on a large corpus of sentences, we produce a list of \"bottom-up\" pronunciations for each word in the corpus."
      ]
    },
    {
      "heading": "2.4 Rule probability estimation",
      "text": [
        "The rule-tagged surface lexicon described in §2.1 and the counts derived from the forced-Viterbi described in §2.3 can be combined to form a tagged lexicon that also has counts for each pronunciation of each word.",
        "Following is a sample entry from this lexicon for the word Adams which shows the five derivations for its single pronunciation: Adams: ae dz ax m z: count=2",
        "Each pronunciation of each word in this lexicon is annotated with rule tags.",
        "Since each pronunciation may be derived from different source dictionaries or via different rules, each pronunciation of a word may contain multiple derivations, each consisting of the list of rules which applied to give the pronunciation from the base form.",
        "These tags are either positive, indicating that a rule applied, or negative, indicating that it did not.",
        "To produce the initial rule probabilities, we need to count the number of times each rule applies, out of the number-of times it had the potential to apply.",
        "If each pronunciation only had a single derivation,",
        "this would be computed simply as follows:",
        "However, since each pronunciation can have multiple derivations, the counts for each rule from each derivation need to be weighted by the probability of the derivation.",
        "The derivation probability is computed simply by multiplying together the probability of each of the applications or non-applications of the rule.",
        "Let",
        "• DERIVS(p) be the set of all derivations of a pronunciation p, • POSRULES(p,r,d) be 1.0 if derivation d of pronunciation p uses rule r, else 0.",
        "• ALLRULES(p,r) be the count of all derivations of p in which rule r could have applied (i.e. in which d has either a +R or R tag).",
        "• P(d1p) be the probability of the derivation d of pronunciation p. • PRON be the set of pronunciations derived from",
        "the forced-Viterbi output.",
        "Now a single iteration of the rule-probability algorithm must perform the following computation:",
        "Since we have no prior knowledge, we make the zero-knowledge initial assumption that P(dip) = IDERI1V S(p)I.",
        "The algorithm can the be run as a successive estimation-maximization to provide successive approximations to P(djp).",
        "For efficiency reasons, we actually compute the probabilities of all rules in parallel, as shown in Figure 6.",
        "For each word/pron pair P E P RON from forced-Viterbi alignment"
      ]
    },
    {
      "heading": "3 Results",
      "text": [
        "We ran the estimation algorithm on 7203 sentences (129,864 words) read from the Wail Street Journal.",
        "The corpus (1993 WSJ Hub 2 (WSJ 0) training data) Consisted of 12 hours of speech, and had 8916 unique words.",
        "Table 6 shows the probabilities for the ten phonological rules described in §2.2.",
        "Note that all of the rules are indeed quite optional; even the most commonly-employed rules, like flapping and h-voicing, only apply on average about 90% of the time.",
        "Many of the other rules, such as the reduced-vowel or reduced-liquid rules, only apply about 50% of the time.",
        "We next attempted to judge the reliability of our automatic rule-probability estimation algorithm by comparing it with hand transcribed pronunciations.",
        "We took the hand-transcribed pronunciations of each word in TIMIT, and computed rule probabilities by the same rule-tag counting procedure used for our forced-Viterbi output.",
        "Figure 7 shows the fit between the automatic and hand-transcribed probabilities.",
        "Since the TIMIT pronunciations were from a completely different data collection effort with a very different corpus and speakers, the closeness of the probabilities is quite encouraging.",
        "Figure 8 breaks down our automatically generated rule probabilities for the Wall Street Journal corpus"
      ]
    },
    {
      "heading": "Percent of Phonological Rule Use, WSJO vs. TIMIT",
      "text": [
        "into male and female speakers.",
        "Notice that many of the rules seem to be employed more often by men than by women.",
        "For example, men are about 5% more likely to flap, more likely to reduce vowels ih and er, and slightly more likely to reduce liquids and nasals.",
        "Since these are coarticulation or fast-speech effects, our initial hypothesis was that the difference between male and female speakers was due to a faster speech-rate by males.",
        "By computing the weighted average seconds per phone for male and female speakers, we found that females had an average of 71 ms/phone, while males had an average of 68 ms/phone, a difference of about 4%, quite correlated with the similar differences in reduction and flapping."
      ]
    },
    {
      "heading": "4 Related Work",
      "text": [
        "Our algorithm for phonological rule probability estimation synthesizes and extends earlier work by (Cohen 1989) and (Wooters 1993).",
        "The idea of using optional phonological rules to construct a speech-recognition lexicon derives from Cohen (1989), who applied optional phonological rules to a baseform dictionary to produce a surface lexicon and then used TIMIT to assign probabilities for each pronunciation.",
        "The use of a forced-Viterbi speech decoder to discover pronunciations from a corpus was proposed by Wooters (1993).",
        "Wesenick & Schiel (1994) independently propose a very similar forced-Viterbi-decoder-based technique which they use for measuring the accuracy of handwritten phonology.",
        "Chen (1990) and Riley (1991) model the relationship between phonemes and their allophonic realizations by training decision trees on TIMIT data.",
        "A decision tree is learned for each underlying phoneme specifying its .surface realization in different contexts.",
        "These completely automatic techniques, requiring no handwritten rules, can allow a more fine-grained analysis than our rule-based algorithm.",
        "However, as a consequence, it is more difficult to extract generalizations across classes of phonemes to which rules can apply.",
        "We think that a hybrid between a rule-based and a decision-tree approach could prove quite powerful."
      ]
    },
    {
      "heading": "5 Conclusion and Future Work",
      "text": [
        "Although the paradigm of exploratory computational phonology is only in its infancy, we believe our rule-probability estimation algorithm to be a new and useful instance of the use of probabilistic techniques and spoken-language corpora in computational linguistics.",
        "In Tajchman et al.",
        "(1995) we report on the results of our algorithm on speech recognition performance.",
        "We plan in future work to address a number of shortcomings of these experiments, for example including some spontaneous speech corpora, and looking at a wider variety of rules.",
        "In addition, we have extended our algorithm to induce new pronunciations which generalize over pronunciations seen in the corpus (Wooters & Stolcke 1994).",
        "We now plan to augment our probability estimation to use the pronunciations from this new HMM-induction-based generalization step.",
        "This will require extending our tag-based probability estimation step to parse the phone strings from the forced-Viterbi.",
        "In other current work we have also been using this algorithm to model the phonological component of the accent of non-native speakers.",
        "Finally, we hope in future work to be able to combine our rule-based approach with more bottom-up methods like the decision-tree or phonological parsing algorithms to induce rules as well as merely training their probabilities."
      ]
    },
    {
      "heading": "Acknowledgments",
      "text": [
        "Thanks to Mike Hochberg, Nelson Morgan, Steve Renals, Tony Robinson, Florian Schiel, Andreas Stolcke, and Chuck Wooters.",
        "This work was partially funded by ICSI and an SRI subcontract from ARPA contract MDA904-90-C-5253.",
        "Partial funding also came from ESPRIT project 6487 (The Wernicke project)."
      ]
    }
  ]
}
