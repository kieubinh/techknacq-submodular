{
  "info": {
    "authors": [
      "Ezra W. Black",
      "Stephen Eubank",
      "Hideki Kashioka",
      "David M. Magerman",
      "Roger Garside",
      "Geoffrey Leech"
    ],
    "book": "International Conference on Computational Linguistics",
    "id": "acl-C96-1020",
    "title": "Beyond Skeleton Parsing: Producing a Comprehensive Large-Scale General-English Treebank With Full Grammatical Analysis",
    "url": "https://aclweb.org/anthology/C96-1020",
    "year": 1996
  },
  "references": [
    "acl-E91-1004",
    "acl-H90-1054",
    "acl-H92-1023",
    "acl-H94-1020",
    "acl-H94-1052",
    "acl-J93-2004",
    "acl-J93-2006",
    "acl-J94-2001",
    "acl-P93-1035",
    "acl-P95-1037"
  ],
  "sections": [
    {
      "heading": "1 Introduction",
      "text": [
        "A treebank is a body of natural-language text which has been grammatically annotated by hand, in terms of some previously-established scheme of grammatical analysis.",
        "Treebariks have been used within the field of natural-language processing as a source of training data for statistical part of-speech taggers (Black et al., 1992; Brill, 1994; Merialdo, 1994; Weischedel et al., 1993) and for statistical parsers (Black et al., 1993; Brill, 1993; jelinek et al., 1994; Magerman, 1995; Magerman and Marcus, 1991).",
        "In this article, we present the ATR/Lancaster Treebank of American English, a new resource for natural-language--processing research, which has been prepared by Lancaster University (UK)'s Unit for Computer Research on the English Language, according to specifications provided by ATR (Japan)'s Statistical Parsing Group.",
        "First we provide a \"static\" description, with (a) a discussion of the mode of selection and initial processing of text for inclusion in the treebank, and (b) an explanation of the scheme of grammatical annotation we then apply to the text.",
        "Second, we supply a \"process\" description of the treebank, in which we detail the physical and computational mechanisms by which we have created it.",
        "Finally, we lay out plans for the further development of this new treebank.",
        "All of the features of the ATR/Lancaster Treebank that are described below represent a radical departure from extant large-scale (Eyes and Leech, 1993; Garside and McEnery, 1993; Marcus et al., 1993) treebanks.",
        "We have chosen in this article to present our treebank in some detail, rather than to compare and contrast it with other treebanks.",
        "But the major differences between this and earlier treebanks can easily be grasped via a corn",
        "parison of the descriptions below with those of the sources just cited."
      ]
    },
    {
      "heading": "2 General Description of the Treebank",
      "text": []
    },
    {
      "heading": "2.1 Document Selection and Preprocessing",
      "text": [
        "The ATR/Lancaster Treebank consists of approximately 730,000 words of grammatically--analyzed text divided into roughly 950 documents ranging in length from about 30 to about 3600 words.",
        "The idea informing the selection of documents for inclusion in this new treebank was to pack into it the maximum degree of document variation along many different scales – document length, subject area, style, point of view, etc.--but without establishing a single, predetermined classification of the included documents.'",
        "Differing purposes for which the treebank might be utilized may favor differing groupings or classifications of its component documents.",
        "Overall, the rationale for seeking to take as broad as possible a sample of current standard American English, is to support the parsing and tagging of unconstrained American English text by providing a training corpus which includes documents fairly similar to almost any input which might arise.",
        "Documents were obtained from three sources: the Internet; optically-scanned hardcopy \"occasional\" documents (restaurant take-out menus; fundraising letters; utility bills); and purchase from commercial or academic vendors.",
        "To illustrate the diverse nature of the documents included in tins treebank, we list, in Table 1, titles of nine typical documents.",
        "In general, and as one might expect, the documents we have used were written in the early to mid 1990s, in the United States, in \"Standard\" American English.",
        "However, there are fairly many",
        "exceptions: documents written by Captain John Smith of Plymouth Plantation (1600s), by Benjamin Franklin (1700s), by Americans writing in periods throughout the 1800s and 1900s; documents written in Australian, British, Canadian, and Indian English; and documents featuring a, range of dialects and regional varieties of current American English.",
        "A smattering of such documents is included because within standard English, these linguistic varieties are sometimes quoted or otherwise utilized, arid so they should he represented.",
        "As noted above, each document within the treebank is classified along many different axes, in order to support a large variety of different task-specific groupings of the documents.",
        "Each document is classifed according to tone, style, linguistic level, point of view, physical description of document, geographical background of author, etc.",
        "Sample values for these attributes are: \"friendly\", \"dense\", \"literary\", \"technical\", \"how-to guide\", and \"American South\", respectively.",
        "To convey domain information, one or more Dewey Decimal System three-digit classifiers are associated with each document.",
        "For instance, for the cv of a physiologist, Dewey 612 and 616 (Medical Sciences: Human Physiology; Diseases) were chosen.",
        "On a more mundane, \"bookkeeping\" level, values for text title, author, publication date, text source, etc.",
        "are recorded as well.",
        "An SGML like markup language is used to capture a variety of organizational-level facts about each document, such as LIST structure; TITLEs and CAPTIONs; and even more recondite events such as POEM and IMAGE.",
        "HIGHLIGHTing of words and phrases is recorded, along with the variety of highlighting: italics, boldface, large font, etc.",
        "Spelling errors and, where essential, other typographical lapses, are scrupulously recorded and then corrected.",
        "'I'okeniza.tion (i.e. word splitting: Edward's Edward 's) and sentence splitting (e.g.",
        "He said, \"Hi there.",
        "Long time no see.\" (Sentence.",
        "]:) He said, (Sentence.2:) \"Hi there.",
        "(Sentence.3;) Long time no see.\") are performed by hand according to predetermined policies.",
        "Hence the treebank provides the resource of multifarious"
      ]
    },
    {
      "heading": "correct instances of word - and sentence-splitting. 2.2 Scheme of Grammatical Annotation",
      "text": [
        "Heretofore, all existing large-scale treebanks have employed the grammatical analysis technique of skeleton parsing (Eyes and Leech, 1993; Garside and McEnery, 1993; Marcus et al., 1993),2 in which only a partial, relatively sketchy, grammatical analysis of each sentence in the treebank is provided.` In contrast, the ATR/Lancaster Treebank assigns to each of its sentences a full and complete grammatical analysis with respect to a very detailed, very comprehensive broad--coverage grammar of English.",
        "Moreover, a very large, highly detailed part -of-speech ta,gset, is used to label each word of each sentence with its syntactic and semantic categories.",
        "'[lie result is an extremely specific and informative syntactic and semantic diagram of every sentence in the treebank.",
        "This shift from skeleton-parsing-based treebanks to a treebank providing full, detailed grammatical analysis resolves a set of problems, detailed in (Black, 1994), involved in using skeleton-parsing-based treebanks as a means of initializing training statistics for probabilistic grammars (Black et, al., 1993).",
        "Briefly, the first of these problems, which applies even where the grammar being trained has been induced from the training treebank (Sharman et al., 1990), is that the syntactic sketchiness of a skeleton--parsed treebank leads a statistical training algorithm to overcount, in some circumstances, and in other cases to un-2 The 1995-release Penn Treebank adds functional information to some nonterminals (Marcus et al., 1994), but with its rudimentary (roughly tag) tagset, its non-detailed internal analysis of noun compounds and NPs more generally, its lack of semantic categorization of words and phrases, etc., it arguably remains a skeleton-parsed treebank, albeit an enriched one.",
        "3A different kind of partial parse crucially, one generated automatically and not by band – characterizes the \"treebank\" produced by processing the 200-million-word Birmingham University (1TK) Bank--of-English text corpus with the dependency-grammar-based ENGCG Helsinki Parser (Karlsson et al., :1995).",
        "dercount instances of rule firings in training data (treebank) parses, and thus to incorrectly estimate rule probabilities.",
        "The second problem is that where the grammar being t raineo is 'note detailed syntactically than the skeleton parsing based training treebank, the training corpus radically underperforms ill its crucial job of specifying correct, parses for training purposes (Black, 1991).",
        "In addition to resolving grammar training problems, our 'Ireebank provides a means of training non grammar based parsing procedures (Brill, 1993; Jenne': et al., 1991; Magerman, 1995) at new, higher levels of grammatical detail and comprehensiveness.",
        "Treebank sentences are parsed in terms of the /177?",
        "Itinglish Grammar, whose characteristics we Till briefly describe.",
        "'the (-1rantmaris part of speech tagset resent-1)1es the 179 tag Claws tagset developed by ti( IR 1,1, (byes and Leech, 1993), but, with numerous major and Honor differences.",
        "One major difference, for instance, is that.",
        "the Alit?, tagset, captures the difference between e.g. \"wall covering\", where \"covering\" is a lexicalized noun ending in -ing, and \"the covering of all bets\", where \"covering\" is a verbal 1101111.",
        "In Claws practice, both are NN (singular common noun).",
        "The ATk tagset innovates the tag type NVV(; for verbal nouns.",
        "Another major difference is the (limited) use of \"subcategorization\", e.g. VI)131,013,1 for double object, verbs (teach Hill Latin, etc.",
        "), Each verb, noun, adjective and adverb in the A'I'R tagset includes a semantic label, chosen from 42 noun/adjective/adverb categories and 29 verb/verbal categrories, some overlap existing between these category sets.",
        "These semantic categories are intended for any 'Standard AMerican knglish\" terti, in any domain.",
        "Sample categories include: \"physical.attribute\" (nouns/adjectives/adverbs), \"alter\" (verbs/verbals), and \"interpersonal.act,\" (noutis/adjectives/a,dverbs/verhs/verbals).",
        "They were developed by the AIR, grammarian and then proven and refilled via day in day out tagging for six months at, AIR, by two human 1 rec.-bankers\", then for four months at, Lancaster by live treelmnkers, with daily interactions ;1111011g treeballkerS, and between the treebankers and the ATR grammarian.",
        "tr we ignore the semantic portion of AIR tags, the tagset, contains 165 different tags.",
        "Including the semantic categories in tile tags, there are roughly 2290 tags.",
        "As is the case in the.",
        "(laws tagset, so called \"ditto tags\" c!.",
        ";1.11 be created based on almost any tag of the tagset, for the purpose of labelling multiword expressions.",
        "For instance, \"will o' the wisp\" is labelled as a 4 word singular count-ion noun.",
        "This process can add considerable numbers of tags to the above totals.",
        "Sentences in the Treehank arc parsed with respect 1,0 tin,.",
        "Ark Grammar.",
        "The Grammar, a feature based context-free phrase structure grammar, is related to the IBM English Grammar as published in (Black et al., 1993), but, differs more from the 113M Grammar than our tagset, does from the ('laws tagset.",
        "for instance, the notion of \"mnemonic\" has no application to the A'I'R , Grammar; the AIR, Grammar has 67 features and 1100 rides, whereas the IBM Grammar had 10 features and 750 rules, etc.",
        "The precisely correct parse (as pre specified by a human \"treebanker\") figures among the parses produced for any given sentence by the ATR, Grammar, roughly 90% of' the time, for text, of the unconstrained, wide open sort, that, the '1'reebanlc is COMPOSed of.",
        "'rile job of the treebankers is to locate this exact, parse, for each sentence, mid add it to the Treebank.",
        "Eigure I shows two sample parsed sentences from the A'I'R.",
        "Treebank (and originally from a Chinese take out, food flier).",
        "13ecause it, is infbr-mative to know which of the 1190 rules is used at, a given tree node, and since the particular \"nonterminal category\" associated with any node of the tree is always recoverable,`' nodes are labelled with A'I'R, (;rattimar rule names rather than, as is more usual, with nonterminal names."
      ]
    },
    {
      "heading": "3 Producing the Treebaiik",
      "text": [
        "In this part, of the article, we turn from \"what,\" to \"how\", and discuss the mechanisms by which the ATH/Lancaster Treebanki was produced."
      ]
    },
    {
      "heading": "3.1 The Software Backbone GWBTool:",
      "text": [
        "A Treebanker's Workstation (; \\AII3Tool is a Motif-based X-Windows application which allows the trechanker to interact, with the ATP English Grammar in order to produce the most accurate treebank in the shortest.",
        "amount, of time.",
        "The treebanking process begins in the Treebank Editor screen of the treebanker's workstation with a list of sentences tagged with part-of-speech categories, The treehailker selects a sentence -f•0111 the list., for processing.",
        "Next, with the click of a butt-ton, the Treehank Editor graphically displays the parse finest 1(3r the sentence in a mouse-sensitive Parse Tree window (Figure 2).",
        "Each node dis_ played represents a constituent in the parse forest,.",
        "A shaded constituent, node indicates that there are alternative analyses of that, constituent, only one of which is displayed.",
        "By clicking the right mouse button on a shaded node, the treehanker can display a popup menu listing the alternative analyses, any of which (inn be displayed by selecting the appropriate menu item.",
        "Clicking the left, mouse.",
        "button on a constituent node pops up a window listing the feature values for that, constituent.",
        "an example sentence.",
        "On the far right, the feature values of the VBAR2 constituent, indicating that the constituent is an auxiliary verb phrase (bar level 2) containing a present--tense verb phrase with noun semantics SUBSTANCE and verb semantics SEND.",
        "The fact that the number feature is variable (NUMBER=V5) indicates that the number of the verb phrase is not specified by the sentence.",
        "The shaded nodes indicate where there are alternative parses.",
        "The Treebank Editor also displays the number of parses in the parse forest.",
        "If the parse forest is unmanageably large, the treebanker can partially bracket the sentence and, again with the click of a button, see the parse forest containing only those parses which are consistent with the partial bracketing (i.e. which do not have any constituents which violate the constituent boundaries in the partial bracketing).",
        "Note that the treebanker need not specify any labels in the partial bracketing, only constituent boundaries.",
        "The process described above is repeated until the treebanker can narrow the parse forest down to a single correct parse.",
        "Crucially, for experienced Lancaster treebankers, the number of such iterations is, by now, normally none or one."
      ]
    },
    {
      "heading": "3.2 Two – Stage Part – Of – Speech Tagging",
      "text": [
        "Part-of-speech tags are assigned in a two-stage process: (a) one or more potential tags are assigned automatically using the Claws HMM tagger (?",
        "); (b) the tags are corrected by a treebanker using a special-purpose X-windows-based editor, Xanthippe.",
        "This displays a text segment and, for each word contained therein, a ranked list of suggested tags.",
        "The analyst can choose among these tags or, by clicking on a panel of all possible tags, insert a tag not in the ranked list.",
        "The automatic tagger inserts only the syntactic part of the tag.",
        "To insert the semantic part of the tag, Xanthippe presents a panel representing all possible semantic continuations of the syntactic part of the tag selected.",
        "Tokenization, sentence – splitting, and spell – checking are carried out according to rule by the treebankers themselves (see 2.1 above).",
        "However, the Claws tagger performs basic and preliminary tokenization and sentence – splitting, for optional correction using the Xanthippe editor.",
        "Xanthippe retains control at all times during the tag correction process, for instance allowing the insertion only of tags valid according to the ATE, Grammar."
      ]
    },
    {
      "heading": "3.3 The Annotation Process",
      "text": [
        "Initially a file consists of a header detailing the file name, text title, author, etc., and the text itself, which may be in a variety of formats; it may contain HTMI, mark-up, and files vary in the way in which, for example, emphasis is represented.",
        "The first stage of processing is a scan of the text to establish its format and, for large files, to delimit a sample to be annotated.",
        "The second stage is the insertion of SGML-like mark-up.",
        "As with the tagging process, this is done by an automatic procedure with manual correction, using microemacs with a special set of macros.",
        "Third, the tagging process described in section 3.2 is carried out.",
        "The tagged text is then extracted into a file for parsing via GWBToo1 (See 3.1.1).",
        "The final stage is merging the parsed and tagged text with all the annotation (SGML – like markup, header information) for return to ATR."
      ]
    },
    {
      "heading": "3.4 Staff Training; Output Accuracy",
      "text": [
        "Even though all Treebank parses are guaranteed to be acceptable to the ATR Grammar, insuring consistency and accuracy of output has required considerable planning and effort.",
        "Of all the parses output for a sentence being treebanked, only a small subset are appropriate choices, given the sentence's meaning in the document in which it occurs.",
        "The five Lancaster treebankers had to undergo extensive training over a long period, to understand the manifold devices of the ATR Grammar expertly enough to make the requisite choices.",
        "This training was effected in three ways: a week of classroom training was followed by four months of daily email interaction between the treebankers and the creator of the ATE, Grammar; and once this training period ended, daily Lancaster/ATR email interaction continued, as well as constant consultation among the treebankers themselves.",
        "A body of documentation and lore was developed and frequently referred to, concerning how all semantic and certain syntactic aspects of the tagset, as well as various grammar rules, are to be applied and interpreted.",
        "(This material is organized via a menu system, and updated at least weekly.)",
        "A searchable version of files annotated to date, and a list of past tagging decisions, ordered by word and by tag, are at the treebankers' disposal.",
        "In addition to the constant dialogue between the treebankers and the ATE, grammarian, Lancaster output was sampled periodically at ATR, hand -corrected, and sent back to the treebankers.",
        "In this way, quality control, determination of output accuracy, and consistency control were handled conjointly via the twin methods of sample correction and constant treebanker/grammarian dialogue.",
        "With regard both to accuracy and consistency of output analyses, individual treebanker abilities clustered in a fortunate manner.",
        "Scoring of thousands of words of sample data over time revealed that three of the five treebankers had parsing error rates (percentage of sentences parsed incorrectly) of 7%, 10%, and 14% respectively, while the other two treebankers' error rates were 30% and 36% respectively.",
        "Tagging error rates (percentage of all tags that were incorrect), similarly, were 2.3%, 1.7%, 4.0%, 7.3% and 3.6%.",
        "Expected parsing error rate worked out to 11.9% for the first three, but 32.0% for the other two treebankers; while expected tagging error rates were 2.9% and 6.1% respectively.5 'Almost all tagging errors were semantic.",
        "1 1 1 What is fortunate about this clustering of abilities is that the less able treeliankers were also much less prolific than the others, producing only 25% of the total treebank.",
        "Therefore, we are provisionally excluding this 25% of the treebank (about 180,000 words) from use for parser training, though we are experimenting with the use of the entire treebank (expected tagging error rate: 3.9%) for tagger training.",
        "Finally, parsing and tagging consistency among the first three treebankers appears high."
      ]
    },
    {
      "heading": "4 Conclusion",
      "text": [
        "Within the next two years, we intend to produce Version 2 of our 'freebank, in which the 25% of the treebank that is currently suitable for training taggers but not parsers, is fully corrected.'",
        "Over the next several years, the ATR/Lancaster 'freebank of American English will form the basis for the research of Alit's Statistical Parsing Group in statistical parsing, part of-speech tagging, and related fields."
      ]
    }
  ]
}
