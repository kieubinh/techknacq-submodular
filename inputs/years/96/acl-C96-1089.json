{
  "info": {
    "authors": [
      "Masahiko Haruno",
      "Satoru Ikehara",
      "Takefumi Yamazaki"
    ],
    "book": "International Conference on Computational Linguistics",
    "id": "acl-C96-1089",
    "title": "Learning Bilingual Collocations by Word-Level Sorting",
    "url": "https://aclweb.org/anthology/C96-1089",
    "year": 1996
  },
  "references": [
    "acl-A94-1006",
    "acl-C90-3044",
    "acl-C94-1009",
    "acl-C94-1101",
    "acl-C96-1097",
    "acl-J93-1007",
    "acl-J96-1001",
    "acl-P93-1003",
    "acl-P93-1004",
    "acl-P95-1032",
    "acl-P96-1018"
  ],
  "sections": [
    {
      "heading": "Abstract;",
      "text": [
        "This paper proposes a new method for learning bilingual collocations from sentence-aligned parallel corpora.",
        "Our method comprises two steps: (I) extracting useful word chunks (n-grains) by word-level sorting and (2) constructing bilingual collocations by combining the word-chunks acquired in stage (1).",
        "We apply the method to a very challenging text pair: a stock market bulletin in Japanese and its abstract in English.",
        "Domain specific collocations are well captured even if they were not contained in the dictionaries of economic; terms."
      ]
    },
    {
      "heading": "1 Introduction",
      "text": [
        "In the field of machine translation, there is a growing interest in corpus-based approaches (Sato and Na.gao, 1990; Da.gan and ( 1994; Matsumoto et al., 1993; Kurnano and Iliraka.wa, 1991; Smadja et al., 1996).",
        "The main motivation behind this is to well handle domain specific expressions.",
        "Each application domain has various kinds of collocations ranging from word-level to sentence-level.",
        "The correct use of these collocations greatly influences the quality of output texts.",
        "Because such detailed collocations are difficult to hand-compile, the automatic extraction of bilingual collocations is needed.",
        "A number of studies have attempted to extract bilingual collocations front parallel corpora.",
        "These studies can he classified into two directions.",
        "One is based on the full parsing techniques.",
        "(Matsumoto et al., 1993) proposed a. method to find out phrase-level correspondences, while resolving syntactic ambiguities at the same time.",
        "Their methods determine phrase correspondences by using the phrase structures of the two languages and existing bilingual dictionaries.",
        "Unfortunately these approaches are promising only for the comparatively short sentences that can be analyzed by a CKY type parser.",
        "The other direction for extracting bilingual collocations involves statistics.",
        "(Fling, 1995) acquired bilingual word correspondences without sentence alignment.",
        "Although these methods are robust and assume no information source, their outputs are just word-word correspondences.",
        "(Kupiec, 1993; Kumano and Ilirakawa, 1994) extracted noun phrase (NP) correspondences from aligned parallel corpora.",
        "In (Kupiec, 1993), NPs in English and French texts are first extracted by a. NP recognizes.",
        "Their correspondence prol)-abilities are then gradually refined by using an EM-like iteration algorithm.",
        "(Kumano and rakawa, 1991) first extracted Japanese N Ps in the same way, and combined statistics with a bilingual dictionary for MT to find out NP correspondences.",
        "Although their approaches attained high accuracy for the task considered, the most crucial knowledge for MT is more complex correspondences such as NP-VP correspondences and sentence-level correspondences.",
        "It seenis difficult to extend these statistical methods to a broader range of collocations because they are specialized to N Ps or single words.",
        "(Smadja et, al., 1996) proposed a general method to extract a broader range of collocations.",
        "They first extract English collocations using the )(tract system (Smadja, 1993), and then look for French counterparts.",
        "Their search strategy is an iterative combination of two elements.",
        "This is based on the intuitive idea that \"if a set of words constitutes a collocation, its subset will also be correlated\".",
        "Although this idea.",
        "is correct, the iterative combination strategy generates a munber of useless expressions.",
        "In fact, Xtract, employs a robust English parser to filter out the wrong collocations which (brut snore than half the candidates.",
        "In other languages such as Japanese, parser-based pruning cannot, be used.",
        "Another drawback of their approach is that only the longest n-gram is adopted.",
        "That, is, when 'Japan-US auto trade talks' is adopted as a collocation, 'Japan-US' Cannot be recognized as a. collocation though it is independently used very often.",
        "In this paper, we propose an alternative method based on word-level sorting.",
        "Our method coin-",
        "prises two steps: (1) extracting useful word chunks (n-grams) by word-level sorting and (2) constructing bilingual collocations by combining the word-chunks acquired at stage (1).",
        "Given sentence-aligned texts in two languages(Haruno and Yamazaki, 1996), the first step detects useful word chunks by sorting and counting all uninterrupted word sequences in sentences.",
        "In this phase, we developed a new technique for extracting only useful chunks.",
        "The second step of the method evaluates the statistical similarity of the word chunks appearing in the corresponding sentences.",
        "Most of the fixed (uninterrupted) collocations are directly extracted from the word chunks.",
        "More flexible (interrupted) collocations are acquired level by level by iteratively combining the chunks.",
        "The proposed method, which uses effective word-level sorting, not only extracts fixed collocations with high precision, but also avoids the combinatorial explosion involved in searching flexible collocations.",
        "In addition, our method is robust and suitable for real-world applications because it only assumes part-of-speech taggers for both languages.",
        "Even if the part-of-speech taggers make errors in word segmentation, the errors can be recovered in the word chunk extraction stage."
      ]
    },
    {
      "heading": "2 Two Types of Japanese-English Collocations",
      "text": [
        "In this section, we briefly classify the types of Japanese-English collocations by using the material in Table 1 as an example.",
        "These texts were derived from a stock market bulletin written in Japanese and its abstract written in English, which were distributed electrically via a computer network.",
        "In Table 1, (*V1-A /Tokyo Forex), (Huigi *I /auto talks between Japan and the U.S.) and (ta.t.",
        "/ahead of) are Japanese-English collocations whose elements constitute uninterrupted word sequences.",
        "We call hereafter this type of collocation fixed collocation.",
        "Although fixed collocation seems trivial, more than half of all useful collocations belong to this class.",
        "Thus, it is important to extract fixed collocations with high precision.",
        "In contrast, ( FA,11--elfth t tc /The U.S. currency was quoted at ---- ) and ( F",
        "are constructed from interrupted word sequences.",
        "We will call this type of collocation flexible collocation.",
        "From the viewpoint of machine learning, flexible collocations are much more difficult to learn because they involve the combination of elements.",
        "The points when extracting flexible collocations is how the number of combination (candidates) can be reduced.",
        "Our learning method is twofold according to the collocation types.",
        "First, useful uninterrupted",
        "1--- represents any sequence of words.",
        "word chunks are extracted by the word-level sorting method.",
        "To find out fixed collocations, we evaluate stochastic similarity of the chunks.",
        "Next, we iteratively combin the chunks to extract flexible collocations."
      ]
    },
    {
      "heading": "3 Extracting Useful Chunks by Word-Level Sorting",
      "text": []
    },
    {
      "heading": "3.1 Previous Research",
      "text": [
        "With the availability of large corpora and memory devices, there is once again growing interest in extracting n-grams with large values of n. (Nagao and Mori, 1994) introduced an efficient method for calculating an arbitrary number of n-grams from large corpora.",
        "When the length of a text is / bytes, it occupies I consecutive bytes in memory as depicted in Figure 1.",
        "First, another table of size 1 is prepared, each field of which represents a pointer to a substring.",
        "A substring pointed to by the (i â€“ 1)th entry of the table constitutes a string existing from the ith character to the end of the text string.",
        "Next, to extract common sub-strings, the pointer table is sorted in alphabetic order.",
        "Two adjacent words in the pointer table are compared and the lengths of coincident prefix parts are counted(Gonnet et al., 1992).",
        "For example, when 'auto talks between Japan and the U.S.' and 'auto talks between Japan and China' are two adjacent words, the number of coincidences is 29 as in 'auto talks between Japan and '.",
        "The n-gram frequency table is constructed by counting the number of pointers which represent the same prefix parts.",
        "Although the method is efficient for large corpora, it involves large volume of fractional and unnecessary expressions.",
        "The reason for this is that the method does not consider the interrelationships between the extracted strings.",
        "That is, the method generates redundant substrings which are subsumed by longer strings.",
        "text erring (I characters: I by cm) pointer table",
        "To settle this problem, (Ikehara et al., 1996) proposed a method to extract only useful strings.",
        "Basically, his methods is based on the longest-match principle.",
        "When the method extracts a longest n-gram as a chunk, strings subsumed by the chunk are derived only if the shorter string often appears independently to the longest chunk.",
        "If 'auto talks between Japan and the U.S.' is extracted as a chunk, 'Japan and the U.S. ' is also",
        "1. wgAzt, 1 7 ky â€¢ pj, d\\ryi.56 â€“ â€“ 2 6 im 8 4 IA 2 1 â€“ 2 4a, Tokyo Forex 5 PM: Dollar at 84.21-84.24 yen 2. rilikait 2 81MT-A FA-rliZo) 1 rn,--= 8 4 2 1 â€“ 2 4 ite:A)103k)ZqmRk tr.",
        "The dollar stood 0.26 yen lower at 84.21-84.24 at 5 p.m. 3.",
        "FA,1Z-qA-P.AV_,I.J1-(7.1,n 031\"-M07519c-f-ri tch:, Ei*nainKrinr-coi**amti Y â€“ )1e310.Aft*Sfit* 03411:4,:org1 2 7 Et -11flicAA:r1-4401t2e52, â€“ h:Nt h, PJF 8 4 PillifVeil`a .A\"vcJfll Utc Forex market trading was extremely quiet ahead of further auto talks between Japan and the U.S., slated for early dawn Tuesday.",
        "4.",
        "FA-1-1561-git-%-C'affil.., 1 Fil,= 1.",
        "3 8 6 3 â€“ 6 6 --q.A---elltifl&41â€œ).tkic.",
        "The U.S. currency was quoted at 1.361-1.3863 German marks at 5:15 p.m.",
        "extracted because 'Japan and the U.S.' is used so often independently as in 'Japan and the U.S. agreed â€¢ â€¢ â€¢ '.",
        "However, 'Japan and the' is not extracted because it always appears in the context of 'Japan and the U.S.'.",
        "The method strongly suppresses fractional and unnecessary expressions.",
        "More than 75 % of the strings extracted by Na-gao's method are removed with the new method."
      ]
    },
    {
      "heading": "3.2 Word-Level Sorting Method",
      "text": [
        "poIntorlâ€¢bio",
        "The research described in the previous section deals with character-based n-grams, which generate excessive numbers of expressions and requires large memory for the pointer table.",
        "Thus, from a practical point of view, word-based n-grams are preferable in order to further suppress fractional expressions and pointer table use.",
        "In this paper, we extend Ikehara's method to handle word-based n-grams.",
        "First, both Japanese and English texts are part-of-speech (POS) tagged2 and stored in memory as in Figure 2.",
        "POS tagging is required for two main reasons: (1) There are no explicit word delimiters in Japanese and (2) By using POS information, useless expressions can be removed.",
        "In Figure 2, '@' and AO' represent the explicit word delimiter and the explicit sentence delimiter, respectively.",
        "Compared to previous research, this data structure has the following advantages.",
        "2We use in this phase the JUMAN morphological analyzing system (Kurohashi et al., 1994) for tagging Japanese texts and Brill's transformation-based tagger (Brill, 1994) for tagging English texts.",
        "We would like to thank all people concerned for providing us with the tools.",
        "1.",
        "Only heads of each word are recorded in the pointer table.",
        "As depicted in Figure 2, this' remarkably reduces memory use because the pointer table also contains other string characteristics as Figure 3.",
        "2.",
        "As depicted in Figure 2, only expressions within a sentence are considered by introducing the explicit sentence delimiter AO'.",
        "3.",
        "Only word-level coincidences are extracted by introducing the explicit word delimiter 'A'.",
        "This removes strings arising from a partial match of different words.",
        "For example, the coincident string between 'Japan and China' and 'Japan and Costa Rica' is 'Japan and' in our method, while it is 'Japan and C' in previous methods.",
        "Next, the pointer table is sorted in alphabetic order as shown in Figure 3.",
        "In this table, sentno.",
        "and coincidence represent which sentence the string appeared in and how many characters are shared by the two adjacent strings, respectively.",
        "That is, coincidence delineates candidates for useful expressions.",
        "Note here that the coincidence between Japan#and#Chinaâ€¢ â€¢ â€¢ and Japan#and@Costa Rica.",
        "â€¢ â€¢ is 10 as mentioned above.",
        "Next, in order to remove useless subsumed strings, the pointer table is sorted according to sentno..",
        "In this stage, adopt is filled with '1' or '0' , each of which represents if or not if a string is subsumed by longer word chunks, respectively.",
        "Sorting by sentno.",
        "makes it much easier to check the subsumption of word chunks.",
        "When",
        "both 'Japan and the U.S.' and 'Japan and the' arise from a sentence, the latter is removed because the former subsumes the latter.",
        "Finally, to determine which word-chunks to extract, the pointer table is sorted once again in alphabetic order.",
        "In this stage, we count how many times a string whose adopt is 1 appears in the corpus.",
        "By thresholding the frequency, only useful word chunks are extracted."
      ]
    },
    {
      "heading": "4 Extracting Bilingual Collocations",
      "text": [
        "In this section, we will explain how Japanese-English collocations are constructed from word chunks extracted in the previous stage.",
        "First, fixed collocations are induced in the following way.",
        "We use the contingency matrix to evaluate the similarity of word-chunk occurrences in both languages.",
        "Consider the contingency matrix, shown Table 2, for Japanese word chunk corn and English word chunk ceng.",
        "The contingency matrix shows: (a) the number of Japanese-English corresponding sentence pairs in which both cal,, and Ceng were found, (b) the number of Japanese-English corresponding sentence pairs in which just cent' was found, (c) the number of Japanese-English corresponding sentence pairs in which just Corn was found, (d) the number of Japanese-English corresponding sentence pairs in which neither chunk was found.",
        "If corn and c,â€žll are good translations of one another, a should be large, and b and c should be small.",
        "In contrast, if the two are not good translations of each other, a should be small, and b and c should be large.",
        "To make this argument more precise, we introduce mutual information as follows.",
        "Thresholding the mutual information extracts fixed collocations.",
        "Note that mutual information is reliable in this case because the frequency of each word chunk is thresholded at the word chunk extraction stage.",
        "Next, we summarize how flexible collocations are extracted.",
        "The following is a series of procedures to extract flexible collocations.",
        "1.",
        "For any pair of chunks in a Japanese sentence, compute mutual information.",
        "Combine the two chunks of highest mutual information.",
        "Iteratively repeat this procedure and construct a tree level by level.",
        "2.",
        "For any pair of chunks in an English sentence, repeat the operations done in the the Japanese sentence.",
        "3.",
        "Perform node matching between trees of both languages by using mutual information of Japanese and English word chunks.",
        "The first two steps construct monolingual similarity trees of word chunks in sentences.",
        "The third step iteratively evaluates the bilingual similarity of word chunk combinations by using the above trees.",
        "Consider the example below, in which the underlined word chunks construct a flexible collocation (âœ“Y 71-: â€“ )1410171t% A 71`l'itli4)-(e tot / â€“ rose â€“ on the oil products spot market in Singapore).",
        "First, two similarity trees arc constructed as shown in Figure 4.",
        "Graph matching is then iteratively attempted by computing mutual information for groups of word chunks.",
        "In the present implementation, the system combines three word chunks at most.",
        "The technique we use is similar to the parsing-based methods for extracting bilingual collocation(Matsumoto et al., 1993).",
        "Our method replaces the parse trees with the similarity trees and thus avoids the combinatorial explosion inherent to the parsing-based methods.",
        "AA 4 A L Naphthagas oil and rose on the oil products spot market in Singapore"
      ]
    },
    {
      "heading": "5 Preliminary Evaluation and Discussion",
      "text": [
        "We performed a preliminary evaluation of the proposed method by using 10-days Japanese stock market bulletins and their English abstracts, each containing 2000 sentences.",
        "The text was first automatically aligned and then hand-checked by a human supervisor.",
        "A sample passage is displayed in 'fable 1.",
        "In this experiment, we considered only the word chunks that appeared more than 4 times for fixed collocations and more than 6 times for flexible collocations.",
        "Table 4 illustrates the fixed collocations acquired by our method.",
        "Almost all collocations in Table 1 involve domain specific jargon, which ram on the oil pmclucts spot marckeI In Singapore N â€¢ gm rmizils, Xlow toduai iolonluirto",
        "cannot be constructed compositionally.",
        "For example, No 9 means \"Tokyo Cold Future market ended trading for the clay', but was never written as such.",
        "As well as No.",
        "9 , a number of sentence-level collocations were also extracted.",
        "No.",
        "9, No.",
        "18, No.",
        "23, No.",
        "26, No.",
        "35, No.",
        "56 and No.",
        "67 are typical heads of the stock market.",
        "report.",
        "These expressions appear everyday in stock market reports.",
        "It is interesting to notice the variety of fixed collocations.",
        "They differ in their constructions; noun phrases, verb phrases, prepositional phrases and sentence-level.",
        "Although conventional methods focus on noun phrases or try to encompass all kinds of collocations at the same time, we believe that fixed collocation is an important class of collocation.",
        "It is useful to intensively study fixed collocations because the collocation of more complex structures is difficult to learn regardless of the method used.",
        "Table 3 exemplifies the flexible collocations we acquired front the same corpus.",
        "No.",
        "1 to No.",
        "4 are typical expressions in stock market reports.",
        "These collocation are extremely useful for tenittlate-based machine translation systems.",
        "No.",
        "5 is an example of' a useless collocation.",
        "I3oth Oniron and Sumitomo Forestry are company names that co-occur frequently in stock market reports, but these two companies have no direct relation.",
        "In fact, more than half of all flexible collocations ttc-gunned were like No.",
        "5. l`o remove useless collocations, constraints on the character types would be useful.",
        "Most, useful Japanese flexible collocations contain at least one I1iragana3 character.",
        "'flins, 3,1apanese has three types of characters ( lliragana, Katakana, and 1<.itinji), each of which has ditlerent, amounts of information.",
        "In contrast, knglish has only",
        "many useless collocations can be removed by imposing this constraint on extracted strings.",
        "It is also interesting to compare our results with a Japanese-English dictionary for economics (Iwatsu, 1990).",
        "About half of Table 4 and all of 'Table 3 are not listed in the dictionary.",
        "In particular, no verb-phrase or sentence-level collocations are not covered.",
        "These collocations are more useful for translators than noun phrase collocations, but greatly differ from domain to domain.",
        "Thus, it is difficult in general to hand-compile a dictionary that contains these kinds of collocations.",
        "Because our method automatically extracts these collocations, it will be of significant use in compiling domain specific dictionaries.",
        "Finally, we briefly describe the coverage of the proposed method.",
        "For the corpus examined, 70 % of the fixed collocations and 35 % of the flexible collocations output by the method were correct.",
        "This level of performance was achieved in the face of two problems.",
        "â€¢ The English text was not a literal translation.",
        "Parts of Japanese sentence were often omitted and sometimes appeared in a different English sentence.",
        "â€¢ The data set was too small.",
        "We are now constructing a larger volume of corpus to address the second problem."
      ]
    },
    {
      "heading": "6 Conclusion",
      "text": [
        "We have described a new method for learning bilingual collocations from parallel corpora.",
        "Our method consists of two steps: (1) extracting useful word chunks by the word-level sorting technique and (2) constructing bilingual collocations by combining these chunks.",
        "This architecture reflects the fact that fixed collocations play a more crucial role than accepted in previous research.",
        "Our method not only extracts fixed collocations with high precision but also reduces the combinatorial explosion that would be otherwise considered inescapable in extracting flexible collocations.",
        "Although our research is in the preliminary stage and tested with a small number of Japanese stock market bulletins and their English, the ex-perirnental results have shown a number of interesting collocations that are not contained in a dictionary of economic terms."
      ]
    }
  ]
}
