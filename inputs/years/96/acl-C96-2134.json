{
  "info": {
    "authors": [
      "Yasuhiko Watanabe",
      "Masaki Murata",
      "Masahito Takeuchi",
      "Makoto Nagao"
    ],
    "book": "International Conference on Computational Linguistics",
    "id": "acl-C96-2134",
    "title": "Document Classification Using Domain Specific Kanji Characters Extracted by X2 Method",
    "url": "https://aclweb.org/anthology/C96-2134",
    "year": 1996
  },
  "references": [
    "acl-C94-2172"
  ],
  "sections": [
    {
      "heading": "Abstract",
      "text": [
        "In this paper we describe a method of classifying Japanese text documents using domain specific kanji characters.",
        "Text documents are generally classified by significant words (keywords) of the documents.",
        "However, it is difficult to extract these significant words from Japanese text, because Japanese texts are written without using blank spaces, such as delimiters, and must be segmented into words.",
        "Therefore, instead of words, we used domain specific kanji characters which appear more frequently in one domain than the other.",
        "We extracted these domain specific kanji characters by x2 method.",
        "Then, using these domain specific kanji characters, we classified editorial columns \"TENSEI JINGO\", editorial articles, and articles in \"Scientific American (in Japanese)\".",
        "The correct recognition scores for them were 47%, 74%, and 85%, respectively."
      ]
    },
    {
      "heading": "1 Introduction",
      "text": [
        "Document classification has been widely investigated for assigning domains to documents for text retrieval, or aiding human editors in assigning such domains.",
        "Various successful systems have been developed to classify text documents (Blosseville, 1992; Guthrie, 1994; Hamill, 1980; Masand, 1992; Young, 1985).",
        "Conventional way to develop document classification systems can be divided into the following two groups:",
        "1. semantic approach 2. statistical approach",
        "In the semantic approach, document classification is based on words and keywords of a thesaurus.",
        "If the thesaurus is constructed well, high score is achieved.",
        "But this approach has disadvantages in terms of development and maintenance.",
        "On the other hand, in the statistical approach, a human expert classifies a sample set of documents into predefined domains, and the computer learns from these samples how to classify documents into these domains.",
        "This approach offers advantages in terms of development and maintenance, but the quality of the results is not good enough in comparison with the semantic approach.",
        "In either approach, document classification using words has problems as follows: 1.",
        "Words in the documents must be normalized for matching those in the dictionary and the thesaurus.",
        "Moreover, in the case of Japanese texts, it is difficult to extract words from them, because they are written without using blank spaces as delimiters and must be segmented into words.",
        "2.",
        "A simple word extraction technique generates too many words.",
        "In the statistical approach, the dimensions of the training space are too big and the classification process usually fails.",
        "Therefore, the Japanese document classification on words needs a high precision Japanese morphological analyzer and a great amount of lexical knowledge.",
        "Considering these disadvantages, we propose a new method of document classification on kanji characters, on which document classification is performed without a morphological analyzer and lexical knowledge.",
        "In our approach, we extracted domain specific kanji characters for document classification by the x\" method.",
        "The features of documents and domains are represented using the feature space the axes of which are these domain specific kanji characters.",
        "Then, we classified Japanese documents into domains by measuring the similarity between new documents and the domains in the feature space."
      ]
    },
    {
      "heading": "2 Document Classification on Domain Specific Kanji Characters",
      "text": []
    },
    {
      "heading": "2.1 Text Representation by Kanji Characters",
      "text": [
        "In previous researches, texts were represented by significant words, and a word was regarded as a minimum semantic unit.",
        "13ut a word is not a minimum semantic unit, because a word consists of one or more morphemes.",
        "here, we propose the text representation by morpheme.",
        "We have applied this idea to the Japanese text representation, where a kanji character is a morpheme.",
        "Each kanji character has its meaning, and Japanese words (nouns, verbs, adjectives, and so on) usually contain one or more kanji characters which represent the meaning of the words to some extent.",
        "When representing the features of a text by kanji characters, it is important to consider which kanji characters are significant for the text representation and useful for classification.",
        "We assumed that these significant kanji characters appear more frequently",
        "in one domain than the other, and extracted them by the x2 method.",
        "From now on, these kanji characters are called the domain specific kanji characters.",
        "Then, we represented the content of a Japanese text x as the following vector of domain specific kanji characters:",
        "where component J' is the frequency of domain specific kanji i and 1 is the number of all the extracted kanji characters by the X2 method.",
        "In this way, the Japanese text x is expressed as a point in the re dimensional feature space the axes of which are the domain specific kanji characters.",
        "Then, we used this feature space for representing the features of the domains.",
        "Namely, the domain vi is represented using the feature vector of domain specific kanji characters as follows:",
        "We used this feature space not only for the text representation but also for the document classification.",
        "If the document classification is performed on kanji characters, we may avoid the two problems described in Section 1.",
        "1.",
        "It is simpler to extract kanji characters than to extract Japanese words.",
        "2.",
        "There are about 2,000 kanji characters that are considered necessary for general literacy.",
        "So, the maximum number of dimensions of the training space is about 2,000.",
        "Of course, in our approach, the quality of the results may not be as good as in the previous approaches using the words.",
        "Rut it is significant that we can avoid the cost of morphological analysis which is not so perfect."
      ]
    },
    {
      "heading": "2.2 Procedure for the Document Classification using Kanji Characters",
      "text": [
        "Our approach is the following:",
        "1.",
        "A sample set of Japanese texts is classified by a human expert.",
        "2.",
        "Kanji characters which distribute unevenly among text domains are extracted by the x2 method.",
        "3. l'he feature vectors of the domains are obtained by the information on domain specific kanji characters and its frequency of occurrence.",
        "4.",
        "Tile classification system builds a feature vector of a new document, compares it, with the",
        "feature vectors of each domain, and determines the domain which the document belongs to.",
        "Figure 1 shows a procedure for the document classification using domain specific kanji characters."
      ]
    },
    {
      "heading": "3 Automatic Extraction of Domain Specific Kanji Characters",
      "text": []
    },
    {
      "heading": "3.1 The Learning Sample",
      "text": [
        "For extracting domain specific kanji characters and obtaining the feature vectors of each domain, we use articles of \"Encyclopedia Heibonsha\" as the learning sample.",
        "The reason why we use this encyclopedia is that it is published in the electronic form and contains a great, number of articles.",
        "This en-cyclopedia was written by 6,722 authors, and contains about 80,000 articles, 6.52 x 107 characters, and 2.52 x 107 kanji characters.",
        "An example article of \"Encyclopedia Ileibonsha\" is shown in Figure 2.",
        "Unfortunately, the articles are not classified, but there is the author's name at the end of each article and his specialty is notified in the preface.",
        "Therefore, we can classify these articles into the authors' specialties automatically.",
        "The specialties used in the encyclopedia are wide, but they are not well balanced 1.",
        "Moreover, some domains of the authors' specialties contain only few",
        "articles.",
        "So, it is difficult to extract appropriate domain specific kanji characters from the articles which are classified into the authors' specialties.",
        "Therefore, it is important to consider that 206 specialties in the encyclopedia, which represent almost a half of the specialties, are used as the subjects of the domain in the Nippon Decimal Classification (NDC).",
        "For example, botany, which is one of the authors' specialties, is also one of the subjects of the domain in the NDC.",
        "In addition to this, the NDC has hierarchical domains.",
        "For keeping the domains well balanced, we combined the specialties using the hierarchical relationship of the NDC.",
        "The procedure for combining the specialties is as follows:",
        "1.",
        "We aligned the specialties to the domains in the NDC.",
        "206 specialties corresponded to the domains of the NDC automatically, and the rest was aligned manually.",
        "2.",
        "We combined 418 specialties to 59 code domains of the NDC, using its hierarchical relationship.",
        "Table 1 shows an example of the hierarchical relationship of the NDC.",
        "However, 59 domains are not well balanced.",
        "For example, \"physics\", \"electric engineering\", and \"German literature\" are the code domains of the NDC, and we know these domains are not well balanced by intuition.",
        "So, for keeping the domains well balanced, we combined 59 domains to 42 manually."
      ]
    },
    {
      "heading": "3.2 Selection of Domain Specific Kanji Characters by the X2 Method",
      "text": [
        "Using the value X2 of the X2 test, we can detect the unevenly distributed kanji characters and extract these kanji characters as domain specific kanji characters.",
        "Indeed, it was verified that X2 method is useful for extracting keywords instead of kanji characters(Nagao, 1976).",
        "Suppose we denote the frequency of kanji i in the domain j, xii, and we assume that kanji i is distributed evenly.",
        "Then the value X2 of kanji x?, is expressed by the equations as follows:",
        "where k is the number of varieties of the kanji characters and 1 is the number of the domains.",
        "If the value is relatively big, we consider that the kanji i is distributed unevenly.",
        "There are two considerations about the extraction of the domain specific kanji characters using the X2 method.",
        "The first is the size of the training samples.",
        "If the size of each training sample is different, the ranking of domain specific kanji characters is not equal to the ranking of the value x2.",
        "The second is that we cannot recognize which domains are represented by the extracted kanji characters using only the value x2 of equation (3).",
        "In other words, there is no guarantee that we can extract the appropriate domain specific kanji characters from every domain.",
        "From this, we have extracted the fixed number of domain specific kanji characters from every domain using the ranking of the value x of equation (4) instead of (3).",
        "Not only the value of equation (3) but the value X of equation (4) become big when the kanji i appears more frequently in the domain j than in the other.",
        "Table 2 shows top 20 domain specific kanji characters of the 42 domains.",
        "Further, Appendix shows the meanings of each domain specific kanji character of \"library science\" domain."
      ]
    },
    {
      "heading": "3.3 Feature Space for the Document Classification",
      "text": [
        "In order to measure the closeness between an unclassified document and the 42 domains, we proposed a feature space the axes of which are domain specific kanji characters extracted from the 42 domains.",
        "To represent the features of an unclassified document and the 42 domains, we used feature vectors (1) and (2) respectively.",
        "To find out the closest domain, we measured an angle between the unclassified document and the 42 domains in the feature space.",
        "If we are given a new document the feature vector of which is x, the classification system can compute the angle 0 with each vector vi which represents the domain i 0 (vi , x) = cos-1 and find vi with min 0 (vi, x).",
        "Using this procedure, every document is classified into the closest domain."
      ]
    },
    {
      "heading": "4 Document Classification Using Domain Specific Kanji Characters",
      "text": []
    },
    {
      "heading": "4.1 Experimental Results",
      "text": [
        "For evaluating our approach, we used the following three sets of articles in our experiments:",
        "1. articles in \"Scientific American (in Japanese)\" (162 articles) 2. editorial columns in Asahi Newspaper \"TENSE' JINGO\" (about 2,000 articles) 3. editorial articles in Asahi Newspaper (about 3,000 articles)",
        "Because the articles in \"Scientific American (in Japa-nese)\" are riot classified, we classified them manually.",
        "The articles of \"TENSE' :JINGO\" and the editorial articles are classified by editors into a hi",
        "erarchy of domains which differ from the domains of the NDC.",
        "We aligned these domains to the 42 domains described in Section 3.1.",
        "Some articles in thereof contain two or more themes, and these articles are classified into two or more domains by editors.",
        "For example, the editorial article \"Too Many Katakana Words\" is classified into three domains.",
        "In these cases, we judge that the result of the automatic classification is correct when it corresponds to one of the domains where the document is classified by editors.",
        "Figure 3 , Figure 4, and Figure 5 describe the variations of the classification results with respect to the number of domain specific kanji characters."
      ]
    },
    {
      "heading": "4.2 Evaluation",
      "text": [
        "In our approach, the maximum correct recognition scores for the editorial articles and the articles in \"Scientific American (in Japanese)\" are 74 % and 85 %, respectively.",
        "Considering that our system uses only the statistical information of kanji characters and deals with a great amount of documents which cover various specialties, our approach achieved a good result in document classification.",
        "From this, we believe that our approach is efficient for broadly classifying various subjects of the documents, e.g. news stories.",
        "A method for classifying news stories is significant for distributing and retrieving articles in electronic newspaper.",
        "The maximum recognition scores for \"TENSEI JINGO\" is 47 %.",
        "The reasons why the result is far worse than the results of the other are: 1.",
        "The style of the documents The style of \"TENSEI JINGO\" is similar to that of an essay or a novel and it is written in colloquial Japanese.",
        "In contrast, the style of the editorial articles and \"Scientific American (in Japanese)\" is similar to that of a thesis.",
        "We think the reason why we achieved the good result in the classification of the editorial articles and \"Scientific American (in Japanese)\" is that many technical terms are used in there and it is likely that the kanji characters which represent the technical terms are domain specific kanji characters in that domain.",
        "2.",
        "Two or more themes in one document Many articles of \"TENSEI JINGO\" contain two or more themes.",
        "In these articles, it is usual that the introductory part has little relation to the main theme.",
        "For example, the article \"Splendid Retirement\", whose main theme is the Speaker's resignation of the House of Representatives, has an introductory part about the retirement of famous sportsmen.",
        "In conclusion, our approach is not effective in classifying these articles.",
        "However, if we divide these articles into semantic objects, e.g. chapter and section, these semantic objects may be classified in our approach.",
        "Table 3 shows the results of classifying full text and each chapter of a book \"Artificial Intelligence and Human Being\".",
        "Because this book is manually classified into the domain"
      ]
    },
    {
      "heading": "5 Conclusion",
      "text": [
        "The quality of the experimental results showed that our approach enables document classification with a good accuracy, and suggested the possibility for Japanese documents to be represented on the basis of kanji characters they contain."
      ]
    },
    {
      "heading": "6 Future Work",
      "text": [
        "Because the training samples are created without this application in mind, we may be able to improve the performance by increasing the size of the training samples or by using different samples which have the similar styles and contents to the documents.",
        "We would also like to study the relation between the quality of the classification result and the size of the documents."
      ]
    },
    {
      "heading": "References",
      "text": []
    },
    {
      "heading": "Appendix",
      "text": []
    }
  ]
}
