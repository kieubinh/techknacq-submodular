{
  "info": {
    "authors": [
      "Masaaki Nagata"
    ],
    "book": "International Conference on Computational Linguistics",
    "id": "acl-C96-2136",
    "title": "Context-Based Spelling Correction for Japanese OCR",
    "url": "https://aclweb.org/anthology/C96-2136",
    "year": 1996
  },
  "references": [
    "acl-A88-1019",
    "acl-A92-1018",
    "acl-C94-1032",
    "acl-W96-0205"
  ],
  "sections": [
    {
      "heading": "Abstract",
      "text": [
        "We present a novel spelling correction method for those languages that have no delimiter between words, such as Japanese, Chinese, and Thai.",
        "It consists of an approximate word matching method and an N-best word segmentation algorithm using a statistical language model.",
        "For OCR errors, the proposed word-based correction method outperforms the conventional character-based correction method.",
        "When the baseline character recognition accuracy is 90%, it.",
        "achieves 96.0% character recognition accuracy and 96.3% word segmentation accuracy, while the character recognition accuracy of character-based correction is 93.3%."
      ]
    },
    {
      "heading": "1 Introduction",
      "text": [
        "Automatic spelling correction research dates back in the 1960s.",
        "Today, there are some excellent academic and commercial spell checkers available for English (Kukich, 1992).",
        "However, for those languages that have a different morphology and writing system from English, spelling correction remains one of the significant unsolved research problems in computational linguistics.",
        "The basic strategy for English spelling correction is simple: Word boundaries are defined by white space characters.",
        "If the tokenized string is not found in the dictionary, it is either a non-word or an unknown word.",
        "For a non-word, correction candidates are generated by approximately matching the string with the dictionary, using context-independent word distance measures such as edit distance (Wagner and Fischer, 1974; Kernighan et.",
        "al., 1990).",
        "It is impossible to apply these \"isolated word error correction\" techniques to Japanese in two reasons: First, in noisy texts, word tokenization is difficult because there are no delimiters between words.",
        "Second, context-independent word distance measures are useless because the average word length is very short, (< 2), and the character set is huge ( > 3000).",
        "There are a large number of one edit.",
        "distance neighbors for a Japanese word.",
        "In English spelling correction, \"word boundary problem\", such as splits (forgot for you) and run-ons (in form – > inform), and \"short, word problem\"(at on, or, of, at, it, to, etc.)",
        "are also known to be very difficult..",
        "Context, information, such as word N-gram, is used to supplement, the underlying context-independent correction for these problematic.",
        "examples (Gale and Church, 1990; Mays et, al., 1991).",
        "To the contrary, Japanese spelling correction must.",
        "be essentially context-dependent, because Japanese sentence is, as it were, a run-on sequence of short, words, possibly including some typos, something like (Iforgolotinformyou I forgot.",
        "to inform you).",
        "In this paper, we present a novel approach for spelling correction, which is suitable for those languages that have no delimiter between words, such as Japanese.",
        "It.",
        "consists of two stages: first, all substrings in the input sentence are hypothesized as words, and those words that approximately matched with the substrings are retrieved from the dictionary as well as those that.",
        "exactly matched.",
        "Based on the statistical language model, the.",
        "N-best word sequences are then selected as correction candidates from all combinations of exactly and approximately matched words.",
        "Figure 1 illustrates this approach.",
        "Out of the list of character recognition candidates for the input sentence \"IP 1-iAg-,410fEl6W-V1W=IEA1-60 which means \"to fill out the necessary items in the application form.",
        "\", the system searches the combination of exactly matched words (solid boxes) and approximately matched words (dashed boxes) 1.",
        "The major contribution of this paper is its solutions of the word boundary problem and short word problem in Japanese spelling correction.",
        "By introducing a statistical model of word 'OCR output tends to be very noisy, especially for hand writing.",
        "To compensate for this behavior, OCRs usually output an ordered list of the best N characters.",
        "The list of the candidates for an input string is called charmAm.tuatrix.",
        "length and spelling, the proposed system accurately places word boundaries in noisy texts that include non-words and unknown words.",
        "Ily using the character-based context model, it ace [Irately selects correction candidates for short words from the large nuntber of approximately matched words with the saute edit, distance.",
        "'Mc goal of our project, is to implement an interactive word corrector for a handwritten PA X-0C1i, system.",
        "We are especially interested in texts that, include addresses, names, and messages, such as order forms, questionnaires, and telegraph."
      ]
    },
    {
      "heading": "2 Noisy Channel Model for Character Recognition",
      "text": [
        "First, we formulate the spelling correction of 0( errors in the noisy channel paradigm.",
        "Let (' rep resent the input string and X represent the OC output string.",
        "Finding the most probable string C given the 0( output X amounts to maximizing the function P( X IC)P(C),",
        "where 11 is the string length.. P(.cilci) is called the confusion matrix of characters.",
        "It is trained using the input and output strings of the OCR.",
        "The confusion matrix is highly dependent on the character recognition algorithm and the quality of the input, document.",
        "It, is a labor intensive task to prepare a confusion matrix earl' char, actor recognition system, since Japanese, has more than 3,000 characters.",
        "Therefore, we used a simple OCR model where the confusion matrix is approximated by the correct character distribution over the rank of the candidates.",
        "We assume that the rank order distribution of the correct characters is a geometric distribution whose parameter is the accuracy of the first candidate.",
        "Let ci he the i-tit character in the input, string, is be the j-th candidate for and p be the probability that, the first candidate is correct.",
        "'L'he confusion probability P(xij lei) is approximated as, n.r,s; ) P(J:,.",
        "; is correct) p( p)i--1 (4) Equation ('1) anus to approximate the accuracy of the first Candidate and the tendency that.",
        "the reliability of the candidate decreases abruptly as its rank increases.",
        "I'or example, if the recognition accuracy of the first.",
        "candidate p is 0.75, we will assign the probability of the first, second, and third candidates to (1.75, 0.19, and 0.05, respectively, regardless of the input ;aid output characters.",
        "One of the benefits of using a simple OCIt model is that the spelling correction system becomes highly independent of the underlying 0( characteristics.",
        "Obviously, a more sophisticated OCR model would improve error correction performance, but even this simple (W H. model works fairly well in our experiments 2.",
        "'One of the practical reasons for using the geometric distriblition is that, we, used the confusion matrix for implementing the OCR simulator.",
        "We feel it, is unfair to use the same confusion matrix both fur error generation and error correction."
      ]
    },
    {
      "heading": "3 Word Segmentation Algorithm",
      "text": []
    },
    {
      "heading": "3.1 Statistical Language Model",
      "text": [
        "For the language model in Equation (1), we used the part of speech trigram model (POS trigram or 2nd-order IIMM).",
        "It is used as tagging model in English (Church, 1988; Cutting et al., 1992) and morphological analysis model (word segmentation and tagging) in Japanese (Nagata, 1994).",
        "Let the input character sequence be C c1 c2 en, .",
        "We approximate P(C) by P(W,T), the joint probability of word sequence W = wiw2 w„ and part of speech sequence '1' = t„.",
        "P(W,T) is then approximated by the product of parts of speech trigram probabilities P(tilti_2,-ti_1) and word output probabilities for given part of speech P(wi",
        "computing the relative frequencies of the corresponding events in training corpus 3."
      ]
    },
    {
      "heading": "3.2 Forward-DP Backward-A* Algorithm",
      "text": [
        "Using the language model (5), Japanese morphological analysis can be defined as finding the set of word segmentation and parts of speech (W, that maximizes the joint probability of word sequence and tag sequence P(W,T).",
        "This maximization search can be efficiently implemented by using the forward-DP backward-A* algorithm (Nagata, 1994).",
        "It is a natural extension of the Viterbi algorithm (Church, 1988; Cutting et al., 1992) for those languages that do not have delimiters between words, and it can generate N-best morphological analysis hypotheses, like tree-trellis search (Soong and Huang, 1991).",
        "The algorithm consists of a forward dynamic programming search and a backward A* search.",
        "The forward search starts from the beginning of the input sentence, and proceeds character by character.",
        "At each point in the sentence, it looks up the combination of the best partial parses ending at the point and word hypotheses starting at the point.",
        "If the connection between a partial parse and a word hypothesis is allowed by the language model, that is, the corresponding part of speech trigram probability is positive, a new continuation parse is made and registered in the best partial path table.",
        "boor example, at point 4 in Figure 1, the final word of the partial parses ending at 4 are FIll,3Ag-).",
        "('application'), ('prospect'), 'As a word segmentation model, the advantage of the POS trigram model is that it can be trained using a smaller corpus, than the word bigram model.",
        "and 3.Ag-i.",
        "('inclusive'), while the word hypotheses starting at 4 are fliA ('form'), fpJ ('same'), ('moon'), and PI ('circle').",
        "In the backward A* search, we consider a partial parse recorded in the best partial path table as a state in A* search.",
        "The backward search starts at the end of the input sentence, and backtracks to the beginning of the sentence.",
        "Since the probabilities of the best possible remaining paths are exactly known by the forward search, the backward search is admissible.",
        "We made two extensions to the original forward-DP backward-A* algorithm to handle OCR outputs.",
        "First, it retrieves all words in the dictionary that match the strings which consist of a combination of the characters in the matrix.",
        "Second, the path probability is changed to the product of the language model probability and the OCR model probability, so as to get the most likely character sequence, according to Equation (1)."
      ]
    },
    {
      "heading": "4 Word Model for Non-Words and Unknown Words",
      "text": [
        "The identification of non-words and unknown words is a key to implement Japanese spelling corrector, because word identification error severely affects the segmentation of neighboring words.",
        "We take the following approach for this word boundary problem.",
        "We first hypothesize all substrings in the input sentence as words, and assign a reasonable non-zero probability.",
        "For example, at point 7 in Figure 1, other than the exactly and approximately matched words starting at 7 such as 2.0W ('necessary'), ('necessarily'), and A ('pond'), we hypothesize the substrings Z, ZO, ... as words.",
        "We then locate the most likely word boundaries using the forward-DP backward-A* algorithm, taking into account the entire sentence.",
        "We use a statistical word model to assign a probability to each substring (Nagata, 1996).",
        "It is defined as the joint probability of the character sequence if it is an unknown word.",
        "Without loss of generality, we can write,",
        "where c1 ...ck is the character sequence of length k that constitutes word We call P(k) the word length model, and P(ci ...ck lk) the spelling model.",
        "We assume that word length probability P(k) obeys a Poisson distribution whose parameter is the average word length A,",
        "This means that we think word length is the interval between hidden word boundary markers, which are randomly placed where the average interval equals the average word length.",
        "Although",
        "this word length model is very simple, it, plays a key role in making the word segmentation algorithm robust.",
        "We approximate the spelling probability given word length P(ci ...ckik) by the word-based character trigram model, regardless of word length.",
        "Since there are more than 3,000 characters in Japanese, the amount of training data would be too small if we divided them by word length.",
        "where \"#\" indicates the word boundary marker.",
        "Note that the word-based character trigram model is different from the sentence-based character trigram model.",
        "The former is estimated from the corpus which is segmented into words.",
        "It assigns large probabilities to character sequences that appear within a word, and small probabilities to those that appear across word boundaries."
      ]
    },
    {
      "heading": "5 Approximate Match for Correction Candidates",
      "text": [
        "As described before, we hypothesize all substrings in the input sentence as words, and retrieve approximately matched words front the dictionary as correction candidates.",
        "For a word hypothesis, correction candidates are generated based on the minimum edit distance technique (Wagner and Fischer, 1974).",
        "Edit distance is defined as the minimum number of editing operations (insertions, deletions, and substitutions) required to transform one string into another.",
        "if the target is OCR, output, we can restrict the type of errors to substitutions only.",
        "Thus, the similarity of two words can be computed as c/n, where c is the number of matched characters and n is the length of the.",
        "misspelled (and dictionary) word.",
        "For longer words (> 3 characters), it is reasonable to generate correction candidates by retrieving all words in the dictionary with similarity above a certain threshold (c/n > 0.5).",
        "for example, at point 0 in Figure 1, FP 1✓3A1-)1, ('application') is retrieved by approximately matching the string 1.,3A:7)- with the dictionary (C/ \".= 3/4 -= 0.75).",
        "However, for short words (1 or 2 character word), this strategy is unrealistic because there are a large number of words with one edit distance.",
        "Since the total number of one character words and two character words amounts to more than 80% of the total word tokens in Japanese, we cannot neglect.",
        "these short words.",
        "It is natural to resort to context-dependent word correction methods to overcome the short word problem.",
        "In English, (Gale and Church, 1990) achieved good spelling check performance using word Ingrains.",
        "However, in Japanese, we cannot use word bigram to rank correction candidates, because we have to rank them before we perform word segmentation.",
        "'Therefore, we used character context instead of word context.",
        "Vor a short word, correction candidates with the same edit distance are ranked by the joint probability of the previous and the following two characters in the context.",
        "This probability is computed using the sentence-based character trigram model.",
        "For 2 character words, for example, we first retrieve a. set of words in the dictionary that, match exactly one character with the one in the input string.",
        "We then compute the 6-grain probability for all candidate words sisi+i, and rank them according to the probability.",
        "!for example, at point.",
        "12 in Figure 1, there are many two character words whose first character is WE, such as Ad Ail ('mention'), add ('article'), riE A.",
        "('journalist'), 8A ('entry'), ('commemoration'), etc.",
        "By using character contexts, the system selects CA and Ca as approximately matched word hypotheses."
      ]
    },
    {
      "heading": "6 Experiments",
      "text": []
    },
    {
      "heading": "6.1 Language Data and OCR. Simulator",
      "text": [
        "We used the.",
        "ATR, Dialogue Database (Ehara et al., 1990) to train and test the spelling correction method.",
        "It is a corpus of approximately 800,000 words whose word segmentation and part of speech tagging were laboriously performed by hand.",
        "In this experiment, we used one fourth of the Alit Corpus, a portion of the keyboard dialogues in the conference registration domain.",
        "Table 1 shows the number of sentences, words, and characters for training and test data.",
        "The test data is not included in the training data.",
        "That is, open data were tested in the experiment.",
        "For the spelling correction experiment, we used an OCR simulator because it is very difficult, to obtain a large amount of test.",
        "data with arbitrary recognition accuracies.",
        "The OCR, simulator takes an input string and generates a character matrix using a confusion matrix for Japanese handwriting OCR, developed in our laboratory.",
        "The parameters of the.",
        "OCR simulator are the recognition accuracy of the first candidate (first candidate correct, rate), and the percentage of the correct.",
        "char",
        "acters included in the character matrix (correct candidate included rate).",
        "In general, the accuracy of current Japanese handwriting OCR, is around 90%.",
        "It is lower than that of printed characters (around 98%) due to the wide variability in handwriting.",
        "When the input comes from FAX, it degrades another 10% to 15%, because the resolution of most FAX machines is 200dpi, while that of scanners is 400dpi.",
        "Therefore, we made four test sets of character matrices whose first candidate correct rates and correct candidate included rates were (70%, 90%), (80%, 95%), (90%, 98%), and (95%, 98%), respectively.",
        "The average number of candidates for a character was 8.9 in these character matrices 4."
      ]
    },
    {
      "heading": "6.2 Character Recognition Accuracy",
      "text": [
        "First, we compared the proposed word-based spelling corrector using the POS trigram model (POS3) with the conventional character-based spelling corrector using the character trigram model (Char3).",
        "Table 2 shows the character recognition accuracies after error correction for various baseline OCR, accuracies.",
        "We also changed the condition of the approximate word match.",
        "In Table 2, Matchl, Matcli2, and Match3 represent that the approximate match for substrings whose lengths were more than or equal to one, two, and three characters, respectively.",
        "In general, the approximate match for short.",
        "words improves character recognition accuracy by about, one percent.",
        "When the first candidate correct rate is low (70% and 80%), the word-based corrector significantly outperforms the character-based corrector.",
        "This is because, by approximate word matching, the word-based corrector can correct words even if the correct characters are not.",
        "present in the matrix.",
        "When the first candidate correct rate is high (90% and 95%), the word-based corrector still outperforms the character-based corrector, although the difference is small.",
        "This is because most correct characters are already included in the matrix."
      ]
    },
    {
      "heading": "6.3 Word Segmentation and Word Correction Accuracy",
      "text": [
        "First, we define the performance measures of Japanese word segmentation and word correction.",
        "We will think of the output of the spelling corrector as a set of 2-tuples, word segmentation and orthography.",
        "We then compare the tuples contained in the system's output to the tuples contained in the standard analysis.",
        "For the N-best candidate, we will make the union of the tuples contained in each candidate, in other words, we will make a word lattice from N-best candidates, and compare them to the tuples in the standard.",
        "For comparison, we count the number of tuples in the standard (Std), the number of tuples in the system output (Sys), and the number of matching tuples (M).",
        "We then calculate recall (M/Std) and precision ( M /Sys) as accuracy measures.",
        "We define two degrees of equality among tuples for counting the number of matching tuples.",
        "l'or word segmentation accuracy, two tuples are equal if they have the same word segmentation regardless of orthography.",
        "For word correction accuracy, two tuples are equal if they have the same word segmentation and orthography.",
        "Table 3 shows the words segmentation accuracy and word correction accuracy.",
        "The word segmentation accuracy of the spelling corrector is significantly high, even if the input is very noisy.",
        "For example, when the accuracy of the baseline OCR.",
        "is 80%, since the average number of characters and words in the test sentences are 20.1 and 11.3, there are 4.0 (=20.1*(1-0.80)) character errors in the sentence, in average.",
        "However, 94.5% word segmentation recall means that there are only 0.62 (=11.3*(1-0.945)) word segmentations that are not found in the first candidate.",
        "Moreover, we feel the word correction accuracy in Table 3 is satisfactory for an interactive spelling corrector.",
        "For example, when the accuracy of the baseline OCR, is 90%, there are 2.0 (.=-20.1*(10.90)) character errors in the test sentence.",
        "llowever, 92.8% recall for the first candidate and 95.6% recall for the top-5 candidates means that.",
        "there are only 0.81 (11.3*(1-0.928)) words that are not found in the first candidate, and if you examine the top-5 candidates, this value is reduced to (1.50 (11.3*(1-0.956)).",
        "That is, about half of the errors in the first candidate are corrected by simply selecting the alternatives in the word lattice."
      ]
    },
    {
      "heading": "7 Discussion",
      "text": [
        "Previous works on Japanese OCR, error correction are based on either the character trigram model or time part of speech bigranm model.",
        "'their targets arc printed characters, not handwritten characters.",
        "That, is, they assume the underlying OCR's accuracy is over 90%.",
        "Moreover, their treatment of unknown words and short words is rather ad hoc.",
        "(Takao and Nishino, 1989) used part of speech bi-gram and best first search for OCR correction.",
        "They used heuristic templates for unknown words.",
        "(Ito and Maruyama., 1992) used part of speech bi-gram and beam search in order to get multiple candidates in their interactive OCR corrector 5 The proposed Japanese spelling correction method uses part of speech trigram and N-best search.",
        "This combination is theoretically and practically more accurate than previous methods.",
        "In addition, by using statistical word model, and context based approximate word match, it be-conies robust enough to handle very noisy texts, such as the output of VAX-OCR systems.",
        "'lb improve the word correction accuracy, more powerful language models, such as word bigram, are required.",
        "(Jolinek, 1985) pointed out that \"POS (part of speech) classification is too crude and not necessarily suited to language modeling\".",
        "Ilowever, it is too expensive to prepare a large manually segmented corpus of each target do-maill to compute the word bigram.",
        "Therefore, we are thinking of making a self-organised word segmentation method by generalising the Forward-Backward algorithm for those languages that have no delitniter between words (Na,gata, 199(i)."
      ]
    },
    {
      "heading": "8 Conclusion",
      "text": [
        "We have presented a spelling correction method for noisy Japanese texts.",
        "We are currently building an interactive Japanese spelling corrector jspell, where words are the basic object manipulated by the user in operations such as replace, accept, and edit.",
        "It is something like the Japanese counterpart.",
        "of Unix's spelling corrector ispell, with a, user interface similar to kunu-lokanji converter, a popular .lapanese.",
        "input method 5According to Fig. 6 in (Takao and Nishino, 1989), they achieved about 95% character recognition accuracy when the baseline accuracy is 91% for magazines and introductory textbooks of science and technology domain.",
        "According to Table.",
        "l in (Ito and Marnyarna, 1992), they achieved 94.61% character recognition accuracy when the baseline accuracy is 87.46% for patents in electric engineering domain.",
        "We achieved 96.0% character recognition accuracy, when the baseline accuracy is 90% in the conference registration domain.",
        "It is very difficult to compare our results with the previous results because the experiment conditions are completely different.",
        "for the ASCII keyboard."
      ]
    }
  ]
}
