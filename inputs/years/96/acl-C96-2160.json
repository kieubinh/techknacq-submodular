{
  "info": {
    "authors": [
      "Kentaro Torisawa",
      "Jun'ichi Tsujii"
    ],
    "book": "International Conference on Computational Linguistics",
    "id": "acl-C96-2160",
    "title": "Computing Phrasal-Signs in HPSG Prior to Parsing",
    "url": "https://aclweb.org/anthology/C96-2160",
    "year": 1996
  },
  "references": [
    "acl-P85-1018",
    "acl-P95-1013"
  ],
  "sections": [
    {
      "heading": "Abstract",
      "text": [
        "'this paper describes techniques to corn-pile lexical entries in HPSG (Pollard and Sag, 1987; Pollard and Sag, 1993)-style grammar into a set of finite state automata.",
        "The states in automata are possible signs derived from lexical entries and contain information raised from the lexical entries.",
        "The automata are augmented with feature structures used by a partial unification routine and dc-layedgrozen definite clause programs."
      ]
    },
    {
      "heading": "1 Introduction",
      "text": [
        "Our aim is to build an efficient and robust HPSG-based parser.",
        "HPSG has been regarded as a sophisticated but fragile awl inefficient framework.",
        "However, its principle-based architecture enables a parser to handle real world texts only by giving concise core grammar, including principles and templates for lexical entries, default lexical en-tries(Horiguchi et al., 1995).",
        "The architecture is different from those of conventional unification-based formalisms which require hundreds of CIF skeletons to parse real world texts.",
        "However, these design principles of [MSG have drawbacks in parsing cost.",
        "That is, signs/feature structures corresponding to non-terminal symbols in CFG become 'visible only after applying principles and a parser has to create feature structures one by one using unification.",
        "addition, identity checking of non-terminal symbols used to eliminate spurious signs must be replaced with sub-sumption checking, which further deteriorates efficiency.",
        "Our grammar compiler computes skeletal part of possible phrasal-signs from individual lexical entries prior to parsing, and generates a set of finite state automata from lexical entries to avoid the above drawbacks.",
        "We call this operation Off-line raising and an automaton thus generated is called a Lexical Entry Automaton (LA).",
        "Its states corresponds to part of signs and each transition between states corresponds to application of a rule schema, which is a non-lexical component of grammar.",
        "Our parsing algorithm adopts a two-phased parsing method.",
        "Phase 1 Bottom-up chart-like parsing with LAs.",
        "Phase 2 Computing part of feature structures which cannot be computed at compile-time.",
        "We call the feature structures that are represented as states in automata and are computed at compile-time Core-structures, and the feature structures which are to be computed in Phase 2, Substructures.",
        "In Phase 1 parsing, a core-structure correspond to a state in an l ,A.",
        "The cost of computing substructures at Phase 2 is minimized by Dependency Analysis and Partial Unification.",
        "The next section describes rule schemata, central components of the formalism, and gives a definition of Definite Clause Programs.",
        "Section 3 describes how to obtain LAs from lexical entries and how to perform the Phase 1 parsing.",
        "Section 4 explains the Phase 2 Parsing algorithm.",
        "A parsing example is presented in Section 5.",
        "The effectiveness of our method is exemplified with a series of experiments in Section 6."
      ]
    },
    {
      "heading": "2 Rule Schemata and Definite Clause Programs",
      "text": [
        "Our formalism has only one type of component as non-lexical components of grammar, i.e., rule schemata.'",
        "An example is shown in Figure if.",
        "A rule schema consists of the following two items.",
        "I In our current system, rule schemata are generated from principles and rewriting rules according to a specification given by a programmer.",
        "rule(R) a rewriting rule without specific syntactic categories; fs(R) a feature structure.",
        "A characteristic of HPSG is in the flexibility of principles which demands complex operations, such as append or subtraction of list-value feature structures.",
        "In.",
        "our formalism, those operations are treated by a Definite Clause Program.",
        "A DCP can be seen as a logic program language whose arguments are feature structures.",
        "An auxiliary term, a query to a DCP augmenting a rule schema, is embedded in a feature structure of a rule schema as the value of goals.",
        "The rule schema in the example has an auxiliary term, append( , [2] , [3] ).",
        "The bottom-up application of the rule schema R is carried out as follows.",
        "First, two daughter signs are substituted to the HEAD-DTR position and NON-HEAD-DTR position of the rewriting rule rule(R).",
        "Then, the signs are unified with the head-dtr value and the non-head-dtr value of the feature structure of the schema, f s(R).",
        "Finally, the auxiliary term for DCPs given in the schema is evaluated.",
        "Our definition of a DCP has a more operational flavor than that given by Carpenter(Carpenter, 1992).",
        "The definition is crucial to capture the correctness of our method.2 Definition 1 (DCP) A definite clause program (DCP) is a finite set of feature structures, each of which has the following form.",
        "A feature structure of the above form corresponds to a clause in Prolog.",
        "H, B0, • • • , B„ corresponds to literals in Prolog.",
        "H is the head and B0, • ,B„, are literals in the body of a clause.",
        "Definition 2 (Execution of DCP) Execution of a DCP P for the query,",
        "must be unifiable with [ goals 0 ].",
        "In this case, we call the sequence (Tic.",
        "• ,r„) a resolution sequence.",
        "2 Though, through the rest of the paper, we treat the definition as if it were used in an actual implementation, the actual implementation uses a more efficient method whose output is equivalent with the result obtained by the definition.",
        "(next-steps)2-1 I goals of Queryli dr2U • • • LI ri represents the goals which are to be solved in the steps following the i-th step.",
        "The goals are instantiated by the steps from the first one to i-th one, through structure sharings.",
        "The result of execution in a Prolog-like sense appears in the query.",
        "Figure 2 is an example of execution for the query append ( [a] , [b] , , whose definition is based on a standard definition of append in Prolog.",
        "Given this definition of DCPs, an application of a rule schema to two (laughter signs D1 and D2 can be expressed in the following form, where"
      ]
    },
    {
      "heading": "3 Lexical Entry Automata",
      "text": [
        "This section presents a Lexical Entry Automaton (LA).",
        "The inefficiency of parsing in HPSG is due to the fact that what kind of constituents phrasal-signs would become is invisible until the whole sequence of applications of rule schemata is completed.",
        "Consider the parse tree in Figure 3.",
        "The phrasal-signs S1 and S2 are invisible until a parser creates the feature structures describing them, using expensive unification.",
        "Our parsing method avoids this on-line construction of phrasal-signs by computing skeletal part of parse trees prior to parsing.",
        "In Figure 3, our compiler generates Si and S2 only from the lexical entry \"wrote,\" without specifying the non-head daughters indicated by the triangles in Figure 3.",
        "Since the non-head daughters are token-identical with subcat values of the lexical entry for \"wrote\", the obtained skeletal parse tree contains the information that S1 takes a noun phrase as object and S2 selects another noun-phrase.",
        "Then unifying those non-head daughters with actual signs constructed from input, parsing can be done.",
        "An LA expresses a set of such skeletal parse trees.",
        "A state in an LA corresponds to a phrasal-sign such as S1 and S2.",
        "They are called core-structures.",
        "A transition arc is a domination link between a phrasal-sign and its head daughter, and its condition for transition on input is a non-head [first 3 rest 1[1)",
        "daughter, such as signs tagged [1] and [2] in Figure 3.",
        "Kasper et al.",
        "presented an idea similar to this off-line raising in their work on HPSG-TAG compiler(Kasper et al., 1995).",
        "The difference is that our algorithm is based on substitution, not adjoining.",
        "Furthermore, it is not clear in their work how off-line raising is used to improve efficiency of parsing.",
        "Before giving the definition of LAs, we define the notion of a quasi-sign, which is part of a sign and constitutes LAs.",
        "Definition 3 (quasi-sign(n)) For a given integer n, a feature structure S is a quasi-.sign(n) if it has some of the following four attributes: syn, sem, head-dtr,non-head-dtr and does not have values for the paths (head-dtr non-head-dtr)\" .",
        "A quasi-sign(n) cannot represent a parse tree whose height is more than n, while a sign can express a parse tree with any height.",
        "Through the rest of this paper, we often extract a quasi-sign(n) S from a sign or a quasi-sign(W) 5' where n < n'.",
        "This operation is denoted by S c[r(S',n).",
        "This means that S is equivalent to S' except for the attributes head-dtr and non-head-dtr whose root is the (head-dtr +non-head-dtr)\" value in S'.",
        "Note that S and S' are completely different entities.",
        "In other words, S and S' pose different scopes on structure sharing tags.",
        "In addition, we also extract a feature structure F reached by a path or an attribute p in a feature structure F'.",
        "We denote this by F = val(F',p) and regard F and F' as different entities.",
        "Definition 4 (Lexical Entry Automaton(LA)) A Lexical Entry Automaton is a tuple (Q,A,q0) where, Q : a set of states, where a state is a quasi-sign(0).",
        "A : a set of transition arcs between states, where a transition arc is a tuple where qd,q,„ E Q, N is a quasi-sign(0), D is a quasi-sign(1) and R is a rule schema.",
        "qit the initial state, which corresponds to a lexical entry.",
        "In a transition arc (qd,q,,,,N, , q„, denotes the destination of the transition arc, and qd is the root of the arc.",
        "The N is a non-head daughter of a phrasal-sign, i.e., the destination state of the transition, and expresses the input condition for the transition.",
        "The D is used to represent the dependency between the mother sign and the daughters through structure sharings.",
        "This is called a Dependency Feature Structure(DFS) of the transition arc, the role of which will be discussed in Section 4.",
        "R is the rule schema used to create this arc.",
        "An LA is generated from a lexical entry l by the following recursive procedure:",
        "1.",
        "Let S be VI, A be an empty set and sd = 2.",
        "For each rule schema 1?, and for each of its each resolution sequence (rt , • • • ,r„) obtain,",
        "and if D is a feature structure, obtain sin = ex(D, 0) and N = ex(val(D, non-head-dtr), 0).",
        "3.",
        "If D is a feature structure, • If there is a state 8,i, E S such that s'n, 8„„ 4 let s„, be Otherwise, add s,„ to S. • If there is no TT = (s N\", D\", 17) C",
        "A such that s,, ti Si„ s,1 N 'Tor any feature structures f and f', f f' if f' and f' C f",
        "N\" and D D\", then, add the tuple (sd,sm,N,D,R) to A.",
        "4.",
        "If the new quasi-sign(0) (sm) was added to S in the previous step, let sd be sm and go to Step 2.",
        "When this terminates, (S, A, 1) is the LA for 1.",
        "The major difference of Step 2 and the normal application of a rule schema is that non-head-dtr values are not specified in Step 2.",
        "In spite of this underspecification, certain parts of the non-head-dtr are instantiated because they are token-identical with certain values of the head-dtr domain.",
        "By unifying non-head-dtr values with actual signs to be constructed from input sentences, a parser can obtain parsing results.",
        "For more intuitive explanation, see (Torisawa and Tsujii, 1996).",
        "However, this simple LA generation algorithm has a termination problem.",
        "There are two potential causes of non-termination.",
        "The first is the generative capacity of a feature structure of a rule schema, i.e., a rule schema can generate infinite variety of signs.",
        "The second is non-termination of the execution of DCP in Step 2 because of lack of concrete non-head daughters.",
        "For the first case, consider a rule schema with the following feature structure.",
        "[syn[ counter (barl [1]) head-dtr [ syn [ counter [1] Then, this can generate an infinite sequence of signs, each of which contains a part, [ counter (bar, bar, • • , bar) ] and is not equivalent to any previously generated sign.",
        "In order to resolve this difficulty, we apply the restriction (Shieber, 1985) to a rule schemata and a lexical entry, and split the feature structure F = f s(R) of a rule schema R or a lexical entry F = 1, into two, namely, core(F) and sub(F) such that F = core(F) U sub(F).",
        "The definition of the restriction here is given as follows.",
        "Definition 5 (paths) For any node n in a feature structure F, path„s(n,F) is a set of all the paths that reaches n from the root of F.",
        "• There is a node no in F .such that paths(no, F) = paths(n, F') and type() type(no).",
        "• For any p E paths(n, F'), there is no path p., E rs which prefixes p.",
        "Res eliminates the feature structure nodes which is specified by a restriction schema.",
        "For a certain given restriction schema rs, cor e( f s(R)) = Res(f s(R), rs) and sub(f s(R)) is a minimal feature structure such that core(f s(R)) sub(f s(R)) f s(R).",
        "The nodes eliminated by Res must appear in sub( f s(R)).",
        "In the example, if we add (syn, counter) to a restriction schema and replace f s(R) with core(f s(R)) in the algorithm for generating LAs, the termination problem does not occur because LAs can contain a loop and equivalent signs are reduced to one state in LAs.",
        "The sub( f s(R)) contains the syn I counter, and the value is treated at Phase 2.",
        "The other problem, i.e., termination of DCPs, often occurs because of underspecification of the norv:head-dtr yclues.",
        "CQ11bider the rule schema in Figure 1.",
        "The append does not terminate at Phase 2 because the indices value of non-head daughters is [ L ].",
        "(Consider the case of executing append(X, (b), Y) in Prolog.)",
        "We introduce the freeze functor in Prolog which delays the evaluation of the second argument of the functors if the first argument is not instantiated.",
        "For instance, freeze , append , [b] ,Z)) means to delay the evaluation of append until X is instantiated.",
        "We introduce the functor in the following form.",
        "This means the resolution of this query is not performed if [1] is [1].",
        "The delayed evaluation is considered later when the non-head-dtr values are instantiated by an actual sign.",
        "Note that this change does not affect the discussion on the correctness of our parsing method, because the difference can be seen as only changes of order of unification.",
        "Now, the two phases of our parsing algorithm can be described in more detail.",
        "Phase 1 : Enumerate possible parses or edges in a chart only with unifiability checking in a bottom-up chart-parsing like manner.",
        "Phase 2 : For completed parse trees, compute substructures by DFSs, sub( fs(R)) for each schema R and frozen DCP programs.",
        "Note that, in Phase 1, unification is replaced with unifiability checking, which is more efficient than unification in terms of space and time.",
        "The intended side effect by unification, such as building up logical forms in sem values, is computed at Phase 2 only for the parse trees covering the whole input."
      ]
    },
    {
      "heading": "3.1 Phase 1 Parsing",
      "text": [
        "The Phase 1 parsing algorithm is quite similar to a bottom-up chart parsing for CFG.",
        "The algorithm has a chart and edges.",
        "• 1 and r are vertexes in the chart.",
        "• S is a state of art LA.",
        "• Dep is a set of tuples in the form of",
        "(D, eh, en, R) where eh and e„ are edges, D is a quasi-sign(1) and R is a rule schema.",
        "The intuition behind this definition is,",
        "• S plays the role of a non-/terminal in CFG, though it is actually a quasi-sign(0).",
        "• eh and e„ denote a head daughter edge and a non-head daughter edge, respectively.",
        "• Dep represents the dependency of an edge and its daughter edges.",
        "Where",
        ", cc, c„, R) E Dep, D is a DFS of a transition arc.",
        "Basically, Phase 1 parsing creates these tuples, and Phase 2 parsing uses them.",
        "The Phase 1 parsing consists of the following steps.",
        "Assume that a word in input has a lexical entry Li and that an LA (Qi, ci0 generated from Li is attached to the word:",
        "1.",
        "Create an edge + 1, , 0) in the chart for each Li, for appropriate 2.",
        "For an edge ei whose state is qi in the chart, pick up an edge e2 which is adjacent to eland whose state is (p2.",
        "3.",
        "For a transition arc (qi, q,N,D,1?",
        "), check if N is unifiable with ch.",
        "4.",
        "If the unifiability check is successful, find an edge d = (nid,nd,q,Depd) strictly covering eland e2.",
        "5. if there is, replace d with a new edge (md,nd, q, D epd U (D , e2, 1)1) in the chart.",
        "6.",
        "Otherwise, create a new edge (m, in, q, {(D, el , e2 , It)}) strictly covering ei and c2.",
        "7.",
        "Go to step 2.",
        "4 Phase 2 Parsing",
        "The algorithm of Phase 2 parsing is given in Figure 4.",
        "The procedure substructure is a recursive procedure which takes an edge as input and builds up sub-structures, which is differential feature structures representing modifications to core-structures, in a bottom-up manner.",
        "The obtained substructures are unified with core-structures when 1) the input edge covers a whole input or 2) the edge is a non-head daughter edge of some other edge.",
        "Note that the substructure treats sub(f s(R)), a feature structure eliminated by the restriction in the generation of LAs, (the (A) part in Figure 4) and frozen goals of DCPs, by additional evaluation of DCPs.",
        "(the (B) part) Here, we use two techniques: One is dependency analysis which is embodied by the function dep in Figure 4.",
        "The other is a partial unification routine expressed by p_uni f y in the figure.",
        "The dependency analysis is represented with the function, dep(F, rs), where F is a DFS and rs is a restriction schema used in generation of LAs: Definition 9 (dep) For a feature structure F' and the restriction schema rs, F = dep(F' ,T,S) is a maximal feature structure such that any node 'fbin F satisfies the conjunction of the following two conditions:",
        "1.",
        "There is a node n' in F' such that paths(n, F) = paths(n', F') and type(n) = type(n').",
        "2.",
        "Where A) rid = n or .B) nil is a descendant' of n, paths(nd,F) contains a path prefixed by one of (head-dtr), (non-head-dtr) and (goals).",
        "3.",
        "The disjunction of the following three conditions is satisfied where A) rid = nor B) nd is a descendant of n. • For some p E paths(nd,F), there is a path E rs which prefixes p. • Some p C patli,s(nd,F) is prefixed by (goals).",
        "• There is 7b0 node 71, in F such that i) there is paths P1, :P2 E paths(n„, F) such that pi is prefixed by (syn) or (sem) and 7)2 is prefixed by (head-dtr) or (non-head-dtr), and ii) for any p paths(nd,F) there is p,, E paths(n„, F) which prefixes p.",
        "Roughly, dep eliminates 1) the descendant nodes of the node which appears both in syn/sem domains and head-dtr/non-head-dtr domains and 2) the nodes appearing only in syn/sem domains, except for the node which appears in sub(ls(R)) or goals domains.",
        "In other words, it removes the feature structures that have been already raised to core-structures or other DFSs, except for the structure sharings, and leaves those which will be required by DCPs or ,sub(f s(R)).",
        "p_unify(Fi, F2, rs) is a partial unification routine where Fi and F2 are feature structures, and rs is a restriction schema used in generation of LAs.",
        "Roughly, it performs unification of and F2 only for common part of F2, and it produces unified results only for the node n in F1 if 5 ni is a descendant of n2 in a feature structure If' ilf ni n2, and there are paths pi C paths(ni, and p2 C paths (rt2 , /1, and p2 prefixes pi.",
        "n has a counter part in .F2.",
        "More precisely, it produces the unification results for a node n in F1 such that",
        "• there is a path p E paths(n, F1) such that the node reached by p is also defined in 1'2, or • there is a path p E paths(n, Ft) prefixed by some pr E rs or (goals).",
        "Note that a node is unified if its structure-shared part has a counterpart in F2.",
        "Intuitively, the routine produces unified results for the part of Ft instantiated by F2.",
        "The other part, that is not produced by p_uni f y, is not required at Phase 2 because it is already computed in a state or DFSs in LAs when the LAs are generated.",
        "Then, a sign can be obtained by unifying a substructure and the corresponding core-structure."
      ]
    },
    {
      "heading": "5 Example",
      "text": [
        "This section describes the parsing process of the sentence \"My colleague wrote a good paper.\"",
        "The LA generated from the lexical entry for \"wrote\" in Figure 5 is given in Figure 6.",
        "The transition arc T1 between the states L and S1 is generated by the rule schema in Figure 1.",
        "Note that the query to DCP, f reeze([1],append([1], [2], [3])), is used to obtain union of indices values of daughters and the result is written to the indices values of the mother sign.",
        "During the generation of the transition arc, since the first argument of the query is [ I ], it is frozen.",
        "The core-structures and the dependency-analyzed DFSs that augment the LA are shown in Figure 7.",
        "We assume that we do not use any restriction, i.e., for any lexical entry 1 and rule schemata R, sub(l) = [I] and sub( f s(R)) = [1].",
        "Note that, in the DFSs, the already raised feature structures are eliminated and, that the DFS of the transition arc T contains the frozen query as the goals.",
        "Assume that the noun phrases \"My colleague\" and \"a good paper\" are already recognized by a parser.",
        "At phase 1, they are checked if they are unifiable to the condition of transition arcs T1 and T2, i.e., the NPs which are non-head daughters",
        "naive application of rule schemata (38) 17.13 55.09 (9.27k on y successfiT Phase 1 & naive application of rule schemata 5 31.4 109122 (82.14 A bracketed time indicates nomt1C execution ti no.",
        "'I'M experiments was pelf:mined on SparcStation 20 with 128 1V11, RAM",
        "of S1 and 82.",
        "Since all the unifiability check-ings are successful, Phase 1 parsing produces the parse tree whose form is presented in Figure 3.",
        "The Phase 2 parsing produces the substructures in Figure 8.",
        "Note that the frozen goals are evaluated and the indices values have appropriate values.",
        "A parsing result is obtained by unifying the substructure for S2 with the corresponding core-structure.",
        "The amount of the feature structure nodes generated during parsing are reduced compared to the case of the naive application of rule schemata presented in Section 2.",
        "The important point is that they contain only either the part in the DFSs that was instantiated by head daughters' sub-structures, and non-head daughters' core-structures and sub-structures, or the part that contributes to the DCP's evaluation.",
        "The feature structure that does not appear in a substructure appears in the corresponding core-structure.",
        "See Figure 7.",
        "Because of these properties, the correctness of our parsing method is guaranteed.",
        "(Torisawa and Tsujii, 1996)."
      ]
    },
    {
      "heading": "7 Conclusion",
      "text": [
        "We have presented a two-phased parsing method for HPSG.",
        "In the first phase, our parser produces parse trees using Lexical Entry Automata.",
        "compiled from lexical entries.",
        "In the second phase, only the feature structures which must be computed dynamically are computed.",
        "As a result, amount of the feature structures unified at parsing-time is reduced.",
        "We also showed the effect of our optimization techniques by a series of experiments on a real world text.",
        "It can he noticed that each transition arc of the compiled LAs can be seen as a rewriting rule in CPC (or a dotted notation in a chart parser.)",
        "We believe this can open the way to integrate several methods developed for CFG, including the inside-outside algorithm for grammar learning or disambiguation, into an HPSG framework.",
        "We also believe that, by pursuing this direction for optimizing IIPSG parsers, we can reach the point where grammar learning from corpora can be done with concise and linguistically well-defined core grammar."
      ]
    },
    {
      "heading": "6 Experiments",
      "text": [
        "We have implemented our parsing method in Common Lisp Object System.",
        "Improvement by our method has been measured on 70 randomly selected Japanese sentences from a newspaper (Asahi Shinbun).",
        "The used grammar consists of just 5 rule schemata, which are generated from principles and rewriting rules, and 55 default lexical entries given for each part of speech, with 44 manually tailored lexical entries.",
        "The total 1111111- her of states in the LAs compiled from them was 1490.",
        "The grammar does not have a semantic part.",
        "The results are presented in Figure 9.",
        "Our grammar produced possible parse trees for 43 sentences (61.4%).",
        "We compared the execution time of our parsing method and a more naive algorithm, which performs Phase I. parsing with LAs and ap-plys rule schemata to completed parse trees in the naive way described in Section 2.",
        "As the naive algorithm caused thrashing for storage in GC, it is pointless to compare those figures simply.",
        "However, it is obvious that our method is much faster than the naive one.",
        "We could not measure the execution time for a totally naive algorithm which builds parse trees without LAs because of thrashing."
      ]
    }
  ]
}
