{
  "info": {
    "authors": [
      "Jan Hajič",
      "Barbora Hladká"
    ],
    "book": "Applied Natural Language Processing Conference",
    "id": "acl-A97-1017",
    "title": "Probabilistic and Rule-Based Tagger of an Inflective Language - A Comparison",
    "url": "https://aclweb.org/anthology/A97-1017",
    "year": 1997
  },
  "references": [
    "acl-A92-1018",
    "acl-A92-1021",
    "acl-J93-2004",
    "acl-J94-2001"
  ],
  "sections": [
    {
      "text": [
        "(which is usually called taggingl).",
        "For example, the ending \"-u\" is not only highly ambiguous, but at the same time it carries complex information: it corresponds to the genitive, the dative and the locative singular for inanimate nouns, or the dative singular for animate nouns, or the accusative singular for feminine nouns, or the first person singular present tense active participle for certain verbs.",
        "There are two different techniques for text tagging: a stochastic technique and a rule-based technique.",
        "Each approach has some advantages – for stochastic techniques there exists a good theoretical framework, probabilities provide a straightforward way how to disambiguate tags for each word and probabilities can be acquired automatically from the data; for rule-based techniques the set of meaningful rules is automatically acquired and there exists an easy way how to find and implement improvements of the tagger.",
        "Small set of rules can be used, in contrast to the large statistical tables.",
        "Given the success of statistical methods in different areas, including text tagging, given the very positive results of English statistical taggers and given the fact that there existed no statistical tagger for any Slavic language we wanted to apply statistical methods even for the Czech language although it exhibits a rich inflection accompanied by a high degree of ambiguity.",
        "Originally, we expected that the result would be plain negative, getting no more than about two thirds of the tags correct.",
        "However, as we show below, we got better results than we had expected.",
        "We used the same statistical approach to tag both the English text and the Czech text.",
        "For English, we obtained results comparable with the results presented in (Merialdo, 1992) as well as in (Church, 1992).",
        "For Czech, we obtained results which are less satisfactory than those for English.",
        "Given the comparability of the accuracy of the rule-based part-of-speech (POS) tagger (Brill, 1992) with the accuracy of the stochastic tag"
      ]
    },
    {
      "heading": "Abstract",
      "text": [
        "We present results of probabilistic tagging of Czech texts in order to show how these techniques work for one of the highly morphologically ambiguous inflective languages.",
        "After description of the tag system used, we show the results of four experiments using a simple probabilistic model to tag Czech texts (unigram, two bigram experiments, and a trigram one).",
        "For comparison, we have applied the same code and settings to tag an English text (another four experiments) using the same size of training and test data in the experiments in order to avoid any doubt concerning the validity of the comparison.",
        "The experiments use the source channel model and maximum likelihood training on a Czech hand-tagged corpus and on tagged Wall Street Journal (WSJ) from the LDC collection.",
        "The experiments show (not surprisingly) that the more training data, the better is the success rate.",
        "The results also indicate that for inflective languages with 1000+ tags we have to develop a more sophisticated approach in order to get closer to an acceptable error rate.",
        "In order to compare two different approaches to text tagging statistical and rule-based – we modified Eric Brill's rule-based part of speech tagger and carried out two more experiments on the Czech data, obtaining similar results in terms of the error rate.",
        "We have also run three more experiments with greatly reduced tagset to get another comparison based on similar tagset size."
      ]
    },
    {
      "heading": "1 INTRODUCTION",
      "text": [
        "'The development of automatic tagging of Czech is/was supported fully or partially by the following grants/projects: Charles University GAUK Languages with rich inflection like Czech pose a 39/94, Grant Agency of the Czech Republic GACR special problem for morphological disambiguation 405/96/K214 and Ministry of Education VS96151.",
        "ger and given the fact that a rule-based POS tagger has never been used for a Slavic language we have tried to apply rule-based methods even for Czech."
      ]
    },
    {
      "heading": "2 STATISTICAL EXPERIMENTS",
      "text": []
    },
    {
      "heading": "2.1 CZECH EXPERIMENTS 2.1.1 CZECH TAGSET",
      "text": [
        "Czech experiment is based upon ten basic POS classes and the tags describe the possible combinations of morphological categories for each POS class.",
        "In most cases, the first letter of the tag denotes the part-of-speech; the letters and numbers which follow it describe combinations of morphological categories (for a detailed description, see Table 2.1 and Table 2.2)."
      ]
    },
    {
      "heading": "2 genitive 3 dative 4 accusative 5 vocative 6 locative 7 instrumental",
      "text": [
        "Not all possible combinations of morphological categories are meaningful, however.",
        "In addition to these usual tags we have used special tags for sentence boundaries, punctuation and a so called \"unknown tag\".",
        "In the experiments, we used only those tags which occurred at least once in the training corpus.",
        "To illustrate the form of the tagged text, we present here the following examples from our training data, with comments: wordltag #comments do1Rdo #\" to\" (prepositions have their own individuals tags) oddiluINIS2 #\"unit\" (noun, masculine inanimate, singular, genitive)",
        "(verb, 3rd person, singular, active, present, indicative, masc.",
        "animate, affirmative) pro IRpro #\" for\" (preposition) nasIPP1P4 #\"us\" (pronoun, personal, 1st person, plural, accusative)"
      ]
    },
    {
      "heading": "2.1.2 CZECH TRAINING DATA",
      "text": [
        "For training, we used the corpus collected during the 1960's and 1970's in the Institute for Czech Language at the Czechoslovak Academy of Sciences.",
        "The corpus was originally hand-tagged, including the lemmatization and syntactic tags.",
        "We had to do some cleaning, which means that we have disregarded the lemmatization information and the syntactic tag, as we were interested in words and tags only.",
        "Tags used in this corpus were different from our suggested tags: number of morphological categories was higher in the original sample and the notation was also different.",
        "Thus we had to carry out conversions of the original data into the format presented above, which resulted in the so-called Czech \"modified\" corpus, with the following features:",
        "We used the complete \"modified\" corpus (621015 tokens) in the experiments No.",
        "1, No.",
        "3, No.",
        "4 and a small part of this corpus in the experiment No.",
        "2, as indicated in Table 2.4."
      ]
    },
    {
      "heading": "2.2 ENGLISH EXPERIMENTS 2.2.1 ENGLISH TAGSET",
      "text": [
        "For the tagging of English texts, we used the Penn Treebank tagset which contains 36 POS tags and 12 other tags (for punctuation and the currency symbol).",
        "A detailed description is available in (San-torini, 1990)."
      ]
    },
    {
      "heading": "2.2.2 ENGLISH TRAINING DATA",
      "text": [
        "For training in the English experiments, we used WSJ (Marcus et al., 1993).",
        "We had to change the format of WSJ to prepare it for our tagging software.",
        "We used a small (100k tokens) part of WSJ in the experiment No.",
        "6 and the complete corpus (1M tokens) in the experiments No.",
        "5, No.",
        "7 and No.",
        "8.",
        "Table 2.5 contains the basic characteristics of the training data."
      ]
    },
    {
      "heading": "2.3 CZECH VS ENGLISH",
      "text": [
        "Differences between Czech as a morphologically ambiguous inflective language and English as language with poor inflection are also reflected in the number of tag bigrams and tag trigrams.",
        "The figures given in Table 2.6 and 2.7 were obtained from the training files.",
        "It is interesting to note the frequencies of the most ambiguous tokens encountered in the whole \"modified\" corpus and to compare them with the English data.",
        "Table 2.8 and Table 2.9 contain the first tokens with the highest number of possible tags in the complete Czech \"modified\" corpus and in the complete WSJ.",
        "Token Frequency #tags in train.",
        "data in train.",
        "data jejich 1 087 51 jeho 1 087 46 jeho 163 35 jejich 150 25 vedouci 193 22",
        "In the Czech \"modified\" corpus, the token \"yedouci\" appeared 193 times and was tagged by twenty two different tags: 13 tags for adjective and 9 tags",
        "for noun.",
        "The token \"vedouci\" means either: \"leading\" (adjective) or \"manager\" or \"boss\" (noun).",
        "The following columns represent the tags for the token \"vedouci\" and their frequencies in the training data; for example \"vedouci\" was tagged twice as adjective, feminine, plural, nominative, first degree, affirmative.",
        "It is clear from these figures that the two languages in question have quite different properties and that nothing can be said without really going through an experiment."
      ]
    },
    {
      "heading": "2.4 THE ALGORITHM",
      "text": [
        "We have used the basic source channel model (described e.g. in (Merialdo, 1992)).",
        "The tagging procedure 0 selects a sequence of tags T for the sentence W: 0:W .",
        "In this case the optimal tagging procedure is",
        "Our implementation is based on generating the (W, T) pairs by means of a probabilistic model using approximations of probability distributions Pr(WIT) and Pr(T).",
        "The Pr(T) is based on tag bigrams and trigrams, and Pr(WIT) is approximated as the product of Pr(wilti).",
        "The parameters have been estimated by the usual maximum likelihood training method, i.e. we approximated them as the relative frequencies found in the training data with smoothing based on estimated unigram probability and uniform distributions."
      ]
    },
    {
      "heading": "2.5 THE RESULTS",
      "text": [
        "The results of the Czech experiments are displayed in Table 2.10.",
        "No.",
        "1 No.",
        "2 No.",
        "3 No.",
        "4",
        "These results show, not surprisingly, of course, that the more data, the better (results experiments of No.2 vs. No.3), but in order to get better results for a trigram tag prediction model, we would need far more data.",
        "Clearly, if 88% trigrams occur four times or less, then the statistics is not reliable.",
        "The following tables show a detailed analysis of the errors of the trigram experiment.",
        "The letters in the first column and row denote POS classes, the interpunction (T) and the \"unknown tag\" (X).",
        "The numbers show how many times the tagger assigned an incorrect POS tag to a token in the test file.",
        "The total number of errors was 244.",
        "Altogether, fifty times the adjectives (A) were",
        "tagged incorrectly, nouns (N) 93 times, numbers (C) 5 times and etc.",
        "(see the last unmarked column in Table 2.11b); to provide a better insight, we should add that in 32 cases, when the adjective was correctly tagged as an adjective, but the mistakes appeared in the assignment of morphological categories (see Table 2.12), 6 times the adjective was tagged as a noun, twice as a pronoun, 3 times as an adverb and so on (see the second row in Table 2.11a).",
        "A detailed look at Table 2.12 reveals that for 32 correctly marked adjectives the mistakes was 17 times in gender, once in number, three times in gender and case simultaneously and so on.",
        "Similar tables can be provided for nouns (Table 2.13), numerals (Table 2.14), pronouns(Table 2.15) and verbs (Table 2.16a, Table 2.16b)."
      ]
    },
    {
      "heading": "2.6 A PROTOTYPE OF RANK XEROX POS TAGGER FOR CZECH",
      "text": [
        "(Schiller, 1996) describes the general architecture of the tool for noun phrase mark-up based on finite-state techniques and statistical part-of-speech disambiguation for seven European languages.",
        "For Czech, we created a prototype of the first step of this process – the part-of-speech (POS) tagger using Rank Xerox tools (Tapanainen, 1995), (Cutting et al., 1992).",
        "The first step of POS tagging is obviously a definition of the POS tags.",
        "We performed three ex-A11 g I n To illustrate the results of our tagging experiments, we present here short examples taken from 2We used a special tag XX for unknown words.",
        "periments.",
        "These experiments differ in the POS tagset.",
        "During the first experiment we designed tagset which contains 47 tags.",
        "The POS tagset can be described as follows:",
        "The analysis of the results of the first experiment showed very high ambiguity between the nominative and accusative cases of nouns, adjectives, pronouns and numerals.",
        "That is why we replaced the tags for nominative and accusative of nouns, adjectives, pronouns and numerals by new tags NOUN .NA, ADJ_NA, PRON_NA and NUIVI_NA (meaning nominative or accusative, undistinguished).",
        "The rest of the tags stayed unchanged.",
        "This led 43 POS tags.",
        "In the third experiment we deleted the morphological information for nouns and adjectives alltogether.",
        "This process resulted in the final 34 POS tags."
      ]
    },
    {
      "heading": "2.6.2 RESULTS",
      "text": [
        "Figures representing the results of all experiments are presented in the following table.",
        "We have also included the results of English tagging using the same Xerox tools.",
        "language tags ambiguity.' tagging accuracy",
        "The results show that the more radical reduction of Czech tags (from 1171 to 34) the higher accuracy of the results and the more comparable are the Czech and English results.",
        "However, the difference in the error rate is still more than visible – here we can speculate that the reason is that Czech is \"free\" word order language, whereas English is not."
      ]
    },
    {
      "heading": "3 A RULE-BASED EXPERIMENT FOR CZECH",
      "text": [
        "A simple rule-based part of speech (RBPOS) tagger is introduced in (Brill, 1992).",
        "The accuracy of this tagger for English is comparable to a stochastic English POS tagger.",
        "From our point of view, it is very interesting to compare the results of Czech stochastic POS (SPOS) tagger and a modified RBPOS tagger for Czech."
      ]
    },
    {
      "heading": "3.1 TRAINING DATA",
      "text": [
        "We used the same corpus used in the case of the SPOS tagger for Czech.",
        "RBPOS requires different input format; we thus converted the whole corpus into this format, preserving the original contents."
      ]
    },
    {
      "heading": "3.2 LEARNING",
      "text": [
        "It is an obvious fact that the Czech tagset is totally different from the English tagset.",
        "Therefore, we had to modify the method for the initial guess.",
        "For Czech the algorithm is: \"If the word is W_SB (sentence boundary) assign the tag T_SB, otherwise assign the tag NNS1.\""
      ]
    },
    {
      "heading": "3.2.1 LEARNING RULES TO PREDICT THE MOST LIKELY TAG FOR UNKNOWN WORDS",
      "text": [
        "The first stage of training is learning rules to predict the most likely tag for unknown words.",
        "These rules operate on word types; for example, if",
        "We present here an example of rules taken from LEXRULEOUTFILE from the exp.",
        "No.",
        "1:",
        "u hassuf 1 NIS2 y hassuf 1 NFS2 ho hassuf 2 AIS21A ach hassuf 3 NFP6 nej addpref 3 02A # change the tag to NIS2 if the suffix is \"u\" # change the tag to NFS2 if the suffix is \"y\" # change the tag to AIS21A if the suffix is \"ho\" # change the tag to NFP6 if the suffix is \"ach\" # change the tag to 02A if adding the prefix \"nej\" results in a word"
      ]
    },
    {
      "heading": "3.2.3 RESULTS",
      "text": [
        "# change the tag NIS2 to NIS6 if the preceding tag is Rv # change the tag NISI.",
        "to NIS4 if the preceding tag is Rna"
      ]
    },
    {
      "heading": "3.2.2 LEARNING CONTEXTUAL CUES",
      "text": [
        "The second stage of training is learning rules to improve tagging accuracy based on contextual cues.",
        "These rules operate on individual word tokens.",
        "4We use the same names of files and variables as Eric Brill in the rule-based POS tagger's documentation.",
        "TAGGED-CORPUS – manually tagged training corpus, UNTAGGED-CORPUS – collection of all untagged texts, LEXRULEOUTFILE – the list of transformations to determine the most likely tag for unknown words, TAGGED-CORPUS-2 – manually tagged training corpus, TAGGED-CORPUS-ENTIRE – Czech \"modified\" corpus (the entire manually tagged corpus), CONTEXT-RULEFILE – the list of transformations to improve accuracy based on contextual cues.",
        "The tagger was tested on the same test file as for the statistical experiments.",
        "We obtained the following results:"
      ]
    },
    {
      "heading": "4 CONCLUSION",
      "text": [
        "The results, though they might seem negative compared to English, are still better than our original expectations.",
        "Before trying some completely different approach, we would like to improve the current simple approach by some other simple measures: adding a morphological analyzer (Hajit., 1994) as a front-end to the tagger (serving as a \"supplier\" of possible tags, instead of just taking all tags occurring in the training data for a given token), simplifying the tagset, adding more data.",
        "However, the desired positive effect of some of these measures is not guaranteed: for example, the average number of tags per",
        "token will increase after a morphological analyzer is added.",
        "Success should be guaranteed, however, by certain tagset reductions, as the original tagset (even after the reductions mentioned above) is still too detailed.",
        "This is especially true when comparing it to English, where some tags represent, in fact, a set of tags to be discriminated later (if ever).",
        "For example, the tag VB used in the WSJ corpus actually means \"one of the (five different) tags for 1st person sg., 2nd person sg., 1st person pl., etc.\".",
        "First, we will reduce the tagset to correspond to our morphological analyzer which already uses a reduced one.",
        "Then, the tagset will be reduced even further, but nevertheless, not as much as we did for the Xerox-tools-based experiment, because that tagset is too \"rough\" for many applications, even though the results are good.",
        "Regarding tagset reduction, we should note that we haven't performed a \"combined\" experiment, i.e. using the full (1100+) tagset for (thus) \"intermediate\" tagging, but only the reduced tagset for the final results.",
        "However, it can be quite simply derived from the tables 2.10, 2.11a and 2.11b, that the error rate would not drop much: it will remain high at about 6.5% (based on the results of experiment No.",
        "4) using the very small tagset of 12 number or lines in table 2.11a) tags used for part of speech identification.",
        "This is even much higher than the error rate reported here for the smallest tagset used in the 'pure' experiment (sect.",
        "2.6, table 2.20), which was at 3.8%.",
        "This suggests that maybe the pure methods (which are obviously also simple to implement) are in general better than the \"combined\" methods.",
        "Another possibility of an improvement is to add more data to allow for more reliable trigram estimates.",
        "We will also add contemporary newspaper texts to our training data in order to account for recent language development.",
        "Hedging against failure of all these simple improvements, we are also working on a different model using independent predictions for certain grammatical categories (and the lemma itself), but the final shape of the model has not yet been determined.",
        "This would mean to introduce constraints on possible combinations of morphological categories and take them into account when \"assembling\" the final tag.",
        "ACKNOWLEDGMENTS: The authors wish to thank Eva Haji6ovd for her comments and suggestions and Eric Brill, Jean-Pierre Chanod and Anne Schiller who made their software tools available."
      ]
    }
  ]
}
