{
  "info": {
    "authors": [
      "Dekang Lin"
    ],
    "book": "Applied Natural Language Processing Conference",
    "id": "acl-A97-2010",
    "title": "A Broad-Coverage Word Sense Tagger",
    "url": "https://aclweb.org/anthology/A97-2010",
    "year": 1997
  },
  "references": [
    "acl-C92-2070",
    "acl-J93-1003",
    "acl-P94-1020",
    "acl-P95-1026",
    "acl-P96-1006"
  ],
  "sections": [
    {
      "text": [
        "Previous corpus-based Word Sense Disambiguation (WSD) algorithms (Hearst, 1991; Bruce and Wiebe, 1994; Leacock et al., 1996; Ng and Lee, 1996; Yarowsky, 1992; Yarowsky, 1995) determine the meanings of polysemous words by exploiting their local contexts.",
        "A basic intuition that underlies those algorithms is the following:",
        "(1) Two occurrences of the same word have identical meanings if they have similar local contexts.",
        "In other words, previous corpus-based WSD algorithms learn to disambiguate a polysemous word from previous usages of the same word.",
        "This has several undesirable consequences.",
        "Firstly, a word must occur thousands of times before a good classifier can be trained.",
        "There are thousands of polysemous words, e.g., 11,562 polysemous nouns in WordNet (Miller, 1990).",
        "For every polysemous word to occur thousands of times each, the corpus must contain billions of words.",
        "Secondly, learning to disambiguate a word from the previous usages of the same word means that whatever was learned for one word is not used on other words, which obviously missed generality in natural languages.",
        "Thirdly, these algorithms cannot deal with words for which classifiers have not been trained, which explains why most previous WSD algorithms only deal with a dozen of polysemous words.",
        "We demonstrate a new WSD algorithm that relies on a different intuition:",
        "(2) Two different words are likely to have similar meanings if they occur in identical local contexts.",
        "The local context of a word is defined in our algorithm as a syntactic dependency relationship that the word participates in.",
        "To disambiguate a polysemous word, we search a local context database to retrieve the list of words (called selectors) that appeared in the same local context as the polysemous word in the training corpus.",
        "The meaning of the polysemous word is determined by maximizing its similarity to the selectors.",
        "For example, consider the sentence: (3) The new facility will employ 500 of the existing 600 employees The word \"facility\" has 5 possible meanings in WordNet 1.5:",
        "1. installation 2. proficiency/technique 3. adeptness 4. readiness 5. toilet/bathroom",
        "Since the word \"facility\" is the subject of \"employ\" and is modified by \"new\" in (3), we retrieve other words that appeared in the same contexts and obtain the following two groups of selectors (the log A column shows the likelihood ratios (Dunning, 1993) of these words in the local contexts):",
        "• Subjects of \"employ\" with top-20 highest likelihood ratios:",
        "• Modifiees of \"new\" with top-20 highest likelihood ratios:",
        "Since the similarity between Sense 1 of \"facility\" and the selectors is greater than that of other senses, the word \"facility\" in (3) is tagged \"Sense 1\" The key innovation of our algorithm is that a polysemous word is disambiguated with past usages of other words.",
        "Whether or not it appears in the training corpus is irrelevant.",
        "Compared with previous corpus-based algorithms, our approach offers several advantages:",
        "• The same knowledge sources are used for all words, as opposed to using a separate classifier for each individual word.",
        "For example, the same set of selectors can also be used to disambiguate \"school\" in \"the new school employed 100 peo-ple\".",
        "• It requires a much smaller training corpus that needs not be sense-tagged.",
        "• It is able to deal with words that are infrequent or do not even appear in the training corpus.",
        "• The same mechanism can also be used to infer the semantic categories of unknown words.",
        "In the demonstrated system, the local context database is constructed with 8,665,362 dependency relationships that are extracted from a 25-million-word Wall Street Journal corpus.",
        "The corpus is parsed with a broad-coverage parser, PRINCI-PAR, in 126 hours on a SPARC-Ultra 1/140 with 96MB of memory.",
        "The nouns in the input text are tagged with their senses in WordNet 1.5.",
        "Proper nouns that do not contain simple markers (e.g., Mr., Inc.) to indicate their categories are treated as 3-way ambiguous and are tagged as \"group\", \"person\", or \"location\" by the system."
      ]
    }
  ]
}
