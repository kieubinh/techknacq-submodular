{
  "info": {
    "authors": [
      "John Fry"
    ],
    "book": "Annual Meeting of the Association for Computational Linguistics",
    "id": "acl-P97-1019",
    "title": "Negative Polarity Licensing At the Syntax-Semantics Interface",
    "url": "https://aclweb.org/anthology/P97-1019",
    "year": 1997
  },
  "references": [
    "acl-E93-1013"
  ],
  "sections": [
    {
      "heading": "Abstract",
      "text": [
        "Recent work on the syntax-semantics interface (see e.g. (Dalrymple et al., 1994)) uses a fragment of linear logic as a 'glue language' for assembling meanings compositionally.",
        "This paper presents a glue language account of how negative polarity items (e.g. ever, any) get licensed within the scope of negative or downward-entailing contexts (Ladusaw, 1979), e.g. Nobody ever left.",
        "This treatment of licensing operates precisely at the syntax-semantics interface, since it is carried out entirely within the interface glue language (linear logic).",
        "In addition to the account of negative polarity licensing, we show in detail how linear-logic proof nets (Girard, 1987; Gallier, 1992) can be used for efficient meaning deduction within this 'glue language' framework."
      ]
    },
    {
      "heading": "1 Background",
      "text": [
        "A recent strain of research on the interface between syntax and semantics, starting with (Dalrymple et al., 1993), uses a fragment of linear logic as a 'glue language' for assembling the meaning of a sentence compositionally.",
        "In this approach, meaning assembly is guided not by a syntactic constituent tree but rather by the flatter functional structure (the LFG f-structure) of the sentence.",
        "As a brief review of this approach, consider sentence (1):",
        "(1) Everyone left.",
        "FRED 'LEAVE'",
        "Each word in the sentence is associated with a 'meaning constructor' template, specified in the lexicon; these meaning constructors are then instantiated with values from the f-structure.",
        "For sentence (1), this produces two premises of the linear logic glue language:",
        "In the everyone premise the higher-order variable S ranges over the possible scope meanings of the quantifier, with lower-case x acting as a traditional first-order variable \"placeholder\" within the scope.",
        "H ranges over LFG structures corresponding to the meaning of the entire generalized quantifier.'",
        "A meaning for (1) can be derived by applying the linear version of modus ponens, during which (unlike classical logic) the first premise everyone \"consumes\" the second premise left.",
        "This deduction, along with the substitutions H 1-4 f, X 1-4 x and S 1-4 Ax.leave(x), produces the final meaning f,-.4t every (person, Ax.leave(x)), which is in this simple case the only reading for the sentence.",
        "One advantage of this deductive style of meaning assembly is that it provides an elegant account of quantifier scoping: each possible scope has a corresponding proof, obviating the need for quantifier storage."
      ]
    },
    {
      "heading": "2 Meaning deduction via proof nets",
      "text": [
        "A proof net (Girard, 1987) is an undirected, connected graph whose node labels are propositions.",
        "A 'Here we have simplified the notation of Dalrymple et al.",
        "somewhat, for example by stripping away the universal quantifier operators from the variables.",
        "In this regard, note that the lower-case variables stand for arbitrary constants rather than particular terms, and generally are given limited scope within the antecedent of the premise.",
        "Upper-case variables are Prolog-like variables that become instantiated to specific terms within the proof, and generally their scope is the entire premise.",
        "theorem of multiplicative linear logic corresponds to only one proof net; thus the manipulation of proof nets is more efficient than sequent deduction, in which the same theorem might have different proofs corresponding to different orderings of the inference steps.",
        "A further advantage of proof nets for our purposes is that an invalid meaning deduction, e.g. one corresponding to some spurious scope reading of a particular sentence, can be illustrated by exhibiting its defective graph which demonstrates visually why no proof exists for it.",
        "Proof net techniques have also been exploited within the categorial grammar community, for example for reasons of efficiency (Morrill, 1996) and in order to give logical descriptions of certain syntactic phenomena (Lecomte and Retore, 1995).",
        "In this section we construct a proof net from the premises for sentence (1), showing how to apply higher-order unification to the meaning terms in the process.",
        "We then review the 0(n2) algorithm of Gallier (1992) for propositional (multiplicative) linear logic which checks whether a given proof net is valid, i.e. corresponds to a proof.",
        "The complete process for assembling a meaning from its premises will be shown in four steps: (1) rewrite the premises in a normalized form, (2) assemble the premises into a graph, (3) connect together the positive (\"producer\") and negative (\"consumer\") meaning terms, unifying them in the process, and (4) test whether the resulting graph encodes a proof."
      ]
    },
    {
      "heading": "2.1 Step 1: set up the sequent",
      "text": [
        "Since our goal is to derive, from the premises of sentence (1), a meaning M for the f-structure f of the entire sentence, what we seek is a proof of the form everyone left I f7t M. Glue language semantics has so far been restricted to the multiplicative fragment of linear logic, which uses only the multiplicative conjunction operator 0 (tensor) and the linear implication operator – 0.",
        "The same fragment is obtained by replacing – 0 with the operators and I, where It (par) is the multiplicative 'or' and I is linear negation and (A – o B) (A-L. B).",
        "Using the version without – 0, we normalize two sided sequents of the form A1, ,Am H B1, ,B, into right-sided sequents of the form H , A,n1 , , , Bn.",
        "(In sequent representations of this style, the comma represents 0 on the left side of the sequent and on the right side.)",
        "In our new format, then, the proof takes the form I everyone', left\", fa\"-q M. The proof net further requires that sequents be in negation normal form, in which negation is applied only to atomic terms.3 Moving the negations inward (the usual double-negation and 'de Morgan' properties hold), and displaying the full premises, we obtain the normalized sequent"
      ]
    },
    {
      "heading": "2.2 Step 2: create the graph",
      "text": [
        "The next step is to create a graph whose nodes consist of all the terms which occur in the sequent.",
        "That is, a node is created for each literal C and for each negated literal CI; a node is created for each compound term A 0 B or A II B; and nodes are also created for its subterms A and B.",
        "Then, for each node of the form A B, we draw a soft edge in the form of a horizontal dashed line connecting it to nodes A and B.",
        "For each node of the form A0 B , we draw a hard edge (solid line) connecting it to nodes A and B.",
        "For the example at hand, this produces the graph in Figure 1 (ignoring the curved edges at the top).",
        "'This notation is Gallier's (1992).",
        "3 Note that we refer to noncompound terms as 'literal' or 'atomic' terms because they are atomic from the point of view of the glue language, even though these terms are in fact of the form S.\", M, where S is an expression over LFG structures and M is a type-r expression in the meaning language."
      ]
    },
    {
      "heading": "2.3 Step 3: connect the literals",
      "text": [
        "The final step in assembling the proof net is to connect together the literal nodes at the top of the graph.",
        "It is at this stage that unification is applied to the variables in order to assign them the values they will assume in the final meaning.",
        "Each different way of connecting the literals and instantiating their variables corresponds to a different reading for the sentence.",
        "For each literal, we draw an edge connecting it to a matching literal of opposite sign; i.e. each literal A is connected to a literal B1 where A unifies with B.",
        "Every literal in the graph must be connected in this way.",
        "If for some literal A there exists no matching literal B of opposite sign then the graph does not encode a proof and the algorithm fails.",
        "In this process the unifications apply to whole expressions of the form S-'.",
        "* M, including both variables over LFG structures and variables over meaning terms.",
        "For the meaning terms, this requires a limited higher-order unification scheme that produces the unifier Ax.p(x) from a second-order term T and a first-order term p(x).",
        "As noted by Dalrymple et al.",
        "(to appear), all the apparatus that is required for their simple intensional meaning language falls within the decidable /A fragment of Miller (1990), and therefore can be implemented as an extension of a first-order unification scheme such as that of Prolog.",
        "For the example at hand, there is only one way to connect the literals (and hence at most one reading for the sentence), as shown in Figure 1.",
        "At this stage, the unifications would bind the variables in Figure 1 as follows: X 1-+ x, H 1-4 fa, S Ax.leave(x), M 1-4 every(person,Ax.leave(x))."
      ]
    },
    {
      "heading": "2.4 Step 4: test the graph for validity",
      "text": [
        "Finally, we apply Gallier's (1992) algorithm to the connected graph in order to check that it corresponds to a proof.",
        "This algorithm recursively decomposes the graph from the bottom up while checking for cycles.",
        "Here we present the algorithm informally; for proofs of its correctness and 0(n2) time complexity see (Gallier, 1992).",
        "Base case: If the graph consists of a single link between literals A and A1, the algorithm succeeds and the graph corresponds to a proof.",
        "Recursive case 1: Begin the decomposition by deleting the bottom-level par nodes.",
        "If there is some terminal node A It B connected to higher nodes A and B, delete A B.",
        "This of course eliminates the dashed edge from A tt B to A and to B, but does not remove nodes A and B.",
        "Then run the algorithm on the resulting smaller (possibly unconnected) graph.",
        "Recursive case 2: Otherwise, if no terminal par node is available, find a terminal tensor node to delete.",
        "This case is more complicated because not every way of deleting a tensor node necessarily leads to success, even for a valid proof net.",
        "Just choose some terminal tensor node A 0 B.",
        "If deleting that node results in a single, connected (i.e. cyclic) graph, then that node was not a valid splitting tensor and a different one must be chosen instead, or else halt with failure if none is available.",
        "Otherwise, delete A 0 B, which leaves nodes A and B belonging to two unconnected graphs Cl and G2.",
        "Then run the algorithm on Cl and G2.",
        "This process will be demonstrated in the examples which follow."
      ]
    },
    {
      "heading": "3 A glue language treatment of NPI licensing",
      "text": [
        "Ladusaw (1979) established what is now a well-known generalization in semantics, namely that negative polarity lexical items (NPI's, e.g. any, ever) are licensed within the scope of downward-entailing operators (e.g. no, few).",
        "For example, the NPI ever occurs felicitously in a context like No one ever left but not in *John ever left.'",
        "Laclusaw showed that the status of a lexical item as a NPI or licenser depends on its meaning; i.e. on semantic rather than syntactic or lexical properties.",
        "On the other hand, the requirement that NPI's be licensed in order to appear felicitously in a sentence is a constraint on surface syntactic form.",
        "So the domain of NPI licensing is really the interface between syntax and semantics, where meanings are composed under syntactic guidance.",
        "This section gives an implementation of NPI licensing at the syntax-semantics interface using glue language.",
        "No separate proof or interpretation apparatus is required, only modification of the relevant meaning constructors specified in the lexicon."
      ]
    },
    {
      "heading": "3.1 Meaning constructors for NPI's",
      "text": [
        "There is a resource-based interpretation of the NPI licensing problem: the negative or decreasing licensing operator must make available a resource, call it e, which will license the NPI's, if any, within its scope.",
        "If no such resource is made available the NPI's are unlicensed and the sentence is rejected.",
        "The NPI's must be made to require the t resource.",
        "The way one implements such a requirement in linear logic is to put the required resource on the left side of the implication operator – o.",
        "This is precisely our approach.",
        "However, since the NPI is just 'borrowing' the license, not consuming it (after all, more than one NPI may be licensed, as in No one ever saw anyone), we also add the resource to the right hand side of the implication.",
        "That is, for a meaning constructor of the form A – o B, we can make a corresponding NPI meaning constructor of the form (A 0 t) – 0 (B t).",
        "For example, the meaning constructor proposed in (Dalrymple et al., 1993) for the sentential modifier",
        "ever: (fa^-qP 0 0 – 0 (f'-*t ever(P) t).",
        "This technique can be readily applied to the other categories of NPI as well.",
        "In the case of the NPI quantifier phrase anyone5 the licensing apparatus is added to the earlier template for everyone to produce the meaning constructor",
        "The only function of the t – 0 t pattern inside an NPI is to consume the resource t and then produce it again.",
        "However, for this to happen, the resource t will have to be generated by some licenser whose scope includes the NPI, as we show below.",
        "If no outside t resource is made available, then the extraneous, unconsumed t material in the NPI guarantees that no proof will be generated.",
        "In proof net terms, 'Any also has another, so-called 'free choice' interpretation (as in e.g.",
        "Anyone will do) (Ladusaw, 1979; Kadmon and Landman, 1993), which we ignore here.",
        "the output LI cannot feed back into the input t without producing a cycle.",
        "We now demonstrate how the deduction is blocked for a sentence containing an unlicensed NPI such as (2).",
        "(2) *Al sang yet.",
        "The graph of (2), shown in Figure 2, does not encode a proof.",
        "The reason is shown in Figure 3.",
        "At this point in the algorithm, we have deleted the leftmost terminal tensor node.",
        "However, the only remaining terminal tensor node cannot be deleted, since doing so would produce a single connected subgraph; the cycle is in the edge from t to ti.",
        "At this point the algorithm fails and no meaning is derived."
      ]
    },
    {
      "heading": "3.2 Meaning constructors for NP! licensers",
      "text": [
        "It is clear from the proposal so far that lexical items which license NPI's must make available a t resource within their scope which can be consumed by the NP!.",
        "However, that is not enough; a licenser can still occur inside a sentence without an NPI, as in e.g. No one left.",
        "The resource accounting of linear logic requires that we 'clean up' by consuming any excess resources in order for the meaning deduction to go through.",
        "Fortunately, we can solve this problem within the licenser's meaning constructor itself.",
        "For a lexical category whose meaning constructor is of the form A-0B, we assign to the NPI licensers of that category the meaning constructor (t – 0 (A 0 t)) – o B.",
        "By its logical structure, being embedded inside another implication, the inner implication here serves",
        "to introduce 'hypothetical' material.",
        "All of the NPI licensing occurs within the hypothetical (left) side of the outermost implication.",
        "Since the P resource is made available to the NPI only within this hypothetical, it is guaranteed that the NPI is assembled within, and therefore falls under, the scope of the licenser.",
        "Furthermore, the formula is 'self cleaning', in that the t resource, even if not used by an NPI, does not survive the hypothetical and so cannot affect the meaning of the licenser in some other way.",
        "That is, the licensing constructor (I o (A I)) 0 B can derive all of the same meanings as the nonlicensing version A o B.",
        "This self-cleaning property means that a licensing resource is exactly that – a license.",
        "Within the scope of the licenser, the is available to be used once, several times (in a \"chain\" of NPI's which pass it along), or not at all, as required.6 A simple example is provided by the NPI-licensing adverb rarely.",
        "We modify our sentential adverb template to create a meaning constructor for rarely which licenses an NPI within the sentence it modifies.",
        "rarely: (1 o (fc,-,4tP I)) o rare/y(P) The case of licensing quantifier phrases such as nobody and few students follows the same pattern.",
        "For example, nobody takes the form nobody: ((9,-.4ex I) o (H-.4t SW I)) 0 H-,+t no (person, S).",
        "We can now derive a meaning for sentence (3), in which nobody and anyone play the roles of licenser and NPI, respectively.",
        "(3) Nobody saw anyone.",
        "Normally, a sentence with two quantifiers would generate two different scope readings – in this case,",
        "(4) and (5).",
        "(4) fc,-, t no(person, )x. any (person, Ay .see(x, y))) (5) icr^-4t any(person, )ty.no(person,Ax.see(x, y)))",
        "However, Ladusaw's generalization is that NPI's are licensed within the scope of their licensers.",
        "In fact, the semantics of any prevent it from taking wide scope in such a case (Kadmon and Landman, 1993; Ladusaw, 1979, p. 96-101).",
        "Our analysis, then, should derive (4) but block (5).",
        "6 This multiple-use effect can be achieved more directly using the exponential operator !",
        "; however this unnecessary step would take us outside of the multiplicative fragment of linear logic and preclude the proof net techniques described earlier.",
        "The premises are",
        "The proof net for reading (4) is shown in Figure 4•7 As required, the net in Figure 4, corresponding to wide scope for no, is valid.",
        "The first step in the proof of Figure 4 is to delete the only available splitting tensor, which is boxed in the figure.",
        "A second way of linking the positive and negative literals in Figure 4 produces a net which corresponds to (5), the spurious reading in which any has wide scope.",
        "In that graph, however, all three of the available terminal tensor nodes produce a single, connected (cyclic) graph if deleted, so decomposition cannot even begin and the algorithm fails.",
        "Once again, it is the licensing resources which are enforcing the desired constraint."
      ]
    },
    {
      "heading": "4 Categorial grammar approaches",
      "text": [
        "The t atom used here is somewhat analogous to the (negative) lexical `monotonicity markers' proposed by Sanchez Valencia (1991; 1995) and Dowty (1994) for categorial grammar.",
        "In these approaches, categories of the form AI B are marked with monotonicity properties, i.e. as A+IB+, A+IB-,A-1B+, or A I B , and similarly for left-leaning categories of the form A\\B.",
        "Then monotonicity constraints can be enforced using category assignments like the following from (Dowty, 1994):",
        "Sanchez Valencia and Dowty, however, are less concerned with the distribution of NPI's than they are with using monotonicity properties to characterize valid inference patterns, an issue which we have ignored here.",
        "Hence their work emphasizes logical polarity, where an odd number of negative marks indicates negative polarity, and an even number of negatives cancel each other to produce positive polarity.",
        "For example, the category of no above \"flips\" the polarity of its argument.",
        "By contrast, our system, like Ladusaw's (1979) original proposal, is what Dowty (1994, p. 134-137) would call \"intuitionistic\":",
        "since multiple negative contexts do not cancel each other out, we permit doubly-licensed NPI's as in Nobody rarely sees anyone.",
        "To handle such cases, while at the same time accounting for monotonic inference properties, Dowty (1994) proposes a double-marking framework whereby categories like A:: /Bt are masked for both logical polarity and syntactic polarity."
      ]
    },
    {
      "heading": "5 Conclusion",
      "text": [
        "We have elaborated on and extended slightly the 'glue language' approach to semantics of Dalrymple et al.",
        "It was shown how linear logic proof nets can be used for efficient natural-language meaning deductions in this framework.",
        "We then presented a glue language treatment of negative polarity licensing which ensures that NPI's are licensed within the semantic scope of their licensers, following (Ladusaw, 1979).",
        "This system uses no new global rules or features, nor ambiguous lexical entries, but only the addition of L's to the relevant items within the lexicon.",
        "The licensing takes place precisely at the syntax-semantics interface, since it is implemented entirely in the interface glue language.",
        "Finally, we noted briefly some similarities and differences between this system and categorial grammar 'monotonicity marking' approaches."
      ]
    },
    {
      "heading": "6 Acknowledgements",
      "text": [
        "I'm grateful to Mary Dalrymple, John Lamping and Stanley Peters for very helpful discussions of this material.",
        "Vineet Gupta, Martin Kay, Fernando Pereira and four anonymous reviewers also provided helpful comments on several points.",
        "All remaining errors are naturally my own."
      ]
    }
  ]
}
