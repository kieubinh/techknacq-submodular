{
  "info": {
    "authors": [
      "George Anton Kiraz"
    ],
    "book": "Annual Meeting of the Association for Computational Linguistics",
    "id": "acl-P97-1042",
    "title": "Compiling Regular Formalisms With Rule Features into Finite-State Automata",
    "url": "https://aclweb.org/anthology/P97-1042",
    "year": 1997
  },
  "references": [
    "acl-C88-1006",
    "acl-C96-1077",
    "acl-J94-3001",
    "acl-J95-2004",
    "acl-P96-1031"
  ],
  "sections": [
    {
      "heading": "Abstract",
      "text": [
        "This paper presents an algorithm for the compilation of regular formalisms with rule features into finite-state automata.",
        "Rule features are incorporated into the right context of rules.",
        "This general notion can also be applied to other algorithms which compile regular rewrite rules into automata."
      ]
    },
    {
      "heading": "1 Introduction",
      "text": [
        "The past few years have witnessed an increased interest in applying finite-state methods to language and speech problems.",
        "This in turn generated interest in devising algorithms for compiling rules which describe regular languages/relations into finite-state automata.",
        "It has long been proposed that regular formalisms (e.g., rewrite rules, two-level formalisms) accommodate rule features which provide for finer and more elegant descriptions (Bear, 1988).",
        "Without such a mechanism, writing complex grammars (say two-level grammars for Syriac or Arabic morphology) would be difficult, if not impossible.",
        "Algorithms which compile regular grammars into automata (Kaplan and Kay, 1994; Mohri and Sproat, 1996; Grimley-Evans, Kiraz, and Pulman, 1996) do not make use of this important mechanism.",
        "This paper presents a method for incorporating rule features in the resulting automata.",
        "The following Syriac example is used here, with the infamous Semitic root {ktb} 'notion of writ-ing'.",
        "The verbal pa\"el measure', /katteb/2 'wrote CAUSATIVE ACTIVE', is derived from the following",
        "morphemes: the pattern {cvcvc} 'verbal pattern', the above mentioned root, and the vocalism {ae} 'ACTIVE'.",
        "The morphemes produce the following underlying form:3",
        "/katteb/ is derived then by the gemination, implying CAUSATIVE, of the middle consonant, [t].4 The current work assumes knowledge of regular relations (Kaplan and Kay, 1994).",
        "The following convention has been adopted.",
        "Lexical forms (e.g., morphemes in morphology) appear in braces, { phonological segments in square brackets, [], and elements of tuples in angle brackets, ( ).",
        "Section 2 describes a regular formalism with rule features.",
        "Section 3 introduce a number of mathematical operators used in the compilation process.",
        "Sections 4 and 5 present our algorithm.",
        "Finally, section 6 provides an evaluation and some concluding remarks."
      ]
    },
    {
      "heading": "2 Regular Formalism with Rule Features",
      "text": [
        "This work adopts the following notation for regular formalisms, cf. (Kaplan and Kay, 1994):",
        "where r, A and p are n-way regular expressions which describe same-length relations.' (An n-way regular expression is a regular expression whose terms",
        "are n-tuples of alphabetic symbols or the empty string 6.",
        "A same-length relation is devoid of e. For clarity, the elements of the n-tuple are separated by colons: e.g., a:b:c* q:r:s describes the 3-relation { (am q , bmr, cm s) I m > 0 }.",
        "Following current terminology, we call the first j elements `surface'6 and the remaining elements `lexical'.)",
        "The arrows correspond to context restriction (CR), surface coercion (SC) and composite rules, respectively.",
        "A compound rule takes the form",
        "To accommodate for rule features, each rule may be associated with an (n – j)-tuple of feature structures, each of the form",
        "i.e., an unordered set of attribute=val pairs.",
        "An attribute is an atomic label.",
        "A val can be an atom or a variable drawn from a predefined finite set of possible values.",
        "The ith element in the tuple corresponds to the (j i)th element in rule expressions.",
        "As a way of illustration, consider the simplified grammar in Figure 1 with j = 1.",
        "The four elements of the tuples are: surface, pattern, root, and vocalism.",
        "R1 and R2 sanction the first and third consonants, respectively.",
        "R3 and R4 sanction vowels.",
        "R5 is the gemination rule; it is only triggered if the given rule features are satisfied: [cat=verb] for the first lexical element (i.e., the pattern) and [measure=pa\"el] for the second element (i.e., the root).",
        "The rule also illustrates that 7 can be a sequence of tuples.",
        "The derivation of /katteb/ is illustrated below:",
        "The numbers between the lexical expressions and the surface expression denote the rules in Figure 1 which sanction the given lexical-surface mappings.",
        "Rule features play a role in the semantics of rules: a states that if the contexts and rule features are satisfied, the rule is triggered; a states that if the contexts, lexical expressions and rule features are satisfied, then the rule is applied.",
        "For example, although R5 is devoid of context expressions, the rule is composite indicating that if the root measure is pa \"el, then gemination must occur and vice versa.",
        "Note that in a compound rule, each set of contexts is associated with a feature structure of its own.",
        "What is meant by 'rule features are satisfied'?",
        "Regular grammars which make use of rule features normally interact with a lexicon.",
        "In our model, the lexicon consists of (n – sublexica corresponding to the lexical elements in the formalism.",
        "Each sub-lexical entry is associate with a feature structure.",
        "Rule features are satisfied if they match the feature structures of the lexical entries containing the lexical expressions in 7, respectively.",
        "Consider the lexicon in Figure 2 and rule R5 with 7 = t:c2:t:0 t:0:0:0 and the rule features ([cat=verb], [measure=pa\"el], []).",
        "The lexical entries containing 7 are {ci vc,vc3} and {ktb}, respectively.",
        "For the rule to be triggered, [cat=verb] of the rule must match with [cat=verb] of the lexical entry {c1vc2vc3}, and [measure=pa\"el] of the rule must match with [measure=(p`al,pa\"e1)] of the lexical entry {ktb}.",
        "As a second illustration, R6 derives the simple p 'al measure, /ktab/.",
        "Note that in R5 and R6,",
        "1. the lexical expressions in both rules (ignoring Os) are equivalent, 2. both rules are composite, and",
        "3. they have different surface expression in 7.",
        "In traditional rewrite formalism, such rules will be contradicting each other.",
        "However, this is not the case here since R5 and R6 have different rule features.",
        "The derivation of this measure is shown below (R7 completes the derivation deleting the first vowel on the surface8):",
        "Note that in order to remain within finite-state power, both the attributes and the values in feature structures must be atomic.",
        "The formalism allows a value to be a variable drawn from a predefined finite set of possible atomic values.",
        "In the compilation process, such variables are taken as the disjunction of all possible predefined values.",
        "Additionally, this version of rule feature matching does not cater for rules whose 7 span over two lexical forms.",
        "It is possible, of course, to avoid this limitation by having rule features match the feature structures of both lexical entries in such cases."
      ]
    },
    {
      "heading": "3 Mathematical Preliminaries",
      "text": [
        "We define here a number of operations which will be used in our compilation process.",
        "If an operator Op takes a number of arguments (al , • • • , at), the arguments are shown as a subscript, e.g. Op(ai, ..,a\" - the parentheses are ignored if there is only one argument.",
        "When the operator is mentioned without reference to arguments, it appears on its own, e.g. Op.",
        "Operations which are defined on tuples of strings can be extended to sets of tuples and relations.",
        "For example, if S is a tuple of strings and Op(S) is an operator defined on S, the operator can be extended to a relation R in the following manner",
        "Definition 3.1 (Identity) Let L be a regular language.",
        "Id(L) = X I Xis an n-tuple of the form (x, • • , x), x E L } is the n-way identity of L.9",
        "Definition 3.2 (Insertion) Let R be a regular relation over the alphabet E and let in be a set of symbols not necessarily in E. Insertn,(R) inserts the relation 1d0(a) for all a E in, freely throughout R. Insertra-1 o Insertm(R) = R removes all such instances if in is disjoint from E.1° Remark 3.2 We can define another form of Insert where the elements in m. are tuples of symbols as follows: Let R be a regular relation over the alphabet E and let m be a set of tuples of symbols not necessarily in E. Insertm(R) inserts a, for all a E m, freely throughout R. Definition 3.3 (Substitution) Let S and S' be same-length n-tuples of strings over the alphabet",
        "The symbol 7 denotes 'feasible tuples', similar to 'feasible pairs' in traditional two-level morphology.",
        "The number of surface expressions, j, is always 1.",
        "The operator o represents mathematical composition, not necessarily the composition of transducers."
      ]
    },
    {
      "heading": "4 Compilation without Rule Features",
      "text": [
        "The current algorithm is motivated by the work of (Grimley-Evans, Kiraz, and Pulman, 1996).11 Intuitively, the automata is built by three approximations as follows:",
        "1.",
        "Accepting 7s irrespective of any context.",
        "2.",
        "Adding context restriction constraints making the automata accept only the sequences which appear in contexts described by the grammar.",
        "3.",
        "Forcing surface coercion constraints mak",
        "ing the automata accept all and only the sequences described by the grammar."
      ]
    },
    {
      "heading": "4.1 Accepting rs",
      "text": [
        "Let T be the set of all rs in a regular grammar, p be an auxiliary boundary symbol (not in the grammar's alphabets) and p' = Icin(p).",
        "The first approximation is described by For all 7s, we subtract this expression from the automaton under construction, yielding",
        "Centers accepts the symbols, p', followed by zero or more TS, each (if any) followed by p'.",
        "In other words, the machine accepts all centers described by the grammar (each center surrounded by p') irrespective of their contexts.",
        "It is implementation dependent as to whether T includes other correspondences which are not explicitly given in rules (e.g., a set of additional feasible centers)."
      ]
    },
    {
      "heading": "4.2 Context Restriction Rules",
      "text": [
        "For a given compound rule, the set of relations in which r is invalid is",
        "i.e., r in any context minus 7 in all valid contexts.",
        "However, since in §4.1 above, the symbol p appears freely, we need to introduce it in the above expression.",
        "The result becomes",
        "The above expression is only valid if 7 consists of only one tuple.",
        "However, to allow it to be a sequence of such tuples as in R5 in Figure 1, it must be",
        "1. surrounded by p' on both sides, and 2. devoid of p'.",
        "The first condition is accomplished by simply placing p' to the left and right of T. As for the second condition, we use an auxiliary symbol, w, as a place-holder representing T, introduce p freely, then substitute r in place of w. Formally, let w be an auxiliary symbol (not in the grammar's alphabet), and let w' = Id(w) be a place-holder representing 7.",
        "The above expression becomes",
        "C R now accepts only the sequences of tuples which appear in contexts in the grammar (but including the partitioning symbols p'); however, it does not force surface coercion constraints."
      ]
    },
    {
      "heading": "4.3 Surface Coercion Rules",
      "text": [
        "Let T/ represent the center of the rule with the correct lexical expressions and the incorrect surface expressions with respect to 7* ,",
        "The coerce relation for a compound rule can be simply expressed by12",
        "The two p's surrounding 7' ensure that coercion applies on at least one center of the rule.",
        "For all such expressions, we subtract Coerce from the automaton under construction, yielding",
        "SC now accepts all and only the sequences of tuples described by the grammar (but including the partitioning symbols p').",
        "It remains only to remove all instances of p from the final machine, determinize and minimize it.",
        "There are two methods for interpreting transducers.",
        "When interpreted as acceptors with n-tuples of symbols on each transition, they can be deter-minized using standard algorithms (Hoperoft and Ullman, 1979).",
        "When interpreted as a transduction that maps an input to an output, they cannot always be turned into a deterministic form (see (Mohri, 1994; Roche and Schabes, 1995))."
      ]
    },
    {
      "heading": "5 Compilation with Rule Features",
      "text": [
        "This section shows how feature structures which are associated with rules and lexical entries can be incorporated into FSAs.",
        "'A special case can be added for epenthetic rules."
      ]
    },
    {
      "heading": "5.1 Intuitive Description",
      "text": [
        "We shall describe our handling of rule features with a two-level example.",
        "Consider the following analysis.",
        "Lexical Surface The lexical expression contains the lexical forms {ef} and {ghi}, separated by a boundary symbol, 1), which designates the end of a lexical entry.",
        "The numbers between the tapes represent the rules (in some grammar) which allow the given lexical-surface mappings.",
        "Assume that the above lexical forms are associated in the lexicon with the feature structures as in Figure 3.",
        "Further, assume that each two-level rule m, 1 < m < 10, above is associated with the feature structure Fm.",
        "Hence, in order for the above two-level analysis to be valid, the following feature structures must match",
        "Usually, boundary rules, e.g. rule 5 above, are not associated with feature structures, though there is nothing stopping the grammar writer from doing so.",
        "To match the feature structures associated with rules and those in the lexicon we proceed as follows.",
        "Firstly, we suffix each lexical entry in the lexicon with the boundary symbol, I), and it's feature structure.",
        "(For simplicity, we consider a feature structure with instantiated values to be an atomic object of length one which can be a label of a transition in a FSA.",
        ")13 Hence the above lexical forms become: `abcd 'ef bf2', and `ghi bf3'.",
        "Secondly, we incorporate a feature structure of a rule into the rule's right context, p. For example, if p of rule 1 above is b:b c:c, the context becomes b:b c:c 7r* 0:F1 (12) (this simplified version of the expression suffices for the moment).",
        "In other words, in order for a:a to be sanctioned, it must be followed by the sequence: 13 As to how this is done is a matter of implementation.",
        "1. b:b c:c, i.e., the original right context; 2. any feasible tuple, 7r* ; and 3. the rule's feature structure which is deleted on the surface, 0:F1.",
        "This will succeed if only if F1 (of rule 1) and 11 (of the lexical entry) were identical.",
        "The above analysis is repeated below with the feature structures incorporated into p. aIbIcjd lei f Hf21 gihl i Mf3I Lexical",
        "As indicated earlier, in order to remain within finite-state power, all values in a feature structure must be instantiated.",
        "Since the formalism allows values to be variables drawn from a predefined finite set of possible values, variables entered by the user are replaced by a disjunction over all the possible values."
      ]
    },
    {
      "heading": "5.2 Compiling the Lexicon",
      "text": [
        "Our aim is to construct a FSA which accepts any lexical entry from the ith sublexicon on its j ith tape.",
        "A lexical entry it (e.g., morpheme) which is associated with a feature structure 0 is simply expressed by pbck, where I?",
        "is a (morpheme) boundary symbol which is not in the alphabet of the lexicon.",
        "The expression of sublexicon i with r entries becomes,",
        "We also compute the feasible feature structures of sublexicon i to be = U 6r (14) and the overall feasible feature structures on all sublexica to be",
        "The first element deletes all such features on the surface.",
        "For convenience in later expressions, we incorporate features with 7r as follows",
        "The overall lexicon can be expressed by,\" Lexicon = L1 x L2 x • • (17) \"To make the lexicon describe equal-length relations, a special symbol, say 0, is inserted throughout.",
        "The operator x creates one large lexicon out of all the sublexica.",
        "This lexicon can be substantially reduced by intersecting it with Projectrl (iro)* .",
        "If a two-level grammar is compiled into an automaton, denoted by Gram, and a lexicon is compiled into an automaton, denoted by Lex, the automaton which enforces lexical constraints on the language is expressed by",
        "The first component above is a relation which accepts any surface symbol on its first tape and the lexicon on the remaining tapes."
      ]
    },
    {
      "heading": "5.3 Compiling Rules",
      "text": [
        "A compound regular rule with in context-pairs and in rule features takes the form",
        "where T, Ak , and pk, 1 < k < m are like before and Ok is the tuple of feature structures associated with rule k. The following modifications to the procedure given in section 4 are required.",
        "Forgetting contexts for the moment, our basic machine scans sequences of tuples (from 'T), but requires that any sequence representing a lexical entry be followed by the entry's feature structure (from (I)).",
        "This is achieved by modifying eq.",
        "4 as follows: Centers = P'([( U 7)P1+4101)* (20) TET The expression accepts the symbols, p', followed by zero or more occurrences of the following:",
        "1. one or more 7, each followed by p', and 2. a feature tuple in (I) followed by p'.",
        "In the second and third phases of the compilation process, we need to incorporate members of (I) freely throughout the contexts.",
        "For each ,\\k, we compute the new left context Lk = Insert:1.0k) (21) The right context is more complicated.",
        "It requires that the first feature structure to appear to the right of r is Ok.",
        "This is achieved by the expression,",
        "The intersection with r*Okr; ensures that the first feature structure to appear to the right of T is Ok: zero or more feasible tuples, followed by Ok, followed by zero or more feasible tuples or feature structures.",
        "Now we are ready to modify the Restrict relation.",
        "The first component in eq.",
        "5 becomes A = (7r U r(1))*/-71; (23) The expression allows (I) to appear in the left and right contexts of 7; however, at the left of T, the expression (7rU7r(D) puts the restriction that the first tuple at the left end must be in r, not in <D. The second component in eq.",
        "5 simply becomes",
        "Hence, Restrict becomes (after replacing T with w' in eq.",
        "23 and eq.",
        "24)",
        "In a similar manner, the CoerceR relation becomes"
      ]
    },
    {
      "heading": "6 Conclusion and Future Work",
      "text": [
        "The above algorithm was implemented in Prolog and was tested successfully with a number of sample-type grammars.",
        "In every case, the automata produced by the compiler were manually checked for correctness, and the machines were executed in generation mode to ensure that they did not over generate.",
        "It was mentioned that the algorithm presented here is based on the work of (Grimley-Evans, Kiraz, and Pulman, 1996) rather than (Kaplan and Kay, 1994).",
        "It must be stated, however, that the intuitive ideas behind our compilation of rule features, viz, the incorporation of rule features in contexts, are independent of the algorithm itself and can be also applied to (Kaplan and Kay, 1994) and (Mohri and Sproat, 1996).",
        "One issue which remains to be resolved, however, is to determine which approach for compiling rules into automata is more efficient: the standard method of (Kaplan and Kay, 1994) (also (Mohri and Sproat, 1996) which follows the same philosophy) or"
      ]
    },
    {
      "heading": "Algorithm Intersection Determini",
      "text": [
        "where n = number of rules in a grammar, and ki = number of contexts for rule i,1 < i < n.",
        "the subtractive approach of (Grimley-Evans, Kiraz, and Pulman, 1996).",
        "The statistics of the usage of computationally expensive operations – viz., intersection (quadratic complexity) and determinization (exponential complexity) – in both algorithms are summarized in Figure 4 (KK = Kaplan and Kay, EKP = Grimley-Evans, Kiraz and Pulman).",
        "Note that complementation requires determinization, and subtraction requires one intersection and one complementation since A – B=An73 – (27) Although statistically speaking the number of operations used in (Grimley-Evans, Kiraz, and Pulman, 1996) is less than the ones used in (Kaplan and Kay, 1994), only an empirical study can resolve the issue as the following example illustrates.",
        "Consider the expression dealt with at the morphotactic level using a unification based formalism."
      ]
    },
    {
      "heading": "Acknowledgments",
      "text": [
        "I would like to thank Richard Sproat for commenting on an earlier draft.",
        "Many of the anonymous reviewers' comments proofed very useful.",
        "Mistakes, as always, remain mine."
      ]
    }
  ]
}
