{
  "info": {
    "authors": [
      "Roberto Basili",
      "Gianluca Rossi",
      "Maria Teresa Pazienza"
    ],
    "book": "Conference on Empirical Methods in Natural Language Processing",
    "id": "acl-W97-0314",
    "title": "Inducing Terminology for Lexical Acquisition",
    "url": "https://aclweb.org/anthology/W97-0314",
    "year": 1997
  },
  "references": [
    "acl-A88-1019",
    "acl-C92-3150",
    "acl-C94-1084",
    "acl-C94-2195",
    "acl-J93-1005",
    "acl-J96-4006"
  ],
  "sections": [
    {
      "text": [
        "{basil i , derossi ,pazienza}0 info .utovrm.",
        "it"
      ]
    },
    {
      "heading": "Abstract",
      "text": [
        "Few attention has been paid to terminology extraction for what concerns the possibilities it offers to corpus linguistics and lexical acquisition.",
        "The problem of detecting terms in textual corpora has been approached in a complex framework.",
        "Terminology is seen as the acquisition of domain specific knowledge (i.e. semantic features, selectional restrictions) for complex terms and /or unknown words.",
        "This has useful implications on more complex text processing tasks (e.g. information extraction).",
        "An hybrid symbolic and probabilistic approach to terminology extraction has been defined.",
        "The proposed inductive method puts a specific attention to the linguistic description of what terms are as well as to the statistical characterization of terms as complex units of information typical of domain sub-languages.",
        "Experimental evidence of the proposed method are discussed."
      ]
    },
    {
      "heading": "1 Introduction",
      "text": [
        "Nowadays corpus processing techniques are widely adopted to approach the well-known lexical bottleneck problems in language engineering.",
        "Lexical acquisition methods rely on collocational analysis (pure statistics), robust parsing (syntax-driven acquisition) or semantic annotations as they are found in large thesaura or on-line dictionaries.",
        "The lexical information that trigger induction varies from simple word/tokens to syntactically annotated or semantically typed collocations (e.g. powerful vs. strong tea (Smadja,1989)), syntactic disambiguation rules (e.g. (Hindle and Rooths,1993), (Brill and Resnik,1994)) or sense disambiguation rules are usually derived.",
        "Such information is lexical as it encodes constraints (of different types) at the word level, to be thus inherited by morphologic variants of a given lemma.",
        "This strongly lexicalized knowledge, as it is extracted from corpus data, requires lexical entries to be known in advance in some morphologic database.",
        "POS taggers or lemmatizers are generally used to suitably map tokens to lemmas.",
        "It should be noted that lemmas in a corpus depends on the underlying sublanguage and their nature and shape is not as general as it is usually encoded in a morphologic dictionary.",
        "As an example, let studio (i.e. study as a noun) be an entry in an italian morphologic dictionary.",
        "Typical information in such a database is the following: studio pos=noun gen=mas num=sing The only legal morphologic variant of studio is studi (studies, with num=plur).",
        "When searching for studio in a corpus of environment related texts', we found this kind of occurrences (e.g. short contexts): studi di base ..., (basic studies) studi di impatto ambientale (*studies on the environmental impact) studi di fattibilita ..., (feasibility studies), studi di riferimento..., (reference studies) It is very common in a corpus (not balanced, thus focused to a limited domain) to find a set of specifications of nouns that have some specific properties:",
        "• they are not always compositional (e.g. studio di base); • they describe complex concepts (e.g. studi di fattibilitci) in the underlying technical domain, so they are relevant for text understanding and classification/extraction",
        "'Although our approach is in principle language independent, we systematically will describe rules and examples in italian as they have been derived from text.",
        "corpora in Italian.",
        "The environmental corpus, called ENEA, is a collection of short scientific abstracts or newspaper articles dealing with pollution.",
        "• they select specific and independent senses of the related term: studi di base refers to the abstract notion of study as an ongoing reasearch, while studi di fattibilita' is not a reasearch but a specific engineering task • the related nominal compounds show independent lexical properties.",
        "For example, all the examples are potential object of verbs like carry out, do, ... but only feasibility studies or studies on the environmental impact can be modelled by some techniques or policies.",
        "Furthermore, studies on the environmental impact have specific social and political implications that are no longer valid for the general notion of study.",
        "In the same environmental corpus the typical short contexts of the lemma attivita (activity) include notions like: attivitci umana (human activity), attivitcl entropica (hentropic activity), attivita di costruzione (building activity).",
        "These very common instances show that lexical acquisition for attivita or studio cannot be fully accomplished without discriminating the lexical properties of such pure collocations from those related to their complex nominals.",
        "The results of lexical acquisition should thus be different for entries like attivitli and attivita entropica.",
        "The underlying hypothesis is that complex concepts related to a lemma do not support all the generalizations related to the source lemma.",
        "In fact, whenever a concepts is built it acquires an autonomous role within a language so it behaves in an almost independent fashion.",
        "In order to capture the essential differences we need to select the proper set of terms in a given sublanguages, formalize them into independent lexicalizations and carry out a separate lexical acquisition for each of them.",
        "A further aspects that is worth to be mentioned is that terms are generally understood as single lexical units during syntactic recognition.",
        "They are sentence fragments already parsed.",
        "Robust methods widely emplOyed in computational linguistics are thus sensible to a precise recognition of terms, as much of the ambiguity embedded within the term structures simply disappear after ercognition has been accomplished.",
        "Let for example be attivita di costruzione or articoli da spiaggia (beach articles) two terms.",
        "Sentence fragments like l'inizio della attivita di costruzione the start of the building activity",
        "although inherently ambiguous (l'inizio della costruzione and trasportavano do spiaggia are sentence readings that also obey to selectional constraints (e.g. to transport/bring from a place)) can be correctly parsed when the two terms are employed before syntactic analysis is triggered.",
        "Applying syntactic driven lexical acquisition (e.g. (Grishman and Sterling,1994) or (Basili et al.,I996)) after corpus specific term recognition and extraction highly improve the precision and complexity of the parsing activity.",
        "Experimental evidence will be discussed in later sections.",
        "In synthesis corpus driven terminology definition and recognition has positive implications on LA:",
        "• Terms rather than words are the atomic units of information on which LA applies: more selective induction thus results in a more precise acquisition • Terminologic variants of a given term are hints for domain specific word sense disambiguation • Terms are sentence fragments that have been already parsed: the lower ambiguity resulting from term recognition has a beneficial effect on the later syntagmatic analysis of the corpus"
      ]
    },
    {
      "heading": "2 Terminology and Lexical Acquisition.",
      "text": [
        "In this framework, a term is more than a token or word (to be searched for) as it stands in a more subtle relation with a piece of information in a specific knowledge domain.",
        "It is a concept, as it requires a larger number of constraints on the information to be searched for in texts.",
        "Furthermore a term conveys a well assessed (usually complex) meaning as long as a user community agrees on its content.",
        "As long as we are interested in automatic terminology derivation, we can look at terms as surface canonical forms of (possibly structured) expressions indicating those contents.",
        "A term is thus characterized by a general commitment about it and this has some effects on its usage.",
        "Distributional properties of complex terms (nominals) differ significantly on those of their basic elements.",
        "Deviance from usual distributional behavior of single components can be used both as marker of non compositionality and specific hints of domain relevance.",
        "The detection of complex terms",
        "assumes a crucial role in improving robust parsing and POS tagging for lexical acquisition, thus supporting a more precise induction of lexical properties (e.g. PP disambiguation rules).",
        "This specific view extends and generalizes the classical notion of terminology as used in Information Science.",
        "Most of the domain specific terms we are interested to are nouns or noun phrases that generally denote concepts in a knowledge domain.",
        "In order to approach the problem of terminological induction we thus need:",
        "1. to extract surface forms that are possible candidates as concept markers; 2. to decide which of those candidates are actually concepts within a given knowledge domain, identified by the set of analyzed texts.",
        "Linguistic principles characterize classes of surface forms as potential terms (step 1).",
        "Note that the notion of terminological legal expression here is not equivalent to that of legal noun phrases.",
        "Concepts are lexicalized in surface forms via a set of operations that imply semantic specifications.",
        "The way syntax operates such specification may be very complex and independent on the notion of grammatical well formedness.",
        "The decision in step (2) is again sensible to a principled way a language expresses concept specifications but needs also to be specific to the given knowledge domain, i.e. to the underlying sublan-guage.",
        "Given the body of texts, the selective extraction should be sensitive to the different observed information.",
        "In this phase statistics is crucial to control the relevance of linguistically plausible forms of all the guessed terms."
      ]
    },
    {
      "heading": "3 Integrating linguistic and statistical information for term discovery",
      "text": [
        "The principled definitions of legal grammatical structures by which terms are expressed and the description of their distributional properties in a sub-language are crucial for the automatic construction of a domain terminological dictionary.",
        "A number of methods for language driven terminological extraction and complex nominals parsing and recognition have been proposed to support NLP and lexical acquisition tasks.",
        "They mainly differ in the emphasis they give to syntactic and statistical control of the induction process.",
        "In (Church,1988) a well-know purely statistical method for POS tagging is applied to the derivation of simple noun phrases that are relevant in the underlying corpus.",
        "On the contrary more language oriented methods are those where specialized grammar are used.",
        "LEXTER (Bouri-gault,1992) extracts maximal length noun phrases (mini)) from a corpus, and then applies a special purpose noun phrase parsing to them in order to focus on significant complex nominals.",
        "Although the reported recall of the mlnp extraction is very high (95%) the precision of the method is not reported.",
        "Voutilanen (1993) describes a noun phrase extraction tool (N Ptool) based upon a lemmatizer for English (ENGTWOL) and on a Constraint Grammar parser.",
        "The set of potential well-formed noun phrases are selected according to two parsers working with different NP-hood heuristics.",
        "A very high performance of NP recognition is reported (98.5% recall, and 95% precision).",
        "A more statistically oriented approach is undertaken in (Daille et a1,1994) where a methodology for syntactic recognition of complex nominals is described.",
        "Linguistic filters of morphological nature are also applied.",
        "Corpus driven analysis is mainly based on mutual information statistics and the resulting system has been successfully applied to technical documentation, e.g. telecommunication.",
        "All these methods deal with the problem of NP recognition.",
        "As we are essentially interested to NP that are actual terms in a domain, we will need to decide which NPs are actual terms.",
        "We will define:",
        "1. well formedness principia for term denotations and a description of the different grammatical phenomena related to terms of a language 2. distributional properties that distinguish terms from other (accidental) forms (e.g. non terminological complex nominals)."
      ]
    },
    {
      "heading": "3.1 Grammatical descriptions of terms in Italian",
      "text": [
        "It is generally assumed that a terminologic dictionary is composed of a (possibly structured) list of nouns, or complex nominals.",
        "Nominal forms are in fact lexicalization of domain concepts: proper nouns, acronyms as well as technical concepts are mostly represented as nominal phrases of different length and complexity.",
        "For this reason, we concentrated only on noun phrases analysis, as the main source of terminologic information'.",
        "A term is obtained by applying several mechanisms that add to a source word (generally a noun) a set of further specifications (as additional constraints of semantic nature).",
        "A detailed analysis of the role of syntactic modifiers and specifiers (De Rossi,1996) revealed that legal structures for modifiers and specifiers in Italian are mainly of two types:",
        "1. restrictive (or denotative) modifiers (postnom-inal participial, adjectival or prepositional phrases) 2. appositive (or connotative) modifiers (prenomi-nal modifiers, i.e. adjectival phrases)",
        "Restrictive modifiers are generally used to constraint the semantic information related to the corresponding noun, via a further specification of a given typefor that noun as in scambi commerciali (*exchanges commercial): the referent noun is forced to belong to a restricted set of exchanges (that are in fact of commercial nature).",
        "On the contrary, appositive modifiers are used by the speaker/writer to add additional details: his own point of view or pragmatic information, as in /a bianca cornice (the white frame) or la perduta gente (the lost people).",
        "Appositive modifiers do not correspond to any (shared) classification, but rather to the subjective speaker's point of view.",
        "Furthermore prenominal modifications are rather unfrequent in Italian.",
        "We thus decided to focus only on restrictive modifiers, the best candidates to bring terminological (i.e. assessed classificatory) information.",
        "The set of syntactic phenomena that have been studied as good candidates for restrictive forms are:",
        "1. adjectival specification (via postnominal adjectives, as in inquinamento idrologico (*pollution hydrological)) 2. nominal specification (postnominal appositions, as in vagone letto (wagon-lit), or Fiat Auto (Fiat Cars)) 3. locative phenomena (postnominal proper nouns indicating locations, as in IBM Italia 4. verbal specification (via postnominal past participle, as in siti inquinati (*sites polluted)) 5. prepositional specification (via a particular set",
        "of postnominal prepositional structures, as in istituto di Matematica (Institute of Mathematics), or barca a vela (sailing-boat)).",
        "3 Given the above linguistic principles, a special purpose grammar for potential terminological structures can be sketched.",
        "With a simple language of regular expressions the grammar of adjectival, 3 The set of prepositions that have been selected to introduce typical restrictive descriptions are: di,a,per,da.",
        "Only postnominal prepositional phrases introduced by one of these prepositions have been allowed for term expressions.",
        "prepositional and participial restrictions can be expressed as:",
        "Prepositional postmodifiers are modeled according to the following rules:",
        "Note that the allowed structures are post nominal due to the typical role of specifications in Italian."
      ]
    },
    {
      "heading": "3.2 Distributional properties and term extraction",
      "text": [
        "The recursive nature of some rules require an iterative analysis of the corpus.",
        "The following algorithm is used:",
        "1.",
        "Select singleton nouns whose distributional properties are those for terms and insert them in the terminologic dictionary (TD) 2.",
        "Use the valid terms in TD to trigger the grammar and build complex nominals en 3.",
        "Select those en whose distributional properties are those for terms and insert them in TD.",
        "4.",
        "Iterate steps 2 and 3 to build longer en 4.",
        "Note that newly found complex terms, added to TD in step 3, force a re-estimation of term probabilities obtained by a further corpus scanning, so that their heads are not counted twice.",
        "The validation of a limited set of potential surface forms as actual terms is crucial for lowering the complexity of the above algorithm.",
        "Given the grammar, we need criteria to decide which surface forms, that reflect the typical structure of a potential terms, are actual lexicalizations of relevant concepts of the corpus.",
        "The kind of observations that are available from the corpus are: (i) the set of lemmas met in the texts, (ii) the set of their well formed restrictions (i.e. complex nominals) and (iii) the distributional properties of entries in (i) and (ii).",
        "We firstly establish when a singleton lemma is a relevant concept by using distributional properties of nouns.",
        "Then we characterize which restrictions of those terms are valid lexicalizations of more specific concepts.",
        "We proceed as follows:",
        "1.",
        "Select the set of lemmas that by themselves are markers of relevant concepts in the corpus.",
        "Lemmas are detected according to their frequency in the observed language sample as well as to their selectivity, i.e. how they partition the set of documents.",
        "This phase produces an early TD dictionary of simple terminological elements.",
        "2.",
        "Extend TD also with those (well-formed) re",
        "strictions, cn(l), of any I E TD according to the mutual information they exchange with I.",
        "Select and Extend depend on distributional properties of simple lemmas and complex norninals, respectively.",
        "The distributional property needed for the Select step is the term specificity.",
        "Specific nouns are those frequently occurring in a corpus, but whose selectivity in sets of documents is very high, that is: they are very frequent in a (possibly small) set of documents and very rare in the rest.",
        "In order to capture such behavior we use two scores: the frequency tj of a term i in a document j and the inverse document frequency of a term (Salton,1989).",
        "Given a term i, its inverse document frequency is defined as follows:",
        "where dfi is the number of documents of the corpus that include term i, while N is the total number of documents in the collection.",
        "The following criteria is defined to capture singleton terms: if exists at least one document where a noun i is required as index (because it is relevant for that document and selective with respect to other documents) then such a noun denotes a relevant domain term (i.e. specific concept).",
        "In order to decide we rely on idfi and tij as follows.",
        "DEF: (Singleton term).",
        "A noun i is a term if at least one document j exists for which:",
        "wij captures exactly the notion of specificity required in the Select step of our algorithm.",
        "Potential heads of terminological entries are selected according to their selective power in the corpus.",
        "Even very rare words of the corpus can be captured by (1).",
        "In the Extend step of the algorithm we need to evaluate the mutual information values of phrase structures like:",
        "head Modi Mod2 Mod, Mutual Information between two words x and y is defined as (Fano,1961): gx, 1 o g proPbr( rg:0Y2( y and it can be estimated by a maximum likelihood method as in (Dagan,1993):",
        "where: f req(x , y) is the frequency of the joint event of (x,y), freq(x), freq(y) and N are the frequency of x, y and the corpus size respectively.",
        "In order to apply the standard definition of mutual information we need to extend it to capture the specific nature of the joint event head-modifier (H M1).",
        "Note that Mi denotes post nominal adjectives or past participle but also prepositional phrase like dello Stato in territorio dello Stato.",
        "We decided to estimate the Mutual Information of such structures in a left to right fashion.",
        "The rightmost modifier (i.e. M1 in (H Mr) structures, or Mn in (H M1 ... Mn)) is considered as the right event y and every left incoming substructure (i.e. H or H M0_1) is represented as a single event x.",
        "The generalized evaluation of Mutual information for cn = ((H, M17 M2 • • • Mtt-1), MO is thus:",
        "(2) As an example a term like debit° pubblico (public debt) receive a mutual information score according to the following figure:",
        "while debit° publico ester° (foreign public debt) produces to the following ratio:",
        "The threshold d(H) depends on noun H as it, is evaluated according to the statistical distribution of every complex nominals headed by H 5.",
        "The set of singleton terms is exactly the same set that a classical indexing model (Salton,1989) obtains from the document collection (i.e. the corpus).",
        "The Extend 5 In the experimental tests best values for 6 have been obtained as a function of mean and variance of the I distribution over the set of cn headed by H",
        "phase allows to capture all the relevant specifications of the singleton terms, compile a more appropriate dictionary (for the corpus) and structure it in hierarchically organized entries."
      ]
    },
    {
      "heading": "4 Implementation Issues",
      "text": [
        "The model described in the previous section has been used to implement a system for terminology derivation from a corpus.",
        "The system relies upon the POS tagging activity as it is carried out within a LA framework (e.g. the ARIOSTO system (Basili et al.,1996)) and extracts a full terminologic dictionary TD of:",
        "1. simple terms (i.e. nouns) as seeds of a terminological structured dictionary (selected according to (1) 2. complex nominal forms of some of those seeds, generated by the grammar and filtered according to (3).",
        "Terminology extraction is triggered after POS tagging.",
        "Morphologic analysis is rerun according to the compiled TD.",
        "This feedback allows the system to exploit complex term extraction before activating syntactic recognition, in order to prune out significant components of grammatical ambiguity.",
        "This improves the overall ability of the linguistic processor and supports term oriented rather than lemma oriented lexical acquisition.",
        "A dedicated subsystem has been developed to support manual validation of single terms.",
        "In Figure 1 a screen dump of the graphical interface that supports the interactive validation (or removal) of terms in TD is shown.",
        "TD is hierarchically organized in separate sections where singleton terms dominate all their specified subconcepts.",
        "A section is the set of terms that share the same term head.",
        "A term like smaltimento dei rifiuti (garbage collection), has the noun \"smaltimento\" (garbage) as its term head.",
        "A specific section includes terms like sinalti-mento dei rifiuti, smaltimento di materiale tossico, smaltimento di gas di scarico, ...).",
        "In Figure 1 the head noun debito (debt)) is reported: the section related to debito includes all its validated specifications (e.g.debito pubblico (public debt), debito pubblico estero (foreign public debt) ...)."
      ]
    },
    {
      "heading": "5 Experimental Set-Up",
      "text": [
        "In this section we describe the experimental set-up used to evaluate and assess the described model of terminological derivation.",
        "The method has been tested over two corpora of italian documents.",
        "The first corpus (ENEA) is a",
        "collection of scientific abstracts on the environment, made of about 350.000 words.",
        "The second corpus (Sole240ore) is an excerpt of financial news from the Sole 24 Ore economic newspaper, of about 1.300.000 words.",
        "The terminology extraction have been run over both the corpora.",
        "From the ENEA corpus we derived a dictionary of about 2828 words.",
        "From the Sole240re corpus 5639 terms have been extracted.",
        "In order to carry out the experiments we used a subset of the ENEA corpus in order to measure performance over manually validated documents.",
        "The specific nature of our tests required the definition of particular performance evaluation measures.",
        "In fact, together with the classical notion of recall and precisions, we used also data compression, as the percentage of incorrect syntactic data that are no longer produced when specific terminology is used.",
        "A further index is the average ambiguity defined according to the notion of collision set (Basili et al., 1994).",
        "In order to accomplish the task further reference information has been used: two standard domain specific thesaura have been used for comparing the result of the terminology extraction in the environmental domain (ENEA corpus)."
      ]
    },
    {
      "heading": "5.1 Linguistic analysis of corpus data",
      "text": [
        "In Table 1 the section headed by attivita, as it has been derived from the ENEA corpus, is shown.",
        "The",
        "specific nature of the corpus is well reproduced by the data.",
        "Here two specific senses of the lemma aitivitii are captured: natural and biological activity as in attivita entropica and human activities (like attivita produttiva (productive activity) or attivita di costruzione (building activity).",
        "These latter have specific implications (for what concerns artificial pollution) in the environment.",
        "Table 1 reports also the distribution of the term in a set of 106 documents.",
        "In method RI terms have been selected by classical inverse document frequency (Salton,1989) applied to singleton lemmas (i.e.attivita).",
        "In Method TI we run inverse document frequency after a terminology driven lemma-tization of documents (i.e. using complex terms as source lemmas).",
        "The two sections of the table show that no index has been lost by the TI method (all of the 15 indexes have been found).",
        "This result is more general: TI method produces more indexes.",
        "Over the 106 documents MI extracts 476 simple indexes while TI extracts 732 (terminological) indexes.",
        "Again in Table 1, 5 of the fifteen indexes found by the TI method are complex nominals.",
        "In the set of documents from 1 to 20 (11(320 column) these allow to discriminate between attivita and attivita antropica.",
        "Such an higher discriminating power is required not only for document classification/retrieval but, first of all for lexical acquisition: in this technical domain in fact it seems necessary to rely on the information that attivita is typically carried out by humans while attivita antropica is not.",
        "We are convinced that these are the typical selectional constraints to be captured by corpus driven lexical acquisition methods.",
        "Finer lexicalizations (like attivita antropica) are the only way to provide a better input to the target acquisition tasks."
      ]
    },
    {
      "heading": "5.2 Experiment 1: Effectiveness of the terminology extraction",
      "text": [
        "The aim of this experiment was to test the ability of the method to capture relevant concepts in the sublanguage.",
        "We run this test on the environmental domain (ENEA corpus).",
        "The reference term dictionary was manually compiled by a team of three domain experts, culturally heterogeneous.",
        "We got a complete list of terms (simple nouns as well as complex nominals) to be used as a test-set (RT).",
        "The reference document set was a collection of 106 documents.",
        "The experts compiled a set of 482 terms organized in 155 sections (i.e. relevant head nouns).",
        "Each section thus includes 3.12 terms.",
        "For sake of completeness we selected two large hand-coded thesaura for the environment: the CNR dictionary",
        "(CNR,,1995)(that includes 9613 terms) and the AIB dictionary (AIB,1995).",
        "Both these dictionaries as well as the automatically generated dictionary TD have been compared with the reference RT.",
        "The comparison has been carried out throughout the different aligned sections.",
        "The alignment of the section related to the head smaltimento is reported in Table 2 (\"X\" means the presence of the term in the corresponding dictionary, while \".\" denotes its absence): Any dictionary D can thus be evaluated by measuring precision, i.e. precision and recall, i.e.",
        "For example within the section related to the head smaltimento, we have 3 RT terms, of which 1 is in CNR and AIB respectively and 3 are in TD.",
        "When applying the recall and precision definition to every sections of the RT dictionary we obtained the average performance scores reported in Table 3 over the three dictionaries."
      ]
    },
    {
      "heading": "5.3 Experiment 2: Shallow parsing with terminological knowledge",
      "text": [
        "Consulting a terminologic dictionary before activating a shallow syntactic analyzer is helpful to solve several morphological and syntactic ambiguities.",
        "For exarnple, given the sentence 6 L 'ufficiale delta Guardia di Finanza visitO l'aereoporto di Fiumicino (The officer of Finance Guard visited the Fiumicino airport) a typical shallow syntactic analyzer (SSA) (Basili et al., 1992) produces the following elementary syntactic links (esl), due the syntactic ambiguity of prepositional phrases (PP), e.g. ( (di fitianza), (di Fiumicino)):",
        "As each sentence reading cannot assign more than a single referent to each PP, we can partition the set of esl into several collision sets (i.e. sets of esl that cannot belong to the same sentence reading according to (Basin et al., 1994)).",
        "The sample sentence gives rise to the following collision sets:",
        "When terminology is available many complex nominals are retained as single tokens and several ambiguity disappear.",
        "In the Sole240re corpus our method produced both the terms guardia di finanza and aeroporto di Fiumicino so that the final list of esl reduces to",
        "and no ambiguous (i.e. not singleton) collision set remains.",
        "We have two positive effects on the parsing activity.",
        "The first is data compression.",
        "In fact the overgeneration typically due to the shallow grammatical approach is significantly limited.",
        "In our example the early 7 elementary syntactic groups obtained in absence of terminology reduced to 4 with an overall data compression of ((7-4)/7) 42.8%.",
        "An extended experimentation has been carried out On a subset of 500 sentences of the corpus.",
        "The use of terminology reduces the number of elementary syntactic links from 500 to 403 with a corresponding 20% of overall data compression.",
        "Furthermore, the detection of a term carried out over single tokens that are morphologically ambiguous improves also the morphological recognition.",
        "In fact the detection of a chain of tokens that are part of the same term implies a specific choice on the grammatical category of each token, thus augmenting the selectivity of POS tagging.",
        "Over the same subset of the corpus we measured a decrement of 4% in the number of morphological derivations produced with terminology against the recognition carried out in absence of any terminological knowledge.",
        "A second positive aspect of having an available",
        "domain specific terminology is the reduction of the underlying syntactic ambiguity and increase of the parser precision.",
        "As shown in the example many PP ambiguity disappears as soon as a set complex nominals is detected.",
        "This has a strong implication on shallow (or robust as widely accepted in literature) parsing.",
        "We conducted a systematic analysis of correct parsing results by contrasting a parser with and without access to domain terminology.",
        "The analysis of the results has been performed by comparing collision sets obtained by the two runs over a set of 100 sentences.",
        "Four performance scores have been evaluated: the degree of ambiguity (i.e.the ratio between the number of ambiguous esl's over the total number of derived esl's); the average ambiguity (expressed by the average cardinality of the collision sets (i.e. the number of reciprocally ambiguous esl's); finally, precision and recall have been measured according to a hand validation of the derived syntactic material 7 .",
        "The analysis has been carried out specifically for prepositional esl's (i.e. noun-preposition-noun, verb-preposition-noun, adjective-preposition-noun links).",
        "Results are reported in Table 4 where separate columns express the scores for the different runs: a simple parser (SP), and a terminology driven parser (TP).",
        "As a result the simple parser obtains several complex nominals but only as syntactic structures so that it fails in detecting higher order syntactic links (i.e. syntactic relations between complex nominals and other sentence segments).",
        "In these cases we penalized also the recall of the SP method, so that the difference between the two methods relies not only in amount of persisting ambiguity (i.e. precision), but also in coverage (better captured by recall)."
      ]
    },
    {
      "heading": "6 Conclusions",
      "text": [
        "In this paper a method for the automatic extraction of terminological (possibly complex) units of information from corpora is presented.",
        "The proposed method combines principle of grammatical correctness with statistical constraints on the distributional",
        "properties of the detected domain terms.",
        "In an incremental fashion NPs are first selected as possible candidates for term denotation and then inserted in an incremental terminological dictionary according to their mutual information value.",
        "The experimental test has been difficult as a precise notion of what is a relevant term in a domain is very vague and subjective.",
        "Tests against a domain specific user oriented dictionary have been carried out, in comparison with large scale thesaura in the domain.",
        "The significant improvement against this standard sources is very successful.",
        "The method has been widely applied to different corpora and it demonstrated to be easily portable without any heavy customization.",
        "As it relies upon simple PUS tagging, it is widely portable to other languages, as soon as NP grammars are available.",
        "Feedback of the terminological extraction process to the morphologic analysis has been also designed.",
        "A measure of the improvement that terminological NP recognition implies over the activity of a shallow parser for LA has been carried out.",
        "The result is an overall improvement: data compression is around 5% while syntactic ambiguity elimination is about 10%.",
        "Recall and Precision of the syntactic analysis is consequently higher.",
        "The main result of this method is to support finer lexicalization, in form of complex nominals, for lexical acquisition.",
        "Lexical acquisition based on collocations between terms (and not simple lemmas) provides more granular information on lexical senses as well as (syntactic or semantic) selectional constraints.",
        "The success of this method allow to design automatic methods for taxonomic (thesaurus-like) knowledge generation.",
        "Distributional, as well syntactic, knowledge is a crucial source of information for large scale similarity estimation among detected terms."
      ]
    },
    {
      "heading": "References",
      "text": []
    },
    {
      "heading": "7 Appendix 1: Excerpt of Terminological Dictionaries from two domains",
      "text": []
    }
  ]
}
