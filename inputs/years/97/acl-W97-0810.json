{
  "info": {
    "authors": [
      "Salah Ait-Mokhtar",
      "Jean-Pierre Chanod"
    ],
    "book": "Workshop on Automatic Information Extraction and Building of Lexical Semantic Resources for NLP Applications",
    "id": "acl-W97-0810",
    "title": "Subject and Object Dependency Extraction Using Finite-State Transducers",
    "url": "https://aclweb.org/anthology/W97-0810",
    "year": 1997
  },
  "references": [
    "acl-A97-1012",
    "acl-C92-1027",
    "acl-C92-2099",
    "acl-C94-1043",
    "acl-E93-1046",
    "acl-E95-1021",
    "acl-P91-1027",
    "acl-P96-1015"
  ],
  "sections": [
    {
      "heading": "Abstract",
      "text": [
        "We describe and evaluate an approach for fast automatic recognition and extraction of subject and object dependency relations from large French corpora, using a sequence of finite-state transducers.",
        "The extraction is performed in two major steps: incremental finite-state parsing and extraction of subject/verb and object/verb relations.",
        "Our incremental and cautious approach during the first phase allows the system to deal successfully with complex phenomena such as embeddings, coordination of VPs and NPs or non-standard word order.",
        "The extraction requires no subcategorisation information.",
        "It relies on POS information only.",
        "After describing the two steps, we give the results of an evaluation on various types of unrestricted corpora.",
        "Precision is around 90-97% for subjects (84-88% for objects) and recall around 86-92% for subjects (80-90% for objects).",
        "We also provide some error analysis; in particular, we evaluate the impact of POS tagging errors on subject/object dependency extraction."
      ]
    },
    {
      "heading": "1 Introduction",
      "text": [
        "Dependency extraction from large corpora is mainly used in two major directions: automatic acquisition of lexical patterns [Brent, 1991; Grishman and Sterling, 1992; Briscoe and Carrot, 1994; Sanfilippo, 1994}l for end-user applications such as document indexing or information retrieval [Grefenstette, 1994].",
        "We describe and evaluate an approach for fast automatic recognition and extraction of subject and object dependency relations from large French corpora, using a sequence of finite-state transducers.",
        "The extraction is based on robust shallow parsing.",
        "We extract syntactic relations without producing complete parse trees in the",
        "traditional sense.",
        "The extraction requires no subcategori-sation information.",
        "It relies on POS information only.",
        "The extraction is performed in two major steps: I. incremental finite-state parsing annotates the input string with syntactic markings; 2. the annotated string is transduced in order to extract subject/verb and object/verb relations.",
        "Our incremental and cautious approach during the first phase allows the system to deal successfully with complex phenomena such as embeddings, coordination of VPs and NPs or non-standard word order.",
        "We evaluated subject and object dependency extraction on various types of unrestricted corpora.",
        "Precision is around 90-97% for subjects (84-88% for objects) and recall around 86-92% for subjects (80-90% for objects).",
        "The paper also provides some error analysis; in particular, we evaluate the impact of POS tagging errors on the extraction process."
      ]
    },
    {
      "heading": "2 Incremental Finite-State Parsing",
      "text": [
        "[Mt-Mokhtar and Chanod, 1997] fully describes the incremental finite-state parser.",
        "Unlike previous work in this area [Abney, 1991; Roche, 1993; Appelt et al., 1993; Koskenniemi et al., 1992; Voutilainen and Ta-panainen, 1993; Chanod and Tapanainen, 1996] the parser combines constructivist and reductionist approaches, in order to maximise efficiency and robustness.",
        "Before the parsing proper, we perform tokenisation, lexical lookup and part-of-speech disambiguation, using the French Xerox tagger [Chanod and Tapanainen, 1995].",
        "The input to the parser is a tagged string represented by a sequence of word-form + tag pairs of the type: le bon vin (the good wine) <1e+DET-SG> <bon+ADJ-SG> <vin+NOUN-SG>",
        "The parser output is a shallow parse where phrasal and clausal constructs are bracketed and more or less richly annotated as in: Jean aime le bon yin (lit.",
        ": John likes the good wine) [VC [NP Jean NP]/ SUBJ :v aime v: VC] [NP le [AP bon AP] vin NP]/OBJ The parser consists of a sequence of transducers.",
        "These transducers are compiled from regular expressions that mainly involve the longest match replace operator' [Karttunen, 1996].",
        "Each of these transducers adds syntactic information represented by reserved symbols (annotations), such as segment names, boundaries and tags for syntactic functions.",
        "At any given stage of the sequence, the input and the output represent the whole sentence as an annotated string.",
        "The output of a transducer is the input to the next transducer.",
        "The parsing process is incremental in the sense that the linguistic description attached to a given transducer in the sequence: - adds information relying on the preceding sequence of transductions; - applies only to some instances of a given linguistic phenomenon; - may be revised at a later stage.",
        "Each step defines a syntactic construction using two major operations: segmentation and syntactic marking.",
        "Segmentation consists in bracketing and labeling adjacent elements belonging to a same partial construction (e.g. a nominal or a verbal phrase, or a more partial syntactic chain if necessary).",
        "Segmentation includes also the identification of clause boundaries.",
        "Syntactic marking annotates segments with syntactic functions (e.g. subject, object, PPObj).",
        "The two operations of segmentation and syntactic marking are performed throughout the cascade in an interrelated fashion.",
        "Some segmentations depend on previous syntactic marking and vice versa.",
        "If the constraints encoded by a given transducer do not hold, the string remains unchanged.",
        "This ensures that there is always an output string at the end of the cascade, with possibly underspecified segments.",
        "The additional information provided at each stage in the sequence is instrumental in the definition of the later stages of the cascade.",
        "Networks are ordered in such a way that the easiest tasks are addressed first.",
        "They can be performed accurately with less background information."
      ]
    },
    {
      "heading": "2.1 Primary Segmentation",
      "text": [
        "A segment (or chunk) is a continuous sequence of words that are syntactically linked to each other or to a governing head (see [Federici et al., 1996; Ait-Mokhtar and Chanod, 1997] for a more detailed description).",
        "Segments are marked using regular expressions such as the following one for NPs: [TBeginNP â€“ S[TEndNP] TEndNP ] @-> [NP NPT where the longest-match left-to-right Replace Operator (noted @->) inserts [NP and NP] boundaries around the longest sequence that begins with a potential NP start (TBeginNP) and ends with the first NP end (TEndNP) to the right.",
        "In the primary segmentation step, we mark segment boundaries within sentences as shown below.",
        "Here NP stands for Noun Phrase, PP for Preposition Phrase and VC for Verb Chunk (a VC contains at least one verb and possibly some of its arguments and modifiers).",
        "[PP de demarrage PP] [PP sur la position PP] [AP auxiliaire AP] , [NP F aiguille NP] retoume VC] alors [PP a zero PP] ./SENT3 All the words within a segment, except the head, are linked to words in the same segment at the same level.",
        "The main purpose of marking segments is therefore to constrain the linguistic space that determines the syntactic function of a word.",
        "As one can see from the example above, segmentation is very cautious.",
        "Structural ambiguity inherent to modifiers attachment, verb arguments and coordination is not resolved at this stage."
      ]
    },
    {
      "heading": "2.2 Marking Syntactic Functions",
      "text": [
        "Syntactic functions within nonrecursive segments (AP, NP and PP') are handled first because they are easier to mark.",
        "The other functions within verb segments and at sentence level (subject, object, verb modifier, etc.)",
        "are considered later.",
        "The string marked with segmentation and syntactic annotations is the input to the extraction component described below.",
        "Extracting dependency relations from annotated strings is not straightforward, as the annotations do not explicitly relate arguments to their governing heads.",
        "For instance, shared arguments of coordinated verbs or dependencies accross embedded structures need to be resolved during the extraction phase, as illustrated in the example below': La vile de Lattes rejette toujours la proposition de remonter le niveau du fleuve pour fa-ciliter la circulation des bateaux et n'exclut pas a priori l'idee d'instaurer un pelage.",
        "The parser outputs is: [VC [NP La vile NP]/ SUBJ [PP de Lattes PP] :v rejette v: VC] toujours [NP la proposition NP]/ OBJ [VC de remonter VC] [NP le niveau NP] /OBJ [PP du fleuve PP] [VC pour faciliter VC] [NP la circulation NP]/OBJ [PP des bateaux PP] [VC et :v n exclut v: VC] pas a priori [NP idee NP]/ 013J [VC d' instaurer VC] [NP un peage NP]/ OBJ As objects are marked outside the verb chunks (VC), the extraction phase must still expand the VCs in order to identify object dependencies.",
        "Moreover, the extraction must identify la vile as the shared subject of the coordinated verbs rejette and exclut, which are separated by two infinitival clauses.",
        "After the preliminary parsing stage, the two coordinated verbs still belong to two different VCs."
      ]
    },
    {
      "heading": "3 Subject and Object Recognition and Extraction",
      "text": [
        "The task consists in recognizing the subject and object segments and extracting them along with their respective verbs.",
        "Function tagging is performed during the shallow parsing process; then a special transducer recognizes subject/verb and object/verb dependencies (i.e. it finds out which is the subject or object of which verb) and extracts them."
      ]
    },
    {
      "heading": "3.1 Subject and object tagging",
      "text": [
        "Potential subjects are marked first.",
        "An NP is a potential subject if and only if it is followed by a finite verb and it satisfies some typographical conditions (it should not be separated from the verb with only one comma, etc.).",
        "This prevents the NP Jacques Boutet for instance from being marked as a subject in the sentence below: 5 In English The city of Lattes still rejects the proposal to raise the level of the river to facilitate the boat traffic and does not exclude a priori the idea of imposing a toll [VC [NP le president NP]/SUBJ [PP du CSA PP], [NP Jacques Boutet NP] , a decide' VC] [VC de publier VC] [NP la.",
        "profession NP]/OBJ [PP de foi PP]./ SENT If this type of subject does not exist, we look for inverted subjects under the same typographical constraints.",
        "Other constraints are applied later to eliminate some of the potential subject hypotheses.",
        "These constraints are mainly syntactic:",
        "1.",
        "A potential subject is not a subject if it has no determiner, unless it is a proper noun or it is a coordinated common noun.",
        "2.",
        "A potential subject is not a subject if it immediately follows a PP or an NP (i.e. with no connector in between) and is preceded or followed by another potential subject.",
        "3.",
        "A potential subject is not a subject if it is followed by another potential subject with no coordination.",
        "The remaining potential subjects are taken to be actual subjects.",
        "The whole process of tagging and correcting subject tags consists of a sequence of replace expressions.",
        "Once the subjects are tagged, another transducer performs object tagging with similar steps and constraints but now only non subject NPs are considered."
      ]
    },
    {
      "heading": "3.2 Ernbeddings and regular expressions",
      "text": [
        "To make this approach work properly, we must be very careful to take into account embedded contexts (embedded clauses, text within parentheses, and so on).",
        "For instance, subject constraint 3 above should not apply if the two potential subjects are not at the same level, like the subjects [NI, l'usine NP] and [NP le ministre NP] in the following sentence: [VC [NP L usine NP1/SUBJ [VC que [NP le ministre NP]/SUBJ :v devrait v: VC] [VC implanter VC] [PP a Eloyes PP], :v represente v: VC] [NP un investissement NP]!",
        "OBJ [PP d'environ 148 milliards NP]/N [PP de francs PP] ./SENT6 This also applies throughout the dependency extraction process as described in the next section.",
        "In order to handle this difficulty properly with the finite state calculus, we take advantage of the verb segmenting marks produced by the shallow parser and define a maximal embedding level:",
        "level = [ levelÂ° I [BeginVC level() EndVCi ]* curlev =[levell I [BeginVC levell EndVC] ]* The regular expression level0 matches any string which does not contain any BeginVC or EndVC marks, i.e, an embedded clause, level!",
        "matches any string that contains strings matching level0 or entire embedded clauses that contains only levelÂ° matching strings.",
        "Therefore, curlev (which stands for Current Level) matches strings that either do not contain any embedded clauses, or may contain entire embedded clauses to a maximal depth of 2 embedded levels.",
        "We can easily extend the definition of curlev to handle punctuated embeddings such as texts within parentheses or hyphens.",
        "We define Bs as the beginning of such embeddings (either an opening parenthesis or a hyphen) and Es as the ending (a closing parenthesis or another hyphen):"
      ]
    },
    {
      "heading": "3.3 Extraction of Dependency Relations",
      "text": [
        "Once the subjects and objects are tagged, we get a shallow parse of the sentence where phrasal units and function tags appears, as shown in the example below: [VC [NP Le president NP]/SUBJ [PP du CSA PP], [NP Jacques Boutet NP] , a decide VC] [VC de publier VC] [NP la profession NPUOBJ [PP de foi PP] ./SENT One nontrivial task consists in associating the subjects and objects with the right verb.",
        "There are two main difficulties: with subjects and objects of embedded sentences, and with coordinated verbs and shared subjects and objects.",
        "To find out which is the subject/object of a given verb, only the Nps tagged as subjects/objects that are in the same level should be considered, This is necessary in order to avoid overgeneration of dependencies, that is, extracting the subject of an embedded sentence as the subject of the main verb or of another embedded sentence.",
        "The definition of curlev is very useful for such task.",
        "For instance, the transducer obtained from the following regular expression': Es =1 1\" I \"-\" and redefine the curlev expression as:",
        "levell [ levelÂ° J [BeginVC level0 EndVC] [ Bs level0 Es] 1* curlev [ level J [BeginVC levell EndVC] [ Bs levell Es] ]* Given these definitions, we can control the linguistic space in which rules and constraints apply.",
        "For instance, Subject constraint 3 can be written this way:",
        "which means: remove a potential subject tag (TSUBJ) whenever there is another potential subject on the right which is not preceded by a coordination.",
        "The other potential subject should be the last one before the finite verb.",
        "All these considerations are stated over the same sentence level (expressed as curlev) so that embeddings relative to a given level and what they contain are not concerned at all.",
        "[ 0 .x.",
        "rSUBJ:\"] ] x 0 I",
        "can be applied on the previous sentence to extract normal subject/verb dependencies: SUBJ: [NP Ie president NP] â€“ > [VC a decide.",
        "VC] Other similar expressions are written for the extraction of inverted subjects, shared subjects and objects.",
        "All the extracting expressions are joined using the Union operator I and compiled into a single transducer which takes as input shallow parses and produces subject/verb and object/verb dependencies."
      ]
    },
    {
      "heading": "3.4 Samples",
      "text": [
        "Below are some samples from the output of the extracting transducer.",
        "SUBJ: [NP qui NP] [VC precede VC] OBJ: [VC precede VC] 4 â€“ [NP congres NP] Sentence 2: En relancant ainsi deliberement l'agitation stir des enjeux de la greve de septembre 1988, Mr Guilhaume met en difficulte le gouvemement et force les autres PDG de l'audiovisueI public a choisir leur camp.",
        "Shallow parse: [VC [VC En relancant VC] ainsi deliberÃ©ment [NP r agitation NP]/OBJ [PP sur des enjeux PP] [PP de la greve PP] [PP de septembre PP] [NP 1988 NP1/N , [NP Mr Guilhaume NP] /SUBJ :v met v: VC] [PP en difficult& PP] [NP le gouvernement NPUOBJ [VC et :v force v: VC] [NP les [AP autres AP] PDG NP]/OBJ [PP de l'audiovisuel PP] [AP public AP] [VC a choisir VC] [NP leur camp NP]/ OBJ",
        "[NP les [AP autres AP] PDG NP] OBJ: [VC a choisir VC] < â€“ [NP [cur camp NP] Sentence 3: Mais, dÃ©jÃ , l'idee que ceux-ci puissent avoir la responsabilite d' un musee classcl (dtablissement dependant juridiquetnent dune yule on d' un dclpartement, trials dont les responsables sont nottirnes par l'Etat) provoque une certaine emotion chez les nationaux (voir le Monde du 23 novembre 1989)."
      ]
    },
    {
      "heading": "4 Evaluation",
      "text": [
        "The 15 networks of the parser and extractor require about 750 KBytes of disk space.",
        "The speed of analysis is around 150 words per second on a SPARCstation 10, including preprocessing (tokenisation, lexical lookup, POS tagging), parsing and dependency extractions, We evaluated the extraction on three different types of corpus: newspaper Le Monde (187 sentences, 4560 words, average 24.3 words/sentence), financial reports (524 sentences, 12551 words, average 24 words/sentence) and technical documentation (294 sentences, 5300 words, average 18 words/sentence).",
        "The sentences were selected randomly; they are independent from the corpus used for grammar development.",
        "The evaluation concentrated on recognition of surface nominal and pronominal subjects and on nominal direct object.",
        "Relations are counted as correct only if both the governing head and its argument are correct (for instance, we counted the subject/Verb relation as erroneous if the verb group was not fully correct, even if the subject was)."
      ]
    },
    {
      "heading": "Results are given in tables 1 and 2.",
      "text": []
    },
    {
      "heading": "4.1 Error analysis",
      "text": [
        "We conducted a detailed error analysis on the newspaper corpus.",
        "The major source of subject/verb and object/verb errors was identified for each sentence.",
        "If the same source of error accounts for more than one error in a given sentence, it is counted once.",
        "There may be also more than one source of error for the same sentence.",
        "We identified 81 sources of errors, distributed across the 68 sentences that included at least 1 error (table 3).",
        "Among the errors, some can be corrected easily with limited additional work.",
        "For instance, the tested version of the parser did not include preprocessing for time adverbials or numerical expressions.",
        "The tagset associated with the POS tagger did not provide enough distinctions between different types of pronouns'.",
        "The most significant errors are due to long NP sequences (coordination, enumeration, apposition) and to the POS tagger.",
        "NP sequences are challenging, as it is difficult for the parser to distinguish between apposi-tions, enumeration and coordinated NPs.",
        "Various parameters are to be taken into account (determiners, proper nouns, punctuation, semantic relations, etc.)",
        "many of which go beyond the scope of a shallow (or even non shallow) syntactic parser."
      ]
    },
    {
      "heading": "4.2 Errors due to POS tagger",
      "text": [
        "There is little to be found in the literature on the impact of PUS tagging errors on syntactic analysis.",
        "Out of 187 sentences in our newspaper corpus, 20 had subject or object errors due primarily to tagging errors.",
        "This does not mean that other sentences did not have tagging errors, but such errors had no impact on the assignment of subjects and objects (neither on the identification of head verbs).",
        "This is encouraging, because taggers with 97% acccuracy at word level may have a limited accuracy at sentence level (70%).",
        "Table 4 shows the extraction results from sentences where errors due to the POS tagger had no impact.",
        "The figures between parentheses refer to the results obtained on the whole corpus, i.e. including tagging errors.",
        "Source of errors Number of occurrences errors due to tagger 20 errors due to coordination 9 errors due to apposition or NP enumeration 9 errors due to time expressions , 7 errors due to pronouns 7 errors due to incise 2 errors due to subject inversion (not incise) 3 messed input (typos, missing blanks) 3 numerical expressions 3 punctuation 3 NP adverbials (other than time expressions) 2 errors due to missing determiners 2 errors due to frozen expressions 2 errors due to clause boundaries 2 errors due to negation (e.g. pas mains de) 2 predicate of non-finite verbs 2 bugs 1 emphatic constructions 1 book title (as object) 1",
        "The improvement is mostly for recall of objects.",
        "This is due to the French specific ambiguity for the words de, du, des which can be indefinite determiners or preposi-tion+determiner sequences.",
        "The tagger does not do a good job at distinguishing between the two tags, especially in postverbal position.",
        "This has an obvious impact on the dependency analysis, as segments mistagged as PPs cannot be identified as subjects or objects."
      ]
    },
    {
      "heading": "5 Conclusion",
      "text": [
        "We presented a finite-state approach to subject and object dependency extraction from unrestricted French corpora.",
        "The method involves incremental finite-state parsing and transductions for dependency extraction, using only part-of-speech information.",
        "The evaluation on different corpora (22,000 words) shows high accuracy and precision.",
        "The method is being expanded to other dependency relations and to other languages.",
        "The extracted dependencies can be used to automatically build subcategorisation frames or semantic restrictions for verb arguments, which, in turn, can be reused in further steps of incremental parsing.",
        "They can also be used for knowledge extraction from large corpora and for document indexing."
      ]
    },
    {
      "heading": "Acknowledgments:",
      "text": [
        "We are grateful to Annie Zaenen and Lauri Karttunen for their editorial advices."
      ]
    }
  ]
}
