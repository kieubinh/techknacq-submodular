{
  "info": {
    "authors": [
      "Antonio Sanfilippo"
    ],
    "book": "Workshop on Automatic Information Extraction and Building of Lexical Semantic Resources for NLP Applications",
    "id": "acl-W97-0812",
    "title": "Using Semantic Similarity to Acquire Cooccurrence Restrictions from Corpora",
    "url": "https://aclweb.org/anthology/W97-0812",
    "year": 1997
  },
  "references": [
    "acl-A92-1011",
    "acl-E93-1028",
    "acl-J91-1002",
    "acl-P91-1034",
    "acl-P95-1026",
    "acl-W95-0105"
  ],
  "sections": [
    {
      "heading": "Abstract",
      "text": [
        "We describe a method for acquiring semantic cooccurrence restrictions for tuples of syntactically related words (e.g. verb-object pairs) from text corpora automatically.",
        "This method uses the notion of semantic similarity to assign a sense from a dictionary database (e.g. WordNet) to ambiguous words occurring in a syntactic dependency.",
        "Semantic similarity is also used to merge disambiguated word tuples into classes of cooccurrence restrictions, This encoding makes it possible to reduce subsequent disambiguation events to simple table lookups."
      ]
    },
    {
      "heading": "1 Introduction",
      "text": [
        "Although the assessment of semantic similarity using a dictionary database as knowledge source has been recognized as providing significant cues for word clustering (Resnik 1995b) and the determination of lexical cohesion (Morris & Hirst, 1991), its relevance for word disambiguation in running text remains relatively unexplored.",
        "The goal of this paper is to investigate ways in which semantic similarity can be used to address the disambiguation of syntactic collocates with specific reference to the automatic acquisition of semantic cooccurrence restrictions from text corpora.",
        "A variety of methods have been proposed to rate words for semantic similarity with reference to an existing word sense bank.",
        "In Rada et al.",
        "(1939), semantic similarity is evaluated as the shortest path connecting the word senses being compared in a hierarchically structured thesaurus.",
        "Kozima & Furugori (1993) iffeasure conceptual distance by spreading activation on a semantic network derived from LDOCE.",
        "Resnik (1995a) defines the semantic similarity between two words as the entropy value of the most informative concept subsuming the two words in a hierarchically structured thesaurus.",
        "A comparative assessment of these methods falls outside the scope of this paper as the approach to disambiguation we propose is in principle compatible with virtually any treatment of semantic similarity.",
        "Rather, our objective is to show that given a reliable calculation of semantic similarity, good results can be obtained in the disambiguation of words in context, In the work described here, Resnik's approach was used.",
        "Following Resnik, semantic similarity is assessed with reference to the WordNet lexical database (Miller, 1990) where word senses are hierarchically structured.",
        "For example, (all senses of) the nouns clerk and salesperson in WordNet are connected to the first sense of the nouns employee, worker, person so as to indicate that clerk and salesperson are a kind of employee which is a kind of worker which in turn is a kind of person.",
        "In this case, the semantic similarity between the words clerk and salesperson would correspond to the entropy value of employee which is the most informative (i.e. most specific) concept shared by the two words.",
        "Illustrative extracts of WordNet with specific reference to the examples used throughout the paper are provided in table 1.",
        "The information content (or entropy) of a concept c --- which in WordNet corresponds to a set of such as fire_v_4, dismiss_v_4, terminate_v_4, sack_v_2 --- is formally defined as log p(c) (Abramson, 1963:6-13).",
        "The probability of a concept c is obtained for each choice of text corpus or corpora collection K by dividing the frequency of c in K by the total number of words W observed in K which have the same part of speech p as the word senses in c:",
        "The frequency of a concept is calculated by counting the occurrences of all words which are potential instances of (i.e. subsumed by) the concept.",
        "These include words which have the same orthography and part of speech as the synonyms defining the concept as well as the concept's superordinates.",
        "Each time a word Wp is encountered in K, the count of each concepts cp subsuming Wp (in any of its senses) is increased by one:",
        "The semantic similarity between two words Wlp W2p is expressed as the entropy value of the most informative concept co which subsumes both Wip and W2p, as shown in (3).",
        "which are related to the associating word by the same syntactic dependency, e.g.",
        "The specific senses of W1pW2p under which semantic similarity holds is determined with respect to the sub-sumption relation linking cp with Wip W2p.",
        "Suppose for example that in calculating the semantic similarity of the two verbs fire, dismiss using the WordNet lexical database we find that the most informative subsuming concept is represented by the synonym set containing the word sense remove_v_2.",
        "We will then know that the senses for fire, dismiss under which the similarity holds are fire_v 4 and dismiss_v_4 as these are the only instances of the verbs fire and dismiss subsumed by re-move_v_2 in the WordNet hierarchy.",
        "We propose to use semantic similarity to disambiguate syntactic collocates and to merge disambiguated collocates into classes of cooccurrence restrictions.",
        "Disambiguation of syntactic collocates results from intersecting pairs consisting of (i) a cluster containing all senses of a word collocate WI having appropriate syntactic usage, and (0 a cluster of semantically similar word senses related to WI by the same syntactic dependency, e.g.:",
        "The results of distinct disambiguation events are merged into pairs of semantically compatible word clusters using the notion of semantic similarity."
      ]
    },
    {
      "heading": "2 Extraction of Syntactic Word Collocates from Corpora",
      "text": [
        "First, all instances of the syntactic dependency pairs under consideration (e.g. verb-object, verb-subject, adjective-noun) are extracted from a collection of text corpora using a parser.",
        "In performing this task, only the most important words (e.g. heads of immediate constituents) are chosen.",
        "The chosen words are also lemmatized.",
        "For example, the extraction of verb-object collocates from a text fragment such as have certainly hired the best financial analysts in the area would yield the pair < hire, analyst >.",
        "The extracted pairs are sorted according to the syntactic dependency involved (e.g. verb-object).",
        "All pairs which involve the same dependency and share one word collocate are then merged.",
        "Each new pair consists of a unique associating word and a set of associated words containing all \"statistically relevant\" words (see below)",
        "(5) IN: < fire_v, gun_n > < fire v, rocket_n > < fire v, employee_n > < fire v, clerk n > < fire v, hymn_n > < fire v, rate_n >",
        "The statistical relevance of associated words is defined with reference to their conditional probability.",
        "For example, consider the equations in (6) where the numeric values express the (conditional) probability of occurrence in some corpus for each verb in (5) given the noun employee.",
        "These conditional probabilities are obtained by dividing the number of occurrences of the verb with employee by the total number of occurrences of the verb with reference to the text corpus under consideration, as indicated in (7).",
        "Inclusion in the set of statistically relevant associated words is established with reference to a threshold TI.",
        "which can be either selected manually or determined automatically as the most ubiquitous probability value for each choice of associating word.",
        "For example, the threshold TI for the selection of verbs taking the noun employee as direct object with reference to the conditional probabilities in (6) can be calculated as follows.",
        "First, all probabilities in (6) are distributed over a ten-bin template, where each bin is to receive progressively larger values starting from a fixed lowest point greater than 0, e.g.:",
        "Then one of the values from the bin containing most elements (e.g. the lowest) is chosen as the threshold, The exclusion of collocates which are not statistically relevant in the sense specified above makes it possible to avoid interference from collocations which do not provide sufficiently specific exemplifications of word usage."
      ]
    },
    {
      "heading": "3 Word Clustering and Sense Expansion",
      "text": [
        "Each pair of syntactic collocates at this stage consists of either",
        "• an associating head word (AING) and a set of dependent associated words (AED), e.g. < AING: AED: (gun_n,rocket_n,employee_n,clerk n) > • or an associating dependent word (AING) and a set of associated head words (AED), e.g. < AED: Ifire_v,dismiss v,hire_v,recruit_v), AING: employee_n>",
        "The next step consists in partitioning the set of associated words into clusters of semantically congruent word senses.",
        "This is done in three stages.",
        "1.",
        "Form all possible unique word pairs with non-identical members out of each associated word set, e.g.",
        "IN: (fire, dismiss, hire, recruit) OUT: (fire-ciismiss,fire-hire,fire-recruit, dismiss-hire,dismiss-recruit, hire-recruit) IN: (gun,rocket,employee,clerk) OUT: {gun-rocket,gun-employee,",
        "The assessment of semantic similarity and the ensuing word sense specification are carried out using Resnik's approach (see section 1).",
        "3, Fix the threshold for membership into clusters of semantically congruent word senses (either manually or by calculation of the most ubiquitous semantic similarity value) and generate such clusters.",
        "For example, assuming a threshold value of 3, we will have:",
        "Once associated words have been partitioned into semantically congruent clusters, new sets of collocations are generated as shown in (8) by",
        "• pairing each cluster of semantically congruent associated words with its associating word, and • expanding the associating word into all of its possible senses.",
        "At this stage, all word senses which are syntactically incompatible with the original input words are removed.",
        "For example, the intransitive verb senses fire_v_I and fire_v_5 (see table 1) are eliminated since the occurrence of fire in the input collocation which we are seeking to disambiguate relates to the transitive use of the verb.",
        "Note that the noun employee has only one sense in WordNet (see table 1); therefore, employee has a single expansion when used as an associating word.",
        "2.",
        "Find the semantic similarity (expressed as a numeric value) for each such pair, specifying the senses with respect to which the similarity holds (if any), e.g.",
        "IN: {fire-disnuss,fire-hire,fire-recruit, dismiss-hire,thamiss-recruit,hire-recruit} OUT: {sim(iire_v_4,dismiss_v_4) = 6.124,"
      ]
    },
    {
      "heading": "4 Disambiguating the \"Associating\" Word and Merging Disambiguated Collocations",
      "text": [
        "The disambiguation of the associating word is performed by intersecting correspondent subsets across pairs of the newly generated collocations.",
        "In the case of verb-object pairs, for example, the subsets of these new sets containing verbs are intersected and likewise the subsets containing objects are intersected.",
        "The output comprises a new set which is non-empty if the two sets have one or more common members in both the verb and object subsets.",
        "For the specific example of newly expanded collocations given in (8), there is only one pairwise intersection producing a non empty result, as shown in (9).",
        "(9) IN: < lfire_v_2/3/ 4/6/7/8),",
        "All other pairwise intersections are empty as there are no verbs and objects common to both sets of each pairwise combination.",
        "The result of distinct disambiguation events can be merged into pairs of semantically compatible word clusters using the notion of semantic similarity.",
        "For example, the verbs and nouns of all the input pairs in (10) are closely related in meaning and can therefore be merged into a single pair."
      ]
    },
    {
      "heading": "5 Storing Results",
      "text": [
        "Pairs of semantically congruent word sense clusters such as the one shown in the output of (10) are stored as cooccurrence restrictions so that future disambiguation events involving any head-dependent word sense pair in them can be reduced to simple table lookups.",
        "The storage procedure is structured in three phases.",
        "First, each cluster of word senses in each pair is assigned a unique code consisting of an id number and the syntactic dependency involved:",
        "Finally, each word sense is stored along with its associated cluster code(s): The disambiguation of a pair of syntactically related words such as the pair <fire_v, employee_n> can be carried out by • retrieving all the cluster codes for each word in the pair and create all possible pairwise combinations, e.g.",
        "IN: < fire_v.",
        ", employee_n > OUT: < 102_VO, 102_0V > < 104_VO, 102_OV >",
        "• eliminating code pairs which are not in the table of cooccurrence restrictions for cluster codes, e.g.",
        "INPUT: < 102 VO, 102_0V > < 104_VO, 102_0V > OUTPUT: < 102_VO, 102_0V >",
        "• using the resolved cluster code pairs to retrieve the appropriate senses of the input words from previously stored pairs of word senses and cluster codes such as those in the table above, e.g.",
        "By repeating the acquisition process described in sections 2-4 for collections of appropriately selected source corpora, the acquired cooccurrence restrictions can be parameterized for sublanguage specific domains.",
        "This augmentation can be made by storing each word sense and associated cluster code with a sublanguage specification and a percentage descriptor indicating the relative frequency of the word sense with reference to the cluster code in the specified sublanguage, e.g. fire_v 4 102_VO Business 65% fire_v 4 102_VO Crime 25% fire_v 1 104_VO Business 5% fire_v_l 104_VO Crime 70%"
      ]
    },
    {
      "heading": "6 Statistically Inconspicuous Collocates",
      "text": [
        "Because only statistically relevant collocations are chosen to drive the disambiguation process (see section 2), it follows that no cooccurrence restrictions will be acquired for a variety of word pairs.",
        "This, for example, might be the case with verb-object pairs such as < fire_v, hand_n > where the noun is a somewhat atypical object.",
        "This problem can be addressed by using the cooccurrence restrictions already acquired to classify statistically inconspicuous collocates, as shown below with reference to the verb object pair < fire_v, hancl_n >.",
        "• Find all verb-object cooccurrence restrictions containing the verb fire, which as shown in the previous section are < 102_VO, 102_0V > < 104_VO, 104_0V > • Retrieve all members of the direct object collocate class, e.g.",
        "Cluster the statistically inconspicuous collocate with all members of the direct object collocate class.",
        "This will provide one or more sense classifications for the statistically inconspicuous collocate.",
        "In the present case, the WordNet senses 2 and 9 (glossed as \"farm labourer\" and \"crew member\" respectively) are given when hand_n clusters with elerk_n_l /2 and employee_n_l, e.g.",
        "• Associate the disambiguated statistically inconspicuous collocate with the same code of the word senses with which it has been clustered, e.g. hand 2 102_VO hand 9 102 VO This will make it possible to choose senses 2 and 9 for hand in contexts where hand occurs as the direct object of verbs such as fire, as explained in the previous section."
      ]
    },
    {
      "heading": "7 Preliminary Results and Future Work",
      "text": [
        "A prototype of the system described was partially implemented to test the effectiveness of the disambiguation method.",
        "The prototype comprises:",
        "• a component performing semantic similarity judgements for word pairs using WordNet (this is an implementation of Resnik's approach); • a component which turns sets of word pairs rated for semantic similarity into clusters of semantically congruent word senses, and • a component which performs the disambiguation of syntactic collocates in the manner described in section 4.",
        "The current functionality provides the means to disambiguate a pair of words <WI W2> standing in a given syntactic relation Dep given a list of words related to WI by Dep, a list of words related to W2 by Dep, and a semantic similarity threshold for word clustering, as shown in (12).",
        "In order to provide an indication of how well the system performs, a few examples are presented in (12).",
        "As can be confirmed with reference to the WordNet entries in table 1, these preliminary results are encouraging as they show a reasonable resolution of ambiguities.",
        "A more thorough evaluation is currently being carried out.",
        "input collocations may suffice to provide acceptable results, e.g.",
        "Note that disambiguation can yield multiple senses, as shown with reference to the resolution of the verbs file and wear in the third and fourth examples shown in (12).",
        "Multiple disambiguation results typically occur when some of the senses given for a word in the source dictionary database are close in meaning.",
        "For example, both sense 1 and 9 of wear relate to an eventuality of \"clothing oneself'.",
        "Multiple word sense resolutions can be ranked with reference to the semantic similarity scores used in clustering word senses during disambiguation.",
        "The basic idea is that the word sense resolution contained in the word cluster which has highest semantic similarity scores provides the best disambiguation hypothesis.",
        "For example, specific word senses for the verb-object pair < wear suit > in the third example of (12) above are given by the disambiguated word tuples in (13) which arise from intersecting pairs consisting of all senses of an associating word and a semantically congruent cluster of its associated words, as described in section 4.",
        "Taking into account the scores shown in (14), the best word sense candidate for the verb wear in the context wear suit would be wear_v_1.",
        "In this case, the semantic similarity scores for the second cluster (i.e. the nouns) do not matter as there is only one such cluster.",
        "(14) sult(have_on_v I, wear v_1) = 6.291 sirn(file v_2, wear_v 9) = 3.309 Preliminary results suggest that the present treatment of disambiguation can achieve good results with small quantities of input data.",
        "For example, as few as four (15) IN: < fire_v-remployee_n,clerk_nb pre,thsmissi-employee_n, 3> OUT: < fire_v_4 employee_n_l > < wear_vIsmt_n,elothes nl, [wear_v,hfive_on_vi-suit n, 3> OUT: < wear_v_l suit n_l > This is because word clustering --- which is the decisive step in disambiguation --- is carried out using a measure of semantic similarity which is essentially induced from the hyponymic links of a semantic word net.",
        "As long as the collocations chosen as input data generate some word clusters, there is a good chance for disambiguation.",
        "The reduction of input data requirements offers a significant advantage compared with methods such as those presented in Brown et al.",
        "(1991), Gale et al.",
        "(1992), Yarowsky (1995), and Karol & Edelman (1996) where strong reliance on statistical techniques for the calculation of word and context similarity commands large source corpora.",
        "Such advantage can be particularly appreciated with reference to the acquisition of cooccurrence restrictions for those sublanguage domains where large corpora are not available.",
        "Ironically, the major advantage of the approach proposed --- namely, a reliance on structured semantic word nets as the main knowledge source for assessing semantic similarity --- is also its major drawback, Semantically structured lexical databases, especially those which are tuned to specific sublanguage domains, are currently not easily available and expensive to build manually, However, advances in the area of automatic thesaurus discovery (Grefenstette, 1994) as well as progress in the area of automatic merger of machine readable dictionaries (Sanfilippo & Poznanski, 1992; Chang & Chen, 1997) indicate that availability of the lexical resources needed may gradually improve in the future.",
        "In addition, ongoing research on rating conceptual distance from unstructured synonym sets (Sanfilippo, 1997) may soon provide an effective way of adapting any commercially available thesaurus to the task of word clustering, thus increasing considerably the range of lexical databases used as knowledge sources in the assessment of semantic similarity."
      ]
    },
    {
      "heading": "Acknowledgements",
      "text": [
        "This research was carried out within the SPARKLE project (LE-12111).",
        "I am indebted to Geert Adriaens, Simon Berry, Ted Briscoe, Ian Johnson, Victor Poznan-ski, Karen Sparck Jones, Ralf Steinberger and Yorick Wilks for valuable feedback."
      ]
    },
    {
      "heading": "References",
      "text": [
        "dismiss v I She dismissed his advances file v 2 put out of judicial consideration 3 stop associating with 4 give notice I end ones encounter with somebody by causing or permitting the person to leave register in a public office or in a court of law 2 smooth with a file 3 proceed in file 4 file a formal charge against place in a filc fire v I open fire 2 fire a gun, fire a bullet"
      ]
    },
    {
      "heading": "3 of pottery 4 give nonce 5 The gun fired 6 Call forth, of emotions, feelings, and re7 spouses",
      "text": [
        "They burned the house and his diaries provide withfuel hire 2 engage or hire for work of goods and services engage in a commercial transaction recruit register formally, as a participant or member The lab director recruited an able crew of assistants conscript, levy wear 2 be dressed in 3 He wore a red ribbon 4 have in ones aspect 5 Wear one's hair in a certain way 6 hold out, endure 7 wear off, wear out, wear thin 8 go to pieces wear out put clothing on one's body employee a worker who is hired to perform a job keeps records or accounts clerk a salesperson in a store a salesperson in a store gun 2 a weapon that discharges a missile large but transportable guns a pedal or hand-operated lever that controls the throttle rocket any weapon propelled by a rocket engine a device containing its own propellant and driven by reaction propulsion erect European annual often grown as a salad crop to be harvested when young and tender propels bright light high in the sky, or used to propel a lifesaving line or harpoon sends a firework display high into the sky suit a set of garments for outerwear all of the same fabric and color"
      ]
    }
  ]
}
