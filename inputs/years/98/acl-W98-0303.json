{
  "info": {
    "authors": [
      "Jill Burstein",
      "Karen Kukich",
      "Susanne Wolff",
      "Chi Lu",
      "Martin Chodorow"
    ],
    "book": "Workshop on Discourse Relations and Discourse Markers",
    "id": "acl-W98-0303",
    "title": "Enriching Automated Essay Scoring Using Discourse Marking",
    "url": "https://aclweb.org/anthology/W98-0303",
    "year": 1998
  },
  "references": [
    "acl-J93-3003",
    "acl-J95-1002",
    "acl-P84-1055",
    "acl-W97-0713"
  ],
  "sections": [
    {
      "heading": "Abstract",
      "text": [
        "Electronic Essay Rater (c-rater) is a prototype automated essay scoring system built at Educational Testing Service (ETS) that uses discourse marking, in addition to syntactic information and topical content vector analyses to automatically assign essay scores.",
        "This paper gives a general description of e-rater as a whole, but its emphasis is on the importance of discourse, marking and argument partitioning for annotating the argument structure of an essay.",
        "We show comparisons between two content vector analysis programs used to predict scores.",
        "EssayContent and ,-1rgContent.",
        "Essavci-onterit assigns scores to essays by using a standard cosine correlation that treats the essay like a \"bat, of words.\"",
        "in that it does not consider word order.",
        ".f,-,eContent employs a novel content vector analysis approach for score assignment based on the individual arguments in an essay.",
        "The average agreement between ArgCantent scores and human rater scores is 82%.",
        "as compared to 69% agreement between E.ssayContent and the human raters.",
        "These results suggest that discourse marking enriches .,--reiter 's scoring capability.",
        "When crater uses its whole set of predictive features, agreement with human rater scores ranges from 87% - 94% across the 15 sets of essay responses used in this study"
      ]
    },
    {
      "heading": "1. Introduction",
      "text": [
        "The development of Electronic Essay Rater (e-rater).",
        "an automated prototype essay scoring system.",
        "was motivated by practical concerns of time and costs that limit the number of essay questions on current standardized tests.",
        "Literature on automated essay scoring shows that reasonably high agreement can be achieved between a machine score and a human rater score simply by doing analyses based on the number of words in an essay (Page and Peterson (1995)).",
        "Scoring an essay based on the essay length is not a criterion that cart be used to define competent writing.",
        "In addition, from a practical standpoint.",
        "essay length is a highly coachable feature.",
        "It doesn't take examinees long to figure out that a computer will assign a high score on an essay based on a pre-specified number of words.",
        "E-rarer's modules extract syntactic and discourse structure information from essays, as well as information about vocabulary content in order to predict the score.",
        "The 57 features included in e-rater are based on writing characteristics specified at each of the six score points in the scoring guide used by human raters for manual scoring (also available at http:/!www.gmat.orei).",
        "For example.",
        "the scoring guide indicates that an essay that stays on the topic of the test question, has a strong, coherent and well-organized argument structure.",
        "and displays a variety of word use and syntactic structure will receive a score at the higher end of the six-point scale (5 or 6).",
        "Lower scores are assigned to essays as these characteristics diminish.",
        "Included in e-rater's feature set are features derived from discourse structure, syntactic structure, and topical analysis as they relate to the human scoring guide.",
        "For each essay question.",
        "crater is run on a set of training data (human-scored essay responses) to extract features.",
        "A stepwise linear regression analysis is performed on the features extracted from the training set to determine which ones have significant weights (the predictive features).",
        "Final score prediction for cross-validation sets is performed using these predictive features identified in the training sets.",
        "Accuracy is determined by measuring agreement between human rater assigned scores and",
        "machine predicted scores, which are considered to \"agree\" if there is no greater than a single point difference on the six-point scale.",
        "This is the same criterion used to measure agreement between two human raters.",
        "Among the strongest predictive features across the essay questions used in this study are the scores generated from ArgContent (a content vector analysis applied to discourse chunked text), and discourse-related surface cue word and non-lexical features.",
        "On average, ArgContent alone has 82% agreement with the human rater score as compared to EssayContent's 69%.",
        "EssctyContent is a content vector analysis program that treats an essay like a \"bat: of words.\"",
        "This suggests two things.",
        "First, the discourse markers detected by the argument annotation and partitioning program.",
        ":IPA, are helpful for identification of relevant units of discourse in essay, responses.",
        "Second.",
        "the application of content vector analysis to those text units appears to increase scoring performance.",
        "Overall, it appears that discourse marking provides feature information that is useful in e-rater.",
        "s essay score predictions.",
        "A long-term goal of automated essay scoring is to be able to generate diagnostic or instructional information, along with a numeric score to a test-taker or instructor.",
        "Information about the discourse structure of essays brings us closer to being able to generate informative feedback to test-takers about the essay's cohesion.",
        "We report on the overall evaluation results from e-rater's scoring performance on 13 sets of essay data from the Analytical Writing Assessments of the Graduate Management Admissions Test (GMAT) (see http://www.gmat.orgi) and 2 sets of essay data from the Test of Written English (TWE) (see hrtp://www.toefl.orgitstprpmahtml for sample TWE questions).",
        "The paper devotes special attention to e-rater's discourse marking and analysis components."
      ]
    },
    {
      "heading": "2. Hybrid Feature Methodology",
      "text": [
        "E-rater uses a hybrid feature approach in that it incorporates several variables that are derived statistically, or extracted through NLP techniques.",
        "The following sections describe the features used in this study."
      ]
    },
    {
      "heading": "2.1 Syntactic Features",
      "text": [
        "The scoring guides indicate that one feature used to evaluate an essay is syntactic variety.",
        "Syntactic structures in essay's are identified using NLP techniques.",
        "All sentences are parsed with the Microsoft Natural Language Processing tool (MSNLP) (see MSNLP (1997)).",
        "Examination of the parse trees yields information about syntactic variety with reaard to what kinds of clauses or verb types were used by a test-taker.",
        "A program was implemented to identify the number of complement clauses, subordinate clauses, infinitive clauses, relative clauses and occurrences of the subjunctive modal auxiliary verbs, would, could.",
        "and may.. for each sentence in an essay.",
        "Ratios of syntactic structure types per essay and per sentence were calculated as possible measures of s).ntactie variety."
      ]
    },
    {
      "heading": "2.2 Discourse Structure Analysis",
      "text": [
        "GMAT essay questions are of two types: Analysis of an Issue (issue) and Analysis of an Argument (argument).",
        "The issue essay asks the writer to respond to a general question and to provide \"reasons and-or examples\" to support his or her position on an issue introduced by the test question.",
        "The argument essay focuses the writer on the argument in a given piece of text.",
        "using the term argument in the sense of a rational presentation of points with the purpose of persuading the reader.",
        "The scoring guides used for manual scoring indicate that an essay will receive a score based on the examinee's demonstration of a well-developed essay.",
        "For the argument essay.",
        "for instance, the scoring guide states that a \"6\" essay \"develops ideas cogently, organizes them logically, and connects them with clear transitions.\"",
        "The correlate to this for the issue essay would appear to be that a 6 essay \"...develops a position on the issue with insightful reasonsa.\"",
        "and that the essay \"is clearly well-organized.\"",
        "Nolan (1997) points out that terms in holistic scoring guides.",
        "such as \"cogent,\" \"logical.\"",
        "\"insightful.\"",
        "and \"well-organized\" have \"fuzzy- meaning.",
        "since they are based on imprecise observation.",
        "Nolan uses methods of \"fuzzy logic\" to automatically assign these kinds of \"fuzzy\" classifications to essays.",
        "In this study, we try to identify organization of an essay through automated analysis and identification of the essay's argument structure through discourse marking.",
        "conjunctive relations from Quirk, et al. (1985) in arg_dev=SAME_TOP1C label denotes the pronoun -it-which terms, such as \"In summary and \"In as indicating the writer has not changed topics.",
        "The conclusion.",
        "which we consider to be surface cue labels arg_in ittCLA I M_THAT and terms.",
        "are classified as conjuncts used for art_r_dev=CLAIMJHAT indicate that a complement summarizing_ Cue words such as \"perhaps- and clause was used to flag a new argument.",
        "or argument possibly are considered to be Belief words used by development.",
        "Arg_aux7SPEGULATE flags subjunctive the writer to express a belief with regard to argument modals that are believed to indicate a writer's development in essays.",
        "Words like \"this- and speculation.",
        "Preliminary analysis of these rules 'these- may often be used to flag that the writer is indicates that some rule refinements might be useful; developing_ on the same topic (Sidner (1986)).",
        "We however, more research needs to be done on this.' also observed that, in certain discourse contexts, non Based on the arg_init flags in the annotated essays, lexical, syntactic structure cues, such as infinitive or .4P.4 outputs a version of the essay partitioned \"by complement clauses.",
        "may characterize the beginning argument.",
        "The araument-partitioned versions of of a new argument.",
        "essays are input to .,-1,-,I.:Con1ent.",
        "the discourse-driven, The automated argument partitioning and annotation topical analysis program described below.",
        "program (4P,4) was implemented to output a discourse-marked annotated version of each essay in which the discourse marking is used to indicate new arguments (arg_init), or development of an argument (arg_dev).",
        "An example of APA annotations is shown in Figure 1.",
        "essay by comparing the words it contains to the words found in manually graded training examples for each of the six score categories.",
        "Two measures of content similarity are computed, one based on word frequency and the other on word weight.",
        "as in information retrieval applications (Salton.",
        "1988).",
        "For the former application (EssayContem).",
        "content similarity is computed over the essay as a whole.",
        "while in the latter application (ArgContent) content similarities are computed for each argument in an essay.",
        "For the frequency based measure (the EssayComent program).",
        "the content of each score category is converted to a single vector whose elements represent the total frequency of each word in the training essays for that category.",
        "In effect.",
        "this merges the essays for each score, (A stop list of some function words is removed prior to vector construction.)",
        "The system computes cosine correlations between the vector for a given test essay and the six vectors representing the trained categories: the category.",
        "that is most similar to the test essay is assiened as the evaluation of its content.",
        "An advantage of using the cosine correlation is that it is not sensitive to essay length, which may.",
        "vary considerably.",
        "The other content similarity measure.",
        "ArgComem.",
        "is imputed separately for each argument in the test essay and is based on the kind of term weighting used in information retrieval.",
        "For this purpose.",
        "the word frequency vectors for the six score categories.",
        "described above, are converted to vectors of word weights.",
        "The weight for word i in score category s is w, , = (freq, , I max_freq,)* log(n_essays.„„;n_essays,) where freq., is the frequency of word i in category s. max_freq, is the frequency of the most frequent word in s (after a stop list of words has been removed).",
        "n_essays„, is the total number of training essays across all six categories, and n_essays, is the number of training essays containing word I.",
        "The first part of the weight formula represents the prominence of word i in the score category.",
        "and the second part is the log of the words inverse document frequency.",
        "(IDF).",
        "For each argument a in the test essay.",
        "a vector of word weights is also constructed.",
        "The weight for word i in argument a is where freq., is the frequency of word i in argument a, and max_freck is the frequency of the most frequent word in a (once again, after a stop list of words has been removed).",
        "Each argument (as it has been partitioned by APA) is evaluated by computing cosine correlations between its weighted vector and those of the six score categories, and the most similar category is assigned to the argument.",
        "As a result of this analysis.",
        "e-rater has a set of scores (one per argument) for each test essay.",
        "We were curious to find out if an essay containing several good arguments (each with scores of 5 or 6) and several poor arguments (each with scores of I or 2) produced a different overall judgment by the human raters than an essay consisting of uniformly mediocre arguments (3's or 4's).",
        "or if perhaps humans were most influenced by the best or poorest argument in the essay.",
        "In a preliminary study.",
        "we looked at how well the minimum, maximum, mode, median, and mean of the set of argument scores agreed with the judgments of human raters for the essay as a whole.",
        "The mode and the mean showed good agreement with human raters.",
        "but the greatest agreement was obtained from an adjusted mean of the argument scores which compensated for an effect of' the number of arguments in the essay.",
        "For example.",
        "essays which contained only one or two arguments tended to receive slightly lower scores from the human raters than the mean of the argument scores, and essays which contained many arguments tended to receive slightly higher scores than the mean of the argument scores.",
        "To compensate for this, an adjusted mean is used as e-rater's ArgContenr,"
      ]
    },
    {
      "heading": "3. Training and Testing",
      "text": [
        "In all.",
        "erasers syntactic.",
        "discourse, and topical analyses yielded a total of 57 features for each essay.",
        "The majority of the features in the overall feature set are discourse-related (see Table 3 for some examples).",
        "To predict the score assigned by human raters, a stepwise linear regression analysis was used to compute the optimal weights for these predictors based on manually scored training essays.",
        "The training sets for each test question consisted of a total (freqimax_freqa)* log(n_essays,, in_essays,)",
        "of 270 essays.",
        "5 essays for score 02, 15 essays for score 1 (a rating infrequently used by the human raters) and 50 essays each for scores 2 through 6.",
        "After training, e-rater analyzed new test essays.",
        "and the regression weights were used to combine the measures into a predicted score for each one.",
        "E-rater predictions were compared to the two human rater scores to measure exact and adjacent agreement (see Table I).",
        "Figure 2 shows the predictive feature set identified by the regression analysis for one of the example test questions, ARG I, in Tables I and 2."
      ]
    },
    {
      "heading": "3.1 Results",
      "text": [
        "Table I shows the overall results for 8 GMAT argument questions, 5 GMAT issue questions and 2 TWE questions.",
        "The level of agreement between crater and the human raters ranged from 87% to 94% across the 15 tests.",
        "Agreement appears to be comparable to that found between the human raters,",
        "Results for the essay questions in Tables I and 2 represent a wide variety of topics.",
        "(Sample questions that show topical variety in GMAT essays can be viewed at httpiliwww.gmatore.",
        "Topical variety in TWE questions can be reviewed at http://www.toefl.orgitstprpmt.html.)",
        "The data also represented a wide range of English writing competency.",
        "The majority of test-takers from the",
        "two TWE data sets were nonnative English speakers.",
        "Despite these differences in topic and writing skill, e-rcuer.",
        "as well as EssayContent.",
        "and ArgContent performed consistently across items.",
        "In fact, over the 15 essay questions.",
        "the discourse features output by APA and scores output by ArgCordent (based on discourse-chunked text) account for the majority of the most frequently occurring predictive features.",
        "These are shown in Table 3."
      ]
    },
    {
      "heading": "4. Discussion and Conclusions",
      "text": [
        "The study indicates that discourse, syntactic.",
        "and topical information can be reliably used for machine prediction of essay scores.",
        "The results suggest that e-ruler's discourse marking is informative to the scoring process.",
        "ArgContem, the statistical, topical discourse analyzer, appears to be the most predictive feature.",
        "Other highly ranked features include surface cue words and non-lexical discourse cues.",
        "One line of future research will examine the effects of various term weighting schemes on the performance of both ArgContent and EssayContent.",
        "Another study will compare the argument boundaries assigned by AP4 and the positions which human readers judge to be beginnings and ends of arguments.",
        "We believe that the discourse related features used by crater might be the most useful building blocks for automated generation of diagnostic and instructional summaries about essays.",
        "For example, sentences indicated as \"the beginning of an argument\" could be used to flag main points of an essay (Marcu (1997)).",
        "ArgContetit's ability to generate \"scores\" for each argument could provide information about the relevance of individual arguments in an essay, which in turn could be used to generate helpful diagnostic or instructional information."
      ]
    },
    {
      "heading": "5. References",
      "text": []
    }
  ]
}
