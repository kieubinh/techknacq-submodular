{
  "info": {
    "authors": [
      "Michael L. McHale"
    ],
    "book": "Workshop on Usage of WordNet in Natural Language Processing Systems",
    "id": "acl-W98-0716",
    "title": "A Comparison of WordNet and Roget's Taxonomy for Measuring Semantic Similarity",
    "url": "https://aclweb.org/anthology/W98-0716",
    "year": 1998
  },
  "references": [
    "acl-C92-2070",
    "acl-C96-1005"
  ],
  "sections": [
    {
      "heading": "Abstract",
      "text": [
        "This paper presents the results of using Roget's International Thesaurus as the taxonomy in a semantic similarity measurement task.",
        "Four similarity metrics were taken from the literature and applied to Roget's.",
        "The experimental evaluation suggests that the traditional edge counting approach does surprisingly well (a correlation of r=0.88 with a benchmark set of human similarity judgements, with an upper bound of r=0.90 for human subjects performing the same task.)"
      ]
    },
    {
      "heading": "Introduction",
      "text": [
        "The study of semantic relatedness has been a part of artificial intelligence and psychology for many years.",
        "Much of the early semantic relatedness work in natural language processing centered around the use of Roget's thesaurus (Yaworsky 92).",
        "As WordNet (Miller 90) became available, most of the new work used it (Agirre & Rigau 96, Resnik 95, Jiang & Conrath 97).",
        "This is understandable, as WordNet is freely available, fairly large and was designed for computing.",
        "Roget's remains, though, an attractive lexical resource for those with access to it.",
        "Its wide, shallow hierarchy is densely populated with nearly 200,000 words and phrases.",
        "The relationships among the words are also much richer than WordNet's IS-A or HAS-PART links.",
        "The price paid for this richness is a somewhat unwieldy tool with ambiguous links.",
        "This paper presents an evaluation of Roget's for the task of measuring semantic similarity.",
        "This is done by using four metrics of semantic similarity found in the literature while using Roget's International Thesaurus, third edition (Roget 1962) as the taxonomy.",
        "Thus the results can be compared to those in the literature (that used WordNet).",
        "The end result is the ability to compare the relative usefulness of Roget's and WordNet for this type of task."
      ]
    },
    {
      "heading": "1 Semantic Similarity",
      "text": [
        "Each metric of semantic similarity makes assumptions about the taxonomy in which it works.",
        "Generally, these assumptions go unstated but since they are important for the understanding of the results we obtain, we will cover them for each metric.",
        "All the metrics assume a taxonomy with some semantic order."
      ]
    },
    {
      "heading": "1.1 Distance Based Similarity",
      "text": [
        "A common method of measuring semantic similarity is to consider the taxonomy as a tree, or lattice, in semantic space.",
        "The distance between concepts within that space is then taken as a measurement of the semantic similarity.",
        "If all the edges (branches of the tree) are of equal length, then the number of intervening edges is a measure of the distance.",
        "The measurement usually used (Rada et al.",
        "89) is the shortest path between concepts.",
        "This, of course, relies on an ideal taxonomy with edges of equal length.",
        "In taxonomies based on natural languages, the edges are not the same length.",
        "In Roget's, for example, the distance (counting edges) between Intellect and Grammar is the same as the distance between Grammar and Phrase Structure.",
        "This does not seem intuitive.",
        "In general, the edges in this type of taxonomy tend to grow shorter with depth.",
        "A number of different metrics related to distance have used edges that have been modified to correct for the problem of non-uniformity.",
        "The modifications include the density of the subhierarchies, the depth in the hierarchy where the word is found, the type of links, and the information content of the nodes subsuming the word.",
        "The use of density is based on the observation that words in a more densely part of the hierarchy are more closely related than words in sparser areas (Agiffe and Rigau 96).",
        "For density to be a valid metric, the hierarchy must be fairly complete or at least the distribution of words in the hierarchy has to closely reflect the distribution of words in the language.",
        "Neither of these conditions ever hold completely.",
        "Furthermore, the observation about density may be an overgeneralization.",
        "In Roget's, for instance, category 277 Ship/Boat has many more words (much denser) than category 372 Blueness.",
        "That does not mean that kayak is more closely related to tugboat than sky blue is to turquoise.",
        "In fact, it does not even mean that kayak is closer to Ship/Boat than turquoise is to Blueness.",
        "Depth in the hierarchy is another attribute often used.",
        "It may be more useful in the deep hierarchy of WordNet than it is in Roget's where the hierarchy is fairly flat and uniform.",
        "All the words in Roget's are at either level 6 or 7 in the hierarchy.",
        "The type of link in WordNet is explicit, in Roget's it is never clear but it consists of more than IS-A and HAS-PART.",
        "One such link is HAS-ATTRIBUTE.",
        "Some of the researchers that have used the above metrics include Sussna (Sussna 93) who weighted the edges by using the density of the subhierarchy, the depth in the hierarchy and the type of link.",
        "Richardson and Smeaton (Richardson and Smeaton 95) used density, hierarchy depth and the information content of the concepts.",
        "Jiang and Conrath (Jiang and Conrath 95) used the number of edges and information content.",
        "They all reported improvement in results compared to straight edge counting.",
        "McHale (95) decomposed Roget's taxonomy and used five different metrics to show the usefulness of the various attributes of the taxonomy.",
        "Two of those metrics deal with distance but only one is of interest to us for this task; the number of intervening words.",
        "The number of intervening words ignores the hierarchy completely, treating it as a flat file.",
        "For the measurement to be an accurate metric, two conditions must be met.",
        "First, the ordering of the words must be correct.",
        "Second, either all the words of the language must be represented (virtually impossible) or they must be evenly distributed throughout the hierarchy'.",
        "Since it is unlikely that either of these conditions hold for any taxonomy, the most that can be expected of this measurement is that it might provide a reasonable approximation of the distance (similar to density).",
        "It is included here, not because the approximation is reasonable, but because it provides information that helps explain the other results."
      ]
    },
    {
      "heading": "1.2 Information Based Similarity",
      "text": [
        "Given the above problems with distance related measures, Resnik (Resnik 95) decided to use just the information content of the concepts and compared the results to edge counting and human replication of the same task.",
        "Resnik defines the similarity of two concepts as the maximum of the Information Content of the concepts that subsume them in the taxonomy.",
        "The Information Content of a concept relies on the probability of encountering an instance of the concept.",
        "To compute this probability, Resnik used the relative frequency of occurrence of each word in the Brown Corpus2.",
        "The probabilities thus found should fairly well approximate the true values for other generalized texts.",
        "The concept probabilities were then computed from the occurrences as simply the relative frequency of the concept.",
        "The information content of each concept is then given by IC(c) = log I 15(c), where P(o) is the probability.",
        "Thus, more common words have lower information content.",
        "To replicate the metric using Roget's, the frequency of occurrence of the words found in the Brown Corpus was divided by the total number of occurrences of the word in Roget's3.",
        "From the information content of each concept, the information content for each node in the Roget hierarchy was computed.",
        "These are simply the minimum of the information content of all the words beneath the node in the taxonomy.",
        "Therefore, the information content of a parent node is never greater than any of its children.",
        "The metric of relatedness for two words according to Resnik is the information content of the lowest common ancestor for any of the word senses.",
        "What this implies is that, for the purpose of measuring relatedness, each synset in WordNet or each semicolon group in Roget's would have an information content equal to its most common member.",
        "For example, the words druid (Roget's Index number 1036.15) and pope (1036.8) would have an information content equal to that of clergy (1036).",
        "Clergy's information content is based on the two most common words below it in the hierarchy – brother and sister.",
        "Thus druid would have an information content less than that of brother, a situation that I do not find intuitive since druid appears much less frequently than brother.",
        "Computationally, the easiest way to compute the information content of a word is to completely compute the values for the entire hierarchy a priori.",
        "This involves approximately 300,000 (200,000 words plus 100,000 nodes in 3 The frequencies were computed for Roget's as the total frequency for each word divided by the number of senses in Roget.",
        "This gives us an approximation of the information content for each concept.",
        "The frequency data were taken from the MRC Psycholinguistic database available from the Oxford Text Archive.",
        "the hierarchy) computations for the entire Roget hierarchy.",
        "This is sizeable overhead compared to edge counting which requires no a priori computations.",
        "Of course, once the computations are done they do not need to be recomputed until a new word is added to the hierarchy.",
        "Since the values for information content bubble up from the words, each addition of a word would require that all the hierarchy above it be recomputed.",
        "Jiang and Conrath (Jiang and Conrath 97) also used information content to measure semantic relatedness but they combined it with edge counting using a formula that also took into consideration local density, node depth and link type.",
        "They optimized the formula by using two parameters, a and 0, that controlled the degree of how much the node depth and density factors contributed to the edge weighting computation.",
        "If a--0 and f3=1, then their formula for the distance between two concepts c and c2 simplifies to",
        "Where LS(c1,c2) denotes the lowest superordinate of cl and c2."
      ]
    },
    {
      "heading": "2 Evaluation",
      "text": [
        "The above metrics are used to rate the similarity of a set of word pairs.",
        "The results are evaluated by comparing them to a rating produced by human subjects.",
        "Miller and Charles (1991) gave a group of students thirty word pairs and asked the students to rate them for \"similarity in meaning\" on a scale from 0 (no similarity) to 4 (perfect synonymy).",
        "Resnik (1995) replicated the task with a different set of students and found a correlation between the two ratings of r=.9011 for the 28 word pairs tested.",
        "Resnik, Jiang and Conrath (1997) and I all consider this value to be a reasonable upper-bound to what one should expect from a computational method performing the same task.",
        "Resnik also performed an evaluation of two computational methods both using WordNet 1.5.",
        "He evaluated simple edge counting (r=.6645) and information content (r=.7911).",
        "Jiang and Conrath improved on that some (r=.8282) using a version of their combined formula given above",
        "that had been empirically optimized for shallow, uniform hierarchy of Roget's than it WordNet.",
        "does in WordNet.",
        "Why this is the case requires Table 1 gives the results from Resnik (the further investigation.",
        "Factors to consider include first four columns) along with the ratings of the uniformity of edges, the maximum number semantic similarity for each word pair using of edges in each hierarchy and the general information content, the number of edges, the organization of the two hierarchies.",
        "I expect that number of intervening words and Jiang and major factors are the fairly uniform nature of Conrath's simplified formula 13=1) with Roget's hierarchy and the broader set of respect to Roget's.",
        "Both the number of edges semantic relations allowed in Roget's.",
        "Currently, and the number of intervening words are given it seems that Roget's captures the popular in their raw form.",
        "The correlation value for the similarity of isolated word pairs better than edges was computed using (12 – Edges) where WordNet does.",
        "12 is the maximum number of edges.",
        "The 5 Related Work",
        "WordNet was 0.7911 while the one conducted Some of the results given in Table 1 seem to here for Roget's was 0.7900.",
        "This is remarkable support the use of density.",
        "The word pairs in that the IC values for Roget's used the forest-graveyard and chord-smile both have an average number of occurrences for all the senses edge distance of 8.",
        "The number of intervening of the words whereas for WordNet the number words for each pair are considerably different of occurrences of the actual sense of the word (296 and 3253 respectively).",
        "For these particular was used.",
        "This may be explainable by realizing word pairs the latter numbers more closely that in either case the numbers are just match the ranking given by humans.",
        "If one approximations of what the real values would be considers density important then perhaps we can for any particular text.",
        "use a different measure of density by computing Jiang & Conrath's metric did just a little the number of intervening words per edge.",
        "This worse using Roget's than the results they gave metric was tested with the 28 word pairs and the using WordNet but that may very well be results were a slight improvement (r=.6472) because I was unable to optimize the values of a over the number of intervening words but are and 13 for Roget's.",
        "still well below that attained by simple edge The harder result to explain seems to be counting."
      ]
    },
    {
      "heading": "Conclusion",
      "text": [
        "This paper presented the results of using Roget's International Thesaurus as the taxonomy in a semantic similarity measurement task.",
        "Four similarity metrics were taken from the literature and applied to Roget's.",
        "The experimental evaluation suggests that the traditional edge counting approach does surprisingly well (a correlation of r=0.8862 with a benchmark set of human similarity judgements, with an upper bound of r--0.9015 for human subjects performing the same task.)",
        "The results should provide incentive to those wishing to understand the effect of various attributes on metrics for semantic relatedness across hierarchies.",
        "Further investigation of why this dramatic improvement in edge counting occurs in the shallow, uniform hierarchy of Roget's needs to be conducted.",
        "The results should prove beneficial to those doing research with Roget's, WorodIslet and other semantic based hierarchies."
      ]
    },
    {
      "heading": "Acknowledgements",
      "text": [
        "This research was sponsored in part by AFOSR under RL-23000601."
      ]
    }
  ]
}
