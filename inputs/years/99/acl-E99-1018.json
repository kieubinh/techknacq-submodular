{
  "info": {
    "authors": [
      "Giorgos S. Orphanos",
      "Dimitris N. Christodoulakis"
    ],
    "book": "Conference of the European Association for Computational Linguistics",
    "id": "acl-E99-1018",
    "title": "POS Disambiguation and Unknown Word Guessing With Decision Trees",
    "url": "https://aclweb.org/anthology/E99-1018",
    "year": 1999
  },
  "references": [
    "acl-A88-1019",
    "acl-A92-1018",
    "acl-C94-1027",
    "acl-C96-2130",
    "acl-E95-1022",
    "acl-J93-2006",
    "acl-J95-2001",
    "acl-J95-4004",
    "acl-P89-1015",
    "acl-W96-0102"
  ],
  "sections": [
    {
      "heading": "Abstract",
      "text": [
        "This paper presents a decision-tree approach to the problems of part-of-speech disambiguation and unknown word guessing as they appear in Modem Greek, a highly inflectional language.",
        "The learning procedure is tag-set independent and reflects the linguistic reasoning on the specific problems.",
        "The decision trees induced are combined with a high-coverage lexicon to form a tagger that achieves 93,5% overall disambiguation accuracy."
      ]
    },
    {
      "heading": "1 Introduction",
      "text": [
        "Part-of-speech (POS) taggers are software devices that aim to assign unambiguous morphosyntactic tags to words of electronic texts.",
        "Although the hardest part of the tagging process is performed by a computational lexicon, a POS tagger cannot solely consist of a lexicon due to: (i) morphosyntactic ambiguity (e.g., 'love' as verb or noun) and (ii) the existence of unknown words (e.g., proper nouns, place names, compounds, etc.).",
        "When the lexicon can assure high coverage, unknown word guessing can be viewed as a decision taken upon the POS of open-class words (i.e., Noun, Verb, Adjective, Adverb or Participle).",
        "Towards the disambiguation of POS tags, two main approaches have been followed.",
        "On one hand, according to the linguistic approach, experts encode handcrafted rules or constraints based on abstractions derived from language paradigms (usually with the aid of corpora) (Green and Rubin, 1971; Voutilainen 1995).",
        "On the other hand, according to the data-driven approach, a frequency-based language model is acquired from corpora and has the forms of n-grams (Church, 1988; Cutting et al., 1992), rules (Hindle, 1989; Brill, 1995), decision trees (Cardie, 1994; Daelemans et al., 1996) or neural networks (Schmid, 1994).",
        "In order to increase their robustness, most POS taggers include a guesser, which tries to extract the POS of words not present in the lexicon.",
        "As a common strategy, POS guessers examine the endings of unknown words (Cutting et al.",
        "1992) along with their capitalization, or consider the distribution of unknown words over specific parts-of-speech (Weischedel et al., 1993).",
        "More sophisticated guessers further examine the prefixes of unknown words (Mikheev, 1996) and the categories of contextual tokens (Brill, 1995; Daelemans et al., 1996).",
        "This paper presents a POS tagger for Modern Greek (M. Greek), a highly inflectional language, and focuses on a data-driven approach for the induction of decision trees used as disambiguation/guessing devices.",
        "Based on a high-coverage' lexicon, we prepared a tagged corpus capable of showing off the behavior of all POS ambiguity schemes present in M. Greek (e.g., Pronoun-Clitic-Article, Pronoun-Clitic, Adjective-Adverb, Verb-Noun, etc.",
        "), as well as the characteristics of unknown words.",
        "Consequently, we used the corpus for the induction of decision trees, which, along with",
        "the lexicon, are integrated into a robust POS tagger for M. Greek texts.",
        "The disambiguating methodology followed is highly influenced by the Memory-Based Tagger (MBT) presented in (Daelemans et al., 1996).",
        "Our main contribution is the successful application of the decision-tree methodology to M. Greek with three improvements/customizations: (i) injection of linguistic bias to the learning procedure, (ii) formation of tag-set independent training patterns, and (iii) handling of set-valued features."
      ]
    },
    {
      "heading": "2 Tagger Architecture",
      "text": [
        "Figure 1 illustrates the functional components of the tagger and the order of processing:"
      ]
    },
    {
      "heading": "Raw Text Tagged Text",
      "text": [
        "Raw text passes through the Tokenizer, where it is converted to a stream of tokens.",
        "Non-word tokens (e.g., punctuation marks, numbers, dates, etc.)",
        "are resolved by the Tokenizer and receive a tag corresponding to their category.",
        "Word tokens are looked-up in the Lexicon and those found receive one or more tags.",
        "Words with more than one tags and those not found in the Lexicon pass through the Disambiguator/Guesser, where the contextually appropriate tag is decided/guessed.",
        "The Disambiguator/Guesser is a 'forest' of decision trees, one tree for each ambiguity scheme present in M. Greek and one tree for unknown word guessing.",
        "When a word with two or more tags appears, its ambiguity scheme is identified.",
        "Then, the corresponding decision tree is selected, which is traversed according to the values of morphosyntactic features extracted from contextual tags.",
        "This traversal returns the contextually appropriate POS.",
        "The ambiguity is resolved by eliminating the tag(s) with different POS than the one returned by the decision tree.",
        "The POS of an unknown word is guessed by traversing the decision tree for unknown words, which examines contextual features along with the word ending and capitalization and returns an open-class POS."
      ]
    },
    {
      "heading": "3 Training Sets",
      "text": [
        "For the study and resolution of lexical ambiguity in M. Greek, we set up a corpus of 137.765 tokens (7.624 sentences), collecting sentences from student writings, literature, newspapers, and technical, financial and sports magazines.",
        "We made sure to adequately cover all POS ambiguity schemes present in M. Greek, without showing preference to any scheme, so as to have an objective view to the problem.",
        "Subsequently, we tokenized the corpus and inserted it into a database and let the lexicon assign a morphosyntactic tag to each word-token.",
        "We did not use any specific tag-set; instead, we let the lexicon assign to each known word all morphosyntactic attributes available.",
        "Table 1 shows a sample sentence after this initial tagging (symbolic names appearing in the tags are explained in Appendix A).",
        "To words with POS ambiguity (e.g., tokens #2 and #3 in Table 1) we manually assigned their contextually appropriate POS.",
        "To unknown words (e.g., token #5 in Table 1), which by default received a disjunct of open-class POS labels, we manually assigned their real POS and declared explicitly their inflectional ending.",
        "At a next phase, for all words relative to a specific ambiguity scheme or for all unknown words, we collected from the tagged corpus their automatically and manually assigned tags along with the automatically assigned tags of their neighboring tokens.",
        "This way, we created a training set for each ambiguity scheme and a training set for unknown words.",
        "Table 2 shows a 10-example fragment from the training set for the ambiguity scheme Verb-Noun.",
        "For reasons of space, Table 2 shows the tags of only the previous (column Tag;_,) and next (column Tagi4.1) tokens in the neighborhood of an ambiguous word, whereas more contextual tags actually comprise a training example.",
        "A training example also includes the manually assigned tag (column Manual Tag;) along with the automatically assigned tag2 (column Tag;) of the ambiguous word.",
        "One can notice that some contextual tags are missing (e.g., Tagi_i of Example 7; the ambiguous word is the first in the sentence), or some contextual tags may exhibit POS ambiguity (e.g., Tagi+i of Example 1), an incident implying that the learner must learn from incomplete/ambiguous examples, since this is the case in real texts.",
        "If we consider that a tag encodes 1 to 5 morphosyntactic features, each feature taking one or a disjunction of 2 to 11 values, then the total number of different tags counts up to several hundreds'.",
        "This fact prohibits the feeding of the training algorithms with patterns that have the form: (Tagi_2, Tagi_b Tag;, Manual_Tagi), which is the case for similar systems that learn POS disambiguation (e.g., Daelemans et al., 1996).",
        "On the other hand, it would be inefficient (yielding to information loss) to generate a simplified tag-set in order to reduce its size.",
        "The `what the training patterns should look like' bottleneck was surpassed by assuming a set of functions that extract from a tag the value(s) of specific features, e.g.:",
        "With the help of these functions, the training examples shown in Table 2 are interpreted to patterns that look like:",
        "Proceedings of EACL '99 that is, a sequence of feature-values extracted from the previous/current/next tags along with the manually assigned POS label.",
        "Due to this transformation, two issues automatically arise: (a) A feature-extracting function may return more than one feature value (as in the Gender(...) example); consequently, the training algorithm should be capable of handling set-valued features.",
        "(b) A feature-extracting function may return no value, e.g.",
        "thus we added an extra value –the value None – to each feature.",
        "To summarize, the training material we prepared consists of: (a) a set of training examples for each ambiguity scheme and a set of training examples for unknown words', and (b) a set of features accompanying each example-set, denoting which features (extracted from the tags of training examples) will participate in the training procedure.",
        "This configuration offers the following advantages:",
        "1.",
        "A training set is examined only for the features that are relative to the corresponding ambiguity scheme, thus addressing its idiosyncratic needs.",
        "2.",
        "What features are included to each feature-set depends on the linguistic reasoning on the specific ambiguity scheme, introducing this way linguistic bias to the learner.",
        "3.",
        "The learning is tag-set independent, since it is based on specific features and not on the entire tags.",
        "4.",
        "The learning of a particular ambiguity",
        "scheme can be fine-tuned by including new features or excluding existing features from its feature-set, without affecting the learning of the other ambiguity schemes."
      ]
    },
    {
      "heading": "4 Decision Trees 4.1 Tree Induction",
      "text": [
        "In the previous section, we stated the use of linguistic reasoning for the selection of feature",
        "sets suitable to the idiosyncratic properties of the corresponding ambiguity schemes.",
        "Formally speaking, let FS be the feature-set attached to a training set TS.",
        "The algorithm used to transform TS into a decision tree belongs to the TDIDT (Top Down Induction of Decision Trees) family (Quinlan, 1986).",
        "Based on the divide and conquer principle, it selects the best Fbest feature from FS, partitions TS according to the values of Fbest and repeats the procedure for each partition excluding Fbest from FS, continuing recursively until all (or the majority of) examples in a partition belong to the same class C or no more features are left in FS.",
        "During each step, in order to find the feature that makes the best prediction of class labels and use it to partition the training set, we select the feature with the highest gain ratio, an information-based quantity introduced by Quinlan (1986).",
        "The gain ratio metric is computed as follows: Assume a training set TS with patterns belonging to one of the classes C1, C2, ... Ck.",
        "The average information needed to identify the class of a pattern in TS is: = (TS) of E x freq(Cj, TS) log2( freq(Cj, TS) in .i ITS ITS I Now consider that TS is partitioned into TS1, TS2, TS„, according to the values of a feature F from FS.",
        "The average information needed to identify the class of a pattern in the partitioned TS is:",
        "Split info is a necessary normalizing factor, since gain favors features with many values, and represents the potential information generated by dividing TS into n subsets:",
        "measures the information relevant to classification that is gained by partitioning TS in accordance with the feature F. Gain ratio is a normalized version of information gain: gain ratio(F) = gain(F)",
        "Proceedings of EACL '99 Taking into consideration the formula that computes the gain ratio, we notice that the best feature is the one that presents the minimum entropy in predicting the class labels of the training set, provided the information of the feature is not split over its values.",
        "The recursive algorithm for the decision tree induction is shown in Figure 2.",
        "Its parameters are: a node N, a training set TS and a feature set FS.",
        "Each node constructed, in a top-down left-to-right fashion, contains a default class label C (which characterizes the path constructed so far) and if it is a non-terminal node it also contains a feature F from FS according to which further branching takes place.",
        "Every value v; of the feature F tested at a non-terminal node is accompanied by a pattern subset TS; (i.e., the subset of patterns containing the value v;).",
        "If two or more values of F are found in a training pattern (set-valued feature), the training pattern is directed to all corresponding branches.",
        "The algorithm is initialized with a root node, the entire training set and the entire feature set.",
        "The root node contains a dummy6 feature and a blank class label."
      ]
    },
    {
      "heading": "4.2 Tree Traversal",
      "text": [
        "ClassLabel TraverseTree( Node N , TestingPattem P ) Begin If N is a non-terminal node Then For each value vi of the feature F tested by N Do If I/1 is the value of F in P Then"
      ]
    },
    {
      "heading": "4.3 Subtree Ordering",
      "text": [
        "The tree-traversal algorithm of Figure 3 can be directly implemented by representing the decision tree as nested if-statements (see Appendix B), where each block of code following an if-statement corresponds to a subtree.",
        "When an if-statement succeeds, the control is transferred to the inner block and, since there is no backtracking, no other feature-values of the same level are tested.",
        "To classify a pattern with a set-valued feature, only one value",
        "Proceedings of EACL '99 from the set steers the traversal; the value that is tested first.",
        "A fair policy suggests to test first the most important (probable) value, or, equivalently, to test first the value that leads to the subtree that gathered more training patterns than sibling subtrees.",
        "This policy can be incarnated in the tree-traversal algorithm if we previously sort the list of feature-values tested by each non-terminal node, according to the algorithm of Figure 4, which is initialized with the root of the tree.",
        "This ordering has a nice side-effect: it increases the classification speed, as the most probable paths are ranked first in the decision tree."
      ]
    },
    {
      "heading": "4.4 Tree Compaction",
      "text": [
        "A tree induced by the algorithm of Figure 2 may contain many redundant paths from root to leaves; paths where, from a node and forward, the same decision is made.",
        "The tree-traversal definitely speeds up by eliminating the tails of the paths that do not alter the decisions taken thus far.",
        "This compaction does not affect the performance of the decision tree.",
        "Figure 5 illustrates the tree-compaction algorithm, which is initialized with the root of the tree."
      ]
    },
    {
      "heading": "5 Evaluation",
      "text": [
        "To evaluate our approach, we first partitioned the datasets described in Section 3 into training and testing sets according to the 10-fold cross-validation method'.",
        "Then, (a) we found the most frequent POS in each training set and (b) we induced a decision tree from each training set.",
        "Consequently, we resolved the ambiguity of the testing sets with two methods: (a) we assigned the most frequent POS acquired from the corresponding training sets and (b) we used the induced decision trees.",
        "Table 3 concentrates the results of our experiments.",
        "In detail: Column (1) shows in what percentage the ambiguity schemes and the unknown words occur in the corpus.",
        "The total problematic word-tokens in the corpus are 23,38%.",
        "Column (2) shows in what percentage each ambiguity scheme contributes to the total POS ambiguity.",
        "Column (3) shows the error rates of method (a).",
        "Column (4) shows the error rates of method (b).",
        "To compute the total POS disambiguation error rates of the two methods (24,1% and 5,48% respectively) we used the contribution percentages shown in column (2)."
      ]
    },
    {
      "heading": "6 Discussion and Future Goals",
      "text": [
        "We have shown a uniform approach to the dual problem of POS disambiguation and unknown word guessing as it appears in M. Greek, reinforcing the argument that \"machine-learning researchers should become more interested in NLP as an application area\" (Daelemans et al., 1997).",
        "As a general remark, we argue that the linguistic approach has good performance when the knowledge or the behavior of a language can be defined explicitly (by means of lexicons, syntactic grammars, etc.",
        "), whereas empirical (corpus-based statistical) learning should apply when exceptions, complex interaction or ambiguity arise.",
        "In addition, there is always the opportunity to bias empirical learning with linguistically motivated parameters, so as to 7 In this method, a dataset is partitioned 10 times into 90% training material and 10% testing material.",
        "Average accuracy provides a reliable estimate of the generalization accuracy.",
        "meet the needs of the specific language problem.",
        "Based on these statements, we combined a high-coverage lexicon and a set of empirically induced decision trees into a POS tagger achieving –5,5% error rate for POS disambiguation and –16% error rate for unknown word guessing.",
        "The decision-tree approach outperforms both the naive approach of assigning the most frequent POS, as well as the –20% error rate obtained by the n-gram tagger for M. Greek presented in (Dermatas and Kokkinakis, 1995).",
        "Comparing our tree-induction algorithm and IGTREE, the algorithm used in MBT (Daelemans et al., 1996), their main difference is that IGTREE produces oblivious decision trees by supplying an a priori ordered list of best features instead of recomputing the best feature during each branching, which is our case.",
        "After applying IGTREE to the datasets described in Section 3, we measured similar performance (-7% error rate for disambiguation and –17% for guessing).",
        "Intuitively, the global search for best features performed by IGTREE has similar results to the local searches over the fragmented datasets performed by our algorithm.",
        "Our goals hereafter aim to cover the following:",
        "• Improve the POS tagging results by: a) finding the optimal feature set for each ambiguity scheme and b) increasing the lexicon coverage.",
        "• Analyze why IGTREE is still so robust when, obviously, it is built on less information.",
        "• Apply the same approach to resolve Gender, Case, Number, etc.",
        "ambiguity and to guess such attributes for unknown words."
      ]
    }
  ]
}
