{
  "info": {
    "authors": [
      "Kemal Oflazer"
    ],
    "book": "Annual Meeting of the Association for Computational Linguistics",
    "id": "acl-P99-1033",
    "title": "Dependency Parsing With an Extended Finite State Approach",
    "url": "https://aclweb.org/anthology/P99-1033",
    "year": 1999
  },
  "references": [
    "acl-A97-1011",
    "acl-A97-1012",
    "acl-C90-2040",
    "acl-C92-1027",
    "acl-C96-1058",
    "acl-C96-2123",
    "acl-E93-1066",
    "acl-J94-3001",
    "acl-W98-0501",
    "acl-W98-1301"
  ],
  "sections": [
    {
      "heading": "Abstract",
      "text": [
        "This paper presents a dependency parsing scheme using an extended finite state approach.",
        "The parser augments input representation with \"channels\" so that links representing syntactic dependency relations among words can be accommodated, and iterates on the input a number of times to arrive at a fixed point.",
        "Intermediate configurations violating various constraints of projective dependency representations such as no crossing links, no independent items except sentential head, etc, are filtered via finite state filters.",
        "We have applied the parser to dependency parsing of Turkish."
      ]
    },
    {
      "heading": "1 Introduction",
      "text": [
        "Recent advances in the development of sophisticated tools for building finite state systems (e.g., XRCE Finite State Tools (Karttunen et al., 1996), AT&T Tools (Mohri et al., 1998)) have fostered the development of quite complex finite state systems for natural language processing.",
        "In the last several years, there have been a number of studies on developing finite state parsing systems, (Koskenniemi, 1990; Koskenniemi et al., 1992; Grefenstette, 1996; Ait-Mokhtar and Chanod, 1997).",
        "There have also been a number of approaches to natural language parsing using extended finite state approaches in which a finite state engine is applied multiple times to the input, or various derivatives thereof, until some stopping condition is reached.",
        "Roche (1997) presents an approach for parsing in which the input is iteratively bracketed using a finite state transducer.",
        "Ab-ney(1996) presents a finite state parsing approach in which a tagged sentence is parsed by transducers which progressively transform the input to sequences of symbols representing phrasal constituents.",
        "This paper presents an approach to dependency parsing using an extended finite state model resembling the approaches of Roche and Abney.",
        "The parser produces outputs that encode a labeled dependency tree representation of the syntactic relations between the words in the sentence.",
        "We assume that the reader is familiar with the basic concepts of finite state transducers (FST hereafter), finite state devices that map between two regular languages U and L (Kaplan and Kay, 1994)."
      ]
    },
    {
      "heading": "2 Dependency Syntax",
      "text": [
        "Dependency approaches to syntactic representation use the notion of syntactic relation to associate surface lexical items.",
        "The book by Mel6uk (1988) presents a comprehensive exposition of dependency syntax.",
        "Computational approaches to dependency syntax have recently become quite popular (e.g., a workshop dedicated to computational approaches to dependency grammars has been held at COL-ING/ACL'98 Conference).",
        "Järvinen and Tapananinen have demonstrated an efficient wide-coverage dependency parser for English (Tapanainen and Jirvinen, 1997; Jirvinen and Tapanainen, 1998).",
        "The work of Sleator and Temperley(1991) on link grammar, an essentially lexicalized variant of dependency grammar, has also proved to be interesting in a number of aspects.",
        "Dependency-based statistical language modeling and analysis have also become quite popular in statistical natural language processing (Lafferty et al., 1992; Eisner, 1996; Chelba and et al., 1997).",
        "Robinson(1970) gives four axioms for well-formed dependency structures, which have been assumed in almost all computational approaches.",
        "In a dependency structure of a sentence (i) one and only one word is independent, i.e., not linked to some other word, (ii) all others depend directly on some word, (iii) no word depends on more than one other, and, (iv) if a word A depends directly on B, and some word C intervenes between them (in linear order), then C depends directly on A or on B, or on some other intervening word.",
        "This last condition of pro-jectivity (or various extensions of it; see e.g., Lau and Huang (1994)) is usually assumed by most computational approaches to dependency grammars as a constraint for filtering configurations, and has also been used as a simplifying condition in statistical approaches for inducing dependencies from corpora (e.g., Yiiret(1998).)"
      ]
    },
    {
      "heading": "3 Turkish",
      "text": [
        "Turkish is an agglutinative language where a sequence of inflectional and derivational morphemes get affixed to a root (Oflazer, 1993).",
        "Derivations are very productive, and the syntactic relations that a word is involved in as a dependent or head element, are determined by the inflectional properties of the",
        "a) Input sequence of IGs are augmented with symbols to represent Channels.",
        "one or more (intermediate) derived forms.",
        "In this work, we assume that a Turkish word is represented as a sequence of inflectional groups (IGs hereafter), separated by \"Ms denoting derivation boundaries, in the following general form:"
      ]
    },
    {
      "heading": "root+Inf11-DB+Inf12-DB+• • •-DB+Infln",
      "text": [
        "where Infli denote relevant inflectional features including the part-of-speech for the root, or any of the derived forms.",
        "For instance, the derived determiner saglamlagtirdigimizdakil would be represented as:2"
      ]
    },
    {
      "heading": "+Pnon+Loc",
      "text": [
        "A sentence would then be represented as a sequence of the IGs making up the words.",
        "An interesting observation that we can make about Turkish is that, when a word is considered as a sequence of IGs, syntactic relation links only emanate from the last IG of a (dependent) word, and land on one of the IG's of the (head) word on the right (with minor exceptions), as exemplified in"
      ]
    },
    {
      "heading": "4 Finite State Dependency Parsing",
      "text": [
        "The approach relies on augmenting the input with \"channels\" that (logically) reside above the IG sequence and \"laying\" links representing dependency relations in these channels, as depicted Figure 3 a).",
        "The parser operates in a number of iterations: At each iteration of the parser, an new empty channel",
        "is \"stacked\" on top of the input, and any possible links are established using these channels, until no new links can be added.",
        "An abstract view of this is presented in parts b) through e) of Figure 3."
      ]
    },
    {
      "heading": "4.1 Representing Channels and Syntactic Relations",
      "text": [
        "The sequence (or the chart) of IGs is produced by a a morphological analyzer FST, with each IG being augmented by two pairs of delimiter symbols, as <(I0) >.",
        "Word final IGs, IGs that links will emanate from, are further augmented with a special marker 0.",
        "Channels are represented by pairs of matching symbols that surround the <... ( and the ) ...> pairs.",
        "Symbols for new channels (upper channels in Figure 3) are stacked so that the symbols for the topmost channels are those closest to the ( ).3 The channel symbol 0 indicates that the channel segment is not used while 1 indicates that the channel is used by a link that starts at some IG on the left and ends at some IG on the right, that is, the link is just crossing over the IG.",
        "If a link starts from an IG (ends on an IG), then a start (stop) symbol denoting the syntactic relation is used on the right (left) side of the IG.",
        "The syntactic relations (along with symbols used) that we currently encode in our parser are the following:4 S (Subject), 0 (Object), M (Modifier, adviadj), P (Possessor), C (Classifier), D (Determiner), T (Dative Adjunct), L ( Locative Adjunct), A: (Ablative Adjunct) and I (Instrumental Adjunct).",
        "For instance, with three channels, the two IGs of bakedeki in Figure 2, would be represented as <MDO (bahge+Noun+A3sg+Pnon+Loc )000> <000(+DetC)00d>.",
        "The M and the D to the left of 'At any time, the number of channel symbols on both sides of an IG are the same.",
        "We use the lower case symbol to mark the start of the link and the upper case symbol to encode the end of the link.",
        "the first IG indicate the incoming modifier and determiner links, and the d on the right of the second IG indicates the outgoing determiner link."
      ]
    },
    {
      "heading": "4.2 Components of a Parser Stage",
      "text": [
        "The basic strategy of a parser stage is to recognize by a rule (encoded as a regular expression) a dependent IG and a head IG, and link them by modifying the \"topmost\" channel between those two.",
        "To achieve this:",
        "1. we put temporary brackets to the left of the dependent IG and to the right of the head IG, making sure that (i) the last channel in that segment is free, and (ii) the dependent is not already linked (at one of the lower channels), 2. we mark the channels of the start, intermediate and ending IGs with the appropriate symbols encoding the relation thus established by the brackets, 3. we remove the temporary brackets.",
        "A typical linking rule looks like the following:5 [LL IG1 [ML IG2 MR]* [RI.",
        "IG3 RR] (->) This rule says: (optionally) bracket (with IS and S}), any occurrence of morphological pattern IG1 (dependent), skipping over any number of occurrences of pattern IG2, finally ending with a pattern IG3 (governor).",
        "The symbols L(eft)L(eft), LB., ML, MB., RI.",
        "and FtR are regular expressions that encode constraints on the bounding channel symbols.",
        "For instance, LEI.",
        "is the pattern \"0\" 11)11 [\"0\" I 11* \">\" which checks that (i) this is a word-final IG (has a \"0\"), (ii) the right side \"topmost\" channel is empty (channel symbol nearest to \")\"is \"0\"), and (iii) the IG is not linked to any other in any of the lower channels (the only symbols on the right side are Os and 1s.)",
        "For instance the example rule",
        "is used to bracket a segment starting with a plural nominative nominal, as subject of a finite verb on the right with either +A3sg or +A3p1 number-person agreement (allowed in Turkish.)",
        "The regular expression NominativeNominalA3p1 matches any nominal IG with nominative case and A3p1 agreement, while the regular expression [FiniteVerbA3sg FiniteVerbA3p1] matches any finite verb IG with either A3sg or A3p1 agreement.",
        "The regular expression AnyIG matches any IG.",
        "All the rules are grouped together into a parallel bracketing rule defined as follows:",
        "which will produce all possible bracketing of the input IG sequence.6"
      ]
    },
    {
      "heading": "4.3 Filtering Crossing Link Configurations",
      "text": [
        "The bracketings produced by Bracket contain configurations that may have crossing links.",
        "This happens when the left side channel symbols of the IG immediately right of a open bracket contains the symbol 1 for one of the lower channels, indicating a link entering the region, or when the right side channel symbols of the IG immediately to the left of a close bracket contains the symbol 1 for one of the lower channels, indicating a link exiting the segment, i.e., either or both of the following patterns appear in the bracketed segment:",
        "Configurations generated by bracketing are filtered by FSTs implementing suitable regular expressions that reject inputs having crossing links.",
        "A second configuration that may appear is the following: A rule may attempt to put a link in the topmost channel even though the corresponding segment is not utilized in a previous channel, e.g., the corresponding segment one of the previous channels may be all Os.",
        "This constraint filters such cases to",
        "prevent redundant configurations from proliferating for later iterations of the parser.7 For these two configuration constraints we define FilterConf igs as8",
        "We can now define one phase (of one iteration) of the parser as:",
        "The transducer MarkChannels modifies the channel symbols in the bracketed segments to either the syntactic relation start or end symbol, or a 1, depending on the 1G.",
        "Finally, the transducer RemoveTempBrackets, removes the brackets.",
        "The formulation up to now does not allow us to bracket an IG on two consecutive non-overlapping links in the same channel.",
        "We would need a bracketing configuration like < > 1m < > sl < > ... but this would not be possible within Bracket, as patterns check that no other brackets are within their segment of interest.",
        "Simply composing the Phase transducer with itself without introducing a new channel solves this problem, giving us a one-stage parser, i.e., Parse = Phase .o.",
        "Phase;"
      ]
    },
    {
      "heading": "4.4 Enforcing Syntactic Constraints",
      "text": [
        "The rules linking the IGs are overgenerating in that they may generate configurations that may violate some general or language specific constraints.",
        "For instance, more than one subject or one object may attach to a verb, or more that one determiner or possessor may attach to a nominal, an object may attach to a passive verb (conjunctions are handled in the manner described in Jirvinen and Tapanainen(1998)), or a nominative pronoun may be linked as a direct object (which is not possible in Turkish), etc.",
        "Constraints preventing these may can be encoded in the bracketing patterns, but doing so results in complex and unreadable rules.",
        "Instead, each can be implemented as a finite state filter which operate on the outputs of Parse by checking the symbols denoting the relations.",
        "For instance we can define the following regular expression for filtering out configurations where two determiners are attached to the same IG:19 7 This constraint is a bit trickier since one has to check that the same number of channels on both sides are empty; we limit ourselves to the last 3 channels in the implementation.",
        "8 .",
        "0 .",
        "denotes the transducer composition operator.",
        "We also use, for exposition purposes, =, instead of the XRCE define command.",
        "The FST for this regular expression makes sure that all configurations that are produced have at most one D symbol among the left channel symbols.\" Many other syntactic constraints (e.g., only one object to a verb) can be formulated similar to above.",
        "All such constraints Consl, Cons2 ...ConsN, can then be composed to give one FST that enforces all of these:",
        "The iterative applications of the parser can now be given (in pseudo-code) as: # Map sentence to a transducer representing a chart of IGs",
        "This procedure iterates until the most recently added channel of every configuration generated is unused (i.e., the (lower regular) language recognized by M .o.",
        "LastChannelNotEmpty is empty.)",
        "The step after the loop, M = M .o.",
        "OnlyOneUnlinked, enforces the constraint that",
        "in a correct dependency parse all except one of the word final IGs have to link as a dependent to some head.",
        "This transduction filters all those configurations (and usually there are many of them due to the optionality in the bracketing step.)",
        "Then, Parses defined as the (lower) language of the resulting FST has all the strings that encode the IGs and the links."
      ]
    },
    {
      "heading": "4.6 Robust Parsing",
      "text": [
        "It is possible that either because of grammar coverage, or ungrammatical input, a parse with only one unlinked word final IG may not be found.",
        "In such cases Parses above would be empty.",
        "One may however opt to accept parses with k > 1 unlinked word final IGs when there are no parses with < k unlinked word final IGs (for some small k.) This can be achieved by using the lenient composition operator (K art tunen, 1998).",
        "Lenient composition, notated as .0 .",
        ", is used with a generator-filter combination.",
        "When a generator transducer G is leniently composed with a filter transducer, F, the resulting transducer, G .0.",
        "F, has the following behavior when an input is applied: If any of the outputs of G in response to the input string satisfies the filter F, then G .0.",
        "F produces just these as output.",
        "Otherwise, G .0.",
        "F outputs what G outputs.",
        "Let Unlinked_i denote a regular expression which accepts parse configurations with less than or equal i unlinked word final IGs.",
        "For instance, for i = 2, this would be defined as follows:",
        "which rejects configurations having more than 2 word final IGs whose right channel symbols contain only Os and is, i.e., they do not link to some other IG as a dependent.",
        "Replacing line M = M .o.",
        "OnlyOneUnlinked, with, for instance, M = M .0.",
        "Unlinked_i .0.",
        "Unlinked_2 .0.",
        "Unlinked_3; will have the parser produce outputs with up to 3 unlinked word final IGs, when there are no outputs with a smaller number of unlinked word final IGs.",
        "Thus it is possible to recover some of the partial dependency structures when a full dependency structure is not available for some reason.",
        "The caveat would be however that since Unlinked_l is a very strong constraint, any relaxation would increase the number of outputs substantially."
      ]
    },
    {
      "heading": "5 Experiments with dependency",
      "text": []
    },
    {
      "heading": "parsing of Turkish",
      "text": [
        "Our work to date has mainly consisted of developing and implementing the representation and finite state techniques involved here, along with a non-trivial grammar component.",
        "We have tested the resulting system and grammar on a corpus of 50 Turkish sentences, 20 of which were also used for developing and testing the grammar.",
        "These sentences had 4 to 24 words with an average 10 about 12 words.",
        "The grammar has two major components.",
        "The morphological analyzer is a full coverage analyzer built using XRCE tools, slightly modified to generate outputs as a sequence of IGs for a sequence of words.",
        "When an input sentence (again represented as a transducer denoting a sequence of words) is composed with the morphological analyzer (see pseudo-code above), a transducer for the chart representing all IGs for all morphological ambiguities (remaining after morphological disambiguation) is generated.",
        "The dependency relations are described by a set of about 30 patterns much like the ones exemplified above.",
        "The rules are almost all non-lexical establishing links of the types listed earlier.",
        "Conjunctions are handled by linking the left conjunct to the conjunction, and linking the conjunction to the right conjunct (possibly at a different channel).",
        "There are an additional set of about 25 finite state constraints that impose various syntactic and configurational constraints.",
        "The resulting Parser transducer has 2707 states 27,713 transitions while the SyntacticConstraints transducer has 28,894 states and 302,354 transitions.",
        "The combined transducer for morphological analysis and (very limited) disambiguation has 87,475 states and 218,082 arcs.",
        "Table 1 presents our results for parsing this set of 50 sentences.",
        "The number of iterations also count the last iteration where no new links are added.",
        "Inspired by Lin's notion of structural complexity (Lin, 1996), measured by the total length of the links in a dependency parse, we ordered the parses of a sentence using this measure.",
        "In 32 out of 50 sentences (64%), the correct parse was either the top ranked parse or among the top ranked parses with the same measure.",
        "In 13 out of 50 parses (26%) the correct parse was not among the top ranked parses, but was ranked lower.",
        "Since smaller structural complexity requires, for example, verbal adjuncts, etc.",
        "to attach to the nearest verb wherever possible, topicalization of such items which brings them to the beginning of the sentence, will generate a long(er) link to the verb (at the end) increasing complexity.",
        "In 5 out of 50 sentences (5%), the correct parse was not available among the parses generated, mainly due to grammar coverage.",
        "The parses generated in these cases used other (morphological) ambiguities of certain lexical items to arrive at some parse within the confines of the grammar.",
        "The finite state transducers compile in about 2 minutes on Apple Macintosh 250 Mhz Power-book.",
        "Parsing is about a second per iteration including lookup in the morphological analyzer.",
        "With completely (and manually) morphologically disambiguated input, parsing is instantaneous.",
        "Figure 4 presents the input and the output of the parser for a sample Turkish sentence.",
        "Figure 5 shows the output",
        "English: World Bank Turkey Director said that as a result of the economic program followed by the government, important steps were taken.",
        "of the parser processed with a Perl script to provide a more human-consumable presentation:"
      ]
    },
    {
      "heading": "6 Discussion and Conclusions",
      "text": [
        "We have presented the architecture and implementation of novel extended finite state dependency parser, with results from Turkish.",
        "We have formulated, but not yet implemented at this stage, two extensions.",
        "Crossing dependency links are very rare in Turkish and almost always occur in Turkish when an adjunct of a verb cuts in a certain position of a (discontinuous) noun phrase.",
        "We can solve this by allowing such adjuncts to use a special channel \"below\" the IG sequence so that limited crossing link configurations can be allowed.",
        "Links where the dependent is to the right of its head, which can happen with some of the word order variations (with backgrounding of some dependents of the main verb) can similarly be handled with a right-to-left version of Parser which is applied during each iteration, but these cases are very rare.",
        "In addition to the reductionistic disambiguator that we have used just prior to parsing, we have implemented a number of heuristics to limit the number of potentially spurious configurations that result because of optionality in bracketing, mainly by enforcing obligatory bracketing for immediately sequential dependency configurations (e.g., the complement of a postposition is immediately before it.)",
        "Such heuristics force such dependencies to appear in the first channel and hence prune many potentially useless configurations popping up in later stages.",
        "The robust parsing technique has been very instrumental during the process mainly in the debugging of the grammar, but we have not made any substantial experiments with it yet."
      ]
    },
    {
      "heading": "7 Acknowledgments",
      "text": [
        "This work was partially supported by a NATO Science for Stability Program Project Grant, TU-LANGUAGE made to Bilkent University.",
        "A portion of this work was done while the author was visiting Computing Research Laboratory at New Mexico State University.",
        "The author thanks Lauri Karttunen of Xerox Research Centre Europe, Grenoble for making available XRCE Finite State Tools."
      ]
    }
  ]
}
