{
  "info": {
    "authors": [
      "Don Blaheta",
      "Eugene Charniak"
    ],
    "book": "Annual Meeting of the Association for Computational Linguistics",
    "id": "acl-P99-1066",
    "title": "Automatic Compensation for Parser Figure-Of-Merit Flaws",
    "url": "https://aclweb.org/anthology/P99-1066",
    "year": 1999
  },
  "references": [
    "acl-H90-1053",
    "acl-H91-1042",
    "acl-H91-1044",
    "acl-H91-1045",
    "acl-H94-1051",
    "acl-J98-2004",
    "acl-W98-1115"
  ],
  "sections": [
    {
      "heading": "Abstract",
      "text": [
        "Best-first chart parsing utilises a figure of merit (FOM) to efficiently guide a parse by first attending to those edges judged better.",
        "In the past it has usually been static; this paper will show that with some extra information, a parser can compensate for FOM flaws which otherwise slow it down.",
        "Our results are faster than the prior best by a factor of 2.5; and the speedup is won with no significant decrease in parser accuracy."
      ]
    },
    {
      "heading": "1 Introduction",
      "text": [
        "Sentence parsing is a task which is traditionally rather computationally intensive.",
        "The best known practical methods are still roughly cubic in the length of the sentence – less than ideal when dealing with nontrivial sentences of 30 or 40 words in length, as frequently found in the Penn Wall Street Journal treebank corpus.",
        "Fortunately, there is now a body of literature on methods to reduce parse time so that the exhaustive limit is never reached in prac-tice.'",
        "For much of the work, the chosen vehicle is chart parsing.",
        "In this technique, the parser begins at the word or tag level and uses the rules of a context-free grammar to build larger and larger constituents.",
        "Completed constituents are stored in the cells of a chart according to their location and",
        "length.",
        "Incomplete constituents (\"edges\") are stored in an agenda.",
        "The exhaustion of the agenda definitively marks the completion of the parsing algorithm, but the parse needn't take that long; already in the early work on chart parsing, (Kay, 1970) suggests that by ordering the agenda one can find a parse without resorting to an exhaustive search.",
        "The introduction of statistical parsing brought with an obvious tactic for ranking the agenda: (Bobrow, 1990) and (Chi-trao and Grishman, 1990) first used probabilistic context free grammars (PCFGs) to generate probabilities for use in a figure of merit (FOM).",
        "Later work introduced other FOMs formed from PCFG data (Kochman and Kupin, 1991); (Magerman and Marcus, 1991); and (Miller and Fox, 1994).",
        "More recently, we have seen parse times lowered by several orders of magnitude.",
        "The (Caraballo and Charniak, 1998) article considers a number of different figures of merit for ordering the agenda, and ultimately recommends one that reduces the number of edges required for a full parse into the thousands.",
        "(Goldwater et al., 1998) (henceforth [Go1d98j) introduces an edge-based technique, (instead of constituent-based), which drops the average edge count into the hundreds.",
        "However, if we establish \"perfection\" as the minimum number of edges needed to generate the correct parse-47.5 edges on average in our corpus – we can hope for still more improvement.",
        "This paper looks at two new figures of merit, both of which take the [0o1d98] figure (of \"independent\" merit) as a starting point in calculating a new figure",
        "of merit for each edge, taking into account some additional information.",
        "Our work further lowers the average edge count, bringing it from the hundreds into the dozens."
      ]
    },
    {
      "heading": "2 Figure of independent merit",
      "text": [
        "(Caraballo and Charniak, 1998) and [Go1d981 use a figure which indicates the merit of a given constituent or edge, relative only to itself and its children but independent of the progress of the parse – we will call this the edge's independent merit (IM).",
        "The philosophical backing for this figure is that we would like to rank an edge based on the value",
        "where M, k represents an edge of type i (NP, 2 S, etc.",
        "), which encompasses words j through k – 1 of the sentence, and tom represents all n part-of-speech tags, from 0 to n – 1.",
        "(As in the previous research, we simplify by looking at a tag stream, ignoring lexical information.)",
        "Given a few basic independence assumptions (Caraballo and Charniak, 1998), this value can be calculated as",
        "with fi and a representing the well-known \"inside\" and \"outside\" probability functions:",
        "Unfortunately, the outside probability is not calculable until after a parse is completed.",
        "Thus, the IM is an approximation; if we cannot calculate the full outside probability (the probability of this constituent occurring with all the other tags in the sentence), we can at least calculate the probability of this constituent occurring with the previous and subsequent tag.",
        "This approximation, as given in (Caraballo and Charniak, 1998), is",
        "Of the five values required, P(Arj,k P(tk 14-1), and P(tkIN.1,k) can be observed directly from the training data; the inside probability is estimated using the most probable parse for NIA, and the tag sequence probability is estimated using a bitag approximation.",
        "Two different probability distributions are used in this estimate, and the PCFG probabilities in the numerator tend to be a bit lower than the bitag probabilities in the denominator; this is more of a factor in larger constituents, so the figure tends to favour the smaller ones.",
        "To adjust the distributions to counteract this effect, we will use a normalisation constant n as in [Gold98].",
        "Effectively, the inside probability 3 is multiplied by n1-3, preventing the discrepancy and hence the preference for shorter edges.",
        "In this paper we will use n 1.3 throughout; this is the factor by which the two distributions differ, and was also empirically shown to be the best tradeoff between number of popped edges and accuracy (in [Gold981)."
      ]
    },
    {
      "heading": "3 Finding FOM flaws",
      "text": [
        "Clearly, any improvement to be had would need to come through eliminating the incorrect edges before they are popped from the agenda – that is, improving the figure of merit.",
        "We observed that the FOMs used tended to cause the algorithm to spend too much time in one area of a sentence, generating multiple parses for the same substring, before it would generate even one parse for another area.",
        "The reason for that is that the figures of independent merit are frequently good as relative measures for ranking different parses of the same section of the sentence, but not so good as absolute measures for ranking parses of different substrings.",
        "For instance, if the word \"there\" as an NP in \"there's a hole in the bucket\" had a low probability, it would tend to hold up the parsing of a sentence; since the bi-tag probability of \"there\" occurring at the beginning of a sentence is very high, the denominator of the IM would overbalance the numerator.",
        "(Note that this is a contrived",
        "example – the actual problem cases are more obscure.)",
        "Of course, a different figure of independent merit might have different characteristics, but with many of them there will be cases where the figure is flawed, causing a single, vital edge to remain on the agenda while the parser 'thrashes' around in other parts of the sentence with higher IM values.",
        "We could characterise this observation as follows: Postulate 1 The longer an edge stays in the agenda without any competitors, the more likely it is to be correct (even if it has a low figure of independent merit).",
        "A better figure, then, would take into account whether a given piece of text had already been parsed or not.",
        "We took two approaches to finding such a figure."
      ]
    },
    {
      "heading": "4 Compensating for flaws",
      "text": []
    },
    {
      "heading": "4.1 Experiment 1: Table lookup",
      "text": [
        "In one approach to the problem, we tried to start our program with no extra information and train it statistically to counter the problem mentioned in the previous section.",
        "There are four values mentioned in Postulate 1: correctness, time (amount of work done), number of competitors, and figure of independent merit.",
        "We defined them as follows: Correctness.",
        "The obvious definition is that an edge 1\\rj,k is correct if a constituent appears in the parse given in the treebank.",
        "There is an unobvious but unfortunate consequence of choosing this definition, however; in many cases (especially with larger constituents), the \"correct\" rule appears just once in the entire corpus, and is thus considered too unlikely to be chosen by the parser as correct.",
        "If the \"correct\" parse were never achieved, we wouldn't have any statistic at all as to the likelihood of the first, second, or third competitor being better than the others.",
        "If we define \"correct\" for the purpose of statistics-gathering as \"in the MAP parse\", the problem is diminished.",
        "Both definitions were tried for gathering statistics, though of course only the first was used for measuring accuracy of output parses.",
        "Work.",
        "Here, the most logical measure for amount of work done is the number of edges popped off the agenda.",
        "We use it both because it is conveniently processor-independent and because it offers us a tangible measure of perfection (47.5 edges – the average number of edges in the correct parse of a sentence).",
        "Competitorship.",
        "At the most basic level, the competitors of a given edge Arlk would be all those edges such that m < j and n > k. Initially we only considered an edge a 'competitor' if it met this definition and were already in the chart; later we tried considering an edge to be a competitor if it had a higher independent merit, no matter whether it be in the agenda or the chart.",
        "We also tried a hybrid of the two.",
        "Merit.",
        "The independent merit of an edge is defined in section 2.",
        "Unlike earlier work, which used what we call \"Independent Merit\" as the FOM for parsing, we use this figure as just one of many sources of information about a given edge.",
        "Given our postulate, the ideal figure of merit would be",
        "We can save information about this probability for each edge in every parse; but to be useful in a statistical model, the IM must first be discretised, and all three prior statistics need to be grouped, to avoid sparse data problems.",
        "We bucketed all three logarithmically, with bases 4, 2, and 10, respectively.",
        "This gives us the following approximation:",
        "To somewhat counteract the effect of dis-cretising the IM figure, each time we needed",
        "to calculate a figure of merit, we looked up the table entry on either side of the IM and interpolated.",
        "Thus the actual value used as a figure of merit was that given in equation (8).",
        "Each trial consisted of a training run and a testing run.",
        "The training runs consisted of using a grammar induced on treebank sections 2-21 to run the edge-based best-first algorithm (with the IM alone as figure of merit) on section 24, collecting the statistics along the way.",
        "It seems relatively obvious that each edge should be counted when it is created.",
        "But our postulate involves edges which have stayed on the agenda for a long time without accumulating competitors; thus we wanted to update our counts when an edge happened to get more competitors, and as time passed.",
        "Whenever the number of edges popped crossed into a new logarithmic bucket (i.e. whenever it passed a power of four), we recounted every edge in the agenda in that new bucket.",
        "In addition, when the number of competitors of a given edge passed a bucket boundary (power of two), that edge would be recounted.",
        "In this manner, we had a count of exactly how many edges – correct or not – had a given IM and a given number of competitors at a given point in the parse.",
        "Already at this stage we found strong evidence for our postulate.",
        "We were paying particular attention to those edges with a low IM and zero competitors, because those were the edges that were causing problems when the parser ignored them.",
        "When, considering this subset of edges, we looked at a graph of the percentage of edges in the agenda which were correct, we saw an increase of orders of magnitude as work increased – see Figure 1.",
        "For the testing runs, then, we used as figure of merit the value in expression 8.",
        "Aside from that change, we used the same edge-based best-first parsing algorithm as before.",
        "The test runs were all made on treebank section 22, with all sentences longer than 40 words thrown out; thus our results can be directly compared to those in the previous work.",
        "We made several trials, using different definitions of 'correct' and 'competitor', as described above.",
        "Some performed much better than others, as seen in Table 1, which gives our results, both in terms of accuracy and speed, as compared to the best previous result, given in [Go1d98].",
        "The trial descriptions refer back to the multiple definitions given for 'correct' and 'competitor' at the beginning of this section.",
        "While our best speed improvement (48.6% of the previous minimum) was achieved with the first run, it is associated with a significant loss in accuracy.",
        "Our best results overall, listed in the last row of the table, let us cut the edge count by almost half while reducing labelled precision/recall by only 0.24%."
      ]
    },
    {
      "heading": "4.2 Experiment 2: Demeriting",
      "text": [
        "We hoped, however, that we might be able to find a way to simplify the algorithm such that it would be easier to implement and/or",
        "faster to run, without sacrificing accuracy.",
        "To that end, we looked over the data, viewing it as (among other things) a series of \"planes\" seen by setting the amount of work constant (see Figure 2).",
        "Viewed like this, the original algorithm behaves like a scan line, parallel to the competitor axis, scanning for the one edge with the highest figure of (independent) merit.",
        "However, one look at figure 2 dramatically confirms our postulate – that an edge with zero competitors can have an IM orders of magnitude lower than an edge with many competitors, and still be more likely to be correct.",
        "Effectively, then, under the table lookup algorithm, the scan 2Previous work has shown that the parser performs better if it runs slightly past the first parse; so for every run referenced in this paper, the parser was allowed to run to first parse plus a tenth.",
        "All reported final counts for popped edges are thus 1.1 times the count at first parse.",
        "line is not parallel to the competitor axis, but rather angled so that the low-IM low-competitor items pass the scan before the high-IM high-competitor items.",
        "This can be simulated by multiplying each edge's independent merit by a demeriting factor 5 per competitor (thus a total of 69.",
        "Its exact value would determine the steepness of the scan line.",
        "Each trial consisted of one run, an edge-based best-first parse of treebank section 22 (with sentences longer than 40 words thrown out, as before), using the new figure of merit:",
        "This idea works extremely well.",
        "It is, predictably, easier to implement; somewhat surprisingly, though, it actually performs better than the method it approximates.",
        "When o = .7, for instance, the accuracy loss is only .28%, comparable to the table lookup result, but the number of edges popped drops to just 91.23, or 39.7% of the prior result found in [Go1d98].",
        "Using other demeriting factors gives similarly dramatic decreases in edge count, with varying effects on accuracy – see Figures 3 and 4.",
        "It is not immediately clear as to why demeriting improves performance so dramatically over the table lookup method.",
        "One possibility is that the statistical method runs into too many sparse data problems around the fringe of the data set – were we able to use a larger data set, we might see the statistics approach the curve defined by the demeriting.",
        "Another is that the bucketing is too coarse, although the interpolation along",
        "the independent merit axis would seem to mitigate that problem."
      ]
    },
    {
      "heading": "5 Conclusion",
      "text": [
        "In the prior work, we see the average edge cost of a chart parse reduced from 170,000 or so down to 229.7.",
        "This paper gives a simple modification to the [Go1d98] algorithm that further reduces this count to just over 90 edges, less than two times the perfect minimum number of edges.",
        "In addition to speeding up tag-stream parsers, it seems reasonable to assume that the demeriting system would work in other classes of parsers such as the lexicalised model of (Charniak, 1997)-as long as the parsing technique has some sort of demeritable ranking system, or at least some way of paying less attention to already-filled positions, the kernel of the system should be applicable.",
        "Furthermore, because of its ease of implementation, we strongly recommend the demeriting system to those working with best-first parsing."
      ]
    }
  ]
}
