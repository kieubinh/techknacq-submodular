{
  "info": {
    "authors": [
      "Sanda M. Harabagiu",
      "George A. Miller",
      "Dan Moldovan"
    ],
    "book": "SIGLEX Workshop on Standardizing Lexical Resources",
    "id": "acl-W99-0501",
    "title": "WordNet 2 - A Morphologically and Semantically Enhanced Resource",
    "url": "https://aclweb.org/anthology/W99-0501",
    "year": 1999
  },
  "references": [
    "acl-C92-2083",
    "acl-C92-4189",
    "acl-P90-1033",
    "acl-P92-1032",
    "acl-P99-1020"
  ],
  "sections": [
    {
      "heading": "Abstract",
      "text": [
        "This paper presents an ongoing project intended to enhance WordNet moiphologically and semantically The motivation for this work steams from the current limitations of WordNet when used as a linguistic knowledge base We envision a software tool that automatically parses the conceptual defining glosses, attributing part-of-speech tags and phrasal brackets The nouns, verbs, adjectives and adverbs from every definition are then disambiguated and linked to the corresponding synsets This increases the connectivity between synsets allowing the tetrieval of topically telated concepts Furthermore, the tool ttansforms the glosses, first into logical forms and then into semantic Rums Using derivational morphology new links are added between the synsets"
      ]
    },
    {
      "heading": "1 Motivation",
      "text": [
        "WordNet has already been x ecogmzed as a valuable tesource in the human language technology and know ledge processing communities Its applicability has been cited in mote than 200 papers and s)stems have been implemented using WordNet A WoidNet bibliogiapf* maintained at the Univeisit3 of Pennsyls ania (http //www cis upenn edu/-3osephr/wnMho html) In Europe, WordNet is being used to develop a multilingual database with basic semantic relations between words for several European languages (the EuroWordNet project) Capabilities WordNet was conceived as a machine-readable dictionary, following psycholinguistic principles Unlike standard alphabetical clictionai ies which otganize vocabulaties using mot phological similaiities, WordNet structures lexical Information in terms of word meanings WordNet maps word forms in word senses using the syntactic category as a parametei Although it covers only tout patts of speech nouns verbs, adjectives and ad-y erbs, it encompasses a large majority of English words (http //www cogsu princeton edu/'wn) Woids of the same syntactic categoi) that can be used to express the same meaning are grouped into a single synonym set, called synset Words with multiple meanings (polysemous) belong to multiple synsets An important part of the 99 643 synsets encoded in WordNet 1 6 contain word collocations, thus representing complex nominals (e g the synset {manufacturer, maker, manufacturing business} , complex vet-bals (e g the synset {leave office, quit, step down), complex adjectivals (e g the synset {true, dead on target} or complex adverbials (e g the synset {out of hand, beyond control} The tep-tesentation of collocations as synset entt les movides for their semantic interptetation \\Voids and concepts are furthet connected through a small set of lexico-semantic relations The dominant semantic relation is the hypernymy, which structures the noun concepts in 11 hier-aichies and the verb concepts into 312 hietatchies Thiee metonym telations are encoded between noun concepts the has_member, the has_staff and the has_part Ielations Logical opeiations between events or entities ate modeled through entailment and cause_to telations between vetb concepts or antonymy relations among nouns, vetbs adjectives or adverb words Theme are only a few mot-phologically motivated connections between words known as pertaynym relations Limitations The main weaknesses of WoIdNet cited in the litetature ate",
        "2 Limited number of connections between topically related words 3 The lack of morphological relations 4 The absence of thematic relations/ selectional restrictions 5 Some concepts (word senses) and relations are missing 6 Since glosses were written manually, sometimes theie is a lack of uniformity and consistency in the definitions",
        "The key idea in our project is to put to work the rich sourse of information contained in glosses that now can be used only by humans to read the definition of synsets For example, WordNet 16 lists the concept {cat, true cat} with the gloss (feline mammal usually having thick soft fur and being unable to roar, domestic cats, wildcats) Currently, from a concept like this, only a few other concepts could be reached In Extended WordNet, the concept {cat, true cat} will be related to 215 other concepts (10 from its own gloss, 38 from the glosses of its hyper-ny ms, 25 concepts that use it in their glosses as a defining concept plus other 142 concepts with which the concept interacts in these 25 glosses) This level of information is rich enough to presume that the Extended WordNet will work well as a knowledge base for common-sense reasoning"
      ]
    },
    {
      "heading": "2 Related work",
      "text": [
        "Machine Readable Dictionaries (MRDs) have long been recognized as N aluable resources in computational linguistics In their paper, Ide and Veroms (Ide and Veroms, 1993) projected a rather pessimistic outlook for the utility of MRDs as knowledge sources, a view that has impeded the enthusiasm of some researchers (Wilks et al. 1996) make a strong argument in favor of using MRDs and shale then positive experience with using some dictionaries The MindNet project at Microsoft aims at fully automating the development of a very large lexical knowledge base using two MRDs the Long-man Dictionary of Contemporary, English (LDOCE) and the American Heritage Third Edition (AHD3) Many technical aspects of this project are rooted in the works of Vanderwende (Vanderwende 1996) and Richardson (Richardson 1997)"
      ]
    },
    {
      "heading": "3 Word sense disambiguation of gloss concepts",
      "text": [
        "There are several differences between gloss disambiguation and text disambiguation A major difference is that in our project we know the meaning of each gloss, namely the synset to which a gloss applies Second, the glosses contain a definition, comments, and one or more examples We address the word sense disambiguation problem by using three complementary methods (a) heuristics, (b) conceptual density, and (c) statistics on large corpora The first two methods rely entirely on the information contained in WordNet, while the third one uses other corpora Specifically, the sources of knowledge available to us ate (1) lexical information that includes part of speech, position of words (i e head word), and lexical relations (2) collocations and syntactic patterns, (3) sy nset to which a gloss belongs, (4) hypernyms of sy nset and their glosses (5) synsets of poly semouns words and their glosses, (6) hypernyms of synsets of polysemous words, and their glosses, and so on"
      ]
    },
    {
      "heading": "Method 1 Classes of heuristics for word sense disambiguation",
      "text": [
        "A suitable technique for disambiguating dictionaries is to rely on heuristics able to cope with different sources of information Work in tins area was done by Ravin (Rat in 1990) in a similar project at IBM, (Klavans et al. 1990), and others We present now some of the heuristics used by us",
        "1.",
        "Class Hypernyms",
        "A way of explaining a concept is to specialize a more general concept (1 e a hypernym) It is likely that an explanation begins with a phrase whose head is one of its hypernyms, and the features are expressed either as attributes in the same phrase or as phrases attached to the first phrase Example The gloss of synset {intrusion} is (entrance by force or without permission or welcome) • entrance#3, the head of the first phrase, is a hypernym of intrusion, thus we pick sense 3 of noun entrance (The senses in WoidNet are ranked according to then frequency of occurrence in the Brown corpus, entrance#3 means sense 3 of word entrance )"
      ]
    },
    {
      "heading": "2 Class Linguistic Parallelism",
      "text": [
        "It is likely that the syntactic parallelism of two words translates into semantic parallelism and the words may have a common hypernym, or one is a hypernym of the other For adjectives, the hyperny my is replaced by the similarity relation Other heuristics in this class check whether or not two polysemous words belong to the same synset, or one is a hy-perny m of the other, or if they belong to the same hierarchy Example The gloss of {interaction} is (a mutual or reciprocal action)",
        "• Adjective reciprocal has only one sense in WordNet 1 6, whereas mutual has two senses But we find that between sense 2 of mutual and reciprocal there is a similar link in WordNet 1 6, thus pick mut uallt2 3.",
        "Class.",
        "Gloss Comments.",
        "In glosses, comments and examples are meant to provide supplemental information It is possible to find the specialization or typical relation linking the comment to the preceding head phrase in one of the synsets (or gloss) of the head phrase Example The gloss of the synset {scuff, scuffing} is (the act of scuffing (scraping or dragging the feet))",
        "• In WordNet 1 6 there is a synset {scuf f #1, drag}, thus verb scuff is disambiguated"
      ]
    },
    {
      "heading": "4 Class. Gloss Examples",
      "text": [
        "Examples in WordNet provide collocatronal information of the words in synsets The intrinsic semantic tag of the word from the synset which is used in the example can occur in the same lexical relation in some other gloss, carrying the semantic tag with it Example Synset {penetration} has the gloss (the act of forcing a way into something)",
        "• [wirw2] = [force way] The gloss of {way#9} contains the example (\" I had it my way\"), providing the lexical relation [w3rw2] = [have way] • Noun way is disambiguated (sense 9), and verbs have#7 and f orce#9 have a common hypernym, therefore verb force is also disambiguated"
      ]
    },
    {
      "heading": "5 Class Collocations",
      "text": [
        "Nouns representing actions are nominalizations of some verbs If a verbal collocation contains a noun, and is also a synonym of some morphologically related verb, then it is likely to be the nommalization source The verb from the gloss of a synonym describing an action, if not the source of the nomi-nalization is likely to belong to the same hierarchy as the true nommalization source, since they must share some properties Example Let s = {escape, flight}, with the gloss (the act of escaping physically)",
        "• The verb escape is morphologically identical to the noun escape from synset s • Sense 1 of verb escape has a hypernym collocation using noun flight from s, thus is selected"
      ]
    },
    {
      "heading": "6 Class Lexical Relations",
      "text": [
        "A. lexical relation using a word w both in the gloss of a sy nsct s and in some other gloss signals a property of w associated NI lth S In other cases when two relations [w,/ tv.,] and [w,/ wk] are found in two glosses of WordNet, and there are senses of w, and wk that have a common hypernym, it is likely that the correlation between w, and the common hypernym projected in both collocations Example The gloss of the synset {Underground Railroad} is (abolitionists secret aid to escaping slaves)",
        "• We have [wirw2] = [aid to slave] • The gloss of { aid#4} is (aid to someone) • The pronoun someone can refer to {slave#1} thus sense 4 of noun aid is picked"
      ]
    },
    {
      "heading": "Method 2 Conceptual density method",
      "text": [
        "We have implemented a WSD system for free text that disambiguates multiple words simultaneously (Nlihalcea and Moldovan, 1999) The method is based.",
        "on measuring the number of common nouns shared by the verb and noun hierarchies, and thus gets around the lack of connections problem As an example, consider a verb - noun pair of words Denote with < vi,v2„ vh > and < n1, n2, 71/ > the senses of the verb and the noun in Woi dNet For each possible pan v, – n„, the conceptual density is computed as follows 1 Extract all the glosses from the sub-hierarchy of th and determine the nouns from these glosses This constitutes the noun-context of verb v, Each such noun is stored together with a weight w that indicates the level in the sub-hierarchy of the verb concept in whose gloss the noun was found 2 Determine the glosses of the noun sub-hierarchy of nj and determine the nouns in them 3 Compute the conceptual density Ci) of the common concepts between the nouns obtained at (1) and the nouns obtained at (2) using the metric",
        "where",
        "• icd is the number of common concepts between the hierarchies of v, and n, • Wk are the levels of the nouns in the hierarchy of verb v, • descendents) is the total number of words within the hierarchy of noun nj",
        "4 C,, tanks each pair v, – n, for all z and j Van-ants of this method work for other parts of speech pairs such as noun-noun, noun-verb, verb-verb, verb-noun, adjective-noun and verb-adverb This is a powerful method that works surprisingly well even for free text We ha') e tested the method on SemCor, the part of the Brown corpus tagged with WordNet senses With this technique it is possible to rank the senses and to keep not only the first ranked sense, but the second or thud ranked senses",
        "especially when the ranking is sufficiently close and there is another way to check the validity of the disambiguation"
      ]
    },
    {
      "heading": "Method 3 Statistics on large corpora",
      "text": [
        "As a last resort, we can use a statistical approach to disambiguate those words that can not be done with any of the methods described so far Consider a collocating word-word pair w1 – w2 in which we consider that wi has been disambiguated already The disambiguation of w2 proceeds as follows",
        "(1) For each sense w;, form a similarity list with w; and all other words that may be in that synset",
        "(2) Form pans of w1 and all the words in each similarity list for all i",
        "(3) Search a large corpus for the occurrences of any of the pans in the list above",
        "{ woul,\" OR w1w21(1)\" OR \"w1w21)\" We have searched the Internet using the AltaVista search engine The number of hits for each similarity list measures the relatedness of wi with each sense to; and thus provides a ranking of the senses"
      ]
    },
    {
      "heading": "Overall Procedure and Results",
      "text": [
        "The following procedure was used to disambiguate 12,762 words from 1000 randomly selected glosses Step 1 Identify and separate the monosemous words - that have only one sense in WordNet (in our experiment 6468 words were found) Step 2 Apply Method 1 - Heuristics - to the remaining 6294 polysemous words Method 1 provides correct disambiguation for 5475 words, thus an accuracy of 87% Out of the remaining 13% of the words, 3% were disambiguated erroneously and 10% could not be done with the heuristics used The collect sense for each word was determined manually by a team of three students We ha‘e found a few s3 nsets such as {commemorate, remember} that have no links to any other synsets, le no h3 perny ms and no hypomynis Step 3 Apply Method 2 - Conceptual Density - to the 6294 polysemous words, star ting fresh Step 4 Apply Method 3 - Statistics - to the 6294 words using AltaN ista on the Internet Step 5 The results obtained with Method 1 and Method 2 are combined, that is, take all the words that were disambiguated, and in the case of conflict give priority to Method 1 Step 6 The results from Step 5 are combined with the results given by Method 3 and in the case of conflict give priority to results obtained in Step 5 Table 1 indicates the accuracy obtained at each step An overall accuracy of 94% was achieved Our goal is to improve the technique to be able to disambiguate all words automatically These results must be seen against the background average rate of 59 39% correct sense assignment achieved when the first WordNet sense is assigned to each polysemous word This is considered the baseline performance level for word-sense disambiguation programs (Gale et al. 1992) and is consistent with our own measurements"
      ]
    },
    {
      "heading": "4 Logical form transformation",
      "text": [
        "Our extension of WordNet intends to serve as a lexico-semantic resource for a variety of NLP applications, many of them requiring pragmatic and common-sense knowledge (Harabagm and Moldovan 1998) It is beneficial to transform the conceptual glosses in logical formulae Approach to implement Logical Form Transformations (LFTs)",
        "(1) Traditional lexicographic principles determine the discrimination of any conceptual definitions into a genus and the differentia Our LFTs implement the same distinction by always placing the genus predicate on the first position of the LFT, and the rest of the LFT viewed as the definition differentia (2) A predicate is generated for every noun, verb, adjective or adverb encountered in any gloss The name of the predicate is a concatenation of the morpheme's base form, the part-of-speech and the WordNet semantic sense, thus capturing the full lexical and semantic disambiguation For example, the LFT of the gloss of {student, pupil, educatee} contains the predicates learner n#1, enroll v#1 and educationalinstitution n#1 (3) In the spirit of the Davidsoman treatment of the action predicates, all verb predicates (as well as the nominalizations representing actions, e‘ents or states) hal, e three arguments action/state/eventpredicate(e„Li where • e, represents the eventuality of the action state or ¢ r stated by the N.erb to take place, • a.1 represents the syntactic subject of the action event or state, and • zi2 represents the syntactic object of the action event or state",
        "In the case when the subject or the object are present in the gloss, they share the corresponding arguments with the action/state/event predicate For example, the LFT of (a person who backs a politician) the gloss of {supporter, protagonist, champion, admirer, booster, friend} is LFT = [person n#1(2,1) Sz back v#1(e1,114)) politician n#2(x2)",
        "(4) The role of complements within a phrase is replicated in the LFTs Predicates genelated from modifiers share the same arguments with the predicates corresponding to the phrase heads Adjective 'medicates share the same argument as the predicate corresponding to the noun they modify An exemplification is the LFT of the gloss of {art if act , artefact}, which maps (a man-made object) into [ object n#1(xi) Sc man-made a#1(xi)1 Similarly, the argument of adverbial predicate is the argument marking the eventuality of the event/state/action they modify For example, the gloss of the verb synset {hare} is (run quickly), producing the LFT = [run(e1,2,1,x2) quickly(e1)] (5) Conjunctions ate transformed in predicates, which enable the aggregation of several predicates under the same syntactic role (e g subject, object or prepositional object) By convention, conjunction-predicates have a variable number of arguments, since they cover a variable number of predicates The first argument represents the \"result\" of the logical operation induced by the conjunction (e g a logical and in the case of the and conjunction, or a logical or in the case of the or conjunction) The rest of the aiguments indicate the predicates covered by the conjunction, as they are aiguments of those predicates as well (6) We also genezate 'medicates for every preposition encountered in the gloss The preposition predicates always have two arguments the first argument corresponding to the predicate of the head of the phiase to which prepositional phiase is attached, whereas the second argument corresponds to the prepositional object Sources of information.",
        "The implementation of LFTs relies on information provided by",
        "(a) Lexical and semantic disambiguation pioduced in the pieprocessing and semantic disambiguation phases This information contributes to the creation of predicate names (b) Phrasal parsing, enabling the recognition of basic and complex phrases This determines all complements to share the same predicate argument with the phi ase head (c) Syntactic tiansformation rules, discriminating the syntactic subject and object of every vet b (oi noininalization) based on the local syntactic context (d) Prepositional attachment resolution, indicating the arguments of the preposition 'medicates",
        "Table 2 illustiates the tiansfoimations for the gloss of {tennis, lawn tennis}"
      ]
    },
    {
      "heading": "5 Semantic form transformation",
      "text": [
        "Many NLP problems iely on the recognition of the typical lexico-semantic ielationships between linguistic concepts The LFT codification met ely acknowledges the following syntax-based relationships (1) syntactic subjects, (2) syntactic objects (3) prepositional attachments (4) complex nominals and (5) adjectival/adverbial adjuncts Semantic interpretations of utterances, as well as discoui se processing require knowledge about the semantic or thematic relationships between concepts The semantic form transformations provide with constraint-based mappings of the syntax-based relations covered in the LFTs into binary thematic relations or semantic relations (We distinguish between thematic tela-tions such as agent, expenencer, etc, and semantic relations such as a-kind-of, part-of, etc ) Approach to implement Semantic Form Transformations (SFTs) 1 The syntactic subject relations iecognized in the LFTs by the predicative formula subject(zi )&verb(e, .21,3,2) can be mapped into a N a-iiety of thematic relations The definition of the thematic relations is entirely based on infounation internal to the WordNet database, expiessed as constraints Foi example, all the subjects of verbs that are hyponyms of the verb cause or have this concept as the genus of then glosses are defined to represent the role of agents (2) The syntactic object ielations ate lec-ognized in the LFTs by the predicative formula verb(ei noun(z2) The definition of the thematic relations in which syntactic objects can be mapped is expressed in terms of verb synsets The constraining verb synsets lepresent the uppermost hypernyms of all verbs that (z) have syntactic objects in the WordNet glosses and (ii) belong to the same hierarchy or ale defined by gloss geni from the same hiei archy (3) The prepositional predicates ale tiansfoimed into thematic oi semantic relations When a Word",
        "Net semantic relation holds between the arguments of a prepositional predicate, that specific relation becomes the semantic transformation of the predicate For example, the PP attachment [sacrament of penance} derived from the gloss of {confession} indicates a semantic kind-of relation due to the fact that in WordNet penance is a hyponym of sacrament",
        "(4) The transformation of complex nominal predicates into thematic or semantic constraints is done by first seeking a WordNet relation (or a combination of such relations) between the components of the predicate If such a (chain of) relation(s) found, predicate nn is transformed into the dominant WordNet semantic relation Otherwise, the nn predicate is transformed into a thematic relation (5) The transformation of adjectival and adverbial adjuncts, represented in the LFTs as predicates sharing the same argument with the concepts they modify shall be connected to their modifiers through attribute relations"
      ]
    },
    {
      "heading": "6 Include more derivational morphology",
      "text": [
        "Since the organization of WordNet divides the English vocabulary into four separate domains-nouns, verbs, adjectives, and adverbs closely related concepts are often entered in more than one of these domains Many (probably most) of these relations can be identified in terms of derivational morphology, e g, the noun execution is derived from the verb execute and so is an example of a deverbal noun WordNet already contains some of this kind of derivational morphology deadjectival nouns are linked to their root adjectives (length is derived twin long), deadjectival adverbs are linked to then root adjectnes (rapidly is derived from rapid), and some denominal adjectives are linked to then root nouns (cellular is derived from cell) In order to increase the connectivity of WordNet it would be desirable to include more such derivational morphology For example, derivational relations between nouns and verbs should be particularly useful (Hull and Gomez 1996) both deverbal nouns (avowal from avow) and denoininal verbs (summarize from summary) Such connections would facilitate the recognition that the same idea can be expressed in different ways, e g , that \"He summarized the book\" and \"He gave a summary of the book\" are effectively equivalent in meaning Sometimes these morphological relations can be picked up from glosses, as when {disagreement} is defined as (the speech act of disagreeing or arguing or disputing), but these are generally regarded as uninformative definitions, and the reverse relation may not happen to occur Since many of the words are polysemous, morphological relations should not link words, but synsets that have related meanings For example, {execute} meaning (to put to death) should be linked to {execution} meaning (the act of putting a condemned person to death), and {execute} meaning (to carry out a task) should be linked to {execution} meaning (the act of doing something successfully), etc And in cases where the concepts of the noun and verb are different-e g, {womanize} from {woman}-no semantic link would need to be created"
      ]
    }
  ]
}
