{
  "info": {
    "authors": [
      "Daniel Ka-Leung Chan",
      "Dekai Wu"
    ],
    "book": "Joint SIGDAT Conference on Empirical Methods in Natural Language Processing and Very Large Corpora",
    "id": "acl-W99-0630",
    "title": "Automatically Merging Lexicons That Have Incompatible Part-Of-Speech Categories",
    "url": "https://aclweb.org/anthology/W99-0630",
    "year": 1999
  },
  "references": [
    "acl-P98-2230"
  ],
  "sections": [
    {
      "heading": "Abstract lemma tag",
      "text": [
        "We present a new method to automatically merge lexicons that employ different incompatible POS categories.",
        "Such incompatibilities have hindered efforts to combine lexicons to maximize coverage with reasonable human effort.",
        "Given an \"original lexicon\", our method is able to merge lexemes from an \"additional lexicon\" into the original lexicon, converting lexemes from the additional lexicon with about 89% precision.",
        "This level of precision is achieved with the aid of a device we introduce called an anti-lexicon, which neatly summarizes all the essential information we need about the co-occurrence of tags and lemmas.",
        "Our model is intuitive, fast, easy to implement, and does not require heavy computational resources nor training corpus."
      ]
    },
    {
      "heading": "1 Motivation",
      "text": [
        "We present a new, accurate method to automatically merge lexicons that contain incompatible POS categories.",
        "In this paper, we look specifically at the problem that different lexicons employ their own part-of-speech (POS) tagsets that are incompatible with each other, owing to their different linguistic backgrounds, application domains, and/or lexical acquisition methods.",
        "Consider the way that lemmas are typically marked with POS information in machine-readable lexicons.",
        "For example, here are a few entries from the lexicon in Brill's tagger (Brill, 1994) and the Moby lexicon (Ward, 1996), showing simple pairs of lemmas and POS tags:",
        "Perhaps the most natural first approach to merging the lexicons is to construct a set of POS mapping rules.",
        "For example, we might wish to acquire the following mapping rules: ( \"NN\" , \"N\" ( \"VB\" , \"V\" ) .",
        "Here, the first rule says that the \"NN\" POS in the Brill lexicon should be mapped to the \"N\" POS in the Moby lexicon.",
        "Of course, not all POS tags can be accurately translated this way, but the strategy is a reasonable first approximation.",
        "In order to incorporate entries from other lexicons into the current knowledge base, the mapping rules between different POS tagsets are usually formulated by hand in ad hoc ways.",
        "In view of this heterogeneity and human subjectiveness, some people had begun to investigate and develop methods of learning the mapping rules between different POS categories in different lexicons.",
        "Teufel described a tool to support manual mapping between different tagsets using a rule-based approach (Teufel, 1995).",
        "This approach requires heavy human intervention, and therefore does not scale up easily.",
        "Another ap",
        "proach was proposed by Hughes et al., to automatically extract mapping rules from corpora tagged with more than one annotation scheme (Hughes et al., 1995).",
        "However, the dependence on multiply-annotated corpora requires heavy annotation and/or computation resources, whereas we are investigating methods with only the information found in existing lexicons.",
        "In this paper, we will begin by presenting a basic method that generates a set of mapping rules.",
        "Experimental results on a variety of lexicons will be presented.",
        "We will then introduce a mechanism called an \"antilexicon\" that significantly improves precision on the learned rules and merged lexicons, though at a cost to recall."
      ]
    },
    {
      "heading": "2 Basics",
      "text": [
        "Our general strategy is to inspect the co-occurrence of tags on those lemmas that are found in both lexicons, and to use that information as a basis for generalizing, thus yielding POS mapping rules.",
        "To do this requires several steps, as described in the following subsections.",
        "As a preliminary step, we will introduce a way to represent POS tags using feature vectors.",
        "We then use these vectors to generate mapping rules.",
        "To obtain better accuracy, we can restrict the training examples to entries that occur in both lexicons.",
        "The generation algorithm also requires us to define a similarity metric between PUS feature vectors."
      ]
    },
    {
      "heading": "2.1 Part-of-speech feature vector",
      "text": [
        "A necessary preliminary step of our method is to introduce POS feature vectors.",
        "A feature vector is a useful representation of a POS tag, because it neatly summarizes all the information we need about which lemmas can and cannot have that POS tag, illustrated as follows.",
        "Given:",
        "• a lemma set .A/1 ={ \"apple\", \"boy\", \"calculate\" } • a set of POS tags P ={\"NN\",\"VB\"}",
        "A tiny example lexicon consisting of lemma and POS tag pairs might be as follows, where each cell with • indicates the existence of that lemma-POS pair in the lexicon: apple boy calculate",
        "where P1 here is the \"NN\" POS represented by the set of words that can be nouns in a given lexicon, in this example { \"apple\", \"boy\" } and P2 similarly is the \"VB\" POS.",
        "The feature value for feature f in 7-jean be either:",
        "• 0 to indicate that we are not sure whether p is a tag of f; • 1 to indicate that p is a tag for f; • 2 to indicate that p can never be a tag for lemma f.",
        "Obtaining information about the last of these (the value 2) is a non-trivial problem, which we will return to later in this paper.",
        "With ordinary lexicons, we only directly obtain feature vectors containing 0 and 1 values."
      ]
    },
    {
      "heading": "2.2 Mapping rule learning algorithm",
      "text": [
        "Given a feature vector for every PUS tag in both lexicons say, Brill's lexicon and the Moby lexicon we use the following algorithm to learn mapping rules from POS tags in Bull's tagset to PUS tags in the Moby tagset.",
        "The idea is to assume that a mapping rule between two PUS tags holds if the similarity between their feature vectors exceeds a preset threshold, called a sim-threshold T. The similarity metric (SimScore) will be described later, but let's first look at the learning algorithm, as described in algorithm 1.",
        "This algorithm does not exclude m-to-n mappings; that is, any Brill PUS tag could in principle get mapped to any number of Moby PUS tags.",
        "end end end Algorithm 1: Mapping rule learning algorithm"
      ]
    },
    {
      "heading": "2.3 Improving the training set by intersecting the lexicons",
      "text": [
        "We can obtain better results by considering only those lemmas that occur in both lexicons.",
        "This has the effect of eliminating unreliable features in the POS feature vectors, since lemmas that do not occur in both lexicons cannot be relied upon when judging similarity.",
        "This results in pruned versions of both lexicons.",
        "For example, pretend that the following are the only entries in the Brill and Moby lexicons:"
      ]
    },
    {
      "heading": "Moby lexicon",
      "text": [
        "In this case, intersecting the lexicons would result in the following pruned lexicons: Of course, in reality the lexicons are much bigger and the effect is not so drastic.",
        "In all experiments in this paper, we used lexicon intersection to prune the lexicons."
      ]
    },
    {
      "heading": "2.4 Similarity metric",
      "text": [
        "The similarity function we use calculates a similarity score between two feature vectors by counting the number of features with the same feature value 1 or 2, indicating that a lemma either can or cannot belong to that POS category.",
        "(Recall that the value",
        "0 means \"don't know\", so we simply ignore any features with value 0.)",
        "The score is normalized by the length of the feature vector.",
        "We also require that there be at least one positive match in the sense that some lemma is shared by both of the POS categories; otherwise, if there are only negative matches (i.e., lemmas that cannot belong to either PUS category), we consider the evidence to be too weak and the similarity score is then defined to be zero.",
        "The whole algorithm is described in algorithm 2.",
        "2.5 The \"complete lexicon\" assumption As mentioned earlier, ordinary lexicons do not explicitly contain information about which parts of speech a lemma can not be used as.",
        "We have two choices.",
        "In the examples up till now, we used a value of 0 for any lemma-tag pair not explicitly listed in the lexicon, signifying that we don't know whether the POS category can include that lemma.",
        "However, having many \"don't know\" values significantly weakens our similarity scoring method.",
        "Alternatively, we can choose to assume that our lexicons are complete – a kind of closed world assumption.",
        "In this case, we assume that any lemma-tag pair not found in the lexicon is not merely an omission, but really can never occur.",
        "This means we use the value 2 instead of the value 0.",
        "The \"complete lexicon\" assumption only makes sense when we are dealing with large, broad coverage lexicons (as is the case in this paper).",
        "It is not reasonable when dealing with small or specialized sublexicons."
      ]
    },
    {
      "heading": "3 Anti-lexicon",
      "text": [
        "Based on the above intuition on utilizing negative information, we propose an improved model using something we call an anti-lexicon, that indicates the PUS tags that a lemma cannot have, which we will call its anti-tags.",
        "A POS tag p is called an anti-tag a of a lemma m if p can never be a tag of m. The anti-lexicon consists of a set of pieces of this negative information, each called an anti-lexenze def (rn, where is the anti-tag of lemma m, and p is a POS used in the lexicon.",
        "Some examples of anti-lexemes are:",
        "where \"IN\" ,\"JJ\" and \"VB\" are the preposition, adjective and verb tags in Brill lexicon respectively.",
        "Similar to a traditional lexicon which contains lexemes in the form of pairs of lemmas and their corresponding possible PUS tag(s), an anti-lexicon contains anti-lexernes which are simple pairs that associate a lemma with an anti-tag.",
        "The anti-lexicon can be automatically generated quickly and easily.",
        "To illustrate the idea, consider an example lexicon where we add the lemma \"Central\" and the POS \"NP\" to the example lexicon we have been working with.",
        "Suppose we want to know whether \"Central\" can be a \"NN\", and whether \"calculate\" can be a \"NN\".",
        "The fact that \"apple\" can be tagged by both \"NN\" and \"NP\", but not \"VB\" , gives \"Central\" (a lemma that is already known to be able to serve as an \"NP\") a higher likelihood of possibly serving as an \"NN\" than \"calculate\" (a lemma that is not known to be able to serve as an \"NP\").",
        "Based on this assumption that lexernes with similar semantics will have similar POS tags, we conceptualize this kind of pattern in terms of \"cohesion\" between lemmas and POS tags in a lexicon.",
        "The \"cohesion\" of a lemma 1 and a POS tag p measures the likelihood of a POS tag p being a possible tag of a lemma 1, and is defined as:",
        "where cohesion(\"Central\", \"NN\") = 0.5",
        "number of lemmas in the lexicon for which Pi,P2, ,p,„ are all legal POS tags of 1, and the probability Pr (PIP1) P2 • • • , pn) is just a simple relative frequency of the lemmas that can have all the POS in the Therefore \"NN\" is more likely to be associated to \"Central\" than \"calculate\", which implies \"NN\" will be less likely to be the valid POS to \"calculate\" than to \"Central\".",
        "tags.",
        "Entries with low cohesion will be considered as anti-lexemes and inserted into the anti-lexicon.",
        "where A is a threshold called anti-threshold, usually a very small real number between 0 and 1.",
        "In our example, if we set anti-threshold to 0.4, \"NN\" will become an anti-tag for \"calculate\" but not for \"Central\".",
        "Since the lemmas in actual lexicons usually have many possible POS tags, their cohesion to any PUS tag will in turn be smaller than the cohesion in our simple example.",
        "To create a more accurate anti-lexicon, we should set the anti-threshold to smaller value."
      ]
    },
    {
      "heading": "4 Lexicon merging algorithm",
      "text": [
        "Given a POS mapping table 5 between the POS tagset P used by the original lexicon Lq and the PUS tagset Q used by the additional lexicon LP, we merge the entries from the additional lexicon into the original lexicon by an algorithm as shown in algorithm 3.",
        "This algorithm does not exclude Triton POS mappings; that is, a lexeme in the additional lexicon can generate more than one lexeme and we can merge all of them into the original lexicon."
      ]
    },
    {
      "heading": "5 Experiment",
      "text": []
    },
    {
      "heading": "5.1 Setup",
      "text": [
        "We tested the above method in a set of experiments using four commonly-used machine-readable dictionaries.",
        "They are Brill's lexicon, the Moby lexicon, the Collins lexicon, the Oxford machine-readable dictionary, with characteristics as summarized in table 1.",
        "The lexicons use distinct POS tagsets of different tag granularities, as summarized in table 2.",
        "With these four training lexicons we can test twelve pairwise lexicon merging tasks, as shown in table 3.",
        "For each pairs of lexicon combination, we intersect them by the strategy mentioned before and produced a",
        "new set of training lexicons in each task.",
        "Note that the trimmed down Brill lexicon in the \"Brill-to-Collins\" task is not the same as the trimmed down Brill lexicon in \"Brill-to-Moby\".",
        "In order to evaluate the accuracy of our methods, we asked a linguist to manually create twelve \"gold standard\" sets of PUS mapping rules, R, one for each of the twelve pairwise lexicons on the semantics between the POS tag only.",
        "We then ran the experiments to automatically generate two sets of PUS mapping tables, with one under the complete world assumption and another using an anti-lexicon in each merging task.",
        "We evaluated precision and recall on POS mapping rules as follows: precision on POS mapping rules = I el I where",
        "• E is the resulting tagset mapping table containing all mapping rules obtained from experiment; • el is the subset of E which contains all correct mapping rules in R. (E E"
      ]
    },
    {
      "heading": "C",
      "text": [
        "recall on POS mapping rules = Ra Using an anti-threshold A ----- 0.00001, we cre- ated twelve anti-lexicons which can then be used in our algorithm.",
        "We obtained the POS mapping results as shown in table 4.",
        "In the baseline model, the precision is very low, mainly due to data sparseness caused",
        "tagset granularity size example tags on noun, proper noun, adjective, verb Penn TreeBank fine 43 NN, NP,JJ, VV Collins tagset fine 32 n, n, adj, vb Moby tagset coarse 15 n, n, a, v Oxford tagset coarse 20",
        "lexicon_insertor (ZP,Gq)",
        "input : 1.",
        "Two sets of lexemes, each lexeme in the form of a pair of lemma and POS.",
        "• rP {(Tni,P.i), • • .}",
        ".",
        "Lq = {(mk, .1 2.",
        "A POS mapping table B from the POS tagset P to POS tagset Q • B = { • • .1 output : An enlarged set of lexemes in .Cq, which contains newly inserted lexemes converted from ZP.",
        "where (pi, qs) e 13, and (m7, q,) rq for all k, 1, p, q, r, s",
        "if (Tni, q,) not in ,Cq then rg 4 lYu (m, q8)}",
        "end end end Algorithm 3: Lexicon merging algorithm",
        "by the fact that machine readable lexicons usually do not contain full lexeme coverage.",
        "This means our \"complete lexicon assump-tion\" which says that we can interpret entries not being in the lexicon as \"negative examples\" is not correct.",
        "In the anti-lexicon model, the precision greatly improves, with some experiments even achieving 100% precision.",
        "Unfortunately, the recall suffers sharply.",
        "After automatically constructing the POS mapping tables from training, we proceeded to merge lexicons in each testing task using the lexicon merging algorithm described above, and evaluated the accuracy of the merged lexicons as follow.",
        "In each merging task, we randomly selected 100 lexemes from the additional lexicon.",
        "Given these 100 lexemes, a linguist first manually constructs a set of correctly converted lexemes, which will be used as the \"gold standard\" set of lexernes, RL.",
        "Similar to the evaluation criteria outlined for POS mappings, we define the precision and recall on lexicon merging as the following: ELF precision on lexicon merging = lel' where",
        "• EL is the set of lexemes generated by the lexicon insertor.",
        "• EL' is the subset of EL that contains all lexemes in RI",
        "recall on lexicon merging = I"
      ]
    },
    {
      "heading": "5.2 Results",
      "text": [
        "We obtain the results on lexicon merging as shown at table 5.",
        "The anti-lexicon model significantly improves the precision in both the generated PUS mapping rules and merged lexicons.",
        "Most of the 12 lexicon merging tasks achieve",
        "nearly more than 92% precision, which cannot be obtained by using even the gold standard mapping rules, as shown in table 6.",
        "The recall degradation using anti-lexicon is lower in lexicon merging than in POS mapping rule learning, owing to the fact that not all PUS tags appear in lexicons with same frequency.",
        "For example, nouns and verbs occur far more frequently than prepositions and adverbs.",
        "High recall in POS mapping rules will not necessarily yield more accurate converted lexemes, if all the mapping rules obtained are only those rarely-occurring POS tags.",
        "Conversely, the successful generation of a single correct mapping rule for a frequently-occuring POS tag greatly improves recall.",
        "The mapping rules generated by our anti-lexicon model confirm this assumption: recall for POS mapping rules is 8%, but for lexicon merging it improves to about 22%.",
        "Recall suffers sharply, but precision is more important than recall in lexicon merging.",
        "This is because the cost of post-lexicon clean up on lexemes with incorrect PUS tag in a lexicon after merging is very expensive.",
        "A set of high precision POS mapping rules guarantees a much cleaner resulting lexicon after merging.",
        "Thus during lexicon merging, a conservative algorithm, which generates fewer but more exact lexemes is preferable.",
        "task precision recall bm 0.6953 0.8203 bc 0.5081 0.8263 bo 0.3478 0.8136 cm 0.3697 0.9037 om 0.4006 0.9236 co 0.3103 0.9612 oc 0.4804 0.9340 mo 0.3160 0.9537 mc 0.3996 0.9162 ob 0.1590 0.8671 cb 0.2272 0.9007 mb 0.2157 0.8861 average 0.3664 0.8922 Table 6: Lexicon merging results using gold standard POS mapping rules To show how anti-lexicons affect the precision and recall on lexicon merging, we also ran experiments using different combinations of sim-thresholds and anti-thresholds.",
        "In most cases, the precision of lexicon merging obtained from anti-lexicon are much higher than those without.",
        "The results are summarized in table 7 and table 8.",
        "The",
        "best precision for lexicon merging is obtained from T = 0.8 and A = 0.00001 in a grid-search."
      ]
    },
    {
      "heading": "5.3 Discussion",
      "text": [
        "As mentioned earlier, the mapping rule learning algorithm we used permits m-to-n mappings so long as the mapping rules created for every tag in a lexicon reach the sim-threshold, that is, the confidence level specified by the lexicographer.",
        "An alternative approach that we are experimenting with is to allow only m-to-1 mappings, by simply choosing the mapping rule with highest similarity score.",
        "In theory, this would seem to limit the possible accuracy of the algorithm, but empirically we have found that this approach often yields higher precision and recall.",
        "Further investigation is needed.",
        "Different similarity scoring functions can also be used.",
        "If data sparseness is a serious problem, we can use a similarity score which counts only the lemmas which are tagged, but not the lemmas which are not tagged.",
        "One effect of ignoring unlikely tags in this way is that the need for an anti-lexicon is eliminated.",
        "We are also currently investigating the mapping power of such variant methods.",
        "In general, we have observed different behaviors depending on factors such as the granularity of the tagsets, the linguistic theories behind the tagsets, and the coverage of the lexicons.",
        "Finally, in addition to lexicon merging, POS mapping table is also useful in other applications.",
        "Wu and Wong apply them in their SITG channel model to give better performance in their translation application (Wu and Wong, 1998).",
        "There is a serious problem of low recall on our anti-lexicon model.",
        "This is because our model prunes out many possible PUS mapping rules which results in very conservative lexeme selection during the lexicon merging process.",
        "Moreover, our model cannot discover which POS tags in original lexicon have no corresponding tag in the additional lexicon.",
        "Our model took POS mapping rules as a natural starting point since this repre",
        "sentation has been used in earlier related work.",
        "However, our experiments showing low precision on lexicon merging even using the human-generated gold standard mapping rules indicates it might not be a good approach to use POS mapping rules at all to tackle the lexicon merging problems.",
        "Our next step will be to investigate models that are not constrained by the POS mapping rule representation."
      ]
    },
    {
      "heading": "6 Conclusion",
      "text": [
        "We present a new method to automatically merge lexicons that employ different incompatible POS categories, which merges lexernes from an additional lexicon into an original lexicon with 89% in average precision.",
        "We showed how precision in the final merged lexicon can be improved by introducing a model called anti-lexicon, which neatly summarizes all the essential information we need about the co-occurrence of tags and lemmas.",
        "Our model is intuitive, fast, easy to implement, and does not require heavy computational resources nor training corpus."
      ]
    },
    {
      "heading": "7 Acknowledgments",
      "text": [
        "Many thanks to Josephine Kwan and Harriet Lee for their help on hand-crafting the gold standard POS mapping rules and lexeme sets in the evaluation phrase.",
        "We also thank the SILC members, Ahoy Wong, Hong-sing Wong, Vincent Chow, James Pang for their rigorous constructive criticisms on our model and experiments."
      ]
    }
  ]
}
